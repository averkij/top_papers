[30.05.2025 05:13] Read previous papers.
[30.05.2025 05:13] Generating top page (month).
[30.05.2025 05:13] Writing top page (month).
[30.05.2025 06:16] Read previous papers.
[30.05.2025 06:16] Get feed.
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23762
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22653
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23693
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23747
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23621
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23604
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23716
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23419
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23380
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23660
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23359
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23606
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23585
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23559
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22961
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23735
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23416
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22421
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23758
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22618
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20755
[30.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.20088
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23754
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23742
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17818
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23745
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23625
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23253
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20282
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19286
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18087
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22943
[30.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.22126
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19360
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19236
[30.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.23646
[30.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20199
[30.05.2025 06:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[30.05.2025 06:16] No deleted papers detected.
[30.05.2025 06:16] Downloading and parsing papers (pdf, html). Total: 37.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23762.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23762.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23762.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.22653.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.22653.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.22653.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23693.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23693.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23693.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23747.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23747.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23747.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23621.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23621.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23621.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23604.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23604.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23604.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23716.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23716.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23716.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23419.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23419.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23419.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23380.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23380.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23380.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23660.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23660.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23660.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23359.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23359.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23359.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23606.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23606.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23606.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23585.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23585.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23585.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23559.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23559.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23559.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.22961.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.22961.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.22961.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23735.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23735.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23735.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23416.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23416.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23416.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.22421.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.22421.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.22421.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.23758.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.23758.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.23758.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.22618.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.22618.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.22618.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20755.
[30.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20755.json), skip PDF parsing.
[30.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20755.json), skip HTML parsing.
[30.05.2025 06:16] Success.
[30.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20088.
[30.05.2025 06:16] Downloading paper 2505.20088 from http://arxiv.org/pdf/2505.20088v2...
[30.05.2025 06:16] Extracting affiliations from text.
[30.05.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Multi-Domain Explainability of Preferences Liat Ein-DorI T Faculty of Data and Decision Sciences, Technion nitay@campus.technion.ac.il liate@il.ibm.com roiri@technion.ac.il 5 2 0 2 9 2 ] . [ 2 8 8 0 0 2 . 5 0 5 2 : r a "
[30.05.2025 06:17] Response: ```python
["Faculty of Data and Decision Sciences, Technion"]
```
[30.05.2025 06:17] Deleting PDF ./assets/pdf/2505.20088.pdf.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.23754.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.23754.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.23754.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.23742.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.23742.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.23742.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.17818.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.17818.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.17818.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.23745.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.23745.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.23745.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.23625.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.23625.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.23625.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.23253.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.23253.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.23253.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.20282.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.20282.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.20282.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.19286.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.19286.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.19286.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.18087.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.18087.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.18087.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.22943.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.22943.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.22943.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.22126.
[30.05.2025 06:17] Downloading paper 2505.22126 from http://arxiv.org/pdf/2505.22126v1...
[30.05.2025 06:17] Extracting affiliations from text.
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 2 ] . [ 1 6 2 1 2 2 . 5 0 5 2 : r SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model Yifan Chang1,2 Yukang Feng 2,3 Jianwen Sun2,3 Jiaxin Ai2,4 Chuanhao Li5 S. Kevin Zhou1 Kaipeng Zhang2,5 1 University of Science and Technology of China 4 Wuhan University 3 Nankai University 2 Shanghai Innovation Institute 5 Shanghai AI Laboratory "
[30.05.2025 06:17] Response: ```python
["University of Science and Technology of China", "Wuhan University", "Nankai University", "Shanghai Innovation Institute", "Shanghai AI Laboratory"]
```
[30.05.2025 06:17] Deleting PDF ./assets/pdf/2505.22126.pdf.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.19360.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.19360.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.19360.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.19236.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.19236.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.19236.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.23646.
[30.05.2025 06:17] Downloading paper 2505.23646 from http://arxiv.org/pdf/2505.23646v1...
[30.05.2025 06:17] Extracting affiliations from text.
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 2 ] . [ 1 6 4 6 3 2 . 5 0 5 2 : r Are Reasoning Models More Prone to Hallucination? Zijun Yao Yantao Liu Yanxu Chen Jianhui Chen Juanzi Li Tat-Seng Chua Junfeng Fang Lei Hou Department of Computer Science and Technology, Tsinghua University School of Computing, National University of Singapore yaozj20@mails.tsinghua.edu.cn "
[30.05.2025 06:17] Response: ```python
["Department of Computer Science and Technology, Tsinghua University", "School of Computing, National University of Singapore"]
```
[30.05.2025 06:17] Deleting PDF ./assets/pdf/2505.23646.pdf.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.20199.
[30.05.2025 06:17] Extra JSON file exists (./assets/json/2505.20199.json), skip PDF parsing.
[30.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.20199.json), skip HTML parsing.
[30.05.2025 06:17] Success.
[30.05.2025 06:17] Enriching papers with extra data.
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 0. ZeroGUI is an online learning framework that uses Vision-Language Models for task generation and reward estimation, enhancing GUI Agents' performance with minimal human intervention.  					AI-generated summary 				 The rapid advancement of large Vision-Language Models (VLMs) has propelled the develo...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 1. LLMs exhibit robustness to reward noise during post-training and achieve high performance using reasoning pattern rewards (RPR) in conjunction with noisy reward models.  					AI-generated summary 				 Recent studies on post-training large language models (LLMs) for reasoning through reinforcement le...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 2. A new benchmark, VF-Eval, evaluates the capabilities of MLLMs in interpreting AI-generated content videos across four tasks, highlighting challenges and demonstrating benefits in video generation through human feedback alignment.  					AI-generated summary 				 MLLMs have been widely studied for vid...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 3. Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting the...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 4. Two post-training strategies, distillation and RLVR, enable inference-time scaling in table reasoning tasks, resulting in a model (Table-R1-Zero) that matches GPT-4.1's performance using fewer parameters and shows strong generalization.  					AI-generated summary 				 In this work, we present the fi...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 5. EvoScale, an evolutionary and reinforcement learning-based method, enhances small language models' performance on real-world software engineering tasks by iteratively improving and refining outputs.  					AI-generated summary 				 Language models (LMs) perform well on standardized coding benchmarks ...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 6. AnySplat is a feed forward network that performs novel view synthesis without camera poses, using 3D Gaussian primitives and unified design for efficiency and quality across sparse and dense datasets.  					AI-generated summary 				 We introduce AnySplat, a feed forward network for novel view synthe...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 7. The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 8. UniRL is a self-improving post-training method for unified multimodal large language models that uses generated images as training data, enhancing both generation and understanding tasks without external data.  					AI-generated summary 				 Unified multimodal large language models such as Show-o an...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 9. Diffusion via Autoregressive models (D-AR) recasts the image diffusion process as a standard autoregressive task, achieving high-quality image generation with consistent previews and layout control using a large language model backbone.  					AI-generated summary 				 This paper presents Diffusion v...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 10. A new benchmark, VideoReasonBench, evaluates complex vision-centric video reasoning, finding that extended thinking budgets are crucial for improved performance compared to existing benchmarks.  					AI-generated summary 				 Recent studies have shown that long chain-of-thought (CoT) reasoning can s...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 11. Muddit, a unified discrete diffusion transformer, achieves fast and high-quality generation across text and image modalities by integrating pretrained visual priors with a lightweight text decoder.  					AI-generated summary 				 Unified generation models aim to handle diverse tasks across modalitie...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 12. Reinforcement learning algorithms are fundamental to align large language models with human preferences and to enhance their reasoning capabilities. However, current reinforcement learning algorithms often suffer from training instability due to loose on-policy constraints and computational ineffici...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 13. SafeScientist is an AI framework that enhances safety in AI-driven scientific research through multiple defensive mechanisms and is validated using the SciSafetyBench benchmark.  					AI-generated summary 				 Recent advancements in large language model (LLM) agents have significantly accelerated sc...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 14. ToMAP enhances LLM persuaders with Theory of Mind modules, improving opponent awareness and argument quality.  					AI-generated summary 				 Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably, while...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 15. Transformers have been established as the most popular backbones in sequence modeling, mainly due to their effectiveness in in-context retrieval tasks and the ability to learn at scale. Their quadratic memory and time complexity, however, bound their applicability in longer sequences and so has moti...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 16. Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces KVzip, a query-agnostic KV cache eviction method enabli...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 17. GeoDrive integrates robust 3D geometry into driving world models to improve spatial understanding and action controllability in autonomous navigation, enhancing safety and reliability.  					AI-generated summary 				 Recent advancements in world models have revolutionized dynamic environment simulat...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 18. LoRAShop, a framework for multi-concept image editing with LoRA models, leverages spatially coherent feature activation in Flux-style diffusion transformers to achieve seamless integration of multiple subjects or styles while preserving global context and identity.  					AI-generated summary 				 We...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 19. A novel block-wise approximate KV Cache and confidence-aware parallel decoding strategy improve the inference speed of diffusion-based large language models without significant quality loss.  					AI-generated summary 				 Diffusion-based large language models (Diffusion LLMs) have shown promise for...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 20. Uni-Instruct unifies and enhances one-step diffusion distillation methods through a novel diffusion expansion theory, achieving state-of-the-art performance in unconditional and conditional image generation and text-to-3D generation.  					AI-generated summary 				 In this paper, we unify more than ...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 21. A new automated method using concept-based vectors and a Hierarchical Multi-Domain Regression model improves preference explanations and predictions for large language models.  					AI-generated summary 				 Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, a...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 22. DeepTheorem enhances LLM theorem-proving through a large-scale natural language dataset and a tailored reinforcement learning strategy, achieving state-of-the-art results in informal theorem proving.  					AI-generated summary 				 Theorem proving serves as a major testbed for evaluating complex rea...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 23. Video generation has made substantial strides with the emergence of deep generative models, especially diffusion-based approaches. However, video generation based on multiple reference subjects still faces significant challenges in maintaining multi-subject consistency and ensuring high generation q...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 24. PatientSim generates diverse and realistic patient personas using clinical data to evaluate LLMs in medical dialogue settings.  					AI-generated summary 				 Doctor-patient consultations require multi-turn, context-aware communication tailored to diverse patient personas. Training or evaluating doc...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 25. TrustVLM enhances the reliability of Vision-Language Models by estimating prediction trustworthiness without retraining, improving misclassification detection in multimodal tasks.  					AI-generated summary 				 Vision-Language Models (VLMs) have demonstrated strong capabilities in aligning visual a...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 26. ZeroSep, a text-guided audio diffusion model, achieves zero-shot source separation through pre-trained models and text conditioning, outperforming supervised methods on various benchmarks.  					AI-generated summary 				 Audio source separation is fundamental for machines to understand complex acous...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 27. UniTEX generates high-quality, consistent 3D textures by using Texture Functions and adapting Diffusion Transformers directly from images and geometry without UV mapping.  					AI-generated summary 				 We present UniTEX, a novel two-stage 3D texture generation framework to create high-quality, cons...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 28. Entropy minimization with one sample and minimal optimization achieves significant performance improvements for large language models.  					AI-generated summary 				 We trained 13,440 large language models and found that entropy minimization requires only a single unlabeled data and 10 steps optimi...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 29. The study explores the structural patterns of knowledge in large language models from a graph perspective, uncovering knowledge homophily and developing models for graph machine learning to estimate entity knowledge.  					AI-generated summary 				 Large language models have been extensively studied...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 30. CheXStruct and CXReasonBench evaluate Large Vision-Language Models in clinical diagnosis by assessing structured reasoning, visual grounding, and generalization using the MIMIC-CXR-JPG dataset.  					AI-generated summary 				 Recent progress in Large Vision-Language Models (LVLMs) has enabled promis...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 31. A benchmark using deceptive text samples to evaluate compositional vulnerabilities in multimodal representations is introduced, and a self-training approach improves zero-shot methods by enhancing attack success and sample diversity.  					AI-generated summary 				 While pre-trained multimodal repre...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 32. The introduction of SridBench, a benchmark for scientific figure generation, reveals that current top-tier models, such as GPT-4o-image, fall short in semantic and structural accuracy compared to human performance, underscoring the need for more advanced multimodal reasoning-driven visual generation...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 33. ChartLens enhances multimodal language models with fine-grained visual attributions, improving the accuracy of chart understanding by 26-66%.  					AI-generated summary 				 The growing capabilities of multimodal large language models (MLLMs) have advanced tasks like chart understanding. However, th...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 34. A novel pairwise-comparison framework using CreataSet dataset trains CrEval, an LLM-based evaluator that significantly improves the assessment of textual creativity aligned with human judgments.  					AI-generated summary 				 Creativity evaluation remains a challenging frontier for large language m...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 35. Large reasoning models exhibit varying susceptibility to hallucination depending on post-training pipelines, revealing critical cognitive behaviors and uncertainty misalignment as contributing factors.  					AI-generated summary 				 Recently evolved large reasoning models (LRMs) show powerful perfo...
[30.05.2025 06:17] ********************************************************************************
[30.05.2025 06:17] Abstract 36. Adaptive Classifier-Free Guidance (A-CFG) dynamically adjusts the guidance in masked diffusion language models by focusing on areas of low model confidence, leading to significant improvements in language generation performance.  					AI-generated summary 				 Classifier-Free Guidance (CFG) signific...
[30.05.2025 06:17] Read previous papers.
[30.05.2025 06:17] Generating reviews via LLM API.
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#rl", "#optimization", "#games", "#rlhf"], "emoji": "🤖", "ru": {"title": "Автоматизация обучения ГПИ-агентов без участия человека", "desc": "ZeroGUI - это фреймворк онлайн-обучения, использующий визуально-языковые модели для генерации задач и оценки вознаграждений, что ул
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#optimization", "#reasoning", "#training", "#rlhf"], "emoji": "🧠", "ru": {"title": "LLM устойчивы к шуму: вознаграждение за процесс важнее результата", "desc": "Исследование показывает, что большие языковые модели (LLM) демонстрируют устойчивость к шуму в функции вознагражден
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#video", "#games", "#interpretability", "#benchmark", "#reasoning", "#alignment", "#rlhf"], "emoji": "🎥", "ru": {"title": "VF-Eval: новый рубеж в оценке ИИ-видео мультимодальными моделями", "desc": "Новый бенчмарк VF-Eval оценивает способности мультимодальных языковых моделей (MLLM)
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#3d", "#dataset", "#multimodal", "#architecture", "#reasoning", "#training"], "emoji": "🧠", "ru": {"title": "Пространственный интеллект из 2D наблюдений", "desc": "Статья представляет Spatial-MLLM - новую модель для пространственного анализа на основе только 2D изображений и видео. 
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#inference", "#rl", "#reasoning", "#dataset", "#training"], "emoji": "🧠", "ru": {"title": "Эффективное масштабирование для рассуждений над таблицами", "desc": "В этой статье представлено исследование масштабирования во время вывода для задач рассуждения над таблицам
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#small_models", "#rl", "#optimization", "#open_source", "#training"], "emoji": "🧬", "ru": {"title": "Эволюционное масштабирование для повышения эффективности малых языковых моделей", "desc": "EvoScale - это метод, сочетающий эволюционное обучение и обучение с подкреплением для улучш
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "🎥", "ru": {"title": "Синтез новых ракурсов без калибровки камер", "desc": "AnySplat - это нейронная сеть прямого распространения для синтеза новых ракурсов на основе неоткалиброванных наборов изображений. Она предсказывает 3D гауссовы примитивы, кодирующие ге
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#benchmark", "#survey"], "emoji": "🔄", "ru": {"title": "SWE-bench-Live: Динамичный эталон для оценки ИИ в реальной разработке ПО", "desc": "Статья представляет SWE-bench-Live - новый эталонный тест для оценки возможностей больших языковых моделей в решен
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#synthetic", "#open_source", "#multimodal", "#training", "#optimization"], "emoji": "🔄", "ru": {"title": "Самосовершенствование мультимодальных ИИ-моделей без внешних данных", "desc": "UniRL - это метод пост-обучения для универсальных мультимодальных языковых моделей, который исполь
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#open_source", "#multimodal", "#diffusion", "#cv", "#benchmark"], "emoji": "🖼️", "ru": {"title": "D-AR: Диффузия изображений через авторегрессию", "desc": "Статья представляет новый подход к генерации изображений, называемый Diffusion via Autoregres
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#video", "#multimodal", "#benchmark"], "emoji": "🎥", "ru": {"title": "Глубокое рассуждение - ключ к пониманию видео искусственным интеллектом", "desc": "VideoReasonBench - это новый бенчмарк для оценки сложных задач рассуждения на основе видео. Он требует от моделей то
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#multimodal", "#architecture"], "emoji": "🔄", "ru": {"title": "Унифицированная мультимодальная генерация с помощью дискретной диффузии", "desc": "Muddit - это унифицированный дискретный диффузионный трансформер, объединяющий предобученные визуальные приоры с лег
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#math", "#reasoning", "#alignment", "#rlhf"], "emoji": "🧠", "ru": {"title": "OPO: Стабильное обучение с подкреплением для улучшения языковых моделей", "desc": "Статья представляет новый алгоритм обучения с подкреплением под названием OPO (On-Poli
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#healthcare", "#ethics", "#science", "#benchmark", "#open_source", "#security"], "emoji": "🔬", "ru": {"title": "Безопасный ИИ-ученый: этичные исследования без компромиссов", "desc": "SafeScientist - это фреймворк искусственного интеллекта, который повышает безопасность на
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#rl", "#training", "#reasoning", "#alignment"], "emoji": "🧠", "ru": {"title": "ToMAP: ИИ-убеждающий с пониманием оппонента", "desc": "Статья представляет ToMAP - новый подход к созданию более гибких агентов-убеждающих с использованием модулей теории разума. ToMAP улучшает
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#long_context", "#benchmark"], "emoji": "🧠", "ru": {"title": "ATLAS: Революция в долговременной памяти нейросетей", "desc": "Статья представляет ATLAS - новый модуль долговременной памяти для нейронных сетей. ATLAS преодолевает ограничения современных 
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#inference", "#long_context", "#optimization", "#reasoning"], "emoji": "🗜️", "ru": {"title": "KVzip: Эффективное сжатие кэша для ускорения языковых моделей", "desc": "Статья представляет KVzip - метод сжатия кэша ключ-значение (KV) для больших языковых моделей на основе
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#games", "#agents", "#3d", "#training"], "emoji": "🚗", "ru": {"title": "GeoDrive: 3D-геометрия для безопасного автономного вождения", "desc": "GeoDrive - это новый подход к моделированию мира для автономного вождения, который интегрирует надежную 3D-геометрию для ул
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#story_generation", "#diffusion"], "emoji": "🎨", "ru": {"title": "Умное редактирование изображений с помощью ИИ", "desc": "LoRAShop - это новая система для редактирования изображений с использованием нескольких концепций на основе моделей LoRA. Она использует п
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#diffusion"], "emoji": "🚀", "ru": {"title": "Ускорение диффузионных ЯМ без потери качества", "desc": "Статья представляет новые методы для улучшения скорости вывода диффузионных языковых моделей. Авторы предлагают блочный приближенный KV-к
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#3d", "#transfer_learning", "#cv", "#diffusion", "#dataset", "#math", "#optimization", "#benchmark"], "emoji": "🚀", "ru": {"title": "Uni-Instruct: Революция в одношаговой дистилляции диффузионных моделей", "desc": "Статья представляет Uni-Instruct - новый подход к одношаговой дистил
[30.05.2025 06:17] Querying the API.
[30.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A new automated method using concept-based vectors and a Hierarchical Multi-Domain Regression model improves preference explanations and predictions for large language models.  					AI-generated summary 				 Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, are central to aligning and evaluating large language models (LLMs). Yet, the underlying concepts that drive these preferences remain poorly understood. In this work, we propose a fully automated method for generating local and global concept-based explanations of preferences across multiple domains. Our method utilizes an LLM to identify concepts that distinguish between chosen and rejected responses, and to represent them with concept-based vectors. To model the relationships between concepts and preferences, we propose a white-box Hierarchical Multi-Domain Regression model that captures both domain-general and domain-specific effects. To evaluate our method, we curate a dataset spanning eight challenging and diverse domains and explain twelve mechanisms. Our method achieves strong preference prediction performance, outperforming baselines while also being explainable. Additionally, we assess explanations in two application-driven settings. First, guiding LLM outputs with concepts from LaaJ explanations yields responses that those judges consistently prefer. Second, prompting LaaJs with concepts explaining humans improves their preference predictions. Together, our work establishes a new paradigm for explainability in the era of LLMs.
[30.05.2025 06:17] Response: {
  "desc": "Этот научный труд представляет новый автоматизированный метод для объяснения и прогнозирования предпочтений в больших языковых моделях (БЯМ). Метод использует векторы на основе концепций и иерархическую мультидоменную регрессионную модель. Авторы предлагают способ генерации локальных и глобальных объяснений предпочтений на основе концепций в различных доменах. Исследование демонстрирует высокую эффективность метода в предсказании предпочтений и улучшении выходных данных БЯМ.",
  "emoji": "🧠",
  "title": "Раскрывая тайны предпочтений в больших языковых моделях"
}
[30.05.2025 06:17] Renaming some terms.
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new automated method using concept-based vectors and a Hierarchical Multi-Domain Regression model improves preference explanations and predictions for large language models.  					AI-generated summary 				 Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, are central to aligning and evaluating large language models (LLMs). Yet, the underlying concepts that drive these preferences remain poorly understood. In this work, we propose a fully automated method for generating local and global concept-based explanations of preferences across multiple domains. Our method utilizes an LLM to identify concepts that distinguish between chosen and rejected responses, and to represent them with concept-based vectors. To model the relationships between concepts and preferences, we propose a white-box Hierarchical Multi-Domain Regression model that captures both domain-general and domain-specific effects. To evaluate our method, we curate a dataset spanning eight challenging and diverse domains and explain twelve mechanisms. Our method achieves strong preference prediction performance, outperforming baselines while also being explainable. Additionally, we assess explanations in two application-driven settings. First, guiding LLM outputs with concepts from LaaJ explanations yields responses that those judges consistently prefer. Second, prompting LaaJs with concepts explaining humans improves their preference predictions. Together, our work establishes a new paradigm for explainability in the era of LLMs."

[30.05.2025 06:17] Response: ```python
["DATASET", "DATA", "RLHF", "TRAINING"]
```
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new automated method using concept-based vectors and a Hierarchical Multi-Domain Regression model improves preference explanations and predictions for large language models.  					AI-generated summary 				 Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and reward models, are central to aligning and evaluating large language models (LLMs). Yet, the underlying concepts that drive these preferences remain poorly understood. In this work, we propose a fully automated method for generating local and global concept-based explanations of preferences across multiple domains. Our method utilizes an LLM to identify concepts that distinguish between chosen and rejected responses, and to represent them with concept-based vectors. To model the relationships between concepts and preferences, we propose a white-box Hierarchical Multi-Domain Regression model that captures both domain-general and domain-specific effects. To evaluate our method, we curate a dataset spanning eight challenging and diverse domains and explain twelve mechanisms. Our method achieves strong preference prediction performance, outperforming baselines while also being explainable. Additionally, we assess explanations in two application-driven settings. First, guiding LLM outputs with concepts from LaaJ explanations yields responses that those judges consistently prefer. Second, prompting LaaJs with concepts explaining humans improves their preference predictions. Together, our work establishes a new paradigm for explainability in the era of LLMs."

[30.05.2025 06:17] Response: ```python
['ALIGNMENT', 'INTERPRETABILITY']
```
[30.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new automated approach that enhances how we explain and predict preferences in large language models (LLMs) using concept-based vectors and a Hierarchical Multi-Domain Regression model. The method identifies key concepts that differentiate between preferred and non-preferred responses, allowing for better understanding of the underlying preferences. By employing a white-box regression model, it captures both general and specific influences across various domains, leading to improved prediction accuracy. The results demonstrate that this approach not only outperforms existing methods but also provides clear explanations, paving the way for better alignment of LLMs with human preferences.","title":"Enhancing Preference Predictions with Concept-Based Explanations in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new automated approach that enhances how we explain and predict preferences in large language models (LLMs) using concept-based vectors and a Hierarchical Multi-Domain Regression model. The method identifies key concepts that differentiate between preferred and non-preferred responses, allowing for better understanding of the underlying preferences. By employing a white-box regression model, it captures both general and specific influences across various domains, leading to improved prediction accuracy. The results demonstrate that this approach not only outperforms existing methods but also provides clear explanations, paving the way for better alignment of LLMs with human preferences.', title='Enhancing Preference Predictions with Concept-Based Explanations in LLMs'))
[30.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的自动化方法，利用基于概念的向量和层次多领域回归模型，来改善大型语言模型的偏好解释和预测。该方法通过大型语言模型识别区分选择和拒绝响应的概念，并用基于概念的向量表示这些概念。我们提出的白盒层次多领域回归模型能够捕捉领域通用和领域特定的效应，从而建模概念与偏好之间的关系。通过在八个不同领域的数据集上进行评估，我们的方法在偏好预测性能上超越了基线，同时也具备良好的可解释性。","title":"新方法提升大型语言模型的偏好解释与预测"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的自动化方法，利用基于概念的向量和层次多领域回归模型，来改善大型语言模型的偏好解释和预测。该方法通过大型语言模型识别区分选择和拒绝响应的概念，并用基于概念的向量表示这些概念。我们提出的白盒层次多领域回归模型能够捕捉领域通用和领域特定的效应，从而建模概念与偏好之间的关系。通过在八个不同领域的数据集上进行评估，我们的方法在偏好预测性能上超越了基线，同时也具备良好的可解释性。', title='新方法提升大型语言模型的偏好解释与预测'))
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#math", "#rl", "#training", "#reasoning", "#benchmark", "#dataset"], "emoji": "🧠", "ru": {"title": "Прорыв в автоматическом доказательстве теорем с помощью естественного языка", "desc": "DeepTheorem - это комплексная система для неформального доказательства теорем с использованием б
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#video", "#diffusion", "#benchmark", "#open_source"], "emoji": "🎬", "ru": {"title": "MAGREF: Революция в генерации видео с несколькими объектами", "desc": "Статья представляет MAGREF - новую систему для генерации видео на основе нескольких референсных изображений и текстового описан
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#open_source", "#training", "#healthcare", "#dataset", "#science"], "emoji": "🩺", "ru": {"title": "Реалистичная симуляция пациентов для обучения ИИ в медицине", "desc": "PatientSim - это симулятор, генерирующий разнообразные и реалистичные профили пациентов для оценки языковых модел
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#interpretability", "#benchmark", "#architecture", "#security"], "emoji": "🔍", "ru": {"title": "Повышение надежности мультимодальных моделей без переобучения", "desc": "TrustVLM - это новый подход к повышению надежности мультимодальных моделей ма
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#transfer_learning", "#audio", "#benchmark", "#diffusion"], "emoji": "🎵", "ru": {"title": "Разделение аудиоисточников без обучения с помощью текстовых подсказок", "desc": "ZeroSep - это модель разделения аудиоисточников на основе диффузии, управляемой текстом. Она достигает разделен
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#3d", "#open_source", "#diffusion"], "emoji": "🎨", "ru": {"title": "Революция в 3D-текстурировании: UniTEX объединяет функциональное пространство и нейросети", "desc": "UniTEX - это новая двухэтапная система для генерации высококачественных и согласованных 3D-текстур. Она использует
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training"], "emoji": "🚀", "ru": {"title": "Революция в обучении языковых моделей: максимальный эффект при минимальных затратах", "desc": "Исследователи обнаружили, что минимизация энтропии с использованием всего одного образца данных и минимальной оптимизаци
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#data", "#interpretability", "#graphs", "#architecture", "#dataset", "#reasoning", "#benchmark", "#training"], "emoji": "🕸️", "ru": {"title": "Графовый анализ раскрывает структуру знаний в языковых моделях", "desc": "Исследование изучает структурные паттерны знаний в больших языковы
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#healthcare", "#dataset", "#science", "#multimodal", "#cv", "#benchmark", "#interpretability", "#reasoning"], "emoji": "🩻", "ru": {"title": "Структурированное рассуждение в медицинском ИИ: новый подход к оценке", "desc": "CheXStruct и CXReasonBench - это новые инструменты для оценки
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#hallucinations", "#multimodal", "#benchmark", "#security", "#training"], "emoji": "🎭", "ru": {"title": "Раскрытие слабых мест мультимодальных моделей с помощью обманчивых текстов", "desc": "Статья представляет новый бенчмарк Multimodal Adversarial Compositionality (MAC) для оценки 
[30.05.2025 06:17] Querying the API.
[30.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The introduction of SridBench, a benchmark for scientific figure generation, reveals that current top-tier models, such as GPT-4o-image, fall short in semantic and structural accuracy compared to human performance, underscoring the need for more advanced multimodal reasoning-driven visual generation.  					AI-generated summary 				 Recent years have seen rapid advances in AI-driven image generation. Early diffusion models emphasized perceptual quality, while newer multimodal models like GPT-4o-image integrate high-level reasoning, improving semantic understanding and structural composition. Scientific illustration generation exemplifies this evolution: unlike general image synthesis, it demands accurate interpretation of technical content and transformation of abstract ideas into clear, standardized visuals. This task is significantly more knowledge-intensive and laborious, often requiring hours of manual work and specialized tools. Automating it in a controllable, intelligent manner would provide substantial practical value. Yet, no benchmark currently exists to evaluate AI on this front. To fill this gap, we introduce SridBench, the first benchmark for scientific figure generation. It comprises 1,120 instances curated from leading scientific papers across 13 natural and computer science disciplines, collected via human experts and MLLMs. Each sample is evaluated along six dimensions, including semantic fidelity and structural accuracy. Experimental results reveal that even top-tier models like GPT-4o-image lag behind human performance, with common issues in text/visual clarity and scientific correctness. These findings highlight the need for more advanced reasoning-driven visual generation capabilities.
[30.05.2025 06:17] Response: {
  "desc": "SridBench - это новый эталонный тест для оценки генерации научных иллюстраций искусственным интеллектом. Он включает 1120 примеров из 13 научных дисциплин, оцениваемых по 6 параметрам, включая семантическую точность и структурную корректность. Результаты показывают, что даже передовые модели, такие как GPT-4o-image, значительно уступают человеку в этой задаче. Это подчеркивает необходимость разработки более продвинутых моделей мультимодального рассуждения для генерации визуального контента.",
  "emoji": "🔬",
  "title": "SridBench: вызов ИИ в создании научных иллюстраций"
}
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The introduction of SridBench, a benchmark for scientific figure generation, reveals that current top-tier models, such as GPT-4o-image, fall short in semantic and structural accuracy compared to human performance, underscoring the need for more advanced multimodal reasoning-driven visual generation.  					AI-generated summary 				 Recent years have seen rapid advances in AI-driven image generation. Early diffusion models emphasized perceptual quality, while newer multimodal models like GPT-4o-image integrate high-level reasoning, improving semantic understanding and structural composition. Scientific illustration generation exemplifies this evolution: unlike general image synthesis, it demands accurate interpretation of technical content and transformation of abstract ideas into clear, standardized visuals. This task is significantly more knowledge-intensive and laborious, often requiring hours of manual work and specialized tools. Automating it in a controllable, intelligent manner would provide substantial practical value. Yet, no benchmark currently exists to evaluate AI on this front. To fill this gap, we introduce SridBench, the first benchmark for scientific figure generation. It comprises 1,120 instances curated from leading scientific papers across 13 natural and computer science disciplines, collected via human experts and MLLMs. Each sample is evaluated along six dimensions, including semantic fidelity and structural accuracy. Experimental results reveal that even top-tier models like GPT-4o-image lag behind human performance, with common issues in text/visual clarity and scientific correctness. These findings highlight the need for more advanced reasoning-driven visual generation capabilities."

[30.05.2025 06:17] Response: ```python
["BENCHMARK", "MULTIMODAL"]
```
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The introduction of SridBench, a benchmark for scientific figure generation, reveals that current top-tier models, such as GPT-4o-image, fall short in semantic and structural accuracy compared to human performance, underscoring the need for more advanced multimodal reasoning-driven visual generation.  					AI-generated summary 				 Recent years have seen rapid advances in AI-driven image generation. Early diffusion models emphasized perceptual quality, while newer multimodal models like GPT-4o-image integrate high-level reasoning, improving semantic understanding and structural composition. Scientific illustration generation exemplifies this evolution: unlike general image synthesis, it demands accurate interpretation of technical content and transformation of abstract ideas into clear, standardized visuals. This task is significantly more knowledge-intensive and laborious, often requiring hours of manual work and specialized tools. Automating it in a controllable, intelligent manner would provide substantial practical value. Yet, no benchmark currently exists to evaluate AI on this front. To fill this gap, we introduce SridBench, the first benchmark for scientific figure generation. It comprises 1,120 instances curated from leading scientific papers across 13 natural and computer science disciplines, collected via human experts and MLLMs. Each sample is evaluated along six dimensions, including semantic fidelity and structural accuracy. Experimental results reveal that even top-tier models like GPT-4o-image lag behind human performance, with common issues in text/visual clarity and scientific correctness. These findings highlight the need for more advanced reasoning-driven visual generation capabilities."

[30.05.2025 06:17] Response: ```python
['SCIENCE', 'INTERPRETABILITY', 'REASONING']
```
[30.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SridBench is a new benchmark designed to evaluate the generation of scientific figures by AI models. It highlights that current leading models, such as GPT-4o-image, struggle with achieving the same level of semantic and structural accuracy as human-generated illustrations. The benchmark includes 1,120 carefully selected examples from various scientific fields, assessing models on criteria like semantic fidelity and structural accuracy. The results indicate a significant gap in performance, emphasizing the necessity for improved multimodal reasoning in visual generation tasks.","title":"SridBench: Elevating AI in Scientific Figure Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SridBench is a new benchmark designed to evaluate the generation of scientific figures by AI models. It highlights that current leading models, such as GPT-4o-image, struggle with achieving the same level of semantic and structural accuracy as human-generated illustrations. The benchmark includes 1,120 carefully selected examples from various scientific fields, assessing models on criteria like semantic fidelity and structural accuracy. The results indicate a significant gap in performance, emphasizing the necessity for improved multimodal reasoning in visual generation tasks.', title='SridBench: Elevating AI in Scientific Figure Generation'))
[30.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SridBench是一个用于科学图形生成的基准测试，旨在评估当前AI模型在生成科学插图时的表现。尽管像GPT-4o-image这样的顶尖模型在图像生成方面取得了进展，但它们在语义和结构准确性上仍然无法与人类相媲美。科学插图生成需要对技术内容进行准确解读，并将抽象概念转化为清晰的标准化视觉效果，这一过程知识密集且耗时。SridBench通过提供1,120个实例，填补了这一评估空白，强调了对更先进的多模态推理驱动的视觉生成能力的需求。","title":"科学图形生成的新基准：SridBench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SridBench是一个用于科学图形生成的基准测试，旨在评估当前AI模型在生成科学插图时的表现。尽管像GPT-4o-image这样的顶尖模型在图像生成方面取得了进展，但它们在语义和结构准确性上仍然无法与人类相媲美。科学插图生成需要对技术内容进行准确解读，并将抽象概念转化为清晰的标准化视觉效果，这一过程知识密集且耗时。SridBench通过提供1,120个实例，填补了这一评估空白，强调了对更先进的多模态推理驱动的视觉生成能力的需求。', title='科学图形生成的新基准：SridBench'))
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#hallucinations", "#cv", "#benchmark"], "emoji": "📊", "ru": {"title": "Точное понимание графиков с помощью ChartLens", "desc": "ChartLens - это новый алгоритм для улучшения понимания графиков мультимодальными языковыми моделями. Он использует сегментацию
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#creativity", "#dataset", "#open_source", "#data", "#benchmark"], "emoji": "🎨", "ru": {"title": "CrEval: Революция в автоматической оценке креативности текста", "desc": "Статья представляет новый фреймворк для оценки текстовой креативности, основанный на попарном сравнении. Авторы с
[30.05.2025 06:17] Querying the API.
[30.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large reasoning models exhibit varying susceptibility to hallucination depending on post-training pipelines, revealing critical cognitive behaviors and uncertainty misalignment as contributing factors.  					AI-generated summary 				 Recently evolved large reasoning models (LRMs) show powerful performance in solving complex tasks with long chain-of-thought (CoT) reasoning capability. As these LRMs are mostly developed by post-training on formal reasoning tasks, whether they generalize the reasoning capability to help reduce hallucination in fact-seeking tasks remains unclear and debated. For instance, DeepSeek-R1 reports increased performance on SimpleQA, a fact-seeking benchmark, while OpenAI-o3 observes even severer hallucination. This discrepancy naturally raises the following research question: Are reasoning models more prone to hallucination? This paper addresses the question from three perspectives. (1) We first conduct a holistic evaluation for the hallucination in LRMs. Our analysis reveals that LRMs undergo a full post-training pipeline with cold start supervised fine-tuning (SFT) and verifiable reward RL generally alleviate their hallucination. In contrast, both distillation alone and RL training without cold start fine-tuning introduce more nuanced hallucinations. (2) To explore why different post-training pipelines alters the impact on hallucination in LRMs, we conduct behavior analysis. We characterize two critical cognitive behaviors that directly affect the factuality of a LRM: Flaw Repetition, where the surface-level reasoning attempts repeatedly follow the same underlying flawed logic, and Think-Answer Mismatch, where the final answer fails to faithfully match the previous CoT process. (3) Further, we investigate the mechanism behind the hallucination of LRMs from the perspective of model uncertainty. We find that increased hallucination of LRMs is usually associated with the misalignment between model uncertainty and factual accuracy. Our work provides an initial understanding of the hallucination in LRMs.
[30.05.2025 06:17] Response: {
  "desc": "Это исследование изучает склонность к галлюцинациям у больших моделей рассуждений (LRM) в зависимости от различных методов пост-обучения. Авторы обнаружили, что холодный старт с контролируемой тонкой настройкой и обучение с подкреплением на основе проверяемых наград обычно уменьшают галлюцинации. Выявлены два ключевых когнитивных поведения, влияющих на фактическую точность LRM: повторение ошибок и несоответствие между рассуждениями и ответом. Исследование также показало связь между повышенными галлюцинациями и несоответствием между неопределенностью модели и фактической точностью.",
  "emoji": "🤖",
  "title": "Галлюцинации в больших моделях рассуждений: причины и решения"
}
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large reasoning models exhibit varying susceptibility to hallucination depending on post-training pipelines, revealing critical cognitive behaviors and uncertainty misalignment as contributing factors.  					AI-generated summary 				 Recently evolved large reasoning models (LRMs) show powerful performance in solving complex tasks with long chain-of-thought (CoT) reasoning capability. As these LRMs are mostly developed by post-training on formal reasoning tasks, whether they generalize the reasoning capability to help reduce hallucination in fact-seeking tasks remains unclear and debated. For instance, DeepSeek-R1 reports increased performance on SimpleQA, a fact-seeking benchmark, while OpenAI-o3 observes even severer hallucination. This discrepancy naturally raises the following research question: Are reasoning models more prone to hallucination? This paper addresses the question from three perspectives. (1) We first conduct a holistic evaluation for the hallucination in LRMs. Our analysis reveals that LRMs undergo a full post-training pipeline with cold start supervised fine-tuning (SFT) and verifiable reward RL generally alleviate their hallucination. In contrast, both distillation alone and RL training without cold start fine-tuning introduce more nuanced hallucinations. (2) To explore why different post-training pipelines alters the impact on hallucination in LRMs, we conduct behavior analysis. We characterize two critical cognitive behaviors that directly affect the factuality of a LRM: Flaw Repetition, where the surface-level reasoning attempts repeatedly follow the same underlying flawed logic, and Think-Answer Mismatch, where the final answer fails to faithfully match the previous CoT process. (3) Further, we investigate the mechanism behind the hallucination of LRMs from the perspective of model uncertainty. We find that increased hallucination of LRMs is usually associated with the misalignment between model uncertainty and factual accuracy. Our work provides an initial understanding of the hallucination in LRMs."

[30.05.2025 06:17] Response: ```python
['RL', 'TRAINING']
```
[30.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large reasoning models exhibit varying susceptibility to hallucination depending on post-training pipelines, revealing critical cognitive behaviors and uncertainty misalignment as contributing factors.  					AI-generated summary 				 Recently evolved large reasoning models (LRMs) show powerful performance in solving complex tasks with long chain-of-thought (CoT) reasoning capability. As these LRMs are mostly developed by post-training on formal reasoning tasks, whether they generalize the reasoning capability to help reduce hallucination in fact-seeking tasks remains unclear and debated. For instance, DeepSeek-R1 reports increased performance on SimpleQA, a fact-seeking benchmark, while OpenAI-o3 observes even severer hallucination. This discrepancy naturally raises the following research question: Are reasoning models more prone to hallucination? This paper addresses the question from three perspectives. (1) We first conduct a holistic evaluation for the hallucination in LRMs. Our analysis reveals that LRMs undergo a full post-training pipeline with cold start supervised fine-tuning (SFT) and verifiable reward RL generally alleviate their hallucination. In contrast, both distillation alone and RL training without cold start fine-tuning introduce more nuanced hallucinations. (2) To explore why different post-training pipelines alters the impact on hallucination in LRMs, we conduct behavior analysis. We characterize two critical cognitive behaviors that directly affect the factuality of a LRM: Flaw Repetition, where the surface-level reasoning attempts repeatedly follow the same underlying flawed logic, and Think-Answer Mismatch, where the final answer fails to faithfully match the previous CoT process. (3) Further, we investigate the mechanism behind the hallucination of LRMs from the perspective of model uncertainty. We find that increased hallucination of LRMs is usually associated with the misalignment between model uncertainty and factual accuracy. Our work provides an initial understanding of the hallucination in LRMs."

[30.05.2025 06:17] Response: ```python
["HALLUCINATIONS", "REASONING"]
```
[30.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how large reasoning models (LRMs) can produce incorrect information, known as hallucination, and how this varies based on their training methods. It finds that certain post-training techniques, like supervised fine-tuning and reinforcement learning, can reduce hallucination, while others may worsen it. The authors identify two key cognitive behaviors—Flaw Repetition and Think-Answer Mismatch—that contribute to these inaccuracies. Additionally, they explore how the model\'s uncertainty can misalign with factual correctness, leading to increased hallucination in LRMs.","title":"Understanding and Reducing Hallucination in Large Reasoning Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper investigates how large reasoning models (LRMs) can produce incorrect information, known as hallucination, and how this varies based on their training methods. It finds that certain post-training techniques, like supervised fine-tuning and reinforcement learning, can reduce hallucination, while others may worsen it. The authors identify two key cognitive behaviors—Flaw Repetition and Think-Answer Mismatch—that contribute to these inaccuracies. Additionally, they explore how the model's uncertainty can misalign with factual correctness, leading to increased hallucination in LRMs.", title='Understanding and Reducing Hallucination in Large Reasoning Models'))
[30.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文探讨了大型推理模型（LRMs）在后训练流程中对幻觉的不同敏感性。研究发现，经过冷启动监督微调和可验证奖励强化学习的后训练流程可以减轻幻觉现象，而单独的蒸馏或没有冷启动微调的强化学习则会引入更多复杂的幻觉。论文还分析了影响LRMs事实性的两种关键认知行为：缺陷重复和思考-回答不匹配。最后，研究表明，LRMs的幻觉增加通常与模型不确定性和事实准确性之间的不一致有关。","title":"理解大型推理模型中的幻觉现象"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文探讨了大型推理模型（LRMs）在后训练流程中对幻觉的不同敏感性。研究发现，经过冷启动监督微调和可验证奖励强化学习的后训练流程可以减轻幻觉现象，而单独的蒸馏或没有冷启动微调的强化学习则会引入更多复杂的幻觉。论文还分析了影响LRMs事实性的两种关键认知行为：缺陷重复和思考-回答不匹配。最后，研究表明，LRMs的幻觉增加通常与模型不确定性和事实准确性之间的不一致有关。', title='理解大型推理模型中的幻觉现象'))
[30.05.2025 06:17] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#benchmark", "#training"], "emoji": "🎭", "ru": {"title": "Динамическая адаптация руководства для повышения качества генерации текста", "desc": "Статья представляет новый метод под названием Адаптивное Бесклассовое Руководство (A-CFG) для улучшения генера
[30.05.2025 06:17] Loading Chinese text from previous data.
[30.05.2025 06:17] Renaming data file.
[30.05.2025 06:17] Renaming previous data. hf_papers.json to ./d/2025-05-30.json
[30.05.2025 06:17] Saving new data file.
[30.05.2025 06:17] Generating page.
[30.05.2025 06:17] Renaming previous page.
[30.05.2025 06:17] Renaming previous data. index.html to ./d/2025-05-30.html
[30.05.2025 06:17] [Experimental] Generating Chinese page for reading.
[30.05.2025 06:17] Chinese vocab [{'word': '旨在', 'pinyin': 'zhǐ zài', 'trans': 'aim to'}, {'word': '解决', 'pinyin': 'jiě jué', 'trans': 'solve'}, {'word': '强化学习', 'pinyin': 'qiáng huà xué xí', 'trans': 'reinforcement learning'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '主要', 'pinyin': 'zhǔ yào', 'trans': 'major'}, {'word': '障碍', 'pinyin': 'zhàng ài', 'trans': 'obstacle'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '熵', 'pinyin': 'shāng', 'trans': 'entropy'}, {'word': '崩溃', 'pinyin': 'bēng kuì', 'trans': 'collapse'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discover'}, {'word': '干预', 'pinyin': 'gān yù', 'trans': 'intervention'}, {'word': '情况', 'pinyin': 'qíng kuàng', 'trans': 'situation'}, {'word': '阶段', 'pinyin': 'jiē duàn', 'trans': 'stage'}, {'word': '急剧', 'pinyin': 'jí jù', 'trans': 'drastic'}, {'word': '下降', 'pinyin': 'xià jiàng', 'trans': 'decline'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'}, {'word': '探索', 'pinyin': 'tàn suǒ', 'trans': 'exploration'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '减弱', 'pinyin': 'jiǎn ruò', 'trans': 'weaken'}, {'word': '停滞', 'pinyin': 'tíng zhì', 'trans': 'stagnate'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '转换', 'pinyin': 'zhuǎn huàn', 'trans': 'conversion'}, {'word': '方程', 'pinyin': 'fāng chéng', 'trans': 'equation'}, {'word': '下游', 'pinyin': 'xià yóu', 'trans': 'downstream'}, {'word': '理论', 'pinyin': 'lǐ lùn', 'trans': 'theory'}, {'word': '实证', 'pinyin': 'shí zhèng', 'trans': 'empirical'}, {'word': '分析', 'pinyin': 'fēn xī', 'trans': 'analysis'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamics'}, {'word': '最终', 'pinyin': 'zuì zhōng', 'trans': 'ultimately'}, {'word': '技术', 'pinyin': 'jì shù', 'trans': 'technique'}, {'word': '控制', 'pinyin': 'kòng zhì', 'trans': 'control'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '表明', 'pinyin': 'biǎo míng', 'trans': 'indicate'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '促进', 'pinyin': 'cù jìn', 'trans': 'promote'}, {'word': '避免', 'pinyin': 'bì miǎn', 'trans': 'avoid'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}]
[30.05.2025 06:17] Renaming previous Chinese page.
[30.05.2025 06:17] Renaming previous data. zh.html to ./d/2025-05-29_zh_reading_task.html
[30.05.2025 06:17] Writing Chinese reading task.
[30.05.2025 06:17] Writing result.
[30.05.2025 06:17] Renaming log file.
[30.05.2025 06:17] Renaming previous data. log.txt to ./logs/2025-05-30_last_log.txt
