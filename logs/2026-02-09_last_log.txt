[09.02.2026 04:26] Read previous papers.
[09.02.2026 04:26] Generating top page (month).
[09.02.2026 04:26] Writing top page (month).
[09.02.2026 06:04] Read previous papers.
[09.02.2026 06:04] Get feed.
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03392
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.06291
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.06570
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05940
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06075
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06391
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.05843
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.01734
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06960
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06949
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06663
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05281
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.05367
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.06854
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06471
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06139
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05711
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2601.23039
[09.02.2026 06:04] Extract page data from URL. URL: https://huggingface.co/papers/2602.06554
[09.02.2026 06:04] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01064
[09.02.2026 06:04] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.02.2026 06:04] No deleted papers detected.
[09.02.2026 06:04] Downloading and parsing papers (pdf, html). Total: 20.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.03392.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.03392.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.03392.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06291.
[09.02.2026 06:04] Downloading paper 2602.06291 from https://arxiv.org/pdf/2602.06291v1...
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Judging What We Cannot Solve: Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math Guijin Son 1 2 Donghun Yang 3 Hitesh Laxmichand Patel 4 Hyunwoo Ko 2 Amit Agarwal 4 Sunghee Ahn 1 Kyong-Ha Lee 3 Youngjae Yu 1 Abstract Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains bottleneck, consuming scarce expert time. We hypothesize that meaningful solution should contain enough method-level information that, when applied to neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose Consequence-Based Utility, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of researchlevel math problems each paired with one expertwritten solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPTOSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits larger solverevaluator gap, maintaining stronger correctwrong separation even on instances the underlying solver often fails to solve. 6 2 0 2 6 ] . [ 1 1 9 2 6 0 . 2 0 6 2 : r 1. Introduction For mathematical hypothesis to be accepted as scientific knowledge, it must undergo extensive review and validation. Yet many recent efforts to advance science with LLMs (Gottweis et al., 2025) emphasize hypothesis generation (Zhou et al., 2024; Radensky et al., 2024) and experimental planning (Goel et al., 2025), while giving comparatively less attention to rigorous validation. Accordingly, this step is 1Seoul National University 2OnelineAI"
[09.02.2026 06:04] Response: ```python
[
    "Seoul National University",
    "OnelineAI"
]
```
[09.02.2026 06:04] Deleting PDF ./assets/pdf/2602.06291.pdf.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06570.
[09.02.2026 06:04] Downloading paper 2602.06570 from https://arxiv.org/pdf/2602.06570v1...
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Baichuan-M3 Technical Report 6 2 0 2 6 ] . [ 1 0 7 5 6 0 . 2 0 6 2 : r Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making Baichuan-M3 Team Abstract We introduce Baichuan-M3, medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes specialized training pipeline to model the systematic workflow of physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3. Large language models (LLMs) are advancing rapidly [14], driving broader adoption in healthcare [59]. As result, expectations are shifting from one-off question answering to end-to-end clinical decision support [10, 11]. This trend is reflected in leading systems such as OpenAIs GPT5.2 [12], ChatGPT Health [13], and Claude in Healthcare [14]. Yet key limitations persist: despite better scores on static, well-specified benchmarks, models often fail to stay evidence-grounded and uncertainty-aware in open-ended clinical interactions, where missing information and longhorizon decisions make hallucinations harder to control [15]. Our goal is therefore to move beyond reliable QA toward decision-support partners that can operate safely in practice. To bridge the gap between passive retrieval and active clinical support, recent studies have been 1 Baichuan-M3 Technical Report evaluated along two p"
[09.02.2026 06:04] Response: ```python
[]
```
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Baichuan-M3 Technical Report 6 2 0 2 6 ] . [ 1 0 7 5 6 0 . 2 0 6 2 : r Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making Baichuan-M3 Team Abstract We introduce Baichuan-M3, medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes specialized training pipeline to model the systematic workflow of physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3.Large language models (LLMs) are advancing rapidly [14], driving broader adoption in healthcare [59]. As result, expectations are shifting from one-off question answering to end-to-end clinical decision support [10, 11]. This trend is reflected in leading systems such as OpenAIs GPT5.2 [12], ChatGPT Health [13], and Claude in Healthcare [14]. Yet key limitations persist: despite better scores on static, well-specified benchmarks, models often fail to stay evidence-grounded and uncertainty-aware in open-ended clinical interactions, where missing information and longhorizon decisions make hallucinations harder to control [15]. Our goal is therefore to move beyond reliable QA toward decision-support partners that can operate safely in practice. To bridge the gap between passive retrieval and active clinical support, recent studies have been 1 Baichuan-M3 Technical Report evaluated along two partially disconnected paradigms: (i) factuality-focused, single-turn benchmarks and (ii) process-oriented, multi-turn consultation simulations. Benchmarks such as HealthBench [16] and Med-HALT [17] measure factual consistency and common error modes, including hallucinations. They often show that performance drops on harder cases that require complex, multi-constraint clinical reasoning, and that models may produce ungrounded claims. In parallel, growing attention has been paid to Interactive History Taking (IHT) in OSCE-style (Objective Structured Clinical Examination) settings, where models are assessed on their ability to elicit missing information and follow clinical workflows. Systems such as Googles AMIE [18, 19] demonstrate strong communication quality in simulated encounters under these rubrics. However, critical gap remains in unifying these two dimensions. Existing approaches often treat conversational interaction and clinical reasoning as orthogonal objectives, rather than components of single coherent system. Knowledge-centric models exhibit inquiry inertia, lacking the agency to elicit missing evidence, while interaction-focused models can sacrifice diagnostic depth, prioritizing fluency over principled differential reasoning. Integrating interaction and reasoning is challenging due to three technical bottlenecks. First, heterogeneous training environments across diverse clinical tasks hinder stable multi-task fusion. Second, long-horizon interactions amplify the credit-assignment problem in reinforcement learning (RL) [2022]: when supervision is dominated by terminal outcomes, models struggle to identify which conversational turns were causally responsible for diagnostic success. Third, efforts to increase reasoning depth often encounter reward saturation, where learning signals diminish near performance plateaussometimes accompanied by increased hallucination as models attempt to satisfy complex logical constraints [23, 24]. To address these challenges, we introduce Baichuan-M3, next-generation medical LLM designed to unify clinical inquiry with reliable decision-making. Baichuan-M3 emphasizes three core competencies aligned with real clinical workflows: (i) proactive information acquisition, (ii) construction of coherent reasoning trajectories, and (iii) adaptive hallucination suppression. Methodologically, we propose three-stage training framework consisting of Task-Specific Reinforcement Learning (TaskRL), Offline Policy Distillation, and Multi-Teacher Online Policy Distillation (MOPD). This hierarchical design decouples the optimization of individual competencies before integrating them into single policy. To improve long-horizon consultation performance, we introduce Segmented Pipeline Reinforcement Learning, which decomposes complex tasks into stages with separate reward signals. We further strengthen diagnostic reasoning via Dynamic Rubric Evolution and targeted RL objectives for hallucination suppression. 2 Baichuan-M3 achieves state-of-the-art performance on three authoritative benchmarks: (1) 44.4 on HealthBench-Hard, outperforming GPT-5.2; (2) top performance across all three dimensions of ScanBench (our OSCE-like benchmark)Clinical Inquiry (74.9), Laboratory Testing (72.1), and Diagnosis (74.4)exceeding both GPT-5.2-High and expert baselines; and (3) superior factual reliability in tool-free hallucination assessments. In summary, our contributions are three-fold: Baichuan-M3 Technical Report Bridging Inquiry and Reasoning: We present Baichuan-M3, designed to transform LLMs from passive information retrievers into robust decision-support partners. By modeling the full clinical decision-making process, our system demonstrates the agency to actively elicit missing data while maintaining rigorous diagnostic logic, addressing the critical limitation of "hallucination via assumption" in open-ended scenarios. Clinical-Process-Aligned Optimization: We introduce training paradigm that mirrors professional medical training, utilizing Segmented Pipeline RL to align model behavior with distinct stages of clinical consultation (inquiry, lab testing, diagnosis). This approach, combined with dynamic rubric evolution, ensures that the model learns to prioritize evidence-based reasoning over mere conversational fluency or forced logical fitting. Superior Empirical Results: Extensive experiments demonstrate Baichuan-M3s leadership in both factual reliability and interactive procedural rigor. It sets new state-"
[09.02.2026 06:04] Mistral response. {"id": "63bfa7d5a6974528a7037c2e6a1ce43d", "created": 1770617065, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1330, "total_tokens": 1342, "completion_tokens": 12, "num_cached_tokens": 1329}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Baichuan Inc.\"]\n```"}}]}
[09.02.2026 06:04] Response: ```python
["Baichuan Inc."]
```
[09.02.2026 06:04] Deleting PDF ./assets/pdf/2602.06570.pdf.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.05940.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.05940.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.05940.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06075.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.06075.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.06075.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06391.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.06391.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.06391.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.05843.
[09.02.2026 06:04] Downloading paper 2602.05843 from https://arxiv.org/pdf/2602.05843v1...
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ODYSSEYARENA: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions Fangzhi Xu 1 * Hang Yan 1 * Qiushi Sun 2 * Jinyang Wu 3 Zixian Huang 4 Muye Huang 1 Jingyang Gong 2 Zichen Ding 4 Kanzhi Cheng 5 Yian Wang 6 Xinyu Che 1 Zeyi Sun 4 Jian Zhang 1 Zhangyue Yin 7 Haoran Luo 8 Xuanjing Huang 7 Ben Kao 2 Jun Liu 1 Qika Lin 6 6 2 0 2 5 ] . [ 1 3 4 8 5 0 . 2 0 6 2 : r a "
[09.02.2026 06:04] Response: ```python
[]
```
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ODYSSEYARENA: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions Fangzhi Xu 1 * Hang Yan 1 * Qiushi Sun 2 * Jinyang Wu 3 Zixian Huang 4 Muye Huang 1 Jingyang Gong 2 Zichen Ding 4 Kanzhi Cheng 5 Yian Wang 6 Xinyu Che 1 Zeyi Sun 4 Jian Zhang 1 Zhangyue Yin 7 Haoran Luo 8 Xuanjing Huang 7 Ben Kao 2 Jun Liu 1 Qika Lin 6 6 2 0 2 5 ] . [ 1 3 4 8 5 0 . 2 0 6 2 : r aThe rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce ODYSSEYARENA, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish ODYSSEYARENALITE for standardized benchmarking, providing set of 120 tasks to measure an agents inductive efficiency and long-horizon discovery. Pushing further, we introduce ODYSSEYARENACHALLENGE to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit deficiency in inductive scenarios, identifying critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/ xufangzhi/Odyssey-Arena *Equal contribution 1Xian Jiaotong University 2The University of Hong Kong 3Tsinghua University 4Shanghai AI Laboratory 5Nanjing University 6National University of Singapore 7Fudan University 8Nanyang Techonological University. Correspondence to: Qika Lin <linqika@nus.edu.sg>. Preprint. Copyright 2026 by the author(s). 1 Figure 1. Comparison between deductive and inductive settings in multi-turn agentic tasks. 1. Introduction The emergence of Large Language Models (LLMs; Gemini Team, 2025; Anthropic AI, 2024) has sparked unprecedented interest in autonomous agents that can perceive environments, make decisions, and take actions to accomplish complex tasks. These AI agents are increasingly deployed across diverse domainsfrom robotics (Wang et al., 2025a) and game playing (Akata et al., 2025) to scientific discovery (Sun et al., 2025b) and business automation (Xu et al., 2025c). As the capabilities of LLMs expand, so does the demand for evaluation benchmarks that can reliably assess agent performance in realistic, dynamic settings. While recent benchmarks have evolved from static question answering toward interactive decision-making (Xie et al., 2024; Vodrahalli et al., 2024; Chung et al., 2025), they predominantly assess deductive mode of intelligence where agents rely on extensive prior knowledge to complete tasks. As illustrated in Figure 1, such evaluation overlooks the essential inductive mode, in which agents are required to actively explore and induce the hidden rules underlying the environment. This omission restricts the evaluation of an agents proficiency in complex environments where rules are not pre-specified. We identify three critical capability dimensions that remain largely unaddressed in the current landscape. First, extremely long-horizon interaction is often neglected by existing benchmarks that restrict episodes to fewer than 50 steps, which fails to capture the strategic coherence and error accumulation challenges inherent in sequences of thousands of steps. Second, active exploration ODYSSEYARENA: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions and trial-and-error are frequently bypassed by environments that provide fully specified success criteria, whereas realistic deployment requires agents to actively probe, react to feedback, and iteratively adjust their actions through self-improvement (Yan et al., 2025). Finally, inductive reasoning from interaction represents critical evaluation gap in current benchmarks, as most protocols assess deductive compliance to provided instructions rather than the capacity to infer latent rules and transition dynamics from experience. In order to bridge this gap, we introduce ODYSSEYARENA, suite of interactive environments that re-centers evaluation on long-horizon, active, and inductive reasoning, which entails inferring latent transition laws from empirical interactions. We formalize environments as generative state transition functions: (st+1, rt) = (st, at), where st is the latent state and at is the agent action. The transition function implicitly encodes the environments rules and regularities, which agents must actively induce from interaction in order to anticipate outcomes, plan effectively, and optimize behavior over long horizons. This makes the central object of agent evaluation. To systematically study an agents inductive capacity, we decompose into taxonomy of four representative structural primitives: discrete latent rules, continuous stochastic dynamics, multi-objective periodic patterns, and relational dependencies. To facilitate empirical investigation into these abstract dynamics, we materialize these primitives into four diverse ODYSSEYARENA environments. These environments are curated to be computationally efficient and lightweight while remaining functionally representative of real-world systems, providing tractable and scalable testbed for the community. Specifically, Turn On Lights grounds discrete Boolean logic in interdependent bulb configurations, while AI Trading presents continuous stochastic dynamics through multivariate stock-factor relationships. Energy Dispatch requires agents to uncover periodic efficiency patterns under multi-objective constraints, and Repo System engages agents in deducing the topological dependencies among software package versions in virtual environment. For practical evaluation, we provide ODYSSEYARENA-LITE as standardized benchmark of 120 curated tasks. This suite serves as representative of scalable task distribution, optimized for high evaluation throughput while preserving the core challenges of active and inductive discovery. Each task mai"
[09.02.2026 06:04] Mistral response. {"id": "82d7a35dcaad4fdebcb27428f4a54753", "created": 1770617074, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1401, "total_tokens": 1466, "completion_tokens": 65, "num_cached_tokens": 1400}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Xian Jiaotong University\",\n    \"The University of Hong Kong\",\n    \"Tsinghua University\",\n    \"Shanghai AI Laboratory\",\n    \"Nanjing University\",\n    \"National University of Singapore\",\n    \"Fudan University\",\n    \"Nanyang Technological University\"\n]\n```"}}]}
[09.02.2026 06:04] Response: ```python
[
    "Xian Jiaotong University",
    "The University of Hong Kong",
    "Tsinghua University",
    "Shanghai AI Laboratory",
    "Nanjing University",
    "National University of Singapore",
    "Fudan University",
    "Nanyang Technological University"
]
```
[09.02.2026 06:04] Deleting PDF ./assets/pdf/2602.05843.pdf.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.01734.
[09.02.2026 06:04] Downloading paper 2602.01734 from https://arxiv.org/pdf/2602.01734v1...
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 4 3 7 1 0 . 2 0 6 2 : r MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration Lianhai Ren 1 2 Yucheng Ding 1 Xiao Liu 1 Qianxiao Li 2 Peng Cheng 1 Yeyun Gong "
[09.02.2026 06:04] Response: ```python
[]
```
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 2 ] . [ 1 4 3 7 1 0 . 2 0 6 2 : r MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration Lianhai Ren 1 2 Yucheng Ding 1 Xiao Liu 1 Qianxiao Li 2 Peng Cheng 1 Yeyun GongTraining instability remains critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in 5M-parameter NanoGPT model scaled via µP, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with computational overhead of less than 7.0%. 1. Introduction Modern deep learning optimizers and training techniques including Adam (Kingma & Ba, 2015), layer normalization (Ba et al., 2016), and learning rate schedules generally enable reliable training. However, as the model scale increases, pretraining large language models (LLMs) becomes increasingly fragile. Training failures manifest as sudden, unrecoverable gradient explosions and corresponding loss growth, which are difficult to predict and can waste substantial computational resources (Chowdhery et al., 2023; Zhang et al., 2022). Empirical Investigation: Identifying the Failure Mechanism. We systematically study training failures using Work done during their internship at Microsoft Re1Microsoft SIGMA Team, Microsoft Research. search. 2Department of Mathematics, National University of Singapore, 10 Lower Kent Ridge Rd, Singapore 119076. Correspondence to: Peng Cheng <pengc@microsoft.com>, Yeyun Gong <yegong@microsoft.com>. Preprint. February 3, 2026. 1 5M-parameter NanoGPT model derived from µP scaling (Yang et al., 2022), which provides controlled environment for reproducible failure analysis. Through extensive monitoring, we identify two critical phenomena that consistently precede training collapse (Figure 1): /W2 Observation 1: Stable Rank Collapse. The stable rank of weight matrices defined as srank(W) = W2 2 declines sharply in the steps preceding failure. This indicates that spectral energy becomes concentrated in the top singular directions, reducing the effective dimensionality of the weight matrices. Observation 2: Jacobian Alignment Growth. The alignment between adjacent layer Jacobians increases, meaning the top singular subspaces of consecutive layers become increasingly correlated. It prevents the typical cancellation effects in matrix products. We prove that these two phenomena jointly cause training instability: low stable rank implies high layer Jacobian spectral norms (since W2 = WF /(cid:112)srank(W) for fixed Frobenius norm), and high alignment ensures these norms multiply constructively across layers. The total Jacobian norm grows as (aM )L where is alignment, is layer Jacobian norm, and is depth, leading to exponential gradient explosion when aM > 1. Our Solution: The MSign Optimizer. To break the stable rank collapse condition, we propose MSign, an optimizer that periodically applies the matrix sign operation sign(W) = UVT (where = USVT is the SVD). This operation maximizes stable rank by equalizing all non-zero singular values to 1, while preserving the column and row spaces. We restore the original Frobenius norm after the operation to maintain training dynamics. MSign is applied every steps (typically = 100) to projection weights, with computational overhead below 7.0%. Experimental Validation. We validate MSign across four model configurations spanning 5M to 3B parameters: NanoGPT-5M 1, Sigma-40M (hybrid MHA/MLA attention) (Qu et al., 2025; Hu et al., 2025), LLaMA-1B (Kumar et al., 2025), and LLaMA-MoE-3B (mixture of experts). In all cases, baseline training with standard hyperparame1https://github.com/karpathy/nanoGPT MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration ters fails via gradient explosion, while training with MSign converges stably. The intervention maintains stable rank above critical thresholds, controls Jacobian alignment, and keeps gradient norms bounded. Ablation studies reveal that applying MSign to attention layers (particularly output projections) is sufficient, MLP-only application does not prevent failures. Contributions. We summarize our contributions: 1. Mechanism identification and theoretical analysis: We identify stable rank collapse and Jacobian alignment as consistent precursors to LLM training failures, and prove that their combination causes exponential gradient growth with network depth. 2. Practical solution: We propose MSign, new optimizer that prevents training failures by periodically restoring weight stable rank. 3. Extensive validation: We demonstrate MSigns effectiveness across diverse architectures (dense, MoE) and scales (5M3B parameters) with minimal overhead. 2. Literature Review Training Instability in Large Language Models. Training instability in large language models has been widely observed across major LLM projects. Chowdhery et al. (2023) documented loss spikes during PaLM training that required manual intervention and checkpoint rollbacks, while Zhang et al. (2022) provided detailed logs of OPT-175B training showing dozens of restarts due to hardware failures and gradient explosions. Zeng et al. (2023) reported similar challenges in GLM-130B training. Several factors have been proposed to explain instability: Kaplan et al. (2020) studied the sensitivity of training dynamics to learning rate in the context of scaling laws; Pascanu et al. (2012) analyzed gradient clipping as remedy for exploding gradients in RNNs; Dong et al. (2021) identified attention entropy collapse as failure mode in Vision Transformers. More recently, Wortsman et al. (2024) showed that small-scale proxy models can predict instabilities at larger scales, and Moniri et al. (2024) proposed theoretical framework connecting loss spikes to heavy-tailed gradient noise. However, these explanations typically address symptoms rather than underlying mechanisms. Low-Rank Struc"
[09.02.2026 06:04] Mistral response. {"id": "e6560d412d104734961aae39997cc89f", "created": 1770617083, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1491, "total_tokens": 1519, "completion_tokens": 28, "num_cached_tokens": 1490}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"Microsoft SIGMA Team, Microsoft Research\",\n    \"Department of Mathematics, National University of Singapore\"\n]\n```"}}]}
[09.02.2026 06:04] Response: ```python
[
    "Microsoft SIGMA Team, Microsoft Research",
    "Department of Mathematics, National University of Singapore"
]
```
[09.02.2026 06:04] Deleting PDF ./assets/pdf/2602.01734.pdf.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06960.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.06960.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.06960.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06949.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.06949.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.06949.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06663.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.06663.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.06663.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.05281.
[09.02.2026 06:04] Extra JSON file exists (./assets/json/2602.05281.json), skip PDF parsing.
[09.02.2026 06:04] Paper image links file exists (./assets/img_data/2602.05281.json), skip HTML parsing.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.05367.
[09.02.2026 06:04] Downloading paper 2602.05367 from https://arxiv.org/pdf/2602.05367v1...
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs Youngcheon You * 1 Banseok Lee * 1 Minseop Choi 1 Seonyoung Kim 1 Hyochan Chong 1 Changdong Kim 1 Youngmin Kim 1 Dongkyu Kim 1 6 2 0 2 5 ] A . [ 1 7 6 3 5 0 . 2 0 6 2 : r a "
[09.02.2026 06:04] Response: ```python
[]
```
[09.02.2026 06:04] Extracting affiliations from text.
[09.02.2026 06:04] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs Youngcheon You * 1 Banseok Lee * 1 Minseop Choi 1 Seonyoung Kim 1 Hyochan Chong 1 Changdong Kim 1 Youngmin Kim 1 Dongkyu Kim 1 6 2 0 2 5 ] A . [ 1 7 6 3 5 0 . 2 0 6 2 : r aEfficient deployment of large language models (LLMs) requires extreme quantization, forcing critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary (1) layers, but is plagued by pathological feature co-adaptation. We identify key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, novel quantization framework that resolves co-adaptation by algoIts rithmically enforcing residual hierarchy. core mechanism sequentially derives each binary path from single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers 4.49 inference speed-up over full-precision models on an RTX 4090. 1. Introduction Model compression is essential for efficient deployment of large language models (LLMs). While 4-bit quantization methods (Frantar et al., 2022; Lin et al., 2024) have emerged as successful industry standard (Kwon et al., 2023; Zheng *Equal contribution 1Samsung Research, Seoul, Korea. Correspondence to: Dongkyu Kim <dongkyu.k@samsung.com>, Youngmin Kim <ym1012.kim@samsung.com>. Preprint. February 6, 2026. et al., 2024), the relentless pursuit of greater efficiency is pushing the research frontier towards the 2-bit regime. This transition to lower bit compression introduces architectural trade-offs that characterize the current domain. At the 2-bit frontier, two primary strategies present choice between representational fidelity and hardware efficiency. Vector Quantization (VQ) methods typically yield high accuracy but incur hardware overhead due to lookup tables or complex rotations (Tseng et al., 2024a;b; Egiazarian et al., 2024). Conversely, residual binarizationstacking multiple binary layersfacilitates exceptional, matmul-free efficiency. However, this approach has struggled to preserve performance, due to fundamental training instabilities that prevent full potential realization (Bulat et al., 2024; Wang et al., 2024a; Tran & Nguyen, 2025). The core promise of residual architecturethat subsequent paths compensate for the errors of preceding onesis fundamentally undermined by feature co-adaptation (Hinton et al., 2012), pathological training dynamic where parallel components learn redundant features. In residual binarization, we identify critical manifestation of this phenomenon, which we term inter-path adaptation. During standard quantization-aware training (QAT) (Bengio et al., 2013; Hubara et al., 2018), structurally agnostic global gradient is simultaneously applied to all paths. This forces each path to learn redundant features in race to minimize the global objective, overriding their intended compensatory roles. The result is breakdown of the residual hierarchy that severely limits the models expressive power. Previous efforts have employed heuristic constraints, such as path freezing (Bulat et al., 2024; Tran & Nguyen, 2025), which inherently limit the models capacity to derive an optimal joint solution. To address this, we propose ResidualAware Binarization Training (RaBiT), QAT framework that resolves inter-path adaptation by design, as depicted in Figure 1. Instead of using independent latent weights, RaBiT maintains single shared full-precision weight from which binary paths are sequentially derived on-the-fly, guided by learnable scales. This algorithmically enforces residual hierarchy, training each path to correct RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs (a) (b) (c) Figure 1. Overview of the RaBiT training framework. (a) Dynamic Compute Process: During training, binary paths are dynamically derived from shared weight WFP to enforce residual hierarchy. (b) Forward Pass: For inference, these paths execute in parallel for matmul-free efficiency. (c) Backward Pass: Gradients from the loss update both the learnable scales (gi, hi) and the shared WFP. its predecessors error. Combined with robust, functionaware initialization, RaBiT achieves state-of-the-art accuracy while delivering up to 4.49 inference speed-up and halving the training memory footprint. Our contributions can be summarized as follows: We identify and analyze inter-path adaptation, critical manifestation of feature co-adaptation in residual binarization, where the intended error-compensation structure breaks down during Standard QAT, as parallel paths become functionally redundant. We propose RaBiT, novel QAT framework that resolves inter-path adaptation by enforcing residual coupling onthe-fly. The mechanism inherently halves the training memory footprint and is stabilized by robust functionaware initialization strategy to directly address the unstable dynamics of extreme QAT. We demonstrate that RaBiT achieves state-of-the-art accuracy at 2-bit precision, delivering up to 4.49 inference speed-up while maintaining competitive performance against hardware-intensive VQ methods through matmul-free operations. 2. Related Works The Shift to QAT in Extreme Quantization. PostTraining Quantization (PTQ) methods, such as GPTQ (Frantar et al., 2022) and AWQ (Lin et al., 2024), have proven to be highly successful for compressing large language models to 3or 4-bit precision by focusing on weight approximation. However, these methods encounter substantial performance degradation at lower bit-widths (e.g., 2-bit) (Wang et al., 2023; Huang et al., 2024; Li et al., 2024), as the information loss inherent to coarse quantization cannot be mitigated solely by weight approximation. Consequently, more recent works target preserving global model functionality (Liu et al., 2025) via quantization-aware training (Q"
[09.02.2026 06:04] Mistral response. {"id": "af4f5014639b4b0ab1e40e9135da2857", "created": 1770617092, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1514, "total_tokens": 1529, "completion_tokens": 15, "num_cached_tokens": 1513}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Samsung Research, Seoul, Korea\"]\n```"}}]}
[09.02.2026 06:04] Response: ```python
["Samsung Research, Seoul, Korea"]
```
[09.02.2026 06:04] Deleting PDF ./assets/pdf/2602.05367.pdf.
[09.02.2026 06:04] Success.
[09.02.2026 06:04] Downloading and parsing paper https://huggingface.co/papers/2602.06854.
[09.02.2026 06:04] Downloading paper 2602.06854 from https://arxiv.org/pdf/2602.06854v1...
[09.02.2026 06:05] Extracting affiliations from text.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 6 ] . [ 1 4 5 8 6 0 . 2 0 6 2 : r Published as conference paper at ICLR 2026 SEMA: SIMPLE YET EFFECTIVE LEARNING FOR MULTI-TURN JAILBREAK ATTACKS Mingqian Feng1, Xiaodong Liu2, Weiwei Yang2, Jialin Song2, Xuekai Zhu2, Chenliang Xu1 and Jianfeng Gao2 1University of Rochester, 2Microsoft Research "
[09.02.2026 06:05] Response: ```python
["University of Rochester", "Microsoft Research"]
```
[09.02.2026 06:05] Deleting PDF ./assets/pdf/2602.06854.pdf.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Downloading and parsing paper https://huggingface.co/papers/2602.06471.
[09.02.2026 06:05] Extra JSON file exists (./assets/json/2602.06471.json), skip PDF parsing.
[09.02.2026 06:05] Paper image links file exists (./assets/img_data/2602.06471.json), skip HTML parsing.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Downloading and parsing paper https://huggingface.co/papers/2602.06139.
[09.02.2026 06:05] Extra JSON file exists (./assets/json/2602.06139.json), skip PDF parsing.
[09.02.2026 06:05] Paper image links file exists (./assets/img_data/2602.06139.json), skip HTML parsing.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Downloading and parsing paper https://huggingface.co/papers/2602.05711.
[09.02.2026 06:05] Extra JSON file exists (./assets/json/2602.05711.json), skip PDF parsing.
[09.02.2026 06:05] Paper image links file exists (./assets/img_data/2602.05711.json), skip HTML parsing.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Downloading and parsing paper https://huggingface.co/papers/2601.23039.
[09.02.2026 06:05] Downloading paper 2601.23039 from https://arxiv.org/pdf/2601.23039v3...
[09.02.2026 06:05] Extracting affiliations from text.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 4 ] . [ 3 9 3 0 3 2 . 1 0 6 2 : r Avoiding Premature Collapse: Adaptive Annealing for Entropy-Regularized Structural Inference Yizhi Liu Department of Computer Science, Stony Brook University liuyizhi774@gmail.com January 23, 2026 Abstract Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT) [5, 9], serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via annealing ϵ 0 is notoriously unstable [9]. We identify fundamental mechanism for this failure: Premature Mode Collapse. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map [11], we reveal theoretical thermodynamic speed limit: standard exponential cooling outpaces the contraction rate of the inference operator, which degrades as O(1/ϵ) [4, 12]. To address this, we propose Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC), an adaptive scheduling algorithm that monitors the stability of the inference process. We demonstrate that EPH-ASC is essential for stabilizing Manifold-Constrained Hyper-Connections (mHC) [6] during largescale training on the FineWeb-Edu dataset, preventing late-stage gradient explosions by enforcing linear stability law. Entropy-regularized Optimal Transport (OT) has become standard surrogate for combinatorial inference [5, 1] and modern macro-architecture design [6, 13]. Practitioners often attempt to recover hard assignments or specialized routing by annealing the regularization parameter ϵ 0 [8, 9]. Recently, studies such as Manifold-Constrained Hyper-Connections (mHC) [6] have utilized the Sinkhorn-Knopp algorithm [10] to project residual mappings onto the Birkhoff polytope, thereby restoring the identity mapping property in multi-stream architectures [6]. Empirically, however, this cooling process is fragile [9, 2]. As ϵ decreases, the sensitivity of the optimal plan to cost"
[09.02.2026 06:05] Response: ```python
["Department of Computer Science, Stony Brook University"]
```
[09.02.2026 06:05] Deleting PDF ./assets/pdf/2601.23039.pdf.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Downloading and parsing paper https://huggingface.co/papers/2602.06554.
[09.02.2026 06:05] Downloading paper 2602.06554 from https://arxiv.org/pdf/2602.06554v1...
[09.02.2026 06:05] Extracting affiliations from text.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2026-02-09 SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees Tianyi Hu, Qingxu Fu, Yanxi Chen, Zhaoyang Liu, Bolin Ding Tongyi Lab , Alibaba Group {wenju.hty, fuqingxu.fqx, chenyanxi.cyx, jingmu.lzy, bolin.ding}@alibaba-inc.com Abstract Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies. In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPOs original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios. To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-byturn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction. Experiments on AppWorld and BFCL v4 demonstrate SeeUPOs substantial improvements over existing backbone algorithms: relative gains of 43.3%54.6% on Qwen3-14B and 24.1%41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability. 6 2 0 F 6 ] . [ 1 4 5 5 6 0 . 2 0 6 2 : r Figure 1: Performance comparison of training Qwen3-14B model on the AppWorld and BFCL-v4 benchmarks. (a)-(b) show trainin"
[09.02.2026 06:05] Response: ```python
["Tongyi Lab, Alibaba Group"]
```
[09.02.2026 06:05] Deleting PDF ./assets/pdf/2602.06554.pdf.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Downloading and parsing paper https://huggingface.co/papers/2602.01064.
[09.02.2026 06:05] Extra JSON file exists (./assets/json/2602.01064.json), skip PDF parsing.
[09.02.2026 06:05] Paper image links file exists (./assets/img_data/2602.01064.json), skip HTML parsing.
[09.02.2026 06:05] Success.
[09.02.2026 06:05] Enriching papers with extra data.
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 0. The paper establishes a theoretical framework for analyzing entropy dynamics in reinforcement fine-tuning of large language models, deriving expressions for entropy change and proposing entropy control methods based on discriminant analysis.  					AI-generated summary 				 Entropy serves as a critic...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 1. Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation.  					AI-generated summary 				 Recent progress in reasoning models suggests that g...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 2. Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression.  					AI-generated summary 				 We introduce Baichuan-M3, a medical-enhanced large language model...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 3. TRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages.  					AI-generated summary 				 Long reasoning models often struggle in multilingual settings: they tend to reason in En...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 4. A comprehensive memory-focused benchmark for mobile GUI agents reveals significant memory capability gaps and provides systematic evaluation methods and design insights.  					AI-generated summary 				 Current mobile GUI agent benchmarks systematically fail to assess memory capabilities, with only 5...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 5. GUI agents for automated digital tasks rely on vision-language models with enhanced grounding capabilities, achieved through refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards.  					AI-generated summary 				 The rapid advancement of vision-lan...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 6. OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws.  					AI-generated summary 				 The rapid advancement of Large Language Models (LLMs) has catalyzed the development ...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 7. Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.  					AI-generated summary 				 Training instability remains a critical challenge in large languag...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 8. InftyThink+ uses reinforcement learning to optimize iterative reasoning processes, improving accuracy and efficiency in large language models.  					AI-generated summary 				 Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from ...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 9. DreamDojo is a foundation world model trained on 44k hours of egocentric human videos that enables efficient simulation of dexterous robotic tasks through continuous latent actions and real-time distillation.  					AI-generated summary 				 Being able to simulate the outcomes of actions in varied en...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 10. PlanViz benchmark evaluates unified multimodal models' capabilities in computer-use planning tasks through route planning, work diagramming, and web&UI displaying sub-tasks with a task-adaptive scoring system.  					AI-generated summary 				 Unified multimodal models (UMMs) have shown impressive cap...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 11. A novel reinforcement learning approach called ARM addresses entropy collapse in LLM reasoning by equilibrating confidence levels across correct responses through dynamic reward shaping.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an indispens...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 12. Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs.  					AI-generated summary 				 Efficient deployment of large language models (LLMs) requires ext...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 13. A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and ...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 14. Replacing conventional feed-forward networks with hourglass-shaped MLPs in Transformers improves model efficiency and performance by enabling better parameter utilization and competitive scaling.  					AI-generated summary 				 Dense Transformer language models have largely adhered to one consistent...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 15. Multi-modal large language models struggle to jointly understand audio and visual signals in egocentric videos, but a new scalable data engine and dataset significantly improve their performance through targeted fine-tuning.  					AI-generated summary 				 Understanding egocentric videos plays a vit...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 16. OmniMoE presents a system-algorithm co-designed framework that achieves fine-grained expert specialization in Mixture-of-Experts architectures through vector-level atomic experts and optimized routing and scheduling mechanisms.  					AI-generated summary 				 Mixture-of-Experts (MoE) architectures a...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 17. Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training.  					AI-generated summary 				 Differentiable matching layers and residual ...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 18. SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates.  					AI-generated summary 				 Reinforcement learning (RL...
[09.02.2026 06:05] ********************************************************************************
[09.02.2026 06:05] Abstract 19. Knowledge purification techniques consolidate rationales from multiple teacher LLMs to reduce conflicts and improve efficiency in distillation processes.  					AI-generated summary 				 Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language ...
[09.02.2026 06:05] Read previous papers.
[09.02.2026 06:05] Generating reviews via LLM API.
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#rlhf", "#math", "#training", "#rl"], "emoji": "⚖️", "ru": {"title": "Теория энтропии в усиленном обучении языковых моделей", "desc": "В статье разработан теоретический фреймворк для анализа динамики энтропии при усиленном обучении больших языковых моделей. Авторы выводят выражения 
[09.02.2026 06:05] Querying the API.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation.  					AI-generated summary 				 Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose Consequence-Based Utility, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap, maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve.
[09.02.2026 06:05] Response: ```json
{
  "desc": "В статье предлагается метод Consequence-Based Utility для оценки качества математических решений без привлечения экспертов. Вместо использования традиционных reward моделей или судейства через LLM, метод проверяет, насколько хорошо данное решение работает как пример в контексте (in-context exemplar) для решения связанных задач. Эксперименты на исследовательском уровне математических задач показывают, что предложенный подход существенно превосходит существующие методы оценки по метрикам ранжирования и разделению корректных и некорректных решений. Ключевая идея заключается в том, что качественное решение содержит достаточно методологической информации, которая помогает решать похожие задачи лучше, чем некорректные решения.",
  "emoji": "🧮",
  "title": "Оценка математических решений через их практическую полезность на соседних задачах"
}
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation.  					AI-generated summary 				 Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose Consequence-Based Utility, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap, maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve."

[09.02.2026 06:05] Response: ```python
["MATH", "BENCHMARK", "DATASET"]
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation.  					AI-generated summary 				 Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose Consequence-Based Utility, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap, maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve."

[09.02.2026 06:05] Response: ```python
['REASONING', 'SCIENCE']
```
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Consequence-Based Utility, a new method for evaluating mathematical solutions by assessing their effectiveness as examples for similar problems. Unlike traditional reward models and LLM judges, this approach does not rely on pre-defined rewards but instead tests how well a solution can help solve related questions. The authors demonstrate that their method significantly improves the ranking quality of solutions, achieving higher accuracy and area under the curve (AUC) scores compared to existing models. This innovation addresses the challenge of verifying complex mathematical solutions while reducing the burden on expert evaluators.","title":"Evaluating Math Solutions with Consequence-Based Utility"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Consequence-Based Utility, a new method for evaluating mathematical solutions by assessing their effectiveness as examples for similar problems. Unlike traditional reward models and LLM judges, this approach does not rely on pre-defined rewards but instead tests how well a solution can help solve related questions. The authors demonstrate that their method significantly improves the ranking quality of solutions, achieving higher accuracy and area under the curve (AUC) scores compared to existing models. This innovation addresses the challenge of verifying complex mathematical solutions while reducing the burden on expert evaluators.', title='Evaluating Math Solutions with Consequence-Based Utility'))
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的评估方法，称为基于后果的效用（Consequence-Based Utility），用于评估数学问题的解决方案。该方法通过测试候选解在解决相关可验证问题中的表现，来判断其作为示例的价值。研究表明，这种方法在排名质量上优于传统的奖励模型和大型语言模型（LLM）评估者。具体而言，基于后果的效用在多个研究级数学问题上显示出显著的性能提升，尤其是在正确与错误的区分上表现更为出色。","title":"基于后果的效用：提升数学解答评估的创新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的评估方法，称为基于后果的效用（Consequence-Based Utility），用于评估数学问题的解决方案。该方法通过测试候选解在解决相关可验证问题中的表现，来判断其作为示例的价值。研究表明，这种方法在排名质量上优于传统的奖励模型和大型语言模型（LLM）评估者。具体而言，基于后果的效用在多个研究级数学问题上显示出显著的性能提升，尤其是在正确与错误的区分上表现更为出色。', title='基于后果的效用：提升数学解答评估的创新方法'))
[09.02.2026 06:05] Querying the API.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression.  					AI-generated summary 				 We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3.
[09.02.2026 06:05] Response: ```json
{
  "desc": "Baichuan-M3 — это медицинская LLM, которая переводит парадигму взаимодействия с пациентами от пассивного ответа на вопросы к активной поддержке клинических решений. Модель обучена на специализированном конвейере, моделирующем систематический рабочий процесс врача, и включает три ключевые способности: проактивный сбор информации для разрешения неоднозначности, долгосрочное рассуждение для синтеза доказательств в связный диагноз и адаптивное подавление галлюцинаций. Архитектура обеспечивает высокую факт-отчётность и достигает лучших результатов на специализированных бенчмарках HealthBench, HealthBench-Hallu и ScanBench, превосходя существующие решения в клинических консультациях и безопасности. Модель опубликована в открытом доступе и доступна для практического применения в медицинских приложениях.",
  "emoji": "⚕️",
  "title": "От пассивных ответов к активной врачебной поддержке"
}
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression.  					AI-generated summary 				 We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3."

[09.02.2026 06:05] Response: ```python
["HEALTHCARE", "DATASET", "TRAINING"]
```

**Justification:**

1. **HEALTHCARE**: The paper explicitly focuses on applying ML to medical/healthcare domains. Baichuan-M3 is designed for "clinical decision support" and is evaluated on medical benchmarks (HealthBench, HealthBench-Hallu, ScanBench).

2. **DATASET**: The paper introduces new datasets/benchmarks for evaluation: "HealthBench-Hallu and ScanBench" are newly introduced evaluation frameworks for the medical domain.

3. **TRAINING**: The paper describes "a specialized training pipeline" designed to model physician workflows, which directly relates to training methodology improvements.
[09.02.2026 06:05] Error. Failed to parse JSON from LLM. ["HEALTHCARE", "DATASET", "TRAINING"]


**Justification:**

1. **HEALTHCARE**: The paper explicitly focuses on applying ML to medical/healthcare domains. Baichuan-M3 is designed for "clinical decision support" and is evaluated on medical benchmarks (HealthBench, HealthBench-Hallu, ScanBench).

2. **DATASET**: The paper introduces new datasets/benchmarks for evaluation: "HealthBench-Hallu and ScanBench" are newly introduced evaluation frameworks for the medical domain.

3. **TRAINING**: The paper describes "a specialized training pipeline" designed to model physician workflows, which directly relates to training methodology improvements.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression.  					AI-generated summary 				 We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3."

[09.02.2026 06:05] Response: ```python
['REASONING', 'HALLUCINATIONS', 'SCIENCE', 'OPEN_SOURCE']
```
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Baichuan-M3 is a large language model specifically designed for medical applications, focusing on enhancing clinical decision-making. It moves beyond traditional question-answering by actively supporting healthcare professionals with proactive information gathering and long-term reasoning. The model effectively integrates various pieces of evidence to form coherent diagnoses while minimizing inaccuracies through adaptive hallucination suppression. Evaluations show that Baichuan-M3 outperforms existing models like GPT-5.2 in clinical tasks, making it a significant advancement in medical AI.","title":"Revolutionizing Clinical Decision Support with Baichuan-M3"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Baichuan-M3 is a large language model specifically designed for medical applications, focusing on enhancing clinical decision-making. It moves beyond traditional question-answering by actively supporting healthcare professionals with proactive information gathering and long-term reasoning. The model effectively integrates various pieces of evidence to form coherent diagnoses while minimizing inaccuracies through adaptive hallucination suppression. Evaluations show that Baichuan-M3 outperforms existing models like GPT-5.2 in clinical tasks, making it a significant advancement in medical AI.', title='Revolutionizing Clinical Decision Support with Baichuan-M3'))
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Baichuan-M3是一种医学增强的大型语言模型，旨在为临床决策提供支持。它的主要特点包括主动信息获取、长时间推理和幻觉抑制，能够有效解决现有系统在开放式咨询中的局限性。该模型通过专门的训练流程模拟医生的系统工作流程，能够将分散的证据整合为连贯的诊断。实证评估表明，Baichuan-M3在HealthBench等基准测试中表现优异，显著超越了GPT-5.2。","title":"主动决策支持，超越传统问答"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Baichuan-M3是一种医学增强的大型语言模型，旨在为临床决策提供支持。它的主要特点包括主动信息获取、长时间推理和幻觉抑制，能够有效解决现有系统在开放式咨询中的局限性。该模型通过专门的训练流程模拟医生的系统工作流程，能够将分散的证据整合为连贯的诊断。实证评估表明，Baichuan-M3在HealthBench等基准测试中表现优异，显著超越了GPT-5.2。', title='主动决策支持，超越传统问答'))
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#translation", "#transfer_learning", "#multilingual", "#training", "#reasoning"], "emoji": "🌍", "ru": {"title": "Объединение перевода и рассуждений для улучшения многоязычного понимания", "desc": "В статье представлен фреймворк TRIT, который улучшает многоязычное рассуждение путём с
[09.02.2026 06:05] Using data from previous issue: {"categories": [], "emoji": "🧠", "ru": {"title": "Память как критический недостаток мобильных GUI-агентов: комплексная оценка и решения", "desc": "В работе представлена MemGUI-Bench — комплексный бенчмарк для оценки способности мобильных GUI-агентов к запоминанию информации и обучению на основе пред
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#multimodal", "#rl", "#benchmark", "#agents", "#training", "#cv", "#data"], "emoji": "🖱️", "ru": {"title": "Точное определение элементов GUI через инженерию данных и обучение с подкреплением", "desc": "В статье представлена модель POINTS-GUI-G-8B для автоматизации задач с графически
[09.02.2026 06:05] Querying the API.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws.  					AI-generated summary 				 The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena
[09.02.2026 06:05] Response: ```json
{
  "desc": "В работе представлен OdysseyArena — новый бенчмарк для оценки больших языковых моделей на задачах с длинным горизонтом планирования, где агенты должны самостоятельно открывать законы переходов окружающей среды из опыта. Существующие подходы к оценке агентов сосредоточены на дедуктивной парадигме, когда агенты выполняют явно заданные задачи, однако пренебрегают индуктивной способностью к автономному обнаружению скрытых закономерностей. Авторы формализуют четыре примитива переходных динамик и создают две версии бенчмарка: OdysseyArena-Lite с 120 задачами для измерения эффективности индуктивного обучения и OdysseyArena-Challenge для тестирования стабильности агентов на экстремально длинных взаимодействиях (более 200 шагов). Эксперименты на 15+ передовых LLM показали критический недостаток в способности моделей к индуктивному рассуждению в сложных окружающих средах.",
  "emoji": "🧭",
  "title": "Оценка автономного открытия законов природы в долгосрочных взаимодействиях агентов"
}
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws.  					AI-generated summary 				 The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena"

[09.02.2026 06:05] Response: ```python
["AGENTS", "BENCHMARK", "DATASET"]
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws.  					AI-generated summary 				 The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena"

[09.02.2026 06:05] Response: ```python
['REASONING', 'LONG_CONTEXT', 'OPEN_SOURCE']
```
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OdysseyArena introduces a new framework for assessing large language models (LLMs) in tasks that require long-term planning and the ability to learn from their environment. Unlike traditional evaluations that rely on fixed rules, this framework emphasizes the importance of inductive reasoning, allowing agents to discover underlying transition laws through experience. The framework includes OdysseyArena-Lite for standardized benchmarking with 120 tasks, and OdysseyArena-Challenge to evaluate agent performance over extended interactions. Experiments show that even advanced LLMs struggle with these inductive tasks, highlighting a significant challenge in developing autonomous agents capable of effective long-term decision-making.","title":"Empowering Agents to Learn and Adapt Autonomously"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='OdysseyArena introduces a new framework for assessing large language models (LLMs) in tasks that require long-term planning and the ability to learn from their environment. Unlike traditional evaluations that rely on fixed rules, this framework emphasizes the importance of inductive reasoning, allowing agents to discover underlying transition laws through experience. The framework includes OdysseyArena-Lite for standardized benchmarking with 120 tasks, and OdysseyArena-Challenge to evaluate agent performance over extended interactions. Experiments show that even advanced LLMs struggle with these inductive tasks, highlighting a significant challenge in developing autonomous agents capable of effective long-term decision-making.', title='Empowering Agents to Learn and Adapt Autonomously'))
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OdysseyArena是一个新的框架，用于评估大型语言模型在长时间范围内的自主发现环境转变规律的能力。现有的评估方法主要基于演绎推理，忽视了代理从经验中自主发现潜在转变规律的必要性。我们提出了OdysseyArena，重新聚焦于长时间范围内的主动和归纳交互，建立了四个基本原理，将抽象的转变动态转化为具体的交互环境。通过标准化基准测试OdysseyArena-Lite，我们提供了120个任务来衡量代理的归纳效率和长时间发现能力。","title":"自主发现的未来：OdysseyArena框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='OdysseyArena是一个新的框架，用于评估大型语言模型在长时间范围内的自主发现环境转变规律的能力。现有的评估方法主要基于演绎推理，忽视了代理从经验中自主发现潜在转变规律的必要性。我们提出了OdysseyArena，重新聚焦于长时间范围内的主动和归纳交互，建立了四个基本原理，将抽象的转变动态转化为具体的交互环境。通过标准化基准测试OdysseyArena-Lite，我们提供了120个任务来衡量代理的归纳效率和长时间发现能力。', title='自主发现的未来：OdysseyArena框架'))
[09.02.2026 06:05] Querying the API.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.  					AI-generated summary 				 Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via μP, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.
[09.02.2026 06:05] Response: ```json
{
  "desc": "В статье исследуется проблема нестабильности обучения больших языковых моделей, которая проявляется в виде взрывного роста градиентов. Авторы выявили два ключевых явления, предшествующих коллапсу: снижение стабильного ранга матриц весов и возрастающее выравнивание якобианов соседних слоёв. Они доказали теоретически, что эти условия вместе вызывают экспоненциальный рост нормы градиента с глубиной сети. Для решения этой проблемы предложен оптимизатор MSign, который периодически применяет операции матричного знака для восстановления стабильного ранга.",
  "emoji": "⚡",
  "title": "MSign: стабилизация обучения больших моделей через восстановление ранга матриц"
}
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.  					AI-generated summary 				 Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via μP, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%."

[09.02.2026 06:05] Response: ```python
["TRAINING", "ARCHITECTURE"]
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.  					AI-generated summary 				 Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via μP, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%."

[09.02.2026 06:05] Response: ```python
["OPTIMIZATION"]
```
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the problem of training instability in large language models, which often leads to gradient explosions during pretraining. The authors identify two critical factors that contribute to this instability: a rapid decline in the stable rank of weight matrices and increased alignment of Jacobians between layers. They introduce a new optimizer called MSign, which uses matrix sign operations to maintain stable rank and prevent these issues. Experimental results show that MSign successfully mitigates training failures with minimal additional computational cost.","title":"Stabilizing Training in Large Language Models with MSign"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the problem of training instability in large language models, which often leads to gradient explosions during pretraining. The authors identify two critical factors that contribute to this instability: a rapid decline in the stable rank of weight matrices and increased alignment of Jacobians between layers. They introduce a new optimizer called MSign, which uses matrix sign operations to maintain stable rank and prevent these issues. Experimental results show that MSign successfully mitigates training failures with minimal additional computational cost.', title='Stabilizing Training in Large Language Models with MSign'))
[09.02.2026 06:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"在大型语言模型的训练中，训练不稳定性是一个重要挑战，常常表现为突发的梯度爆炸，浪费大量计算资源。我们研究了一个5M参数的NanoGPT模型的训练失败，发现了导致崩溃的两个关键现象：权重矩阵稳定秩的快速下降和相邻层雅可比矩阵之间的对齐增加。我们理论证明这两个条件共同导致了随着网络深度的增加，梯度范数的指数增长。为了解决这一不稳定机制，我们提出了MSign，一种新的优化器，通过周期性地应用矩阵符号操作来恢复稳定秩。","title":"解决大型语言模型训练不稳定性的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='在大型语言模型的训练中，训练不稳定性是一个重要挑战，常常表现为突发的梯度爆炸，浪费大量计算资源。我们研究了一个5M参数的NanoGPT模型的训练失败，发现了导致崩溃的两个关键现象：权重矩阵稳定秩的快速下降和相邻层雅可比矩阵之间的对齐增加。我们理论证明这两个条件共同导致了随着网络深度的增加，梯度范数的指数增长。为了解决这一不稳定机制，我们提出了MSign，一种新的优化器，通过周期性地应用矩阵符号操作来恢复稳定秩。', title='解决大型语言模型训练不稳定性的新方法'))
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#small_models", "#optimization", "#rl", "#training", "#reasoning", "#long_context"], "emoji": "🧠", "ru": {"title": "Умное резюмирование мыслей через обучение с подкреплением", "desc": "В статье предложена система InftyThink+, которая использует обучение с подкреплением для оптимизац
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#inference", "#open_source", "#synthetic", "#transfer_learning", "#video", "#training", "#robotics", "#dataset"], "emoji": "🤖", "ru": {"title": "Универсальная модель мира для ловкого робоуправления из видео человека", "desc": "DreamDojo — это фундаментальная модель мира, обученная н
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#survey", "#multimodal", "#benchmark", "#cv", "#dataset"], "emoji": "📋", "ru": {"title": "Оценка мультимодальных моделей в задачах планирования с использованием компьютера", "desc": "Исследование представляет бенчмарк PlanViz для оценки способностей объединённых мультимодальных моде
[09.02.2026 06:05] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#rl"], "emoji": "⚖️", "ru": {"title": "Уравновешивание уверенности для разнообразного рассуждения в больших языковых моделях", "desc": "В статье предложен новый метод ARM (Advantage Re-weighting Mechanism) для решения проблемы коллапса энт
[09.02.2026 06:05] Querying the API.
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs.  					AI-generated summary 				 Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary (pm1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a 4.49times inference speed-up over full-precision models on an RTX 4090.
[09.02.2026 06:05] Response: ```json
{
  "desc": "RaBiT — это новая структура квантизации для больших языковых моделей, которая решает проблему совместной адаптации признаков путём иерархического построения остаточных бинарных путей. Ключевое улучшение заключается в том, что каждый бинарный путь последовательно выводится из одного общего полноточного веса, что обеспечивает коррекцию ошибок предыдущим слоем. Метод включает надёжную инициализацию, которая приоритизирует сохранение функциональности модели над простым приближением весов. RaBiT достигает лучшего баланса между точностью и эффективностью, конкурируя с методами векторной квантизации и обеспечивая 4,49-кратное ускорение инференса на RTX 4090.",
  "emoji": "⚡",
  "title": "Иерархическая бинаризация для эффективного инференса LLM"
}
```
[09.02.2026 06:05] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs.  					AI-generated summary 				 Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary (pm1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a 4.49times inference speed-up over full-precision models on an RTX 4090."

[09.02.2026 06:06] Response: ```python
['INFERENCE', 'TRAINING', 'ARCHITECTURE']
```
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs.  					AI-generated summary 				 Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary (pm1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a 4.49times inference speed-up over full-precision models on an RTX 4090."

[09.02.2026 06:06] Response: ```python
['OPTIMIZATION']
```
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces the Residual Binarization framework (RaBiT) to tackle the issue of feature co-adaptation in quantized large language models (LLMs). It highlights a problem called inter-path adaptation, where multiple binary paths learn similar features, which reduces the model\'s performance. RaBiT addresses this by creating a hierarchical structure for binary paths that ensures each path builds on the previous one, improving error correction. This method not only enhances accuracy but also significantly speeds up inference, outperforming traditional quantization techniques.","title":"RaBiT: Revolutionizing Quantization for Efficient LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces the Residual Binarization framework (RaBiT) to tackle the issue of feature co-adaptation in quantized large language models (LLMs). It highlights a problem called inter-path adaptation, where multiple binary paths learn similar features, which reduces the model's performance. RaBiT addresses this by creating a hierarchical structure for binary paths that ensures each path builds on the previous one, improving error correction. This method not only enhances accuracy but also significantly speeds up inference, outperforming traditional quantization techniques.", title='RaBiT: Revolutionizing Quantization for Efficient LLMs'))
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为RaBiT的残差二值化框架，旨在解决量化大语言模型（LLMs）中的特征共适应问题。通过分层路径推导和稳健初始化，RaBiT能够在低比特效率和模型性能之间实现优越的权衡。该框架通过算法性地强制执行残差层次结构，确保每个二进制路径都能纠正前一个路径的错误，从而提高模型的表达能力。最终，RaBiT在2比特精度效率的前沿上重新定义了性能标准，显著提升了推理速度。","title":"残差二值化：提升量化模型性能的创新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为RaBiT的残差二值化框架，旨在解决量化大语言模型（LLMs）中的特征共适应问题。通过分层路径推导和稳健初始化，RaBiT能够在低比特效率和模型性能之间实现优越的权衡。该框架通过算法性地强制执行残差层次结构，确保每个二进制路径都能纠正前一个路径的错误，从而提高模型的表达能力。最终，RaBiT在2比特精度效率的前沿上重新定义了性能标准，显著提升了推理速度。', title='残差二值化：提升量化模型性能的创新框架'))
[09.02.2026 06:06] Querying the API.
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and datasets.  					AI-generated summary 				 Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average 80.1% ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA.
[09.02.2026 06:06] Response: ```json
{
  "desc": "Представлена фреймворк SEMA для обучения многоходовых атак на большие языковые модели без использования существующих стратегий и внешних данных. Метод состоит из двух этапов: предварительной настройки с самонастройкой для генерации устойчивых неудачных примеров и обучения с подкреплением с учётом дрейфа интента для сохранения вредоносной цели. Система достигает состояния искусства в частоте успешных атак (80.1% на AdvBench), превосходя однооходовые и существующие многоходовые базовые методы. Подход компактен, воспроизводим и хорошо переносится между различными моделями-жертвами.",
  "emoji": "🎯",
  "title": "Многоходовые атаки на LLM через обучение с подкреплением без внешних данных"
}
```
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and datasets.  					AI-generated summary 				 Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average 80.1% ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA."

[09.02.2026 06:06] Response: ```python
["RL", "TRAINING"]
```
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and datasets.  					AI-generated summary 				 Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average 80.1% ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA."

[09.02.2026 06:06] Response: ```python
["SECURITY", "ALIGNMENT", "OPEN_SOURCE"]
```
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces SEMA, a new framework designed to train multi-turn attackers for large language models (LLMs) without using existing strategies or external data. It addresses the limitations of previous methods that struggle with exploration complexity and intent drift by employing a two-stage process: prefilling self-tuning and reinforcement learning with intent-drift-aware rewards. SEMA achieves state-of-the-art attack success rates by effectively generating adversarial prompts that maintain harmful intent across multiple turns. This approach is compact, reproducible, and transferable, making it a robust tool for testing the safety of LLMs.","title":"SEMA: Revolutionizing Multi-Turn Attacks for Safer Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces SEMA, a new framework designed to train multi-turn attackers for large language models (LLMs) without using existing strategies or external data. It addresses the limitations of previous methods that struggle with exploration complexity and intent drift by employing a two-stage process: prefilling self-tuning and reinforcement learning with intent-drift-aware rewards. SEMA achieves state-of-the-art attack success rates by effectively generating adversarial prompts that maintain harmful intent across multiple turns. This approach is compact, reproducible, and transferable, making it a robust tool for testing the safety of LLMs.', title='SEMA: Revolutionizing Multi-Turn Attacks for Safer Language Models'))
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种名为SEMA的新框架，旨在有效训练多轮攻击者，以应对大型语言模型的安全性问题。SEMA不依赖于现有策略或外部数据，能够在不同模型和数据集上实现最先进的攻击成功率。该框架包括两个阶段：自我调优的预填充和基于意图漂移的强化学习，确保生成有效的多轮对抗提示。通过这种方法，SEMA在多个数据集和模型上表现出色，提供了更强大和现实的压力测试，促进了大型语言模型的安全性研究。","title":"SEMA：多轮攻击的新框架，提升语言模型安全性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种名为SEMA的新框架，旨在有效训练多轮攻击者，以应对大型语言模型的安全性问题。SEMA不依赖于现有策略或外部数据，能够在不同模型和数据集上实现最先进的攻击成功率。该框架包括两个阶段：自我调优的预填充和基于意图漂移的强化学习，确保生成有效的多轮对抗提示。通过这种方法，SEMA在多个数据集和模型上表现出色，提供了更强大和现实的压力测试，促进了大型语言模型的安全性研究。', title='SEMA：多轮攻击的新框架，提升语言模型安全性'))
[09.02.2026 06:06] Using data from previous issue: {"categories": ["#optimization"], "emoji": "⏳", "ru": {"title": "Песочные часы вместо традиции: переосмысление архитектуры Трансформеров", "desc": "Исследование предлагает заменить традиционные полносвязные сети (FFN) в Трансформерах на более глубокие сети в форме песочных часов, которые лучше испол
[09.02.2026 06:06] Using data from previous issue: {"categories": ["#audio", "#multimodal", "#benchmark", "#video", "#training", "#robotics", "#dataset"], "emoji": "👁️‍🗨️", "ru": {"title": "Гармоничное слияние звука и видения в эгоцентрических сценах", "desc": "Работа исследует проблему совместного понимания аудио и визуальной информации в эгоцентри
[09.02.2026 06:06] Using data from previous issue: {"categories": ["#inference", "#training", "#architecture"], "emoji": "⚡", "ru": {"title": "Атомарные эксперты: максимальная специализация при сохранении скорости", "desc": "OmniMoE представляет систему, которая достигает максимальной специализации экспертов в архитектуре Mixture-of-Experts благодар
[09.02.2026 06:06] Querying the API.
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training.  					AI-generated summary 				 Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT), serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via annealing εto 0 is notoriously unstable. In this work, we identify a fundamental mechanism for this failure: Premature Mode Collapse. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map, we reveal a theoretical thermodynamic speed limit: standard exponential cooling outpaces the contraction rate of the inference operator, which degrades as O(1/ε). To address this, we propose Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC), an adaptive scheduling algorithm that monitors the stability of the inference process. We demonstrate that EPH-ASC is essential for stabilizing Manifold-Constrained Hyper-Connections (mHC) during large-scale training on the FineWeb-Edu dataset, effectively preventing late-stage gradient explosions by enforcing a linear stability law.
[09.02.2026 06:06] Response: ```json
{
  "desc": "В работе исследователи выявили проблему преждевременного коллапса мод в моделях структурного предсказания, основанных на оптимальном транспорте. Авторы провели анализ динамики алгоритма Синхорна и обнаружили фундаментальное ограничение: стандартное экспоненциальное охлаждение работает быстрее, чем сжатие оператора вывода. Для решения этой проблемы предложен адаптивный алгоритм EPH-ASC, который отслеживает стабильность процесса вывода и контролирует градиентные взрывы. Метод успешно стабилизирует обучение больших моделей на датасетах масштаба FineWeb-Edu, обеспечивая устойчивость через принцип линейной стабильности.",
  "emoji": "⚡",
  "title": "Адаптивная стабилизация режимов в оптимальном транспорте для масштабируемого предсказания структур"
}
```
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training.  					AI-generated summary 				 Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT), serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via annealing εto 0 is notoriously unstable. In this work, we identify a fundamental mechanism for this failure: Premature Mode Collapse. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map, we reveal a theoretical thermodynamic speed limit: standard exponential cooling outpaces the contraction rate of the inference operator, which degrades as O(1/ε). To address this, we propose Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC), an adaptive scheduling algorithm that monitors the stability of the inference process. We demonstrate that EPH-ASC is essential for stabilizing Manifold-Constrained Hyper-Connections (mHC) during large-scale training on the FineWeb-Edu dataset, effectively preventing late-stage gradient explosions by enforcing a linear stability law."

[09.02.2026 06:06] Response: ```python
["ARCHITECTURE", "TRAINING", "MATH"]
```

**Justification:**

- **ARCHITECTURE**: The paper proposes novel neural architecture components, specifically "Differentiable matching layers and residual connection paradigms" and "Manifold-Constrained Hyper-Connections (mHC)".

- **TRAINING**: The paper addresses training stability issues, proposes an adaptive scheduling algorithm (EPH-ASC) for stabilizing training, and demonstrates its effectiveness during large-scale training on the FineWeb-Edu dataset.

- **MATH**: The paper provides theoretical analysis including "non-normal dynamics of the Sinkhorn fixed-point map," "thermodynamic speed limit," and mathematical characterization of the contraction rate degradation as O(1/ε).
[09.02.2026 06:06] Error. Failed to parse JSON from LLM. ["ARCHITECTURE", "TRAINING", "MATH"]


**Justification:**

- **ARCHITECTURE**: The paper proposes novel neural architecture components, specifically "Differentiable matching layers and residual connection paradigms" and "Manifold-Constrained Hyper-Connections (mHC)".

- **TRAINING**: The paper addresses training stability issues, proposes an adaptive scheduling algorithm (EPH-ASC) for stabilizing training, and demonstrates its effectiveness during large-scale training on the FineWeb-Edu dataset.

- **MATH**: The paper provides theoretical analysis including "non-normal dynamics of the Sinkhorn fixed-point map," "thermodynamic speed limit," and mathematical characterization of the contraction rate degradation as O(1/ε).
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training.  					AI-generated summary 				 Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT), serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via annealing εto 0 is notoriously unstable. In this work, we identify a fundamental mechanism for this failure: Premature Mode Collapse. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map, we reveal a theoretical thermodynamic speed limit: standard exponential cooling outpaces the contraction rate of the inference operator, which degrades as O(1/ε). To address this, we propose Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC), an adaptive scheduling algorithm that monitors the stability of the inference process. We demonstrate that EPH-ASC is essential for stabilizing Manifold-Constrained Hyper-Connections (mHC) during large-scale training on the FineWeb-Edu dataset, effectively preventing late-stage gradient explosions by enforcing a linear stability law."

[09.02.2026 06:06] Response: ```python
["OPTIMIZATION"]
```
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper tackles the issue of premature mode collapse in optimal transport-based structural prediction models, which can lead to instability during training. The authors introduce an adaptive stability control algorithm called Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC) to prevent gradient explosions. By analyzing the dynamics of the Sinkhorn fixed-point map, they uncover a speed limit that contributes to the instability. The proposed method is shown to effectively stabilize the training process, particularly in large-scale applications like the FineWeb-Edu dataset.","title":"Stabilizing Structural Prediction with Adaptive Control"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper tackles the issue of premature mode collapse in optimal transport-based structural prediction models, which can lead to instability during training. The authors introduce an adaptive stability control algorithm called Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC) to prevent gradient explosions. By analyzing the dynamics of the Sinkhorn fixed-point map, they uncover a speed limit that contributes to the instability. The proposed method is shown to effectively stabilize the training process, particularly in large-scale applications like the FineWeb-Edu dataset.', title='Stabilizing Structural Prediction with Adaptive Control'))
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究针对基于最优传输的结构预测模型中的早期模式崩溃问题，提出了一种自适应稳定性控制算法。该算法能够在大规模训练过程中防止梯度爆炸，确保模型的稳定性。我们分析了Sinkhorn固定点映射的非正常动态，揭示了一个理论热力学速度极限，指出标准的指数冷却速度超过了推理算子的收缩速率。通过引入高效分段混合自适应稳定性控制（EPH-ASC），我们成功地在FineWeb-Edu数据集上稳定了流形约束超连接（mHC），有效避免了后期的梯度爆炸。","title":"防止早期模式崩溃的自适应稳定性控制"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究针对基于最优传输的结构预测模型中的早期模式崩溃问题，提出了一种自适应稳定性控制算法。该算法能够在大规模训练过程中防止梯度爆炸，确保模型的稳定性。我们分析了Sinkhorn固定点映射的非正常动态，揭示了一个理论热力学速度极限，指出标准的指数冷却速度超过了推理算子的收缩速率。通过引入高效分段混合自适应稳定性控制（EPH-ASC），我们成功地在FineWeb-Edu数据集上稳定了流形约束超连接（mHC），有效避免了后期的梯度爆炸。', title='防止早期模式崩溃的自适应稳定性控制'))
[09.02.2026 06:06] Querying the API.
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.   In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.   To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.   Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.
[09.02.2026 06:06] Response: ```json
{
  "desc": "SeeUPO — это метод обучения с подкреплением без критика, который гарантирует сходимость при взаимодействии агентов в несколько ходов. Авторы показали, что существующие алгоритмы (PPO, REINFORCE) теряют гарантии сходимости в многоходовых сценариях при использовании bepaрametrических оценок преимущества. Предложенный подход моделирует многоходовое взаимодействие как последовательно выполняемые задачи многоагентного бандита и использует обратную индукцию для обновления политики в обратном порядке ходов. Экспериментальные результаты демонстрируют значительное улучшение производительности и стабильности обучения по сравнению с существующими методами на бенчмарках AppWorld и BFCL v4.",
  "emoji": "🎯",
  "title": "Гарантированная сходимость обучения с подкреплением без критика через обратную индукцию"
}
```
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.   In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.   To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.   Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability."

[09.02.2026 06:06] Response: ```python
["RL", "AGENTS", "TRAINING"]
```
[09.02.2026 06:06] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.   In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.   To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.   Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability."

[09.02.2026 06:06] Response: ```python
['REASONING', 'OPTIMIZATION', 'ALIGNMENT']
```
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces SeeUPO, a novel reinforcement learning method designed for multi-turn interactions among agents. It addresses the lack of convergence guarantees in existing RL algorithms by modeling these interactions as multi-agent bandit problems. SeeUPO employs backward induction for policy updates, ensuring that the learning process leads to optimal solutions while maintaining stability. Experimental results show that SeeUPO significantly outperforms traditional RL methods, achieving higher performance and better training consistency.","title":"SeeUPO: Ensuring Convergence in Multi-Turn Reinforcement Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces SeeUPO, a novel reinforcement learning method designed for multi-turn interactions among agents. It addresses the lack of convergence guarantees in existing RL algorithms by modeling these interactions as multi-agent bandit problems. SeeUPO employs backward induction for policy updates, ensuring that the learning process leads to optimal solutions while maintaining stability. Experimental results show that SeeUPO significantly outperforms traditional RL methods, achieving higher performance and better training consistency.', title='SeeUPO: Ensuring Convergence in Multi-Turn Reinforcement Learning'))
[09.02.2026 06:06] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SeeUPO是一种无评论的强化学习方法，旨在确保多轮代理交互中的收敛性。它将顺序决策建模为多智能体赌博问题，并通过反向推导进行策略更新。研究表明，传统的强化学习算法在多轮场景中无法同时实现无评论和收敛保证。SeeUPO通过逐轮的反向执行顺序策略更新，确保了单调改进和全局最优解的收敛。","title":"SeeUPO：多轮交互中的无评论强化学习新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SeeUPO是一种无评论的强化学习方法，旨在确保多轮代理交互中的收敛性。它将顺序决策建模为多智能体赌博问题，并通过反向推导进行策略更新。研究表明，传统的强化学习算法在多轮场景中无法同时实现无评论和收敛保证。SeeUPO通过逐轮的反向执行顺序策略更新，确保了单调改进和全局最优解的收敛。', title='SeeUPO：多轮交互中的无评论强化学习新方法'))
[09.02.2026 06:06] Using data from previous issue: {"categories": ["#transfer_learning", "#small_models", "#training"], "emoji": "🧹", "ru": {"title": "Очистка знаний для эффективной дистилляции из многих учителей", "desc": "В работе предлагается метод очистки знаний для трансферного обучения между большими языковыми моделями и более компактными моде
[09.02.2026 06:06] Renaming data file.
[09.02.2026 06:06] Renaming previous data. hf_papers.json to ./d/2026-02-09.json
[09.02.2026 06:06] Saving new data file.
[09.02.2026 06:06] Generating page.
[09.02.2026 06:06] Renaming previous page.
[09.02.2026 06:06] Renaming previous data. index.html to ./d/2026-02-09.html
[09.02.2026 06:06] Writing result.
[09.02.2026 06:06] Renaming log file.
[09.02.2026 06:06] Renaming previous data. log.txt to ./logs/2026-02-09_last_log.txt
