[25.03.2025 05:13] Read previous papers.
[25.03.2025 05:13] Generating top page (month).
[25.03.2025 05:13] Writing top page (month).
[25.03.2025 06:15] Read previous papers.
[25.03.2025 06:15] Get feed.
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17359
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18942
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18892
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18940
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17489
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18945
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18923
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17439
[25.03.2025 06:15] Extract page data from URL. URL: https://huggingface.co/papers/2503.15879
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18013
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18908
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18866
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.14428
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18769
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18559
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17735
[25.03.2025 06:15] Extract page data from URL. URL: https://huggingface.co/papers/2503.17500
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17422
[25.03.2025 06:15] Get page data from previous paper. URL: https://huggingface.co/papers/2503.16924
[25.03.2025 06:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[25.03.2025 06:15] No deleted papers detected.
[25.03.2025 06:15] Downloading and parsing papers (pdf, html). Total: 19.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.17359.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.17359.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.17359.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18942.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18942.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18942.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18892.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18892.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18892.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18940.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18940.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18940.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.17489.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.17489.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.17489.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18945.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18945.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18945.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18923.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18923.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18923.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.17439.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.17439.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.17439.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.15879.
[25.03.2025 06:15] Downloading paper 2503.15879 from http://arxiv.org/pdf/2503.15879v2...
[25.03.2025 06:15] Extracting affiliations from text.
[25.03.2025 06:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Typed-RAG: Type-aware Multi-Aspect Decomposition for Non-Factoid Question Answering DongGeon Lee1* Ahjeong Park2 Hyeri Lee3 Hyeonseo Nam4 Yunho Maeng5, 6 1Pohang University of Science and Technology 3Independent Researcher 4KT 6LLM Experimental Lab, MODULABS 5Ewha Womans University 2Sookmyung Womens University donggeonlee@postech.ac.kr {keira.hyeri.lee, namhs2030}@gmail.com ahjeong@sookmyung.ac.kr yunhomaeng@ewha.ac.kr "
[25.03.2025 06:15] Response: ```python
[
    "Pohang University of Science and Technology",
    "Independent Researcher",
    "KT",
    "LLM Experimental Lab, MODULABS",
    "Ewha Womans University",
    "Sookmyung Womens University"
]
```
[25.03.2025 06:15] Deleting PDF ./assets/pdf/2503.15879.pdf.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18013.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18013.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18013.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18908.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18908.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18908.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18866.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18866.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18866.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.14428.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.14428.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.14428.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18769.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18769.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18769.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.18559.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.18559.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.18559.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.17735.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.17735.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.17735.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.17500.
[25.03.2025 06:15] Downloading paper 2503.17500 from http://arxiv.org/pdf/2503.17500v1...
[25.03.2025 06:15] Extracting affiliations from text.
[25.03.2025 06:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Variance Control via Weight Rescaling in LLM Pre-training Louis Owen, Abhay Kumar, Nilabhra Roy Chowdhury, Fabian GÃ¼ra BluOrion First Authors {louis.owen, abhay.kumar, nilabhra.chowdhury, fabian.guera}@bluorion.com March 21, "
[25.03.2025 06:15] Response: ```python
["BluOrion"]
```
[25.03.2025 06:15] Deleting PDF ./assets/pdf/2503.17500.pdf.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.17422.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.17422.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.17422.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Downloading and parsing paper https://huggingface.co/papers/2503.16924.
[25.03.2025 06:15] Extra JSON file exists (./assets/json/2503.16924.json), skip PDF parsing.
[25.03.2025 06:15] Paper image links file exists (./assets/img_data/2503.16924.json), skip HTML parsing.
[25.03.2025 06:15] Success.
[25.03.2025 06:15] Enriching papers with extra data.
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 0. Modern game development faces significant challenges in creativity and cost due to predetermined content in traditional game engines. Recent breakthroughs in video generation models, capable of synthesizing realistic and interactive virtual environments, present an opportunity to revolutionize game ...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 1. With the scale capability of increasing training data, model size, and computational cost, video generation has achieved impressive results in digital creation, enabling users to express creativity across various domains. Recently, researchers in Large Language Models (LLMs) have expanded the scalin...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 2. DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can naturally emerge through a simple reinforcement learning (RL) framework with rule-based rewards, where the training may directly start from the base models-a paradigm referred to as zero RL training. Most recent efforts to reproduc...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 3. Diffusion models have demonstrated remarkable capabilities in visual content generation but remain challenging to deploy due to their high computational cost during inference. This computational burden primarily arises from the quadratic complexity of self-attention with respect to image or video re...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 4. Evaluating generative foundation models on open-ended multimodal understanding (MMU) and generation (MMG) tasks across diverse modalities (e.g., images, audio, video) poses significant challenges due to the complexity of cross-modal interactions. To this end, the idea of utilizing Multimodal LLMs (M...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 5. The integration of geometric reconstruction and generative modeling remains a critical challenge in developing AI systems capable of human-like spatial reasoning. This paper proposes Aether, a unified framework that enables geometry-aware reasoning in world models by jointly optimizing three core ca...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 6. Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we introduce Video SimpleQA, the first comprehensive benchma...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 7. Large language models (LLMs) have demonstrated remarkable reasoning capability in solving mathematical problems. However, existing approaches primarily focus on improving the quality of correct training data, e.g., distilling high-quality correct solutions from advanced models, neglecting the value ...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 8. Non-factoid question-answering (NFQA) poses a significant challenge due to its open-ended nature, diverse intents, and the need for multi-aspect reasoning, which renders conventional factoid QA approaches, including retrieval-augmented generation (RAG), inadequate. Unlike factoid questions, non-fact...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 9. Large Vision-Language Models (LVLMs) typically follow a two-stage training paradigm-pretraining and supervised fine-tuning. Recently, preference optimization, derived from the language domain, has emerged as an effective post-training reinforcement strategy to enhance capabilities of LVLMs. However,...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 10. We introduce FFN Fusion, an architectural optimization technique that reduces sequential computation in large language models by identifying and exploiting natural opportunities for parallelization. Our key insight is that sequences of Feed-Forward Network (FFN) layers, particularly those remaining ...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 11. Compute scaling for language model (LM) pretraining has outpaced the growth of human-written texts, leading to concerns that data will become the bottleneck to LM scaling. To continue scaling pretraining in this data-constrained regime, we propose that explicitly modeling and inferring the latent th...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 12. Text-to-video (T2V) generation has made significant strides with diffusion models. However, existing methods still struggle with accurately binding attributes, determining spatial relationships, and capturing complex action interactions between multiple subjects. To address these limitations, we pro...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 13. This paper presents AlphaSpace, a novel methodology designed to enhance the spatial reasoning capabilities of large language models (LLMs) for 3D Cartesian space navigation. AlphaSpace employs a semantics-based tokenization strategy, encoding height information through specialized semantic tokens, a...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 14. Text-to-Video (T2V) generation has attracted significant attention for its ability to synthesize realistic videos from textual descriptions. However, existing models struggle to balance computational efficiency and high visual quality, particularly on resource-limited devices, e.g.,iGPUs and mobile ...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 15. Recently, great progress has been made in video generation technology, attracting the widespread attention of scholars. To apply this technology to downstream applications under resource-constrained conditions, researchers usually fine-tune the pre-trained models based on parameter-efficient tuning ...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 16. The outcome of Large Language Model (LLM) pre-training strongly depends on weight initialization and variance control strategies. Although the importance of initial variance control has been well documented in neural networks in general, the literature on initialization and management of its growth ...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 17. The recent exponential growth of Large Language Models (LLMs) has relied on GPU-based systems. However, CPUs are emerging as a flexible and lower-cost alternative, especially when targeting inference and reasoning workloads. RISC-V is rapidly gaining traction in this area, given its open and vendor-...
[25.03.2025 06:15] ********************************************************************************
[25.03.2025 06:15] Abstract 18. 3D Gaussian Splatting (3DGS) has emerged as a powerful representation for real-time, high-performance rendering, enabling a wide range of applications. However, representing 3D scenes with numerous explicit Gaussian primitives imposes significant storage and memory overhead. Recent studies have show...
[25.03.2025 06:15] Read previous papers.
[25.03.2025 06:15] Generating reviews via LLM API.
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#video", "#architecture", "#games", "#multimodal"], "emoji": "ð®", "ru": {"title": "Ð ÐµÐ²Ð¾Ð»ÑÑÐ¸Ñ Ð² ÑÐ°Ð·ÑÐ°Ð±Ð¾ÑÐºÐµ Ð¸Ð³Ñ: ÐÐ-Ð³ÐµÐ½ÐµÑÐ¸ÑÑÐµÐ¼ÑÐµ Ð¼Ð¸ÑÑ Ð±ÑÐ´ÑÑÐµÐ³Ð¾", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ ÐºÐ¾Ð½ÑÐµÐ¿ÑÐ¸Ñ ÐÐµÐ½ÐµÑÐ°ÑÐ¸Ð²Ð½ÑÑ ÐÐ³ÑÐ¾Ð²ÑÑ ÐÐ²Ð¸Ð¶ÐºÐ¾Ð² (GGE), Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½ÑÑ Ð½Ð° ÐÐ½ÑÐµÑÐ°ÐºÑÐ¸Ð²Ð½Ð¾Ð¹ ÐÐµÐ½ÐµÑÐ°ÑÐ¸Ð²Ð½Ð¾Ð¹ ÐÐ¸Ð´ÐµÐ¾ ÑÐµÑÐ½Ð¾Ð»Ð¾Ð³Ð¸Ð¸ (IGV). GG
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#video", "#inference", "#games", "#optimization", "#benchmark"], "emoji": "ð¥", "ru": {"title": "ÐÐ°ÑÑÑÐ°Ð±Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð²ÑÐµÐ¼ÐµÐ½Ð¸ ÑÐµÑÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ: Ð½Ð¾Ð²ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¸ÑÑÐ»ÐµÐ´ÑÐµÑ Ð¿ÑÐ¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð¼ÐµÑÐ¾Ð´Ð° Ð¼Ð°ÑÑÑÐ°Ð±Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ Ð²ÑÐµÐ¼ÐµÐ½Ð¸ ÑÐµÑÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ (TTS) Ð´Ð»Ñ ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ ÐºÐ°ÑÐµÑ
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#rl", "#training", "#small_models"], "emoji": "ð§ ", "ru": {"title": "Ð Ð°Ð·Ð²Ð¸ÑÐ¸Ðµ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ð² ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑÑ ÑÐµÑÐµÐ· RL Ñ Ð½ÑÐ»Ñ", "desc": "Ð­ÑÐ¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÑÐ²ÑÑÐµÐ½Ð¾ Ð¿ÑÐ¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ (RL) Ð±ÐµÐ· Ð¿ÑÐµÐ´Ð²Ð°ÑÐ¸ÑÐµÐ»ÑÐ½Ð¾Ð¹ Ð¿Ð¾Ð´Ð³Ð¾ÑÐ¾Ð²ÐºÐ¸ Ð´Ð»Ñ ÑÐ°Ð·Ð²Ð¸ÑÐ¸Ñ ÑÐ¿Ð¾ÑÐ¾Ð±
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#cv", "#optimization", "#diffusion", "#inference", "#video"], "emoji": "â±ï¸", "ru": {"title": "Ð£ÑÐºÐ¾ÑÐµÐ½Ð¸Ðµ Ð´Ð¸ÑÑÑÐ·Ð¸Ð¾Ð½Ð½ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð±ÐµÐ· Ð¿Ð¾ÑÐµÑÐ¸ ÐºÐ°ÑÐµÑÑÐ²Ð°", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð½Ð¾Ð²ÑÐ¹ Ð¼ÐµÑÐ¾Ð´ ÑÑÐºÐ¾ÑÐµÐ½Ð¸Ñ ÑÐ°Ð±Ð¾ÑÑ Ð´Ð¸ÑÑÑÐ·Ð¸Ð¾Ð½Ð½ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Bottleneck Sampling. Ð­ÑÐ¾Ñ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·ÑÐµÑ
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#multimodal", "#hallucinations", "#benchmark", "#alignment", "#open_source"], "emoji": "ð¤", "ru": {"title": "Ð£Ð½Ð¸Ð²ÐµÑÑÐ°Ð»ÑÐ½Ð°Ñ Ð¾ÑÐµÐ½ÐºÐ° Ð¼ÑÐ»ÑÑÐ¸Ð¼Ð¾Ð´Ð°Ð»ÑÐ½ÑÑ ÐÐ-Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: Ð¾Ñ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ðº Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð½Ð¾Ð²ÑÐµ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐºÐ¸ TaskAnything Ð¸ JudgeAnything Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ Ð¼ÑÐ»ÑÑÐ¸Ð¼Ð¾Ð´Ð°Ð»ÑÐ½
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#video", "#3d", "#reasoning", "#agents", "#synthetic"], "emoji": "ð§ ", "ru": {"title": "ÐÐ´Ð¸Ð½Ð°Ñ ÑÐ¸ÑÑÐµÐ¼Ð° Ð´Ð»Ñ Ð³ÐµÐ¾Ð¼ÐµÑÑÐ¸ÑÐµÑÐºÐ¾Ð³Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¸ÑÐ° Ð¸ Ð¿Ð»Ð°Ð½Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ Ð´ÐµÐ¹ÑÑÐ²Ð¸Ð¹", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Aether - ÑÐ½Ð¸ÑÐ¸ÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð½ÑÑ ÑÐ¸ÑÑÐµÐ¼Ñ Ð´Ð»Ñ Ð³ÐµÐ¾Ð¼ÐµÑÑÐ¸ÑÐµÑÐºÐ¸-Ð¾ÑÐ¾Ð·Ð½Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð¼Ð¾Ð´ÐµÐ»ÑÑ Ð¼Ð¸
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#video", "#interpretability", "#reasoning", "#long_context", "#multimodal", "#rag", "#benchmark"], "emoji": "ð¥", "ru": {"title": "ÐÐ¾Ð²ÑÐ¹ ÑÑÐ°Ð½Ð´Ð°ÑÑ Ð¾ÑÐµÐ½ÐºÐ¸ ÑÐ°ÐºÑÐ¸ÑÐµÑÐºÐ¾Ð¹ ÑÐ¾ÑÐ½Ð¾ÑÑÐ¸ Ð²Ð¸Ð´ÐµÐ¾-ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Video SimpleQA - Ð¿ÐµÑÐ²ÑÐ¹ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½ÑÐ¹ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ 
[25.03.2025 06:15] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#dataset", "#data"], "emoji": "ð§®", "ru": {"title": "Ð£ÑÐ¸Ð¼ÑÑ Ð½Ð° Ð¾ÑÐ¸Ð±ÐºÐ°Ñ: Ð½Ð¾Ð²ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ Ð¼Ð°ÑÐµÐ¼Ð°ÑÐ¸ÑÐµÑÐºÐ¸Ñ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑÐµÐ¹ ÐÐ", "desc": "Ð­ÑÐ° ÑÑÐ°ÑÑÑ Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ Ð¼ÐµÑÐ¾Ð´ LEMMA Ð´Ð»Ñ ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑÐ¸ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) ÑÐµÑÐ°ÑÑ Ð¼Ð°ÑÐµÐ¼Ð°ÑÐ¸ÑÐµÑ
[25.03.2025 06:15] Querying the API.
[25.03.2025 06:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Non-factoid question-answering (NFQA) poses a significant challenge due to its open-ended nature, diverse intents, and the need for multi-aspect reasoning, which renders conventional factoid QA approaches, including retrieval-augmented generation (RAG), inadequate. Unlike factoid questions, non-factoid questions (NFQs) lack definitive answers and require synthesizing information from multiple sources across various reasoning dimensions. To address these limitations, we introduce Typed-RAG, a type-aware multi-aspect decomposition framework within the RAG paradigm for NFQA. Typed-RAG classifies NFQs into distinct types -- such as debate, experience, and comparison -- and applies aspect-based decomposition to refine retrieval and generation strategies. By decomposing multi-aspect NFQs into single-aspect sub-queries and aggregating the results, Typed-RAG generates more informative and contextually relevant responses. To evaluate Typed-RAG, we introduce Wiki-NFQA, a benchmark dataset covering diverse NFQ types. Experimental results demonstrate that Typed-RAG outperforms baselines, thereby highlighting the importance of type-aware decomposition for effective retrieval and generation in NFQA. Our code and dataset are available at https://github.com/TeamNLP/Typed-RAG{https://github.com/TeamNLP/Typed-RAG}.
[25.03.2025 06:16] Response: {
  "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð½Ð¾Ð²ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº Ð¾ÑÐ²ÐµÑÐ°Ð¼ Ð½Ð° Ð½ÐµÑÐ°ÐºÑÐ¾Ð¸Ð´Ð½ÑÐµ Ð²Ð¾Ð¿ÑÐ¾ÑÑ (NFQA) Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Typed-RAG. Ð­ÑÐ¾Ñ Ð¼ÐµÑÐ¾Ð´ ÐºÐ»Ð°ÑÑÐ¸ÑÐ¸ÑÐ¸ÑÑÐµÑ Ð²Ð¾Ð¿ÑÐ¾ÑÑ Ð¿Ð¾ ÑÐ¸Ð¿Ð°Ð¼ Ð¸ Ð¿ÑÐ¸Ð¼ÐµÐ½ÑÐµÑ Ð´ÐµÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸ÑÐ¸Ñ Ð½Ð° Ð°ÑÐ¿ÐµÐºÑÑ Ð´Ð»Ñ ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ ÑÑÑÐ°ÑÐµÐ³Ð¸Ð¹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð¾ÑÐ²ÐµÑÐ¾Ð². ÐÐ²ÑÐ¾ÑÑ ÑÐ°ÐºÐ¶Ðµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÑÑ Ð½Ð¾Ð²ÑÐ¹ Ð½Ð°Ð±Ð¾Ñ Ð´Ð°Ð½Ð½ÑÑ Wiki-NFQA Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾ÑÑÐ¸ Typed-RAG. Ð­ÐºÑÐ¿ÐµÑÐ¸Ð¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÐµ ÑÐµÐ·ÑÐ»ÑÑÐ°ÑÑ Ð¿Ð¾ÐºÐ°Ð·ÑÐ²Ð°ÑÑ, ÑÑÐ¾ Typed-RAG Ð¿ÑÐµÐ²Ð¾ÑÑÐ¾Ð´Ð¸Ñ Ð±Ð°Ð·Ð¾Ð²ÑÐµ Ð¼ÐµÑÐ¾Ð´Ñ Ð² Ð·Ð°Ð´Ð°ÑÐµ NFQA.",
  "emoji": "ð§ ",
  "title": "Typed-RAG: ÑÐ¼Ð½Ð¾Ðµ ÑÐ°Ð·Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð²Ð¾Ð¿ÑÐ¾ÑÐ¾Ð² Ð´Ð»Ñ Ð»ÑÑÑÐ¸Ñ Ð¾ÑÐ²ÐµÑÐ¾Ð²"
}
[25.03.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Non-factoid question-answering (NFQA) poses a significant challenge due to its open-ended nature, diverse intents, and the need for multi-aspect reasoning, which renders conventional factoid QA approaches, including retrieval-augmented generation (RAG), inadequate. Unlike factoid questions, non-factoid questions (NFQs) lack definitive answers and require synthesizing information from multiple sources across various reasoning dimensions. To address these limitations, we introduce Typed-RAG, a type-aware multi-aspect decomposition framework within the RAG paradigm for NFQA. Typed-RAG classifies NFQs into distinct types -- such as debate, experience, and comparison -- and applies aspect-based decomposition to refine retrieval and generation strategies. By decomposing multi-aspect NFQs into single-aspect sub-queries and aggregating the results, Typed-RAG generates more informative and contextually relevant responses. To evaluate Typed-RAG, we introduce Wiki-NFQA, a benchmark dataset covering diverse NFQ types. Experimental results demonstrate that Typed-RAG outperforms baselines, thereby highlighting the importance of type-aware decomposition for effective retrieval and generation in NFQA. Our code and dataset are available at https://github.com/TeamNLP/Typed-RAG{https://github.com/TeamNLP/Typed-RAG}."

[25.03.2025 06:16] Response: ```python
['RAG', 'DATASET', 'BENCHMARK']
```
[25.03.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Non-factoid question-answering (NFQA) poses a significant challenge due to its open-ended nature, diverse intents, and the need for multi-aspect reasoning, which renders conventional factoid QA approaches, including retrieval-augmented generation (RAG), inadequate. Unlike factoid questions, non-factoid questions (NFQs) lack definitive answers and require synthesizing information from multiple sources across various reasoning dimensions. To address these limitations, we introduce Typed-RAG, a type-aware multi-aspect decomposition framework within the RAG paradigm for NFQA. Typed-RAG classifies NFQs into distinct types -- such as debate, experience, and comparison -- and applies aspect-based decomposition to refine retrieval and generation strategies. By decomposing multi-aspect NFQs into single-aspect sub-queries and aggregating the results, Typed-RAG generates more informative and contextually relevant responses. To evaluate Typed-RAG, we introduce Wiki-NFQA, a benchmark dataset covering diverse NFQ types. Experimental results demonstrate that Typed-RAG outperforms baselines, thereby highlighting the importance of type-aware decomposition for effective retrieval and generation in NFQA. Our code and dataset are available at https://github.com/TeamNLP/Typed-RAG{https://github.com/TeamNLP/Typed-RAG}."

[25.03.2025 06:16] Response: ```python
["REASONING", "OPTIMIZATION", "OPEN_SOURCE"]
```
[25.03.2025 06:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenges of non-factoid question-answering (NFQA), which involves questions that do not have straightforward answers and require complex reasoning. The authors propose a new framework called Typed-RAG, which enhances the retrieval-augmented generation (RAG) approach by classifying NFQs into specific types and breaking them down into simpler sub-queries. By focusing on individual aspects of the questions, Typed-RAG improves the quality of the generated responses, making them more relevant and informative. The effectiveness of this method is validated through a new benchmark dataset, Wiki-NFQA, showing that type-aware decomposition significantly boosts performance in NFQA tasks.","title":"Typed-RAG: Enhancing NFQA with Type-Aware Decomposition"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenges of non-factoid question-answering (NFQA), which involves questions that do not have straightforward answers and require complex reasoning. The authors propose a new framework called Typed-RAG, which enhances the retrieval-augmented generation (RAG) approach by classifying NFQs into specific types and breaking them down into simpler sub-queries. By focusing on individual aspects of the questions, Typed-RAG improves the quality of the generated responses, making them more relevant and informative. The effectiveness of this method is validated through a new benchmark dataset, Wiki-NFQA, showing that type-aware decomposition significantly boosts performance in NFQA tasks.', title='Typed-RAG: Enhancing NFQA with Type-Aware Decomposition'))
[25.03.2025 06:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"éäºå®é®ç­ï¼NFQAï¼å å¶å¼æ¾æ§ãå¤æ ·åçæå¾åå¤æ¹é¢æ¨ççéæ±èé¢ä¸´éå¤§ææï¼ä¼ ç»çäºå®é®ç­æ¹æ³ï¼å¦æ£ç´¢å¢å¼ºçæRAGï¼æ æ³æ»¡è¶³è¿äºéæ±ãä¸äºå®é®é¢ä¸åï¼éäºå®é®é¢ï¼NFQï¼æ²¡ææç¡®çç­æ¡ï¼éè¦ä»å¤ä¸ªæ¥æºç»¼åä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºTyped-RAGï¼è¿æ¯ä¸ç§å¨RAGèå¼ä¸çç±»åæç¥å¤æ¹é¢åè§£æ¡æ¶ãTyped-RAGå°NFQåç±»ä¸ºä¸åç±»åï¼å¹¶éè¿åºäºæ¹é¢çåè§£æ¥ä¼åæ£ç´¢åçæç­ç¥ï¼ä»èçææ´å·ä¿¡æ¯éåä¸ä¸æç¸å³çåç­ã","title":"ç±»åæç¥ï¼æåéäºå®é®ç­çææ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='éäºå®é®ç­ï¼NFQAï¼å å¶å¼æ¾æ§ãå¤æ ·åçæå¾åå¤æ¹é¢æ¨ççéæ±èé¢ä¸´éå¤§ææï¼ä¼ ç»çäºå®é®ç­æ¹æ³ï¼å¦æ£ç´¢å¢å¼ºçæRAGï¼æ æ³æ»¡è¶³è¿äºéæ±ãä¸äºå®é®é¢ä¸åï¼éäºå®é®é¢ï¼NFQï¼æ²¡ææç¡®çç­æ¡ï¼éè¦ä»å¤ä¸ªæ¥æºç»¼åä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºTyped-RAGï¼è¿æ¯ä¸ç§å¨RAGèå¼ä¸çç±»åæç¥å¤æ¹é¢åè§£æ¡æ¶ãTyped-RAGå°NFQåç±»ä¸ºä¸åç±»åï¼å¹¶éè¿åºäºæ¹é¢çåè§£æ¥ä¼åæ£ç´¢åçæç­ç¥ï¼ä»èçææ´å·ä¿¡æ¯éåä¸ä¸æç¸å³çåç­ã', title='ç±»åæç¥ï¼æåéäºå®é®ç­çææ'))
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training", "#benchmark", "#rlhf"], "emoji": "ðï¸", "ru": {"title": "Vision-R1: Ð ÐµÐ²Ð¾Ð»ÑÑÐ¸Ñ Ð² Ð¾Ð±ÑÑÐµÐ½Ð¸Ð¸ Ð²Ð¸Ð·ÑÐ°Ð»ÑÐ½Ð¾-ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð±ÐµÐ· ÑÑÑÐ½Ð¾Ð¹ ÑÐ°Ð·Ð¼ÐµÑÐºÐ¸", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½ Ð½Ð¾Ð²ÑÐ¹ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ ÐºÑÑÐ¿Ð½ÑÑ Ð²Ð¸Ð·ÑÐ°Ð»ÑÐ½Ð¾-ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#inference"], "emoji": "ð", "ru": {"title": "Ð£ÑÐºÐ¾ÑÐµÐ½Ð¸Ðµ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÑÐµÑÐµÐ· Ð¿Ð°ÑÐ°Ð»Ð»ÐµÐ»Ð¸Ð·Ð°ÑÐ¸Ñ FFN ÑÐ»Ð¾ÐµÐ²", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ ÑÐµÑÐ½Ð¸ÐºÑ Ð¾Ð¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÑ Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ FFN Fusion, ÐºÐ¾ÑÐ¾ÑÐ°Ñ ÑÐ¾ÐºÑÐ°ÑÐ°ÐµÑ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»ÑÐ½ÑÐµ Ð²
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#training", "#transfer_learning", "#synthetic", "#data", "#math"], "emoji": "ð§ ", "ru": {"title": "Ð Ð°ÑÐºÑÑÑÐ¸Ðµ ÑÐºÑÑÑÑÑ Ð¼ÑÑÐ»ÐµÐ¹ Ð´Ð»Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ Ð¼ÐµÑÐ¾Ð´ Ð¿Ð¾Ð²ÑÑÐµÐ½Ð¸Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾ÑÑÐ¸ Ð¿ÑÐµÐ´Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð² ÑÑÐ»Ð¾Ð²Ð¸ÑÑ 
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#training", "#multimodal", "#architecture", "#games", "#diffusion", "#video"], "emoji": "ð¬", "ru": {"title": "MagicComp: Ð£ÑÐ¾Ð²ÐµÑÑÐµÐ½ÑÑÐ²Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ ÑÐµÐºÑÑÑ Ð±ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸ÑÐµÐ»ÑÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ", "desc": "MagicComp - ÑÑÐ¾ Ð¼ÐµÑÐ¾Ð´ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ ÑÐµÐºÑÑÑ, Ð½Ðµ ÑÑÐµÐ±ÑÑÑÐ¸Ð¹ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸ÑÐµÐ»ÑÐ½Ð¾Ð³
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#architecture", "#synthetic", "#reasoning", "#3d"], "emoji": "ð§ ", "ru": {"title": "AlphaSpace: ÐÑÐ¾ÑÑÐ² Ð² Ð¿ÑÐ¾ÑÑÑÐ°Ð½ÑÑÐ²ÐµÐ½Ð½Ð¾Ð¼ Ð¼ÑÑÐ»ÐµÐ½Ð¸Ð¸ ÐÐ", "desc": "AlphaSpace - ÑÑÐ¾ Ð½Ð¾Ð²Ð°Ñ Ð¼ÐµÑÐ¾Ð´Ð¾Ð»Ð¾Ð³Ð¸Ñ, ÑÐ°Ð·ÑÐ°Ð±Ð¾ÑÐ°Ð½Ð½Ð°Ñ Ð´Ð»Ñ ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ Ð¿ÑÐ¾ÑÑÑÐ°Ð½ÑÑÐ²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¼ÑÑÐ»ÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ð² Ð½Ð°Ð²Ð¸Ð³Ð°ÑÐ¸Ð¸ Ð¿Ð¾ 3D
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#long_context", "#video", "#optimization", "#open_source", "#training", "#small_models", "#data"], "emoji": "ð¦", "ru": {"title": "Ð­ÑÑÐµÐºÑÐ¸Ð²Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ ÑÐµÐºÑÑÑ Ð´Ð»Ñ Ð¼Ð¾Ð±Ð¸Ð»ÑÐ½ÑÑ ÑÑÑÑÐ¾Ð¹ÑÑÐ²", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð»ÐµÐ³ÐºÐ¾Ð²ÐµÑÐ½ÑÑ Ð¼Ð¾Ð´ÐµÐ»Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ ÑÐµÐºÑÑÑ Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ H
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#video", "#dataset", "#optimization", "#training", "#transfer_learning"], "emoji": "ð¬", "ru": {"title": "Ð­ÑÑÐµÐºÑÐ¸Ð²Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð½ÑÐ»Ñ Ð²Ð¼ÐµÑÑÐ¾ ÑÐ¾Ð½ÐºÐ¾Ð¹ Ð½Ð°ÑÑÑÐ¾Ð¹ÐºÐ¸ Ð±Ð¾Ð»ÑÑÐ¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð½Ð¾Ð²ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð² ÑÑÐ»Ð¾Ð²Ð¸ÑÑ Ð¾Ð³ÑÐ°Ð½Ð¸ÑÐµÐ½Ð½ÑÑ ÑÐµÑÑÑÑÐ¾Ð². ÐÐ²ÑÐ¾ÑÑ 
[25.03.2025 06:16] Querying the API.
[25.03.2025 06:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The outcome of Large Language Model (LLM) pre-training strongly depends on weight initialization and variance control strategies. Although the importance of initial variance control has been well documented in neural networks in general, the literature on initialization and management of its growth during LLM pre-training, specifically, is somewhat sparse. In this paper, we introduce the Layer Index Rescaling (LIR) weight initialization scheme, and the Target Variance Rescaling (TVR) variance control strategy. Experiments on a 1B parameter LLaMA model demonstrate that better variance management using these techniques yields substantial improvements in downstream task performance (up to 4.6% on common pre-training benchmarks) and reduces extreme activation values, thus mitigating challenges associated with quantization and low-precision training. Our code is available at: https://github.com/bluorion-com/weight_rescaling.
[25.03.2025 06:16] Response: {
  "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð½Ð¾Ð²ÑÐµ Ð¼ÐµÑÐ¾Ð´Ñ Ð¸Ð½Ð¸ÑÐ¸Ð°Ð»Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð²ÐµÑÐ¾Ð² Ð¸ ÐºÐ¾Ð½ÑÑÐ¾Ð»Ñ Ð´Ð¸ÑÐ¿ÐµÑÑÐ¸Ð¸ Ð´Ð»Ñ Ð¿ÑÐµÐ´Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM). ÐÐ²ÑÐ¾ÑÑ Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÑÑ ÑÑÐµÐ¼Ñ Ð¸Ð½Ð¸ÑÐ¸Ð°Ð»Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð²ÐµÑÐ¾Ð² Layer Index Rescaling (LIR) Ð¸ ÑÑÑÐ°ÑÐµÐ³Ð¸Ñ ÐºÐ¾Ð½ÑÑÐ¾Ð»Ñ Ð´Ð¸ÑÐ¿ÐµÑÑÐ¸Ð¸ Target Variance Rescaling (TVR). Ð­ÐºÑÐ¿ÐµÑÐ¸Ð¼ÐµÐ½ÑÑ Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸ LLaMA Ñ 1 Ð¼Ð»ÑÐ´ Ð¿Ð°ÑÐ°Ð¼ÐµÑÑÐ¾Ð² Ð¿Ð¾ÐºÐ°Ð·ÑÐ²Ð°ÑÑ, ÑÑÐ¾ ÑÑÐ¸ ÑÐµÑÐ½Ð¸ÐºÐ¸ ÑÐ»ÑÑÑÐ°ÑÑ Ð¿ÑÐ¾Ð¸Ð·Ð²Ð¾Ð´Ð¸ÑÐµÐ»ÑÐ½Ð¾ÑÑÑ Ð½Ð° ÑÐµÐ»ÐµÐ²ÑÑ Ð·Ð°Ð´Ð°ÑÐ°Ñ Ð¸ ÑÐ¼ÐµÐ½ÑÑÐ°ÑÑ ÑÐºÑÑÑÐµÐ¼Ð°Ð»ÑÐ½ÑÐµ Ð·Ð½Ð°ÑÐµÐ½Ð¸Ñ Ð°ÐºÑÐ¸Ð²Ð°ÑÐ¸Ð¹. Ð ÐµÐ·ÑÐ»ÑÑÐ°ÑÑ Ð´ÐµÐ¼Ð¾Ð½ÑÑÑÐ¸ÑÑÑÑ Ð²Ð°Ð¶Ð½Ð¾ÑÑÑ Ð¿ÑÐ°Ð²Ð¸Ð»ÑÐ½Ð¾Ð³Ð¾ ÑÐ¿ÑÐ°Ð²Ð»ÐµÐ½Ð¸Ñ Ð´Ð¸ÑÐ¿ÐµÑÑÐ¸ÐµÐ¹ Ð¿ÑÐ¸ Ð¾Ð±ÑÑÐµÐ½Ð¸Ð¸ LLM.",
  "emoji": "âï¸",
  "title": "Ð¢Ð¾ÑÐ½Ð°Ñ Ð½Ð°ÑÑÑÐ¾Ð¹ÐºÐ° Ð²ÐµÑÐ¾Ð² - ÐºÐ»ÑÑ Ðº ÑÑÑÐµÐºÑÐ¸Ð²Ð½ÑÐ¼ ÑÐ·ÑÐºÐ¾Ð²ÑÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼"
}
[25.03.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The outcome of Large Language Model (LLM) pre-training strongly depends on weight initialization and variance control strategies. Although the importance of initial variance control has been well documented in neural networks in general, the literature on initialization and management of its growth during LLM pre-training, specifically, is somewhat sparse. In this paper, we introduce the Layer Index Rescaling (LIR) weight initialization scheme, and the Target Variance Rescaling (TVR) variance control strategy. Experiments on a 1B parameter LLaMA model demonstrate that better variance management using these techniques yields substantial improvements in downstream task performance (up to 4.6% on common pre-training benchmarks) and reduces extreme activation values, thus mitigating challenges associated with quantization and low-precision training. Our code is available at: https://github.com/bluorion-com/weight_rescaling."

[25.03.2025 06:16] Response: ```python
["TRAINING", "INFERENCE", "BENCHMARK", "ARCHITECTURE"]
```
[25.03.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The outcome of Large Language Model (LLM) pre-training strongly depends on weight initialization and variance control strategies. Although the importance of initial variance control has been well documented in neural networks in general, the literature on initialization and management of its growth during LLM pre-training, specifically, is somewhat sparse. In this paper, we introduce the Layer Index Rescaling (LIR) weight initialization scheme, and the Target Variance Rescaling (TVR) variance control strategy. Experiments on a 1B parameter LLaMA model demonstrate that better variance management using these techniques yields substantial improvements in downstream task performance (up to 4.6% on common pre-training benchmarks) and reduces extreme activation values, thus mitigating challenges associated with quantization and low-precision training. Our code is available at: https://github.com/bluorion-com/weight_rescaling."

[25.03.2025 06:16] Response: ```python
["OPTIMIZATION"]
```
[25.03.2025 06:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses how the performance of Large Language Models (LLMs) during pre-training is influenced by how their weights are initialized and how variance is controlled. It introduces two new techniques: Layer Index Rescaling (LIR) for weight initialization and Target Variance Rescaling (TVR) for managing variance growth. The authors show that applying these methods to a 1B parameter LLaMA model leads to significant improvements in performance on various tasks, achieving up to a 4.6% increase on standard benchmarks. Additionally, these techniques help reduce extreme activation values, which can complicate quantization and low-precision training.","title":"Enhancing LLM Performance through Innovative Weight and Variance Management"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses how the performance of Large Language Models (LLMs) during pre-training is influenced by how their weights are initialized and how variance is controlled. It introduces two new techniques: Layer Index Rescaling (LIR) for weight initialization and Target Variance Rescaling (TVR) for managing variance growth. The authors show that applying these methods to a 1B parameter LLaMA model leads to significant improvements in performance on various tasks, achieving up to a 4.6% increase on standard benchmarks. Additionally, these techniques help reduce extreme activation values, which can complicate quantization and low-precision training.', title='Enhancing LLM Performance through Innovative Weight and Variance Management'))
[25.03.2025 06:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æ¬è®ºææ¢è®¨äºå¤§åè¯­è¨æ¨¡åï¼LLMï¼é¢è®­ç»ä¸­æéåå§ååæ¹å·®æ§å¶ç­ç¥çéè¦æ§ãæä»¬æåºäºä¸ç§æ°çæéåå§åæ¹æ¡ï¼ç§°ä¸ºå±ç´¢å¼éç¼©æ¾ï¼LIRï¼ï¼ä»¥åç®æ æ¹å·®éç¼©æ¾ï¼TVRï¼æ¹å·®æ§å¶ç­ç¥ãå®éªè¡¨æï¼ä½¿ç¨è¿äºææ¯è¿è¡æ´å¥½çæ¹å·®ç®¡çå¯ä»¥æ¾èæé«ä¸æ¸¸ä»»å¡çæ§è½ï¼æé«å¯è¾¾4.6%çæåï¼å¹¶åå°æç«¯æ¿æ´»å¼ï¼ä»èç¼è§£éååä½ç²¾åº¦è®­ç»å¸¦æ¥çææãæä»¬çä»£ç å·²å¨GitHubä¸åå¸ï¼ä¾ç ç©¶äººåä½¿ç¨ã","title":"ä¼åå¤§åè¯­è¨æ¨¡åçé¢è®­ç»æ§è½"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='æ¬è®ºææ¢è®¨äºå¤§åè¯­è¨æ¨¡åï¼LLMï¼é¢è®­ç»ä¸­æéåå§ååæ¹å·®æ§å¶ç­ç¥çéè¦æ§ãæä»¬æåºäºä¸ç§æ°çæéåå§åæ¹æ¡ï¼ç§°ä¸ºå±ç´¢å¼éç¼©æ¾ï¼LIRï¼ï¼ä»¥åç®æ æ¹å·®éç¼©æ¾ï¼TVRï¼æ¹å·®æ§å¶ç­ç¥ãå®éªè¡¨æï¼ä½¿ç¨è¿äºææ¯è¿è¡æ´å¥½çæ¹å·®ç®¡çå¯ä»¥æ¾èæé«ä¸æ¸¸ä»»å¡çæ§è½ï¼æé«å¯è¾¾4.6%çæåï¼å¹¶åå°æç«¯æ¿æ´»å¼ï¼ä»èç¼è§£éååä½ç²¾åº¦è®­ç»å¸¦æ¥çææãæä»¬çä»£ç å·²å¨GitHubä¸åå¸ï¼ä¾ç ç©¶äººåä½¿ç¨ã', title='ä¼åå¤§åè¯­è¨æ¨¡åçé¢è®­ç»æ§è½'))
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#reasoning", "#inference"], "emoji": "ð", "ru": {"title": "Ð£ÑÐºÐ¾ÑÐµÐ½Ð¸Ðµ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð½Ð° RISC-V Ð¿ÑÐ¾ÑÐµÑÑÐ¾ÑÐ°Ñ", "desc": "ÐÐ°Ð½Ð½Ð°Ñ ÑÑÐ°ÑÑÑ Ð¿Ð¾ÑÐ²ÑÑÐµÐ½Ð° Ð¾Ð¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð¸Ð½ÑÐµÑÐµÐ½ÑÐ° Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ð½Ð° Ð¿ÑÐ¾ÑÐµÑÑÐ¾ÑÐ°Ñ RISC-V, Ð² ÑÐ°ÑÑÐ½Ð¾ÑÑÐ¸ Ð½Ð° Sophon SG2042. 
[25.03.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#3d", "#inference", "#open_source"], "emoji": "ð¨", "ru": {"title": "OMG: ÐÐ¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ñ 3D Gaussian Splatting Ð´Ð»Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ ÑÐµÐ½Ð´ÐµÑÐ¸Ð½Ð³Ð°", "desc": "Ð ÑÑÐ¾Ð¹ ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½ Ð¼ÐµÑÐ¾Ð´ Optimized Minimal Gaussians (OMG) Ð´Ð»Ñ Ð¾Ð¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ð¸ 3D Gaussian Splatting. OMG Ð·Ð½Ð°ÑÐ¸ÑÐµÐ»ÑÐ½Ð¾
[25.03.2025 06:16] Loading Chinese text from previous data.
[25.03.2025 06:16] Renaming data file.
[25.03.2025 06:16] Renaming previous data. hf_papers.json to ./d/2025-03-25.json
[25.03.2025 06:16] Saving new data file.
[25.03.2025 06:16] Generating page.
[25.03.2025 06:16] Renaming previous page.
[25.03.2025 06:16] Renaming previous data. index.html to ./d/2025-03-25.html
[25.03.2025 06:16] [Experimental] Generating Chinese page for reading.
[25.03.2025 06:16] Chinese vocab [{'word': 'å¤æ¨¡æ', 'pinyin': 'duÅ mÃ³ tÃ i', 'trans': 'multimodal'}, {'word': 'ç§å­¦é®é¢', 'pinyin': 'kÄ xuÃ© wÃ¨n tÃ­', 'trans': 'scientific problems'}, {'word': 'ææ', 'pinyin': 'tiÇo zhÃ n', 'trans': 'challenges'}, {'word': 'æ´å', 'pinyin': 'zhÄng hÃ©', 'trans': 'integrate'}, {'word': 'æ¨¡æ', 'pinyin': 'mÃ³ tÃ i', 'trans': 'modality'}, {'word': 'ææ¬', 'pinyin': 'wÃ©n bÄn', 'trans': 'text'}, {'word': 'å¾è¡¨', 'pinyin': 'tÃº biÇo', 'trans': 'charts'}, {'word': 'é¢ä¸´', 'pinyin': 'miÃ n lÃ­n', 'trans': 'face'}, {'word': 'æ¨ç', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'}, {'word': 'åæ', 'pinyin': 'fÇn sÄ«', 'trans': 'reflection'}, {'word': 'è½å', 'pinyin': 'nÃ©ng lÃ¬', 'trans': 'ability'}, {'word': 'æåº', 'pinyin': 'tÃ­ chÅ«', 'trans': 'propose'}, {'word': 'åºäº', 'pinyin': 'jÄ« yÃº', 'trans': 'based on'}, {'word': 'å¤§ä¸äººæ ¼', 'pinyin': 'dÃ  qÄ« rÃ©n gÃ©', 'trans': 'Big Five personality traits'}, {'word': 'èæ ¼æåº', 'pinyin': 'sÅ« gÃ© lÄ dÇ', 'trans': 'Socrates'}, {'word': 'æå¯¼', 'pinyin': 'zhÇ dÇo', 'trans': 'guidance'}, {'word': 'æ¡æ¶', 'pinyin': 'kuÃ ng jiÃ ', 'trans': 'framework'}, {'word': 'å®éª', 'pinyin': 'shÃ­ yÃ n', 'trans': 'experiment'}, {'word': 'ç»æ', 'pinyin': 'jiÃ© guÇ', 'trans': 'results'}, {'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'}, {'word': 'åºè²', 'pinyin': 'chÅ« sÃ¨', 'trans': 'outstanding'}, {'word': 'è¶è¶', 'pinyin': 'chÄo yuÃ¨', 'trans': 'surpass'}, {'word': 'ç°æ', 'pinyin': 'xiÃ n yÇu', 'trans': 'existing'}, {'word': 'æä½³', 'pinyin': 'zuÃ¬ jiÄ', 'trans': 'best'}, {'word': 'æ¨¡å', 'pinyin': 'mÃ³ xÃ­ng', 'trans': 'model'}]
[25.03.2025 06:16] Renaming previous Chinese page.
[25.03.2025 06:16] Renaming previous data. zh.html to ./d/2025-03-24_zh_reading_task.html
[25.03.2025 06:16] Writing Chinese reading task.
[25.03.2025 06:16] Writing result.
[25.03.2025 06:16] Renaming log file.
[25.03.2025 06:16] Renaming previous data. log.txt to ./logs/2025-03-25_last_log.txt
