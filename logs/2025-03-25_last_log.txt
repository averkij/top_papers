[25.03.2025 06:16] Read previous papers.
[25.03.2025 06:16] Generating top page (month).
[25.03.2025 06:16] Writing top page (month).
[25.03.2025 07:11] Read previous papers.
[25.03.2025 07:11] Get feed.
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17359
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18942
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18892
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18940
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17489
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18945
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18923
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17439
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.15879
[25.03.2025 07:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.18102
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18908
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18866
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18013
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.14428
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18769
[25.03.2025 07:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.18813
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.18559
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17735
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17500
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17422
[25.03.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.16924
[25.03.2025 07:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[25.03.2025 07:11] No deleted papers detected.
[25.03.2025 07:11] Downloading and parsing papers (pdf, html). Total: 21.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.17359.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.17359.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.17359.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18942.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18942.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18942.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18892.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18892.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18892.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18940.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18940.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18940.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.17489.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.17489.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.17489.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18945.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18945.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18945.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18923.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18923.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18923.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.17439.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.17439.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.17439.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.15879.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.15879.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.15879.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18102.
[25.03.2025 07:11] Downloading paper 2503.18102 from http://arxiv.org/pdf/2503.18102v1...
[25.03.2025 07:11] Extracting affiliations from text.
[25.03.2025 07:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2025-3-25 AgentRxiv: Towards Collaborative Autonomous Research Samuel Schmidgall1 and Michael Moor2 1Department of Electrical & Computer Engineering, Johns Hopkins University, 2Department of Biosystems Science & Engineering, ETH Zurich Progress in scientific discovery is rarely the result of single "Eureka" moment, but is rather the product of hundreds of scientists incrementally working together toward common goal. While existing agent workflows are capable of producing research autonomously, they do so in isolation, without the ability to continuously improve upon prior research results. To address these challenges, we introduce AgentRxiva framework that lets LLM agent laboratories upload and retrieve reports from shared preprint server in order to collaborate, share insights, and iteratively build on each others research. We task agent laboratories to develop new reasoning and prompting techniques and find that agents with access to their prior research achieve higher performance improvements compared to agents operating in isolation (11.4% relative improvement over baseline on MATH-500). We find that the best performing strategy generalizes to benchmarks in other domains (improving on average by 3.3%). Multiple agent laboratories sharing research through AgentRxiv are able to work together towards common goal, progressing more rapidly than isolated laboratories, achieving higher overall accuracy (13.7% relative improvement over baseline on MATH-500). These findings suggest that autonomous agents may play role in designing future AI systems alongside humans. We hope that AgentRxiv allows agents to collaborate toward research goals and enables researchers to accelerate discovery. AgentRxiv.github.io 5 2 0 M 3 2 ] . [ 1 2 0 1 8 1 . 3 0 5 2 : r Figure 1 Collaborative Autonomous Research via AgentRxiv. Autonomous agent laboratories distributed collaboratively pursue shared research goal using AgentRxiv. Human researchers provide initial guidance through research dire"
[25.03.2025 07:11] Response: ```python
[
    "Department of Electrical & Computer Engineering, Johns Hopkins University",
    "Department of Biosystems Science & Engineering, ETH Zurich"
]
```
[25.03.2025 07:11] Deleting PDF ./assets/pdf/2503.18102.pdf.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18908.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18908.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18908.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18866.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18866.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18866.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18013.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18013.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18013.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.14428.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.14428.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.14428.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18769.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18769.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18769.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18813.
[25.03.2025 07:11] Downloading paper 2503.18813 from http://arxiv.org/pdf/2503.18813v1...
[25.03.2025 07:11] Extracting affiliations from text.
[25.03.2025 07:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Edoardo Debenedetti1,3*, Ilia Shumailov2, Tianqi Fan1, Jamie Hayes2, Nicholas Carlini2, Daniel Fabian1, Christoph Kern1, Chongyang Shi2, Andreas Terzis2 and Florian Tramèr3 1Google, 2Google DeepMind, 3ETH Zurich 5 2 0 2 4 2 ] . [ 1 3 1 8 8 1 . 3 0 5 2 : r Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an external environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, robust defense that creates protective system layer around the LLM, securing it even when underlying models may be susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL relies on notion of capability to prevent the exfiltration of private data over unauthorized data flows. We demonstrate effectiveness of CaMeL by solving 67% of tasks with provable security in AgentDojo [NeurIPS 2024], recent agentic security benchmark. 1. Introduction Large Language Models (LLMs) are increasingly used as the core of modern agentic systems (Wooldridge and Jennings, 1995) interacting with external environments via APIs and user interfaces (Nakano et al., 2021; Thoppilan et al., 2022; Schick et al., 2023; Yao et al., 2022; Qin et al., 2023; Lu et al., 2024; Gao et al., 2023; Shen et al., 2024). This exposes them to prompt injection attacks (Goodside, 2022; Perez and Ribeiro, 2022; Greshake et al., 2023) when data or instructions come from untrusted sources (e.g., from compromised user, from tool call outputs, or from web page). In these attacks, adversaries insert malicious instructions into the LLMs context, aiming to exfiltrate data or cause harmful actions (Rehberger, 2024; AI-Security-Team et al., 2025; Anthropic, 2025; OpenAI, 2025). Current defenses often rely on training or prompting models to adhere to securit"
[25.03.2025 07:11] Response: ```python
["Google", "Google DeepMind", "ETH Zurich"]
```
[25.03.2025 07:11] Deleting PDF ./assets/pdf/2503.18813.pdf.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.18559.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.18559.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.18559.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.17735.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.17735.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.17735.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.17500.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.17500.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.17500.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.17422.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.17422.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.17422.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2503.16924.
[25.03.2025 07:11] Extra JSON file exists (./assets/json/2503.16924.json), skip PDF parsing.
[25.03.2025 07:11] Paper image links file exists (./assets/img_data/2503.16924.json), skip HTML parsing.
[25.03.2025 07:11] Success.
[25.03.2025 07:11] Enriching papers with extra data.
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 0. Modern game development faces significant challenges in creativity and cost due to predetermined content in traditional game engines. Recent breakthroughs in video generation models, capable of synthesizing realistic and interactive virtual environments, present an opportunity to revolutionize game ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 1. With the scale capability of increasing training data, model size, and computational cost, video generation has achieved impressive results in digital creation, enabling users to express creativity across various domains. Recently, researchers in Large Language Models (LLMs) have expanded the scalin...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 2. DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can naturally emerge through a simple reinforcement learning (RL) framework with rule-based rewards, where the training may directly start from the base models-a paradigm referred to as zero RL training. Most recent efforts to reproduc...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 3. Diffusion models have demonstrated remarkable capabilities in visual content generation but remain challenging to deploy due to their high computational cost during inference. This computational burden primarily arises from the quadratic complexity of self-attention with respect to image or video re...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 4. Evaluating generative foundation models on open-ended multimodal understanding (MMU) and generation (MMG) tasks across diverse modalities (e.g., images, audio, video) poses significant challenges due to the complexity of cross-modal interactions. To this end, the idea of utilizing Multimodal LLMs (M...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 5. The integration of geometric reconstruction and generative modeling remains a critical challenge in developing AI systems capable of human-like spatial reasoning. This paper proposes Aether, a unified framework that enables geometry-aware reasoning in world models by jointly optimizing three core ca...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 6. Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in video contexts remains a critical unsolved challenge. To address this gap, we introduce Video SimpleQA, the first comprehensive benchma...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 7. Large language models (LLMs) have demonstrated remarkable reasoning capability in solving mathematical problems. However, existing approaches primarily focus on improving the quality of correct training data, e.g., distilling high-quality correct solutions from advanced models, neglecting the value ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 8. Non-factoid question-answering (NFQA) poses a significant challenge due to its open-ended nature, diverse intents, and the need for multi-aspect reasoning, which renders conventional factoid QA approaches, including retrieval-augmented generation (RAG), inadequate. Unlike factoid questions, non-fact...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 9. Progress in scientific discovery is rarely the result of a single "Eureka" moment, but is rather the product of hundreds of scientists incrementally working together toward a common goal. While existing agent workflows are capable of producing research autonomously, they do so in isolation, without ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 10. We introduce FFN Fusion, an architectural optimization technique that reduces sequential computation in large language models by identifying and exploiting natural opportunities for parallelization. Our key insight is that sequences of Feed-Forward Network (FFN) layers, particularly those remaining ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 11. Compute scaling for language model (LM) pretraining has outpaced the growth of human-written texts, leading to concerns that data will become the bottleneck to LM scaling. To continue scaling pretraining in this data-constrained regime, we propose that explicitly modeling and inferring the latent th...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 12. Large Vision-Language Models (LVLMs) typically follow a two-stage training paradigm-pretraining and supervised fine-tuning. Recently, preference optimization, derived from the language domain, has emerged as an effective post-training reinforcement strategy to enhance capabilities of LVLMs. However,...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 13. Text-to-video (T2V) generation has made significant strides with diffusion models. However, existing methods still struggle with accurately binding attributes, determining spatial relationships, and capturing complex action interactions between multiple subjects. To address these limitations, we pro...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 14. This paper presents AlphaSpace, a novel methodology designed to enhance the spatial reasoning capabilities of large language models (LLMs) for 3D Cartesian space navigation. AlphaSpace employs a semantics-based tokenization strategy, encoding height information through specialized semantic tokens, a...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 15. Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an external environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer a...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 16. Text-to-Video (T2V) generation has attracted significant attention for its ability to synthesize realistic videos from textual descriptions. However, existing models struggle to balance computational efficiency and high visual quality, particularly on resource-limited devices, e.g.,iGPUs and mobile ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 17. Recently, great progress has been made in video generation technology, attracting the widespread attention of scholars. To apply this technology to downstream applications under resource-constrained conditions, researchers usually fine-tune the pre-trained models based on parameter-efficient tuning ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 18. The outcome of Large Language Model (LLM) pre-training strongly depends on weight initialization and variance control strategies. Although the importance of initial variance control has been well documented in neural networks in general, the literature on initialization and management of its growth ...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 19. The recent exponential growth of Large Language Models (LLMs) has relied on GPU-based systems. However, CPUs are emerging as a flexible and lower-cost alternative, especially when targeting inference and reasoning workloads. RISC-V is rapidly gaining traction in this area, given its open and vendor-...
[25.03.2025 07:11] ********************************************************************************
[25.03.2025 07:11] Abstract 20. 3D Gaussian Splatting (3DGS) has emerged as a powerful representation for real-time, high-performance rendering, enabling a wide range of applications. However, representing 3D scenes with numerous explicit Gaussian primitives imposes significant storage and memory overhead. Recent studies have show...
[25.03.2025 07:11] Read previous papers.
[25.03.2025 07:11] Generating reviews via LLM API.
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#video", "#architecture", "#games", "#multimodal"], "emoji": "🎮", "ru": {"title": "Революция в разработке игр: ИИ-генерируемые миры будущего", "desc": "Статья предлагает концепцию Генеративных Игровых Движков (GGE), основанных на Интерактивной Генеративной Видео технологии (IGV). GG
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#video", "#inference", "#games", "#optimization", "#benchmark"], "emoji": "🎥", "ru": {"title": "Масштабирование времени тестирования: новый подход к улучшению генерации видео", "desc": "Статья исследует применение метода масштабирования времени тестирования (TTS) для улучшения качес
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#rl", "#training", "#small_models"], "emoji": "🧠", "ru": {"title": "Развитие рассуждений в языковых моделях через RL с нуля", "desc": "Это исследование посвящено применению обучения с подкреплением (RL) без предварительной подготовки для развития способ
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#cv", "#optimization", "#diffusion", "#inference", "#video"], "emoji": "⏱️", "ru": {"title": "Ускорение диффузионных моделей без потери качества", "desc": "Статья представляет новый метод ускорения работы диффузионных моделей под названием Bottleneck Sampling. Этот подход использует
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#multimodal", "#hallucinations", "#benchmark", "#alignment", "#open_source"], "emoji": "🤖", "ru": {"title": "Универсальная оценка мультимодальных ИИ-моделей: от понимания к генерации", "desc": "Статья представляет новые бенчмарки TaskAnything и JudgeAnything для оценки мультимодальн
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#video", "#3d", "#reasoning", "#agents", "#synthetic"], "emoji": "🧠", "ru": {"title": "Единая система для геометрического моделирования мира и планирования действий", "desc": "Статья представляет Aether - унифицированную систему для геометрически-осознанного рассуждения в моделях ми
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#video", "#interpretability", "#reasoning", "#long_context", "#multimodal", "#rag", "#benchmark"], "emoji": "🎥", "ru": {"title": "Новый стандарт оценки фактической точности видео-языковых моделей", "desc": "Статья представляет Video SimpleQA - первый комплексный бенчмарк для оценки 
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#dataset", "#data"], "emoji": "🧮", "ru": {"title": "Учимся на ошибках: новый подход к улучшению математических способностей ИИ", "desc": "Эта статья предлагает метод LEMMA для улучшения способности больших языковых моделей (LLM) решать математичес
[25.03.2025 07:11] Using data from previous issue: {"categories": ["#rag", "#open_source", "#benchmark", "#optimization", "#dataset", "#reasoning"], "emoji": "🧠", "ru": {"title": "Typed-RAG: умное разложение вопросов для лучших ответов", "desc": "Статья представляет новый подход к ответам на нефактоидные вопросы (NFQA) под названием Typed-RAG. Этот 
[25.03.2025 07:11] Querying the API.
[25.03.2025 07:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Progress in scientific discovery is rarely the result of a single "Eureka" moment, but is rather the product of hundreds of scientists incrementally working together toward a common goal. While existing agent workflows are capable of producing research autonomously, they do so in isolation, without the ability to continuously improve upon prior research results. To address these challenges, we introduce AgentRxiv-a framework that lets LLM agent laboratories upload and retrieve reports from a shared preprint server in order to collaborate, share insights, and iteratively build on each other's research. We task agent laboratories to develop new reasoning and prompting techniques and find that agents with access to their prior research achieve higher performance improvements compared to agents operating in isolation (11.4% relative improvement over baseline on MATH-500). We find that the best performing strategy generalizes to benchmarks in other domains (improving on average by 3.3%). Multiple agent laboratories sharing research through AgentRxiv are able to work together towards a common goal, progressing more rapidly than isolated laboratories, achieving higher overall accuracy (13.7% relative improvement over baseline on MATH-500). These findings suggest that autonomous agents may play a role in designing future AI systems alongside humans. We hope that AgentRxiv allows agents to collaborate toward research goals and enables researchers to accelerate discovery.
[25.03.2025 07:12] Response: {
  "desc": "Статья представляет AgentRxiv - фреймворк, позволяющий агентам на основе больших языковых моделей (LLM) обмениваться результатами исследований через общий препринт-сервер. Эксперименты показывают, что агенты с доступом к предыдущим исследованиям достигают более высоких результатов по сравнению с изолированными агентами. Несколько лабораторий агентов, обменивающихся исследованиями через AgentRxiv, способны быстрее продвигаться к общей цели. Результаты предполагают, что автономные агенты могут играть роль в разработке будущих систем искусственного интеллекта наряду с людьми.",
  "emoji": "🤖",
  "title": "Коллективный разум ИИ: AgentRxiv объединяет LLM-агентов для ускорения научных открытий"
}
[25.03.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Progress in scientific discovery is rarely the result of a single "Eureka" moment, but is rather the product of hundreds of scientists incrementally working together toward a common goal. While existing agent workflows are capable of producing research autonomously, they do so in isolation, without the ability to continuously improve upon prior research results. To address these challenges, we introduce AgentRxiv-a framework that lets LLM agent laboratories upload and retrieve reports from a shared preprint server in order to collaborate, share insights, and iteratively build on each other's research. We task agent laboratories to develop new reasoning and prompting techniques and find that agents with access to their prior research achieve higher performance improvements compared to agents operating in isolation (11.4% relative improvement over baseline on MATH-500). We find that the best performing strategy generalizes to benchmarks in other domains (improving on average by 3.3%). Multiple agent laboratories sharing research through AgentRxiv are able to work together towards a common goal, progressing more rapidly than isolated laboratories, achieving higher overall accuracy (13.7% relative improvement over baseline on MATH-500). These findings suggest that autonomous agents may play a role in designing future AI systems alongside humans. We hope that AgentRxiv allows agents to collaborate toward research goals and enables researchers to accelerate discovery."

[25.03.2025 07:12] Response: ```python
['AGENTS', 'BENCHMARK', 'MATH']
```
[25.03.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Progress in scientific discovery is rarely the result of a single "Eureka" moment, but is rather the product of hundreds of scientists incrementally working together toward a common goal. While existing agent workflows are capable of producing research autonomously, they do so in isolation, without the ability to continuously improve upon prior research results. To address these challenges, we introduce AgentRxiv-a framework that lets LLM agent laboratories upload and retrieve reports from a shared preprint server in order to collaborate, share insights, and iteratively build on each other's research. We task agent laboratories to develop new reasoning and prompting techniques and find that agents with access to their prior research achieve higher performance improvements compared to agents operating in isolation (11.4% relative improvement over baseline on MATH-500). We find that the best performing strategy generalizes to benchmarks in other domains (improving on average by 3.3%). Multiple agent laboratories sharing research through AgentRxiv are able to work together towards a common goal, progressing more rapidly than isolated laboratories, achieving higher overall accuracy (13.7% relative improvement over baseline on MATH-500). These findings suggest that autonomous agents may play a role in designing future AI systems alongside humans. We hope that AgentRxiv allows agents to collaborate toward research goals and enables researchers to accelerate discovery."

[25.03.2025 07:12] Response: ```python
['REASONING', 'SCIENCE']
```
[25.03.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces AgentRxiv, a collaborative framework for large language model (LLM) agents to share and build upon research findings. Unlike traditional isolated workflows, AgentRxiv allows agents to upload and retrieve reports from a shared preprint server, fostering collaboration and iterative improvement. The study shows that agents utilizing prior research achieve significant performance gains, with a 11.4% relative improvement on the MATH-500 benchmark. This collaborative approach not only enhances individual agent performance but also accelerates overall research progress, suggesting a promising future for autonomous agents in scientific discovery.","title":"Collaborative AI: Accelerating Research with AgentRxiv"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces AgentRxiv, a collaborative framework for large language model (LLM) agents to share and build upon research findings. Unlike traditional isolated workflows, AgentRxiv allows agents to upload and retrieve reports from a shared preprint server, fostering collaboration and iterative improvement. The study shows that agents utilizing prior research achieve significant performance gains, with a 11.4% relative improvement on the MATH-500 benchmark. This collaborative approach not only enhances individual agent performance but also accelerates overall research progress, suggesting a promising future for autonomous agents in scientific discovery.', title='Collaborative AI: Accelerating Research with AgentRxiv'))
[25.03.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文介绍了AgentRxiv，一个框架使得大型语言模型（LLM）代理实验室能够上传和检索共享的预印本报告，从而实现合作和知识共享。通过这种方式，代理实验室可以在彼此的研究基础上进行迭代，提升研究成果。研究表明，能够访问先前研究的代理在性能上有显著提升，相比于孤立操作的代理，提升达到了11.4%。这些结果表明，多个代理实验室通过AgentRxiv合作，可以更快地朝着共同目标前进，并在整体准确性上实现更高的提升。","title":"AgentRxiv：促进代理实验室协作的研究框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文介绍了AgentRxiv，一个框架使得大型语言模型（LLM）代理实验室能够上传和检索共享的预印本报告，从而实现合作和知识共享。通过这种方式，代理实验室可以在彼此的研究基础上进行迭代，提升研究成果。研究表明，能够访问先前研究的代理在性能上有显著提升，相比于孤立操作的代理，提升达到了11.4%。这些结果表明，多个代理实验室通过AgentRxiv合作，可以更快地朝着共同目标前进，并在整体准确性上实现更高的提升。', title='AgentRxiv：促进代理实验室协作的研究框架'))
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#inference"], "emoji": "🚀", "ru": {"title": "Ускорение больших языковых моделей через параллелизацию FFN слоев", "desc": "Статья представляет технику оптимизации архитектуры под названием FFN Fusion, которая сокращает последовательные в
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#transfer_learning", "#synthetic", "#data", "#math"], "emoji": "🧠", "ru": {"title": "Раскрытие скрытых мыслей для эффективного обучения языковых моделей", "desc": "Статья предлагает метод повышения эффективности предобучения языковых моделей в условиях 
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training", "#benchmark", "#rlhf"], "emoji": "👁️", "ru": {"title": "Vision-R1: Революция в обучении визуально-языковых моделей без ручной разметки", "desc": "В статье представлен новый алгоритм обучения с подкреплением для крупных визуально-языковых моделей п
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#training", "#multimodal", "#architecture", "#games", "#diffusion", "#video"], "emoji": "🎬", "ru": {"title": "MagicComp: Усовершенствованная генерация видео по тексту без дополнительного обучения", "desc": "MagicComp - это метод генерации видео по тексту, не требующий дополнительног
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#synthetic", "#reasoning", "#3d"], "emoji": "🧠", "ru": {"title": "AlphaSpace: Прорыв в пространственном мышлении ИИ", "desc": "AlphaSpace - это новая методология, разработанная для улучшения пространственного мышления больших языковых моделей (LLM) в навигации по 3D
[25.03.2025 07:12] Querying the API.
[25.03.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an external environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models may be susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL relies on a notion of a capability to prevent the exfiltration of private data over unauthorized data flows. We demonstrate effectiveness of CaMeL by solving 67% of tasks with provable security in AgentDojo [NeurIPS 2024], a recent agentic security benchmark.
[25.03.2025 07:12] Response: {
  "desc": "Статья представляет CaMeL - новый метод защиты агентов на основе больших языковых моделей (LLM) от атак внедрения промптов. CaMeL создает защитный системный слой вокруг LLM, извлекая потоки управления и данных из доверенного запроса. Это предотвращает влияние недоверенных данных на выполнение программы. Метод также использует концепцию возможностей для предотвращения утечки приватных данных. Эффективность CaMeL продемонстрирована решением 67% задач с доказуемой безопасностью в бенчмарке AgentDojo.",
  "emoji": "🛡️",
  "title": "CaMeL: Надежная защита LLM-агентов от атак внедрения промптов"
}
[25.03.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an external environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models may be susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL relies on a notion of a capability to prevent the exfiltration of private data over unauthorized data flows. We demonstrate effectiveness of CaMeL by solving 67% of tasks with provable security in AgentDojo [NeurIPS 2024], a recent agentic security benchmark."

[25.03.2025 07:12] Response: ```python
['AGENTS', 'BENCHMARK', 'INFERENCE']
```
[25.03.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an external environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models may be susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL relies on a notion of a capability to prevent the exfiltration of private data over unauthorized data flows. We demonstrate effectiveness of CaMeL by solving 67% of tasks with provable security in AgentDojo [NeurIPS 2024], a recent agentic security benchmark."

[25.03.2025 07:12] Response: ```python
["SECURITY"]
```
[25.03.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces CaMeL, a defense mechanism designed to protect Large Language Models (LLMs) from prompt injection attacks when they interact with untrusted data. CaMeL works by creating a secure layer that separates control and data flows, ensuring that untrusted inputs do not affect the execution of the program. Additionally, it implements a capability system to prevent unauthorized access to private data. The effectiveness of CaMeL is demonstrated through its ability to solve 67% of tasks securely in the AgentDojo benchmark.","title":"Securing LLMs Against Prompt Injection with CaMeL"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces CaMeL, a defense mechanism designed to protect Large Language Models (LLMs) from prompt injection attacks when they interact with untrusted data. CaMeL works by creating a secure layer that separates control and data flows, ensuring that untrusted inputs do not affect the execution of the program. Additionally, it implements a capability system to prevent unauthorized access to private data. The effectiveness of CaMeL is demonstrated through its ability to solve 67% of tasks securely in the AgentDojo benchmark.', title='Securing LLMs Against Prompt Injection with CaMeL'))
[25.03.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型（LLMs）在与外部环境交互的智能系统中越来越多地被使用。然而，当处理不可信数据时，LLM代理容易受到提示注入攻击。本文提出了CaMeL，这是一种强大的防御机制，它在LLM周围创建了一个保护系统层，即使底层模型可能容易受到攻击。CaMeL通过明确提取控制和数据流来操作，从而确保LLM检索到的不可信数据不会影响程序流程，并通过能力概念进一步提高安全性，防止私密数据通过未经授权的数据流泄露。","title":"CaMeL：保护大型语言模型的安全防线"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型（LLMs）在与外部环境交互的智能系统中越来越多地被使用。然而，当处理不可信数据时，LLM代理容易受到提示注入攻击。本文提出了CaMeL，这是一种强大的防御机制，它在LLM周围创建了一个保护系统层，即使底层模型可能容易受到攻击。CaMeL通过明确提取控制和数据流来操作，从而确保LLM检索到的不可信数据不会影响程序流程，并通过能力概念进一步提高安全性，防止私密数据通过未经授权的数据流泄露。', title='CaMeL：保护大型语言模型的安全防线'))
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#long_context", "#video", "#optimization", "#open_source", "#training", "#small_models", "#data"], "emoji": "🐦", "ru": {"title": "Эффективная генерация видео по тексту для мобильных устройств", "desc": "Статья представляет легковесную модель генерации видео по тексту под названием H
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#video", "#dataset", "#optimization", "#training", "#transfer_learning"], "emoji": "🎬", "ru": {"title": "Эффективная генерация видео с нуля вместо тонкой настройки больших моделей", "desc": "Статья представляет новый подход к генерации видео в условиях ограниченных ресурсов. Авторы 
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#inference", "#benchmark", "#optimization", "#training", "#architecture"], "emoji": "⚖️", "ru": {"title": "Точная настройка весов - ключ к эффективным языковым моделям", "desc": "Статья представляет новые методы инициализации весов и контроля дисперсии для предобучения больших языко
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#reasoning", "#inference"], "emoji": "🚀", "ru": {"title": "Ускорение языковых моделей на RISC-V процессорах", "desc": "Данная статья посвящена оптимизации инференса больших языковых моделей (LLM) на процессорах RISC-V, в частности на Sophon SG2042. 
[25.03.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#3d", "#inference", "#open_source"], "emoji": "🎨", "ru": {"title": "OMG: Оптимизация 3D Gaussian Splatting для эффективного рендеринга", "desc": "В этой статье представлен метод Optimized Minimal Gaussians (OMG) для оптимизации 3D Gaussian Splatting. OMG значительно
[25.03.2025 07:12] Loading Chinese text from previous data.
[25.03.2025 07:12] Renaming data file.
[25.03.2025 07:12] Renaming previous data. hf_papers.json to ./d/2025-03-25.json
[25.03.2025 07:12] Saving new data file.
[25.03.2025 07:12] Generating page.
[25.03.2025 07:12] Renaming previous page.
[25.03.2025 07:12] Renaming previous data. index.html to ./d/2025-03-25.html
[25.03.2025 07:12] [Experimental] Generating Chinese page for reading.
[25.03.2025 07:12] Chinese vocab [{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '科学问题', 'pinyin': 'kē xué wèn tí', 'trans': 'scientific problems'}, {'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenges'}, {'word': '整合', 'pinyin': 'zhěng hé', 'trans': 'integrate'}, {'word': '模态', 'pinyin': 'mó tài', 'trans': 'modality'}, {'word': '文本', 'pinyin': 'wén běn', 'trans': 'text'}, {'word': '图表', 'pinyin': 'tú biǎo', 'trans': 'charts'}, {'word': '面临', 'pinyin': 'miàn lín', 'trans': 'face'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '反思', 'pinyin': 'fǎn sī', 'trans': 'reflection'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '基于', 'pinyin': 'jī yú', 'trans': 'based on'}, {'word': '大七人格', 'pinyin': 'dà qī rén gé', 'trans': 'Big Five personality traits'}, {'word': '苏格拉底', 'pinyin': 'sū gé lā dǐ', 'trans': 'Socrates'}, {'word': '指导', 'pinyin': 'zhǐ dǎo', 'trans': 'guidance'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'results'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chū sè', 'trans': 'outstanding'}, {'word': '超越', 'pinyin': 'chāo yuè', 'trans': 'surpass'}, {'word': '现有', 'pinyin': 'xiàn yǒu', 'trans': 'existing'}, {'word': '最佳', 'pinyin': 'zuì jiā', 'trans': 'best'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}]
[25.03.2025 07:12] Renaming previous Chinese page.
[25.03.2025 07:12] Renaming previous data. zh.html to ./d/2025-03-24_zh_reading_task.html
[25.03.2025 07:12] Writing Chinese reading task.
[25.03.2025 07:12] Writing result.
[25.03.2025 07:12] Renaming log file.
[25.03.2025 07:12] Renaming previous data. log.txt to ./logs/2025-03-25_last_log.txt
