[08.01.2026 23:20] Read previous papers.
[08.01.2026 23:20] Generating top page (month).
[08.01.2026 23:20] Writing top page (month).
[09.01.2026 01:49] Read previous papers.
[09.01.2026 01:49] Get feed.
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02151
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03509
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03872
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03986
[09.01.2026 01:49] Extract page data from URL. URL: https://huggingface.co/papers/2601.03822
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04151
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04194
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04171
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02075
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00423
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03471
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03699
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03315
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03467
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03448
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.02933
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03955
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.03236
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.04090
[09.01.2026 01:49] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00705
[09.01.2026 01:49] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.01.2026 01:49] No deleted papers detected.
[09.01.2026 01:49] Downloading and parsing papers (pdf, html). Total: 20.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.02151.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.02151.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.02151.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03509.
[09.01.2026 01:49] Downloading paper 2601.03509 from https://arxiv.org/pdf/2601.03509v1...
[09.01.2026 01:49] Failed to download and parse paper https://huggingface.co/papers/2601.03509: 'LTChar' object is not iterable
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03872.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03872.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03872.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03986.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03986.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03986.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03822.
[09.01.2026 01:49] Downloading paper 2601.03822 from https://arxiv.org/pdf/2601.03822v1...
[09.01.2026 01:49] Extracting affiliations from text.
[09.01.2026 01:49] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition Muyang Zhao1, Qi Qi1*, Hao Sun1* 1Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China {myzhao13, qi.qi, haosun}@ruc.edu.cn 6 2 0 2 7 ] A . [ 1 2 2 8 3 0 . 1 0 6 2 : r a "
[09.01.2026 01:49] Response: ```python
["Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China"]
```
[09.01.2026 01:49] Deleting PDF ./assets/pdf/2601.03822.pdf.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.04151.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.04151.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.04151.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.04194.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.04194.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.04194.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.04171.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.04171.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.04171.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.02075.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.02075.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.02075.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.00423.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.00423.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.00423.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03471.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03471.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03471.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03699.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03699.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03699.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03315.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03315.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03315.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03467.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03467.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03467.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03448.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03448.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03448.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.02933.
[09.01.2026 01:49] Downloading paper 2601.02933 from https://arxiv.org/pdf/2601.02933v1...
[09.01.2026 01:49] Failed to download and parse paper https://huggingface.co/papers/2601.02933: 'LTChar' object is not iterable
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03955.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03955.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03955.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.03236.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.03236.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.03236.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.04090.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.04090.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.04090.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Downloading and parsing paper https://huggingface.co/papers/2601.00705.
[09.01.2026 01:49] Extra JSON file exists (./assets/json/2601.00705.json), skip PDF parsing.
[09.01.2026 01:49] Paper image links file exists (./assets/img_data/2601.00705.json), skip HTML parsing.
[09.01.2026 01:49] Success.
[09.01.2026 01:49] Enriching papers with extra data.
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 0. Entropy-Adaptive Fine-Tuning addresses catastrophic forgetting in supervised fine-tuning by using token-level entropy to distinguish uncertainty from knowledge conflict, enabling better preservation of general capabilities.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) is the standard...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 1. Programmatic Skill Network enables continual skill acquisition through executable symbolic programs that evolve via reflection, progressive optimization, and structural refactoring mechanisms.  					AI-generated summary 				 We study continual skill acquisition in open-ended embodied environments wh...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 2. ATLAS is a dual-path framework that dynamically selects optimal model-tool combinations for cross-domain reasoning through cluster-based routing and reinforcement learning-based multi-step routing, achieving superior performance on complex reasoning tasks.  					AI-generated summary 				 The integra...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 3. Researchers developed Benchmark^2, a framework with three metrics to evaluate benchmark quality for large language models, revealing significant variations in existing benchmarks and enabling more efficient evaluation through selective benchmark construction.  					AI-generated summary 				 The rapi...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 4. Budgeted inference-time reasoning framework enables large language models to make strategic computational decisions by predicting costs and utilities before generation, then optimizing sequential allocation under strict token constraints through meta-cognitive fine-tuning and reinforcement learning....
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 5. Klear addresses audio-video joint generation challenges through a unified model architecture, progressive multitask training, and large-scale dense-caption data construction, achieving superior alignment and generalization.  					AI-generated summary 				 Audio-video joint generation has progressed ...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 6. CHORD is a universal generative framework that extracts Lagrangian motion information from Eulerian video representations to synthesize diverse 4D dynamic scenes without requiring category-specific rules or large datasets.  					AI-generated summary 				 Dynamic objects in our physical 4D (3D + time...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 7. Agentic Rubrics enable efficient and scalable verification for software engineering agents by creating context-aware checklists that outperform traditional methods while maintaining interpretability.  					AI-generated summary 				 Verification is critical for improving agents: it provides the rewar...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 8. MDAgent2 enables automated molecular dynamics code generation and question answering through domain-adapted language models and a multi-agent runtime system.  					AI-generated summary 				 Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials scienc...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 9. Entropy-aware policy optimization method for reinforcement learning in flow matching models that improves exploration through SDE and ODE sampling strategies.  					AI-generated summary 				 Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stoc...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 10. EpiQAL presents a novel benchmark for evaluating epidemiological reasoning in language models through three distinct subsets measuring factual recall, multi-step inference, and conclusion reconstruction from scientific literature.  					AI-generated summary 				 Reliable epidemiological reasoning re...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 11. RedBench presents a unified dataset with standardized risk categorization for evaluating LLM vulnerabilities across multiple domains and attack types.  					AI-generated summary 				 As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against ad...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 12. A case study of four attempts to autonomously generate ML research papers using LLM agents reveals recurring failure modes and proposes design principles for robust AI-scientist systems.  					AI-generated summary 				 We report a case study of four end-to-end attempts to autonomously generate ML re...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 13. ThinkRL-Edit enhances reasoning-centric image editing through reinforcement learning by expanding visual reasoning exploration beyond denoising stochasticity and using unbiased reward strategies.  					AI-generated summary 				 Instruction-driven image editing with unified multimodal generative mode...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 14. Language models pre-trained with a framework combining standard next-token prediction and structured language learning tasks show enhanced linguistic competence without sacrificing general reasoning capabilities.  					AI-generated summary 				 Language models (LMs) are pre-trained on raw text datas...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 15. Pearmut is a platform that simplifies human evaluation in multilingual NLP by providing a lightweight solution for end-to-end evaluation with support for various protocols and learning strategies.  					AI-generated summary 				 Human evaluation is the gold standard for multilingual NLP, but is ofte...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 16. A novel 1D visual tokenizer called Residual Tokenizer is introduced that incorporates hierarchical residuals to improve autoregressive image generation by leveraging vision-specific design principles rather than language modeling approaches.  					AI-generated summary 				 Existing 1D visual tokeniz...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 17. MAGMA is a multi-graph memory architecture that improves long-context reasoning in language models by separating memory representation from retrieval logic across semantic, temporal, causal, and entity dimensions.  					AI-generated summary 				 Memory-Augmented Generation (MAG) extends Large Langua...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 18. Gen3R combines foundational reconstruction models with video diffusion models to generate 3D scenes with RGB videos and geometric information through aligned latents.  					AI-generated summary 				 We present Gen3R, a method that bridges the strong priors of foundational reconstruction models and v...
[09.01.2026 01:49] ********************************************************************************
[09.01.2026 01:49] Abstract 19. RGS-SLAM presents a robust Gaussian-splatting SLAM framework that uses dense multi-view correspondences and DINOv3 descriptors for efficient, stable mapping with improved rendering fidelity.  					AI-generated summary 				 We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replac...
[09.01.2026 01:49] Read previous papers.
[09.01.2026 01:49] Generating reviews via LLM API.
[09.01.2026 01:49] Using data from previous issue: {"categories": [], "emoji": "‚öñÔ∏è", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–±—ã–≤–∞–Ω–∏—è –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –≤—ã—è–≤–∏–ª–∏, —á—Ç–æ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º (SFT) –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –ø–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ
[09.01.2026 01:49] Using data from previous issue: {"categories": [], "emoji": "üß¨", "ru": {"title": "–≠–≤–æ–ª—é—Ü–∏—è –Ω–∞–≤—ã–∫–æ–≤ —á–µ—Ä–µ–∑ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏—é", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ Programmatic Skill Network (PSN) ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –≤ –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Å—Ä–µ–¥–∞—Ö, –≥–¥–µ –Ω–∞–≤—ã–∫–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≥
[09.01.2026 01:49] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#rl", "#agents", "#benchmark", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é", "desc": "ATLAS ‚Äî —ç—Ç–æ –¥–≤—É—Ö–ø—É—Ç—ë–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å
[09.01.2026 01:49] Using data from previous issue: {"categories": ["#benchmark"], "emoji": "üìè", "ru": {"title": "–ò–∑–º–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π: —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Benchmark¬≤, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –§—Ä–µ–π–º–≤–æ—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –º–µ—Ç
[09.01.2026 01:49] Querying the API.
[09.01.2026 01:49] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Budgeted inference-time reasoning framework enables large language models to make strategic computational decisions by predicting costs and utilities before generation, then optimizing sequential allocation under strict token constraints through meta-cognitive fine-tuning and reinforcement learning.  					AI-generated summary 				 Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.
[09.01.2026 01:50] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ ROI-Reasoning –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Ç–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã —Ñ–æ—Ä–º–∞–ª–∏–∑—É—é—Ç –∑–∞–¥–∞—á—É –∫–∞–∫ –∑–∞–¥–∞—á—É –æ –º–Ω–æ–≥–æ–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ–º —Ä–∞–Ω—Ü–µ —Å–æ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –¥–≤–∞ —ç—Ç–∞–ø–∞ –æ–±—É—á–µ–Ω–∏—è: –º–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏, –∞ —Ç–∞–∫–∂–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤. –ú–µ—Ç–æ–¥ —É—á–∏—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ –∏ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Ç–æ–º, —Å—Ç–æ–∏—Ç –ª–∏ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á—É –∏–ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ—ë. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ ROI-Reasoning —É–ª—É—á—à–∞–µ—Ç –æ–±—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å–Ω–∏–∂–∞–µ—Ç —Å–æ–∂–∞–ª–µ–Ω–∏–µ –≤ —É—Å–ª–æ–≤–∏—è—Ö –∂—ë—Å—Ç–∫–∏—Ö –±—é–¥–∂–µ—Ç–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π.",
  "emoji": "üß†",
  "title": "–†–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–≥–æ –±—é–¥–∂–µ—Ç–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö"
}
```
[09.01.2026 01:50] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Budgeted inference-time reasoning framework enables large language models to make strategic computational decisions by predicting costs and utilities before generation, then optimizing sequential allocation under strict token constraints through meta-cognitive fine-tuning and reinforcement learning.  					AI-generated summary 				 Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets."

[09.01.2026 01:50] Response: ```python
["INFERENCE", "TRAINING", "RL", "BENCHMARK"]
```
[09.01.2026 01:50] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Budgeted inference-time reasoning framework enables large language models to make strategic computational decisions by predicting costs and utilities before generation, then optimizing sequential allocation under strict token constraints through meta-cognitive fine-tuning and reinforcement learning.  					AI-generated summary 				 Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets."

[09.01.2026 01:50] Response: ```python
['REASONING', 'OPTIMIZATION']
```
[09.01.2026 01:50] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a framework called ROI-Reasoning that helps large language models (LLMs) make better decisions about how much computation to use for different tasks. It formalizes the problem as an Ordered Stochastic Multiple-Choice Knapsack Problem (OS-MCKP), which requires the model to predict the difficulty of tasks and the expected benefits of computation. The framework consists of two stages: first, Meta-Cognitive Fine-Tuning teaches the model to estimate costs and utilities before generating responses, and second, Rationality-Aware Reinforcement Learning optimizes how the model allocates its computational resources under strict token limits. The results show that ROI-Reasoning improves performance on reasoning tasks while minimizing wasted computation.","title":"Smart Computation: Budgeting for Better Reasoning in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a framework called ROI-Reasoning that helps large language models (LLMs) make better decisions about how much computation to use for different tasks. It formalizes the problem as an Ordered Stochastic Multiple-Choice Knapsack Problem (OS-MCKP), which requires the model to predict the difficulty of tasks and the expected benefits of computation. The framework consists of two stages: first, Meta-Cognitive Fine-Tuning teaches the model to estimate costs and utilities before generating responses, and second, Rationality-Aware Reinforcement Learning optimizes how the model allocates its computational resources under strict token limits. The results show that ROI-Reasoning improves performance on reasoning tasks while minimizing wasted computation.', title='Smart Computation: Budgeting for Better Reasoning in LLMs'))
[09.01.2026 01:50] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈ¢ÑÁÆóÊé®ÁêÜÊ°ÜÊû∂Ôºå‰ΩøÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãËÉΩÂ§üÂú®ÁîüÊàê‰πãÂâçÈ¢ÑÊµãËÆ°ÁÆóÊàêÊú¨ÂíåÊïàÁî®Ôºå‰ªéËÄåËøõË°åÊàòÁï•ÊÄßËÆ°ÁÆóÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨Â∞ÜËøô‰∏ÄËøáÁ®ãÂΩ¢ÂºèÂåñ‰∏∫ÊúâÂ∫èÈöèÊú∫Â§öÈÄâËÉåÂåÖÈóÆÈ¢òÔºàOS-MCKPÔºâÔºåÂº∫Ë∞É‰∫ÜÊ®°ÂûãÂú®Êé®ÁêÜÊó∂ÈúÄË¶ÅÂÖ∑Â§áÁöÑÂÖÉËÆ§Áü•ËÉΩÂäõ„ÄÇÈÄöËøáÂÖÉËÆ§Áü•ÂæÆË∞ÉÔºåÊ®°ÂûãÂ≠¶‰π†Âú®ÁîüÊàêÂâçÈ¢ÑÊµãÊé®ÁêÜÊàêÊú¨ÂíåÈ¢ÑÊúüÊïàÁî®Ôºå‰ªéËÄåÂÅöÂá∫ÊòéÁ°ÆÁöÑËß£ÂÜ≥ÊàñË∑≥ËøáÂÜ≥Á≠ñ„ÄÇÊúÄÂêéÔºåÁêÜÊÄßÊÑèËØÜÂº∫ÂåñÂ≠¶‰π†Âú®‰∏•Ê†ºÁöÑ‰ª§ÁâåÈ¢ÑÁÆó‰∏ã‰ºòÂåñÂ∫èÂàóÂÜ≥Á≠ñÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂ≠¶‰π†ÈïøÊúüÁöÑËÆ°ÁÆóÂàÜÈÖçÁ≠ñÁï•„ÄÇ","title":"È¢ÑÁÆóÊé®ÁêÜÔºöËÆ©Ê®°ÂûãÊõ¥ËÅ™ÊòéÁöÑËÆ°ÁÆóÂÜ≥Á≠ñ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈ¢ÑÁÆóÊé®ÁêÜÊ°ÜÊû∂Ôºå‰ΩøÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãËÉΩÂ§üÂú®ÁîüÊàê‰πãÂâçÈ¢ÑÊµãËÆ°ÁÆóÊàêÊú¨ÂíåÊïàÁî®Ôºå‰ªéËÄåËøõË°åÊàòÁï•ÊÄßËÆ°ÁÆóÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨Â∞ÜËøô‰∏ÄËøáÁ®ãÂΩ¢ÂºèÂåñ‰∏∫ÊúâÂ∫èÈöèÊú∫Â§öÈÄâËÉåÂåÖÈóÆÈ¢òÔºàOS-MCKPÔºâÔºåÂº∫Ë∞É‰∫ÜÊ®°ÂûãÂú®Êé®ÁêÜÊó∂ÈúÄË¶ÅÂÖ∑Â§áÁöÑÂÖÉËÆ§Áü•ËÉΩÂäõ„ÄÇÈÄöËøáÂÖÉËÆ§Áü•ÂæÆË∞ÉÔºåÊ®°ÂûãÂ≠¶‰π†Âú®ÁîüÊàêÂâçÈ¢ÑÊµãÊé®ÁêÜÊàêÊú¨ÂíåÈ¢ÑÊúüÊïàÁî®Ôºå‰ªéËÄåÂÅöÂá∫ÊòéÁ°ÆÁöÑËß£ÂÜ≥ÊàñË∑≥ËøáÂÜ≥Á≠ñ„ÄÇÊúÄÂêéÔºåÁêÜÊÄßÊÑèËØÜÂº∫ÂåñÂ≠¶‰π†Âú®‰∏•Ê†ºÁöÑ‰ª§ÁâåÈ¢ÑÁÆó‰∏ã‰ºòÂåñÂ∫èÂàóÂÜ≥Á≠ñÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂ≠¶‰π†ÈïøÊúüÁöÑËÆ°ÁÆóÂàÜÈÖçÁ≠ñÁï•„ÄÇ', title='È¢ÑÁÆóÊé®ÁêÜÔºöËÆ©Ê®°ÂûãÊõ¥ËÅ™ÊòéÁöÑËÆ°ÁÆóÂÜ≥Á≠ñ'))
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#data", "#training", "#dataset", "#audio", "#video", "#multimodal", "#architecture"], "emoji": "üé¨", "ru": {"title": "–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Ä–æ–∂–¥–µ–Ω–∏–µ –∑–≤—É–∫–∞ –∏ –æ–±—Ä–∞–∑–∞: –µ–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Klear ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π –≥–µ–Ω–µ
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#video", "#synthetic", "#3d", "#multimodal", "#robotics"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 4D –¥–∏–Ω–∞–º–∏–∫–∏ –∏–∑ 2D –≤–∏–¥–µ–æ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª", "desc": "CHORD ‚Äî —ç—Ç–æ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ 2D –≤–∏–¥–µ–æ –≤ –≠
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#interpretability", "#plp", "#benchmark", "#rl"], "emoji": "‚úÖ", "ru": {"title": "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —á–µ–∫–ª–∏—Å—Ç—ã –≤–º–µ—Å—Ç–æ –∫–æ–¥–∞: –∞–≥–µ–Ω—Ç–∏–≤–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –º–µ—Ç–æ–¥ Agentic Rubrics –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –±
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#data", "#training", "#agents", "#dataset", "#plp", "#benchmark", "#rl", "#optimization", "#open_source", "#science", "#small_models"], "emoji": "‚öõÔ∏è", "ru": {"title": "–Ø–∑—ã–∫ –¥–ª—è –Ω–∞—É–∫–∏: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏", "desc": "MDAgent2 ‚Äî —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#training", "#rl", "#alignment", "#optimization"], "emoji": "üé≤", "ru": {"title": "–≠–Ω—Ç—Ä–æ–ø–∏—è –∫–∞–∫ –∫–ª—é—á –∫ –ª—É—á—à–µ–º—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è E-GRPO ‚Äî –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π —ç–Ω—Ç—Ä–æ–ø–∏—é, –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ 
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#benchmark", "#healthcare", "#science"], "emoji": "üî¨", "ru": {"title": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω EpiQAL ‚Äî –ø–µ—Ä–≤—ã–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è 
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#open_source", "#security", "#dataset", "#benchmark"], "emoji": "üîí", "ru": {"title": "–ï–¥–∏–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RedBench ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π 37 —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#long_context", "#open_source", "#hallucinations", "#science"], "emoji": "ü§ñ", "ru": {"title": "–ù–∞ –ø—É—Ç–∏ –∫ –Ω–∞–¥–µ–∂–Ω—ã–º AI-—É—á–µ–Ω—ã–º: —É—Ä–æ–∫–∏ –∏–∑ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫", "desc": "–í —Å—Ç–∞—Ç—å–µ –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–º–æ—â—å—é —Å–∏—Å—Ç–µ–º—ã –∏–∑ —à–µ—Å
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#reasoning", "#training", "#cv", "#rl", "#optimization", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ì–ª—É–±–æ–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ reinforcement learning –≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "ThinkRL-Edit ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ reinforcement learning –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ
[09.01.2026 01:50] Using data from previous issue: {"categories": [], "emoji": "üìö", "ru": {"title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç L2T ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Å —è–≤–Ω—ã–º–∏ –∑
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#multilingual", "#benchmark"], "emoji": "üë•", "ru": {"title": "–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ: —É–ø—Ä–æ—â–µ–Ω–∏–µ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ NLP —á–µ—Ä–µ–∑ Pearmut", "desc": "Pearmut ‚Äî —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞, –∫–æ—Ç–æ—Ä–∞—è —É–ø—Ä–æ—â–∞–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –ª—é–¥—å–º–∏ –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –æ–±—Ä–∞–±
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#cv", "#training", "#architecture"], "emoji": "üèóÔ∏è", "ru": {"title": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –æ—Å—Ç–∞—Ç–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –≤–∏–¥–µ–Ω–∏–µ –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Residual Tokenizer, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –æ—Å—Ç–∞—Ç–∫–∏
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#rag", "#graphs", "#long_context", "#interpretability", "#reasoning", "#agents", "#architecture"], "emoji": "üß†", "ru": {"title": "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", "desc": "MAGMA –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ–≥—Ä–∞—Ñ–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–∞–º—è—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–æ–ª–≥–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂
[09.01.2026 01:50] Using data from previous issue: {"categories": ["#3d", "#multimodal", "#video", "#architecture", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–°–æ–≤–º–µ—Å—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –∏ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ —á–µ—Ä–µ–∑ –≤—ã—Ä–∞–≤–Ω–µ–Ω–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è", "desc": "Gen3R –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–æ–¥–µ–ª–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω. 
[09.01.2026 01:50] Using data from previous issue: {"categories": [], "emoji": "üó∫Ô∏è", "ru": {"title": "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø–ª–æ—Ç–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –ì–∞—É—Å—Å–æ–≤–∞ SLAM", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç RGS-SLAM, –º–æ—â–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ì–∞—É—Å—Å–æ–≤—ã—Ö —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ü–µ–Ω—ã. –í–º–µ—Å—Ç–æ –ø–æ—Å—Ç–µ–ø
[09.01.2026 01:50] Renaming data file.
[09.01.2026 01:50] Renaming previous data. hf_papers.json to ./d/2026-01-09.json
[09.01.2026 01:50] Saving new data file.
[09.01.2026 01:50] Generating page.
[09.01.2026 01:50] Renaming previous page.
[09.01.2026 01:50] Renaming previous data. index.html to ./d/2026-01-09.html
[09.01.2026 01:50] Writing result.
[09.01.2026 01:50] Renaming log file.
[09.01.2026 01:50] Renaming previous data. log.txt to ./logs/2026-01-09_last_log.txt
