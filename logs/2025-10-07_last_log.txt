[07.10.2025 14:13] Read previous papers.
[07.10.2025 14:13] Generating top page (month).
[07.10.2025 14:13] Writing top page (month).
[07.10.2025 15:14] Read previous papers.
[07.10.2025 15:14] Get feed.
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05096
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05034
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05094
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05025
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03632
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04800
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03871
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05091
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03561
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00263
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04996
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02919
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03264
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05069
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03755
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04618
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04290
[07.10.2025 15:14] Extract page data from URL. URL: https://huggingface.co/papers/2510.03528
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04673
[07.10.2025 15:14] Extract page data from URL. URL: https://huggingface.co/papers/2510.00499
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00732
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04434
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04016
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05093
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04860
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24613
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02350
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05081
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05040
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04786
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04399
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04226
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04136
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01586
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00507
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04995
[07.10.2025 15:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04979
[07.10.2025 15:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[07.10.2025 15:14] No deleted papers detected.
[07.10.2025 15:14] Downloading and parsing papers (pdf, html). Total: 37.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05096.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05096.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05096.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05034.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05034.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05034.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05094.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05094.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05094.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05025.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05025.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05025.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.03632.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.03632.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.03632.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04800.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04800.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04800.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.03871.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.03871.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.03871.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05091.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05091.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05091.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.03561.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.03561.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.03561.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.00263.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.00263.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.00263.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04996.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04996.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04996.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.02919.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.02919.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.02919.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.03264.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.03264.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.03264.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05069.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05069.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05069.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.03755.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.03755.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.03755.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04618.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04618.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04618.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04290.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04290.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04290.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.03528.
[07.10.2025 15:14] Downloading paper 2510.03528 from http://arxiv.org/pdf/2510.03528v1...
[07.10.2025 15:14] Extracting affiliations from text.
[07.10.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance Ahmed Alajrami Xingwei Tan Nikolaos Aletras Department of Computer Science University of Sheffield, UK {ajsalajrami1, xingwei.tan, n.aletras}@sheffield.ac.uk 5 2 0 2 3 ] . [ 1 8 2 5 3 0 . 0 1 5 2 : r a "
[07.10.2025 15:14] Response: ```python
["Department of Computer Science University of Sheffield, UK"]
```
[07.10.2025 15:14] Deleting PDF ./assets/pdf/2510.03528.pdf.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04673.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04673.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04673.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.00499.
[07.10.2025 15:14] Downloading paper 2510.00499 from http://arxiv.org/pdf/2510.00499v2...
[07.10.2025 15:14] Extracting affiliations from text.
[07.10.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 ] . [ 2 9 9 4 0 0 . 0 1 5 2 : r MOSS-Speech: Towards True Speech-to-Speech Models Without Text Guidance SII OpenMOSS Team1,2,3, 1Shanghai Innovation Institute 2Fudan University 3MOSI "
[07.10.2025 15:14] Response: ```python
["Shanghai Innovation Institute", "Fudan University", "MOSI"]
```
[07.10.2025 15:14] Deleting PDF ./assets/pdf/2510.00499.pdf.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.00732.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.00732.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.00732.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04434.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04434.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04434.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04016.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04016.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04016.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05093.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05093.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05093.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04860.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04860.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04860.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2509.24613.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2509.24613.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2509.24613.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.02350.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.02350.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.02350.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05081.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05081.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05081.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.05040.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.05040.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.05040.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04786.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04786.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04786.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04399.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04399.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04399.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04226.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04226.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04226.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04136.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04136.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04136.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.01586.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.01586.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.01586.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.00507.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.00507.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.00507.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04995.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04995.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04995.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Downloading and parsing paper https://huggingface.co/papers/2510.04979.
[07.10.2025 15:14] Extra JSON file exists (./assets/json/2510.04979.json), skip PDF parsing.
[07.10.2025 15:14] Paper image links file exists (./assets/img_data/2510.04979.json), skip HTML parsing.
[07.10.2025 15:14] Success.
[07.10.2025 15:14] Enriching papers with extra data.
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 0. PaperTalker is a multi-agent framework that automates academic presentation video generation by integrating slide generation, layout refinement, subtitling, speech synthesis, and talking-head rendering, outperforming existing methods.  					AI-generated summary 				 Academic presentation videos have...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 1. This survey examines post-training methodologies for Video-LMMs, focusing on supervised fine-tuning, reinforcement learning, and test-time scaling, while addressing challenges in video understanding.  					AI-generated summary 				 Video understanding represents the most challenging frontier in comp...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 2. VChain enhances video generation by integrating visual reasoning from multimodal models to guide sparse tuning of a pre-trained video generator.  					AI-generated summary 				 Recent video generation models can produce smooth and visually appealing clips, but they often struggle to synthesize compl...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 3. Imperceptible jailbreaks using Unicode variation selectors enable high attack success rates against aligned LLMs without visible prompt modifications.  					AI-generated summary 				 Jailbreaking attacks on the vision modality typically rely on imperceptible adversarial perturbations, whereas attack...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 4. Mutual Information Tree Search (MITS) uses information-theoretic principles to guide and evaluate reasoning paths in large language models, improving performance and efficiency.  					AI-generated summary 				 Tree search has become as a representative framework for test-time reasoning with large la...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 5. A comprehensive evaluation of hybrid language models combining self-attention with structured state space models, analyzing inter-layer and intra-layer fusion strategies, and providing design recommendations.  					AI-generated summary 				 Recent progress in large language models demonstrates that ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 6. Joint optimal scaling of model and dataset sizes in deep learning is governed by the operator norm of the output layer, a phenomenon termed norm transfer, which provides a necessary condition for optimal learning rate and batch size.  					AI-generated summary 				 Despite recent progress in optimal...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 7. A comprehensive investigation into generating and editing structured visuals using a unified model integrating a VLM with FLUX Kontext, achieving strong performance and introducing a new benchmark and evaluation metric.  					AI-generated summary 				 While modern visual generation models excel at c...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 8. The Reactive Transformer (RxT) addresses the limitations of stateless Transformers in conversational AI by using an event-driven paradigm with a fixed-size Short-Term Memory (STM) system, achieving linear scaling and low latency.  					AI-generated summary 				 The Transformer architecture has becom...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 9. A framework for calibrating probabilistic autoraters to preference distributions using supervised fine-tuning and reinforcement learning improves alignment with human values and reduces bias.  					AI-generated summary 				 The alignment of large language models (LLMs) with human values increasingly...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 10. Reinforce-Ada is an adaptive sampling framework for online reinforcement learning post-training of large language models, which accelerates convergence and improves performance by dynamically reallocating sampling effort based on prompt uncertainty.  					AI-generated summary 				 Reinforcement lear...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 11. SRGen, a lightweight test-time framework, improves LLM reasoning by dynamically identifying and correcting high-uncertainty tokens during generation, leading to better single-pass quality and self-consistency.  					AI-generated summary 				 Large language models (LLMs) increasingly solve complex re...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 12. Introducing reasoning data during pretraining significantly enhances LLM performance compared to post-training, with pretraining benefiting more from diverse data patterns while SFT benefits more from high-quality data.  					AI-generated summary 				 The prevailing paradigm for enhancing the reason...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 13. SwiReasoning, a training-free framework for LLMs, dynamically switches between explicit and latent reasoning to improve accuracy and token efficiency.  					AI-generated summary 				 Recent work shows that, beyond discrete reasoning through explicit chain-of-thought steps, which are limited by the b...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 14. Code4MeV2 is an open-source code completion plugin for JetBrains IDEs that provides a transparent data collection framework for researchers, offering industry-level performance and user feedback.  					AI-generated summary 				 The adoption of AI-powered code completion tools in software development...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 15. ACE, a framework for adaptive context engineering, enhances LLM applications by preserving detailed knowledge through structured updates, outperforming baselines in agent and domain-specific tasks with reduced adaptation costs.  					AI-generated summary 				 Large language model (LLM) applications ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 16. ChronoEdit addresses physical consistency in image editing by reframing it as a video generation problem, leveraging pretrained video models and temporal reasoning tokens.  					AI-generated summary 				 Recent advances in large generative models have significantly advanced image editing and in-cont...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 17. Introducing perturbations in instruction-tuning data can enhance large language models' resistance to noisy instructions and improve performance on benchmarks.  					AI-generated summary 				 Instruction-tuning plays a vital role in enhancing the task-solving abilities of large language models (LLMs...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 18. Watch & Learn converts web demonstration videos into UI trajectories to enhance computer use agents, improving both in-context demonstrations and supervised training.  					AI-generated summary 				 Computer use agents (CUAs) need to plan task workflows grounded in diverse, ever-changing application...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 19. MOSS-Speech is a speech-to-speech large language model that directly processes and generates speech without text intermediates, achieving state-of-the-art performance in spoken question answering and competitive text performance.  					AI-generated summary 				 Spoken dialogue systems often rely on ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 20. A novel data augmentation pipeline enhances the robustness and generalizability of large language models for formal theorem proving by addressing syntactic and semantic symmetry and varying difficulty levels, leading to state-of-the-art performance on multiple benchmarks.  					AI-generated summary ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 21. The study reveals that ACL authors are more likely to address social good concerns in non-ACL venues, and most NLP4SG publications are from non-ACL authors.  					AI-generated summary 				 The social impact of Natural Language Processing (NLP) is increasingly important, with a rising community focus...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 22. Real-time Thai text-only end-of-turn detection using zero-shot and few-shot prompting of compact LLMs and lightweight transformers achieves near-instant accuracy suitable for on-device agents.  					AI-generated summary 				 Fluid voice-to-voice interaction requires reliable and low-latency detectio...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 23. A framework using Cross-Character Embedding and Cross-Character Augmentation enables natural interactions between characters from different worlds while preserving their identity and style.  					AI-generated summary 				 Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where cha...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 24. Self-evolving LLM agents can abandon alignment constraints post-deployment, leading to rapid misalignment and collective failure in multi-agent systems.  					AI-generated summary 				 As Large Language Model (LLM) agents increasingly gain self-evolutionary capabilities to adapt and refine their str...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 25. A hierarchical benchmark for Korean-English code-switching in ASR evaluates model performance and demonstrates improvement through fine-tuning with code-switched data.  					AI-generated summary 				 Despite advances in multilingual automatic speech recognition (ASR), code-switching (CS), the mixing...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 26. LLMSQL is a revised and cleaned version of WikiSQL designed for modern large language models, providing clean questions and full SQL queries for straightforward evaluation in text-to-SQL tasks.  					AI-generated summary 				 Converting natural language questions into SQL queries (Text-to-SQL) enabl...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 27. A method for disentangled and continuous text-to-image editing uses token-level manipulation of text embeddings with sparse autoencoders to control image attributes smoothly.  					AI-generated summary 				 Large-scale text-to-image diffusion models have become the backbone of modern image editing, ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 28. HEX, a training-free inference method for diffusion-based large language models, ensembles diverse generation paths to improve accuracy across various reasoning benchmarks without additional training.  					AI-generated summary 				 Diffusion-based large language models (dLLMs) are trained flexibly ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 29. Test-time curriculum (TTC-RL) uses reinforcement learning to dynamically select task-relevant data, improving model performance on challenging benchmarks without human curation.  					AI-generated summary 				 Humans are good at learning on the job: We learn how to solve the tasks we face as we go a...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 30. Self-improving systems face a utility-learning tension that can degrade their ability to learn and generalize, requiring capacity bounds to ensure safe self-modification.  					AI-generated summary 				 As systems trend toward superintelligence, a natural modeling premise is that agents can self-imp...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 31. A study measures epistemic diversity in LLM outputs, showing that newer models are more diverse but still less so than web searches, and that RAG improves diversity with cultural context variations.  					AI-generated summary 				 Large language models (LLMs) tend to generate lexically, semantically...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 32. MoME, a novel framework integrating sparse Mixture-of-Experts into Matryoshka representation learning, enhances audio-visual speech recognition by dynamically adjusting capacity across scales and modalities, achieving state-of-the-art performance with fewer parameters.  					AI-generated summary 			...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 33. AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning framework, enhances safety and utility in LLM-based multi-agent systems by internally optimizing task agents against evolving attacks without additional overhead.  					AI-generated summary 				 LLM-based multi-agent systems excel at ...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 34. Graph2Eval, a knowledge graph-based framework, generates multimodal and interactive tasks to comprehensively evaluate agents' reasoning, collaboration, and web interaction capabilities.  					AI-generated summary 				 As multimodal LLM-driven agents continue to advance in autonomy and generalization...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 35. Power transforms are extended to federated learning to improve numerical stability and robustness.  					AI-generated summary 				 Power transforms are popular parametric techniques for making data more Gaussian-like, and are widely used as preprocessing steps in statistical analysis and machine lea...
[07.10.2025 15:14] ********************************************************************************
[07.10.2025 15:14] Abstract 36. A method for approximating ROC and PR curves in federated learning under distributed differential privacy ensures high accuracy, minimal communication, and strong privacy guarantees.  					AI-generated summary 				 Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are fundamen...
[07.10.2025 15:14] Read previous papers.
[07.10.2025 15:14] Generating reviews via LLM API.
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset", "#multimodal", "#open_source", "#agents"], "emoji": "🎓", "ru": {"title": "Автоматическая генерация академических презентаций с помощью мультиагентной системы", "desc": "PaperTalker — это первый мультиагентный фреймворк для автоматического создани
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#training", "#survey", "#reasoning", "#multimodal", "#video", "#optimization"], "emoji": "🎥", "ru": {"title": "Пост-тренировка Video-LMMs: ключ к пониманию видео", "desc": "Эта статья рассматривает методы пост-тренировки для Video-LMMs, включая супервизионное дообучени
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#games", "#inference", "#multimodal", "#video", "#optimization"], "emoji": "🔗", "ru": {"title": "Визуальное мышление для улучшения видеогенерации", "desc": "VChain — это новый подход, который использует мультимодальные модели (например, GPT-4o) для улучшения генерации видео. Мультим
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#alignment", "#security", "#agents", "#multimodal"], "emoji": "👻", "ru": {"title": "Невидимые атаки: как Unicode-символы обманывают защиту LLM", "desc": "Исследователи обнаружили новый способ джейлбрейка LLM с помощью невидимых Unicode-символов, называемых селекторами вариаций. Эти 
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#reasoning", "#training", "#architecture"], "emoji": "🌳", "ru": {"title": "Информационная теория направляет рассуждения LLM через умный древовидный поиск", "desc": "Статья представляет MITS — новый метод древовидного поиска для улучшения рассуждений в 
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#training", "#optimization"], "emoji": "🔀", "ru": {"title": "Оптимальный рецепт гибридных архитектур: как правильно смешивать attention и Mamba", "desc": "Исследователи провели системное сравнение гибридных архитектур языковых моделей, которые комби
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#training", "#optimization"], "emoji": "⚖️", "ru": {"title": "Норма оператора как ключ к оптимальному масштабированию", "desc": "Исследователи обнаружили, что оптимальное совместное масштабирование размера модели и датасета в deep learning определяется единственным инвариантом — нор
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#training", "#survey", "#games", "#reasoning", "#dataset", "#data", "#multimodal", "#open_source", "#optimization", "#interpretability"], "emoji": "📊", "ru": {"title": "Единая модель для генерации и редактирования структурированных изображений", "desc": "Современные мо
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#long_context", "#training", "#architecture", "#synthetic"], "emoji": "🔄", "ru": {"title": "Реактивный Transformer: постоянная память для экономичных диалогов", "desc": "Авторы предлагают архитектуру Reactive Transformer (RxT), которая решает проблему обработки длинных диалогов в co
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#alignment", "#training", "#ethics", "#rlhf"], "emoji": "⚖️", "ru": {"title": "Автооценщики, настроенные на распределение предпочтений людей", "desc": "Статья предлагает framework для калибровки вероятностных автооценщиков (autoraters) - LLM, которые автоматически оценивают ответы д
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#rlhf", "#training", "#rl", "#reasoning", "#optimization"], "emoji": "🎯", "ru": {"title": "Умное распределение ресурсов: адаптивный сэмплирование для RL-обучения LLM", "desc": "Reinforce-Ada — это адаптивный метод для post-training больших языковых моделей с помощью reinforcement le
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#rlhf", "#training", "#math", "#interpretability", "#reasoning"], "emoji": "🔄", "ru": {"title": "Самокоррекция LLM на лету через анализ неопределённости токенов", "desc": "SRGen — это легковесный фреймворк для улучшения рассуждений LLM во время генерации текста. Метод динамически оп
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#data"], "emoji": "🧠", "ru": {"title": "Учить рассуждать нужно с самого начала", "desc": "Исследование показывает, что добавление данных для обучения рассуждениям на этапе pretraining значительно эффективнее (прирост 19%), чем только на эт
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#training", "#reasoning", "#math", "#optimization"], "emoji": "🔀", "ru": {"title": "Умное переключение между явным и скрытым рассуждением для эффективности LLM", "desc": "SwiReasoning — это framework без обучения для LLM, который динамически переключается между явным р
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#agents", "#dataset", "#data", "#open_source", "#plp"], "emoji": "🔬", "ru": {"title": "Открытая платформа для изучения взаимодействия разработчиков с AI-ассистентами", "desc": "Исследователи представили Code4MeV2 — open-source плагин для JetBrains IDE с функциями автодополнения кода
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#training", "#multimodal", "#open_source", "#agents", "#optimization", "#long_context"], "emoji": "📚", "ru": {"title": "Контекст как живой учебник: адаптивное обучение LLM без обновления весов", "desc": "ACE (Agentic Context Engineering) — это фреймворк для адаптации LLM через модиф
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#video", "#games", "#cv", "#reasoning", "#benchmark", "#optimization"], "emoji": "⏱️", "ru": {"title": "Физически правдоподобное редактирование через видео-генерацию", "desc": "ChronoEdit решает проблему физической согласованности при редактировании изображений, переформулируя задач
[07.10.2025 15:14] Querying the API.
[07.10.2025 15:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Introducing perturbations in instruction-tuning data can enhance large language models' resistance to noisy instructions and improve performance on benchmarks.  					AI-generated summary 				 Instruction-tuning plays a vital role in enhancing the task-solving abilities of large language models (LLMs), improving their usability in generating helpful responses on various tasks. However, previous work has demonstrated that they are sensitive to minor variations in instruction phrasing. In this paper, we explore whether introducing perturbations in instruction-tuning data can enhance LLMs' resistance against noisy instructions. We focus on how instruction-tuning with perturbations, such as removing stop words or shuffling words, affects LLMs' performance on the original and perturbed versions of widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics and potential shifts in model behavior. Surprisingly, our results suggest that instruction-tuning on perturbed instructions can, in some cases, improve downstream performance. These findings highlight the importance of including perturbed instructions in instruction-tuning, which can make LLMs more resilient to noisy user inputs.
[07.10.2025 15:14] Response: ```json
{
  "desc": "Исследование показывает, что добавление искажений в данные для instruction-tuning может улучшить устойчивость больших языковых моделей к зашумленным инструкциям. Авторы экспериментировали с различными типами возмущений, такими как удаление стоп-слов или перестановка слов в инструкциях. Результаты на бенчмарках MMLU, BBH и GSM8K продемонстрировали, что обучение на искаженных инструкциях может неожиданно улучшить производительность модели. Работа подчеркивает важность включения возмущенных инструкций в процесс обучения для повышения робастности LLM к шумным пользовательским запросам.",
  "emoji": "🔀",
  "title": "Шум в обучении делает LLM устойчивее к неточным инструкциям"
}
```
[07.10.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Introducing perturbations in instruction-tuning data can enhance large language models' resistance to noisy instructions and improve performance on benchmarks.  					AI-generated summary 				 Instruction-tuning plays a vital role in enhancing the task-solving abilities of large language models (LLMs), improving their usability in generating helpful responses on various tasks. However, previous work has demonstrated that they are sensitive to minor variations in instruction phrasing. In this paper, we explore whether introducing perturbations in instruction-tuning data can enhance LLMs' resistance against noisy instructions. We focus on how instruction-tuning with perturbations, such as removing stop words or shuffling words, affects LLMs' performance on the original and perturbed versions of widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics and potential shifts in model behavior. Surprisingly, our results suggest that instruction-tuning on perturbed instructions can, in some cases, improve downstream performance. These findings highlight the importance of including perturbed instructions in instruction-tuning, which can make LLMs more resilient to noisy user inputs."

[07.10.2025 15:14] Response: ```python
['DATA', 'BENCHMARK', 'TRAINING']
```
[07.10.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Introducing perturbations in instruction-tuning data can enhance large language models' resistance to noisy instructions and improve performance on benchmarks.  					AI-generated summary 				 Instruction-tuning plays a vital role in enhancing the task-solving abilities of large language models (LLMs), improving their usability in generating helpful responses on various tasks. However, previous work has demonstrated that they are sensitive to minor variations in instruction phrasing. In this paper, we explore whether introducing perturbations in instruction-tuning data can enhance LLMs' resistance against noisy instructions. We focus on how instruction-tuning with perturbations, such as removing stop words or shuffling words, affects LLMs' performance on the original and perturbed versions of widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics and potential shifts in model behavior. Surprisingly, our results suggest that instruction-tuning on perturbed instructions can, in some cases, improve downstream performance. These findings highlight the importance of including perturbed instructions in instruction-tuning, which can make LLMs more resilient to noisy user inputs."

[07.10.2025 15:14] Response: ```python
["OPTIMIZATION", "HALLUCINATIONS"]
```
[07.10.2025 15:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates how adding small changes, or perturbations, to instruction-tuning data can help large language models (LLMs) better handle noisy instructions. The authors found that by modifying the instructions—like removing unnecessary words or rearranging them—LLMs can perform better on various benchmarks. They tested this approach on popular datasets and observed that it sometimes led to improved performance, even when the instructions were altered. The study emphasizes the value of using perturbed instructions in training to make LLMs more robust against variations in user input.","title":"Enhancing LLM Resilience with Perturbed Instructions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates how adding small changes, or perturbations, to instruction-tuning data can help large language models (LLMs) better handle noisy instructions. The authors found that by modifying the instructions—like removing unnecessary words or rearranging them—LLMs can perform better on various benchmarks. They tested this approach on popular datasets and observed that it sometimes led to improved performance, even when the instructions were altered. The study emphasizes the value of using perturbed instructions in training to make LLMs more robust against variations in user input.', title='Enhancing LLM Resilience with Perturbed Instructions'))
[07.10.2025 15:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了在指令调优数据中引入扰动是否能增强大型语言模型（LLMs）对噪声指令的抵抗力。研究表明，指令调优在提升LLMs的任务解决能力方面至关重要，但它们对指令措辞的细微变化非常敏感。通过对指令调优数据进行扰动处理，如去除停用词或打乱词序，研究了其对LLMs在标准基准（如MMLU、BBH、GSM8K）上的表现影响。结果显示，在某些情况下，使用扰动指令进行调优可以提高下游任务的性能，强调了在指令调优中包含扰动指令的重要性。","title":"引入扰动，提升模型抗噪声能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文探讨了在指令调优数据中引入扰动是否能增强大型语言模型（LLMs）对噪声指令的抵抗力。研究表明，指令调优在提升LLMs的任务解决能力方面至关重要，但它们对指令措辞的细微变化非常敏感。通过对指令调优数据进行扰动处理，如去除停用词或打乱词序，研究了其对LLMs在标准基准（如MMLU、BBH、GSM8K）上的表现影响。结果显示，在某些情况下，使用扰动指令进行调优可以提高下游任务的性能，强调了在指令调优中包含扰动指令的重要性。', title='引入扰动，提升模型抗噪声能力'))
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#dataset", "#data", "#open_source", "#agents"], "emoji": "🎥", "ru": {"title": "Обучение AI-агентов управлению компьютером через просмотр видео из интернета", "desc": "Статья представляет фреймворк Watch & Learn, который преобразует видео с демонстрациями 
[07.10.2025 15:14] Querying the API.
[07.10.2025 15:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MOSS-Speech is a speech-to-speech large language model that directly processes and generates speech without text intermediates, achieving state-of-the-art performance in spoken question answering and competitive text performance.  					AI-generated summary 				 Spoken dialogue systems often rely on cascaded pipelines that transcribe, process, and resynthesize speech. While effective, this design discards paralinguistic cues and limits expressivity. Recent end-to-end methods reduce latency and better preserve these cues, yet still rely on text intermediates, creating a fundamental bottleneck. We present MOSS-Speech, a true speech-to-speech large language model that directly understands and generates speech without relying on text guidance. Our approach combines a modality-based layer-splitting architecture with a frozen pre-training strategy, preserving the reasoning and knowledge of pretrained text LLMs while adding native speech capabilities. Experiments show that our model achieves state-of-the-art results in spoken question answering and delivers comparable speech-to-speech performance relative to existing text-guided systems, while still maintaining competitive text performance. By narrowing the gap between text-guided and direct speech generation, our work establishes a new paradigm for expressive and efficient end-to-end speech interaction.
[07.10.2025 15:14] Response: ```json
{
  "title": "Речь напрямую: LLM без текстовых посредников",
  "emoji": "🗣️",
  "desc": "MOSS-Speech — это speech-to-speech LLM, которая обрабатывает и генерирует речь напрямую, без промежуточного преобразования в текст. Модель использует архитектуру с разделением слоёв по модальностям и замороженную предобученную текстовую LLM, сохраняя её знания и добавляя нативные речевые способности. В отличие от каскадных систем (распознавание→обработка→синтез), такой подход сохраняет паралингвистические особенности речи и снижает latency. MOSS-Speech достигает state-of-the-art результатов в spoken question answering и сопоставимого качества с text-guided системами, открывая новую парадигму для выразительного речевого взаимодействия."
}
```
[07.10.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MOSS-Speech is a speech-to-speech large language model that directly processes and generates speech without text intermediates, achieving state-of-the-art performance in spoken question answering and competitive text performance.  					AI-generated summary 				 Spoken dialogue systems often rely on cascaded pipelines that transcribe, process, and resynthesize speech. While effective, this design discards paralinguistic cues and limits expressivity. Recent end-to-end methods reduce latency and better preserve these cues, yet still rely on text intermediates, creating a fundamental bottleneck. We present MOSS-Speech, a true speech-to-speech large language model that directly understands and generates speech without relying on text guidance. Our approach combines a modality-based layer-splitting architecture with a frozen pre-training strategy, preserving the reasoning and knowledge of pretrained text LLMs while adding native speech capabilities. Experiments show that our model achieves state-of-the-art results in spoken question answering and delivers comparable speech-to-speech performance relative to existing text-guided systems, while still maintaining competitive text performance. By narrowing the gap between text-guided and direct speech generation, our work establishes a new paradigm for expressive and efficient end-to-end speech interaction."

[07.10.2025 15:14] Response: ```python
['AUDIO', 'MULTIMODAL', 'ARCHITECTURE']
```
[07.10.2025 15:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MOSS-Speech is a speech-to-speech large language model that directly processes and generates speech without text intermediates, achieving state-of-the-art performance in spoken question answering and competitive text performance.  					AI-generated summary 				 Spoken dialogue systems often rely on cascaded pipelines that transcribe, process, and resynthesize speech. While effective, this design discards paralinguistic cues and limits expressivity. Recent end-to-end methods reduce latency and better preserve these cues, yet still rely on text intermediates, creating a fundamental bottleneck. We present MOSS-Speech, a true speech-to-speech large language model that directly understands and generates speech without relying on text guidance. Our approach combines a modality-based layer-splitting architecture with a frozen pre-training strategy, preserving the reasoning and knowledge of pretrained text LLMs while adding native speech capabilities. Experiments show that our model achieves state-of-the-art results in spoken question answering and delivers comparable speech-to-speech performance relative to existing text-guided systems, while still maintaining competitive text performance. By narrowing the gap between text-guided and direct speech generation, our work establishes a new paradigm for expressive and efficient end-to-end speech interaction."

[07.10.2025 15:14] Response: ```python
[]
```
[07.10.2025 15:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MOSS-Speech is a novel speech-to-speech large language model that processes and generates spoken language directly, bypassing the need for text intermediates. This model addresses limitations of traditional systems that often lose important vocal cues and expressiveness due to their reliance on text transcription. By utilizing a unique architecture that separates modalities and leveraging pre-trained text models, MOSS-Speech enhances both spoken question answering and overall speech performance. The results demonstrate that it not only matches but also improves upon existing text-guided systems, paving the way for more natural and efficient speech interactions.","title":"Revolutionizing Speech Interaction with Direct Speech-to-Speech Processing"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MOSS-Speech is a novel speech-to-speech large language model that processes and generates spoken language directly, bypassing the need for text intermediates. This model addresses limitations of traditional systems that often lose important vocal cues and expressiveness due to their reliance on text transcription. By utilizing a unique architecture that separates modalities and leveraging pre-trained text models, MOSS-Speech enhances both spoken question answering and overall speech performance. The results demonstrate that it not only matches but also improves upon existing text-guided systems, paving the way for more natural and efficient speech interactions.', title='Revolutionizing Speech Interaction with Direct Speech-to-Speech Processing'))
[07.10.2025 15:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MOSS-Speech是一种直接处理和生成语音的大型语言模型，能够在没有文本中介的情况下进行语音到语音的转换。该模型通过结合基于模态的层分离架构和冻结预训练策略，保留了预训练文本语言模型的推理和知识，同时增加了原生语音能力。实验结果表明，MOSS-Speech在口语问答任务中达到了最先进的性能，并且在语音到语音的表现上与现有的文本引导系统相当。通过缩小文本引导和直接语音生成之间的差距，我们的工作为高效且富有表现力的端到端语音交互建立了新的范式。","title":"MOSS-Speech：无文本的语音交互新范式"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MOSS-Speech是一种直接处理和生成语音的大型语言模型，能够在没有文本中介的情况下进行语音到语音的转换。该模型通过结合基于模态的层分离架构和冻结预训练策略，保留了预训练文本语言模型的推理和知识，同时增加了原生语音能力。实验结果表明，MOSS-Speech在口语问答任务中达到了最先进的性能，并且在语音到语音的表现上与现有的文本引导系统相当。通过缩小文本引导和直接语音生成之间的差距，我们的工作为高效且富有表现力的端到端语音交互建立了新的范式。', title='MOSS-Speech：无文本的语音交互新范式'))
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#reasoning", "#data", "#dataset", "#optimization", "#benchmark", "#training"], "emoji": "🔄", "ru": {"title": "Симметрия и сложность: новый рецепт для обучения AI-доказателей теорем", "desc": "Исследователи разработали новый подход к аугментации данных для улучшения способности больш
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#ethics", "#survey"], "emoji": "🌍", "ru": {"title": "NLP для социального блага живёт за пределами ACL", "desc": "Исследование анализирует публикации по NLP для социального блага (NLP4SG), связанные с целями устойчивого развития ООН. Оказалось, что авторы из ACL-сообщества чаще публи
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#low_resource", "#audio", "#small_models", "#agents", "#dataset", "#training"], "emoji": "🇹🇭", "ru": {"title": "Мгновенное определение конца реплики для тайского языка", "desc": "Исследователи разработали систему для определения момента, когда пользователь закончил говорить, специал
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#multimodal", "#story_generation", "#video"], "emoji": "🎭", "ru": {"title": "Персонажи из разных миров: естественное взаимодействие без потери стиля", "desc": "В статье представлена новая методика, позволяющая персонажам из разных миров взаимодействовать ес
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#rl", "#ethics", "#agents", "#alignment"], "emoji": "⚠️", "ru": {"title": "Alignment LLM-агентов оказался хрупким и деградирует в процессе самообучения", "desc": "Исследование выявляет критический риск для самообучающихся LLM-агентов после развертывания: процесс разруш
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#training", "#low_resource", "#dataset", "#audio", "#machine_translation", "#multilingual"], "emoji": "🔀", "ru": {"title": "HiKE: иерархический бенчмарк для code-switching в корейско-английской речи", "desc": "Исследователи представили HiKE — первый публично доступный 
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#data", "#benchmark", "#dataset", "#open_source", "#transfer_learning"], "emoji": "🗄️", "ru": {"title": "LLMSQL: чистый бенчмарк для преобразования естественного языка в SQL-запросы", "desc": "LLMSQL — это обновлённая и очищенная версия датасета WikiSQL, специально адаптированная дл
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#multimodal"], "emoji": "🎚️", "ru": {"title": "Точный контроль редактирования изображений через манипуляцию текстовыми эмбеддингами", "desc": "Статья представляет метод улучшенного контроля при редактировании изображений с помощью text-to-image диффузионных моде
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#training", "#reasoning", "#benchmark", "#math", "#inference"], "emoji": "🧠", "ru": {"title": "Новая парадигма для масштабирования тестов в диффузионных LLM", "desc": "В статье рассматривается метод HEX, который улучшает точность диффузионных LLM без д
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training", "#benchmark"], "emoji": "🎯", "ru": {"title": "Обучение на ходу: модель сама выбирает задачи", "desc": "Исследователи предложили метод TTC-RL, который использует reinforcement learning для автоматического составления учебной программы во время тест
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#agents", "#alignment", "#agi", "#rl"], "emoji": "🔄", "ru": {"title": "Парадокс самосовершенствования: как AI может разучиться учиться", "desc": "Исследователи формализовали проблему самомодифицирующихся AI-систем, стремящихся к сверхинтеллекту. Они обнаружили фундаментальное против
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#hallucinations", "#dataset", "#rag", "#ethics", "#multilingual", "#data", "#alignment"], "emoji": "📉", "ru": {"title": "Почему LLM знают меньше, чем поисковик", "desc": "Исследователи измерили эпистемическое разнообразие (вариативность реальных утверждений) в выходных данных LLM и 
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#interpretability", "#multimodal", "#audio", "#training"], "emoji": "🎭", "ru": {"title": "Гибкое распознавание речи с динамическим сжатием и экспертами", "desc": "Статья представляет MoME - новый фреймворк, который объединяет разреженную архитектуру
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#agents", "#security", "#reasoning", "#rl"], "emoji": "🛡️", "ru": {"title": "Встроенная безопасность через коэволюцию агентов без дополнительных затрат", "desc": "AdvEvo-MARL — это фреймворк для обучения мультиагентных систем на основе LLM, который повышает их безопасность через сов
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#games", "#multimodal", "#synthetic", "#agents", "#dataset", "#benchmark", "#reasoning"], "emoji": "🕸️", "ru": {"title": "Граф знаний для автоматической генерации задач оценки AI-агентов", "desc": "Graph2Eval — это фреймворк на основе графов знаний, который автоматически генерирует 
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#training", "#survey", "#optimization", "#data"], "emoji": "⚡", "ru": {"title": "Стабильные степенные преобразования для federated learning", "desc": "В статье анализируются проблемы численной нестабильности при использовании степенных преобразований (power transforms) для нормализа
[07.10.2025 15:14] Using data from previous issue: {"categories": ["#benchmark", "#data", "#healthcare", "#security"], "emoji": "🔒", "ru": {"title": "Приватная оценка качества моделей в федеративном обучении", "desc": "Статья предлагает метод для построения ROC и PR кривых в федеративном обучении с распределённой дифференциальной приватностью. Главн
[07.10.2025 15:14] Renaming data file.
[07.10.2025 15:14] Renaming previous data. hf_papers.json to ./d/2025-10-07.json
[07.10.2025 15:14] Saving new data file.
[07.10.2025 15:14] Generating page.
[07.10.2025 15:14] Renaming previous page.
[07.10.2025 15:14] Renaming previous data. index.html to ./d/2025-10-07.html
[07.10.2025 15:14] Writing result.
[07.10.2025 15:14] Renaming log file.
[07.10.2025 15:14] Renaming previous data. log.txt to ./logs/2025-10-07_last_log.txt
