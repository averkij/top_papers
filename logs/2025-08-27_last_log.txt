[27.08.2025 06:17] Read previous papers.
[27.08.2025 06:17] Generating top page (month).
[27.08.2025 06:17] Writing top page (month).
[27.08.2025 07:11] Read previous papers.
[27.08.2025 07:11] Get feed.
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18124
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19205
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17661
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19209
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18756
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17445
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19247
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17437
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19242
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15774
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18621
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15804
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18773
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18672
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18370
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16697
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19188
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19026
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18271
[27.08.2025 07:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.19202
[27.08.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18192
[27.08.2025 07:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.08.2025 07:11] No deleted papers detected.
[27.08.2025 07:11] Downloading and parsing papers (pdf, html). Total: 21.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.18124.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.18124.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.18124.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.19205.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.19205.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.19205.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.17661.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.17661.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.17661.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.19209.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.19209.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.19209.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.18756.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.18756.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.18756.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.17445.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.17445.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.17445.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.19247.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.19247.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.19247.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.17437.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.17437.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.17437.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.19242.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.19242.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.19242.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.15774.
[27.08.2025 07:11] Downloading paper 2508.15774 from http://arxiv.org/pdf/2508.15774v1...
[27.08.2025 07:11] Extracting affiliations from text.
[27.08.2025 07:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 1 CineScale: Free Lunch in High-Resolution Cinematic Visual Generation Haonan Qiu*, Ning Yu(cid:66), Ziqi Huang, Paul Debevec, Ziwei Liu(cid:66) 5 2 0 2 1 ] . [ 1 4 7 7 5 1 . 8 0 5 2 : r AbstractVisual diffusion models achieve remarkable progress, yet they are typically trained at limited resolutions due to the lack of highresolution data and constrained computation resources, hampering their ability to generate high-fidelity images or videos at higher resolutions. Recent efforts have explored tuning-free strategies to exhibit the untapped potential higher-resolution visual generation of pre-trained these methods are still prone to producing lowmodels. However, quality visual content with repetitive patterns. The key obstacle lies in the inevitable increase in high-frequency information when the model generates visual content exceeding its training resolution, leading to undesirable repetitive patterns deriving from the accumulated errors. In this work, we propose CineScale, novel inference paradigm to enable higher-resolution visual generation. To tackle the various issues introduced by the two types of video generation architectures, we propose dedicated variants tailored to each. Unlike existing baseline methods that are confined to high-resolution T2I and T2V generation, CineScale broadens the scope by enabling high-resolution I2V and V2V synthesis, built atop state-of-the-art open-source video generation frameworks. Extensive experiments validate the superiority of our paradigm in extending the capabilities of higher-resolution visual generation for both image and video models. Remarkably, our approach enables 8k image generation without any fine-tuning, and achieves 4k video generation with only minimal LoRA fine-tuning. Generated video samples are available at our website: https://eyeline-labs.github.io/CineScale/. Index TermsDiffusion Models, Image Generation, Video Generation, High Resolution Diffusi"
[27.08.2025 07:11] Response: ```python
[]
```
[27.08.2025 07:11] Extracting affiliations from text.
[27.08.2025 07:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 1 CineScale: Free Lunch in High-Resolution Cinematic Visual Generation Haonan Qiu*, Ning Yu(cid:66), Ziqi Huang, Paul Debevec, Ziwei Liu(cid:66) 5 2 0 2 1 ] . [ 1 4 7 7 5 1 . 8 0 5 2 : r AbstractVisual diffusion models achieve remarkable progress, yet they are typically trained at limited resolutions due to the lack of highresolution data and constrained computation resources, hampering their ability to generate high-fidelity images or videos at higher resolutions. Recent efforts have explored tuning-free strategies to exhibit the untapped potential higher-resolution visual generation of pre-trained these methods are still prone to producing lowmodels. However, quality visual content with repetitive patterns. The key obstacle lies in the inevitable increase in high-frequency information when the model generates visual content exceeding its training resolution, leading to undesirable repetitive patterns deriving from the accumulated errors. In this work, we propose CineScale, novel inference paradigm to enable higher-resolution visual generation. To tackle the various issues introduced by the two types of video generation architectures, we propose dedicated variants tailored to each. Unlike existing baseline methods that are confined to high-resolution T2I and T2V generation, CineScale broadens the scope by enabling high-resolution I2V and V2V synthesis, built atop state-of-the-art open-source video generation frameworks. Extensive experiments validate the superiority of our paradigm in extending the capabilities of higher-resolution visual generation for both image and video models. Remarkably, our approach enables 8k image generation without any fine-tuning, and achieves 4k video generation with only minimal LoRA fine-tuning. Generated video samples are available at our website: https://eyeline-labs.github.io/CineScale/. Index TermsDiffusion Models, Image Generation, Video Generation, High ResolutionDiffusion models have revolutionized visual generation [1] [6], empowering individuals without any artistic expertise to effortlessly create distinctive and personalized designs, graphics, and short films using specific textual descriptions. Nonetheless, current visual diffusion models are generally trained on data with limited resolution, such as 5122 for SD 1.5 [7], 10242 for SDXL [1], and 320 512 for VideoCrafter2 [4], hampering their ability to generate highfidelity images or videos at higher resolutions. Given the scarcity of high-resolution visual data and the substantially greater model capacity required for modeling such *This work was done during an internship at Netflix Eyeline Studios, (cid:66)corresponding authors H. Qiu, Z. Huang, and Z. Liu are with Nanyang Technological University. Email: {HAONAN002, ZIQI002}@e.ntu.edu.sg, ziwei.liu@ntu.edu.sg H. Qiu, N. Yu, and P. Debevec are with Netflix Eyeline Studios. Email: {ning.yu, debevec}@scanlinevfx.com data, recent efforts have focused on employing tuning-free strategies for high-resolution visual generation to inherit the strong generation capacities of existing pre-trained diffusion models. Despite the advances achieved by existing methods, they are still prone to producing low-quality images or videos, particularly manifesting as repetitive object occurrences and unreasonable object structures. ScaleCrafter [8] puts forward that the primary cause of the object repetition issue is the limited convolutional receptive field and uses dilated convolutional layers to achieve tuning-free higher-resolution sampling. But the generated results of ScaleCrafter still suffer from the problem of local repetition. Inspired by MultiDiffusion [9] fusing the local patches of the whole images, DemoFusion [10] designed mechanism by fusing the local patches and global patches, almost eliminating the local repetition. Essentially, this solution just transfers the extra signal of the object to the background, leading to small object repetition generation. FouriScale [11] reduces those extra signals by removing the high-frequency signals of the latent before the convolution operation. Although FouriScale completely eliminates all types of repetition, the generated results always have weird colors and textures due to its violent editing on the frequency domain. To generate satisfactory visual contents without any unexpected repetition, we propose FreeScale, tuning-free inference paradigm that enables pre-trained image and video diffusion models to generate vivid higher-resolution results. Building on past effective modules [8], [12], we first propose tailored self-cascade upscaling and restrained dilated convolution to gain the basic visual structure and maintain the quality in higher-resolution generation. To further eliminate all kinds of unexpected object repetitions, FreeScale processes information from different receptive scales and then fuses it by extracting desired frequency components, ensuring both the structures overall rationality and the objects local quality. This fusion is smoothly integrated into the original self-attention layers, thereby bringing only minimal additional time overhead. Finally, we demonstrate the effectiveness of our model on both the text-to-image model and the text-to-video model, pushing the boundaries of image generation even up to an 8k resolution. Benefiting from the exceptional scalability, DiT has become the dominant architecture in the development of recent foundational diffusion models. Nevertheless, FreeScale and the majority of existing works are built upon the UNet 00000000/00$00.00 2021 IEEE JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST architecture. Due to the architectural gap, these methods exhibit limited effectiveness on DiT-based models. Specifically, the major challenge faced by DiT-based models in highresolution generation is the substantial increase in token count, which results in untrained positional embeddings and overly diluted attention, ultimately hindering generation quality. Indeed, these challenges have been thoroughly explored in large language models for long-text generation [13], [14], providing valuable empirical knowledge like NTK-aware interpolation and attention reweighting. Combining those technologies, we extend the original FreeScale framework by tailoring it to the architectural properties of DiT, yielding new variant that supports high-resolution generation on DiT-based models. Although tuning-free stra"
[27.08.2025 07:11] Mistral response. {"object": "error", "message": "Service tier capacity exceeded for this model.", "type": "service_tier_capacity_exceeded", "param": null, "code": "3505"}
[27.08.2025 07:11] Failed to download and parse paper https://huggingface.co/papers/2508.15774: 'choices'
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.18621.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.18621.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.18621.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.15804.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.15804.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.15804.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.18773.
[27.08.2025 07:11] Extra JSON file exists (./assets/json/2508.18773.json), skip PDF parsing.
[27.08.2025 07:11] Paper image links file exists (./assets/img_data/2508.18773.json), skip HTML parsing.
[27.08.2025 07:11] Success.
[27.08.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2508.18672.
[27.08.2025 07:11] Downloading paper 2508.18672 from http://arxiv.org/pdf/2508.18672v1...
[27.08.2025 07:12] Extracting affiliations from text.
[27.08.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks Taishi Nakamura 1 2 Satoki Ishikawa 1 Masaki Kawamura 1 Takumi Okamoto 1 2 Daisuke Nohara 1 Jun Suzuki 3 2 4 Rio Yokota "
[27.08.2025 07:12] Response: []
[27.08.2025 07:12] Extracting affiliations from text.
[27.08.2025 07:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks Taishi Nakamura 1 2 Satoki Ishikawa 1 Masaki Kawamura 1 Takumi Okamoto 1 2 Daisuke Nohara 1 Jun Suzuki 3 2 4 Rio Yokota1. Introduction 5 2 0 2 6 2 ] . [ 1 2 7 6 8 1 . 8 0 5 2 : r Empirical scaling laws have driven the evolution of large language models (LLMs), yet their coefficients shift whenever the model architecture or data pipeline changes. Mixture-of-Experts (MoE) models, now standard in state-of-the-art systems, introduce new sparsity dimension that current dense-model frontiers overlook. We investigate how MoE sparsity influences two distinct capability regimes: memorization and reasoning. We train families of MoE Transformers that systematically vary total parameters, active parameters, and top-k routing while holding the compute budget fixed. For every model we record pre-training loss, downstream task loss, and task accuracy, allowing us to separate the train-test generalization gap from the loss-accuracy gap. Memorization benchmarks improve monotonically with total parameters, mirroring training loss. By contrast, reasoning performance saturates and can even regress despite continued gains in both total parameters and training loss. Altering top-k alone has little effect when active parameters are constant, and classic hyperparameters such as learning rate and initialization modulate the generalization gap in the same direction as sparsity. Neither post-training reinforcement learning (GRPO) nor extra test-time compute rescues the reasoning deficit of overly sparse models. Our model checkpoints, code and logs are open-source at https://github.com/ rioyokotalab/optimal-sparsity. 1Institute of Science Tokyo, Tokyo, Japan 2Research and Development Center for Large Language Models, National Institute of Informatics, Tokyo, Japan 3Tohoku University, Sendai, Japan 4RIKEN, Tokyo, Japan. Correspondence to: Taishi Nakamura <taishi@rio.scrc.iir.isct.ac.jp>, Rio Yokota <rioyokota@rio.scrc.iir.isct.ac.jp>. 1 The recent evolution of large language models (LLMs) has been driven by empirical scaling laws (Hestness et al., 2017) that link training loss to model size, dataset size, and compute budget. Kaplan et al. showed that these laws hold across seven orders of magnitude, establishing them as reliable extrapolation tool for dense Transformers (Kaplan et al., 2020). Subsequent work by Hoffmann et al. demonstrated that scaling curves can be inverted to choose the compute-optimal combination of parameters and tokens for fixed budget (Hoffmann et al., 2022). Together, these results have made scaling analysis cornerstone of model planning at both academic and industrial labs. Yet the coefficients of the scaling laws are not universal. Highly expressive models trained under different optimizers or architectures often follow the same loss trajectory but diverge substantially on downstream reasoning benchmarks (Liu et al., 2023). Brandfonbrener et al. extend the classic laws with loss-to-loss prediction, showing that the mapping between training and test distributions admits its own power law when the distributions differ substantially (Brandfonbrener et al., 2025). These observations imply that optimal budgets must be re-estimated whenever we modify the model or the data pipeline. particularly compelling architectural modification is the Mixture-of-Experts (MoE) paradigm, offering high capacity at fixed FLOPs by routing each token through sparse subset of experts (Shazeer et al., 2017; Lepikhin et al., 2021; Fedus et al., 2021). Modern flagship models, e.g., Gemini 2.5 Pro (Gemini Team, 2025), DeepSeek-V3 (DeepSeek-AI, 2025b), and Qwen3 (Qwen Team, 2025) now rely on MoE as de-facto standard for economical scaling. Abnar et al. derive parameters-vs-FLOPs frontier and locate an optimal sparsity for given compute budget (Abnar et al., 2025). These findings emphasize that the classical dense-model frontier is an incomplete picture, and one must account for architectural knobs such as MoE sparsity and top-k routing. Furthermore, loss-based scaling curves do not always predict the performance on downstream tasks. Jelassi et al. report that increasing MoE sparsity improves memorization benchmarks, but saturates for reasoning performance (Jelassi et al., 2025). However, the Mixture of Parrots paper (JeOptimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks lassi et al., 2025) only explores the number of active vs. total parameters, ignoring the effect of routing strategies beyond standard top-2 routing. They also do not consider the effect of reinforcement learning and test-time compute on their reasoning benchmarks. Evaluating reasoning performance immediately after pre-training overlooks both the benefits of post-training adaptation and the leverage of additional testtime compute. Post-training methods such as GRPO, which use reinforcement signals to encourage coherent chain-ofthought generation, sharpen models reasoning on complex tasks (OpenAI, 2024b; DeepSeek-AI, 2025a). Beyond these refinements, models can further improve outputs at test time by adopting calibrated decoding strategies that mirror how humans pause to reconsider difficult problems. These test-time approaches not only boost routine benchmark performance but, when properly tuned, substantially enhance multi-step mathematical reasoning, demonstrating that adaptive computing at test time is powerful complement to both model scale and post-training adaptation. In this paper, we aim to identify how the optimal sparsity of MoE changes between memorization (TriviaQA, HellaSwag) and reasoning (GSM8K, GSM-Plus) tasks. In this work, we use the term dense models to refer to standard Transformers with single feed-forward network per layer. For MoE models, we define sparsity as sparsity = 1 Top-k Experts following the convention that sparsity measures the fraction of inactive parameters. We train families of MoEs varying not only the total vs. active parameters, but also the number of top-k experts. For each model, we measure the loss on the pre-training data, the task loss on the downstream benchmarks, and the accuracy on those benchmarks. This allows us to disentangle the generalization gap between the train vs. test loss, and the gap between loss vs. accuracy. For both memorization and reasoning benchmarks, the train loss decreases monotonically with the total parameters. The task loss and accuracy follow the same monotonic trend as the trai"
[27.08.2025 07:12] Mistral response. {"object": "error", "message": "Service tier capacity exceeded for this model.", "type": "service_tier_capacity_exceeded", "param": null, "code": "3505"}
[27.08.2025 07:12] Failed to download and parse paper https://huggingface.co/papers/2508.18672: 'choices'
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.18370.
[27.08.2025 07:12] Extra JSON file exists (./assets/json/2508.18370.json), skip PDF parsing.
[27.08.2025 07:12] Paper image links file exists (./assets/img_data/2508.18370.json), skip HTML parsing.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.16697.
[27.08.2025 07:12] Extra JSON file exists (./assets/json/2508.16697.json), skip PDF parsing.
[27.08.2025 07:12] Paper image links file exists (./assets/img_data/2508.16697.json), skip HTML parsing.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.19188.
[27.08.2025 07:12] Extra JSON file exists (./assets/json/2508.19188.json), skip PDF parsing.
[27.08.2025 07:12] Paper image links file exists (./assets/img_data/2508.19188.json), skip HTML parsing.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.19026.
[27.08.2025 07:12] Extra JSON file exists (./assets/json/2508.19026.json), skip PDF parsing.
[27.08.2025 07:12] Paper image links file exists (./assets/img_data/2508.19026.json), skip HTML parsing.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.18271.
[27.08.2025 07:12] Extra JSON file exists (./assets/json/2508.18271.json), skip PDF parsing.
[27.08.2025 07:12] Paper image links file exists (./assets/img_data/2508.18271.json), skip HTML parsing.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.19202.
[27.08.2025 07:12] Downloading paper 2508.19202 from http://arxiv.org/pdf/2508.19202v1...
[27.08.2025 07:12] Extracting affiliations from text.
[27.08.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 2 0 2 9 1 . 8 0 5 2 : r Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning Alan Li1* Yixin Liu1* Arpan Sarkar2 Doug Downey3,4 Arman Cohan1,4 1Yale University, 2Harvard University, 3Northwestern University, 4Allen Institute of AI {haoxin.li,yixin.liu}@yale.edu "
[27.08.2025 07:12] Response: ```python
["Yale University", "Harvard University", "Northwestern University", "Allen Institute of AI"]
```
[27.08.2025 07:12] Deleting PDF ./assets/pdf/2508.19202.pdf.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2508.18192.
[27.08.2025 07:12] Extra JSON file exists (./assets/json/2508.18192.json), skip PDF parsing.
[27.08.2025 07:12] Paper image links file exists (./assets/img_data/2508.18192.json), skip HTML parsing.
[27.08.2025 07:12] Success.
[27.08.2025 07:12] Enriching papers with extra data.
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 0. CMPhysBench evaluates LLMs in condensed matter physics using calculation problems and a new SEED score for partial credit assessment, revealing significant capability gaps.  					AI-generated summary 				 We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 1. VibeVoice synthesizes long-form multi-speaker speech using next-token diffusion and a highly efficient continuous speech tokenizer, achieving superior performance and fidelity.  					AI-generated summary 				 This report presents VibeVoice, a novel model designed to synthesize long-form speech with ...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 2. Spacer, a scientific discovery system, uses deliberate decontextualization to generate creative and factually grounded scientific concepts from keyword sets, achieving high accuracy and similarity to leading publications.  					AI-generated summary 				 Recent advances in LLMs have made automated sc...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 3. A framework using Multimodal Large Language Models and a specialized Multimodal DiT architecture generates semantically coherent and expressive character animations from multimodal inputs.  					AI-generated summary 				 Existing video avatar models can produce fluid human animations, yet they strug...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 4. UltraMemV2, a redesigned memory-layer architecture, achieves performance parity with 8-expert MoE models while significantly reducing memory access costs.  					AI-generated summary 				 While Mixture of Experts (MoE) models achieve remarkable efficiency by activating only subsets of parameters, the...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 5. TreePO, a self-guided rollout algorithm for sequence generation, reduces computational cost and enhances exploration diversity in reinforcement learning for large language models.  					AI-generated summary 				 Recent advancements in aligning large language models via reinforcement learning have ac...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 6. VoxHammer is a training-free method that performs precise and coherent 3D editing in latent space, ensuring consistency in preserved regions and high-quality overall results.  					AI-generated summary 				 3D local editing of specified regions is crucial for game industry and robot interaction. Rec...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 7. PIXIE, a neural network method, predicts physical properties of 3D scenes from visual features, enabling fast and realistic physics simulation using supervised learning and pretrained visual features.  					AI-generated summary 				 Inferring the physical properties of 3D scenes from visual informat...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 8. AUSM, an autoregressive universal segmentation model, unifies prompted and unprompted video segmentation by treating it as sequential mask prediction, achieving superior performance and faster training on standard benchmarks.  					AI-generated summary 				 Recent video foundation models such as SAM...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 9. CineScale is a novel inference paradigm that enables high-resolution visual generation for both images and videos without extensive fine-tuning, addressing issues of repetitive patterns and high-frequency information accumulation.  					AI-generated summary 				 Visual diffusion models achieve remar...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 10. Wan-S2V, an audio-driven model built on Wan, enhances expressiveness and fidelity in cinematic character animation compared to existing methods.  					AI-generated summary 				 Current state-of-the-art (SOTA) methods for audio-driven character animation demonstrate promising performance for scenario...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 11. ReportBench evaluates the content quality of research reports generated by large language models, focusing on cited literature quality and statement faithfulness, demonstrating that commercial Deep Research agents produce more comprehensive and reliable reports than standalone LLMs.  					AI-generat...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 12. ThinkDial is an open-source framework that implements controllable reasoning in large language models through discrete operational modes, achieving performance while reducing computational effort.  					AI-generated summary 				 Large language models (LLMs) with chain-of-thought reasoning have demon...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 13. MoE models introduce sparsity that affects memorization and reasoning capabilities differently in large language models, with reasoning performance potentially regressing despite increased parameters.  					AI-generated summary 				 Empirical scaling laws have driven the evolution of large language ...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 14. CTF-Dojo, a large-scale executable runtime with 658 CTF challenges, enables rapid training of LLM-based agents with verifiable feedback, achieving state-of-the-art performance in competitive benchmarks.  					AI-generated summary 				 Large language models (LLMs) have demonstrated exceptional capabi...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 15. QueryBandits, a bandit framework, effectively mitigates hallucinations in LLMs by proactively rewriting queries based on linguistic features, outperforming static prompting strategies.  					AI-generated summary 				 Advanced reasoning capabilities in Large Language Models (LLMs) have caused higher ...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 16. A framework for efficient artistic mesh generation reduces redundancy by separating vertex and face generation, using an autoregressive model for vertices and a bidirectional transformer for faces, and includes a fidelity enhancer and post-processing to improve quality and speed.  					AI-generated ...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 17. MovieCORE is a video question answering dataset that uses multiple large language models to generate deep cognitive questions, and introduces an agentic enhancement module to improve VQA model performance.  					AI-generated summary 				 This paper introduces MovieCORE, a novel video question answer...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 18. ObjFiller-3D uses video editing models to achieve high-quality and consistent 3D object completion, outperforming previous methods in terms of reconstruction fidelity and practical deployment.  					AI-generated summary 				 3D inpainting often relies on multi-view 2D image inpainting, where the inh...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 19. SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for ...
[27.08.2025 07:12] ********************************************************************************
[27.08.2025 07:12] Abstract 20. A network-based framework links cognitive skills, LLM architectures, and datasets, revealing unique emergent skill patterns in LLMs that benefit from dynamic, cross-regional interactions.  					AI-generated summary 				 Large Language Models (LLMs) have reshaped our world with significant advancemen...
[27.08.2025 07:12] Read previous papers.
[27.08.2025 07:12] Generating reviews via LLM API.
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset"], "emoji": "🔬", "ru": {"title": "Новый вызов для ИИ: решение задач по физике конденсированного состояния", "desc": "CMPhysBench - это новый бенчмарк для оценки способностей больших языковых моделей (LLM) в области физики конденсированного состояни
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#diffusion", "#audio"], "emoji": "🗣️", "ru": {"title": "VibeVoice: революция в синтезе длительной многоголосой речи", "desc": "VibeVoice - это новая модель для синтеза длительной многоголосой речи, использующая диффузию следующего токена и эффективны
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#science", "#data", "#multimodal", "#dataset"], "emoji": "🧬", "ru": {"title": "Spacer: Революция в автоматизированных научных открытиях", "desc": "Spacer - это система научных открытий, использующая намеренную деконтекстуализацию для генерации креативных и фактически обоснованных на
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#optimization", "#games", "#multimodal", "#video"], "emoji": "🎭", "ru": {"title": "Семантически осмысленная анимация персонажей с помощью мультимодального ИИ", "desc": "Эта статья представляет новую модель OmniHuman-1.5 для генерации анимации пе
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "UltraMemV2: Эффективность MoE без высоких затрат на память", "desc": "UltraMemV2 - это новая архитектура слоя памяти для нейронных сетей, которая достигает производительности 8-экспертных 
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#rl", "#rlhf"], "emoji": "🌳", "ru": {"title": "TreePO: Эффективное обучение с подкреплением для языковых моделей", "desc": "Статья представляет TreePO - алгоритм самонаправляемой генерации последовательностей для обучения с подкреплением б
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#games", "#dataset", "#synthetic", "#3d"], "emoji": "🔨", "ru": {"title": "Точное 3D-редактирование без компромиссов", "desc": "VoxHammer - это метод редактирования 3D-моделей в латентном пространстве без дополнительного обучения. Он обеспечивает точное и согласованное редактирование
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#inference", "#synthetic", "#3d"], "emoji": "🧠", "ru": {"title": "Быстрое предсказание физических свойств 3D-сцен с помощью нейронных сетей", "desc": "PIXIE - это нейросетевой метод, который предсказывает физические свойства 3D-сцен на основе визуальных 
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#training", "#video", "#optimization"], "emoji": "🎬", "ru": {"title": "Универсальная сегментация видео как последовательное предсказание масок", "desc": "AUSM - это модель универсальной сегментации видео, объединяющая подходы с подсказками и без них. Она рассматрива
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#inference", "#cv", "#video"], "emoji": "🎬", "ru": {"title": "CineScale: Прорыв в генерации высококачественного визуального контента", "desc": "CineScale - это новая парадигма вывода, позволяющая генерировать изображения и видео высокого разрешения без 
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#story_generation", "#audio", "#games", "#benchmark", "#video"], "emoji": "🎭", "ru": {"title": "Wan-S2V: Революция в анимации кинематографических персонажей на основе аудио", "desc": "Модель Wan-S2V, основанная на аудио, улучшает выразительность и точность анимации кинематографическ
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#survey", "#agents", "#open_source"], "emoji": "🔬", "ru": {"title": "ReportBench: новый стандарт оценки AI-исследований", "desc": "ReportBench - это новый метод оценки качества исследовательских отчетов, сгенерированных большими языковыми моделями 
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#reasoning", "#agi", "#rl"], "emoji": "🧠", "ru": {"title": "ThinkDial: контролируемое рассуждение в больших языковых моделях", "desc": "ThinkDial - это фреймворк с открытым исходным кодом, который реализует контролируемо
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#architecture", "#training", "#open_source"], "emoji": "🧠", "ru": {"title": "Разреженность в MoE: компромисс между запоминанием и рассуждением", "desc": "Статья исследует влияние разреженности в моделях Mixture-of-Experts (MoE) на способности больших я
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#open_source", "#training", "#dataset", "#games", "#benchmark", "#agents"], "emoji": "🏆", "ru": {"title": "CTF-Dojo: революция в обучении ИИ-агентов через исполняемую среду", "desc": "CTF-Dojo - это крупномасштабная исполняемая среда с 658 задачами CTF, позволяющая быстро обучать аг
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#training", "#hallucinations", "#multimodal", "#rl"], "emoji": "🎯", "ru": {"title": "Умное переписывание запросов побеждает галлюцинации ИИ", "desc": "QueryBandits - это фреймворк, использующий алгоритмы многоруких бандитов для снижения галлюцинаций в больших языковых 
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "🎨", "ru": {"title": "Эффективная генерация 3D-моделей: разделяй и властвуй", "desc": "Предложена эффективная система генерации художественных 3D-моделей, разделяющая процессы создания вершин и граней. Для вершин используется авторегрессион
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#video", "#reasoning", "#alignment", "#agents", "#benchmark", "#dataset"], "emoji": "🎬", "ru": {"title": "MovieCORE: Глубокое понимание фильмов с помощью ИИ", "desc": "MovieCORE - это новый набор данных для ответов на вопросы по видео, который использует несколько больших языковых м
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#video", "#optimization", "#3d"], "emoji": "🎨", "ru": {"title": "Революция в 3D-инпейнтинге: от видео к реалистичным объектам", "desc": "ObjFiller-3D - это новый метод для заполнения и редактирования трехмерных объектов высокого качества. Он использует модели редактирования видео дл
[27.08.2025 07:12] Querying the API.
[27.08.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for LLMs, requiring both deep domain knowledge and the ability to apply such knowledge through complex reasoning. While automated scientific reasoners hold great promise for assisting human scientists, there is currently no widely adopted holistic benchmark for evaluating scientific reasoning, and few approaches systematically disentangle the distinct roles of knowledge and reasoning in these tasks. To address these gaps, we introduce SciReas, a diverse suite of existing benchmarks for scientific reasoning tasks, and SciReas-Pro, a selective subset that requires more complex reasoning. Our holistic evaluation surfaces insights about scientific reasoning performance that remain hidden when relying on individual benchmarks alone. We then propose KRUX, a probing framework for studying the distinct roles of reasoning and knowledge in scientific tasks. Combining the two, we conduct an in-depth analysis that yields several key findings: (1) Retrieving task-relevant knowledge from model parameters is a critical bottleneck for LLMs in scientific reasoning; (2) Reasoning models consistently benefit from external knowledge added in-context on top of the reasoning enhancement; (3) Enhancing verbalized reasoning improves LLMs' ability to surface task-relevant knowledge. Finally, we conduct a lightweight analysis, comparing our science-focused data composition with concurrent efforts on long CoT SFT, and release SciLit01, a strong 8B baseline for scientific reasoning.
[27.08.2025 07:12] Response: {
  "desc": "Статья представляет новые бенчмарки SciReas и SciReas-Pro для оценки научного мышления у языковых моделей. Авторы также предлагают фреймворк KRUX для анализа роли знаний и рассуждений в научных задачах. Исследование показывает, что извлечение релевантной информации из параметров модели является узким местом для ЯМ в научном мышлении. Обнаружено, что улучшение вербализованных рассуждений повышает способность ЯМ извлекать релевантные знания.",
  "emoji": "🧠",
  "title": "Разделяй и властвуй: новый подход к оценке научного мышления ЯМ"
}
[27.08.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for LLMs, requiring both deep domain knowledge and the ability to apply such knowledge through complex reasoning. While automated scientific reasoners hold great promise for assisting human scientists, there is currently no widely adopted holistic benchmark for evaluating scientific reasoning, and few approaches systematically disentangle the distinct roles of knowledge and reasoning in these tasks. To address these gaps, we introduce SciReas, a diverse suite of existing benchmarks for scientific reasoning tasks, and SciReas-Pro, a selective subset that requires more complex reasoning. Our holistic evaluation surfaces insights about scientific reasoning performance that remain hidden when relying on individual benchmarks alone. We then propose KRUX, a probing framework for studying the distinct roles of reasoning and knowledge in scientific tasks. Combining the two, we conduct an in-depth analysis that yields several key findings: (1) Retrieving task-relevant knowledge from model parameters is a critical bottleneck for LLMs in scientific reasoning; (2) Reasoning models consistently benefit from external knowledge added in-context on top of the reasoning enhancement; (3) Enhancing verbalized reasoning improves LLMs' ability to surface task-relevant knowledge. Finally, we conduct a lightweight analysis, comparing our science-focused data composition with concurrent efforts on long CoT SFT, and release SciLit01, a strong 8B baseline for scientific reasoning."

[27.08.2025 07:12] Response: ```python
['BENCHMARK', 'DATASET', 'MULTIMODAL']
```
[27.08.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for LLMs, requiring both deep domain knowledge and the ability to apply such knowledge through complex reasoning. While automated scientific reasoners hold great promise for assisting human scientists, there is currently no widely adopted holistic benchmark for evaluating scientific reasoning, and few approaches systematically disentangle the distinct roles of knowledge and reasoning in these tasks. To address these gaps, we introduce SciReas, a diverse suite of existing benchmarks for scientific reasoning tasks, and SciReas-Pro, a selective subset that requires more complex reasoning. Our holistic evaluation surfaces insights about scientific reasoning performance that remain hidden when relying on individual benchmarks alone. We then propose KRUX, a probing framework for studying the distinct roles of reasoning and knowledge in scientific tasks. Combining the two, we conduct an in-depth analysis that yields several key findings: (1) Retrieving task-relevant knowledge from model parameters is a critical bottleneck for LLMs in scientific reasoning; (2) Reasoning models consistently benefit from external knowledge added in-context on top of the reasoning enhancement; (3) Enhancing verbalized reasoning improves LLMs' ability to surface task-relevant knowledge. Finally, we conduct a lightweight analysis, comparing our science-focused data composition with concurrent efforts on long CoT SFT, and release SciLit01, a strong 8B baseline for scientific reasoning."

[27.08.2025 07:12] Response: ```python
['REASONING', 'SCIENCE']
```
[27.08.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces SciReas and SciReas-Pro, benchmarks designed to evaluate the performance of large language models (LLMs) in scientific reasoning tasks. It highlights the importance of both knowledge retrieval and reasoning capabilities, identifying key challenges that LLMs face in these areas. The KRUX framework is proposed to analyze how knowledge and reasoning interact in scientific problem-solving. The findings suggest that improving knowledge retrieval and enhancing reasoning processes can significantly boost the effectiveness of LLMs in scientific contexts.","title":"Unlocking Scientific Reasoning in LLMs with SciReas and KRUX"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces SciReas and SciReas-Pro, benchmarks designed to evaluate the performance of large language models (LLMs) in scientific reasoning tasks. It highlights the importance of both knowledge retrieval and reasoning capabilities, identifying key challenges that LLMs face in these areas. The KRUX framework is proposed to analyze how knowledge and reasoning interact in scientific problem-solving. The findings suggest that improving knowledge retrieval and enhancing reasoning processes can significantly boost the effectiveness of LLMs in scientific contexts.', title='Unlocking Scientific Reasoning in LLMs with SciReas and KRUX'))
[27.08.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文介绍了SciReas和SciReas-Pro基准，以及KRUX框架，旨在揭示知识和推理在科学任务中的不同角色。科学问题解决对大型语言模型（LLMs）提出了独特的挑战，需要深厚的领域知识和复杂的推理能力。我们提出的SciReas是一个多样化的基准套件，而SciReas-Pro则是一个需要更复杂推理的子集。通过综合评估，我们发现知识检索和推理模型的外部知识增强对科学推理的性能至关重要。","title":"揭示科学推理中的知识与推理角色"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文介绍了SciReas和SciReas-Pro基准，以及KRUX框架，旨在揭示知识和推理在科学任务中的不同角色。科学问题解决对大型语言模型（LLMs）提出了独特的挑战，需要深厚的领域知识和复杂的推理能力。我们提出的SciReas是一个多样化的基准套件，而SciReas-Pro则是一个需要更复杂推理的子集。通过综合评估，我们发现知识检索和推理模型的外部知识增强对科学推理的性能至关重要。', title='揭示科学推理中的知识与推理角色'))
[27.08.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#science", "#training", "#interpretability", "#dataset"], "emoji": "🧠", "ru": {"title": "Сетевой анализ раскрывает когнитивные паттерны в языковых моделях", "desc": "Данная статья представляет сетевую модель, связывающую когнитивные навыки, архитектуры языковых моде
[27.08.2025 07:12] Renaming data file.
[27.08.2025 07:12] Renaming previous data. hf_papers.json to ./d/2025-08-27.json
[27.08.2025 07:12] Saving new data file.
[27.08.2025 07:12] Generating page.
[27.08.2025 07:12] Renaming previous page.
[27.08.2025 07:12] Renaming previous data. index.html to ./d/2025-08-27.html
[27.08.2025 07:12] Writing result.
[27.08.2025 07:12] Renaming log file.
[27.08.2025 07:12] Renaming previous data. log.txt to ./logs/2025-08-27_last_log.txt
