[27.08.2025 08:15] Read previous papers.
[27.08.2025 08:15] Generating top page (month).
[27.08.2025 08:15] Writing top page (month).
[27.08.2025 09:12] Read previous papers.
[27.08.2025 09:12] Get feed.
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18124
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19205
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17445
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17661
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19209
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18756
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19247
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17437
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19242
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18621
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15774
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15804
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18773
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19188
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19026
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18672
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18370
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16697
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18271
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19202
[27.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18192
[27.08.2025 09:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.08.2025 09:12] No deleted papers detected.
[27.08.2025 09:12] Downloading and parsing papers (pdf, html). Total: 21.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.18124.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.18124.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.18124.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.19205.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.19205.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.19205.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.17445.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.17445.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.17445.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.17661.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.17661.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.17661.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.19209.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.19209.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.19209.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.18756.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.18756.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.18756.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.19247.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.19247.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.19247.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.17437.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.17437.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.17437.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.19242.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.19242.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.19242.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.18621.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.18621.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.18621.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.15774.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.15774.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.15774.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.15804.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.15804.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.15804.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.18773.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.18773.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.18773.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.19188.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.19188.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.19188.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.19026.
[27.08.2025 09:12] Extra JSON file exists (./assets/json/2508.19026.json), skip PDF parsing.
[27.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.19026.json), skip HTML parsing.
[27.08.2025 09:12] Success.
[27.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.18672.
[27.08.2025 09:12] Downloading paper 2508.18672 from http://arxiv.org/pdf/2508.18672v1...
[27.08.2025 09:13] Extracting affiliations from text.
[27.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks Taishi Nakamura 1 2 Satoki Ishikawa 1 Masaki Kawamura 1 Takumi Okamoto 1 2 Daisuke Nohara 1 Jun Suzuki 3 2 4 Rio Yokota "
[27.08.2025 09:13] Response: []
[27.08.2025 09:13] Extracting affiliations from text.
[27.08.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks Taishi Nakamura 1 2 Satoki Ishikawa 1 Masaki Kawamura 1 Takumi Okamoto 1 2 Daisuke Nohara 1 Jun Suzuki 3 2 4 Rio Yokota1. Introduction 5 2 0 2 6 2 ] . [ 1 2 7 6 8 1 . 8 0 5 2 : r Empirical scaling laws have driven the evolution of large language models (LLMs), yet their coefficients shift whenever the model architecture or data pipeline changes. Mixture-of-Experts (MoE) models, now standard in state-of-the-art systems, introduce new sparsity dimension that current dense-model frontiers overlook. We investigate how MoE sparsity influences two distinct capability regimes: memorization and reasoning. We train families of MoE Transformers that systematically vary total parameters, active parameters, and top-k routing while holding the compute budget fixed. For every model we record pre-training loss, downstream task loss, and task accuracy, allowing us to separate the train-test generalization gap from the loss-accuracy gap. Memorization benchmarks improve monotonically with total parameters, mirroring training loss. By contrast, reasoning performance saturates and can even regress despite continued gains in both total parameters and training loss. Altering top-k alone has little effect when active parameters are constant, and classic hyperparameters such as learning rate and initialization modulate the generalization gap in the same direction as sparsity. Neither post-training reinforcement learning (GRPO) nor extra test-time compute rescues the reasoning deficit of overly sparse models. Our model checkpoints, code and logs are open-source at https://github.com/ rioyokotalab/optimal-sparsity. 1Institute of Science Tokyo, Tokyo, Japan 2Research and Development Center for Large Language Models, National Institute of Informatics, Tokyo, Japan 3Tohoku University, Sendai, Japan 4RIKEN, Tokyo, Japan. Correspondence to: Taishi Nakamura <taishi@rio.scrc.iir.isct.ac.jp>, Rio Yokota <rioyokota@rio.scrc.iir.isct.ac.jp>. 1 The recent evolution of large language models (LLMs) has been driven by empirical scaling laws (Hestness et al., 2017) that link training loss to model size, dataset size, and compute budget. Kaplan et al. showed that these laws hold across seven orders of magnitude, establishing them as reliable extrapolation tool for dense Transformers (Kaplan et al., 2020). Subsequent work by Hoffmann et al. demonstrated that scaling curves can be inverted to choose the compute-optimal combination of parameters and tokens for fixed budget (Hoffmann et al., 2022). Together, these results have made scaling analysis cornerstone of model planning at both academic and industrial labs. Yet the coefficients of the scaling laws are not universal. Highly expressive models trained under different optimizers or architectures often follow the same loss trajectory but diverge substantially on downstream reasoning benchmarks (Liu et al., 2023). Brandfonbrener et al. extend the classic laws with loss-to-loss prediction, showing that the mapping between training and test distributions admits its own power law when the distributions differ substantially (Brandfonbrener et al., 2025). These observations imply that optimal budgets must be re-estimated whenever we modify the model or the data pipeline. particularly compelling architectural modification is the Mixture-of-Experts (MoE) paradigm, offering high capacity at fixed FLOPs by routing each token through sparse subset of experts (Shazeer et al., 2017; Lepikhin et al., 2021; Fedus et al., 2021). Modern flagship models, e.g., Gemini 2.5 Pro (Gemini Team, 2025), DeepSeek-V3 (DeepSeek-AI, 2025b), and Qwen3 (Qwen Team, 2025) now rely on MoE as de-facto standard for economical scaling. Abnar et al. derive parameters-vs-FLOPs frontier and locate an optimal sparsity for given compute budget (Abnar et al., 2025). These findings emphasize that the classical dense-model frontier is an incomplete picture, and one must account for architectural knobs such as MoE sparsity and top-k routing. Furthermore, loss-based scaling curves do not always predict the performance on downstream tasks. Jelassi et al. report that increasing MoE sparsity improves memorization benchmarks, but saturates for reasoning performance (Jelassi et al., 2025). However, the Mixture of Parrots paper (JeOptimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks lassi et al., 2025) only explores the number of active vs. total parameters, ignoring the effect of routing strategies beyond standard top-2 routing. They also do not consider the effect of reinforcement learning and test-time compute on their reasoning benchmarks. Evaluating reasoning performance immediately after pre-training overlooks both the benefits of post-training adaptation and the leverage of additional testtime compute. Post-training methods such as GRPO, which use reinforcement signals to encourage coherent chain-ofthought generation, sharpen models reasoning on complex tasks (OpenAI, 2024b; DeepSeek-AI, 2025a). Beyond these refinements, models can further improve outputs at test time by adopting calibrated decoding strategies that mirror how humans pause to reconsider difficult problems. These test-time approaches not only boost routine benchmark performance but, when properly tuned, substantially enhance multi-step mathematical reasoning, demonstrating that adaptive computing at test time is powerful complement to both model scale and post-training adaptation. In this paper, we aim to identify how the optimal sparsity of MoE changes between memorization (TriviaQA, HellaSwag) and reasoning (GSM8K, GSM-Plus) tasks. In this work, we use the term dense models to refer to standard Transformers with single feed-forward network per layer. For MoE models, we define sparsity as sparsity = 1 Top-k Experts following the convention that sparsity measures the fraction of inactive parameters. We train families of MoEs varying not only the total vs. active parameters, but also the number of top-k experts. For each model, we measure the loss on the pre-training data, the task loss on the downstream benchmarks, and the accuracy on those benchmarks. This allows us to disentangle the generalization gap between the train vs. test loss, and the gap between loss vs. accuracy. For both memorization and reasoning benchmarks, the train loss decreases monotonically with the total parameters. The task loss and accuracy follow the same monotonic trend as the trai"
[27.08.2025 09:13] Mistral response. {"object": "error", "message": "Service tier capacity exceeded for this model.", "type": "service_tier_capacity_exceeded", "param": null, "code": "3505"}
[27.08.2025 09:13] Failed to download and parse paper https://huggingface.co/papers/2508.18672: 'choices'
[27.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.18370.
[27.08.2025 09:13] Extra JSON file exists (./assets/json/2508.18370.json), skip PDF parsing.
[27.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.18370.json), skip HTML parsing.
[27.08.2025 09:13] Success.
[27.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.16697.
[27.08.2025 09:13] Extra JSON file exists (./assets/json/2508.16697.json), skip PDF parsing.
[27.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.16697.json), skip HTML parsing.
[27.08.2025 09:13] Success.
[27.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.18271.
[27.08.2025 09:13] Extra JSON file exists (./assets/json/2508.18271.json), skip PDF parsing.
[27.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.18271.json), skip HTML parsing.
[27.08.2025 09:13] Success.
[27.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.19202.
[27.08.2025 09:13] Extra JSON file exists (./assets/json/2508.19202.json), skip PDF parsing.
[27.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.19202.json), skip HTML parsing.
[27.08.2025 09:13] Success.
[27.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.18192.
[27.08.2025 09:13] Extra JSON file exists (./assets/json/2508.18192.json), skip PDF parsing.
[27.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.18192.json), skip HTML parsing.
[27.08.2025 09:13] Success.
[27.08.2025 09:13] Enriching papers with extra data.
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 0. CMPhysBench evaluates LLMs in condensed matter physics using calculation problems and a new SEED score for partial credit assessment, revealing significant capability gaps.  					AI-generated summary 				 We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 1. VibeVoice synthesizes long-form multi-speaker speech using next-token diffusion and a highly efficient continuous speech tokenizer, achieving superior performance and fidelity.  					AI-generated summary 				 This report presents VibeVoice, a novel model designed to synthesize long-form speech with ...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 2. TreePO, a self-guided rollout algorithm for sequence generation, reduces computational cost and enhances exploration diversity in reinforcement learning for large language models.  					AI-generated summary 				 Recent advancements in aligning large language models via reinforcement learning have ac...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 3. Spacer, a scientific discovery system, uses deliberate decontextualization to generate creative and factually grounded scientific concepts from keyword sets, achieving high accuracy and similarity to leading publications.  					AI-generated summary 				 Recent advances in LLMs have made automated sc...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 4. A framework using Multimodal Large Language Models and a specialized Multimodal DiT architecture generates semantically coherent and expressive character animations from multimodal inputs.  					AI-generated summary 				 Existing video avatar models can produce fluid human animations, yet they strug...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 5. UltraMemV2, a redesigned memory-layer architecture, achieves performance parity with 8-expert MoE models while significantly reducing memory access costs.  					AI-generated summary 				 While Mixture of Experts (MoE) models achieve remarkable efficiency by activating only subsets of parameters, the...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 6. VoxHammer is a training-free method that performs precise and coherent 3D editing in latent space, ensuring consistency in preserved regions and high-quality overall results.  					AI-generated summary 				 3D local editing of specified regions is crucial for game industry and robot interaction. Rec...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 7. PIXIE, a neural network method, predicts physical properties of 3D scenes from visual features, enabling fast and realistic physics simulation using supervised learning and pretrained visual features.  					AI-generated summary 				 Inferring the physical properties of 3D scenes from visual informat...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 8. AUSM, an autoregressive universal segmentation model, unifies prompted and unprompted video segmentation by treating it as sequential mask prediction, achieving superior performance and faster training on standard benchmarks.  					AI-generated summary 				 Recent video foundation models such as SAM...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 9. Wan-S2V, an audio-driven model built on Wan, enhances expressiveness and fidelity in cinematic character animation compared to existing methods.  					AI-generated summary 				 Current state-of-the-art (SOTA) methods for audio-driven character animation demonstrate promising performance for scenario...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 10. CineScale is a novel inference paradigm that enables high-resolution visual generation for both images and videos without extensive fine-tuning, addressing issues of repetitive patterns and high-frequency information accumulation.  					AI-generated summary 				 Visual diffusion models achieve remar...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 11. ReportBench evaluates the content quality of research reports generated by large language models, focusing on cited literature quality and statement faithfulness, demonstrating that commercial Deep Research agents produce more comprehensive and reliable reports than standalone LLMs.  					AI-generat...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 12. ThinkDial is an open-source framework that implements controllable reasoning in large language models through discrete operational modes, achieving performance while reducing computational effort.  					AI-generated summary 				 Large language models (LLMs) with chain-of-thought reasoning have demon...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 13. A framework for efficient artistic mesh generation reduces redundancy by separating vertex and face generation, using an autoregressive model for vertices and a bidirectional transformer for faces, and includes a fidelity enhancer and post-processing to improve quality and speed.  					AI-generated ...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 14. MovieCORE is a video question answering dataset that uses multiple large language models to generate deep cognitive questions, and introduces an agentic enhancement module to improve VQA model performance.  					AI-generated summary 				 This paper introduces MovieCORE, a novel video question answer...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 15. MoE models introduce sparsity that affects memorization and reasoning capabilities differently in large language models, with reasoning performance potentially regressing despite increased parameters.  					AI-generated summary 				 Empirical scaling laws have driven the evolution of large language ...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 16. CTF-Dojo, a large-scale executable runtime with 658 CTF challenges, enables rapid training of LLM-based agents with verifiable feedback, achieving state-of-the-art performance in competitive benchmarks.  					AI-generated summary 				 Large language models (LLMs) have demonstrated exceptional capabi...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 17. QueryBandits, a bandit framework, effectively mitigates hallucinations in LLMs by proactively rewriting queries based on linguistic features, outperforming static prompting strategies.  					AI-generated summary 				 Advanced reasoning capabilities in Large Language Models (LLMs) have caused higher ...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 18. ObjFiller-3D uses video editing models to achieve high-quality and consistent 3D object completion, outperforming previous methods in terms of reconstruction fidelity and practical deployment.  					AI-generated summary 				 3D inpainting often relies on multi-view 2D image inpainting, where the inh...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 19. SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for ...
[27.08.2025 09:13] ********************************************************************************
[27.08.2025 09:13] Abstract 20. A network-based framework links cognitive skills, LLM architectures, and datasets, revealing unique emergent skill patterns in LLMs that benefit from dynamic, cross-regional interactions.  					AI-generated summary 				 Large Language Models (LLMs) have reshaped our world with significant advancemen...
[27.08.2025 09:13] Read previous papers.
[27.08.2025 09:13] Generating reviews via LLM API.
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset"], "emoji": "🔬", "ru": {"title": "Новый вызов для ИИ: решение задач по физике конденсированного состояния", "desc": "CMPhysBench - это новый бенчмарк для оценки способностей больших языковых моделей (LLM) в области физики конденсированного состояни
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#diffusion", "#audio"], "emoji": "🗣️", "ru": {"title": "VibeVoice: революция в синтезе длительной многоголосой речи", "desc": "VibeVoice - это новая модель для синтеза длительной многоголосой речи, использующая диффузию следующего токена и эффективны
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#rl", "#rlhf"], "emoji": "🌳", "ru": {"title": "TreePO: Эффективное обучение с подкреплением для языковых моделей", "desc": "Статья представляет TreePO - алгоритм самонаправляемой генерации последовательностей для обучения с подкреплением б
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#science", "#data", "#multimodal", "#dataset"], "emoji": "🧬", "ru": {"title": "Spacer: Революция в автоматизированных научных открытиях", "desc": "Spacer - это система научных открытий, использующая намеренную деконтекстуализацию для генерации креативных и фактически обоснованных на
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#optimization", "#games", "#multimodal", "#video"], "emoji": "🎭", "ru": {"title": "Семантически осмысленная анимация персонажей с помощью мультимодального ИИ", "desc": "Эта статья представляет новую модель OmniHuman-1.5 для генерации анимации пе
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "UltraMemV2: Эффективность MoE без высоких затрат на память", "desc": "UltraMemV2 - это новая архитектура слоя памяти для нейронных сетей, которая достигает производительности 8-экспертных 
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#games", "#dataset", "#synthetic", "#3d"], "emoji": "🔨", "ru": {"title": "Точное 3D-редактирование без компромиссов", "desc": "VoxHammer - это метод редактирования 3D-моделей в латентном пространстве без дополнительного обучения. Он обеспечивает точное и согласованное редактирование
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#inference", "#synthetic", "#3d"], "emoji": "🧠", "ru": {"title": "Быстрое предсказание физических свойств 3D-сцен с помощью нейронных сетей", "desc": "PIXIE - это нейросетевой метод, который предсказывает физические свойства 3D-сцен на основе визуальных 
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#architecture", "#training", "#video", "#optimization"], "emoji": "🎬", "ru": {"title": "Универсальная сегментация видео как последовательное предсказание масок", "desc": "AUSM - это модель универсальной сегментации видео, объединяющая подходы с подсказками и без них. Она рассматрива
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#story_generation", "#audio", "#games", "#benchmark", "#video"], "emoji": "🎭", "ru": {"title": "Wan-S2V: Революция в анимации кинематографических персонажей на основе аудио", "desc": "Модель Wan-S2V, основанная на аудио, улучшает выразительность и точность анимации кинематографическ
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#inference", "#cv", "#video"], "emoji": "🎬", "ru": {"title": "CineScale: Прорыв в генерации высококачественного визуального контента", "desc": "CineScale - это новая парадигма вывода, позволяющая генерировать изображения и видео высокого разрешения без 
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#survey", "#agents", "#open_source"], "emoji": "🔬", "ru": {"title": "ReportBench: новый стандарт оценки AI-исследований", "desc": "ReportBench - это новый метод оценки качества исследовательских отчетов, сгенерированных большими языковыми моделями 
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#reasoning", "#agi", "#rl"], "emoji": "🧠", "ru": {"title": "ThinkDial: контролируемое рассуждение в больших языковых моделях", "desc": "ThinkDial - это фреймворк с открытым исходным кодом, который реализует контролируемо
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "🎨", "ru": {"title": "Эффективная генерация 3D-моделей: разделяй и властвуй", "desc": "Предложена эффективная система генерации художественных 3D-моделей, разделяющая процессы создания вершин и граней. Для вершин используется авторегрессион
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#video", "#reasoning", "#alignment", "#agents", "#benchmark", "#dataset"], "emoji": "🎬", "ru": {"title": "MovieCORE: Глубокое понимание фильмов с помощью ИИ", "desc": "MovieCORE - это новый набор данных для ответов на вопросы по видео, который использует несколько больших языковых м
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#architecture", "#training", "#open_source"], "emoji": "🧠", "ru": {"title": "Разреженность в MoE: компромисс между запоминанием и рассуждением", "desc": "Статья исследует влияние разреженности в моделях Mixture-of-Experts (MoE) на способности больших я
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#open_source", "#training", "#dataset", "#games", "#benchmark", "#agents"], "emoji": "🏆", "ru": {"title": "CTF-Dojo: революция в обучении ИИ-агентов через исполняемую среду", "desc": "CTF-Dojo - это крупномасштабная исполняемая среда с 658 задачами CTF, позволяющая быстро обучать аг
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#reasoning", "#training", "#hallucinations", "#multimodal", "#rl"], "emoji": "🎯", "ru": {"title": "Умное переписывание запросов побеждает галлюцинации ИИ", "desc": "QueryBandits - это фреймворк, использующий алгоритмы многоруких бандитов для снижения галлюцинаций в больших языковых 
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#video", "#optimization", "#3d"], "emoji": "🎨", "ru": {"title": "Революция в 3D-инпейнтинге: от видео к реалистичным объектам", "desc": "ObjFiller-3D - это новый метод для заполнения и редактирования трехмерных объектов высокого качества. Он использует модели редактирования видео дл
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#multimodal", "#science"], "emoji": "🧠", "ru": {"title": "Разделяй и властвуй: новый подход к оценке научного мышления ЯМ", "desc": "Статья представляет новые бенчмарки SciReas и SciReas-Pro для оценки научного мышления у языковых моделей. Авт
[27.08.2025 09:13] Using data from previous issue: {"categories": ["#architecture", "#science", "#training", "#interpretability", "#dataset"], "emoji": "🧠", "ru": {"title": "Сетевой анализ раскрывает когнитивные паттерны в языковых моделях", "desc": "Данная статья представляет сетевую модель, связывающую когнитивные навыки, архитектуры языковых моде
[27.08.2025 09:13] Renaming data file.
[27.08.2025 09:13] Renaming previous data. hf_papers.json to ./d/2025-08-27.json
[27.08.2025 09:13] Saving new data file.
[27.08.2025 09:13] Generating page.
[27.08.2025 09:13] Renaming previous page.
[27.08.2025 09:13] Renaming previous data. index.html to ./d/2025-08-27.html
[27.08.2025 09:13] Writing result.
[27.08.2025 09:13] Renaming log file.
[27.08.2025 09:13] Renaming previous data. log.txt to ./logs/2025-08-27_last_log.txt
