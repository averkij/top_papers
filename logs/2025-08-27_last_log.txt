[27.08.2025 13:23] Read previous papers.
[27.08.2025 13:23] Generating top page (month).
[27.08.2025 13:23] Writing top page (month).
[27.08.2025 14:11] Read previous papers.
[27.08.2025 14:11] Get feed.
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17445
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18124
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19205
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19247
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17661
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19209
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18756
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17437
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15774
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19242
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18621
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19188
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15804
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18773
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19026
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18672
[27.08.2025 14:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.18579
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18370
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18271
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16697
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17621
[27.08.2025 14:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.15213
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19202
[27.08.2025 14:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.18921
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18192
[27.08.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17234
[27.08.2025 14:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.08.2025 14:11] No deleted papers detected.
[27.08.2025 14:11] Downloading and parsing papers (pdf, html). Total: 26.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.17445.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.17445.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.17445.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.18124.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.18124.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.18124.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.19205.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.19205.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.19205.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.19247.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.19247.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.19247.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.17661.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.17661.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.17661.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.19209.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.19209.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.19209.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.18756.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.18756.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.18756.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.17437.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.17437.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.17437.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.15774.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.15774.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.15774.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.19242.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.19242.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.19242.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.18621.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.18621.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.18621.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.19188.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.19188.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.19188.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.15804.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.15804.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.15804.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.18773.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.18773.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.18773.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.19026.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.19026.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.19026.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.18672.
[27.08.2025 14:11] Extra JSON file exists (./assets/json/2508.18672.json), skip PDF parsing.
[27.08.2025 14:11] Paper image links file exists (./assets/img_data/2508.18672.json), skip HTML parsing.
[27.08.2025 14:11] Success.
[27.08.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2508.18579.
[27.08.2025 14:11] Downloading paper 2508.18579 from http://arxiv.org/pdf/2508.18579v1...
[27.08.2025 14:12] Extracting affiliations from text.
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 9 7 5 8 1 . 8 0 5 2 : r DrugReasoner: Interpretable Drug Approval Prediction with Reasoning-augmented Language Model Mohammadreza Ghaffarzadeh-Esfahani1, Ali Motahharynia1,2,*, Nahid Yousefian1, Navid Mazrouei1, Jafar Ghaisari3, and Yousof Gheisari1 1Regenerative Medicine Research Center, Isfahan University of Medical Sciences, Isfahan, Iran 2Isfahan Neuroscience Research Center, Isfahan University of Medical Sciences, Isfahan, Iran 3Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran *Corresponding author: Ali Motahharynia, Regenerative Medicine Research Center, Isfahan University of Medical Sciences, Isfahan, 81746 73461, Iran, Tel: +98 313 668 7087, Email: alimotahharynia@gmail.com, ORCID: 0000-0002-1140-3257 Abstract Drug discovery is complex and resource-intensive process, making early prediction of approval outcomes critical for optimizing research investments. While classical machine learning and deep learning methods have shown promise in drug approval prediction, their limited interpretability constraints their impact. Here, we present DrugReasoner, reasoning-based large language model (LLM) built on the LLaMA architecture and finetuned with group relative policy optimization (GRPO) to predict the likelihood of smallmolecule approval. DrugReasoner integrates molecular descriptors with comparative reasoning against structurally similar approved and unapproved compounds, generating predictions alongside step-by-step rationales and confidence scores. DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score of 0.729 on the validation set and 0.725 and 0.718 on the test set, respectively. These results outperformed conventional baselines, including logistic regression, support vector machine, and k-nearest neighbors and had competitive performance relative to XGBoost. On an external independent dataset, DrugReasoner outperformed both baseline and the recently developed ChemAP"
[27.08.2025 14:12] Response: ```python
[
    "Regenerative Medicine Research Center, Isfahan University of Medical Sciences, Isfahan, Iran",
    "Isfahan Neuroscience Research Center, Isfahan University of Medical Sciences, Isfahan, Iran",
    "Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran"
]
```
[27.08.2025 14:12] Deleting PDF ./assets/pdf/2508.18579.pdf.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.18370.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.18370.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.18370.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.18271.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.18271.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.18271.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.16697.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.16697.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.16697.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.17621.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.17621.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.17621.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.15213.
[27.08.2025 14:12] Downloading paper 2508.15213 from http://arxiv.org/pdf/2508.15213v1...
[27.08.2025 14:12] Extracting affiliations from text.
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering Bolei He1,2* Xinran He2* Run Shao2,3* Shanfu Shu2,4 Xianwei Xue2 Mingquan Cheng2 Haifeng Li3 Zhen-Hua Ling1 1University of Science and Technology of China, Hefei, China 2Baidu Inc., Beijing, China 3Central South University, Changsha, China 4Chongqing University, Chongqing, China. hebl@mail.ustc.edu.cn, zhling@ustc.edu.cn, {hexinran, xuexianwei, shushanfu, chengmingquan}@baidu.com, {shaorun, lihaifeng}@csu.edu.cn 5 2 0 2 1 ] . [ 1 3 1 2 5 1 . 8 0 5 2 : r a "
[27.08.2025 14:12] Response: ```python
[
    "University of Science and Technology of China, Hefei, China",
    "Baidu Inc., Beijing, China",
    "Central South University, Changsha, China",
    "Chongqing University, Chongqing, China"
]
```
[27.08.2025 14:12] Deleting PDF ./assets/pdf/2508.15213.pdf.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.19202.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.19202.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.19202.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.18921.
[27.08.2025 14:12] Downloading paper 2508.18921 from http://arxiv.org/pdf/2508.18921v1...
[27.08.2025 14:12] Extracting affiliations from text.
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . - [ 1 1 2 9 8 1 . 8 0 5 2 : r a Jakub Michanków TripleSun Krakow, Poland jakub.michankow@triplesun.net Abstract This study evaluates deep neural networks for forecasting probability distributions of financial returns. 1D convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) architectures are used to forecast parameters of three probability distributions: Normal, Students t, and skewed Students t. Using custom negative log-likelihood loss functions, distribution parameters are optimized directly. The models are tested on six major equity indices (S&P 500, BOVESPA, DAX, WIG, Nikkei 225, and KOSPI) using probabilistic evaluation metrics including Log Predictive Score (LPS), Continuous Ranked Probability Score (CRPS), and Probability Integral Transform (PIT). Results show that deep learning models provide accurate distributional forecasts and perform competitively with classical GARCH models for Value-at-Risk estimation. The LSTM with skewed Students distribution performs best across multiple evaluation criteria, capturing both heavy tails and asymmetry in financial returns. This work shows that deep neural networks are viable alternatives to traditional econometric models for financial risk assessment and portfolio management. Keywords: Deep Learning, Financial Forecasting, Probability Distributions, Risk Management, Value-at-Risk, LSTM, CNN 1. Introduction Financial return forecasting has moved from simple point prediction models to distributional forecasting that captures the full uncertainty structure of market dynamics. Traditional econometric approaches often struggle to model the complex, non-linear relationships and time-varying volatility patterns in financial time series. Deep learning opens new possibilities for capturing these patterns, yet most applications still focus on point forecasts rather than the complete distributional properties needed for risk management. Distributional forecasting in finance is important because ac"
[27.08.2025 14:12] Response: ```python
["TripleSun Krakow, Poland"]
```
[27.08.2025 14:12] Deleting PDF ./assets/pdf/2508.18921.pdf.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.18192.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.18192.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.18192.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Downloading and parsing paper https://huggingface.co/papers/2508.17234.
[27.08.2025 14:12] Extra JSON file exists (./assets/json/2508.17234.json), skip PDF parsing.
[27.08.2025 14:12] Paper image links file exists (./assets/img_data/2508.17234.json), skip HTML parsing.
[27.08.2025 14:12] Success.
[27.08.2025 14:12] Enriching papers with extra data.
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 0. TreePO, a self-guided rollout algorithm for sequence generation, reduces computational cost and enhances exploration diversity in reinforcement learning for large language models.  					AI-generated summary 				 Recent advancements in aligning large language models via reinforcement learning have ac...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 1. CMPhysBench evaluates LLMs in condensed matter physics using calculation problems and a new SEED score for partial credit assessment, revealing significant capability gaps.  					AI-generated summary 				 We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 2. VibeVoice synthesizes long-form multi-speaker speech using next-token diffusion and a highly efficient continuous speech tokenizer, achieving superior performance and fidelity.  					AI-generated summary 				 This report presents VibeVoice, a novel model designed to synthesize long-form speech with ...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 3. VoxHammer is a training-free method that performs precise and coherent 3D editing in latent space, ensuring consistency in preserved regions and high-quality overall results.  					AI-generated summary 				 3D local editing of specified regions is crucial for game industry and robot interaction. Rec...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 4. Spacer, a scientific discovery system, uses deliberate decontextualization to generate creative and factually grounded scientific concepts from keyword sets, achieving high accuracy and similarity to leading publications.  					AI-generated summary 				 Recent advances in LLMs have made automated sc...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 5. A framework using Multimodal Large Language Models and a specialized Multimodal DiT architecture generates semantically coherent and expressive character animations from multimodal inputs.  					AI-generated summary 				 Existing video avatar models can produce fluid human animations, yet they strug...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 6. UltraMemV2, a redesigned memory-layer architecture, achieves performance parity with 8-expert MoE models while significantly reducing memory access costs.  					AI-generated summary 				 While Mixture of Experts (MoE) models achieve remarkable efficiency by activating only subsets of parameters, the...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 7. PIXIE, a neural network method, predicts physical properties of 3D scenes from visual features, enabling fast and realistic physics simulation using supervised learning and pretrained visual features.  					AI-generated summary 				 Inferring the physical properties of 3D scenes from visual informat...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 8. CineScale is a novel inference paradigm that enables high-resolution visual generation for both images and videos without extensive fine-tuning, addressing issues of repetitive patterns and high-frequency information accumulation.  					AI-generated summary 				 Visual diffusion models achieve remar...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 9. AUSM, an autoregressive universal segmentation model, unifies prompted and unprompted video segmentation by treating it as sequential mask prediction, achieving superior performance and faster training on standard benchmarks.  					AI-generated summary 				 Recent video foundation models such as SAM...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 10. Wan-S2V, an audio-driven model built on Wan, enhances expressiveness and fidelity in cinematic character animation compared to existing methods.  					AI-generated summary 				 Current state-of-the-art (SOTA) methods for audio-driven character animation demonstrate promising performance for scenario...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 11. A framework for efficient artistic mesh generation reduces redundancy by separating vertex and face generation, using an autoregressive model for vertices and a bidirectional transformer for faces, and includes a fidelity enhancer and post-processing to improve quality and speed.  					AI-generated ...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 12. ReportBench evaluates the content quality of research reports generated by large language models, focusing on cited literature quality and statement faithfulness, demonstrating that commercial Deep Research agents produce more comprehensive and reliable reports than standalone LLMs.  					AI-generat...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 13. ThinkDial is an open-source framework that implements controllable reasoning in large language models through discrete operational modes, achieving performance while reducing computational effort.  					AI-generated summary 				 Large language models (LLMs) with chain-of-thought reasoning have demon...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 14. MovieCORE is a video question answering dataset that uses multiple large language models to generate deep cognitive questions, and introduces an agentic enhancement module to improve VQA model performance.  					AI-generated summary 				 This paper introduces MovieCORE, a novel video question answer...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 15. MoE models introduce sparsity that affects memorization and reasoning capabilities differently in large language models, with reasoning performance potentially regressing despite increased parameters.  					AI-generated summary 				 Empirical scaling laws have driven the evolution of large language ...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 16. DrugReasoner, a reasoning-based large language model fine-tuned with GRPO, predicts small-molecule approval with high accuracy and interpretability, outperforming conventional methods and enhancing transparency in drug discovery.  					AI-generated summary 				 Drug discovery is a complex and resour...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 17. CTF-Dojo, a large-scale executable runtime with 658 CTF challenges, enables rapid training of LLM-based agents with verifiable feedback, achieving state-of-the-art performance in competitive benchmarks.  					AI-generated summary 				 Large language models (LLMs) have demonstrated exceptional capabi...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 18. ObjFiller-3D uses video editing models to achieve high-quality and consistent 3D object completion, outperforming previous methods in terms of reconstruction fidelity and practical deployment.  					AI-generated summary 				 3D inpainting often relies on multi-view 2D image inpainting, where the inh...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 19. QueryBandits, a bandit framework, effectively mitigates hallucinations in LLMs by proactively rewriting queries based on linguistic features, outperforming static prompting strategies.  					AI-generated summary 				 Advanced reasoning capabilities in Large Language Models (LLMs) have caused higher ...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 20. The Flexible Activation Steering with Backtracking (FASB) framework dynamically adjusts the intervention strength and necessity in large language models during generation to align with desired behaviors, outperforming existing methods.  					AI-generated summary 				 Large language models (LLMs) hav...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 21. Selct2Know (S2K) enhances domain-specific QA by progressively internalizing and selecting knowledge through a cost-effective framework, outperforming existing methods with lower costs.  					AI-generated summary 				 Large Language Models (LLMs) perform well in general QA but often struggle in domai...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 22. SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for ...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 23. Deep neural networks, including 1D CNNs and LSTMs, provide accurate distributional forecasts of financial returns, outperforming classical GARCH models in Value-at-Risk estimation.  					AI-generated summary 				 This study evaluates deep neural networks for forecasting probability distributions of ...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 24. A network-based framework links cognitive skills, LLM architectures, and datasets, revealing unique emergent skill patterns in LLMs that benefit from dynamic, cross-regional interactions.  					AI-generated summary 				 Large Language Models (LLMs) have reshaped our world with significant advancemen...
[27.08.2025 14:12] ********************************************************************************
[27.08.2025 14:12] Abstract 25. The paper addresses the generation of legal claims for non-professionals using datasets and evaluation metrics, highlighting the limitations of current models in factual precision and clarity.  					AI-generated summary 				 Legal claims refer to the plaintiff's demands in a case and are essential t...
[27.08.2025 14:12] Read previous papers.
[27.08.2025 14:12] Generating reviews via LLM API.
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#rl", "#rlhf"], "emoji": "🌳", "ru": {"title": "TreePO: Эффективное обучение с подкреплением для языковых моделей", "desc": "Статья представляет TreePO - алгоритм самонаправляемой генерации последовательностей для обучения с подкреплением б
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset"], "emoji": "🔬", "ru": {"title": "Новый вызов для ИИ: решение задач по физике конденсированного состояния", "desc": "CMPhysBench - это новый бенчмарк для оценки способностей больших языковых моделей (LLM) в области физики конденсированного состояни
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#diffusion", "#audio"], "emoji": "🗣️", "ru": {"title": "VibeVoice: революция в синтезе длительной многоголосой речи", "desc": "VibeVoice - это новая модель для синтеза длительной многоголосой речи, использующая диффузию следующего токена и эффективны
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#games", "#dataset", "#synthetic", "#3d"], "emoji": "🔨", "ru": {"title": "Точное 3D-редактирование без компромиссов", "desc": "VoxHammer - это метод редактирования 3D-моделей в латентном пространстве без дополнительного обучения. Он обеспечивает точное и согласованное редактирование
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#science", "#data", "#multimodal", "#dataset"], "emoji": "🧬", "ru": {"title": "Spacer: Революция в автоматизированных научных открытиях", "desc": "Spacer - это система научных открытий, использующая намеренную деконтекстуализацию для генерации креативных и фактически обоснованных на
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#optimization", "#games", "#multimodal", "#video"], "emoji": "🎭", "ru": {"title": "Семантически осмысленная анимация персонажей с помощью мультимодального ИИ", "desc": "Эта статья представляет новую модель OmniHuman-1.5 для генерации анимации пе
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "UltraMemV2: Эффективность MoE без высоких затрат на память", "desc": "UltraMemV2 - это новая архитектура слоя памяти для нейронных сетей, которая достигает производительности 8-экспертных 
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#inference", "#synthetic", "#3d"], "emoji": "🧠", "ru": {"title": "Быстрое предсказание физических свойств 3D-сцен с помощью нейронных сетей", "desc": "PIXIE - это нейросетевой метод, который предсказывает физические свойства 3D-сцен на основе визуальных 
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#inference", "#cv", "#video"], "emoji": "🎬", "ru": {"title": "CineScale: Прорыв в генерации высококачественного визуального контента", "desc": "CineScale - это новая парадигма вывода, позволяющая генерировать изображения и видео высокого разрешения без 
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#architecture", "#training", "#video", "#optimization"], "emoji": "🎬", "ru": {"title": "Универсальная сегментация видео как последовательное предсказание масок", "desc": "AUSM - это модель универсальной сегментации видео, объединяющая подходы с подсказками и без них. Она рассматрива
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#story_generation", "#audio", "#games", "#benchmark", "#video"], "emoji": "🎭", "ru": {"title": "Wan-S2V: Революция в анимации кинематографических персонажей на основе аудио", "desc": "Модель Wan-S2V, основанная на аудио, улучшает выразительность и точность анимации кинематографическ
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "🎨", "ru": {"title": "Эффективная генерация 3D-моделей: разделяй и властвуй", "desc": "Предложена эффективная система генерации художественных 3D-моделей, разделяющая процессы создания вершин и граней. Для вершин используется авторегрессион
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#survey", "#agents", "#open_source"], "emoji": "🔬", "ru": {"title": "ReportBench: новый стандарт оценки AI-исследований", "desc": "ReportBench - это новый метод оценки качества исследовательских отчетов, сгенерированных большими языковыми моделями 
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#reasoning", "#agi", "#rl"], "emoji": "🧠", "ru": {"title": "ThinkDial: контролируемое рассуждение в больших языковых моделях", "desc": "ThinkDial - это фреймворк с открытым исходным кодом, который реализует контролируемо
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#video", "#reasoning", "#alignment", "#agents", "#benchmark", "#dataset"], "emoji": "🎬", "ru": {"title": "MovieCORE: Глубокое понимание фильмов с помощью ИИ", "desc": "MovieCORE - это новый набор данных для ответов на вопросы по видео, который использует несколько больших языковых м
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#architecture", "#training", "#open_source"], "emoji": "🧠", "ru": {"title": "Разреженность в MoE: компромисс между запоминанием и рассуждением", "desc": "Статья исследует влияние разреженности в моделях Mixture-of-Experts (MoE) на способности больших я
[27.08.2025 14:12] Querying the API.
[27.08.2025 14:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DrugReasoner, a reasoning-based large language model fine-tuned with GRPO, predicts small-molecule approval with high accuracy and interpretability, outperforming conventional methods and enhancing transparency in drug discovery.  					AI-generated summary 				 Drug discovery is a complex and resource-intensive process, making early prediction of approval outcomes critical for optimizing research investments. While classical machine learning and deep learning methods have shown promise in drug approval prediction, their limited interpretability constraints their impact. Here, we present DrugReasoner, a reasoning-based large language model (LLM) built on the LLaMA architecture and fine-tuned with group relative policy optimization (GRPO) to predict the likelihood of small-molecule approval. DrugReasoner integrates molecular descriptors with comparative reasoning against structurally similar approved and unapproved compounds, generating predictions alongside step-by-step rationales and confidence scores. DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score of 0.729 on the validation set and 0.725 and 0.718 on the test set, respectively. These results outperformed conventional baselines, including logistic regression, support vector machine, and k-nearest neighbors and had competitive performance relative to XGBoost. On an external independent dataset, DrugReasoner outperformed both baseline and the recently developed ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while maintaining high precision and balanced sensitivity, demonstrating robustness in real-world scenarios. These findings demonstrate that DrugReasoner not only delivers competitive predictive accuracy but also enhances transparency through its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug discovery. This study highlights the potential of reasoning-augmented LLMs as interpretable and effective tools for pharmaceutical decision-making.
[27.08.2025 14:12] Response: {
  "desc": "DrugReasoner - это языковая модель, основанная на архитектуре LLaMA и дообученная с помощью GRPO для прогнозирования вероятности одобрения малых молекул. Модель интегрирует молекулярные дескрипторы с сравнительным анализом структурно схожих одобренных и неодобренных соединений, генерируя прогнозы вместе с пошаговыми обоснованиями. DrugReasoner превзошел традиционные методы машинного обучения, достигнув AUC 0.732 и F1-score 0.729 на валидационном наборе. На независимом внешнем наборе данных модель также превзошла базовые методы и недавно разработанную модель ChemAP, продемонстрировав надежность в реальных сценариях.",
  "emoji": "💊",
  "title": "Интерпретируемый ИИ для прогнозирования одобрения лекарств"
}
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DrugReasoner, a reasoning-based large language model fine-tuned with GRPO, predicts small-molecule approval with high accuracy and interpretability, outperforming conventional methods and enhancing transparency in drug discovery.  					AI-generated summary 				 Drug discovery is a complex and resource-intensive process, making early prediction of approval outcomes critical for optimizing research investments. While classical machine learning and deep learning methods have shown promise in drug approval prediction, their limited interpretability constraints their impact. Here, we present DrugReasoner, a reasoning-based large language model (LLM) built on the LLaMA architecture and fine-tuned with group relative policy optimization (GRPO) to predict the likelihood of small-molecule approval. DrugReasoner integrates molecular descriptors with comparative reasoning against structurally similar approved and unapproved compounds, generating predictions alongside step-by-step rationales and confidence scores. DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score of 0.729 on the validation set and 0.725 and 0.718 on the test set, respectively. These results outperformed conventional baselines, including logistic regression, support vector machine, and k-nearest neighbors and had competitive performance relative to XGBoost. On an external independent dataset, DrugReasoner outperformed both baseline and the recently developed ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while maintaining high precision and balanced sensitivity, demonstrating robustness in real-world scenarios. These findings demonstrate that DrugReasoner not only delivers competitive predictive accuracy but also enhances transparency through its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug discovery. This study highlights the potential of reasoning-augmented LLMs as interpretable and effective tools for pharmaceutical decision-making."

[27.08.2025 14:12] Response: ```python
['HEALTHCARE', 'TRAINING', 'ARCHITECTURE']
```
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DrugReasoner, a reasoning-based large language model fine-tuned with GRPO, predicts small-molecule approval with high accuracy and interpretability, outperforming conventional methods and enhancing transparency in drug discovery.  					AI-generated summary 				 Drug discovery is a complex and resource-intensive process, making early prediction of approval outcomes critical for optimizing research investments. While classical machine learning and deep learning methods have shown promise in drug approval prediction, their limited interpretability constraints their impact. Here, we present DrugReasoner, a reasoning-based large language model (LLM) built on the LLaMA architecture and fine-tuned with group relative policy optimization (GRPO) to predict the likelihood of small-molecule approval. DrugReasoner integrates molecular descriptors with comparative reasoning against structurally similar approved and unapproved compounds, generating predictions alongside step-by-step rationales and confidence scores. DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score of 0.729 on the validation set and 0.725 and 0.718 on the test set, respectively. These results outperformed conventional baselines, including logistic regression, support vector machine, and k-nearest neighbors and had competitive performance relative to XGBoost. On an external independent dataset, DrugReasoner outperformed both baseline and the recently developed ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while maintaining high precision and balanced sensitivity, demonstrating robustness in real-world scenarios. These findings demonstrate that DrugReasoner not only delivers competitive predictive accuracy but also enhances transparency through its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug discovery. This study highlights the potential of reasoning-augmented LLMs as interpretable and effective tools for pharmaceutical decision-making."

[27.08.2025 14:12] Response: ```python
["INTERPRETABILITY", "REASONING", "SCIENCE"]
```
[27.08.2025 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DrugReasoner is a large language model designed to predict the approval of small molecules in drug discovery with high accuracy and interpretability. It uses a reasoning-based approach, integrating molecular descriptors and comparing them to similar compounds to generate predictions along with detailed rationales. This model outperforms traditional machine learning methods, such as logistic regression and support vector machines, by providing not only accurate predictions but also transparent reasoning behind them. The results indicate that DrugReasoner is a promising tool for enhancing decision-making in pharmaceutical research.","title":"Enhancing Drug Discovery with Transparent Predictions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DrugReasoner is a large language model designed to predict the approval of small molecules in drug discovery with high accuracy and interpretability. It uses a reasoning-based approach, integrating molecular descriptors and comparing them to similar compounds to generate predictions along with detailed rationales. This model outperforms traditional machine learning methods, such as logistic regression and support vector machines, by providing not only accurate predictions but also transparent reasoning behind them. The results indicate that DrugReasoner is a promising tool for enhancing decision-making in pharmaceutical research.', title='Enhancing Drug Discovery with Transparent Predictions'))
[27.08.2025 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DrugReasoner是一种基于推理的大型语言模型，经过GRPO微调，能够高精度地预测小分子的批准情况，并且具有良好的可解释性。与传统方法相比，DrugReasoner在药物发现中提高了透明度，帮助研究人员更好地理解预测结果。该模型结合了分子描述符和对比推理，生成逐步的推理过程和置信分数。研究结果表明，DrugReasoner在多个数据集上表现优异，展示了推理增强的语言模型在制药决策中的潜力。","title":"DrugReasoner：提升药物发现透明度的推理模型"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DrugReasoner是一种基于推理的大型语言模型，经过GRPO微调，能够高精度地预测小分子的批准情况，并且具有良好的可解释性。与传统方法相比，DrugReasoner在药物发现中提高了透明度，帮助研究人员更好地理解预测结果。该模型结合了分子描述符和对比推理，生成逐步的推理过程和置信分数。研究结果表明，DrugReasoner在多个数据集上表现优异，展示了推理增强的语言模型在制药决策中的潜力。', title='DrugReasoner：提升药物发现透明度的推理模型'))
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#open_source", "#training", "#dataset", "#games", "#benchmark", "#agents"], "emoji": "🏆", "ru": {"title": "CTF-Dojo: революция в обучении ИИ-агентов через исполняемую среду", "desc": "CTF-Dojo - это крупномасштабная исполняемая среда с 658 задачами CTF, позволяющая быстро обучать аг
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#video", "#optimization", "#3d"], "emoji": "🎨", "ru": {"title": "Революция в 3D-инпейнтинге: от видео к реалистичным объектам", "desc": "ObjFiller-3D - это новый метод для заполнения и редактирования трехмерных объектов высокого качества. Он использует модели редактирования видео дл
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#reasoning", "#training", "#hallucinations", "#multimodal", "#rl"], "emoji": "🎯", "ru": {"title": "Умное переписывание запросов побеждает галлюцинации ИИ", "desc": "QueryBandits - это фреймворк, использующий алгоритмы многоруких бандитов для снижения галлюцинаций в больших языковых 
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#training", "#inference", "#alignment"], "emoji": "🎛️", "ru": {"title": "Гибкое управление языковыми моделями в реальном времени", "desc": "Предложена новая система под названием FASB (Гибкое управление активацией с откатом) для динамической корректировки вмешательства в работу боль
[27.08.2025 14:12] Querying the API.
[27.08.2025 14:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Selct2Know (S2K) enhances domain-specific QA by progressively internalizing and selecting knowledge through a cost-effective framework, outperforming existing methods with lower costs.  					AI-generated summary 				 Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost.
[27.08.2025 14:12] Response: {
  "desc": "Selct2Know (S2K) - это фреймворк для улучшения вопросно-ответных систем в специфических предметных областях. Он использует стратегию самостоятельного выбора между внутренними и внешними знаниями, а также селективное обучение с учителем. S2K включает в себя структурированную генерацию данных для рассуждений и интеграцию GRPO для усиления способности к логическим выводам. Эксперименты показывают, что S2K превосходит существующие методы и сравнимо с предобученными на конкретной области языковыми моделями, но при значительно меньших затратах.",
  "emoji": "🧠",
  "title": "Прогрессивное обучение ИИ: от концепций к сложным рассуждениям"
}
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Selct2Know (S2K) enhances domain-specific QA by progressively internalizing and selecting knowledge through a cost-effective framework, outperforming existing methods with lower costs.  					AI-generated summary 				 Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost."

[27.08.2025 14:12] Response: ```python
['RAG', 'TRAINING', 'HEALTHCARE']
```
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Selct2Know (S2K) enhances domain-specific QA by progressively internalizing and selecting knowledge through a cost-effective framework, outperforming existing methods with lower costs.  					AI-generated summary 				 Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost."

[27.08.2025 14:12] Response: ```python
['REASONING', 'HALLUCINATIONS', 'OPTIMIZATION']
```
[27.08.2025 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Selct2Know (S2K) is a framework designed to improve question answering (QA) in specific domains by progressively selecting and internalizing knowledge. It addresses the limitations of existing methods, which often incur high costs and struggle with noisy data retrieval. By mimicking human learning processes, S2K enhances reasoning capabilities through a structured approach to knowledge acquisition and selective fine-tuning. Experiments demonstrate that S2K not only outperforms traditional methods but also achieves results comparable to domain-pretrained large language models at a lower cost.","title":"Progressive Knowledge Selection for Cost-Effective Domain-Specific QA"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Selct2Know (S2K) is a framework designed to improve question answering (QA) in specific domains by progressively selecting and internalizing knowledge. It addresses the limitations of existing methods, which often incur high costs and struggle with noisy data retrieval. By mimicking human learning processes, S2K enhances reasoning capabilities through a structured approach to knowledge acquisition and selective fine-tuning. Experiments demonstrate that S2K not only outperforms traditional methods but also achieves results comparable to domain-pretrained large language models at a lower cost.', title='Progressive Knowledge Selection for Cost-Effective Domain-Specific QA'))
[27.08.2025 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Selct2Know (S2K) 是一种增强领域特定问答的框架，通过逐步内化和选择知识来提高性能，同时降低成本。与现有方法相比，S2K 在医疗、法律和金融等领域的问答基准测试中表现更佳。该方法采用内部-外部知识自我选择策略和选择性监督微调，模仿人类学习的过程。实验结果表明，S2K 能够有效利用部分知识，提升推理能力，且成本显著低于领域预训练的大型语言模型。","title":"逐步内化知识，提升领域问答能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Selct2Know (S2K) 是一种增强领域特定问答的框架，通过逐步内化和选择知识来提高性能，同时降低成本。与现有方法相比，S2K 在医疗、法律和金融等领域的问答基准测试中表现更佳。该方法采用内部-外部知识自我选择策略和选择性监督微调，模仿人类学习的过程。实验结果表明，S2K 能够有效利用部分知识，提升推理能力，且成本显著低于领域预训练的大型语言模型。', title='逐步内化知识，提升领域问答能力'))
[27.08.2025 14:12] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#multimodal", "#science"], "emoji": "🧠", "ru": {"title": "Разделяй и властвуй: новый подход к оценке научного мышления ЯМ", "desc": "Статья представляет новые бенчмарки SciReas и SciReas-Pro для оценки научного мышления у языковых моделей. Авт
[27.08.2025 14:12] Querying the API.
[27.08.2025 14:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Deep neural networks, including 1D CNNs and LSTMs, provide accurate distributional forecasts of financial returns, outperforming classical GARCH models in Value-at-Risk estimation.  					AI-generated summary 				 This study evaluates deep neural networks for forecasting probability distributions of financial returns. 1D convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) architectures are used to forecast parameters of three probability distributions: Normal, Student's t, and skewed Student's t. Using custom negative log-likelihood loss functions, distribution parameters are optimized directly. The models are tested on six major equity indices (S\&P 500, BOVESPA, DAX, WIG, Nikkei 225, and KOSPI) using probabilistic evaluation metrics including Log Predictive Score (LPS), Continuous Ranked Probability Score (CRPS), and Probability Integral Transform (PIT). Results show that deep learning models provide accurate distributional forecasts and perform competitively with classical GARCH models for Value-at-Risk estimation. The LSTM with skewed Student's t distribution performs best across multiple evaluation criteria, capturing both heavy tails and asymmetry in financial returns. This work shows that deep neural networks are viable alternatives to traditional econometric models for financial risk assessment and portfolio management.
[27.08.2025 14:12] Response: {
  "desc": "Исследование оценивает эффективность глубоких нейронных сетей для прогнозирования распределения вероятностей финансовых доходностей. Используются одномерные сверточные нейронные сети (CNN) и сети с долгой краткосрочной памятью (LSTM) для прогнозирования параметров трех распределений вероятностей. Модели тестируются на шести основных фондовых индексах с использованием вероятностных метрик оценки. Результаты показывают, что модели глубокого обучения обеспечивают точные прогнозы распределения и конкурентоспособны с классическими моделями GARCH для оценки Value-at-Risk.",
  "emoji": "📊",
  "title": "Глубокие нейросети превосходят GARCH в прогнозировании финансовых рисков"
}
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Deep neural networks, including 1D CNNs and LSTMs, provide accurate distributional forecasts of financial returns, outperforming classical GARCH models in Value-at-Risk estimation.  					AI-generated summary 				 This study evaluates deep neural networks for forecasting probability distributions of financial returns. 1D convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) architectures are used to forecast parameters of three probability distributions: Normal, Student's t, and skewed Student's t. Using custom negative log-likelihood loss functions, distribution parameters are optimized directly. The models are tested on six major equity indices (S\&P 500, BOVESPA, DAX, WIG, Nikkei 225, and KOSPI) using probabilistic evaluation metrics including Log Predictive Score (LPS), Continuous Ranked Probability Score (CRPS), and Probability Integral Transform (PIT). Results show that deep learning models provide accurate distributional forecasts and perform competitively with classical GARCH models for Value-at-Risk estimation. The LSTM with skewed Student's t distribution performs best across multiple evaluation criteria, capturing both heavy tails and asymmetry in financial returns. This work shows that deep neural networks are viable alternatives to traditional econometric models for financial risk assessment and portfolio management."

[27.08.2025 14:12] Response: ```python
['DATA', 'BENCHMARK', 'ARCHITECTURE', 'TRAINING']
```
[27.08.2025 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Deep neural networks, including 1D CNNs and LSTMs, provide accurate distributional forecasts of financial returns, outperforming classical GARCH models in Value-at-Risk estimation.  					AI-generated summary 				 This study evaluates deep neural networks for forecasting probability distributions of financial returns. 1D convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) architectures are used to forecast parameters of three probability distributions: Normal, Student's t, and skewed Student's t. Using custom negative log-likelihood loss functions, distribution parameters are optimized directly. The models are tested on six major equity indices (S\&P 500, BOVESPA, DAX, WIG, Nikkei 225, and KOSPI) using probabilistic evaluation metrics including Log Predictive Score (LPS), Continuous Ranked Probability Score (CRPS), and Probability Integral Transform (PIT). Results show that deep learning models provide accurate distributional forecasts and perform competitively with classical GARCH models for Value-at-Risk estimation. The LSTM with skewed Student's t distribution performs best across multiple evaluation criteria, capturing both heavy tails and asymmetry in financial returns. This work shows that deep neural networks are viable alternatives to traditional econometric models for financial risk assessment and portfolio management."

[27.08.2025 14:12] Response: ```python
['OPTIMIZATION', 'SCIENCE']
```
[27.08.2025 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the use of deep neural networks, specifically 1D CNNs and LSTMs, for predicting the probability distributions of financial returns. The authors optimize the parameters of Normal, Student\'s t, and skewed Student\'s t distributions using custom negative log-likelihood loss functions. They evaluate the models on six major equity indices and utilize probabilistic metrics like Log Predictive Score and Continuous Ranked Probability Score to assess performance. The findings indicate that these deep learning models outperform traditional GARCH models in Value-at-Risk estimation, particularly highlighting the effectiveness of LSTMs with skewed Student\'s t distributions in capturing complex financial return characteristics.","title":"Deep Learning Outperforms Traditional Models in Financial Forecasting"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper explores the use of deep neural networks, specifically 1D CNNs and LSTMs, for predicting the probability distributions of financial returns. The authors optimize the parameters of Normal, Student's t, and skewed Student's t distributions using custom negative log-likelihood loss functions. They evaluate the models on six major equity indices and utilize probabilistic metrics like Log Predictive Score and Continuous Ranked Probability Score to assess performance. The findings indicate that these deep learning models outperform traditional GARCH models in Value-at-Risk estimation, particularly highlighting the effectiveness of LSTMs with skewed Student's t distributions in capturing complex financial return characteristics.", title='Deep Learning Outperforms Traditional Models in Financial Forecasting'))
[27.08.2025 14:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究评估了深度神经网络在金融收益概率分布预测中的应用。使用一维卷积神经网络（CNN）和长短期记忆网络（LSTM）来预测三种概率分布的参数：正态分布、学生t分布和偏斜学生t分布。通过自定义的负对数似然损失函数，直接优化分布参数。结果表明，深度学习模型在价值-at-risk（VaR）估计中表现优于传统的GARCH模型，尤其是使用偏斜学生t分布的LSTM在多个评估标准中表现最佳。","title":"深度学习助力金融风险评估"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究评估了深度神经网络在金融收益概率分布预测中的应用。使用一维卷积神经网络（CNN）和长短期记忆网络（LSTM）来预测三种概率分布的参数：正态分布、学生t分布和偏斜学生t分布。通过自定义的负对数似然损失函数，直接优化分布参数。结果表明，深度学习模型在价值-at-risk（VaR）估计中表现优于传统的GARCH模型，尤其是使用偏斜学生t分布的LSTM在多个评估标准中表现最佳。', title='深度学习助力金融风险评估'))
[27.08.2025 14:13] Using data from previous issue: {"categories": ["#architecture", "#science", "#training", "#interpretability", "#dataset"], "emoji": "🧠", "ru": {"title": "Сетевой анализ раскрывает когнитивные паттерны в языковых моделях", "desc": "Данная статья представляет сетевую модель, связывающую когнитивные навыки, архитектуры языковых моде
[27.08.2025 14:13] Using data from previous issue: {"categories": ["#dataset", "#science", "#open_source", "#benchmark"], "emoji": "⚖️", "ru": {"title": "ИИ на защите прав: генерация юридических исков для всех", "desc": "Статья посвящена генерации юридических исков для непрофессионалов с использованием датасетов и метрик оценки. Авторы создали первы
[27.08.2025 14:13] Renaming data file.
[27.08.2025 14:13] Renaming previous data. hf_papers.json to ./d/2025-08-27.json
[27.08.2025 14:13] Saving new data file.
[27.08.2025 14:13] Generating page.
[27.08.2025 14:13] Renaming previous page.
[27.08.2025 14:13] Renaming previous data. index.html to ./d/2025-08-27.html
[27.08.2025 14:13] Writing result.
[27.08.2025 14:13] Renaming log file.
[27.08.2025 14:13] Renaming previous data. log.txt to ./logs/2025-08-27_last_log.txt
