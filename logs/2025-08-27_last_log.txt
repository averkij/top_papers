[27.08.2025 12:21] Read previous papers.
[27.08.2025 12:21] Generating top page (month).
[27.08.2025 12:21] Writing top page (month).
[27.08.2025 13:22] Read previous papers.
[27.08.2025 13:22] Get feed.
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17445
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18124
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19205
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19247
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17661
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19209
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18756
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17437
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19242
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18621
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15774
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19188
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15804
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18773
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19026
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18672
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18370
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18271
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16697
[27.08.2025 13:22] Extract page data from URL. URL: https://huggingface.co/papers/2508.17621
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.19202
[27.08.2025 13:22] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18192
[27.08.2025 13:22] Extract page data from URL. URL: https://huggingface.co/papers/2508.17234
[27.08.2025 13:22] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.08.2025 13:22] No deleted papers detected.
[27.08.2025 13:22] Downloading and parsing papers (pdf, html). Total: 23.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.17445.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.17445.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.17445.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18124.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18124.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18124.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19205.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19205.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19205.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19247.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19247.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19247.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.17661.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.17661.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.17661.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19209.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19209.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19209.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18756.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18756.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18756.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.17437.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.17437.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.17437.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19242.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19242.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19242.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18621.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18621.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18621.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.15774.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.15774.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.15774.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19188.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19188.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19188.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.15804.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.15804.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.15804.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18773.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18773.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18773.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19026.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19026.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19026.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18672.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18672.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18672.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18370.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18370.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18370.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18271.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18271.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18271.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.16697.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.16697.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.16697.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.17621.
[27.08.2025 13:22] Downloading paper 2508.17621 from http://arxiv.org/pdf/2508.17621v1...
[27.08.2025 13:22] Extracting affiliations from text.
[27.08.2025 13:22] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 2 ] . [ 1 1 2 6 7 1 . 8 0 5 2 : r Steering When Necessary: Flexible Steering Large Language Models with Backtracking Jinwei Gan, Zifeng Cheng, Zhiwei Jiang, Cong Wang, Yafeng Yin, Xiang Luo, Yuchen Fu, Qing Gu State Key Laboratory for Novel Software Technology, Nanjing University, China {ganjw,chengzf}@smail.nju.edu.cn, jzw@.nju.edu.cn, cw@smail.nju.edu.cn, yafeng@nju.edu.cn, {luoxiang,yuchenfu}@smail.nju.edu.cn, guq@.nju.edu.cn "
[27.08.2025 13:22] Response: ```python
["State Key Laboratory for Novel Software Technology, Nanjing University, China"]
```
[27.08.2025 13:22] Deleting PDF ./assets/pdf/2508.17621.pdf.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.19202.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.19202.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.19202.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.18192.
[27.08.2025 13:22] Extra JSON file exists (./assets/json/2508.18192.json), skip PDF parsing.
[27.08.2025 13:22] Paper image links file exists (./assets/img_data/2508.18192.json), skip HTML parsing.
[27.08.2025 13:22] Success.
[27.08.2025 13:22] Downloading and parsing paper https://huggingface.co/papers/2508.17234.
[27.08.2025 13:22] Downloading paper 2508.17234 from http://arxiv.org/pdf/2508.17234v1...
[27.08.2025 13:23] Extracting affiliations from text.
[27.08.2025 13:23] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 2 ] . [ 1 4 3 2 7 1 . 8 0 5 2 : r ClaimGen-CN: Large-scale Chinese Dataset for Legal Claim Generation Siying Zhou1, Yiquan Wu1, Hui Chen1, Xavier Hu1, Kun Kuang1 Adam Jatowt2, Ming Hu1, Chunyan Zheng1, Fei Wu1 1Zhejiang University, Hangzhou, China 2University of Innsbruck, Innsbruck, Austria {zhousiying, wuyiquan, 22402119, kunkuang,hm606, boxzheng}@zju.edu.cn xavier.hu.research@gmail.com, adam.jatowt@uibk.ac.at, wufei@cs.zju.edu.cn "
[27.08.2025 13:23] Response: ```python
["Zhejiang University, Hangzhou, China", "University of Innsbruck, Innsbruck, Austria"]
```
[27.08.2025 13:23] Deleting PDF ./assets/pdf/2508.17234.pdf.
[27.08.2025 13:23] Success.
[27.08.2025 13:23] Enriching papers with extra data.
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 0. TreePO, a self-guided rollout algorithm for sequence generation, reduces computational cost and enhances exploration diversity in reinforcement learning for large language models.  					AI-generated summary 				 Recent advancements in aligning large language models via reinforcement learning have ac...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 1. CMPhysBench evaluates LLMs in condensed matter physics using calculation problems and a new SEED score for partial credit assessment, revealing significant capability gaps.  					AI-generated summary 				 We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 2. VibeVoice synthesizes long-form multi-speaker speech using next-token diffusion and a highly efficient continuous speech tokenizer, achieving superior performance and fidelity.  					AI-generated summary 				 This report presents VibeVoice, a novel model designed to synthesize long-form speech with ...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 3. VoxHammer is a training-free method that performs precise and coherent 3D editing in latent space, ensuring consistency in preserved regions and high-quality overall results.  					AI-generated summary 				 3D local editing of specified regions is crucial for game industry and robot interaction. Rec...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 4. Spacer, a scientific discovery system, uses deliberate decontextualization to generate creative and factually grounded scientific concepts from keyword sets, achieving high accuracy and similarity to leading publications.  					AI-generated summary 				 Recent advances in LLMs have made automated sc...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 5. A framework using Multimodal Large Language Models and a specialized Multimodal DiT architecture generates semantically coherent and expressive character animations from multimodal inputs.  					AI-generated summary 				 Existing video avatar models can produce fluid human animations, yet they strug...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 6. UltraMemV2, a redesigned memory-layer architecture, achieves performance parity with 8-expert MoE models while significantly reducing memory access costs.  					AI-generated summary 				 While Mixture of Experts (MoE) models achieve remarkable efficiency by activating only subsets of parameters, the...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 7. PIXIE, a neural network method, predicts physical properties of 3D scenes from visual features, enabling fast and realistic physics simulation using supervised learning and pretrained visual features.  					AI-generated summary 				 Inferring the physical properties of 3D scenes from visual informat...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 8. AUSM, an autoregressive universal segmentation model, unifies prompted and unprompted video segmentation by treating it as sequential mask prediction, achieving superior performance and faster training on standard benchmarks.  					AI-generated summary 				 Recent video foundation models such as SAM...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 9. Wan-S2V, an audio-driven model built on Wan, enhances expressiveness and fidelity in cinematic character animation compared to existing methods.  					AI-generated summary 				 Current state-of-the-art (SOTA) methods for audio-driven character animation demonstrate promising performance for scenario...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 10. CineScale is a novel inference paradigm that enables high-resolution visual generation for both images and videos without extensive fine-tuning, addressing issues of repetitive patterns and high-frequency information accumulation.  					AI-generated summary 				 Visual diffusion models achieve remar...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 11. A framework for efficient artistic mesh generation reduces redundancy by separating vertex and face generation, using an autoregressive model for vertices and a bidirectional transformer for faces, and includes a fidelity enhancer and post-processing to improve quality and speed.  					AI-generated ...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 12. ReportBench evaluates the content quality of research reports generated by large language models, focusing on cited literature quality and statement faithfulness, demonstrating that commercial Deep Research agents produce more comprehensive and reliable reports than standalone LLMs.  					AI-generat...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 13. ThinkDial is an open-source framework that implements controllable reasoning in large language models through discrete operational modes, achieving performance while reducing computational effort.  					AI-generated summary 				 Large language models (LLMs) with chain-of-thought reasoning have demon...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 14. MovieCORE is a video question answering dataset that uses multiple large language models to generate deep cognitive questions, and introduces an agentic enhancement module to improve VQA model performance.  					AI-generated summary 				 This paper introduces MovieCORE, a novel video question answer...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 15. MoE models introduce sparsity that affects memorization and reasoning capabilities differently in large language models, with reasoning performance potentially regressing despite increased parameters.  					AI-generated summary 				 Empirical scaling laws have driven the evolution of large language ...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 16. CTF-Dojo, a large-scale executable runtime with 658 CTF challenges, enables rapid training of LLM-based agents with verifiable feedback, achieving state-of-the-art performance in competitive benchmarks.  					AI-generated summary 				 Large language models (LLMs) have demonstrated exceptional capabi...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 17. ObjFiller-3D uses video editing models to achieve high-quality and consistent 3D object completion, outperforming previous methods in terms of reconstruction fidelity and practical deployment.  					AI-generated summary 				 3D inpainting often relies on multi-view 2D image inpainting, where the inh...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 18. QueryBandits, a bandit framework, effectively mitigates hallucinations in LLMs by proactively rewriting queries based on linguistic features, outperforming static prompting strategies.  					AI-generated summary 				 Advanced reasoning capabilities in Large Language Models (LLMs) have caused higher ...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 19. The Flexible Activation Steering with Backtracking (FASB) framework dynamically adjusts the intervention strength and necessity in large language models during generation to align with desired behaviors, outperforming existing methods.  					AI-generated summary 				 Large language models (LLMs) hav...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 20. SciReas and SciReas-Pro benchmarks, along with KRUX framework, provide insights into the distinct roles of knowledge and reasoning in scientific tasks, highlighting critical bottlenecks and improvements for LLMs.  					AI-generated summary 				 Scientific problem solving poses unique challenges for ...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 21. A network-based framework links cognitive skills, LLM architectures, and datasets, revealing unique emergent skill patterns in LLMs that benefit from dynamic, cross-regional interactions.  					AI-generated summary 				 Large Language Models (LLMs) have reshaped our world with significant advancemen...
[27.08.2025 13:23] ********************************************************************************
[27.08.2025 13:23] Abstract 22. The paper addresses the generation of legal claims for non-professionals using datasets and evaluation metrics, highlighting the limitations of current models in factual precision and clarity.  					AI-generated summary 				 Legal claims refer to the plaintiff's demands in a case and are essential t...
[27.08.2025 13:23] Read previous papers.
[27.08.2025 13:23] Generating reviews via LLM API.
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#training", "#rl", "#rlhf"], "emoji": "üå≥", "ru": {"title": "TreePO: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç TreePO - –∞–ª–≥–æ—Ä–∏—Ç–º —Å–∞–º–æ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –±
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset"], "emoji": "üî¨", "ru": {"title": "–ù–æ–≤—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –ò–ò: —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á –ø–æ —Ñ–∏–∑–∏–∫–µ –∫–æ–Ω–¥–µ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è", "desc": "CMPhysBench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–∑–∏–∫–∏ –∫–æ–Ω–¥–µ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#open_source", "#long_context", "#diffusion", "#audio"], "emoji": "üó£Ô∏è", "ru": {"title": "VibeVoice: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∏–Ω—Ç–µ–∑–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–Ω–æ–≥–æ–≥–æ–ª–æ—Å–æ–π —Ä–µ—á–∏", "desc": "VibeVoice - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–Ω–æ–≥–æ–≥–æ–ª–æ—Å–æ–π —Ä–µ—á–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—é —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#games", "#dataset", "#synthetic", "#3d"], "emoji": "üî®", "ru": {"title": "–¢–æ—á–Ω–æ–µ 3D-—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤", "desc": "VoxHammer - —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è 3D-–º–æ–¥–µ–ª–µ–π –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ–µ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#science", "#data", "#multimodal", "#dataset"], "emoji": "üß¨", "ru": {"title": "Spacer: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç–∏—è—Ö", "desc": "Spacer - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞—É—á–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –Ω–∞–º–µ—Ä–µ–Ω–Ω—É—é –¥–µ–∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã—Ö –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#optimization", "#games", "#multimodal", "#video"], "emoji": "üé≠", "ru": {"title": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ò–ò", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å OmniHuman-1.5 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∏–º–∞—Ü–∏–∏ –ø–µ
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#architecture", "#long_context", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "UltraMemV2: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å MoE –±–µ–∑ –≤—ã—Å–æ–∫–∏—Ö –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –ø–∞–º—è—Ç—å", "desc": "UltraMemV2 - —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–ª–æ—è –ø–∞–º—è—Ç–∏ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –∫–æ—Ç–æ—Ä–∞—è –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 8-—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö 
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#inference", "#synthetic", "#3d"], "emoji": "üß†", "ru": {"title": "–ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ 3D-—Å—Ü–µ–Ω —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π", "desc": "PIXIE - —ç—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ 3D-—Å—Ü–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö 
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#architecture", "#training", "#video", "#optimization"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–æ–∫", "desc": "AUSM - —ç—Ç–æ –º–æ–¥–µ–ª—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø–æ–¥—Ö–æ–¥—ã —Å –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏ –∏ –±–µ–∑ –Ω–∏—Ö. –û–Ω–∞ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#story_generation", "#audio", "#games", "#benchmark", "#video"], "emoji": "üé≠", "ru": {"title": "Wan-S2V: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–Ω–∏–º–∞—Ü–∏–∏ –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—É–¥–∏–æ", "desc": "–ú–æ–¥–µ–ª—å Wan-S2V, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞—É–¥–∏–æ, —É–ª—É—á—à–∞–µ—Ç –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∏–º–∞—Ü–∏–∏ –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#inference", "#cv", "#video"], "emoji": "üé¨", "ru": {"title": "CineScale: –ü—Ä–æ—Ä—ã–≤ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "CineScale - —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –≤—ã–≤–æ–¥–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–∏–¥–µ–æ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –±–µ–∑ 
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "üé®", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 3D-–º–æ–¥–µ–ª–µ–π: —Ä–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö 3D-–º–æ–¥–µ–ª–µ–π, —Ä–∞–∑–¥–µ–ª—è—é—â–∞—è –ø—Ä–æ—Ü–µ—Å—Å—ã —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ—Ä—à–∏–Ω –∏ –≥—Ä–∞–Ω–µ–π. –î–ª—è –≤–µ—Ä—à–∏–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#survey", "#agents", "#open_source"], "emoji": "üî¨", "ru": {"title": "ReportBench: –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ AI-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π", "desc": "ReportBench - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ 
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#reasoning", "#agi", "#rl"], "emoji": "üß†", "ru": {"title": "ThinkDial: –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "ThinkDial - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#video", "#reasoning", "#alignment", "#agents", "#benchmark", "#dataset"], "emoji": "üé¨", "ru": {"title": "MovieCORE: –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ñ–∏–ª—å–º–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "MovieCORE - —ç—Ç–æ –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#architecture", "#training", "#open_source"], "emoji": "üß†", "ru": {"title": "–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –≤ MoE: –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of-Experts (MoE) –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#open_source", "#training", "#dataset", "#games", "#benchmark", "#agents"], "emoji": "üèÜ", "ru": {"title": "CTF-Dojo: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∏—Å–ø–æ–ª–Ω—è–µ–º—É—é —Å—Ä–µ–¥—É", "desc": "CTF-Dojo - —ç—Ç–æ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–∞—è –∏—Å–ø–æ–ª–Ω—è–µ–º–∞—è —Å—Ä–µ–¥–∞ —Å 658 –∑–∞–¥–∞—á–∞–º–∏ CTF, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞—Ç—å –∞–≥
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#video", "#optimization", "#3d"], "emoji": "üé®", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-–∏–Ω–ø–µ–π–Ω—Ç–∏–Ω–≥–µ: –æ—Ç –≤–∏–¥–µ–æ –∫ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º –æ–±—ä–µ–∫—Ç–∞–º", "desc": "ObjFiller-3D - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ –¥–ª
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#reasoning", "#training", "#hallucinations", "#multimodal", "#rl"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω–æ–µ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–±–µ–∂–¥–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –ò–ò", "desc": "QueryBandits - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–æ–≤ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö 
[27.08.2025 13:23] Querying the API.
[27.08.2025 13:23] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Flexible Activation Steering with Backtracking (FASB) framework dynamically adjusts the intervention strength and necessity in large language models during generation to align with desired behaviors, outperforming existing methods.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable performance across many generation tasks. Nevertheless, effectively aligning them with desired behaviors remains a significant challenge. Activation steering is an effective and cost-efficient approach that directly modifies the activations of LLMs during the inference stage, aligning their responses with the desired behaviors and avoiding the high cost of fine-tuning. Existing methods typically indiscriminately intervene to all generations or rely solely on the question to determine intervention, which limits the accurate assessment of the intervention strength. To this end, we propose the Flexible Activation Steering with Backtracking (FASB) framework, which dynamically determines both the necessity and strength of intervention by tracking the internal states of the LLMs during generation, considering both the question and the generated content. Since intervening after detecting a deviation from the desired behavior is often too late, we further propose the backtracking mechanism to correct the deviated tokens and steer the LLMs toward the desired behavior. Extensive experiments on the TruthfulQA dataset and six multiple-choice datasets demonstrate that our method outperforms baselines. Our code will be released at https://github.com/gjw185/FASB.
[27.08.2025 13:23] Response: {
  "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º FASB (–ì–∏–±–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π —Å –æ—Ç–∫–∞—Ç–æ–º) –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ —Ä–∞–±–æ—Ç—É –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. FASB –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∏ —Å–∏–ª—É –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞, –æ—Ç—Å–ª–µ–∂–∏–≤–∞—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º –æ—Ç–∫–∞—Ç–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –æ—Ç –∂–µ–ª–∞–µ–º–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ FASB –Ω–∞–¥ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö.",
  "emoji": "üéõÔ∏è",
  "title": "–ì–∏–±–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"
}
[27.08.2025 13:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Flexible Activation Steering with Backtracking (FASB) framework dynamically adjusts the intervention strength and necessity in large language models during generation to align with desired behaviors, outperforming existing methods.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable performance across many generation tasks. Nevertheless, effectively aligning them with desired behaviors remains a significant challenge. Activation steering is an effective and cost-efficient approach that directly modifies the activations of LLMs during the inference stage, aligning their responses with the desired behaviors and avoiding the high cost of fine-tuning. Existing methods typically indiscriminately intervene to all generations or rely solely on the question to determine intervention, which limits the accurate assessment of the intervention strength. To this end, we propose the Flexible Activation Steering with Backtracking (FASB) framework, which dynamically determines both the necessity and strength of intervention by tracking the internal states of the LLMs during generation, considering both the question and the generated content. Since intervening after detecting a deviation from the desired behavior is often too late, we further propose the backtracking mechanism to correct the deviated tokens and steer the LLMs toward the desired behavior. Extensive experiments on the TruthfulQA dataset and six multiple-choice datasets demonstrate that our method outperforms baselines. Our code will be released at https://github.com/gjw185/FASB."

[27.08.2025 13:23] Response: ```python
['INFERENCE', 'TRAINING']
```
[27.08.2025 13:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Flexible Activation Steering with Backtracking (FASB) framework dynamically adjusts the intervention strength and necessity in large language models during generation to align with desired behaviors, outperforming existing methods.  					AI-generated summary 				 Large language models (LLMs) have achieved remarkable performance across many generation tasks. Nevertheless, effectively aligning them with desired behaviors remains a significant challenge. Activation steering is an effective and cost-efficient approach that directly modifies the activations of LLMs during the inference stage, aligning their responses with the desired behaviors and avoiding the high cost of fine-tuning. Existing methods typically indiscriminately intervene to all generations or rely solely on the question to determine intervention, which limits the accurate assessment of the intervention strength. To this end, we propose the Flexible Activation Steering with Backtracking (FASB) framework, which dynamically determines both the necessity and strength of intervention by tracking the internal states of the LLMs during generation, considering both the question and the generated content. Since intervening after detecting a deviation from the desired behavior is often too late, we further propose the backtracking mechanism to correct the deviated tokens and steer the LLMs toward the desired behavior. Extensive experiments on the TruthfulQA dataset and six multiple-choice datasets demonstrate that our method outperforms baselines. Our code will be released at https://github.com/gjw185/FASB."

[27.08.2025 13:23] Response: ```python
['ALIGNMENT']
```
[27.08.2025 13:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Flexible Activation Steering with Backtracking (FASB) framework enhances the performance of large language models (LLMs) by dynamically adjusting intervention strength during text generation. It addresses the challenge of aligning LLM outputs with desired behaviors more effectively than existing methods, which often apply uniform interventions. FASB tracks the internal states of LLMs, allowing it to determine when and how much to intervene based on both the input question and the generated content. Additionally, the backtracking mechanism corrects any deviations from desired outputs, ensuring more accurate and aligned responses.","title":"Dynamic Intervention for Better Language Model Alignment"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Flexible Activation Steering with Backtracking (FASB) framework enhances the performance of large language models (LLMs) by dynamically adjusting intervention strength during text generation. It addresses the challenge of aligning LLM outputs with desired behaviors more effectively than existing methods, which often apply uniform interventions. FASB tracks the internal states of LLMs, allowing it to determine when and how much to intervene based on both the input question and the generated content. Additionally, the backtracking mechanism corrects any deviations from desired outputs, ensuring more accurate and aligned responses.', title='Dynamic Intervention for Better Language Model Alignment'))
[27.08.2025 13:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ÁÅµÊ¥ªÊøÄÊ¥ªÂºïÂØº‰∏éÂõûÊ∫ØÔºàFASBÔºâÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®Âä®ÊÄÅË∞ÉÊï¥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÁîüÊàêËøáÁ®ã‰∏≠ÁöÑÂπ≤È¢ÑÂº∫Â∫¶ÂíåÂøÖË¶ÅÊÄß„ÄÇÈÄöËøáË∑üË∏™LLMÁöÑÂÜÖÈÉ®Áä∂ÊÄÅÔºåFASBËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ËØÑ‰º∞Âπ≤È¢ÑÁöÑÂº∫Â∫¶Ôºå‰ªéËÄå‰ΩøÊ®°ÂûãÁöÑËæìÂá∫Êõ¥Á¨¶ÂêàÈ¢ÑÊúüË°å‰∏∫„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåFASB‰∏ç‰ªÖ‰æùËµñ‰∫éÈóÆÈ¢òÔºåËøòËÄÉËôëÁîüÊàêÂÜÖÂÆπÔºå‰ª•ÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÂπ≤È¢Ñ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFASBÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äË°®Áé∞‰ºò‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁîüÊàê‰ªªÂä°‰∏≠ÁöÑÊΩúÂäõ„ÄÇ","title":"ÁÅµÊ¥ªÂπ≤È¢ÑÔºåÁ≤æÂáÜÂºïÂØº"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ÁÅµÊ¥ªÊøÄÊ¥ªÂºïÂØº‰∏éÂõûÊ∫ØÔºàFASBÔºâÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®Âä®ÊÄÅË∞ÉÊï¥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÁîüÊàêËøáÁ®ã‰∏≠ÁöÑÂπ≤È¢ÑÂº∫Â∫¶ÂíåÂøÖË¶ÅÊÄß„ÄÇÈÄöËøáË∑üË∏™LLMÁöÑÂÜÖÈÉ®Áä∂ÊÄÅÔºåFASBËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ËØÑ‰º∞Âπ≤È¢ÑÁöÑÂº∫Â∫¶Ôºå‰ªéËÄå‰ΩøÊ®°ÂûãÁöÑËæìÂá∫Êõ¥Á¨¶ÂêàÈ¢ÑÊúüË°å‰∏∫„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåFASB‰∏ç‰ªÖ‰æùËµñ‰∫éÈóÆÈ¢òÔºåËøòËÄÉËôëÁîüÊàêÂÜÖÂÆπÔºå‰ª•ÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÂπ≤È¢Ñ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFASBÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äË°®Áé∞‰ºò‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁîüÊàê‰ªªÂä°‰∏≠ÁöÑÊΩúÂäõ„ÄÇ', title='ÁÅµÊ¥ªÂπ≤È¢ÑÔºåÁ≤æÂáÜÂºïÂØº'))
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#multimodal", "#science"], "emoji": "üß†", "ru": {"title": "–†–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –Ω–∞—É—á–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –Ø–ú", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ SciReas –∏ SciReas-Pro –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–∞—É—á–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è —É —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç
[27.08.2025 13:23] Using data from previous issue: {"categories": ["#architecture", "#science", "#training", "#interpretability", "#dataset"], "emoji": "üß†", "ru": {"title": "–°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–µ—Ç–µ–≤—É—é –º–æ–¥–µ–ª—å, —Å–≤—è–∑—ã–≤–∞—é—â—É—é –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ
[27.08.2025 13:23] Querying the API.
[27.08.2025 13:23] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The paper addresses the generation of legal claims for non-professionals using datasets and evaluation metrics, highlighting the limitations of current models in factual precision and clarity.  					AI-generated summary 				 Legal claims refer to the plaintiff's demands in a case and are essential to guiding judicial reasoning and case resolution. While many works have focused on improving the efficiency of legal professionals, the research on helping non-professionals (e.g., plaintiffs) remains unexplored. This paper explores the problem of legal claim generation based on the given case's facts. First, we construct ClaimGen-CN, the first dataset for Chinese legal claim generation task, from various real-world legal disputes. Additionally, we design an evaluation metric tailored for assessing the generated claims, which encompasses two essential dimensions: factuality and clarity. Building on this, we conduct a comprehensive zero-shot evaluation of state-of-the-art general and legal-domain large language models. Our findings highlight the limitations of the current models in factual precision and expressive clarity, pointing to the need for more targeted development in this domain. To encourage further exploration of this important task, we will make the dataset publicly available.
[27.08.2025 13:23] Response: {
  "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–æ–≤ –¥–ª—è –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫ –æ—Ü–µ–Ω–∫–∏. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –ø–µ—Ä–≤—ã–π –∫–∏—Ç–∞–π—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç ClaimGen-CN –¥–ª—è –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–æ–≤ –¥–µ–ª–∞. –û–Ω–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç—Ä–∏–∫—É –æ—Ü–µ–Ω–∫–∏, —É—á–∏—Ç—ã–≤–∞—é—â—É—é —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —è—Å–Ω–æ—Å—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å–∫–æ–≤. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–∏–ª–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —è—Å–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫, —É–∫–∞–∑—ã–≤–∞—è –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–∞–ª—å–Ω–µ–π—à–∏—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–æ–∫ –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏.",
  "emoji": "‚öñÔ∏è",
  "title": "–ò–ò –Ω–∞ –∑–∞—â–∏—Ç–µ –ø—Ä–∞–≤: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–æ–≤ –¥–ª—è –≤—Å–µ—Ö"
}
[27.08.2025 13:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The paper addresses the generation of legal claims for non-professionals using datasets and evaluation metrics, highlighting the limitations of current models in factual precision and clarity.  					AI-generated summary 				 Legal claims refer to the plaintiff's demands in a case and are essential to guiding judicial reasoning and case resolution. While many works have focused on improving the efficiency of legal professionals, the research on helping non-professionals (e.g., plaintiffs) remains unexplored. This paper explores the problem of legal claim generation based on the given case's facts. First, we construct ClaimGen-CN, the first dataset for Chinese legal claim generation task, from various real-world legal disputes. Additionally, we design an evaluation metric tailored for assessing the generated claims, which encompasses two essential dimensions: factuality and clarity. Building on this, we conduct a comprehensive zero-shot evaluation of state-of-the-art general and legal-domain large language models. Our findings highlight the limitations of the current models in factual precision and expressive clarity, pointing to the need for more targeted development in this domain. To encourage further exploration of this important task, we will make the dataset publicly available."

[27.08.2025 13:23] Response: ```python
['DATASET', 'BENCHMARK']
```
[27.08.2025 13:23] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The paper addresses the generation of legal claims for non-professionals using datasets and evaluation metrics, highlighting the limitations of current models in factual precision and clarity.  					AI-generated summary 				 Legal claims refer to the plaintiff's demands in a case and are essential to guiding judicial reasoning and case resolution. While many works have focused on improving the efficiency of legal professionals, the research on helping non-professionals (e.g., plaintiffs) remains unexplored. This paper explores the problem of legal claim generation based on the given case's facts. First, we construct ClaimGen-CN, the first dataset for Chinese legal claim generation task, from various real-world legal disputes. Additionally, we design an evaluation metric tailored for assessing the generated claims, which encompasses two essential dimensions: factuality and clarity. Building on this, we conduct a comprehensive zero-shot evaluation of state-of-the-art general and legal-domain large language models. Our findings highlight the limitations of the current models in factual precision and expressive clarity, pointing to the need for more targeted development in this domain. To encourage further exploration of this important task, we will make the dataset publicly available."

[27.08.2025 13:23] Response: ```python
['SCIENCE', 'OPEN_SOURCE']
```
[27.08.2025 13:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper focuses on creating legal claims for non-professionals using machine learning techniques. It introduces ClaimGen-CN, a new dataset specifically designed for generating legal claims in Chinese, derived from real legal disputes. The authors also propose a unique evaluation metric that measures the factual accuracy and clarity of the generated claims. Their findings reveal that existing models struggle with precision and clarity, indicating a need for improved models in this area.","title":"Empowering Non-Professionals: Generating Clear and Accurate Legal Claims"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper focuses on creating legal claims for non-professionals using machine learning techniques. It introduces ClaimGen-CN, a new dataset specifically designed for generating legal claims in Chinese, derived from real legal disputes. The authors also propose a unique evaluation metric that measures the factual accuracy and clarity of the generated claims. Their findings reveal that existing models struggle with precision and clarity, indicating a need for improved models in this area.', title='Empowering Non-Professionals: Generating Clear and Accurate Legal Claims'))
[27.08.2025 13:23] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊé¢ËÆ®‰∫Ü‰∏∫Èùû‰∏ì‰∏ö‰∫∫Â£´ÁîüÊàêÊ≥ïÂæãËØâÊ±ÇÁöÑÈóÆÈ¢òÔºåÁâπÂà´ÊòØÈíàÂØπÂéüÂëäÁöÑÈúÄÊ±Ç„ÄÇÊàë‰ª¨ÊûÑÂª∫‰∫ÜClaimGen-CNÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Áî®‰∫é‰∏≠ÊñáÊ≥ïÂæãËØâÊ±ÇÁîüÊàêÁöÑÊï∞ÊçÆÂ∫ìÔºåÊù•Ê∫ê‰∫éÂêÑÁßçÁúüÂÆûÁöÑÊ≥ïÂæã‰∫âËÆÆ„ÄÇÊàë‰ª¨ËøòËÆæËÆ°‰∫Ü‰∏ÄÁßçËØÑ‰º∞ÊåáÊ†áÔºå‰∏ìÊ≥®‰∫éÁîüÊàêËØâÊ±ÇÁöÑ‰∫ãÂÆûÂáÜÁ°ÆÊÄßÂíåË°®ËææÊ∏ÖÊô∞Â∫¶„ÄÇÁ†îÁ©∂ÁªìÊûúÊòæÁ§∫ÔºåÂΩìÂâçÊ®°ÂûãÂú®Ëøô‰∏§‰∏™ÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄßÔºåÂº∫Ë∞É‰∫ÜËØ•È¢ÜÂüüÈúÄË¶ÅÊõ¥ÊúâÈíàÂØπÊÄßÁöÑÂºÄÂèë„ÄÇ","title":"‰∏∫Èùû‰∏ì‰∏ö‰∫∫Â£´ÁîüÊàêÊ≥ïÂæãËØâÊ±ÇÁöÑÂàõÊñ∞Êé¢Á¥¢"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊé¢ËÆ®‰∫Ü‰∏∫Èùû‰∏ì‰∏ö‰∫∫Â£´ÁîüÊàêÊ≥ïÂæãËØâÊ±ÇÁöÑÈóÆÈ¢òÔºåÁâπÂà´ÊòØÈíàÂØπÂéüÂëäÁöÑÈúÄÊ±Ç„ÄÇÊàë‰ª¨ÊûÑÂª∫‰∫ÜClaimGen-CNÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™Áî®‰∫é‰∏≠ÊñáÊ≥ïÂæãËØâÊ±ÇÁîüÊàêÁöÑÊï∞ÊçÆÂ∫ìÔºåÊù•Ê∫ê‰∫éÂêÑÁßçÁúüÂÆûÁöÑÊ≥ïÂæã‰∫âËÆÆ„ÄÇÊàë‰ª¨ËøòËÆæËÆ°‰∫Ü‰∏ÄÁßçËØÑ‰º∞ÊåáÊ†áÔºå‰∏ìÊ≥®‰∫éÁîüÊàêËØâÊ±ÇÁöÑ‰∫ãÂÆûÂáÜÁ°ÆÊÄßÂíåË°®ËææÊ∏ÖÊô∞Â∫¶„ÄÇÁ†îÁ©∂ÁªìÊûúÊòæÁ§∫ÔºåÂΩìÂâçÊ®°ÂûãÂú®Ëøô‰∏§‰∏™ÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄßÔºåÂº∫Ë∞É‰∫ÜËØ•È¢ÜÂüüÈúÄË¶ÅÊõ¥ÊúâÈíàÂØπÊÄßÁöÑÂºÄÂèë„ÄÇ', title='‰∏∫Èùû‰∏ì‰∏ö‰∫∫Â£´ÁîüÊàêÊ≥ïÂæãËØâÊ±ÇÁöÑÂàõÊñ∞Êé¢Á¥¢'))
[27.08.2025 13:23] Renaming data file.
[27.08.2025 13:23] Renaming previous data. hf_papers.json to ./d/2025-08-27.json
[27.08.2025 13:23] Saving new data file.
[27.08.2025 13:23] Generating page.
[27.08.2025 13:23] Renaming previous page.
[27.08.2025 13:23] Renaming previous data. index.html to ./d/2025-08-27.html
[27.08.2025 13:23] Writing result.
[27.08.2025 13:23] Renaming log file.
[27.08.2025 13:23] Renaming previous data. log.txt to ./logs/2025-08-27_last_log.txt
