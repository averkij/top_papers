[24.09.2025 07:12] Read previous papers.
[24.09.2025 07:12] Generating top page (month).
[24.09.2025 07:12] Writing top page (month).
[24.09.2025 08:15] Read previous papers.
[24.09.2025 08:15] Get feed.
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19249
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18644
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18174
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18849
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18154
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19297
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18824
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19296
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19284
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13835
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19300
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19087
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19002
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17321
[24.09.2025 08:15] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17083
[24.09.2025 08:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.09.2025 08:15] No deleted papers detected.
[24.09.2025 08:15] Downloading and parsing papers (pdf, html). Total: 15.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19249.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19249.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19249.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.18644.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.18644.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.18644.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.18174.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.18174.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.18174.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.18849.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.18849.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.18849.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.18154.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.18154.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.18154.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19297.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19297.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19297.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.18824.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.18824.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.18824.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19296.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19296.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19296.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19284.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19284.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19284.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.13835.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.13835.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.13835.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19300.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19300.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19300.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19087.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19087.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19087.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.19002.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.19002.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.19002.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.17321.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.17321.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.17321.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Downloading and parsing paper https://huggingface.co/papers/2509.17083.
[24.09.2025 08:15] Extra JSON file exists (./assets/json/2509.17083.json), skip PDF parsing.
[24.09.2025 08:15] Paper image links file exists (./assets/img_data/2509.17083.json), skip HTML parsing.
[24.09.2025 08:15] Success.
[24.09.2025 08:15] Enriching papers with extra data.
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 0. Reinforcement Learning on Pre-Training data (RLPT) optimizes large language models by autonomously exploring meaningful trajectories in pre-training data, improving generalizable reasoning skills without human annotation.  					AI-generated summary 				 The growing disparity between the exponential ...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 1. A state-free policy using only visual observations achieves better spatial generalization and data efficiency in robot manipulation tasks compared to state-based policies.  					AI-generated summary 				 Imitation-learning-based visuomotor policies have been widely used in robot manipulation, where ...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 2. Baseer, a vision-language model fine-tuned for Arabic document OCR, achieves state-of-the-art performance using a decoder-only strategy and a large-scale dataset, outperforming existing solutions with a WER of 0.25.  					AI-generated summary 				 Arabic document OCR remains a challenging task due t...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 3. Mixed Advantage Policy Optimization (MAPO) dynamically reweights the advantage function to improve trajectory ranking in reinforcement learning for foundation models.  					AI-generated summary 				 Recent advances in reinforcement learning for foundation models, such as Group Relative Policy Optimi...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 4. MiniCPM-V 4.5, a 8B parameter multimodal large language model, achieves high performance and efficiency through a unified 3D-Resampler architecture, a unified learning paradigm, and a hybrid reinforcement learning strategy.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) are...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 5. VolSplat, a voxel-aligned Gaussian prediction method, improves novel view synthesis by overcoming pixel alignment limitations and enhancing 3D reconstruction quality.  					AI-generated summary 				 Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective solution for novel view s...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 6. Hyper-Bagel accelerates multimodal understanding and generation tasks using speculative decoding and multi-stage distillation, achieving significant speedups while maintaining high-quality outputs.  					AI-generated summary 				 Unified multimodal models have recently attracted considerable attenti...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 7. A self-distillation framework converts implicit 3D knowledge from video diffusion models into an explicit 3D Gaussian Splatting representation, enabling 3D scene generation from text or images.  					AI-generated summary 				 The ability to generate virtual environments is crucial for applications r...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 8. Effective chain-of-thoughts in large reasoning models are characterized by fewer failed steps and better structural quality, not necessarily by length or review.  					AI-generated summary 				 Large reasoning models (LRMs) spend substantial test-time compute on long chain-of-thought (CoT) traces, b...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 9. Large language models exhibit significant dialect naming and usage bias against German dialect speakers, which is amplified when linguistic demographics are explicitly labeled.  					AI-generated summary 				 Dialects represent a significant component of human culture and are found across all region...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 10. Condition-Aware Reparameterization for Flow Matching (CAR-Flow) enhances conditional generative modeling by repositioning distributions, leading to faster training and improved performance on image data.  					AI-generated summary 				 Conditional generative modeling aims to learn a conditional data...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 11. A training-free method enables generalist multimodal models to process multi-spectral imagery in a zero-shot manner, enhancing performance on remote sensing tasks.  					AI-generated summary 				 Multi-spectral imagery plays a crucial role in diverse Remote Sensing applications including land-use cl...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 12. VIR-Bench, a new benchmark for travel videos, evaluates and enhances MLLMs' geospatial-temporal intelligence, improving itinerary recommendations in real-world applications.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLMs) have significantly enhanced video ...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 13. OpenGVL is a benchmark for task progress prediction in robotics using vision-language models, showing open-source models underperform compared to closed-source ones and enabling automated data curation.  					AI-generated summary 				 Data scarcity remains one of the most limiting factors in driving...
[24.09.2025 08:15] ********************************************************************************
[24.09.2025 08:15] Abstract 14. Hybrid Radiance Fields combine explicit Gaussians and neural fields to achieve high-quality rendering with reduced memory usage and real-time performance.  					AI-generated summary 				 Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative to NeRF-based approaches, enabling r...
[24.09.2025 08:15] Read previous papers.
[24.09.2025 08:15] Generating reviews via LLM API.
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#reasoning", "#benchmark", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "RLPT: –£—Å–∏–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–ú–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (RLPT) –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –±–æ–ª—å—à–∏
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#cv", "#robotics", "#agents", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–ó—Ä–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é —Ä–æ–±–æ—Ç–æ–≤-–º–∞–Ω–∏–ø—É–ª—è—Ç–æ—Ä–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø–æ–ª–∏—Ç–∏–∫–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#cv", "#low_resource", "#multimodal", "#synthetic", "#dataset"], "emoji": "üìú", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –∞—Ä–∞–±—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤: Baseer —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç OCR", "desc": "Baseer - —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#rlhf", "#training"], "emoji": "‚öñÔ∏è", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "MAPO - —ç—Ç–æ –Ω–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–≤–∑–≤–µ
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#architecture", "#rl", "#agi", "#benchmark", "#optimization", "#multimodal", "#training"], "emoji": "üöÄ", "ru": {"title": "MiniCPM-V 4.5: –ö–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö", "desc": "MiniCPM-V 4.5 - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å 8 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#benchmark", "#3d", "#games"], "emoji": "üîç", "ru": {"title": "VolSplat: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–∏–Ω—Ç–µ–∑–µ –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤ —á–µ—Ä–µ–∑ –≤–æ–∫—Å–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥–∞—É—Å—Å–∏–∞–Ω–æ–≤", "desc": "VolSplat - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑–∞ –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –≤–æ–∫—Å–µ–ª—å–Ω–æ-–≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#training"], "emoji": "üöÄ", "ru": {"title": "Hyper-Bagel: –°–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–æ–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –ò–ò –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Hyper-Bagel - —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –û–Ω–∞ –∏
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#3d", "#robotics", "#games", "#synthetic", "#video"], "emoji": "üé≠", "ru": {"title": "3D-–º–∏—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö —Å—Ä–µ–¥", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Å–∞–º–æ–¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –Ω–µ—è–≤–Ω—ã–µ 3D-–∑–Ω–∞–Ω–∏—è –∏–∑ –º–æ–¥–µ–ª–µ–π –≤–∏–¥–µ–æ–¥–∏—Ñ—Ñ—É–∑–∏–∏ –≤ 
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#math", "#rl", "#reasoning", "#interpretability", "#training"], "emoji": "üß†", "ru": {"title": "–ö–∞—á–µ—Å—Ç–≤–æ, –∞ –Ω–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: –∫–ª—é—á –∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º —Ü–µ–ø–æ—á–∫–∞–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –ò–ò", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (Chain-of-Thought, CoT) –≤ –∫—Ä—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö 
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#ethics", "#benchmark", "#multilingual", "#dataset"], "emoji": "üó£Ô∏è", "ru": {"title": "–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—è—Ç —Å—Ç–µ—Ä–µ–æ—Ç–∏–ø—ã –æ –¥–∏–∞–ª–µ–∫—Ç–∞—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –Ω–æ—Å–∏—Ç–µ–ª—è–º –Ω–µ–º–µ—Ü–∫–∏—Ö –¥–∏–∞–ª–µ
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#cv", "#data", "#training", "#synthetic", "#diffusion"], "emoji": "üîÄ", "ru": {"title": "–£–º–Ω–æ–µ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "CAR-Flow - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≤ —É—Å–ª–æ–≤–Ω–æ–º –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–º –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#science", "#dataset", "#benchmark", "#transfer_learning", "#optimization", "#multimodal"], "emoji": "üõ∞Ô∏è", "ru": {"title": "–ú—É–ª—å—Ç–∏—Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ –¥–ª—è –ò–ò –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –º—É–ª—å—Ç–∏—Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –∏–∑–æ
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#benchmark", "#video", "#science", "#games", "#agents", "#multimodal"], "emoji": "üåé", "ru": {"title": "VIR-Bench: –ù–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –≤–∏–¥–µ–æ –æ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è—Ö –¥–ª—è –ò–ò", "desc": "VIR-Bench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–æ–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#data", "#robotics", "#dataset", "#science"], "emoji": "ü§ñ", "ru": {"title": "OpenGVL: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ", "desc": "OpenGVL - —ç—Ç–æ —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–¥–∞—á –≤ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ
[24.09.2025 08:15] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#3d"], "emoji": "üåà", "ru": {"title": "–ì–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–∞–¥–∏–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è: –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ 3D —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–µ", "desc": "–ì–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–∞–¥–∏–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è (HyRF) –æ–±—ä–µ–¥–∏–Ω—è—é—Ç —è–≤–Ω—ã–µ –≥–∞—É—Å—Å–∏–∞–Ω—ã –∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Å —É–º–µ–Ω—å—à
[24.09.2025 08:15] Renaming data file.
[24.09.2025 08:15] Renaming previous data. hf_papers.json to ./d/2025-09-24.json
[24.09.2025 08:15] Saving new data file.
[24.09.2025 08:15] Generating page.
[24.09.2025 08:15] Renaming previous page.
[24.09.2025 08:15] Renaming previous data. index.html to ./d/2025-09-24.html
[24.09.2025 08:15] Writing result.
[24.09.2025 08:15] Renaming log file.
[24.09.2025 08:15] Renaming previous data. log.txt to ./logs/2025-09-24_last_log.txt
