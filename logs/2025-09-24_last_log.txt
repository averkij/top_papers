[24.09.2025 06:17] Read previous papers.
[24.09.2025 06:17] Generating top page (month).
[24.09.2025 06:17] Writing top page (month).
[24.09.2025 07:11] Read previous papers.
[24.09.2025 07:11] Get feed.
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19249
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18174
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18644
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18154
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19297
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18849
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18824
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19296
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19284
[24.09.2025 07:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.13835
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19300
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19087
[24.09.2025 07:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.19002
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17321
[24.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17083
[24.09.2025 07:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.09.2025 07:11] No deleted papers detected.
[24.09.2025 07:11] Downloading and parsing papers (pdf, html). Total: 15.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.19249.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.19249.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.19249.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.18174.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.18174.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.18174.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.18644.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.18644.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.18644.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.18154.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.18154.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.18154.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.19297.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.19297.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.19297.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.18849.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.18849.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.18849.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.18824.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.18824.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.18824.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.19296.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.19296.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.19296.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.19284.
[24.09.2025 07:11] Extra JSON file exists (./assets/json/2509.19284.json), skip PDF parsing.
[24.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.19284.json), skip HTML parsing.
[24.09.2025 07:11] Success.
[24.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.13835.
[24.09.2025 07:11] Downloading paper 2509.13835 from http://arxiv.org/pdf/2509.13835v1...
[24.09.2025 07:12] Extracting affiliations from text.
[24.09.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Minh Duc Bui*1 Carolin Holtermann*2 Valentin Hofmann3,4 Katharina von der Wense1,5 Anne Lauscher2 1Johannes Gutenberg University Mainz, Germany 2Data Science Group, University of Hamburg, Germany 3Allen Institute for AI 4University of Washington, USA 5University of Colorado Boulder, USA minhducbui@uni-mainz.de, carolin.holtermann@uni-hamburg.de 5 2 0 2 7 1 ] . [ 1 5 3 8 3 1 . 9 0 5 2 : r a "
[24.09.2025 07:12] Response: ```python
[
    "Johannes Gutenberg University Mainz, Germany",
    "Data Science Group, University of Hamburg, Germany",
    "Allen Institute for AI",
    "University of Washington, USA",
    "University of Colorado Boulder, USA"
]
```
[24.09.2025 07:12] Deleting PDF ./assets/pdf/2509.13835.pdf.
[24.09.2025 07:12] Success.
[24.09.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2509.19300.
[24.09.2025 07:12] Extra JSON file exists (./assets/json/2509.19300.json), skip PDF parsing.
[24.09.2025 07:12] Paper image links file exists (./assets/img_data/2509.19300.json), skip HTML parsing.
[24.09.2025 07:12] Success.
[24.09.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2509.19087.
[24.09.2025 07:12] Extra JSON file exists (./assets/json/2509.19087.json), skip PDF parsing.
[24.09.2025 07:12] Paper image links file exists (./assets/img_data/2509.19087.json), skip HTML parsing.
[24.09.2025 07:12] Success.
[24.09.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2509.19002.
[24.09.2025 07:12] Downloading paper 2509.19002 from http://arxiv.org/pdf/2509.19002v1...
[24.09.2025 07:12] Extracting affiliations from text.
[24.09.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 2 ] . [ 1 2 0 0 9 1 . 9 0 5 2 : r VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction Hao Wang 1 Eiki Murata 2,3 Lingfang Zhang1 Ayako Sato2 So Fukuda1 Ziqi Yin1 Wentao Hu1 Keisuke Nakao1 Yusuke Nakamura1 Sebastian Zwirner1 Yi-Chia Chen1 Hiroyuki Otomo2 Hiroki Ouchi4,2 Daisuke Kawahara 1Waseda University 2CyberAgent, Inc. 3AI Shift, Inc. 4Nara Institute of Science and Technology https://github.com/nlp-waseda/VIR-Bench "
[24.09.2025 07:12] Response: ```python
["Waseda University", "CyberAgent, Inc.", "AI Shift, Inc.", "Nara Institute of Science and Technology"]
```
[24.09.2025 07:12] Deleting PDF ./assets/pdf/2509.19002.pdf.
[24.09.2025 07:12] Success.
[24.09.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2509.17321.
[24.09.2025 07:12] Extra JSON file exists (./assets/json/2509.17321.json), skip PDF parsing.
[24.09.2025 07:12] Paper image links file exists (./assets/img_data/2509.17321.json), skip HTML parsing.
[24.09.2025 07:12] Success.
[24.09.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2509.17083.
[24.09.2025 07:12] Extra JSON file exists (./assets/json/2509.17083.json), skip PDF parsing.
[24.09.2025 07:12] Paper image links file exists (./assets/img_data/2509.17083.json), skip HTML parsing.
[24.09.2025 07:12] Success.
[24.09.2025 07:12] Enriching papers with extra data.
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 0. Reinforcement Learning on Pre-Training data (RLPT) optimizes large language models by autonomously exploring meaningful trajectories in pre-training data, improving generalizable reasoning skills without human annotation.  					AI-generated summary 				 The growing disparity between the exponential ...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 1. Baseer, a vision-language model fine-tuned for Arabic document OCR, achieves state-of-the-art performance using a decoder-only strategy and a large-scale dataset, outperforming existing solutions with a WER of 0.25.  					AI-generated summary 				 Arabic document OCR remains a challenging task due t...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 2. A state-free policy using only visual observations achieves better spatial generalization and data efficiency in robot manipulation tasks compared to state-based policies.  					AI-generated summary 				 Imitation-learning-based visuomotor policies have been widely used in robot manipulation, where ...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 3. MiniCPM-V 4.5, a 8B parameter multimodal large language model, achieves high performance and efficiency through a unified 3D-Resampler architecture, a unified learning paradigm, and a hybrid reinforcement learning strategy.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) are...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 4. VolSplat, a voxel-aligned Gaussian prediction method, improves novel view synthesis by overcoming pixel alignment limitations and enhancing 3D reconstruction quality.  					AI-generated summary 				 Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective solution for novel view s...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 5. Mixed Advantage Policy Optimization (MAPO) dynamically reweights the advantage function to improve trajectory ranking in reinforcement learning for foundation models.  					AI-generated summary 				 Recent advances in reinforcement learning for foundation models, such as Group Relative Policy Optimi...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 6. Hyper-Bagel accelerates multimodal understanding and generation tasks using speculative decoding and multi-stage distillation, achieving significant speedups while maintaining high-quality outputs.  					AI-generated summary 				 Unified multimodal models have recently attracted considerable attenti...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 7. A self-distillation framework converts implicit 3D knowledge from video diffusion models into an explicit 3D Gaussian Splatting representation, enabling 3D scene generation from text or images.  					AI-generated summary 				 The ability to generate virtual environments is crucial for applications r...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 8. Effective chain-of-thoughts in large reasoning models are characterized by fewer failed steps and better structural quality, not necessarily by length or review.  					AI-generated summary 				 Large reasoning models (LRMs) spend substantial test-time compute on long chain-of-thought (CoT) traces, b...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 9. Large language models exhibit significant dialect naming and usage bias against German dialect speakers, which is amplified when linguistic demographics are explicitly labeled.  					AI-generated summary 				 Dialects represent a significant component of human culture and are found across all region...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 10. Condition-Aware Reparameterization for Flow Matching (CAR-Flow) enhances conditional generative modeling by repositioning distributions, leading to faster training and improved performance on image data.  					AI-generated summary 				 Conditional generative modeling aims to learn a conditional data...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 11. A training-free method enables generalist multimodal models to process multi-spectral imagery in a zero-shot manner, enhancing performance on remote sensing tasks.  					AI-generated summary 				 Multi-spectral imagery plays a crucial role in diverse Remote Sensing applications including land-use cl...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 12. VIR-Bench, a new benchmark for travel videos, evaluates and enhances MLLMs' geospatial-temporal intelligence, improving itinerary recommendations in real-world applications.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLMs) have significantly enhanced video ...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 13. OpenGVL is a benchmark for task progress prediction in robotics using vision-language models, showing open-source models underperform compared to closed-source ones and enabling automated data curation.  					AI-generated summary 				 Data scarcity remains one of the most limiting factors in driving...
[24.09.2025 07:12] ********************************************************************************
[24.09.2025 07:12] Abstract 14. Hybrid Radiance Fields combine explicit Gaussians and neural fields to achieve high-quality rendering with reduced memory usage and real-time performance.  					AI-generated summary 				 Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative to NeRF-based approaches, enabling r...
[24.09.2025 07:12] Read previous papers.
[24.09.2025 07:12] Generating reviews via LLM API.
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#reasoning", "#benchmark", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "RLPT: Усиление языковых моделей через самообучение на предобученных данных", "desc": "Метод обучения с подкреплением на предварительно обученных данных (RLPT) оптимизирует больши
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#cv", "#low_resource", "#multimodal", "#synthetic", "#dataset"], "emoji": "📜", "ru": {"title": "Прорыв в распознавании арабских текстов: Baseer устанавливает новый стандарт OCR", "desc": "Baseer - это модель машинного зрения и обработки естественного яз
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#cv", "#robotics", "#agents", "#optimization"], "emoji": "🤖", "ru": {"title": "Зрение вместо состояния: новый подход к обучению роботов-манипуляторов", "desc": "Исследование показывает, что политика без использования состояния, основанная только на визуальных наблюдениях, превосходи
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#rl", "#agi", "#benchmark", "#optimization", "#multimodal", "#training"], "emoji": "🚀", "ru": {"title": "MiniCPM-V 4.5: Компактность и эффективность в мультимодальных ИИ-моделях", "desc": "MiniCPM-V 4.5 - это мультимодальная большая языковая модель с 8 миллиардами п
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#benchmark", "#3d", "#games"], "emoji": "🔍", "ru": {"title": "VolSplat: революция в синтезе новых ракурсов через воксельное предсказание гауссианов", "desc": "VolSplat - это новый метод синтеза новых ракурсов, использующий воксельно-выровненное предс
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#rlhf", "#training"], "emoji": "⚖️", "ru": {"title": "Адаптивная оптимизация преимущества для улучшения обучения с подкреплением", "desc": "MAPO - это новая стратегия обучения с подкреплением для фундаментальных моделей. Она динамически перевзве
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#training"], "emoji": "🚀", "ru": {"title": "Hyper-Bagel: Сверхбыстрое мультимодальное ИИ без потери качества", "desc": "Статья представляет Hyper-Bagel - унифицированную систему для ускорения мультимодальных задач понимания и генерации контента. Она и
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#3d", "#robotics", "#games", "#synthetic", "#video"], "emoji": "🎭", "ru": {"title": "3D-миры из текста и изображений: новый подход к генерации виртуальных сред", "desc": "Статья представляет фреймворк самодистилляции, который преобразует неявные 3D-знания из моделей видеодиффузии в 
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#math", "#rl", "#reasoning", "#interpretability", "#training"], "emoji": "🧠", "ru": {"title": "Качество, а не количество: ключ к эффективным цепочкам рассуждений в ИИ", "desc": "Исследование показывает, что эффективность цепочек рассуждений (Chain-of-Thought, CoT) в крупных моделях 
[24.09.2025 07:12] Querying the API.
[24.09.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models exhibit significant dialect naming and usage bias against German dialect speakers, which is amplified when linguistic demographics are explicitly labeled.  					AI-generated summary 				 Dialects represent a significant component of human culture and are found across all regions of the world. In Germany, more than 40% of the population speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural importance, individuals speaking dialects often face negative societal stereotypes. We examine whether such stereotypes are mirrored by large language models (LLMs). We draw on the sociolinguistic literature on dialect perception to analyze traits commonly associated with dialect speakers. Based on these traits, we assess the dialect naming bias and dialect usage bias expressed by LLMs in two tasks: an association task and a decision task. To assess a model's dialect usage bias, we construct a novel evaluation corpus that pairs sentences from seven regional German dialects (e.g., Alemannic and Bavarian) with their standard German counterparts. We find that: (1) in the association task, all evaluated LLMs exhibit significant dialect naming and dialect usage bias against German dialect speakers, reflected in negative adjective associations; (2) all models reproduce these dialect naming and dialect usage biases in their decision making; and (3) contrary to prior work showing minimal bias with explicit demographic mentions, we find that explicitly labeling linguistic demographics--German dialect speakers--amplifies bias more than implicit cues like dialect usage.
[24.09.2025 07:12] Response: {
  "desc": "Исследование показывает, что большие языковые модели (БЯМ) демонстрируют значительное предвзятое отношение к носителям немецких диалектов. Это проявляется в негативных ассоциациях и предвзятых решениях моделей при упоминании диалектов или их использовании. Интересно, что явное указание лингвистической демографии усиливает предвзятость сильнее, чем неявные признаки вроде использования диалекта. Результаты подчеркивают необходимость учитывать и корректировать лингвистические предубеждения в БЯМ.",
  "emoji": "🗣️",
  "title": "Языковые модели воспроизводят стереотипы о диалектах"
}
[24.09.2025 07:12] Renaming some terms.
[24.09.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models exhibit significant dialect naming and usage bias against German dialect speakers, which is amplified when linguistic demographics are explicitly labeled.  					AI-generated summary 				 Dialects represent a significant component of human culture and are found across all regions of the world. In Germany, more than 40% of the population speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural importance, individuals speaking dialects often face negative societal stereotypes. We examine whether such stereotypes are mirrored by large language models (LLMs). We draw on the sociolinguistic literature on dialect perception to analyze traits commonly associated with dialect speakers. Based on these traits, we assess the dialect naming bias and dialect usage bias expressed by LLMs in two tasks: an association task and a decision task. To assess a model's dialect usage bias, we construct a novel evaluation corpus that pairs sentences from seven regional German dialects (e.g., Alemannic and Bavarian) with their standard German counterparts. We find that: (1) in the association task, all evaluated LLMs exhibit significant dialect naming and dialect usage bias against German dialect speakers, reflected in negative adjective associations; (2) all models reproduce these dialect naming and dialect usage biases in their decision making; and (3) contrary to prior work showing minimal bias with explicit demographic mentions, we find that explicitly labeling linguistic demographics--German dialect speakers--amplifies bias more than implicit cues like dialect usage."

[24.09.2025 07:12] Response: ```python
['DATASET', 'BENCHMARK', 'MULTILINGUAL']
```
[24.09.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models exhibit significant dialect naming and usage bias against German dialect speakers, which is amplified when linguistic demographics are explicitly labeled.  					AI-generated summary 				 Dialects represent a significant component of human culture and are found across all regions of the world. In Germany, more than 40% of the population speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural importance, individuals speaking dialects often face negative societal stereotypes. We examine whether such stereotypes are mirrored by large language models (LLMs). We draw on the sociolinguistic literature on dialect perception to analyze traits commonly associated with dialect speakers. Based on these traits, we assess the dialect naming bias and dialect usage bias expressed by LLMs in two tasks: an association task and a decision task. To assess a model's dialect usage bias, we construct a novel evaluation corpus that pairs sentences from seven regional German dialects (e.g., Alemannic and Bavarian) with their standard German counterparts. We find that: (1) in the association task, all evaluated LLMs exhibit significant dialect naming and dialect usage bias against German dialect speakers, reflected in negative adjective associations; (2) all models reproduce these dialect naming and dialect usage biases in their decision making; and (3) contrary to prior work showing minimal bias with explicit demographic mentions, we find that explicitly labeling linguistic demographics--German dialect speakers--amplifies bias more than implicit cues like dialect usage."

[24.09.2025 07:12] Response: ```python
['ETHICS']
```
[24.09.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the biases present in large language models (LLMs) against speakers of German dialects. It highlights that these models not only associate negative traits with dialect speakers but also exhibit biased decision-making when processing dialect-related content. The research utilizes a novel evaluation corpus to measure dialect naming and usage biases through specific tasks. The findings reveal that explicitly labeling dialect speakers increases bias, contradicting previous studies that suggested minimal bias with demographic mentions.","title":"Unmasking Bias: Language Models and German Dialects"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the biases present in large language models (LLMs) against speakers of German dialects. It highlights that these models not only associate negative traits with dialect speakers but also exhibit biased decision-making when processing dialect-related content. The research utilizes a novel evaluation corpus to measure dialect naming and usage biases through specific tasks. The findings reveal that explicitly labeling dialect speakers increases bias, contradicting previous studies that suggested minimal bias with demographic mentions.', title='Unmasking Bias: Language Models and German Dialects'))
[24.09.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文研究了大型语言模型（LLMs）对德语方言使用者的偏见，发现这些模型在方言命名和使用上存在显著的偏见。研究表明，方言使用者常常面临负面的社会刻板印象，而这些刻板印象在LLMs中得到了反映。通过关联任务和决策任务，作者评估了模型的方言命名偏见和使用偏见，并构建了一个新的评估语料库。结果显示，明确标记语言人口统计信息会加剧偏见，反映出对德语方言使用者的负面联想。","title":"大型语言模型对德语方言使用者的偏见研究"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文研究了大型语言模型（LLMs）对德语方言使用者的偏见，发现这些模型在方言命名和使用上存在显著的偏见。研究表明，方言使用者常常面临负面的社会刻板印象，而这些刻板印象在LLMs中得到了反映。通过关联任务和决策任务，作者评估了模型的方言命名偏见和使用偏见，并构建了一个新的评估语料库。结果显示，明确标记语言人口统计信息会加剧偏见，反映出对德语方言使用者的负面联想。', title='大型语言模型对德语方言使用者的偏见研究'))
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#cv", "#data", "#training", "#synthetic", "#diffusion"], "emoji": "🔀", "ru": {"title": "Умное перераспределение для эффективного генеративного моделирования", "desc": "CAR-Flow - это новый метод в условном генеративном моделировании, который улучшает производительность и ускоряет об
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#science", "#dataset", "#benchmark", "#transfer_learning", "#optimization", "#multimodal"], "emoji": "🛰️", "ru": {"title": "Мультиспектральное зрение для ИИ без переобучения", "desc": "Статья представляет метод, позволяющий мультимодальным моделям обрабатывать мультиспектральные изо
[24.09.2025 07:12] Querying the API.
[24.09.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

VIR-Bench, a new benchmark for travel videos, evaluates and enhances MLLMs' geospatial-temporal intelligence, improving itinerary recommendations in real-world applications.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLMs) have significantly enhanced video understanding capabilities, opening new possibilities for practical applications. Yet current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs, underpinning real-world tasks such as embodied-AI planning and navigation. To bridge this gap, we present VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task designed to evaluate and push forward MLLMs' geospatial-temporal intelligence. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, we conduct an in-depth case study in which we develop a prototype travel-planning agent that leverages the insights gained from VIR-Bench. The agent's markedly improved itinerary recommendations verify that our evaluation protocol not only benchmarks models effectively but also translates into concrete performance gains in user-facing applications.
[24.09.2025 07:12] Response: {
  "desc": "VIR-Bench - это новый бенчмарк для оценки и улучшения геопространственно-временного интеллекта мультимодальных больших языковых моделей (MLLM) на основе видео о путешествиях. Он состоит из 200 видео и ставит задачу реконструкции маршрута, что позволяет оценить способность моделей работать с протяженными пространственно-временными траекториями. Эксперименты показали, что современные MLLM, включая проприетарные, испытывают трудности с этой задачей. Применение insights из VIR-Bench позволило значительно улучшить рекомендации по маршрутам в прототипе агента для планирования путешествий.",
  "emoji": "🌎",
  "title": "VIR-Bench: Новый рубеж в понимании видео о путешествиях для ИИ"
}
[24.09.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VIR-Bench, a new benchmark for travel videos, evaluates and enhances MLLMs' geospatial-temporal intelligence, improving itinerary recommendations in real-world applications.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLMs) have significantly enhanced video understanding capabilities, opening new possibilities for practical applications. Yet current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs, underpinning real-world tasks such as embodied-AI planning and navigation. To bridge this gap, we present VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task designed to evaluate and push forward MLLMs' geospatial-temporal intelligence. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, we conduct an in-depth case study in which we develop a prototype travel-planning agent that leverages the insights gained from VIR-Bench. The agent's markedly improved itinerary recommendations verify that our evaluation protocol not only benchmarks models effectively but also translates into concrete performance gains in user-facing applications."

[24.09.2025 07:12] Response: ```python
['BENCHMARK', 'VIDEO', 'MULTIMODAL', 'AGENTS']
```
[24.09.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VIR-Bench, a new benchmark for travel videos, evaluates and enhances MLLMs' geospatial-temporal intelligence, improving itinerary recommendations in real-world applications.  					AI-generated summary 				 Recent advances in multimodal large language models (MLLMs) have significantly enhanced video understanding capabilities, opening new possibilities for practical applications. Yet current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs, underpinning real-world tasks such as embodied-AI planning and navigation. To bridge this gap, we present VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task designed to evaluate and push forward MLLMs' geospatial-temporal intelligence. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, we conduct an in-depth case study in which we develop a prototype travel-planning agent that leverages the insights gained from VIR-Bench. The agent's markedly improved itinerary recommendations verify that our evaluation protocol not only benchmarks models effectively but also translates into concrete performance gains in user-facing applications."

[24.09.2025 07:12] Response: ```python
["GAMES", "SCIENCE"]
```
[24.09.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VIR-Bench is a new benchmark designed to assess and improve the geospatial-temporal intelligence of multimodal large language models (MLLMs) using travel videos. It consists of 200 videos that focus on long-distance travel, a topic that has been largely overlooked in existing benchmarks. The study shows that even advanced MLLMs struggle with the complexities of itinerary reconstruction from these videos. By developing a travel-planning agent based on insights from VIR-Bench, the research demonstrates significant improvements in itinerary recommendations, highlighting the practical benefits of this evaluation framework.","title":"Enhancing Travel Itinerary Recommendations with VIR-Bench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VIR-Bench is a new benchmark designed to assess and improve the geospatial-temporal intelligence of multimodal large language models (MLLMs) using travel videos. It consists of 200 videos that focus on long-distance travel, a topic that has been largely overlooked in existing benchmarks. The study shows that even advanced MLLMs struggle with the complexities of itinerary reconstruction from these videos. By developing a travel-planning agent based on insights from VIR-Bench, the research demonstrates significant improvements in itinerary recommendations, highlighting the practical benefits of this evaluation framework.', title='Enhancing Travel Itinerary Recommendations with VIR-Bench'))
[24.09.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"VIR-Bench是一个新的旅行视频基准，旨在评估和提升多模态大语言模型（MLLMs）的地理时空智能，从而改善现实应用中的行程推荐。当前的视频基准主要集中在室内场景或短途户外活动上，长途旅行的挑战尚未得到充分探索。掌握扩展的地理时空轨迹对于下一代MLLMs至关重要，这支持了诸如具身人工智能规划和导航等现实任务。通过VIR-Bench，我们展示了一个包含200个旅行视频的基准，将行程重建作为一项挑战性任务，以评估和推动MLLMs的地理时空智能。","title":"提升旅行视频理解的基准挑战"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='VIR-Bench是一个新的旅行视频基准，旨在评估和提升多模态大语言模型（MLLMs）的地理时空智能，从而改善现实应用中的行程推荐。当前的视频基准主要集中在室内场景或短途户外活动上，长途旅行的挑战尚未得到充分探索。掌握扩展的地理时空轨迹对于下一代MLLMs至关重要，这支持了诸如具身人工智能规划和导航等现实任务。通过VIR-Bench，我们展示了一个包含200个旅行视频的基准，将行程重建作为一项挑战性任务，以评估和推动MLLMs的地理时空智能。', title='提升旅行视频理解的基准挑战'))
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#data", "#robotics", "#dataset", "#science"], "emoji": "🤖", "ru": {"title": "OpenGVL: Новый стандарт для оценки прогресса в робототехнике", "desc": "OpenGVL - это эталонный тест для прогнозирования прогресса задач в робототехнике с использованием моделе
[24.09.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#3d"], "emoji": "🌈", "ru": {"title": "Гибридные радиационные поля: высокое качество и эффективность в 3D рендеринге", "desc": "Гибридные радиационные поля (HyRF) объединяют явные гауссианы и нейронные поля для высококачественного рендеринга с уменьш
[24.09.2025 07:12] Renaming data file.
[24.09.2025 07:12] Renaming previous data. hf_papers.json to ./d/2025-09-24.json
[24.09.2025 07:12] Saving new data file.
[24.09.2025 07:12] Generating page.
[24.09.2025 07:12] Renaming previous page.
[24.09.2025 07:12] Renaming previous data. index.html to ./d/2025-09-24.html
[24.09.2025 07:12] Writing result.
[24.09.2025 07:12] Renaming log file.
[24.09.2025 07:12] Renaming previous data. log.txt to ./logs/2025-09-24_last_log.txt
