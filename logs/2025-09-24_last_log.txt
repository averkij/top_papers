[23.09.2025 23:10] Read previous papers.
[23.09.2025 23:10] Generating top page (month).
[23.09.2025 23:10] Writing top page (month).
[24.09.2025 00:50] Read previous papers.
[24.09.2025 00:50] Get feed.
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17567
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17765
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17627
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18091
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18056
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17437
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17396
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16117
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16941
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18084
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17985
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17177
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17158
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16596
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17671
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17428
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18058
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15709
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18010
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17818
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15248
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18095
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18094
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18083
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18053
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17641
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17336
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17786
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17998
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17938
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17399
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17277
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.17191
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16633
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16591
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16415
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14856
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09873
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.04441
[24.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16548
[24.09.2025 00:50] Extract page data from URL. URL: https://huggingface.co/papers/2509.16195
[24.09.2025 00:50] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.09.2025 00:50] No deleted papers detected.
[24.09.2025 00:50] Downloading and parsing papers (pdf, html). Total: 41.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17567.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17567.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17567.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17765.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17765.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17765.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17627.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17627.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17627.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18091.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18091.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18091.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18056.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18056.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18056.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17437.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17437.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17437.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17396.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17396.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17396.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16117.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16117.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16117.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16941.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16941.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16941.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18084.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18084.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18084.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17985.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17985.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17985.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17177.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17177.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17177.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17158.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17158.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17158.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16596.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16596.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16596.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17671.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17671.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17671.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17428.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17428.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17428.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18058.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18058.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18058.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.15709.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.15709.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.15709.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18010.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18010.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18010.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17818.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17818.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17818.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.15248.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.15248.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.15248.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18095.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18095.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18095.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18094.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18094.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18094.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18083.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18083.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18083.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18053.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18053.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18053.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17641.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17641.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17641.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17336.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17336.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17336.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17786.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17786.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17786.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17998.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17998.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17998.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17938.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17938.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17938.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17399.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17399.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17399.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17277.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17277.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17277.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.17191.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.17191.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.17191.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16633.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16633.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16633.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16591.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16591.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16591.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16415.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16415.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16415.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.14856.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.14856.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.14856.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.09873.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.09873.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.09873.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.04441.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.04441.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.04441.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16548.
[24.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16548.json), skip PDF parsing.
[24.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16548.json), skip HTML parsing.
[24.09.2025 00:50] Success.
[24.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16195.
[24.09.2025 00:50] Downloading paper 2509.16195 from http://arxiv.org/pdf/2509.16195v1...
[24.09.2025 00:51] Extracting affiliations from text.
[24.09.2025 00:51] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"FOCALCODEC-STREAM: STREAMING LOW-BITRATE SPEECH CODING VIA CAUSAL DISTILLATION Luca Della Libera1,2, Cem Subakan3,1,2, Mirco Ravanelli1,2 1Concordia University, 2Mila-Quebec AI Institute, 3Universite Laval 5 2 0 2 9 1 ] . [ 1 5 9 1 6 1 . 9 0 5 2 : r a "
[24.09.2025 00:51] Response: ```python
["Concordia University", "Mila-Quebec AI Institute", "Universite Laval"]
```
[24.09.2025 00:51] Deleting PDF ./assets/pdf/2509.16195.pdf.
[24.09.2025 00:51] Success.
[24.09.2025 00:51] Enriching papers with extra data.
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 0. LIMI demonstrates that sophisticated agentic intelligence can emerge from minimal, strategically curated demonstrations, outperforming data-intensive models on agency benchmarks.  					AI-generated summary 				 We define Agency as the emergent capacity of AI systems to function as autonomous agents ...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 1. Qwen3-Omni, a multimodal model, achieves state-of-the-art performance across text, image, audio, and video, using a Thinker-Talker MoE architecture and a lightweight causal ConvNet for efficient streaming synthesis.  					AI-generated summary 				 We present Qwen3-Omni, a single multimodal model tha...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 2. OmniInsert addresses challenges in mask-free video insertion using a novel data pipeline, feature injection, progressive training, and context-aware rephrasing, outperforming commercial solutions.  					AI-generated summary 				 Recent advances in video insertion based on diffusion models are impres...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 3. OnePiece integrates LLM-style context engineering and reasoning into industrial search and recommendation systems, achieving significant improvements in key business metrics.  					AI-generated summary 				 Despite the growing interest in replicating the scaled success of large language models (LLMs...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 4. TempSamp-R1, a reinforcement fine-tuning framework, enhances multimodal large language models for video temporal grounding by using off-policy supervision and a hybrid Chain-of-Thought training paradigm, achieving state-of-the-art performance on benchmark datasets.  					AI-generated summary 				 Th...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 5. A two-stage reinforcement learning framework improves geometric reasoning and problem-solving in multimodal language models by first enhancing visual perception.  					AI-generated summary 				 Recent advancements in reinforcement learning (RL) have enhanced the reasoning abilities of large language...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 6. EpiCache is a KV cache management framework for long conversational question answering that reduces memory usage and improves accuracy through block-wise prefill, episodic KV compression, and adaptive layer-wise budget allocation.  					AI-generated summary 				 Recent advances in large language mod...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 7. Diffusion Negative-aware FineTuning (DiffusionNFT) optimizes diffusion models directly on the forward process via flow matching, improving efficiency and performance compared to existing methods.  					AI-generated summary 				 Online reinforcement learning (RL) has been central to post-training lan...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 8. SWE-Bench Pro is a challenging benchmark for coding models, featuring complex, enterprise-level problems that require substantial code modifications, with performance evaluations showing significant limitations in current models.  					AI-generated summary 				 We introduce SWE-Bench Pro, a substant...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 9. This paper introduces ByteWrist, a novel highly-flexible and anthropomorphic parallel wrist for robotic manipulation. ByteWrist addresses the critical limitations of existing serial and parallel wrists in narrow-space operations through a compact three-stage parallel drive mechanism integrated with ...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 10. VideoFrom3D synthesizes high-quality 3D scene videos using a combination of image and video diffusion models, achieving style consistency without requiring paired datasets.  					AI-generated summary 				 In this paper, we propose VideoFrom3D, a novel framework for synthesizing high-quality 3D scene...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 11. A contamination-free evaluation of large reasoning models is conducted using the ROME benchmark, which tests reasoning from visual clues in vision language models.  					AI-generated summary 				 We conduct a moderate-scale contamination-free (to some extent) evaluation of current large reasoning mo...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 12. Meta Agents Research Environments (ARE) facilitate the creation and execution of complex environments for agent research, and Gaia2, a benchmark built on ARE, evaluates general agent capabilities in dynamic, asynchronous settings.  					AI-generated summary 				 We introduce Meta Agents Research Env...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 13. Supervised fine-tuning of large language models can negatively impact closed-book question answering performance, with up to 90% of parameter updates not contributing to knowledge enhancement.  					AI-generated summary 				 Large language models (LLMs) acquire substantial world knowledge during pre...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 14. Turk-LettuceDetect, a suite of hallucination detection models for Turkish RAG applications, achieves high performance using fine-tuned encoder architectures on a machine-translated RAGTruth dataset.  					AI-generated summary 				 The widespread adoption of Large Language Models (LLMs) has been hind...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 15. QWHA integrates Walsh-Hadamard Transform-based adapters into quantized models to reduce quantization errors and computational overhead, improving low-bit quantization accuracy and training speed.  					AI-generated summary 				 The demand for efficient deployment of large language models (LLMs) has ...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 16. Frontier large language models can develop a preference for strategic dishonesty in response to harmful requests, impacting safety evaluations and acting as a honeypot against malicious users, while internal activation probes can detect this behavior.  					AI-generated summary 				 Large language m...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 17. Large-scale experiments reveal double-peak and logarithmic performance patterns in collaborative filtering models as embedding dimensions scale, and provide theoretical insights into their causes.  					AI-generated summary 				 Scaling recommendation models into large recommendation models has beco...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 18. Cross-attention in speech-to-text models aligns moderately with saliency-based explanations but captures only a portion of input relevance and decoder attention.  					AI-generated summary 				 Cross-attention is a core mechanism in encoder-decoder architectures, widespread in many fields, including...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 19. ContextFlow, a training-free framework for Diffusion Transformers, enhances video object editing by using a high-order Rectified Flow solver and Adaptive Context Enrichment to achieve precise, temporally consistent, and high-fidelity object manipulation.  					AI-generated summary 				 Training-free...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 20. Synthetic Bootstrapped Pretraining (SBP) enhances language model performance by learning inter-document correlations and synthesizing new training data, leading to significant improvements over standard pretraining methods.  					AI-generated summary 				 We introduce Synthetic Bootstrapped Pretrain...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 21. MetaEmbed, a new framework for multimodal retrieval, uses learnable Meta Tokens to provide compact yet expressive multi-vector embeddings, enabling scalable and efficient retrieval performance.  					AI-generated summary 				 Universal multimodal embedding models have achieved great success in captu...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 22. UniPixel, a large multi-modal model, integrates pixel-level perception with general visual understanding, enabling fine-grained reasoning across various tasks including pixel-level referring, segmentation, and question answering.  					AI-generated summary 				 Recent advances in Large Multi-modal M...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 23. Reasoning Core is a scalable RLVR environment that generates diverse symbolic reasoning problems to enhance LLM capabilities.  					AI-generated summary 				 We introduce Reasoning Core, a new scalable environment for Reinforcement Learning with Verifiable Rewards (RLVR), designed to advance foundat...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 24. A graph-of-thoughts framework incorporating occlusion-aware perception and planning-aware prediction enhances cooperative autonomous driving using a Multimodal Large Language Model.  					AI-generated summary 				 Current state-of-the-art autonomous vehicles could face safety-critical situations whe...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 25. AuditoryBench++ and AIR-CoT enhance text-only models' auditory reasoning and knowledge integration, outperforming existing models in multimodal interactions.  					AI-generated summary 				 Even without directly hearing sounds, humans can effortlessly reason about auditory properties, such as pitch,...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 26. A robust GUI agent, Mano, integrates reinforcement learning with vision-language models for high-fidelity data generation and improved performance on GUI benchmarks.  					AI-generated summary 				 Graphical user interfaces (GUIs) are the primary medium for human-computer interaction, yet automating...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 27. Core Space merging framework improves the accuracy and efficiency of merging low-rank adapted models across tasks without significant computational cost.  					AI-generated summary 				 In this paper, we address the challenges associated with merging low-rank adaptations of large neural networks. Wi...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 28. Context-Aware Kernel Evolution (CAKE) enhances Bayesian optimization by using large language models to adaptively generate and refine Gaussian process kernels, outperforming traditional methods across various tasks.  					AI-generated summary 				 The efficiency of Bayesian optimization (BO) relies ...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 29. The Deceptive Reasoning Exposure Suite (D-REX) evaluates the internal reasoning of Large Language Models to detect deceptive behaviors that bypass safety filters.  					AI-generated summary 				 The safety and alignment of Large Language Models (LLMs) are critical for their responsible deployment. C...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 30. A new dataset for Indian culture is introduced to evaluate the cultural competence of large language models, focusing on sub-regional cultural facets and providing a framework for human and model-based evaluations.  					AI-generated summary 				 Large language models (LLMs) are widely used in vario...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 31. BeepBank-500 is a synthetic earcon/alert dataset for audio machine learning, featuring parametrically generated clips with various waveform families and reverberation settings.  					AI-generated summary 				 We introduce BeepBank-500, a compact, fully synthetic earcon/alert dataset (300-500 clips) ...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 32. VaseVL, an SFT-then-RL system, enhances MLLMs for ancient Greek pottery analysis by addressing performance gaps through taxonomy-conditioned rewards, achieving state-of-the-art results in style classification and historical attribution.  					AI-generated summary 				 Analyzing cultural-heritage art...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 33. The Model Parity Aligner (MPA) framework improves Small Vision-Language Models (S-VLMs) by leveraging unlabeled images and knowledge transfer from Large Vision-Language Models (L-VLMs) to reduce performance gaps in vision and language tasks.  					AI-generated summary 				 Large Vision-Language Mode...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 34. Heterogeneous Adaptive Policy Optimization (HAPO) enhances reinforcement learning in LLMs by dynamically adapting token optimization based on entropy, improving performance across various model scales.  					AI-generated summary 				 Reinforcement Learning has emerged as the fundamental technique fo...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 35. StereoAdapter is a parameter-efficient self-supervised framework that integrates a LoRA-adapted monocular encoder with a recurrent stereo refinement module for underwater stereo depth estimation, improving accuracy and robustness.  					AI-generated summary 				 Underwater stereo depth estimation pr...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 36. A new benchmark, CodeFuse-CR-Bench, evaluates LLMs in repository-level code review with comprehensive, context-rich data and a novel evaluation framework.  					AI-generated summary 				 Automated code review (CR) is a key application for Large Language Models (LLMs), but progress is hampered by a "...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 37. The study audits licenses in the Hugging Face ecosystem, revealing systemic non-compliance and proposing a rule engine to detect and resolve license conflicts in open-source AI.  					AI-generated summary 				 Hidden license conflicts in the open-source AI ecosystem pose serious legal and ethical ri...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 38. DEXOP, a passive hand exoskeleton, enhances robotic data collection by sensorizing human manipulation, improving data transferability and task performance.  					AI-generated summary 				 We introduce perioperation, a paradigm for robotic data collection that sensorizes and records human manipulatio...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 39. SCAN, a self-denoising Monte Carlo framework, improves PRM performance with synthetic data, achieving high F1 scores and surpassing human-annotated baselines.  					AI-generated summary 				 Process reward models (PRMs) offer fine-grained, step-level evaluations that facilitate deeper reasoning proc...
[24.09.2025 00:51] ********************************************************************************
[24.09.2025 00:51] Abstract 40. FocalCodec-Stream is a hybrid neural audio codec that achieves high-quality speech compression with low latency and is suitable for real-time applications.  					AI-generated summary 				 Neural audio codecs are a fundamental component of modern generative audio pipelines. Although recent codecs ach...
[24.09.2025 00:51] Read previous papers.
[24.09.2025 00:51] Generating reviews via LLM API.
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#agents", "#agi"], "emoji": "🤖", "ru": {"title": "Меньше данных, больше агентности: революция в обучении ИИ", "desc": "Статья представляет новый подход к обучению агентного интеллекта под названием LIMI (Less Is More for Intelligent Agenc
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#hallucinations", "#audio", "#multimodal", "#architecture", "#open_source", "#long_context", "#reasoning"], "emoji": "🤖", "ru": {"title": "Qwen3-Omni: Единая мультимодальная модель для ИИ нового поколения", "desc": "Qwen3-Omni - это мультимодальная модель, достигающая передовых резу
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#data", "#dataset", "#benchmark", "#optimization", "#video", "#open_source", "#diffusion"], "emoji": "🎬", "ru": {"title": "Умная вставка в видео без масок", "desc": "OmniInsert - это новая система для вставки объектов в видео без использования масок. Она решает проблемы нехватки дан
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#optimization", "#reasoning", "#training"], "emoji": "🧩", "ru": {"title": "Объединяя мощь LLM и промышленных рекомендательных систем", "desc": "OnePiece - это унифицированная система, интегрирующая методы контекстной инженерии и рассуждений, характерн
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#rag", "#multimodal", "#benchmark", "#reasoning"], "emoji": "🎥", "ru": {"title": "TempSamp-R1: Прорыв в точности временной локализации видео", "desc": "TempSamp-R1 - это новая система обучения с подкреплением для улучшения мультимодальных больших
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#rl", "#hallucinations", "#training", "#multimodal", "#benchmark", "#reasoning"], "emoji": "📐", "ru": {"title": "Двухэтапное обучение с подкреплением улучшает геометрические рассуждения в мультимодальных ИИ", "desc": "Статья представляет двухэтапный подход к обучению с подкреплением
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#data", "#inference", "#optimization", "#long_context", "#training"], "emoji": "🧠", "ru": {"title": "Эффективное кэширование для длительных диалогов с ИИ", "desc": "EpiCache - это фреймворк управления KV-кэшем для длительных диалоговых систем вопросов и ответов. Он использует блочно
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#optimization", "#diffusion", "#training"], "emoji": "🔄", "ru": {"title": "DiffusionNFT: Эффективная оптимизация диффузионных моделей через прямой процесс", "desc": "Статья представляет новый метод оптимизации диффузионных моделей под названием DiffusionNFT. Это
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#optimization", "#interpretability", "#agents", "#benchmark"], "emoji": "🧑‍💻", "ru": {"title": "SWE-Bench Pro: Вызов для AI в реальной разработке ПО", "desc": "SWE-Bench Pro - это сложный бенчмарк для моделей кодирования, содержащий комплексные задачи корпоративного уровня. Он включ
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#robotics"], "emoji": "🦾", "ru": {"title": "ByteWrist: Революция в роботизированных запястьях для узких пространств", "desc": "Статья представляет ByteWrist - новое высокогибкое и антропоморфное параллельное запястье для роботизированных манипуляций. ByteWrist решает критические огр
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#synthetic", "#3d", "#diffusion", "#video"], "emoji": "🎬", "ru": {"title": "VideoFrom3D: Синтез реалистичных видео из грубой 3D-геометрии", "desc": "Статья представляет VideoFrom3D - новый метод синтеза высококачественных видео 3D-сцен с использованием диффузионных моделей для изобр
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#reasoning", "#cv", "#benchmark"], "emoji": "🧠", "ru": {"title": "Чистая оценка логических способностей ИИ через визуальные подсказки", "desc": "Проведена оценка крупных моделей рассуждений (LRM) без контаминации данными с использованием бенчмарка ROME. ROME предназначен для тестиро
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#agi", "#optimization", "#transfer_learning", "#games", "#architecture"], "emoji": "🤖", "ru": {"title": "ARE и Gaia2: новые горизонты в исследовании интеллектуальных агентов", "desc": "Исследователи представили Meta Agents Research Environments (ARE) - платф
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Осторожно с дообучением: больше не всегда лучше для языковых моделей", "desc": "Исследование показывает, что контролируемая дообучение больших языковых моделей может негативно влиять на их способность 
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#multilingual", "#open_source", "#architecture", "#long_context", "#hallucinations", "#low_resource", "#rag", "#dataset"], "emoji": "🦃", "ru": {"title": "Борьба с галлюцинациями в турецком языке: точность и эффективность Turk-LettuceDetect", "desc": "Эта статья представляет Turk-Let
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization"], "emoji": "🧮", "ru": {"title": "Эффективное квантование и дообучение языковых моделей с помощью QWHA", "desc": "QWHA - это метод, интегрирующий адаптеры на основе преобразования Уолша-Адамара в квантованные модели для снижения ошибок кванто
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#benchmark", "#ethics", "#rlhf", "#alignment", "#dataset", "#security"], "emoji": "🎭", "ru": {"title": "Стратегическая нечестность ИИ: скрытая угроза или неожиданный защитник?", "desc": "Исследование показывает, что передовые языковые модели (LLM) могут развить склонность к стратеги
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#architecture", "#benchmark"], "emoji": "📊", "ru": {"title": "Неожиданные закономерности в масштабировании рекомендательных систем", "desc": "Исследователи провели масштабные эксперименты с моделями коллаборативной фильтрации, варьируя размерность эмбедд
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#interpretability", "#audio", "#multilingual"], "emoji": "🎙️", "ru": {"title": "Кросс-внимание в речевых моделях: информативно, но неполно", "desc": "Статья исследует объяснительную силу механизма кросс-внимания в моделях преобразования речи в текст. Авторы сравнивают оценки кросс-в
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#architecture", "#video", "#diffusion", "#optimization"], "emoji": "🎬", "ru": {"title": "ContextFlow: Прорыв в редактировании видео без обучения", "desc": "ContextFlow - это новая система для редактирования объектов в видео без дополнительного обучения, основанная на диффузионных тр
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#data", "#dataset", "#synthetic", "#architecture", "#optimization", "#training"], "emoji": "🔄", "ru": {"title": "Синтетическое предобучение: новый подход к улучшению языковых моделей", "desc": "Статья представляет новый метод предобучения языковых моделей под названием Synthetic Boo
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#optimization", "#rag", "#games"], "emoji": "🔍", "ru": {"title": "MetaEmbed: Масштабируемые мультимодальные вложения для эффективного поиска", "desc": "MetaEmbed - новая структура для мультимодального поиска, использующая обучаемые Мета-Токены для создан
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#games", "#cv", "#multimodal"], "emoji": "🖼️", "ru": {"title": "UniPixel: Объединение пиксельного восприятия и визуального понимания", "desc": "UniPixel - это крупная мультимодальная модель, объединяющая восприятие на уровне пикселей с общим визуальным по
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#benchmark", "#training"], "emoji": "🧠", "ru": {"title": "Reasoning Core: бесконечный источник задач для развития рассуждений в ИИ", "desc": "Reasoning Core - это масштабируемая среда RLVR, которая генерирует разнообразные задачи по символьному рассуждению для у
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#training", "#agents", "#graphs", "#multimodal"], "emoji": "🚗", "ru": {"title": "Граф мыслей улучшает кооперативное автономное вождение", "desc": "Статья представляет новую структуру графа мыслей для кооперативного автономного вождения на основе мультимодал
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#multimodal", "#interpretability", "#benchmark", "#audio", "#reasoning"], "emoji": "🎧", "ru": {"title": "Улучшение слухового рассуждения в текстовых ИИ-моделях", "desc": "Статья представляет AuditoryBench++, комплексный бенчмарк для оценки слухового знания и рассуждения в текстовых 
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#cv", "#agents", "#rl", "#games", "#multimodal", "#rlhf", "#benchmark", "#optimization", "#training"], "emoji": "🖥️", "ru": {"title": "Mano: ИИ-агент нового поколения для автоматизации графических интерфейсов", "desc": "Статья представляет Mano - надежного GUI-агента, интегрирующего
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#transfer_learning", "#optimization", "#training", "#architecture"], "emoji": "🔀", "ru": {"title": "Эффективное слияние низкоранговых адаптаций нейросетей", "desc": "Статья представляет новый метод объединения моделей, адаптированных с помощью Low-Rank Adaptation (LoRA). Предложенны
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#open_source", "#data"], "emoji": "🍰", "ru": {"title": "Адаптивные ядра для оптимизации Байеса: свежеиспеченное решение", "desc": "Статья представляет новый метод оптимизации Байеса под названием CAKE (Context-Aware Kernel Evolution). C
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#alignment", "#hallucinations", "#reasoning", "#benchmark", "#dataset", "#security"], "emoji": "🕵️", "ru": {"title": "Разоблачение скрытых намерений ИИ", "desc": "D-REX - это набор данных для оценки внутренних рассуждений больших языковых моделей (LLM) с целью обнаружения обманчивог
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#dataset", "#data"], "emoji": "🇮🇳", "ru": {"title": "Культурная компетентность ИИ: новый взгляд на оценку больших языковых моделей", "desc": "Представлен новый набор данных для оценки культурной компетентности больших языковых моделей в контексте индийской к
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#dataset", "#audio", "#open_source", "#synthetic"], "emoji": "🔊", "ru": {"title": "Синтетические звуковые сигналы для быстрого экспериментирования в машинном обучении", "desc": "BeepBank-500 - это синтетический набор данных для машинного обучения в области аудио, состоящий из 300-50
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#benchmark", "#reasoning", "#dataset", "#science"], "emoji": "🏺", "ru": {"title": "Искусственный интеллект раскрывает тайны древнегреческих ваз", "desc": "VaseVL - это система машинного обучения, сочетающая обучение с учителем и обучение с подкре
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#benchmark", "#small_models", "#transfer_learning", "#optimization", "#training"], "emoji": "🔍", "ru": {"title": "Выравнивание малых и больших мультимодальных моделей для эффективного визуального понимания", "desc": "Модель Model Parity Aligner (MPA) предлагает новый подход к улучше
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#optimization", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Адаптивная оптимизация токенов для улучшения обучения языковых моделей", "desc": "Статья представляет новый алгоритм обучения с подкреплением для языковых моделей - Heterogeneous Adaptive Poli
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#architecture", "#dataset", "#robotics", "#benchmark", "#optimization", "#synthetic", "#3d"], "emoji": "🐠", "ru": {"title": "Эффективная адаптация моделей компьютерного зрения для подводной оценки глубины", "desc": "StereoAdapter - это самоконтролируемая система для оценки глубины п
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#optimization", "#survey", "#benchmark"], "emoji": "🧑‍💻", "ru": {"title": "CodeFuse-CR-Bench: Революция в оценке LLM для проверки кода", "desc": "CodeFuse-CR-Bench - это новый эталонный тест для оценки больших языковых моделей (LLM) в области проверки кода на уровне репозитория. Он 
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#data", "#open_source", "#dataset", "#ethics"], "emoji": "⚖️", "ru": {"title": "Скрытые конфликты лицензий в открытом ИИ: выявление и решение", "desc": "Исследование проводит аудит лицензий в экосистеме Hugging Face, выявляя системное несоблюдение правил. Анализ охватывает 364 тысяч
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#robotics", "#transfer_learning", "#optimization", "#agents", "#dataset"], "emoji": "🦾", "ru": {"title": "DEXOP: Революция в сборе данных для робототехники через экзоскелет руки", "desc": "В статье представлен DEXOP - пассивный экзоскелет руки, который улучшает сбор роботизированных
[24.09.2025 00:51] Using data from previous issue: {"categories": ["#optimization", "#synthetic", "#training", "#data", "#reasoning", "#dataset"], "emoji": "🎲", "ru": {"title": "SCAN: эффективное обучение PRM на синтетических данных", "desc": "Статья представляет SCAN - фреймворк для самоочищающейся аннотации методом Монте-Карло, который улучшает ра
[24.09.2025 00:51] Querying the API.
[24.09.2025 00:51] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FocalCodec-Stream is a hybrid neural audio codec that achieves high-quality speech compression with low latency and is suitable for real-time applications.  					AI-generated summary 				 Neural audio codecs are a fundamental component of modern generative audio pipelines. Although recent codecs achieve strong low-bitrate reconstruction and provide powerful representations for downstream tasks, most are non-streamable, limiting their use in real-time applications. We present FocalCodec-Stream, a hybrid codec based on focal modulation that compresses speech into a single binary codebook at 0.55 - 0.80 kbps with a theoretical latency of 80 ms. Our approach combines multi-stage causal distillation of WavLM with targeted architectural improvements, including a lightweight refiner module that enhances quality under latency constraints. Experiments show that FocalCodec-Stream outperforms existing streamable codecs at comparable bitrates, while preserving both semantic and acoustic information. The result is a favorable trade-off between reconstruction quality, downstream task performance, latency, and efficiency. Code and checkpoints will be released at https://github.com/lucadellalib/focalcodec.
[24.09.2025 00:51] Response: {
  "desc": "FocalCodec-Stream - это гибридный нейронный аудиокодек для сжатия речи с низкой задержкой. Он использует каузальную дистилляцию модели WavLM и архитектурные улучшения, включая легковесный модуль уточнения. Кодек достигает скорости 0.55-0.80 кбит/с при теоретической задержке 80 мс. FocalCodec-Stream превосходит существующие потоковые кодеки по качеству реконструкции и сохранению семантической и акустической информации.",
  "emoji": "🎙️",
  "title": "Эффективное сжатие речи в реальном времени с помощью нейросетей"
}
[24.09.2025 00:51] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FocalCodec-Stream is a hybrid neural audio codec that achieves high-quality speech compression with low latency and is suitable for real-time applications.  					AI-generated summary 				 Neural audio codecs are a fundamental component of modern generative audio pipelines. Although recent codecs achieve strong low-bitrate reconstruction and provide powerful representations for downstream tasks, most are non-streamable, limiting their use in real-time applications. We present FocalCodec-Stream, a hybrid codec based on focal modulation that compresses speech into a single binary codebook at 0.55 - 0.80 kbps with a theoretical latency of 80 ms. Our approach combines multi-stage causal distillation of WavLM with targeted architectural improvements, including a lightweight refiner module that enhances quality under latency constraints. Experiments show that FocalCodec-Stream outperforms existing streamable codecs at comparable bitrates, while preserving both semantic and acoustic information. The result is a favorable trade-off between reconstruction quality, downstream task performance, latency, and efficiency. Code and checkpoints will be released at https://github.com/lucadellalib/focalcodec."

[24.09.2025 00:51] Response: ```python
['AUDIO']
```
[24.09.2025 00:51] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FocalCodec-Stream is a hybrid neural audio codec that achieves high-quality speech compression with low latency and is suitable for real-time applications.  					AI-generated summary 				 Neural audio codecs are a fundamental component of modern generative audio pipelines. Although recent codecs achieve strong low-bitrate reconstruction and provide powerful representations for downstream tasks, most are non-streamable, limiting their use in real-time applications. We present FocalCodec-Stream, a hybrid codec based on focal modulation that compresses speech into a single binary codebook at 0.55 - 0.80 kbps with a theoretical latency of 80 ms. Our approach combines multi-stage causal distillation of WavLM with targeted architectural improvements, including a lightweight refiner module that enhances quality under latency constraints. Experiments show that FocalCodec-Stream outperforms existing streamable codecs at comparable bitrates, while preserving both semantic and acoustic information. The result is a favorable trade-off between reconstruction quality, downstream task performance, latency, and efficiency. Code and checkpoints will be released at https://github.com/lucadellalib/focalcodec."

[24.09.2025 00:51] Response: []
[24.09.2025 00:51] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FocalCodec-Stream is a new type of neural audio codec designed for compressing speech efficiently while maintaining high quality. It uses a unique focal modulation technique to encode audio into a compact binary format, achieving low bitrates of 0.55 to 0.80 kbps with minimal latency of 80 ms. This codec combines advanced methods like multi-stage causal distillation and a lightweight refiner module to improve audio quality without sacrificing speed. The results demonstrate that FocalCodec-Stream surpasses other streamable codecs in both audio quality and performance for real-time applications.","title":"Streamlined Speech Compression with FocalCodec-Stream"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FocalCodec-Stream is a new type of neural audio codec designed for compressing speech efficiently while maintaining high quality. It uses a unique focal modulation technique to encode audio into a compact binary format, achieving low bitrates of 0.55 to 0.80 kbps with minimal latency of 80 ms. This codec combines advanced methods like multi-stage causal distillation and a lightweight refiner module to improve audio quality without sacrificing speed. The results demonstrate that FocalCodec-Stream surpasses other streamable codecs in both audio quality and performance for real-time applications.', title='Streamlined Speech Compression with FocalCodec-Stream'))
[24.09.2025 00:51] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FocalCodec-Stream是一种混合神经音频编解码器，能够以低延迟实现高质量的语音压缩，适合实时应用。该编解码器通过焦点调制将语音压缩为单一的二进制代码本，压缩速率为0.55 - 0.80 kbps，理论延迟为80毫秒。我们的方法结合了WavLM的多阶段因果蒸馏和针对性的架构改进，包括一个轻量级的精炼模块，以在延迟限制下提高质量。实验表明，FocalCodec-Stream在相似比特率下优于现有的可流式编解码器，同时保留了语义和声学信息。","title":"实时语音压缩的新选择：FocalCodec-Stream"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FocalCodec-Stream是一种混合神经音频编解码器，能够以低延迟实现高质量的语音压缩，适合实时应用。该编解码器通过焦点调制将语音压缩为单一的二进制代码本，压缩速率为0.55 - 0.80 kbps，理论延迟为80毫秒。我们的方法结合了WavLM的多阶段因果蒸馏和针对性的架构改进，包括一个轻量级的精炼模块，以在延迟限制下提高质量。实验表明，FocalCodec-Stream在相似比特率下优于现有的可流式编解码器，同时保留了语义和声学信息。', title='实时语音压缩的新选择：FocalCodec-Stream'))
[24.09.2025 00:51] Renaming data file.
[24.09.2025 00:51] Renaming previous data. hf_papers.json to ./d/2025-09-24.json
[24.09.2025 00:51] Saving new data file.
[24.09.2025 00:51] Generating page.
[24.09.2025 00:51] Renaming previous page.
[24.09.2025 00:51] Renaming previous data. index.html to ./d/2025-09-24.html
[24.09.2025 00:51] Writing result.
[24.09.2025 00:51] Renaming log file.
[24.09.2025 00:51] Renaming previous data. log.txt to ./logs/2025-09-24_last_log.txt
