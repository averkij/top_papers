[07.04.2025 08:15] Read previous papers.
[07.04.2025 08:15] Generating top page (month).
[07.04.2025 08:15] Writing top page (month).
[07.04.2025 09:12] Read previous papers.
[07.04.2025 09:12] Get feed.
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02605
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03553
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03561
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02949
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03641
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03601
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03011
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02402
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03536
[07.04.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2503.24067
[07.04.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2503.24310
[07.04.2025 09:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[07.04.2025 09:12] No deleted papers detected.
[07.04.2025 09:12] Downloading and parsing papers (pdf, html). Total: 11.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.02605.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.02605.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.02605.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.03553.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.03553.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.03553.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.03561.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.03561.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.03561.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.02949.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.02949.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.02949.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.03641.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.03641.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.03641.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.03601.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.03601.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.03601.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.03011.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.03011.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.03011.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.02402.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.02402.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.02402.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2504.03536.
[07.04.2025 09:12] Extra JSON file exists (./assets/json/2504.03536.json), skip PDF parsing.
[07.04.2025 09:12] Paper image links file exists (./assets/img_data/2504.03536.json), skip HTML parsing.
[07.04.2025 09:12] Success.
[07.04.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2503.24067.
[07.04.2025 09:13] Downloading paper 2503.24067 from http://arxiv.org/pdf/2503.24067v1...
[07.04.2025 09:13] Extracting affiliations from text.
[07.04.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 3 ] . [ 1 7 6 0 4 2 . 3 0 5 2 : r Preprint. Under review. TransMamba: Flexibly Switching between Transformer and Mamba Yixing Li2, Ruobing Xie1, Zhen Yang1, Xingwu Sun1,3, Shuaipeng Li1, Weidong Han1, Zhanhui Kang1, Yu Cheng2, Chengzhong Xu3, Di Wang1, Jie Jiang1 1Tencent Hunyuan 2The Chinese University of Hong Kong 3University of Macau li.yixing@outlook.com xrbsnowing@163.com {andreasyang, sammsun, jonnyhan}@tencent.com chengyu@cse.cuhk.edu.hk "
[07.04.2025 09:13] Response: ```python
["Tencent Hunyuan", "The Chinese University of Hong Kong", "University of Macau"]
```
[07.04.2025 09:13] Deleting PDF ./assets/pdf/2503.24067.pdf.
[07.04.2025 09:13] Success.
[07.04.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2503.24310.
[07.04.2025 09:13] Extra JSON file exists (./assets/json/2503.24310.json), skip PDF parsing.
[07.04.2025 09:13] Paper image links file exists (./assets/img_data/2503.24310.json), skip HTML parsing.
[07.04.2025 09:13] Success.
[07.04.2025 09:13] Enriching papers with extra data.
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 0. The task of issue resolving is to modify a codebase to generate a patch that addresses a given issue. However, existing benchmarks, such as SWE-bench, focus almost exclusively on Python, making them insufficient for evaluating Large Language Models (LLMs) across diverse software ecosystems. To addre...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 1. Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional agent planning approaches adopt a "flood irrigation" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models....
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 2. In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomou...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 3. In this work, we present VARGPT-v1.1, an advanced unified visual autoregressive model that builds upon our previous framework VARGPT. The model preserves the dual paradigm of next-token prediction for visual understanding and next-scale generation for image synthesis. Specifically, VARGPT-v1.1 integ...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 4. Existing MLLM benchmarks face significant challenges in evaluating Unified MLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional tasks, leading to inconsistent comparisons; 2) absence of benchmarks for mixed-modality generation, which fails to assess multimodal reasoning capabil...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 5. Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In t...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 6. This paper introduces Comprehensive Relighting, the first all-in-one approach that can both control and harmonize the lighting from an image or video of humans with arbitrary body parts from any scene. Building such a generalizable model is extremely challenging due to the lack of dataset, restricti...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 7. When sound waves hit an object, they induce vibrations that produce high-frequency and subtle visual changes, which can be used for recovering the sound. Early studies always encounter trade-offs related to sampling rate, bandwidth, field of view, and the simplicity of the optical path. Recent advan...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 8. Single-image human reconstruction is vital for digital human modeling applications but remains an extremely challenging task. Current approaches rely on generative models to synthesize multi-view images for subsequent 3D reconstruction and animation. However, directly generating multiple views from ...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 9. Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable cont...
[07.04.2025 09:13] ********************************************************************************
[07.04.2025 09:13] Abstract 10. In this research, we introduce BEATS, a novel framework for evaluating Bias, Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building upon the BEATS framework, we present a bias benchmark for LLMs that measure performance across 29 distinct metrics. These metrics span a broad range...
[07.04.2025 09:13] Read previous papers.
[07.04.2025 09:13] Generating reviews via LLM API.
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#agi", "#benchmark", "#rl", "#open_source", "#multilingual", "#dataset"], "emoji": "🌐", "ru": {"title": "Многоязычный бенчмарк для оценки ИИ в решении программных задач", "desc": "Представлен новый многоязычный бенчмарк Multi-SWE-bench для оценки способности языковых моделей решать 
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#agents", "#agi"], "emoji": "🧠", "ru": {"title": "Самоосознанность в планировании: эффективное использование знаний языковыми моделями", "desc": "Статья представляет новый подход к обучению языковых моделей для задач планирования, называем
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#transfer_learning", "#agents", "#rl"], "emoji": "🌐", "ru": {"title": "SynWorld: Автономное исследование и обучение агентов в новых средах", "desc": "SynWorld - это фреймворк, позволяющий агентам на основе больших языковых моделей (LLM) автономно исследовать новые с
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#training", "#multimodal", "#rlhf", "#open_source", "#cv", "#optimization"], "emoji": "🖼️", "ru": {"title": "Единая модель для понимания, генерации и редактирования изображений", "desc": "VARGPT-v1.1 - это усовершенствованная унифицированная визуальная авторегрессионная модель, разв
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#survey"], "emoji": "🧠", "ru": {"title": "Новый стандарт оценки мультимодальных языковых моделей", "desc": "Эта статья представляет новую систему оценки для унифицированных мультимодальных языковых моделей (U-MLLM). Авторы разработали комплексный фреймво
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#agents", "#open_source", "#data", "#training"], "emoji": "🤖", "ru": {"title": "Революция в обучении ИИ-агентов: синтетические данные для реалистичного многоходового взаимодействия", "desc": "APIGen-MT - это новый фреймворк для генерации качественных данных
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#inference", "#video", "#cv", "#diffusion"], "emoji": "💡", "ru": {"title": "Универсальное управление освещением людей на изображениях и видео", "desc": "Статья представляет Comprehensive Relighting - первый универсальный подход к контролю и гармонизации освещения людей на изображени
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#training", "#dataset", "#data", "#cv"], "emoji": "🔊", "ru": {"title": "Новый подход к бесконтактному восстановлению звука с помощью событийных камер", "desc": "Статья представляет новый метод бесконтактного восстановления звука с использованием событийных камер. Авторы разработали 
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#synthetic", "#cv", "#3d"], "emoji": "🧑‍🦰", "ru": {"title": "Реалистичные 3D-модели людей из одного фото", "desc": "HumanDreamer-X - это новая система для реконструкции 3D-моделей человека по одному изображению. Она объединяет генерацию мультиракурсных изображений и 3D-реконструкцию
[07.04.2025 09:13] Querying the API.
[07.04.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable contextual learning and multitask generalization. This paper proposes TransMamba, a novel framework that unifies Transformer and Mamba through shared parameter matrices (e.g., QKV and CBx), and thus could dynamically switch between attention and SSM mechanisms at different token lengths and layers. We design the Memory converter to bridge Transformer and Mamba by converting attention outputs into SSM-compatible states, ensuring seamless information flow at TransPoints where the transformation happens. The TransPoint scheduling is also thoroughly explored for further improvements. We conducted extensive experiments demonstrating that TransMamba achieves superior training efficiency and performance compared to baselines, and validated the deeper consistency between Transformer and Mamba paradigms, offering a scalable solution for next-generation sequence modeling.
[07.04.2025 09:13] Response: {
  "desc": "TransMamba - это новая архитектура, объединяющая Transformer и Mamba через общие матрицы параметров. Она позволяет динамически переключаться между механизмами внимания и моделями пространства состояний (SSM) на разных длинах токенов и слоях. Модель использует конвертер памяти для преобразования выходов внимания в состояния, совместимые с SSM. Эксперименты показали, что TransMamba превосходит базовые модели по эффективности обучения и производительности.",
  "emoji": "🔀",
  "title": "Объединение Transformer и Mamba для эффективной обработки длинных последовательностей"
}
[07.04.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable contextual learning and multitask generalization. This paper proposes TransMamba, a novel framework that unifies Transformer and Mamba through shared parameter matrices (e.g., QKV and CBx), and thus could dynamically switch between attention and SSM mechanisms at different token lengths and layers. We design the Memory converter to bridge Transformer and Mamba by converting attention outputs into SSM-compatible states, ensuring seamless information flow at TransPoints where the transformation happens. The TransPoint scheduling is also thoroughly explored for further improvements. We conducted extensive experiments demonstrating that TransMamba achieves superior training efficiency and performance compared to baselines, and validated the deeper consistency between Transformer and Mamba paradigms, offering a scalable solution for next-generation sequence modeling."

[07.04.2025 09:13] Response: ```python
['ARCHITECTURE', 'TRAINING']
```
[07.04.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable contextual learning and multitask generalization. This paper proposes TransMamba, a novel framework that unifies Transformer and Mamba through shared parameter matrices (e.g., QKV and CBx), and thus could dynamically switch between attention and SSM mechanisms at different token lengths and layers. We design the Memory converter to bridge Transformer and Mamba by converting attention outputs into SSM-compatible states, ensuring seamless information flow at TransPoints where the transformation happens. The TransPoint scheduling is also thoroughly explored for further improvements. We conducted extensive experiments demonstrating that TransMamba achieves superior training efficiency and performance compared to baselines, and validated the deeper consistency between Transformer and Mamba paradigms, offering a scalable solution for next-generation sequence modeling."

[07.04.2025 09:13] Response: ```python
["OPTIMIZATION", "LONG_CONTEXT"]
```
[07.04.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces TransMamba, a new framework that combines the strengths of Transformers and Mamba, a state space model, to improve efficiency in processing long sequences. By using shared parameter matrices, TransMamba can switch between attention mechanisms and state space models based on the length of the input tokens. The Memory converter is designed to ensure smooth transitions between these two methods, allowing for effective information flow. Experimental results show that TransMamba outperforms existing models in both training efficiency and performance, making it a promising solution for future sequence modeling tasks.","title":"TransMamba: Bridging Transformers and State Space Models for Efficient Sequence Processing"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces TransMamba, a new framework that combines the strengths of Transformers and Mamba, a state space model, to improve efficiency in processing long sequences. By using shared parameter matrices, TransMamba can switch between attention mechanisms and state space models based on the length of the input tokens. The Memory converter is designed to ensure smooth transitions between these two methods, allowing for effective information flow. Experimental results show that TransMamba outperforms existing models in both training efficiency and performance, making it a promising solution for future sequence modeling tasks.', title='TransMamba: Bridging Transformers and State Space Models for Efficient Sequence Processing'))
[07.04.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的框架TransMamba，旨在结合Transformer和Mamba模型，以提高长序列处理的效率。通过共享参数矩阵，TransMamba能够在不同的token长度和层次之间动态切换注意力机制和状态空间模型（SSM）。我们设计了记忆转换器，将注意力输出转换为SSM兼容的状态，确保信息在转换点的无缝流动。此外，本文还深入探讨了TransPoint调度，以进一步提升性能。","title":"TransMamba：高效的序列建模新方案"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的框架TransMamba，旨在结合Transformer和Mamba模型，以提高长序列处理的效率。通过共享参数矩阵，TransMamba能够在不同的token长度和层次之间动态切换注意力机制和状态空间模型（SSM）。我们设计了记忆转换器，将注意力输出转换为SSM兼容的状态，确保信息在转换点的无缝流动。此外，本文还深入探讨了TransPoint调度，以进一步提升性能。', title='TransMamba：高效的序列建模新方案'))
[07.04.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#ethics"], "emoji": "⚖️", "ru": {"title": "BEATS: комплексная оценка этичности языковых моделей", "desc": "Исследователи представили BEATS - новую систему оценки предвзятости, этики, справедливости и фактической точности в больших языковых моделях (LLM). На
[07.04.2025 09:13] Trying to get texts in Chinese.
[07.04.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

The task of issue resolving is to modify a codebase to generate a patch that addresses a given issue. However, existing benchmarks, such as SWE-bench, focus almost exclusively on Python, making them insufficient for evaluating Large Language Models (LLMs) across diverse software ecosystems. To address this, we introduce a multilingual issue-resolving benchmark, called Multi-SWE-bench, covering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a total of 1,632 high-quality instances, which were carefully annotated from 2,456 candidates by 68 expert annotators, ensuring that the benchmark can provide an accurate and reliable evaluation. Based on Multi-SWE-bench, we evaluate a series of state-of-the-art models using three representative methods (Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with key empirical insights. In addition, we launch a Multi-SWE-RL open-source community, aimed at building large-scale reinforcement learning (RL) training datasets for issue-resolving tasks. As an initial contribution, we release a set of 4,723 well-structured instances spanning seven programming languages, laying a solid foundation for RL research in this domain. More importantly, we open-source our entire data production pipeline, along with detailed tutorials, encouraging the open-source community to continuously contribute and expand the dataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL community as catalysts for advancing RL toward its full potential, bringing us one step closer to the dawn of AGI.
[07.04.2025 09:13] Mistral response. {"id": "cb82e8e5f2644d2bb240d5fd576f273a", "object": "chat.completion", "created": 1744017198, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u8bed\u8a00\u95ee\u9898\u89e3\u51b3\u57fa\u51c6\uff0c\u79f0\u4e3aMulti-SWE-bench\u3002\u5b83\u6db5\u76d6\u4e86Java\u3001TypeScript\u3001JavaScript\u3001Go\u3001Rust\u3001C\u548cC++\u7b49\u8bed\u8a00\u3002\u8be5\u57fa\u51c6\u5305\u542b1,632\u4e2a\u9ad8\u8d28\u91cf\u5b9e\u4f8b\uff0c\u753168\u4f4d\u4e13\u5bb6\u6ce8\u91ca\u3002\u57fa\u4e8e\u8fd9\u4e2a\u57fa\u51c6\uff0c\u4f5c\u8005\u8bc4\u4f30\u4e86\u4e00\u7cfb\u5217\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5206\u6790\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8fd8\u5ba3\u5e03\u6210\u7acb\u4e86\u4e00\u4e2a\u5f00\u6e90\u793e\u533aMulti-SWE-RL\uff0c\u65e8\u5728\u4e3a\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u6784\u5efa\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\u96c6\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 396, "total_tokens": 563, "completion_tokens": 167}}
[07.04.2025 09:13] Response: 这篇文章介绍了一个新的多语言问题解决基准，称为Multi-SWE-bench。它涵盖了Java、TypeScript、JavaScript、Go、Rust、C和C++等语言。该基准包含1,632个高质量实例，由68位专家注释。基于这个基准，作者评估了一系列先进的模型，并提供了详细的分析。此外，文章还宣布成立了一个开源社区Multi-SWE-RL，旨在为问题解决任务构建大规模强化学习训练数据集。
[07.04.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

这篇文章介绍了一个新的多语言问题解决基准，称为Multi-SWE-bench。它涵盖了Java、TypeScript、JavaScript、Go、Rust、C和C++等语言。该基准包含1,632个高质量实例，由68位专家注释。基于这个基准，作者评估了一系列先进的模型，并提供了详细的分析。此外，文章还宣布成立了一个开源社区Multi-SWE-RL，旨在为问题解决任务构建大规模强化学习训练数据集。
[07.04.2025 09:13] Mistral response. {"id": "5129c5a544224d97856a822783906834", "object": "chat.completion", "created": 1744017203, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u8bed\u8a00\u95ee\u9898\u89e3\u51b3\u57fa\u51c6\uff0c\u79f0\u4e3aMulti-SWE-bench\u3002\u5b83\u6db5\u76d6\u4e86Java\u3001TypeScript\u3001JavaScript\u3001Go\u3001Rust\u3001C\u548cC++\u7b49\u8bed\u8a00\u3002\u8be5\u57fa\u51c6\u5305\u542b1,632\u4e2a\u9ad8\u8d28\u91cf\u5b9e\u4f8b\uff0c\u753168\u4f4d\u4e13\u5bb6\u6ce8\u91ca\u3002\u57fa\u4e8e\u8fd9\u4e2a\u57fa\u51c6\uff0c\u4f5c\u8005\u8bc4\u4f30\u4e86\u4e00\u7cfb\u5217\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5206\u6790\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8fd8\u5ba3\u5e03\u6210\u7acb\u4e86\u4e00\u4e2a\u5f00\u6e90\u793e\u533aMulti-SWE-RL\uff0c\u65e8\u5728\u4e3a\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u6784\u5efa\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\u96c6\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng ji\u00e8 sh\u00e0o le y\u012b g\u00e8 x\u012bn de du\u014d y\u01d4 y\u00e1n w\u00e8n t\u00ed ji\u011b ju\u00e9 j\u012b zh\u01d4n, ch\u0113ng w\u00e9i Multi-SWE-bench. t\u0101 h\u00e1n g\u01cei le Java, TypeScript, JavaScript, Go, Rust, C h\u00e9 C++ d\u011bng y\u01d4 y\u00e1n. g\u01cei j\u012b zh\u01d4n b\u0101o h\u00e1n 1,632 g\u00e8 g\u0101o zh\u00ec li\u00e0ng sh\u00ed l\u00ec, y\u01d2u 68 w\u00e8i zhu\u0101n ji\u0101 zh\u00f9 sh\u00ec. j\u012b y\u00fa zh\u00e8 g\u00e8 j\u012b zh\u01d4n, zu\u00f2 zh\u011b p\u00edng g\u016b le y\u012b x\u00ec li\u00e8 xi\u0101n j\u00ecn de m\u00f3 x\u00edng, b\u00ecng t\u00ed g\u014dng le xi\u00e1ng x\u00ec de f\u0113n x\u012b. c\u01d0 w\u00e0i, w\u00e9n zh\u0101ng h\u00e1i xu\u0101n b\u00f9 ch\u00e9ng l\u00ec le y\u012b g\u00e8 k\u0101i yu\u00e1n sh\u00e8 q\u016b Multi-SWE-RL, zh\u01d0 y\u00fa w\u00e8i w\u00e8n t\u00ed ji\u011b ju\u00e9 r\u00e8n w\u00f9 g\u00f2u ji\u00e0n d\u00e0 gu\u012b m\u00f3 qi\u00e1ng hu\u00e0 xu\u00e9 x\u00f9n li\u00e0n sh\u00f9 j\u00f9 j\u00ed."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 181, "total_tokens": 673, "completion_tokens": 492}}
[07.04.2025 09:13] Response: 这篇文章介绍了一个新的多语言问题解决基准，称为Multi-SWE-bench。它涵盖了Java、TypeScript、JavaScript、Go、Rust、C和C++等语言。该基准包含1,632个高质量实例，由68位专家注释。基于这个基准，作者评估了一系列先进的模型，并提供了详细的分析。此外，文章还宣布成立了一个开源社区Multi-SWE-RL，旨在为问题解决任务构建大规模强化学习训练数据集。

zhè piān wén zhāng jiè shào le yī gè xīn de duō yǔ yán wèn tí jiě jué jī zhǔn, chēng wéi Multi-SWE-bench. tā hán gǎi le Java, TypeScript, JavaScript, Go, Rust, C hé C++ děng yǔ yán. gǎi jī zhǔn bāo hán 1,632 gè gāo zhì liàng shí lì, yǒu 68 wèi zhuān jiā zhù shì. jī yú zhè gè jī zhǔn, zuò zhě píng gū le yī xì liè xiān jìn de mó xíng, bìng tí gōng le xiáng xì de fēn xī. cǐ wài, wén zhāng hái xuān bù chéng lì le yī gè kāi yuán shè qū Multi-SWE-RL, zhǐ yú wèi wèn tí jiě jué rèn wù gòu jiàn dà guī mó qiáng huà xué xùn liàn shù jù jí.
[07.04.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

这篇文章介绍了一个新的多语言问题解决基准，称为Multi-SWE-bench。它涵盖了Java、TypeScript、JavaScript、Go、Rust、C和C++等语言。该基准包含1,632个高质量实例，由68位专家注释。基于这个基准，作者评估了一系列先进的模型，并提供了详细的分析。此外，文章还宣布成立了一个开源社区Multi-SWE-RL，旨在为问题解决任务构建大规模强化学习训练数据集。
[07.04.2025 09:13] Mistral response. {"id": "3a66650dd1954841b4fa3c2527ff23bb", "object": "chat.completion", "created": 1744017213, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\n    {\"word\": \"\u6db5\u76d6\", \"pinyin\": \"h\u00e1ng\u00e0i\", \"trans\": \"cover\"},\n    {\"word\": \"\u57fa\u51c6\", \"pinyin\": \"j\u012bzh\u01d4n\", \"trans\": \"benchmark\"},\n    {\"word\": \"\u6ce8\u91ca\", \"pinyin\": \"zh\u00f9sh\u00ec\", \"trans\": \"annotate\"},\n    {\"word\": \"\u8bc4\u4f30\", \"pinyin\": \"p\u00edngg\u016b\", \"trans\": \"evaluate\"},\n    {\"word\": \"\u5148\u8fdb\", \"pinyin\": \"xi\u0101nj\u00ecn\", \"trans\": \"advanced\"},\n    {\"word\": \"\u8be6\u7ec6\", \"pinyin\": \"xi\u00e1ngx\u00ec\", \"trans\": \"detailed\"},\n    {\"word\": \"\u5206\u6790\", \"pinyin\": \"f\u0113nx\u012b\", \"trans\": \"analysis\"},\n    {\"word\": \"\u5ba3\u5e03\", \"pinyin\": \"xu\u0101nb\u00f9\", \"trans\": \"announce\"},\n    {\"word\": \"\u6210\u7acb\", \"pinyin\": \"ch\u00e9ngl\u00ec\", \"trans\": \"establish\"},\n    {\"word\": \"\u5f00\u6e90\", \"pinyin\": \"k\u0101iyu\u00e1n\", \"trans\": \"open-source\"},\n    {\"word\": \"\u793e\u533a\", \"pinyin\": \"sh\u00e8q\u016b\", \"trans\": \"community\"},\n    {\"word\": \"\u65e8\u5728\", \"pinyin\": \"zh\u01d0z\u00e0i\", \"trans\": \"aim to\"},\n    {\"word\": \"\u6784\u5efa\", \"pinyin\": \"g\u00f2uji\u00e0n\", \"trans\": \"build\"},\n    {\"word\": \"\u4efb\u52a1\", \"pinyin\": \"r\u00e8nw\u00f9\", \"trans\": \"task\"},\n    {\"word\": \"\u5f3a\u5316\u5b66\u4e60\", \"pinyin\": \"qi\u00e1ng hu\u00e0 xu\u00e9x\u00ed\", \"trans\": \"reinforcement learning\"},\n    {\"word\": \"\u8bad\u7ec3\", \"pinyin\": \"x\u00f9nli\u00e0n\", \"trans\": \"training\"},\n    {\"word\": \"\u6570\u636e\u96c6\", \"pinyin\": \"sh\u00f9j\u00f9j\u00ed\", \"trans\": \"dataset\"}\n]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 213, "total_tokens": 706, "completion_tokens": 493}}
[07.04.2025 09:13] Response: [
    {"word": "涵盖", "pinyin": "hángài", "trans": "cover"},
    {"word": "基准", "pinyin": "jīzhǔn", "trans": "benchmark"},
    {"word": "注释", "pinyin": "zhùshì", "trans": "annotate"},
    {"word": "评估", "pinyin": "pínggū", "trans": "evaluate"},
    {"word": "先进", "pinyin": "xiānjìn", "trans": "advanced"},
    {"word": "详细", "pinyin": "xiángxì", "trans": "detailed"},
    {"word": "分析", "pinyin": "fēnxī", "trans": "analysis"},
    {"word": "宣布", "pinyin": "xuānbù", "trans": "announce"},
    {"word": "成立", "pinyin": "chénglì", "trans": "establish"},
    {"word": "开源", "pinyin": "kāiyuán", "trans": "open-source"},
    {"word": "社区", "pinyin": "shèqū", "trans": "community"},
    {"word": "旨在", "pinyin": "zhǐzài", "trans": "aim to"},
    {"word": "构建", "pinyin": "gòujiàn", "trans": "build"},
    {"word": "任务", "pinyin": "rènwù", "trans": "task"},
    {"word": "强化学习", "pinyin": "qiáng huà xuéxí", "trans": "reinforcement learning"},
    {"word": "训练", "pinyin": "xùnliàn", "trans": "training"},
    {"word": "数据集", "pinyin": "shùjùjí", "trans": "dataset"}
]
[07.04.2025 09:13] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

这篇文章介绍了一个新的多语言问题解决基准，称为Multi-SWE-bench。它涵盖了Java、TypeScript、JavaScript、Go、Rust、C和C++等语言。该基准包含1,632个高质量实例，由68位专家注释。基于这个基准，作者评估了一系列先进的模型，并提供了详细的分析。此外，文章还宣布成立了一个开源社区Multi-SWE-RL，旨在为问题解决任务构建大规模强化学习训练数据集。
[07.04.2025 09:13] Mistral response. {"id": "06ccc9b3321043dc90eb1d2e5bc856ee", "object": "chat.completion", "created": 1744017223, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article introduces a new multilingual problem-solving benchmark called Multi-SWE-bench. It covers languages such as Java, TypeScript, JavaScript, Go, Rust, C, and C++. The benchmark contains 1,632 high-quality instances annotated by 68 experts. Based on this benchmark, the authors evaluated a series of advanced models and provided detailed analyses. Additionally, the article announces the establishment of an open-source community, Multi-SWE-RL, aimed at building large-scale reinforcement learning training datasets for problem-solving tasks."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 179, "total_tokens": 309, "completion_tokens": 130}}
[07.04.2025 09:13] Response: This article introduces a new multilingual problem-solving benchmark called Multi-SWE-bench. It covers languages such as Java, TypeScript, JavaScript, Go, Rust, C, and C++. The benchmark contains 1,632 high-quality instances annotated by 68 experts. Based on this benchmark, the authors evaluated a series of advanced models and provided detailed analyses. Additionally, the article announces the establishment of an open-source community, Multi-SWE-RL, aimed at building large-scale reinforcement learning training datasets for problem-solving tasks.
[07.04.2025 09:13] Renaming data file.
[07.04.2025 09:13] Renaming previous data. hf_papers.json to ./d/2025-04-07.json
[07.04.2025 09:13] Saving new data file.
[07.04.2025 09:13] Generating page.
[07.04.2025 09:13] Renaming previous page.
[07.04.2025 09:13] Renaming previous data. index.html to ./d/2025-04-07.html
[07.04.2025 09:13] [Experimental] Generating Chinese page for reading.
[07.04.2025 09:13] Chinese vocab [{'word': '涵盖', 'pinyin': 'hángài', 'trans': 'cover'}, {'word': '基准', 'pinyin': 'jīzhǔn', 'trans': 'benchmark'}, {'word': '注释', 'pinyin': 'zhùshì', 'trans': 'annotate'}, {'word': '评估', 'pinyin': 'pínggū', 'trans': 'evaluate'}, {'word': '先进', 'pinyin': 'xiānjìn', 'trans': 'advanced'}, {'word': '详细', 'pinyin': 'xiángxì', 'trans': 'detailed'}, {'word': '分析', 'pinyin': 'fēnxī', 'trans': 'analysis'}, {'word': '宣布', 'pinyin': 'xuānbù', 'trans': 'announce'}, {'word': '成立', 'pinyin': 'chénglì', 'trans': 'establish'}, {'word': '开源', 'pinyin': 'kāiyuán', 'trans': 'open-source'}, {'word': '社区', 'pinyin': 'shèqū', 'trans': 'community'}, {'word': '旨在', 'pinyin': 'zhǐzài', 'trans': 'aim to'}, {'word': '构建', 'pinyin': 'gòujiàn', 'trans': 'build'}, {'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'}, {'word': '强化学习', 'pinyin': 'qiáng huà xuéxí', 'trans': 'reinforcement learning'}, {'word': '训练', 'pinyin': 'xùnliàn', 'trans': 'training'}, {'word': '数据集', 'pinyin': 'shùjùjí', 'trans': 'dataset'}]
[07.04.2025 09:13] Renaming previous Chinese page.
[07.04.2025 09:13] Renaming previous data. zh.html to ./d/2025-04-06_zh_reading_task.html
[07.04.2025 09:13] Writing Chinese reading task.
[07.04.2025 09:13] Writing result.
[07.04.2025 09:13] Renaming log file.
[07.04.2025 09:13] Renaming previous data. log.txt to ./logs/2025-04-07_last_log.txt
