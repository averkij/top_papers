[07.04.2025 13:23] Read previous papers.
[07.04.2025 13:23] Generating top page (month).
[07.04.2025 13:23] Writing top page (month).
[07.04.2025 14:11] Read previous papers.
[07.04.2025 14:11] Get feed.
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02605
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03553
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02807
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03561
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03641
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02949
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03011
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.24067
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03601
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03536
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.02402
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.03600
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.24310
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.01328
[07.04.2025 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2504.00396
[07.04.2025 14:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[07.04.2025 14:11] No deleted papers detected.
[07.04.2025 14:11] Downloading and parsing papers (pdf, html). Total: 15.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.02605.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.02605.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.02605.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03553.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03553.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03553.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.02807.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.02807.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.02807.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03561.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03561.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03561.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03641.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03641.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03641.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.02949.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.02949.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.02949.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03011.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03011.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03011.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2503.24067.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2503.24067.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2503.24067.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03601.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03601.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03601.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03536.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03536.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03536.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.02402.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.02402.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.02402.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.03600.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.03600.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.03600.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2503.24310.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2503.24310.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2503.24310.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.01328.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.01328.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.01328.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Downloading and parsing paper https://huggingface.co/papers/2504.00396.
[07.04.2025 14:11] Extra JSON file exists (./assets/json/2504.00396.json), skip PDF parsing.
[07.04.2025 14:11] Paper image links file exists (./assets/img_data/2504.00396.json), skip HTML parsing.
[07.04.2025 14:11] Success.
[07.04.2025 14:11] Enriching papers with extra data.
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 0. The task of issue resolving is to modify a codebase to generate a patch that addresses a given issue. However, existing benchmarks, such as SWE-bench, focus almost exclusively on Python, making them insufficient for evaluating Large Language Models (LLMs) across diverse software ecosystems. To addre...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 1. Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional agent planning approaches adopt a "flood irrigation" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models....
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 2. Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs). However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training. We present Mega...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 3. In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomou...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 4. Existing MLLM benchmarks face significant challenges in evaluating Unified MLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional tasks, leading to inconsistent comparisons; 2) absence of benchmarks for mixed-modality generation, which fails to assess multimodal reasoning capabil...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 5. In this work, we present VARGPT-v1.1, an advanced unified visual autoregressive model that builds upon our previous framework VARGPT. The model preserves the dual paradigm of next-token prediction for visual understanding and next-scale generation for image synthesis. Specifically, VARGPT-v1.1 integ...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 6. This paper introduces Comprehensive Relighting, the first all-in-one approach that can both control and harmonize the lighting from an image or video of humans with arbitrary body parts from any scene. Building such a generalizable model is extremely challenging due to the lack of dataset, restricti...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 7. Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable cont...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 8. Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In t...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 9. Single-image human reconstruction is vital for digital human modeling applications but remains an extremely challenging task. Current approaches rely on generative models to synthesize multi-view images for subsequent 3D reconstruction and animation. However, directly generating multiple views from ...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 10. When sound waves hit an object, they induce vibrations that produce high-frequency and subtle visual changes, which can be used for recovering the sound. Early studies always encounter trade-offs related to sampling rate, bandwidth, field of view, and the simplicity of the optical path. Recent advan...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 11. Medical image and video segmentation is a critical task for precision medicine, which has witnessed considerable progress in developing task or modality-specific and generalist models for 2D images. However, there have been limited studies on building general-purpose models for 3D images and videos ...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 12. In this research, we introduce BEATS, a novel framework for evaluating Bias, Ethics, Fairness, and Factuality in Large Language Models (LLMs). Building upon the BEATS framework, we present a bias benchmark for LLMs that measure performance across 29 distinct metrics. These metrics span a broad range...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 13. Balancing temporal resolution and spatial detail under limited compute budget remains a key challenge for video-based multi-modal large language models (MLLMs). Existing methods typically compress video representations using predefined rules before feeding them into the LLM, resulting in irreversibl...
[07.04.2025 14:11] ********************************************************************************
[07.04.2025 14:11] Abstract 14. Fine-tuning a pre-trained Text-to-Image (T2I) model on a tailored portrait dataset is the mainstream method for text-driven customization of portrait attributes. Due to Semantic Pollution during fine-tuning, existing methods struggle to maintain the original model's behavior and achieve incremental ...
[07.04.2025 14:11] Read previous papers.
[07.04.2025 14:11] Generating reviews via LLM API.
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#agi", "#benchmark", "#rl", "#open_source", "#multilingual", "#dataset"], "emoji": "🌐", "ru": {"title": "Многоязычный бенчмарк для оценки ИИ в решении программных задач", "desc": "Представлен новый многоязычный бенчмарк Multi-SWE-bench для оценки способности языковых моделей решать 
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#agents", "#agi"], "emoji": "🧠", "ru": {"title": "Самоосознанность в планировании: эффективное использование знаний языковыми моделями", "desc": "Статья представляет новый подход к обучению языковых моделей для задач планирования, называем
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#reasoning", "#synthetic", "#data"], "emoji": "🧮", "ru": {"title": "MegaMath: Большие данные для умных вычислений", "desc": "Статья представляет MegaMath - крупномасштабный открытый датасет для предобучения языковых моделей в области математики. Авторы ис
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#optimization", "#transfer_learning", "#agents", "#rl"], "emoji": "🌐", "ru": {"title": "SynWorld: Автономное исследование и обучение агентов в новых средах", "desc": "SynWorld - это фреймворк, позволяющий агентам на основе больших языковых моделей (LLM) автономно исследовать новые с
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#survey"], "emoji": "🧠", "ru": {"title": "Новый стандарт оценки мультимодальных языковых моделей", "desc": "Эта статья представляет новую систему оценки для унифицированных мультимодальных языковых моделей (U-MLLM). Авторы разработали комплексный фреймво
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#training", "#multimodal", "#rlhf", "#open_source", "#cv", "#optimization"], "emoji": "🖼️", "ru": {"title": "Единая модель для понимания, генерации и редактирования изображений", "desc": "VARGPT-v1.1 - это усовершенствованная унифицированная визуальная авторегрессионная модель, разв
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#inference", "#video", "#cv", "#diffusion"], "emoji": "💡", "ru": {"title": "Универсальное управление освещением людей на изображениях и видео", "desc": "Статья представляет Comprehensive Relighting - первый универсальный подход к контролю и гармонизации освещения людей на изображени
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#long_context"], "emoji": "🔀", "ru": {"title": "Объединение Transformer и Mamba для эффективной обработки длинных последовательностей", "desc": "TransMamba - это новая архитектура, объединяющая Transformer и Mamba через общие матрицы па
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#agents", "#open_source", "#data", "#training"], "emoji": "🤖", "ru": {"title": "Революция в обучении ИИ-агентов: синтетические данные для реалистичного многоходового взаимодействия", "desc": "APIGen-MT - это новый фреймворк для генерации качественных данных
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#synthetic", "#cv", "#3d"], "emoji": "🧑‍🦰", "ru": {"title": "Реалистичные 3D-модели людей из одного фото", "desc": "HumanDreamer-X - это новая система для реконструкции 3D-моделей человека по одному изображению. Она объединяет генерацию мультиракурсных изображений и 3D-реконструкцию
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#training", "#dataset", "#data", "#cv"], "emoji": "🔊", "ru": {"title": "Новый подход к бесконтактному восстановлению звука с помощью событийных камер", "desc": "Статья представляет новый метод бесконтактного восстановления звука с использованием событийных камер. Авторы разработали 
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#data", "#healthcare", "#3d", "#dataset", "#training", "#cv"], "emoji": "🩻", "ru": {"title": "MedSAM2: Революция в сегментации медицинских 3D-изображений и видео", "desc": "MedSAM2 - это модель сегментации медицинских 3D-изображений и видео, основанная на fine-tuning Segment Anythin
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#ethics"], "emoji": "⚖️", "ru": {"title": "BEATS: комплексная оценка этичности языковых моделей", "desc": "Исследователи представили BEATS - новую систему оценки предвзятости, этики, справедливости и фактической точности в больших языковых моделях (LLM). На
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#multimodal", "#video", "#architecture"], "emoji": "🎬", "ru": {"title": "Эффективное понимание видео с помощью slow-fast архитектуры для MLLM", "desc": "Статья представляет новую архитектуру slow-fast для видео-ориентированных мультимодальных больших я
[07.04.2025 14:11] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#training", "#dataset"], "emoji": "🖼️", "ru": {"title": "Точная настройка генерации портретов без семантического загрязнения", "desc": "Статья представляет новый метод SPF-Portrait для настройки моделей генерации изображений по тексту для создания портретов. Ав
[07.04.2025 14:11] Loading Chinese text from previous data.
[07.04.2025 14:11] Renaming data file.
[07.04.2025 14:11] Renaming previous data. hf_papers.json to ./d/2025-04-07.json
[07.04.2025 14:11] Saving new data file.
[07.04.2025 14:11] Generating page.
[07.04.2025 14:11] Renaming previous page.
[07.04.2025 14:11] Renaming previous data. index.html to ./d/2025-04-07.html
[07.04.2025 14:11] [Experimental] Generating Chinese page for reading.
[07.04.2025 14:11] Chinese vocab [{'word': '涵盖', 'pinyin': 'hángài', 'trans': 'cover'}, {'word': '基准', 'pinyin': 'jīzhǔn', 'trans': 'benchmark'}, {'word': '注释', 'pinyin': 'zhùshì', 'trans': 'annotate'}, {'word': '评估', 'pinyin': 'pínggū', 'trans': 'evaluate'}, {'word': '先进', 'pinyin': 'xiānjìn', 'trans': 'advanced'}, {'word': '详细', 'pinyin': 'xiángxì', 'trans': 'detailed'}, {'word': '分析', 'pinyin': 'fēnxī', 'trans': 'analysis'}, {'word': '宣布', 'pinyin': 'xuānbù', 'trans': 'announce'}, {'word': '成立', 'pinyin': 'chénglì', 'trans': 'establish'}, {'word': '开源', 'pinyin': 'kāiyuán', 'trans': 'open-source'}, {'word': '社区', 'pinyin': 'shèqū', 'trans': 'community'}, {'word': '旨在', 'pinyin': 'zhǐzài', 'trans': 'aim to'}, {'word': '构建', 'pinyin': 'gòujiàn', 'trans': 'build'}, {'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'}, {'word': '强化学习', 'pinyin': 'qiáng huà xuéxí', 'trans': 'reinforcement learning'}, {'word': '训练', 'pinyin': 'xùnliàn', 'trans': 'training'}, {'word': '数据集', 'pinyin': 'shùjùjí', 'trans': 'dataset'}]
[07.04.2025 14:11] Renaming previous Chinese page.
[07.04.2025 14:11] Renaming previous data. zh.html to ./d/2025-04-06_zh_reading_task.html
[07.04.2025 14:11] Writing Chinese reading task.
[07.04.2025 14:11] Writing result.
[07.04.2025 14:11] Renaming log file.
[07.04.2025 14:11] Renaming previous data. log.txt to ./logs/2025-04-07_last_log.txt
