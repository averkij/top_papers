[20.08.2025 12:22] Read previous papers.
[20.08.2025 12:22] Generating top page (month).
[20.08.2025 12:22] Writing top page (month).
[20.08.2025 13:25] Read previous papers.
[20.08.2025 13:25] Get feed.
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13167
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14041
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13948
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06905
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08777
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12040
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09131
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13998
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13632
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12903
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10830
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11548
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04324
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12669
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13139
[20.08.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2508.12845
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12535
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11032
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10478
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09789
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04326
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13992
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13186
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04038
[20.08.2025 13:25] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13804
[20.08.2025 13:25] Extract page data from URL. URL: https://huggingface.co/papers/2508.12800
[20.08.2025 13:25] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.08.2025 13:25] No deleted papers detected.
[20.08.2025 13:25] Downloading and parsing papers (pdf, html). Total: 26.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13167.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13167.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13167.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.14041.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.14041.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.14041.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13948.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13948.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13948.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.06905.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.06905.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.06905.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.08777.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.08777.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.08777.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.12040.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.12040.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.12040.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.09131.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.09131.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.09131.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13998.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13998.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13998.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13632.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13632.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13632.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.12903.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.12903.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.12903.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.10830.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.10830.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.10830.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.11548.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.11548.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.11548.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.04324.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.04324.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.04324.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.12669.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.12669.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.12669.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13139.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13139.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13139.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.12845.
[20.08.2025 13:25] Downloading paper 2508.12845 from http://arxiv.org/pdf/2508.12845v1...
[20.08.2025 13:25] Extracting affiliations from text.
[20.08.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"CAMAR: Continuous Actions Multi-Agent Routing Artem Pshenitsyn1,2, Aleksandr Panov1,2, Alexey Skrynnik1,2 1 AIRI, Moscow, Russia 2 MIPT, Moscow, Russia {pshenitsyn, panov, skrynnik}@airi.net 5 2 0 2 8 1 ] . [ 1 5 4 8 2 1 . 8 0 5 2 : r Abstract Multi-agent reinforcement learning (MARL) is powerful paradigm for solving cooperative and competitive decisionmaking problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents challenging and realistic testbed for the MARL community. Code https://github.com/AIRI-Institute/CAMAR.git Introduction Multi-agent reinforcement learning (MARL) has shown strong results in cooperative and competitive settings. Many recent studies explore how MARL can solve various tasks, including navigation and coordination, even in complex environments [1, 2, 3, 4, 5, 6]. However, current MARL benchmarks do not fully match the needs of real-world applications such as robotics. Among the many MARL scenarios, navigation and path planning are especially important for robotic systems. Yet, most existing benchmarks simplify navigation into grid worlds and discrete actions that fail to capture the smooth motion and c"
[20.08.2025 13:25] Response: ```python
["AIRI, Moscow, Russia", "MIPT, Moscow, Russia"]
```
[20.08.2025 13:25] Deleting PDF ./assets/pdf/2508.12845.pdf.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.12535.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.12535.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.12535.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.11032.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.11032.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.11032.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.10478.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.10478.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.10478.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.09789.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.09789.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.09789.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.04326.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.04326.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.04326.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13992.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13992.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13992.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13186.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13186.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13186.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.04038.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.04038.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.04038.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.13804.
[20.08.2025 13:25] Extra JSON file exists (./assets/json/2508.13804.json), skip PDF parsing.
[20.08.2025 13:25] Paper image links file exists (./assets/img_data/2508.13804.json), skip HTML parsing.
[20.08.2025 13:25] Success.
[20.08.2025 13:25] Downloading and parsing paper https://huggingface.co/papers/2508.12800.
[20.08.2025 13:25] Downloading paper 2508.12800 from http://arxiv.org/pdf/2508.12800v2...
[20.08.2025 13:26] Extracting affiliations from text.
[20.08.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward Yong Deng, Guoqing Wang, Zhenzhe Ying, Xiaofeng Wu, Jinzhen Lin, Wenwen Xiong, Yuqin Dai, Shuo Yang, Zhanwei Zhang, Qiwen Wang, Yang Qin, Changhua Meng Ant Group Core Contributors Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns. Code: https://github.com/antgroup/Research-Venus 5 2 0 2 9 ] . [ 2 0 0 8 2 1 . 8 0 5 2 : r Figure 1 Atom-Searcher achieves SOTA performance on both in-domain and out-of-domain be"
[20.08.2025 13:26] Response: ```python
["Ant Group"]
```
[20.08.2025 13:26] Deleting PDF ./assets/pdf/2508.12800.pdf.
[20.08.2025 13:26] Success.
[20.08.2025 13:26] Enriching papers with extra data.
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 0. Chain-of-Agents (CoA) paradigm enables end-to-end complex problem-solving in LLMs through dynamic agent activation, improving performance via multi-agent distillation and agentic reinforcement learning.  					AI-generated summary 				 Recent advances in large language models (LLMs) and multi-agent s...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 1. LongSplat improves novel view synthesis from long videos with irregular motion through joint optimization, robust pose estimation, and efficient anchor formation.  					AI-generated summary 				 LongSplat addresses critical challenges in novel view synthesis (NVS) from casually captured long videos ...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 2. POML addresses challenges in prompting Large Language Models by providing a structured, data-integrated, and format-sensitive markup language with templating and developer tools.  					AI-generated summary 				 Large Language Models (LLMs) require sophisticated prompting, yet current practices face ...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 3. Experiments with multiple image-text models and agentic frameworks show that even state-of-the-art systems struggle with generating images from multiple visual references, highlighting the need for more flexible creative tools.  					AI-generated summary 				 Visual designers naturally draw inspirat...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 4. A novel framework uses Large Language Models to evaluate podcast recommendations by constructing user profiles and providing context for the LLM to make judgments, improving efficiency and interpretability.  					AI-generated summary 				 Evaluating personalized recommendations remains a central cha...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 5. FineCE is a novel confidence estimation method for large language models that provides accurate, fine-grained confidence scores during text generation, outperforming existing methods.  					AI-generated summary 				 While large language models (LLMs) have demonstrated remarkable performance across d...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 6. ColorCtrl, a training-free method using Multi-Modal Diffusion Transformers, achieves precise and consistent color editing in images and videos with word-level control and superior performance compared to existing approaches.  					AI-generated summary 				 Text-guided color editing in images and vid...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 7. A pointing-centric representation and reinforced fine-tuning approach improve embodied AI generalization across various tasks and visual disturbances.  					AI-generated summary 				 Generalization in embodied AI is hindered by the "seeing-to-doing gap," which stems from data scarcity and embodiment...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 8. OmniTry extends Virtual Try-ON to various wearable objects using a two-stage pipeline that combines unpaired and paired image training to improve object localization and appearance consistency.  					AI-generated summary 				 Virtual Try-ON (VTON) is a practical and widely-applied task, for which mo...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 9. ProActive Self-Refinement (PASR) dynamically enhances LLM outputs during generation, reducing token consumption and improving accuracy.  					AI-generated summary 				 Recent advances in self-refinement have demonstrated significant potential for improving the outputs of large language models (LLMs)...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 10. A survey of DNN-based speech separation techniques, covering learning paradigms, separation scenarios, and architectural components, with a focus on current advancements and promising future directions.  					AI-generated summary 				 The field of speech separation, addressing the "cocktail party pr...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 11. A survey of LLM copyright protection technologies, focusing on model fingerprinting, clarifies its relationship with text watermarking and provides a comprehensive overview of fingerprinting techniques, evaluation metrics, and open challenges.  					AI-generated summary 				 Copyright protection for...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 12. TempFlow-GRPO enhances text-to-image generation by addressing temporal credit assignment and noise-aware optimization in flow models, improving human preference alignment and benchmark performance.  					AI-generated summary 				 Recent flow matching models for text-to-image generation have achieved...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 13. LLMs predict misery scores from text using various prompting strategies, with few-shot approaches outperforming zero-shot, and a gamified framework assessing their adaptability in emotional reasoning tasks.  					AI-generated summary 				 This study investigates the use of Large Language Models (LLM...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 14. Motion2Motion is a training-free framework that efficiently transfers animations between characters with different skeletal topologies using sparse bone correspondences.  					AI-generated summary 				 This work studies the challenge of transfer animations between characters whose skeletal topologie...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 15. CAMAR is a new MARL benchmark for continuous action pathfinding that supports efficient evaluation and hybrid approaches with classical planning methods.  					AI-generated summary 				 Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 16. CorrSteer improves language model performance by selecting relevant features through correlation with SAE activations at inference time, enhancing tasks like QA, bias mitigation, and reasoning.  					AI-generated summary 				 Sparse Autoencoders (SAEs) can extract interpretable features from large l...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 17. MedSAMix, a training-free model merging method, combines generalist and specialist models to improve medical image segmentation performance across diverse tasks.  					AI-generated summary 				 Universal medical image segmentation models have emerged as a promising paradigm due to their strong gener...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 18. A bi-encoder model fine-tuned on both search and recommendation tasks provides effective Semantic IDs for a unified generative recommender system.  					AI-generated summary 				 Generative models powered by Large Language Models (LLMs) are emerging as a unified solution for powering both recommenda...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 19. A zero-finetuning framework uses Multimodal Large Language Models to inject high-level semantics into video recommendations, improving intent-awareness over traditional methods.  					AI-generated summary 				 Existing video recommender systems rely primarily on user-defined metadata or on low-level...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 20. A systematic survey of radiance fields in XR applications identifies implementation details, research gaps, and future directions within the broader RF research field.  					AI-generated summary 				 The development of radiance fields (RF), such as 3D Gaussian Splatting (3DGS) and Neural Radiance Fi...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 21. MMAU-Pro is a comprehensive benchmark for evaluating audio intelligence in AI systems, assessing 49 unique skills across speech, sound, music, and their combinations, revealing significant limitations in current models.  					AI-generated summary 				 Audio comprehension-including speech, non-speech...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 22. A new benchmark, MM-BrowseComp, evaluates AI agents' multimodal retrieval and reasoning capabilities, revealing limitations in current models' handling of images and videos in web browsing tasks.  					AI-generated summary 				 AI agents with advanced reasoning and tool use capabilities have demonst...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 23. ZARA is an agent-based framework for zero-shot, explainable human activity recognition from raw motion time-series, achieving state-of-the-art performance without fine-tuning.  					AI-generated summary 				 Motion sensor time-series are central to human activity recognition (HAR), with applications...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 24. A Bayesian evaluation framework assesses large language models' moral understanding by modeling human annotator disagreements, showing AI models perform well with fewer false negatives.  					AI-generated summary 				 How do large language models understand moral dimensions compared to humans?   Thi...
[20.08.2025 13:26] ********************************************************************************
[20.08.2025 13:26] Abstract 25. Atom-Searcher, an RL framework integrating Atomic Thought and Reasoning Reward Models, enhances LLMs' multi-hop reasoning and strategic search capabilities, improving performance and interpretability.  					AI-generated summary 				 Large language models (LLMs) exhibit remarkable problem-solving abi...
[20.08.2025 13:26] Read previous papers.
[20.08.2025 13:26] Generating reviews via LLM API.
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#agi", "#architecture", "#open_source", "#rl", "#agents", "#training", "#rlhf"], "emoji": "🤖", "ru": {"title": "Chain-of-Agents: Новый подход к решению сложных задач в языковых моделях", "desc": "Статья представляет новую парадигму рассуждений для больших
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#cv", "#architecture", "#3d"], "emoji": "🎥", "ru": {"title": "Улучшение синтеза новых ракурсов для длинных видео с помощью LongSplat", "desc": "LongSplat - это новый метод синтеза новых ракурсов из длинных видео с нерегулярным движением камеры. Он испо
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#data", "#multimodal"], "emoji": "🗂️", "ru": {"title": "POML: структурированный подход к промптингу языковых моделей", "desc": "Статья представляет POML - язык разметки для структурированного промптинга больших языковых моделей. POML решает проблемы интеграции данных, чувствительнос
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#synthetic", "#cv", "#dataset", "#benchmark"], "emoji": "🎨", "ru": {"title": "Генеративные модели нуждаются в улучшении работы с множественными визуальными ссылками", "desc": "Исследование показывает, что современные системы генерации изображений испыт
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#multimodal", "#interpretability", "#training", "#audio", "#alignment"], "emoji": "🎧", "ru": {"title": "LLM как эксперт по рекомендациям подкастов", "desc": "Предложена новая система оценки рекомендаций подкастов с использованием больших языковых моделей (LLM). Система создает профи
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#data", "#optimization", "#training", "#hallucinations", "#inference"], "emoji": "🎯", "ru": {"title": "Точная оценка уверенности для больших языковых моделей", "desc": "FineCE - это новый метод оценки уверенности для больших языковых моделей, котор
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#diffusion", "#video", "#cv", "#multimodal"], "emoji": "🎨", "ru": {"title": "Точное редактирование цвета без обучения с помощью диффузионных трансформеров", "desc": "ColorCtrl - это метод редактирования цвета в изображениях и видео без дополнительного обучения, использующий мультимо
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#training", "#agents", "#dataset", "#optimization", "#reasoning", "#robotics", "#agi"], "emoji": "🤖", "ru": {"title": "Указательное представление открывает путь к универсальному воплощенному ИИ", "desc": "Статья представляет новый подход к улучшению обобщения в воплощенном ИИ с испо
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#data", "#benchmark", "#cv", "#open_source", "#dataset", "#training"], "emoji": "🕶️", "ru": {"title": "Виртуальная примерка любых носимых объектов без масок", "desc": "OmniTry - это унифицированная система, расширяющая возможности виртуальной примерки (VTON) на разл
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#training", "#optimization"], "emoji": "🔄", "ru": {"title": "Динамическое самосовершенствование LLM в реальном времени", "desc": "Статья представляет новый метод ProActive Self-Refinement (PASR) для улучшения выходных данных больших языковых моделей (LLM). PASR позволяет LLM динамич
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#benchmark", "#survey", "#multimodal", "#audio"], "emoji": "🎙️", "ru": {"title": "Комплексный анализ DNN-методов разделения речи: от основ до инноваций", "desc": "Это обзор методов разделения речи на основе глубоких нейронных сетей (DNN). В статье рассматриваются парадигмы обучения,
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#multimodal", "#ethics", "#data", "#dataset", "#benchmark", "#survey"], "emoji": "🔐", "ru": {"title": "Защита интеллектуальной собственности в эпоху больших языковых моделей", "desc": "Статья представляет собой обзор технологий защиты авторских прав для больших языковых моделей (LLM
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#cv", "#benchmark", "#alignment", "#optimization"], "emoji": "🖼️", "ru": {"title": "Темпоральная оптимизация для улучшения генерации изображений", "desc": "Статья представляет TempFlow-GRPO - новый метод для улучшения генерации изображений по текстовому описанию. Дан
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#data", "#multimodal", "#reasoning", "#games", "#training"], "emoji": "😢", "ru": {"title": "LLM как эмпаты: оценка способности AI понимать человеческие страдания", "desc": "Это исследование оценивает способность больших языковых моделей (LLM) предсказывать уровень несчастья человека
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#dataset", "#3d", "#transfer_learning"], "emoji": "🦴", "ru": {"title": "Универсальный перенос анимации без обучения", "desc": "Motion2Motion - это система для переноса анимации между персонажами с разной скелетной топологией, не требующая обучения. Она использует разреженные соответ
[20.08.2025 13:26] Querying the API.
[20.08.2025 13:26] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CAMAR is a new MARL benchmark for continuous action pathfinding that supports efficient evaluation and hybrid approaches with classical planning methods.  					AI-generated summary 				 Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community.
[20.08.2025 13:26] Response: {
  "desc": "CAMAR - это новый бенчмарк для мультиагентного обучения с подкреплением (MARL) в задачах непрерывного поиска пути. Он поддерживает эффективную оценку и гибридные подходы с классическими методами планирования. CAMAR обеспечивает кооперативные и конкурентные взаимодействия между агентами в непрерывных пространствах состояний и действий. Бенчмарк включает набор тестовых сценариев и инструментов для обеспечения воспроизводимости и корректного сравнения алгоритмов.",
  "emoji": "🗺️",
  "title": "CAMAR: Новый рубеж в мультиагентном обучении для непрерывного поиска пути"
}
[20.08.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CAMAR is a new MARL benchmark for continuous action pathfinding that supports efficient evaluation and hybrid approaches with classical planning methods.  					AI-generated summary 				 Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community."

[20.08.2025 13:26] Response: ```python
['BENCHMARK', 'RL']
```
[20.08.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CAMAR is a new MARL benchmark for continuous action pathfinding that supports efficient evaluation and hybrid approaches with classical planning methods.  					AI-generated summary 				 Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community."

[20.08.2025 13:26] Response: ```python
["GAMES", "OPTIMIZATION"]
```
[20.08.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CAMAR is a new benchmark for multi-agent reinforcement learning (MARL) that focuses on continuous action pathfinding. It allows agents to work together or compete in environments where they must navigate using continuous actions. The benchmark runs efficiently, supporting up to 100,000 environment steps per second, and includes a three-tier evaluation protocol for tracking progress. Additionally, CAMAR integrates classical planning methods like RRT and RRT* with MARL, providing a comprehensive suite of scenarios for testing and comparison.","title":"CAMAR: Advancing Multi-Agent Pathfinding with Continuous Actions"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CAMAR is a new benchmark for multi-agent reinforcement learning (MARL) that focuses on continuous action pathfinding. It allows agents to work together or compete in environments where they must navigate using continuous actions. The benchmark runs efficiently, supporting up to 100,000 environment steps per second, and includes a three-tier evaluation protocol for tracking progress. Additionally, CAMAR integrates classical planning methods like RRT and RRT* with MARL, providing a comprehensive suite of scenarios for testing and comparison.', title='CAMAR: Advancing Multi-Agent Pathfinding with Continuous Actions'))
[20.08.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CAMAR是一个新的多智能体强化学习（MARL）基准，专注于连续动作的路径规划。它支持智能体之间的合作与竞争，并且能够高效运行，每秒可处理多达100,000个环境步骤。该基准引入了三层评估协议，以便更好地跟踪算法进展并深入分析性能。此外，CAMAR还允许将经典规划方法（如RRT和RRT*）与MARL管道结合，提供了测试场景和基准工具，以确保可重复性和公平比较。","title":"CAMAR：多智能体路径规划的新基准"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CAMAR是一个新的多智能体强化学习（MARL）基准，专注于连续动作的路径规划。它支持智能体之间的合作与竞争，并且能够高效运行，每秒可处理多达100,000个环境步骤。该基准引入了三层评估协议，以便更好地跟踪算法进展并深入分析性能。此外，CAMAR还允许将经典规划方法（如RRT和RRT*）与MARL管道结合，提供了测试场景和基准工具，以确保可重复性和公平比较。', title='CAMAR：多智能体路径规划的新基准'))
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#ethics", "#data", "#interpretability", "#training", "#benchmark", "#architecture", "#reasoning", "#optimization"], "emoji": "🧠", "ru": {"title": "CorrSteer: Автоматическое улучшение ИИ через корреляционный анализ", "desc": "CorrSteer - это новый метод улучшения работы языковых моде
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#training", "#optimization", "#healthcare", "#games", "#cv"], "emoji": "🩺", "ru": {"title": "MedSAMix: Умное объединение моделей для универсальной сегментации медицинских изображений", "desc": "MedSAMix - это метод объединения моделей без дополнительного обучения, который сочетает у
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#data", "#training", "#architecture", "#transfer_learning", "#optimization"], "emoji": "🔍", "ru": {"title": "Единые семантические ID для поиска и рекомендаций", "desc": "Статья исследует эффективные способы создания семантических идентификаторов для единой генеративной рекомендатель
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#multimodal", "#games", "#video", "#dataset", "#optimization"], "emoji": "🎥", "ru": {"title": "MLLM для интеллектуальных видеорекомендаций без дообучения", "desc": "В статье представлен новый подход к рекомендательным системам для видео, использующий мультимодальные языковые модели 
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#multimodal", "#3d", "#robotics", "#survey", "#cv"], "emoji": "🔍", "ru": {"title": "Радиационные поля в XR: от визии к реальности", "desc": "Это систематический обзор применения радиационных полей (RF) в приложениях расширенной реальности (XR). Исследование анализирует 365 работ, св
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#audio", "#multimodal", "#benchmark", "#reasoning", "#agi", "#open_source"], "emoji": "🎧", "ru": {"title": "MMAU-Pro: новый стандарт оценки аудиоинтеллекта ИИ", "desc": "MMAU-Pro - это комплексный бенчмарк для оценки аудиоинтеллекта в системах искусственного интеллекта. Он оценивает
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#benchmark", "#multimodal"], "emoji": "🔍", "ru": {"title": "Мультимодальный вызов для ИИ: новый рубеж в веб-навигации", "desc": "MM-BrowseComp - это новый бенчмарк для оценки способностей ИИ-агентов в мультимодальном поиске и рассуждениях. Он состоит из 224 
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#interpretability", "#reasoning", "#healthcare"], "emoji": "🏃", "ru": {"title": "ZARA: Универсальное распознавание активности без обучения", "desc": "ZARA - это агентная система для распознавания человеческой активности по временным рядам движения без предв
[20.08.2025 13:26] Using data from previous issue: {"categories": ["#data", "#benchmark", "#ethics", "#alignment"], "emoji": "🧠", "ru": {"title": "ИИ превосходит людей в моральной оценке текстов", "desc": "Исследование представляет Байесовский подход к оценке понимания моральных аспектов крупными языковыми моделями. В отличие от предыдущих работ, ис
[20.08.2025 13:26] Querying the API.
[20.08.2025 13:26] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Atom-Searcher, an RL framework integrating Atomic Thought and Reasoning Reward Models, enhances LLMs' multi-hop reasoning and strategic search capabilities, improving performance and interpretability.  					AI-generated summary 				 Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns.
[20.08.2025 13:26] Response: {
  "desc": "Atom-Searcher - это новая система обучения с подкреплением для улучшения рассуждений и стратегического поиска у больших языковых моделей. Она использует концепцию 'атомарной мысли', разбивая процесс рассуждения на мелкие функциональные единицы. Система применяет модели вознаграждения за рассуждения для точного руководства этими единицами. Atom-Searcher показывает улучшенную производительность и интерпретируемость по сравнению с современными методами на семи эталонных задачах.",
  "emoji": "🧠",
  "title": "Атомарное мышление для эффективных ИИ-рассуждений"
}
[20.08.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Atom-Searcher, an RL framework integrating Atomic Thought and Reasoning Reward Models, enhances LLMs' multi-hop reasoning and strategic search capabilities, improving performance and interpretability.  					AI-generated summary 				 Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns."

[20.08.2025 13:26] Response: ```python
['RL', 'RAG', 'AGENTS', 'TRAINING', 'BENCHMARK']
```
[20.08.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Atom-Searcher, an RL framework integrating Atomic Thought and Reasoning Reward Models, enhances LLMs' multi-hop reasoning and strategic search capabilities, improving performance and interpretability.  					AI-generated summary 				 Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns."

[20.08.2025 13:26] Response: ```python
['REASONING', 'INTERPRETABILITY', 'OPTIMIZATION']
```
[20.08.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Atom-Searcher is a reinforcement learning framework designed to enhance the multi-hop reasoning and strategic search capabilities of large language models (LLMs). It introduces a new thinking paradigm called Atomic Thought, which breaks down reasoning into smaller, manageable units that are guided by Reasoning Reward Models (RRMs). This approach addresses issues like conflicting gradients and reward sparsity in traditional RL methods by using a curriculum-inspired reward schedule that focuses on process-level rewards before shifting to outcome rewards. Experiments demonstrate that Atom-Searcher significantly improves performance and interpretability in complex reasoning tasks compared to existing methods.","title":"Empowering LLMs with Atomic Thought for Enhanced Reasoning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Atom-Searcher is a reinforcement learning framework designed to enhance the multi-hop reasoning and strategic search capabilities of large language models (LLMs). It introduces a new thinking paradigm called Atomic Thought, which breaks down reasoning into smaller, manageable units that are guided by Reasoning Reward Models (RRMs). This approach addresses issues like conflicting gradients and reward sparsity in traditional RL methods by using a curriculum-inspired reward schedule that focuses on process-level rewards before shifting to outcome rewards. Experiments demonstrate that Atom-Searcher significantly improves performance and interpretability in complex reasoning tasks compared to existing methods.', title='Empowering LLMs with Atomic Thought for Enhanced Reasoning'))
[20.08.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Atom-Searcher 是一个强化学习框架，结合了原子思维和推理奖励模型，提升了大型语言模型（LLMs）在多跳推理和战略搜索方面的能力。该框架通过将推理分解为细粒度的功能单元，利用推理奖励模型提供的奖励进行指导，从而改善了模型的表现和可解释性。Atom-Searcher 采用课程激励的奖励调度，早期注重过程级奖励，后期转向结果奖励，加速了有效推理路径的收敛。实验结果表明，Atom-Searcher 在七个基准测试中均表现出优于现有技术的持续改进。","title":"Atom-Searcher：提升推理与搜索能力的强化学习框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Atom-Searcher 是一个强化学习框架，结合了原子思维和推理奖励模型，提升了大型语言模型（LLMs）在多跳推理和战略搜索方面的能力。该框架通过将推理分解为细粒度的功能单元，利用推理奖励模型提供的奖励进行指导，从而改善了模型的表现和可解释性。Atom-Searcher 采用课程激励的奖励调度，早期注重过程级奖励，后期转向结果奖励，加速了有效推理路径的收敛。实验结果表明，Atom-Searcher 在七个基准测试中均表现出优于现有技术的持续改进。', title='Atom-Searcher：提升推理与搜索能力的强化学习框架'))
[20.08.2025 13:26] Renaming data file.
[20.08.2025 13:26] Renaming previous data. hf_papers.json to ./d/2025-08-20.json
[20.08.2025 13:26] Saving new data file.
[20.08.2025 13:26] Generating page.
[20.08.2025 13:26] Renaming previous page.
[20.08.2025 13:26] Renaming previous data. index.html to ./d/2025-08-20.html
[20.08.2025 13:26] Writing result.
[20.08.2025 13:26] Renaming log file.
[20.08.2025 13:26] Renaming previous data. log.txt to ./logs/2025-08-20_last_log.txt
