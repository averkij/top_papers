[20.08.2025 18:16] Read previous papers.
[20.08.2025 18:16] Generating top page (month).
[20.08.2025 18:16] Writing top page (month).
[20.08.2025 19:09] Read previous papers.
[20.08.2025 19:09] Get feed.
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13167
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14041
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13948
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06905
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08777
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13998
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12040
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09131
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13632
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12903
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10830
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12669
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04324
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12845
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11548
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09789
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13992
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13186
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13139
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12535
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11032
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10478
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04326
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13320
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04038
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13804
[20.08.2025 19:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12800
[20.08.2025 19:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.08.2025 19:09] No deleted papers detected.
[20.08.2025 19:09] Downloading and parsing papers (pdf, html). Total: 27.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13167.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13167.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13167.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.14041.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.14041.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.14041.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13948.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13948.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13948.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.06905.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.06905.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.06905.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.08777.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.08777.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.08777.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13998.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13998.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13998.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.12040.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.12040.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.12040.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.09131.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.09131.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.09131.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13632.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13632.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13632.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.12903.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.12903.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.12903.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.10830.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.10830.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.10830.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.12669.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.12669.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.12669.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.04324.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.04324.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.04324.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.12845.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.12845.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.12845.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.11548.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.11548.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.11548.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.09789.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.09789.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.09789.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13992.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13992.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13992.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13186.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13186.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13186.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13139.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13139.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13139.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.12535.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.12535.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.12535.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.11032.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.11032.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.11032.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.10478.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.10478.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.10478.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.04326.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.04326.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.04326.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13320.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13320.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13320.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.04038.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.04038.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.04038.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.13804.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.13804.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.13804.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Downloading and parsing paper https://huggingface.co/papers/2508.12800.
[20.08.2025 19:09] Extra JSON file exists (./assets/json/2508.12800.json), skip PDF parsing.
[20.08.2025 19:09] Paper image links file exists (./assets/img_data/2508.12800.json), skip HTML parsing.
[20.08.2025 19:09] Success.
[20.08.2025 19:09] Enriching papers with extra data.
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 0. Chain-of-Agents (CoA) paradigm enables end-to-end complex problem-solving in LLMs through dynamic agent activation, improving performance via multi-agent distillation and agentic reinforcement learning.  					AI-generated summary 				 Recent advances in large language models (LLMs) and multi-agent s...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 1. LongSplat improves novel view synthesis from long videos with irregular motion through joint optimization, robust pose estimation, and efficient anchor formation.  					AI-generated summary 				 LongSplat addresses critical challenges in novel view synthesis (NVS) from casually captured long videos ...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 2. POML addresses challenges in prompting Large Language Models by providing a structured, data-integrated, and format-sensitive markup language with templating and developer tools.  					AI-generated summary 				 Large Language Models (LLMs) require sophisticated prompting, yet current practices face ...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 3. Experiments with multiple image-text models and agentic frameworks show that even state-of-the-art systems struggle with generating images from multiple visual references, highlighting the need for more flexible creative tools.  					AI-generated summary 				 Visual designers naturally draw inspirat...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 4. A novel framework uses Large Language Models to evaluate podcast recommendations by constructing user profiles and providing context for the LLM to make judgments, improving efficiency and interpretability.  					AI-generated summary 				 Evaluating personalized recommendations remains a central cha...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 5. A pointing-centric representation and reinforced fine-tuning approach improve embodied AI generalization across various tasks and visual disturbances.  					AI-generated summary 				 Generalization in embodied AI is hindered by the "seeing-to-doing gap," which stems from data scarcity and embodiment...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 6. FineCE is a novel confidence estimation method for large language models that provides accurate, fine-grained confidence scores during text generation, outperforming existing methods.  					AI-generated summary 				 While large language models (LLMs) have demonstrated remarkable performance across d...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 7. ColorCtrl, a training-free method using Multi-Modal Diffusion Transformers, achieves precise and consistent color editing in images and videos with word-level control and superior performance compared to existing approaches.  					AI-generated summary 				 Text-guided color editing in images and vid...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 8. OmniTry extends Virtual Try-ON to various wearable objects using a two-stage pipeline that combines unpaired and paired image training to improve object localization and appearance consistency.  					AI-generated summary 				 Virtual Try-ON (VTON) is a practical and widely-applied task, for which mo...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 9. ProActive Self-Refinement (PASR) dynamically enhances LLM outputs during generation, reducing token consumption and improving accuracy.  					AI-generated summary 				 Recent advances in self-refinement have demonstrated significant potential for improving the outputs of large language models (LLMs)...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 10. A survey of DNN-based speech separation techniques, covering learning paradigms, separation scenarios, and architectural components, with a focus on current advancements and promising future directions.  					AI-generated summary 				 The field of speech separation, addressing the "cocktail party pr...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 11. LLMs predict misery scores from text using various prompting strategies, with few-shot approaches outperforming zero-shot, and a gamified framework assessing their adaptability in emotional reasoning tasks.  					AI-generated summary 				 This study investigates the use of Large Language Models (LLM...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 12. TempFlow-GRPO enhances text-to-image generation by addressing temporal credit assignment and noise-aware optimization in flow models, improving human preference alignment and benchmark performance.  					AI-generated summary 				 Recent flow matching models for text-to-image generation have achieved...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 13. CAMAR is a new MARL benchmark for continuous action pathfinding that supports efficient evaluation and hybrid approaches with classical planning methods.  					AI-generated summary 				 Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 14. A survey of LLM copyright protection technologies, focusing on model fingerprinting, clarifies its relationship with text watermarking and provides a comprehensive overview of fingerprinting techniques, evaluation metrics, and open challenges.  					AI-generated summary 				 Copyright protection for...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 15. A zero-finetuning framework uses Multimodal Large Language Models to inject high-level semantics into video recommendations, improving intent-awareness over traditional methods.  					AI-generated summary 				 Existing video recommender systems rely primarily on user-defined metadata or on low-level...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 16. MMAU-Pro is a comprehensive benchmark for evaluating audio intelligence in AI systems, assessing 49 unique skills across speech, sound, music, and their combinations, revealing significant limitations in current models.  					AI-generated summary 				 Audio comprehension-including speech, non-speech...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 17. A new benchmark, MM-BrowseComp, evaluates AI agents' multimodal retrieval and reasoning capabilities, revealing limitations in current models' handling of images and videos in web browsing tasks.  					AI-generated summary 				 AI agents with advanced reasoning and tool use capabilities have demonst...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 18. Motion2Motion is a training-free framework that efficiently transfers animations between characters with different skeletal topologies using sparse bone correspondences.  					AI-generated summary 				 This work studies the challenge of transfer animations between characters whose skeletal topologie...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 19. CorrSteer improves language model performance by selecting relevant features through correlation with SAE activations at inference time, enhancing tasks like QA, bias mitigation, and reasoning.  					AI-generated summary 				 Sparse Autoencoders (SAEs) can extract interpretable features from large l...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 20. MedSAMix, a training-free model merging method, combines generalist and specialist models to improve medical image segmentation performance across diverse tasks.  					AI-generated summary 				 Universal medical image segmentation models have emerged as a promising paradigm due to their strong gener...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 21. A bi-encoder model fine-tuned on both search and recommendation tasks provides effective Semantic IDs for a unified generative recommender system.  					AI-generated summary 				 Generative models powered by Large Language Models (LLMs) are emerging as a unified solution for powering both recommenda...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 22. A systematic survey of radiance fields in XR applications identifies implementation details, research gaps, and future directions within the broader RF research field.  					AI-generated summary 				 The development of radiance fields (RF), such as 3D Gaussian Splatting (3DGS) and Neural Radiance Fi...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 23. A self-attentive prototypical network improves few-shot adaptation for detecting synthesized speech under distribution shifts, achieving significant performance gains over zero-shot detectors.  					AI-generated summary 				 We address the challenge of detecting synthesized speech under distribution...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 24. ZARA is an agent-based framework for zero-shot, explainable human activity recognition from raw motion time-series, achieving state-of-the-art performance without fine-tuning.  					AI-generated summary 				 Motion sensor time-series are central to human activity recognition (HAR), with applications...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 25. A Bayesian evaluation framework assesses large language models' moral understanding by modeling human annotator disagreements, showing AI models perform well with fewer false negatives.  					AI-generated summary 				 How do large language models understand moral dimensions compared to humans?   Thi...
[20.08.2025 19:09] ********************************************************************************
[20.08.2025 19:09] Abstract 26. Atom-Searcher, an RL framework integrating Atomic Thought and Reasoning Reward Models, enhances LLMs' multi-hop reasoning and strategic search capabilities, improving performance and interpretability.  					AI-generated summary 				 Large language models (LLMs) exhibit remarkable problem-solving abi...
[20.08.2025 19:09] Read previous papers.
[20.08.2025 19:09] Generating reviews via LLM API.
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#agi", "#architecture", "#open_source", "#rl", "#agents", "#training", "#rlhf"], "emoji": "ü§ñ", "ru": {"title": "Chain-of-Agents: –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#cv", "#architecture", "#3d"], "emoji": "üé•", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é LongSplat", "desc": "LongSplat - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑–∞ –Ω–æ–≤—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤ –∏–∑ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –¥–≤–∏–∂–µ–Ω–∏–µ–º –∫–∞–º–µ—Ä—ã. –û–Ω –∏—Å–ø–æ
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#data", "#multimodal"], "emoji": "üóÇÔ∏è", "ru": {"title": "POML: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–æ–º–ø—Ç–∏–Ω–≥—É —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç POML - —è–∑—ã–∫ —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∏–Ω–≥–∞ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. POML —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö, —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#synthetic", "#cv", "#dataset", "#benchmark"], "emoji": "üé®", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ —É–ª—É—á—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø—ã—Ç
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#interpretability", "#training", "#audio", "#alignment"], "emoji": "üéß", "ru": {"title": "LLM –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º –ø–æ–¥–∫–∞—Å—Ç–æ–≤", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–¥–∫–∞—Å—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –°–∏—Å—Ç–µ–º–∞ —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Ñ–∏
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#training", "#agents", "#dataset", "#optimization", "#reasoning", "#robotics", "#agi"], "emoji": "ü§ñ", "ru": {"title": "–£–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –ø—É—Ç—å –∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º—É –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–º—É –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –æ–±–æ–±—â–µ–Ω–∏—è –≤ –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–º –ò–ò —Å –∏—Å–ø–æ
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#data", "#optimization", "#training", "#hallucinations", "#inference"], "emoji": "üéØ", "ru": {"title": "–¢–æ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "FineCE - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#diffusion", "#video", "#cv", "#multimodal"], "emoji": "üé®", "ru": {"title": "–¢–æ—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞ –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤", "desc": "ColorCtrl - —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–≤–µ—Ç–∞ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –∏ –≤–∏–¥–µ–æ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º—É–ª—å—Ç–∏–º–æ
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#data", "#benchmark", "#cv", "#open_source", "#dataset", "#training"], "emoji": "üï∂Ô∏è", "ru": {"title": "–í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∏–º–µ—Ä–∫–∞ –ª—é–±—ã—Ö –Ω–æ—Å–∏–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –±–µ–∑ –º–∞—Å–æ–∫", "desc": "OmniTry - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Ä–∞—Å—à–∏—Ä—è—é—â–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–∏ (VTON) –Ω–∞ —Ä–∞–∑–ª
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#training", "#optimization"], "emoji": "üîÑ", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ LLM –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ ProActive Self-Refinement (PASR) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). PASR –ø–æ–∑–≤–æ–ª—è–µ—Ç LLM –¥–∏–Ω–∞–º–∏—á
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#benchmark", "#survey", "#multimodal", "#audio"], "emoji": "üéôÔ∏è", "ru": {"title": "–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ DNN-–º–µ—Ç–æ–¥–æ–≤ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Ä–µ—á–∏: –æ—Ç –æ—Å–Ω–æ–≤ –¥–æ –∏–Ω–Ω–æ–≤–∞—Ü–∏–π", "desc": "–≠—Ç–æ –æ–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Ä–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–ª—É–±–æ–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (DNN). –í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –ø–∞—Ä–∞–¥–∏–≥–º—ã –æ–±—É—á–µ–Ω–∏—è,
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#data", "#multimodal", "#reasoning", "#games", "#training"], "emoji": "üò¢", "ru": {"title": "LLM –∫–∞–∫ —ç–º–ø–∞—Ç—ã: –æ—Ü–µ–Ω–∫–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ AI –ø–æ–Ω–∏–º–∞—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–¥–∞–Ω–∏—è", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —É—Ä–æ–≤–µ–Ω—å –Ω–µ—Å—á–∞—Å—Ç—å—è —á–µ–ª–æ–≤–µ–∫–∞
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#cv", "#benchmark", "#alignment", "#optimization"], "emoji": "üñºÔ∏è", "ru": {"title": "–¢–µ–º–ø–æ—Ä–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç TempFlow-GRPO - –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é. –î–∞–Ω
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#rl", "#games"], "emoji": "üó∫Ô∏è", "ru": {"title": "CAMAR: –ù–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏", "desc": "CAMAR - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (MARL) –≤ –∑–∞–¥–∞—á–∞—Ö –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏. –û–Ω 
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#ethics", "#data", "#dataset", "#benchmark", "#survey"], "emoji": "üîê", "ru": {"title": "–ó–∞—â–∏—Ç–∞ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —ç–ø–æ—Ö—É –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±–∑–æ—Ä —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∑–∞—â–∏—Ç—ã –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#games", "#video", "#dataset", "#optimization"], "emoji": "üé•", "ru": {"title": "MLLM –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –≤–∏–¥–µ–æ—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º –¥–ª—è –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ 
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#audio", "#multimodal", "#benchmark", "#reasoning", "#agi", "#open_source"], "emoji": "üéß", "ru": {"title": "MMAU-Pro: –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –∞—É–¥–∏–æ–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –ò–ò", "desc": "MMAU-Pro - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞—É–¥–∏–æ–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. –û–Ω –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#benchmark", "#multimodal"], "emoji": "üîç", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –ò–ò: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –≤–µ–±-–Ω–∞–≤–∏–≥–∞—Ü–∏–∏", "desc": "MM-BrowseComp - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º –ø–æ–∏—Å–∫–µ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö. –û–Ω —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 224 
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#dataset", "#3d", "#transfer_learning"], "emoji": "ü¶¥", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å –∞–Ω–∏–º–∞—Ü–∏–∏ –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è", "desc": "Motion2Motion - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –∞–Ω–∏–º–∞—Ü–∏–∏ –º–µ–∂–¥—É –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏ —Å —Ä–∞–∑–Ω–æ–π —Å–∫–µ–ª–µ—Ç–Ω–æ–π —Ç–æ–ø–æ–ª–æ–≥–∏–µ–π, –Ω–µ —Ç—Ä–µ–±—É—é—â–∞—è –æ–±—É—á–µ–Ω–∏—è. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#ethics", "#data", "#interpretability", "#training", "#benchmark", "#architecture", "#reasoning", "#optimization"], "emoji": "üß†", "ru": {"title": "CorrSteer: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ò–ò —á–µ—Ä–µ–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "desc": "CorrSteer - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#healthcare", "#games", "#cv"], "emoji": "ü©∫", "ru": {"title": "MedSAMix: –£–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "MedSAMix - —ç—Ç–æ –º–µ—Ç–æ–¥ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—á–µ—Ç–∞–µ—Ç —É
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#data", "#training", "#architecture", "#transfer_learning", "#optimization"], "emoji": "üîç", "ru": {"title": "–ï–¥–∏–Ω—ã–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ ID –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –µ–¥–∏–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#3d", "#robotics", "#survey", "#cv"], "emoji": "üîç", "ru": {"title": "–†–∞–¥–∏–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è –≤ XR: –æ—Ç –≤–∏–∑–∏–∏ –∫ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏", "desc": "–≠—Ç–æ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ä–∞–¥–∏–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π (RF) –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ (XR). –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç 365 —Ä–∞–±–æ—Ç, —Å–≤
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#transfer_learning", "#audio", "#training", "#low_resource"], "emoji": "üéôÔ∏è", "ru": {"title": "–ë—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–µ—á–∏ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø—Ä–∏–º–µ—Ä–∞–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–µ—á–∏ –≤ —É—Å–ª–æ–≤–∏—è—Ö —Å–º–µ—â–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö. –ê–≤—Ç–æ—Ä
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#interpretability", "#reasoning", "#healthcare"], "emoji": "üèÉ", "ru": {"title": "ZARA: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è", "desc": "ZARA - —ç—Ç–æ –∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–∞–º –¥–≤–∏–∂–µ–Ω–∏—è –±–µ–∑ –ø—Ä–µ–¥–≤
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#data", "#benchmark", "#ethics", "#alignment"], "emoji": "üß†", "ru": {"title": "–ò–ò –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –ª—é–¥–µ–π –≤ –º–æ—Ä–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ —Ç–µ–∫—Å—Ç–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–æ—Ä–∞–ª—å–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –∫—Ä—É–ø–Ω—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–∞–±–æ—Ç, –∏—Å
[20.08.2025 19:09] Using data from previous issue: {"categories": ["#optimization", "#training", "#benchmark", "#reasoning", "#rl", "#rag", "#interpretability", "#agents"], "emoji": "üß†", "ru": {"title": "–ê—Ç–æ–º–∞—Ä–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –ò–ò-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "Atom-Searcher - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏
[20.08.2025 19:09] Renaming data file.
[20.08.2025 19:09] Renaming previous data. hf_papers.json to ./d/2025-08-20.json
[20.08.2025 19:09] Saving new data file.
[20.08.2025 19:09] Generating page.
[20.08.2025 19:09] Renaming previous page.
[20.08.2025 19:09] Renaming previous data. index.html to ./d/2025-08-20.html
[20.08.2025 19:09] Writing result.
[20.08.2025 19:09] Renaming log file.
[20.08.2025 19:09] Renaming previous data. log.txt to ./logs/2025-08-20_last_log.txt
