[21.04.2025 19:09] Read previous papers.
[21.04.2025 19:09] Generating top page (month).
[21.04.2025 19:09] Writing top page (month).
[21.04.2025 20:12] Read previous papers.
[21.04.2025 20:12] Get feed.
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13837
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13835
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.11544
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.11833
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.10823
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13173
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13157
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.09621
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13072
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13828
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13626
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13816
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.12083
[21.04.2025 20:12] Extract page data from URL. URL: https://huggingface.co/papers/2504.13677
[21.04.2025 20:12] Get page data from previous paper. URL: https://huggingface.co/papers/2504.13519
[21.04.2025 20:12] Extract page data from URL. URL: https://huggingface.co/papers/2504.13359
[21.04.2025 20:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.04.2025 20:12] No deleted papers detected.
[21.04.2025 20:12] Downloading and parsing papers (pdf, html). Total: 16.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13837.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13837.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13837.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13835.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13835.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13835.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.11544.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.11544.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.11544.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.11833.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.11833.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.11833.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.10823.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.10823.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.10823.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13173.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13173.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13173.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13157.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13157.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13157.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.09621.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.09621.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.09621.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13072.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13072.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13072.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13828.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13828.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13828.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13626.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13626.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13626.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13816.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13816.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13816.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.12083.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.12083.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.12083.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13677.
[21.04.2025 20:12] Downloading paper 2504.13677 from http://arxiv.org/pdf/2504.13677v1...
[21.04.2025 20:12] Extracting affiliations from text.
[21.04.2025 20:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results Andrea Santilli* Sapienza University of Rome Adam Goli nski* Apple Miao Xiong National University of Singapore Sinead A. Williamson Apple 5 2 0 2 8 1 ] . [ 1 7 7 6 3 1 . 4 0 5 2 : r a "
[21.04.2025 20:12] Response: ```python
["Sapienza University of Rome", "Apple", "National University of Singapore"]
```
[21.04.2025 20:12] Deleting PDF ./assets/pdf/2504.13677.pdf.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13519.
[21.04.2025 20:12] Extra JSON file exists (./assets/json/2504.13519.json), skip PDF parsing.
[21.04.2025 20:12] Paper image links file exists (./assets/img_data/2504.13519.json), skip HTML parsing.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Downloading and parsing paper https://huggingface.co/papers/2504.13359.
[21.04.2025 20:12] Downloading paper 2504.13359 from http://arxiv.org/pdf/2504.13359v1...
[21.04.2025 20:12] Extracting affiliations from text.
[21.04.2025 20:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Cost-of-Pass: An Economic Framework for Evaluating Language Models Mehmet Hamza Erol* 1 Batu El* 1 Mirac Suzgun* 1 Mert Yuksekgonul 1 James Zou "
[21.04.2025 20:12] Response: []
[21.04.2025 20:12] Extracting affiliations from text.
[21.04.2025 20:12] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Cost-of-Pass: An Economic Framework for Evaluating Language Models Mehmet Hamza Erol* 1 Batu El* 1 Mirac Suzgun* 1 Mert Yuksekgonul 1 James Zou1. Introduction 5 2 0 2 7 1 ] . [ 1 9 5 3 3 1 . 4 0 5 2 : r The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce cost-ofpass, the expected monetary cost of generating correct solution. We then define the frontier costof-pass as the minimum cost-of-pass achievable across available models or the human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledgeintensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiersestimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledgeintensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides principled tool for measuring this progress and guiding deployment. *Co-first authors. Co-senior authors. 1Stanford University. (cid:0) {mhamza,jamesz}@stanford.edu. https://github.com/mhamzaerol/Cost-of-Pass. 1 The recent progress in generative AI, particularly language models (LMs), has sparked significant interest in their potential to transform industries, automate cognitive tasks, and reshape economic productivity (Brynjolfsson et al., 2025; Eloundou et al., 2024; Acemoglu, 2024). The widespread adoption of these AI systems in the economy hinges on whether the economic benefits generated by the tasks they can perform outweigh the associated inference costs, and whether those inference costs are lower than the cost of equivalent human labor. Consequently, two priorities have emerged at the forefront of LM research: advancing capabilities and reducing costs. These goals, however, often involve trade-offs with more powerful models or testtime techniques that offer higher accuracy at the expense of greater computational and monetary cost (Chen et al., 2024; Parashar et al., 2025; Madaan et al., 2023; Wang et al., 2023; Kapoor et al., 2024). While standard metrics capture accuracy or other system capabilities, they fail to account for cost, leading to an incomplete picture of progress. Ultimately, what matters to the users is not just raw capability, but the value delivered relative to cost and the standard has been to interpret and report these separately. As the ecosystem of models grows, it is essential to assess new models not in isolation, but in the context of broader ecosystem, where marginal improvements may or may not justify higher costs, and do so in an easy-to-interpret manner. To systematically investigate the trade-off between cost and performance and analyze the LM ecosystem as whole, we draw insights from well-established and foundational framework from economics: production frontiers. Economists have long studied these frontiers, which map set of inputs to the maximum output attainable under given technology (Farrell, 1957). In Farrells original formulation, producer is technically efficient if no input can be reduced without lowering output, and price efficient if the input mix minimizes cost given input prices. Together, these conditions yield the lowest possible cost per unit of output. Extending this framework, Aigner et al. (1977) introduced stochastic frontier production functions, in which the relationship between inputs and output is modeled as stochastic rather than deterministic, practically accounting for potential defective outputs that do not pass evaluation criteria due to factors beyond the producers control. Cost-of-Pass: An Economic Framework for Evaluating Language Models Figure 1: Highlights of the cost-of-pass framework and empirical analyses. Core concepts (left) set foundations for: (A) Comparing the Human Expert Baseline to the frontier achieved by the single most effective LM per task category. (B) Tracking the reduction in frontier cost-of-pass over time, indicating progress driven by new model releases (color-coded by family). (C) Quantifying the essential contribution of each model family: lightweight (less than $1 per million tokens), large, and reasoning; to the current cost-efficiency frontier, measured by the percentage of each familys contribution. (D) Assessing the economic benefit (relative cost reduction) achieved by applying common inference-time techniques over the baseline model frontier (which rarely results in meaningful gains). These economic concepts are highly relevant to modern LMs, which inherently function as stochastic producers: for given input, they yield desired output (e.g., correct solution) stochastically (Brown et al., 2024). Common practices such as employing scaffolds or more computationally intensive inference techniques (Snell et al., 2024; Madaan et al., 2023; Wang et al., 2023) represent efforts to manipulate this production process. These strategies seek to increase the probability of success but typically do so at the expense of higher computational cost, directly mirroring the economic trade-offs inherent in production efficiency. Motivated by these parallels and the economic goal of minimizing cost per successful output under uncertainty, we develop quantitative framework tailored to LMs. We summarize our contributions as follows. Concepts. We introduce cost-of-pass (2.2), which quantifies the expected monetary cost to achieve successful output for given problem. Building on th"
[21.04.2025 20:12] Mistral response. {"id": "52a0068a99ea41e084ef947ea021a161", "object": "chat.completion", "created": 1745266360, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\"Stanford University\"]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1537, "total_tokens": 1544, "completion_tokens": 7}}
[21.04.2025 20:12] Response: ["Stanford University"]
[21.04.2025 20:12] Deleting PDF ./assets/pdf/2504.13359.pdf.
[21.04.2025 20:12] Success.
[21.04.2025 20:12] Enriching papers with extra data.
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 0. Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning capabilities of LLMs, particularly in mathematics and programming tasks. It is widely believed that RLVR enables LLMs to continuously self-improve, thus acquiring novel reasonin...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 1. Data quality and diversity are key to the construction of effective instruction-tuning datasets. % With the increasing availability of open-source instruction-tuning datasets, it is advantageous to automatically select high-quality and diverse subsets from a vast amount of data. % Existing methods t...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 2. Retrieval-augmented generation (RAG) empowers large language models to access external and private corpus, enabling factually consistent responses in specific domains. By exploiting the inherent structure of the corpus, graph-based RAG methods further enrich this process by building a knowledge grap...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 3. Previous work indicates that large language models exhibit a significant "English bias", i.e. they often perform better when tasks are presented in English. Interestingly, we have observed that using certain other languages in reasoning tasks can yield better performance than English. However, this ...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 4. Navigating high-stakes dilemmas involving conflicting values is challenging even for humans, let alone for AI. Yet prior work in evaluating the reasoning capabilities of large language models (LLMs) in such situations has been limited to everyday scenarios. To close this gap, this work first introdu...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 5. Designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neural arc...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 6. We explore the task of geometric reconstruction of images captured from a mixture of ground and aerial views. Current state-of-the-art learning-based approaches fail to handle the extreme viewpoint variation between aerial-ground image pairs. Our hypothesis is that the lack of high-quality, co-regis...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 7. Global contextual information and local detail features are essential for haze removal tasks. Deep learning models perform well on small, low-resolution images, but they encounter difficulties with large, high-resolution ones due to GPU memory limitations. As a compromise, they often resort to image...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 8. Scene-level 3D generation represents a critical frontier in multimedia and computer graphics, yet existing approaches either suffer from limited object categories or lack editing flexibility for interactive applications. In this paper, we present HiScene, a novel hierarchical framework that bridges ...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 9. The first generation of Large Language Models - what might be called "Act I" of generative AI (2020-2023) - achieved remarkable success through massive parameter and data scaling, yet exhibited fundamental limitations in knowledge latency, shallow reasoning, and constrained cognitive processes. Duri...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 10. Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities in multiple tasks. However, LRMs typically suffer from "overthinking" problems, where models generate significantly redundant reasoning steps wh...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 11. While understanding the knowledge boundaries of LLMs is crucial to prevent hallucination, research on knowledge boundaries of LLMs has predominantly focused on English. In this work, we present the first study to analyze how LLMs recognize knowledge boundaries across different languages by probing t...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 12. Despite recent advances in Large Video Language Models (LVLMs), they still struggle with fine-grained temporal understanding, hallucinate, and often make simple mistakes on even simple video question-answering tasks, all of which pose significant challenges to their safe and reliable deployment in r...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 13. Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In thi...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 14. Effective denoising is crucial in low-dose CT to enhance subtle structures and low-contrast lesions while preventing diagnostic errors. Supervised methods struggle with limited paired datasets, and self-supervised approaches often require multiple noisy images and rely on deep networks like U-Net, o...
[21.04.2025 20:12] ********************************************************************************
[21.04.2025 20:12] Abstract 15. The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating lan...
[21.04.2025 20:12] Read previous papers.
[21.04.2025 20:12] Generating reviews via LLM API.
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#optimization"], "emoji": "🤖", "ru": {"title": "Обучение с подкреплением не расширяет границы рассуждений ИИ", "desc": "Исследование показывает, что обучение с подкреплением с верифицируемыми наградами (RLVR) не приводит к появлению принципиально но
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#data", "#open_source", "#training", "#dataset", "#optimization"], "emoji": "🧠", "ru": {"title": "Максимизация информационного прироста для эффективного обучения языковых моделей", "desc": "Статья представляет новый метод для отбора высококачественных и разнообразных подмножеств дан
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#games", "#graphs", "#open_source", "#rag", "#multimodal", "#optimization"], "emoji": "🕸️", "ru": {"title": "NodeRAG: Графовый подход к улучшению генерации с дополнением из источников", "desc": "NodeRAG - это новый подход к генерации с дополнением из источников (RAG), использующий г
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#reasoning", "#low_resource", "#multilingual"], "emoji": "🌍", "ru": {"title": "Многоязычное рассуждение - ключ к улучшению больших языковых моделей", "desc": "Это исследование показывает, что использование нескольких языков в задачах рассуждения может значительно повысить эффективно
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#alignment", "#reasoning", "#dataset", "#benchmark"], "emoji": "🤔", "ru": {"title": "Испытание искусственного интеллекта этическими дилеммами", "desc": "Статья представляет набор данных CLASH для оценки способности языковых моделей решать сложные этические дилеммы. Исследование выяв
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#training", "#architecture", "#reasoning", "#optimization"], "emoji": "🧠", "ru": {"title": "Переосмысление архитектур нейронных сетей через призму селективного внимания", "desc": "Статья представляет новый подход к проектированию архитектур нейронных сетей, вдохновленный когнитивным
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#synthetic", "#dataset", "#3d"], "emoji": "🏙️", "ru": {"title": "Преодоление разрыва между землей и небом в компьютерном зрении", "desc": "Статья посвящена геометрической реконструкции изображений с наземных и аэросъемок. Авторы предлагают масштабируем
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#optimization", "#data", "#cv"], "emoji": "🌫️", "ru": {"title": "DehazeXL: эффективное удаление дымки на больших изображениях", "desc": "DehazeXL - это новый метод удаления дымки, который эффективно балансирует глобальный контекст и извлечен
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#3d"], "emoji": "🏠", "ru": {"title": "HiScene: Иерархическая 3D-генерация сцен с композиционной структурой", "desc": "HiScene - это новый иерархический подход к генерации 3D-сцен, который объединяет 2D-генерацию изображений и 3D-генерацию объектов. Метод рассматривает сцены как иера
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#agi", "#multimodal", "#survey", "#optimization", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "От извлечения знаний к конструированию мыслей: новая эра ИИ", "desc": "Статья описывает переход от первого поколения больших языковых моделей (LLM) к новому этапу развития ис
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#training", "#optimization", "#reasoning", "#alignment"], "emoji": "🧠", "ru": {"title": "Оптимизация рассуждений больших языковых моделей без переобучения", "desc": "Статья представляет метод ThoughtMani для оптимизации работы больших моделей рассуждений (L
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#hallucinations", "#dataset", "#transfer_learning", "#low_resource", "#open_source", "#training", "#multilingual"], "emoji": "🌐", "ru": {"title": "Преодоление языковых барьеров в понимании пределов знаний ИИ", "desc": "Исследование посвящено анализу восприятия границ знаний языковым
[21.04.2025 20:12] Using data from previous issue: {"categories": ["#optimization", "#hallucinations", "#reasoning", "#rlhf", "#training", "#video", "#alignment"], "emoji": "🎥", "ru": {"title": "Самонастройка видеоязыковых моделей для повышения точности и надежности", "desc": "Статья представляет новый метод самонастройки для крупных видеоязыковых м
[21.04.2025 20:12] Querying the API.
[21.04.2025 20:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases.
[21.04.2025 20:12] Response: {
  "desc": "Данная статья исследует проблему оценки неопределенности в языковых моделях. Авторы обнаружили, что распространенные функции корректности искажают оценку методов количественной оценки неопределенности из-за смещений, связанных с длиной текста. Было проанализировано 7 функций корректности на 4 наборах данных с использованием 4 моделей и 6 методов оценки неопределенности. Исследование показало, что подход 'LLM-as-a-judge' наименее подвержен смещению по длине и может помочь снизить эти искажения.",
  "emoji": "🎭",
  "title": "Борьба со смещениями в оценке неопределенности языковых моделей"
}
[21.04.2025 20:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases."

[21.04.2025 20:12] Response: ```python
["DATASET", "BENCHMARK", "DATA"]
```
[21.04.2025 20:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases."

[21.04.2025 20:12] Response: ```python
["INTERPRETABILITY", "HALLUCINATIONS"]
```
[21.04.2025 20:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the importance of Uncertainty Quantification (UQ) in Language Models (LMs) for enhancing their safety and reliability. It highlights how traditional correctness functions, such as ROUGE-L, can introduce biases that inflate the perceived performance of UQ methods. The authors evaluate various correctness functions across multiple datasets and models, revealing that length biases in these functions distort UQ assessments. They propose LLM-as-a-judge approaches as a promising solution to reduce these biases and improve UQ evaluations.","title":"Mitigating Biases in UQ Evaluations with LLM-as-a-Judge"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the importance of Uncertainty Quantification (UQ) in Language Models (LMs) for enhancing their safety and reliability. It highlights how traditional correctness functions, such as ROUGE-L, can introduce biases that inflate the perceived performance of UQ methods. The authors evaluate various correctness functions across multiple datasets and models, revealing that length biases in these functions distort UQ assessments. They propose LLM-as-a-judge approaches as a promising solution to reduce these biases and improve UQ evaluations.', title='Mitigating Biases in UQ Evaluations with LLM-as-a-Judge'))
[21.04.2025 20:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"在语言模型中的不确定性量化（UQ）对于提高其安全性和可靠性至关重要。本文展示了常用的正确性函数会通过夸大某些UQ方法的性能来偏见UQ评估。我们评估了7种正确性函数，并发现这些函数的长度偏差会扭曲UQ评估结果。我们指出，LLM作为评判者的方法是最少受长度偏差影响的选择，可能是缓解这些偏差的解决方案。","title":"提升语言模型安全性的关键：不确定性量化"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='在语言模型中的不确定性量化（UQ）对于提高其安全性和可靠性至关重要。本文展示了常用的正确性函数会通过夸大某些UQ方法的性能来偏见UQ评估。我们评估了7种正确性函数，并发现这些函数的长度偏差会扭曲UQ评估结果。我们指出，LLM作为评判者的方法是最少受长度偏差影响的选择，可能是缓解这些偏差的解决方案。', title='提升语言模型安全性的关键：不确定性量化'))
[21.04.2025 20:13] Using data from previous issue: {"categories": ["#data", "#training", "#interpretability", "#low_resource", "#healthcare", "#dataset"], "emoji": "🔬", "ru": {"title": "Интерпретируемое шумоподавление для КТ: от фильтра к чистоте", "desc": "Статья представляет новый метод шумоподавления для низкодозовой компьютерной томографии под н
[21.04.2025 20:13] Querying the API.
[21.04.2025 20:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce "cost-of-pass", the expected monetary cost of generating a correct solution. We then define the "frontier cost-of-pass" as the minimum cost-of-pass achievable across available models or the "human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers: estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledge-intensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides a principled tool for measuring this progress and guiding deployment.
[21.04.2025 20:13] Response: {
  "desc": "Статья предлагает новый подход к оценке языковых моделей, основанный на теории производства, который учитывает как точность, так и стоимость вывода. Авторы вводят метрику 'cost-of-pass' - ожидаемую денежную стоимость генерации правильного решения, и 'frontier cost-of-pass' - минимальную достижимую стоимость среди доступных моделей или экспертов-людей. Анализ показывает, что легковесные модели наиболее эффективны для базовых количественных задач, крупные модели - для задач, требующих обширных знаний, а модели рассуждений - для сложных количественных проблем. Исследование также демонстрирует значительный прогресс в снижении 'frontier cost-of-pass' за последний год, особенно для сложных количественных задач.",
  "emoji": "💹",
  "title": "Экономическая эффективность ИИ: новый подход к оценке языковых моделей"
}
[21.04.2025 20:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce "cost-of-pass", the expected monetary cost of generating a correct solution. We then define the "frontier cost-of-pass" as the minimum cost-of-pass achievable across available models or the "human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers: estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledge-intensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides a principled tool for measuring this progress and guiding deployment."

[21.04.2025 20:13] Response: ```python
["INFERENCE", "BENCHMARK"]
```
[21.04.2025 20:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce "cost-of-pass", the expected monetary cost of generating a correct solution. We then define the "frontier cost-of-pass" as the minimum cost-of-pass achievable across available models or the "human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers: estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledge-intensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides a principled tool for measuring this progress and guiding deployment."

[21.04.2025 20:13] Response: ```python
["OPTIMIZATION", "REASONING"]
```
[21.04.2025 20:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a framework for evaluating language models based on their economic value, balancing performance and inference costs. It introduces the concept of \'cost-of-pass\', which quantifies the expected monetary cost of producing a correct output. The authors analyze how different types of models—lightweight, large, and reasoning—perform across various tasks, revealing that each type excels in specific areas despite differing costs. Additionally, they highlight the importance of model innovations in improving cost-efficiency and provide insights into the effectiveness of inference-time techniques.","title":"Balancing Performance and Cost in AI: A New Economic Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper presents a framework for evaluating language models based on their economic value, balancing performance and inference costs. It introduces the concept of 'cost-of-pass', which quantifies the expected monetary cost of producing a correct output. The authors analyze how different types of models—lightweight, large, and reasoning—perform across various tasks, revealing that each type excels in specific areas despite differing costs. Additionally, they highlight the importance of model innovations in improving cost-efficiency and provide insights into the effectiveness of inference-time techniques.", title='Balancing Performance and Cost in AI: A New Economic Framework'))
[21.04.2025 20:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了人工智能系统在经济中的应用，强调了生成经济价值与推理成本之间的权衡。我们提出了一种基于生产理论的框架，用于评估语言模型的准确性和推理成本。引入了“成本-通过”的概念，表示生成正确解决方案的预期货币成本，并定义了“前沿成本-通过”，即在可用模型中实现的最低成本。我们的分析显示，轻量级模型在基本定量任务中最具成本效益，而大型模型适用于知识密集型任务，推理模型则适合复杂定量问题。","title":"评估语言模型的经济价值与推理成本"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了人工智能系统在经济中的应用，强调了生成经济价值与推理成本之间的权衡。我们提出了一种基于生产理论的框架，用于评估语言模型的准确性和推理成本。引入了“成本-通过”的概念，表示生成正确解决方案的预期货币成本，并定义了“前沿成本-通过”，即在可用模型中实现的最低成本。我们的分析显示，轻量级模型在基本定量任务中最具成本效益，而大型模型适用于知识密集型任务，推理模型则适合复杂定量问题。', title='评估语言模型的经济价值与推理成本'))
[21.04.2025 20:13] Loading Chinese text from previous data.
[21.04.2025 20:13] Renaming data file.
[21.04.2025 20:13] Renaming previous data. hf_papers.json to ./d/2025-04-21.json
[21.04.2025 20:13] Saving new data file.
[21.04.2025 20:13] Generating page.
[21.04.2025 20:13] Renaming previous page.
[21.04.2025 20:13] Renaming previous data. index.html to ./d/2025-04-21.html
[21.04.2025 20:13] [Experimental] Generating Chinese page for reading.
[21.04.2025 20:13] Chinese vocab [{'word': '构建', 'pinyin': 'gòujiàn', 'trans': 'construct'}, {'word': '有效', 'pinyin': 'yǒuxiào', 'trans': 'effective'}, {'word': '指令', 'pinyin': 'zhǐlìng', 'trans': 'instruction'}, {'word': '调整', 'pinyin': 'tiáozhěng', 'trans': 'adjust'}, {'word': '数据集', 'pinyin': 'shùjùjí', 'trans': 'dataset'}, {'word': '关键因素', 'pinyin': 'guǎnjiàn yīnsù', 'trans': 'key factors'}, {'word': '质量', 'pinyin': 'zhìliàng', 'trans': 'quality'}, {'word': '多样性', 'pinyin': 'duōyàngxìng', 'trans': 'diversity'}, {'word': '开源', 'pinyin': 'kāiyuán', 'trans': 'open-source'}, {'word': '自动', 'pinyin': 'zìdòng', 'trans': 'automatic'}, {'word': '选择', 'pinyin': 'xuǎnzé', 'trans': 'select'}, {'word': '子集', 'pinyin': 'zǐjí', 'trans': 'subset'}, {'word': '变得', 'pinyin': 'biàndé', 'trans': 'become'}, {'word': '重要', 'pinyin': 'zhòngyào', 'trans': 'important'}, {'word': '现有', 'pinyin': 'xiànyǒu', 'trans': 'existing'}, {'word': '方法', 'pinyin': 'fāngfǎ', 'trans': 'method'}, {'word': '主要', 'pinyin': 'zhǔyào', 'trans': 'main'}, {'word': '关注', 'pinyin': 'guānzhù', 'trans': 'focus on'}, {'word': '实例', 'pinyin': 'shílì', 'trans': 'instance'}, {'word': '启发式', 'pinyin': 'qǐfāshì', 'trans': 'heuristic'}, {'word': '规则', 'pinyin': 'guīzé', 'trans': 'rule'}, {'word': '维持', 'pinyin': 'wéichí', 'trans': 'maintain'}, {'word': '效果', 'pinyin': 'xiàoguǒ', 'trans': 'effect'}, {'word': '不佳', 'pinyin': 'bùjiā', 'trans': 'poor'}, {'word': '作者', 'pinyin': 'zuòzhě', 'trans': 'author'}, {'word': '提出', 'pinyin': 'tíchū', 'trans': 'propose'}, {'word': '新方法', 'pinyin': 'xīn fāngfǎ', 'trans': 'new method'}, {'word': '通过', 'pinyin': 'tōngguò', 'trans': 'through'}, {'word': '标签', 'pinyin': 'biāoqiān', 'trans': 'label'}, {'word': '图', 'pinyin': 'tú', 'trans': 'graph'}, {'word': '模拟', 'pinyin': 'mónǐ', 'trans': 'simulate'}, {'word': '语义', 'pinyin': 'yǔyì', 'trans': 'semantic'}, {'word': '空间', 'pinyin': 'kōngjiān', 'trans': 'space'}, {'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'}, {'word': '信息', 'pinyin': 'xìnxī', 'trans': 'information'}, {'word': '分布', 'pinyin': 'fēnbù', 'trans': 'distribution'}, {'word': '量化', 'pinyin': 'liànghuà', 'trans': 'quantify'}, {'word': '实验', 'pinyin': 'shíyàn', 'trans': 'experiment'}, {'word': '显示', 'pinyin': 'xiǎnshì', 'trans': 'show'}, {'word': '优于', 'pinyin': 'yōuyú', 'trans': 'superior to'}, {'word': '基础', 'pinyin': 'jīchǔ', 'trans': 'foundation'}, {'word': '模型', 'pinyin': 'móxíng', 'trans': 'model'}]
[21.04.2025 20:13] Renaming previous Chinese page.
[21.04.2025 20:13] Renaming previous data. zh.html to ./d/2025-04-20_zh_reading_task.html
[21.04.2025 20:13] Writing Chinese reading task.
[21.04.2025 20:13] Writing result.
[21.04.2025 20:13] Renaming log file.
[21.04.2025 20:13] Renaming previous data. log.txt to ./logs/2025-04-21_last_log.txt
