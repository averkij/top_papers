[18.10.2024 04:15] Read previous papers.
[18.10.2024 04:15] Get feed.
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13824
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13085
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13841
[18.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.13785
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13830
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13852
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13198
[18.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.09019
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09426
[18.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.13618
[18.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.13832
[18.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.13804
[18.10.2024 04:15] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13060
[18.10.2024 04:15] Extract page data from URL. URL: https://huggingface.co/papers/2410.13720
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 0. Text-rich visual understanding-the ability to process environments where dense textual content is integrated with visuals-is crucial for multimodal large language models (MLLMs) to interact effectively with structured environments. To enhance this capability, we propose synthesizing general multimod...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 1. Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models oft...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 2. Post-training has emerged as a crucial paradigm for adapting large-scale pre-trained models to various tasks, whose effects are fully reflected by delta parameters (i.e., the disparity between post-trained and pre-trained parameters). While numerous studies have explored delta parameter properties v...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 3. Alignment of large language models (LLMs) involves training models on preference-contrastive output pairs to adjust their responses according to human preferences. To obtain such contrastive pairs, traditional methods like RLHF and RLAIF rely on limited contrasting patterns, such as varying model va...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 4. Recent advances in customized video generation have enabled users to create videos tailored to both specific subjects and motion trajectories. However, existing methods often require complicated test-time fine-tuning and struggle with balancing subject learning and motion control, limiting their rea...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 5. Multi-turn interactions between large language models (LLMs) and users naturally include implicit feedback signals. If an LLM responds in an unexpected way to an instruction, the user is likely to signal it by rephrasing the request, expressing frustration, or pivoting to an alternative task. Such s...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 6. Generative Error Correction (GEC) has emerged as a powerful post-processing method to enhance the performance of Automatic Speech Recognition (ASR) systems. However, we show that GEC models struggle to generalize beyond the specific types of errors encountered during training, limiting their ability...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 7. Language models (LMs) have demonstrated expert-level reasoning and recall abilities in medicine. However, computational costs and privacy concerns are mounting barriers to wide-scale implementation. We introduce a parsimonious adaptation of phi-3-mini, MedMobile, a 3.8 billion parameter LM capable o...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 8. Recently, quantization has been widely used for the compression and acceleration of large language models~(LLMs). Due to the outliers in LLMs, it is crucial to flatten weights and activations to minimize quantization error with the equally spaced quantization points. Prior research explores various ...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 9. The rapid growth of model scale has necessitated substantial computational resources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA) has sought to address the problem of handling the large updated parameters in full fine-tuning. However, LoRA utilize random initialization and o...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 10. Panoramic image stitching provides a unified, wide-angle view of a scene that extends beyond the camera's field of view. Stitching frames of a panning video into a panoramic photograph is a well-understood problem for stationary scenes, but when objects are moving, a still panorama cannot capture th...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 11. Evaluating large language models (LLMs) is costly: it requires the generation and examination of LLM outputs on a large-scale benchmark of various tasks. This paper investigates how to efficiently reduce the tasks used to benchmark LLMs without affecting the evaluation quality. Our study reveals tha...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 12. The pervasiveness of proprietary language models has raised privacy concerns for users' sensitive data, emphasizing the need for private inference (PI), where inference is performed directly on encrypted inputs. However, current PI methods face prohibitively higher communication and latency overhead...
[18.10.2024 04:15] ********************************************************************************
[18.10.2024 04:15] Abstract 13. We present Movie Gen, a cast of foundation models that generates high-quality, 1080p HD videos with different aspect ratios and synchronized audio. We also show additional capabilities such as precise instruction-based video editing and generation of personalized videos based on a user's image. Our ...
[18.10.2024 04:15] Read previous papers.
[18.10.2024 04:15] Generating reviews via LLM API.
[18.10.2024 04:15] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –°–æ–∑–¥–∞–Ω –¥–∞—Ç–∞—Å–µ—Ç MultiUI, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 7,3 –º–∏–ª–ª–∏–æ–Ω–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
[18.10.2024 04:15] Using data from previous issue: {"desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ MMed-RAG, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∑—Ä–µ–Ω–∏—è –∏ —è–∑—ã–∫–∞ (Med-LVLMs). –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º –ø–æ–∏—Å–∫–∞ —Å —É—á–µ—Ç–æ–º –¥–æ–º–µ–Ω–∞, –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–±–æ—Ä–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ RAG. –≠
[18.10.2024 04:15] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–Ω–∞–ª–∏–∑—É –¥–µ–ª—å—Ç–∞-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ –†–∏–º–∞–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å. –ê–≤—Ç–æ—Ä—ã –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª—å—Ç–∞-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ —Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Ö –≤–ª–∏—è–Ω–∏—è –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ
[18.10.2024 04:15] Querying the API.
[18.10.2024 04:15] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º PopAlign. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ —É—Ä–æ–≤–Ω—è—Ö –ø—Ä–æ–º–ø—Ç–∞, –º–æ–¥–µ–ª–∏ –∏ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö. PopAlign —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç–∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ RLHF –∏ RLAIF, –∏ –ø–æ–≤—ã—à–∞–µ—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –∫ –∞—Ç–∞–∫–∞–º —Ç–∏–ø–∞ jailbreaking. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ PopAlign –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –±–æ–ª–µ–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ.",
  "categories": ["#nlp", "#rlhf", "#benchmark"],
  "emoji": "üéØ",
  "title": "PopAlign: –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"
}
[18.10.2024 04:15] Get embedding for a paper via LLM API.
[18.10.2024 04:15] Using data from previous issue: {"desc": "DreamVideo-2 - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏—Ö —Ä–∞–º–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –æ–±—ä–µ–∫—Ç–æ–º –∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–µ–π –¥–≤–∏–∂–µ–Ω–∏—è. –°–∏—Å—Ç–µ–º–∞ –≤–≤–æ–¥–∏—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –∏ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã
[18.10.2024 04:15] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ ReSpect, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º (LLM) —É—á–∏—Ç—å—Å—è –Ω–∞ –Ω–µ—è–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–∞—Ö –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –≤ —Ö–æ–¥–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç ReSpect –≤ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –≥–¥–µ –ª—é–¥–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏—Ä—É—é—Ç LLM –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è. 
[18.10.2024 04:15] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ DARAG –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –æ—à–∏–±–æ–∫ (GEC) –≤ —Å–∏—Å—Ç–µ–º–∞—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (ASR). DARAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ —Å–∏—Å—Ç–µ–º text-to-speech, –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö. –ú–µ—Ç–æ–¥ 
[18.10.2024 04:15] Querying the API.
[18.10.2024 04:15] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MedMobile - –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π, —Å–ø–æ—Å–æ–±–Ω—É—é —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö. –ú–æ–¥–µ–ª—å, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ phi-3-mini, –∏–º–µ–µ—Ç –≤—Å–µ–≥–æ 3,8 –º–∏–ª–ª–∏–∞—Ä–¥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –Ω–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–ø–µ—á–∞—Ç–ª—è—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–µ MedQA (USMLE), –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è –ø—Ä–æ—Ö–æ–¥–Ω–æ–π –±–∞–ª–ª –¥–ª—è –≤—Ä–∞—á–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —Ç—â–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –ø–æ–∫–∞–∑—ã–≤–∞—è, —á—Ç–æ —Ü–µ–ø–æ—á–∫–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –Ω–∞–∏–±–æ–ª—å—à–µ–º—É —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ retrieval augmented generation –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π.",
  "categories": ["#nlp", "#benchmark", "#rag", "#dataset"],
  "emoji": "ü©∫",
  "title": "–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –ò–ò-–º–æ–¥–µ–ª—å –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –≤—Ä–∞—á–µ–π –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"
}
[18.10.2024 04:15] Get embedding for a paper via LLM API.
[18.10.2024 04:15] Using data from previous issue: {"desc": "FlatQuant - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—é –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ —Å–≥–ª–∞–∂–µ–Ω–Ω–æ—Å—Ç–∏ –≤–µ—Å–æ–≤ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM). –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∞—Ñ—Ñ–∏–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è, –∫–∞–ª–∏–±—Ä—É–µ–º—ã–µ –∑–∞ —á–∞—Å—ã —Å –ø–æ–º–æ—â—å—é –æ–±–ª–µ–≥—á–µ–Ω–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏. 
[18.10.2024 04:15] Querying the API.
[18.10.2024 04:16] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (PEFT) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º LoLDU. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç LDU-—Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞—Ç—Ä–∏—Ü –Ω–∏–∑–∫–æ–≥–æ —Ä–∞–Ω–≥–∞, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –∏ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å. LoLDU –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –æ–±—ã—á–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ PEFT, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–µ–ª–∏ –æ–±—à–∏—Ä–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª—è—Ö, –≤–∫–ª—é—á–∞—è –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è.",

  "categories": ["#nlp", "#cv", "#multimodal", "#benchmark"],

  "emoji": "üî¨",

  "title": "LoLDU: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
}
[18.10.2024 04:16] Get embedding for a paper via LLM API.
[18.10.2024 04:16] Querying the API.
[18.10.2024 04:16] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑–∞ –ø–∞–Ω–æ—Ä–∞–º–Ω–æ–≥–æ –≤–∏–¥–µ–æ –∏–∑ –æ–±—ã—á–Ω–æ–≥–æ –ø–∞–Ω–æ—Ä–∞–º–Ω–æ–≥–æ –≤–∏–¥–µ–æ, —Å–Ω—è—Ç–æ–≥–æ –≤—Ä—É—á–Ω—É—é. –ê–≤—Ç–æ—Ä—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –∑–∞–¥–∞—á—É –∫–∞–∫ –ø—Ä–æ–±–ª–µ–º—É –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–±—ä–µ–º–∞, –∏—Å–ø–æ–ª—å–∑—É—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ–æ. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤–∏–¥–µ–æ–ø–∞–Ω–æ—Ä–∞–º—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω, –≤–∫–ª—é—á–∞—è –¥–≤–∏–∂—É—â–∏–µ—Å—è –æ–±—ä–µ–∫—Ç—ã –∏ –ª—é–¥–µ–π. –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ –ø–∞–Ω–æ—Ä–∞–º–Ω—ã—Ö –≤–∏–¥–µ–æ.",
  "categories": ["#cv", "#video", "#multimodal"],
  "emoji": "üé•",
  "title": "–ü–∞–Ω–æ—Ä–∞–º–Ω–æ–µ –≤–∏–¥–µ–æ: –æ—Ç –æ–±—ã—á–Ω–æ–π —Å—ä–µ–º–∫–∏ –∫ —à–∏—Ä–æ–∫–æ—É–≥–æ–ª—å–Ω–æ–º—É –æ–±–∑–æ—Ä—É"
}
[18.10.2024 04:16] Get embedding for a paper via LLM API.
[18.10.2024 04:16] Querying the API.
[18.10.2024 04:16] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –º–µ—Ç–æ–¥—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–¥–∞—á –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –±–µ–∑ —É—â–µ—Ä–±–∞ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω–∫–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç—Ä–∏–∫—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (ICL). –ê–Ω–∞–ª–∏–∑–∏—Ä—É—è –ø–æ–ø–∞—Ä–Ω—É—é –ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç—å, –º–æ–∂–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –Ω–∞–±–æ—Ä –∑–∞–¥–∞—á –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö LLM –¥–æ 5% —Å —Ä–∞–∑–Ω–∏—Ü–µ–π –º–µ–Ω–µ–µ 4% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –æ—Ü–µ–Ω–∫–æ–π –Ω–∞ –ø–æ–ª–Ω–æ–º –Ω–∞–±–æ—Ä–µ. –ú–µ—Ç–æ–¥ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –≤—ã—Å–æ–∫–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º.",
  "categories": ["#nlp", "#benchmark", "#rlhf"],
  "emoji": "üéØ",
  "title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –º–µ–Ω—å—à–µ –∑–∞–¥–∞—á, —Ç–∞ –∂–µ —Ç–æ—á–Ω–æ—Å—Ç—å"
}
[18.10.2024 04:16] Get embedding for a paper via LLM API.
[18.10.2024 04:16] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–æ–ª–∏ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –¥–µ–∫–æ–¥–µ—Ä-—Ç–æ–ª—å–∫–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç AERO - —á–µ—Ç—ã—Ä–µ—Ö—ç—Ç–∞–ø–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, –∫–æ—Ç–æ—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ LayerNorm –∏ GELU, –∏ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏
[18.10.2024 04:16] Querying the API.
[18.10.2024 04:16] Got response. {
  "desc": "MovieGen - —ç—Ç–æ –Ω–∞–±–æ—Ä —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∏—Ö –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ 1080p HD —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ. –ú–æ–¥–µ–ª–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö, –≤–∫–ª—é—á–∞—è —Å–∏–Ω—Ç–µ–∑ –≤–∏–¥–µ–æ –ø–æ —Ç–µ–∫—Å—Ç—É, –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é –≤–∏–¥–µ–æ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∞—É–¥–∏–æ. –ö—Ä—É–ø–Ω–µ–π—à–∞—è –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç 30 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 16-—Å–µ–∫—É–Ω–¥–Ω—ã–µ –≤–∏–¥–µ–æ. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Ä—è–¥ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–Ω–æ–≤–∞—Ü–∏–π –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ, –æ–±—É—á–µ–Ω–∏–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–ª—å—Ç–∏–º–µ–¥–∏–∞.",
  "categories": ["#multimodal", "#video", "#benchmark", "#nlp"],
  "emoji": "üé¨",
  "title": "MovieGen: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—É–ª—å—Ç–∏–º–µ–¥–∏–∞"
}
[18.10.2024 04:16] Get embedding for a paper via LLM API.
[18.10.2024 04:16] Loading Chinese text from previous data.
[18.10.2024 04:16] Renaming data file.
[18.10.2024 04:16] Renaming previous data. hf_papers.json to 2024-10-17_hf_papers.json
[18.10.2024 04:16] Saving new data file.
[18.10.2024 04:16] Generating page.
[18.10.2024 04:16] Generating Chinese page for reading.
[18.10.2024 04:16] Chinese vocab [{'word': 'ÁºñÁ†Å', 'pinyin': 'biƒÅn m«é', 'trans': 'coding'}, {'word': '‰ªªÂä°', 'pinyin': 'r√®n w√π', 'trans': 'task'}, {'word': 'ËØÑ‰º∞', 'pinyin': 'p√≠ng g≈´', 'trans': 'evaluation'}, {'word': 'Â§ßÂûã', 'pinyin': 'd√† x√≠ng', 'trans': 'large-scale'}, {'word': 'ËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'y«î y√°n m√≥ x√≠ng', 'trans': 'language model'}, {'word': 'È´òÁ∫ß', 'pinyin': 'gƒÅo j√≠', 'trans': 'advanced'}, {'word': 'Êåá‰ª§', 'pinyin': 'zh«ê l√¨ng', 'trans': 'instructions'}, {'word': 'Â§çÊùÇ', 'pinyin': 'f√π z√°', 'trans': 'complex'}, {'word': 'Êé®ÁêÜ', 'pinyin': 'tuƒ´ l«ê', 'trans': 'reasoning'}, {'word': 'ÂäüËÉΩ', 'pinyin': 'g≈çng n√©ng', 'trans': 'functional'}, {'word': 'Á®ãÂ∫è', 'pinyin': 'ch√©ng x√π', 'trans': 'program'}, {'word': 'Â§öÊ®°ÊÄÅ', 'pinyin': 'du≈ç m√≥ shu√†i', 'trans': 'multimodal'}, {'word': 'ËßÜËßâ', 'pinyin': 'sh√¨ ju√©', 'trans': 'visual'}, {'word': 'ÊÑüÁü•', 'pinyin': 'g«én zhƒ´', 'trans': 'perception'}, {'word': 'ÁêÜËß£', 'pinyin': 'l«ê jiƒõ', 'trans': 'understanding'}, {'word': 'ËøõÂ±ï', 'pinyin': 'j√¨n zh«én', 'trans': 'progress'}, {'word': '‰∏•Ê†º', 'pinyin': 'y√°n g√©', 'trans': 'strict'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'}, {'word': 'Âº∫Ë∞É', 'pinyin': 'qi√°ng di√†o', 'trans': 'emphasize'}, {'word': 'Á©∫ÁôΩ', 'pinyin': 'k√≤ng b√°i', 'trans': 'gap'}, {'word': 'ÂºïÂÖ•', 'pinyin': 'y«ên r√π', 'trans': 'introduce'}, {'word': '‰∏ìÈó®', 'pinyin': 'zhuƒÅn m√©n', 'trans': 'specifically'}, {'word': 'ËÆæËÆ°', 'pinyin': 'sh√® j√¨', 'trans': 'design'}, {'word': 'Áî®‰∫é', 'pinyin': 'y√≤ng y√∫', 'trans': 'used for'}, {'word': 'ËΩªÈáèÁ∫ß', 'pinyin': 'qƒ´ng li√†ng j√≠', 'trans': 'lightweight'}, {'word': 'ÂàùÁ∫ß', 'pinyin': 'ch≈´ j√≠', 'trans': 'entry-level'}, {'word': 'Á≤æÂøÉ', 'pinyin': 'jƒ´ng xƒ´n', 'trans': 'carefully'}, {'word': 'ËßÜËßâÂÖÉÁ¥†', 'pinyin': 'sh√¨ ju√© yu√°n s√π', 'trans': 'visual elements'}, {'word': 'ËØ¶ÁªÜ', 'pinyin': 'xi√°ng x√¨', 'trans': 'detailed'}, {'word': 'ÊµãËØï', 'pinyin': 'c√® sh√¨', 'trans': 'test'}, {'word': 'Áî®‰æã', 'pinyin': 'y√≤ng l√¨', 'trans': 'case'}, {'word': 'Á†îÁ©∂', 'pinyin': 'y√°n ji≈´', 'trans': 'research'}, {'word': 'ÂèëÁé∞', 'pinyin': 'fƒÅ xi√†n', 'trans': 'find'}, {'word': 'ÂÖàËøõ', 'pinyin': 'xiƒÅn j√¨n', 'trans': 'advanced'}, {'word': 'Èù¢‰∏¥', 'pinyin': 'mi√†n l√≠n', 'trans': 'face'}, {'word': 'ÈáçÂ§ß', 'pinyin': 'zh√≤ng d√†', 'trans': 'major'}, {'word': 'ÊåëÊàò', 'pinyin': 'ti«éo zh√†n', 'trans': 'challenge'}]
[18.10.2024 04:16] Renaming previous page.
[18.10.2024 04:16] Renaming previous data. index.html to 2024-10-17_hf_papers.html
[18.10.2024 04:16] Renaming previous Chinese page.
[18.10.2024 04:16] Renaming previous data. zh.html to 2024-10-17_zh_reading_task.html
[18.10.2024 04:16] Writing result.
[18.10.2024 04:16] Writing Chinese reading task.
[18.10.2024 04:16] Renaming log file.
[18.10.2024 04:16] Renaming previous data. log.txt to 2024-10-17_last_log.txt
