[18.10.2024 06:17] Read previous papers.
[18.10.2024 06:17] Get feed.
[18.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.13754
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13824
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13085
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13841
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13720
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13785
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13830
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09426
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13198
[18.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.13848
[18.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.11842
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.09019
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13060
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13852
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13618
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13832
[18.10.2024 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2410.13804
[18.10.2024 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2410.13293
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 0. Perceiving and generating diverse modalities are crucial for AI models to effectively learn from and engage with real-world signals, necessitating reliable evaluations for their development. We identify two major issues in current evaluations: (1) inconsistent standards, shaped by different communit...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 1. Text-rich visual understanding-the ability to process environments where dense textual content is integrated with visuals-is crucial for multimodal large language models (MLLMs) to interact effectively with structured environments. To enhance this capability, we propose synthesizing general multimod...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 2. Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models oft...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 3. Post-training has emerged as a crucial paradigm for adapting large-scale pre-trained models to various tasks, whose effects are fully reflected by delta parameters (i.e., the disparity between post-trained and pre-trained parameters). While numerous studies have explored delta parameter properties v...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 4. We present Movie Gen, a cast of foundation models that generates high-quality, 1080p HD videos with different aspect ratios and synchronized audio. We also show additional capabilities such as precise instruction-based video editing and generation of personalized videos based on a user's image. Our ...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 5. Alignment of large language models (LLMs) involves training models on preference-contrastive output pairs to adjust their responses according to human preferences. To obtain such contrastive pairs, traditional methods like RLHF and RLAIF rely on limited contrasting patterns, such as varying model va...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 6. Recent advances in customized video generation have enabled users to create videos tailored to both specific subjects and motion trajectories. However, existing methods often require complicated test-time fine-tuning and struggle with balancing subject learning and motion control, limiting their rea...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 7. Recently, quantization has been widely used for the compression and acceleration of large language models~(LLMs). Due to the outliers in LLMs, it is crucial to flatten weights and activations to minimize quantization error with the equally spaced quantization points. Prior research explores various ...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 8. Generative Error Correction (GEC) has emerged as a powerful post-processing method to enhance the performance of Automatic Speech Recognition (ASR) systems. However, we show that GEC models struggle to generalize beyond the specific types of errors encountered during training, limiting their ability...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 9. In this paper, we introduce Janus, an autoregressive framework that unifies multimodal understanding and generation. Prior research often relies on a single visual encoder for both tasks, such as Chameleon. However, due to the differing levels of information granularity required by multimodal unders...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 10. In this work, we upgrade the multi-head attention mechanism, the core of the Transformer model, to improve efficiency while maintaining or surpassing the previous accuracy level. We show that multi-head attention can be expressed in the summation form. Drawing on the insight that not all attention h...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 11. Language models (LMs) have demonstrated expert-level reasoning and recall abilities in medicine. However, computational costs and privacy concerns are mounting barriers to wide-scale implementation. We introduce a parsimonious adaptation of phi-3-mini, MedMobile, a 3.8 billion parameter LM capable o...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 12. The pervasiveness of proprietary language models has raised privacy concerns for users' sensitive data, emphasizing the need for private inference (PI), where inference is performed directly on encrypted inputs. However, current PI methods face prohibitively higher communication and latency overhead...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 13. Multi-turn interactions between large language models (LLMs) and users naturally include implicit feedback signals. If an LLM responds in an unexpected way to an instruction, the user is likely to signal it by rephrasing the request, expressing frustration, or pivoting to an alternative task. Such s...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 14. The rapid growth of model scale has necessitated substantial computational resources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA) has sought to address the problem of handling the large updated parameters in full fine-tuning. However, LoRA utilize random initialization and o...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 15. Panoramic image stitching provides a unified, wide-angle view of a scene that extends beyond the camera's field of view. Stitching frames of a panning video into a panoramic photograph is a well-understood problem for stationary scenes, but when objects are moving, a still panorama cannot capture th...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 16. Evaluating large language models (LLMs) is costly: it requires the generation and examination of LLM outputs on a large-scale benchmark of various tasks. This paper investigates how to efficiently reduce the tasks used to benchmark LLMs without affecting the evaluation quality. Our study reveals tha...
[18.10.2024 06:17] ********************************************************************************
[18.10.2024 06:17] Abstract 17. Many students struggle with math word problems (MWPs), often finding it difficult to identify key information and select the appropriate mathematical operations.Schema-based instruction (SBI) is an evidence-based strategy that helps students categorize problems based on their structure, improving pr...
[18.10.2024 06:17] Read previous papers.
[18.10.2024 06:17] Generating reviews via LLM API.
[18.10.2024 06:17] Querying the API.
[18.10.2024 06:17] Got response. {
  "desc": "Статья представляет MixEval-X - первый многомодальный бенчмарк для оценки моделей ИИ в реальных задачах. Авторы предлагают новые методы для создания репрезентативных наборов тестов, охватывающих различные модальности ввода и вывода. Бенчмарк решает проблемы несогласованности стандартов оценки и различных видов смещений в существующих методах. Результаты показывают высокую корреляцию с оценками краудсорсинга в реальных сценариях использования.",
  "categories": ["#multimodal", "#benchmark", "#dataset"],
  "emoji": "🎭",
  "title": "MixEval-X: Универсальный бенчмарк для оценки многомодальных моделей ИИ"
}
[18.10.2024 06:17] Get embedding for a paper via LLM API.
[18.10.2024 06:17] Using data from previous issue: {"desc": "В статье представлен новый подход к улучшению понимания визуального контекста с текстом для мультимодальных больших языковых моделей. Авторы предлагают синтезировать инструкции из веб-интерфейсов с помощью текстовых языковых моделей. Создан датасет MultiUI, содержащий 7,3 миллиона образцов
[18.10.2024 06:17] Using data from previous issue: {"desc": "В статье представлена система MMed-RAG, разработанная для повышения фактической точности медицинских крупномасштабных моделей зрения и языка (Med-LVLMs). Система использует механизм поиска с учетом домена, адаптивный метод выбора найденных контекстов и стратегию дообучения на основе RAG. Э
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет новый подход к анализу дельта-параметров в пост-обучении моделей машинного обучения, основанный на аппроксимации Римана функции потерь. Авторы классифицируют существующие методы редактирования дельта-параметров на три категории в зависимости от их влияния на производите
[18.10.2024 06:17] Using data from previous issue: {"desc": "MovieGen - это набор фундаментальных моделей, генерирующих высококачественные видео в формате 1080p HD с синхронизированным аудио. Модели устанавливают новый уровень качества в нескольких задачах, включая синтез видео по тексту, персонализацию видео и генерацию аудио. Крупнейшая модель име
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет новый подход к выравниванию больших языковых моделей под названием PopAlign. Этот метод использует разнообразные контрастные паттерны на уровнях промпта, модели и пайплайна для улучшения данных о предпочтениях. PopAlign решает проблемы ограниченности традиционных методо
[18.10.2024 06:17] Using data from previous issue: {"desc": "DreamVideo-2 - это новая система для создания персонализированных видео без дополнительного обучения. Она использует одно изображение и последовательность ограничивающих рамок для генерации видео с заданным объектом и траекторией движения. Система вводит референсное внимание и маскированны
[18.10.2024 06:17] Using data from previous issue: {"desc": "FlatQuant - это новый подход к квантованию после обучения, направленный на улучшение сглаженности весов и активаций в больших языковых моделях (LLM). Метод использует оптимальные аффинные преобразования для каждого линейного слоя, калибруемые за часы с помощью облегченной целевой функции. 
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет новый подход DARAG для улучшения генеративной коррекции ошибок (GEC) в системах автоматического распознавания речи (ASR). DARAG использует синтетические данные, созданные с помощью языковых моделей и систем text-to-speech, для расширения обучающего набора данных. Метод 
[18.10.2024 06:17] Querying the API.
[18.10.2024 06:17] Got response. {
  "desc": "Статья представляет Janus - новую авторегрессивную модель для мультимодального понимания и генерации. В отличие от предыдущих подходов, Janus использует отдельные визуальные энкодеры для задач понимания и генерации, что позволяет оптимизировать работу модели. Единая архитектура трансформера обрабатывает данные от обоих энкодеров. Эксперименты показывают, что Janus превосходит предыдущие унифицированные модели и не уступает специализированным моделям для конкретных задач.",
  "categories": [
    "#multimodal",
    "#nlp",
    "#cv"
  ],
  "emoji": "🔀",
  "title": "Janus: единая модель для мультимодального понимания и генерации"
}
[18.10.2024 06:17] Get embedding for a paper via LLM API.
[18.10.2024 06:17] Querying the API.
[18.10.2024 06:17] Got response. {
  "desc": "Исследователи предлагают новый механизм внимания Mixture-of-Head (MoH), который улучшает эффективность многоголового внимания в трансформерах. MoH позволяет каждому токену выбирать подходящие головы внимания, повышая эффективность вывода без ущерба для точности. Эксперименты на ViT, DiT и языковых моделях показывают, что MoH превосходит стандартное многоголовое внимание, используя лишь 50-90% голов. Продолжительная настройка предобученных моделей, таких как LLaMA3-8B, с использованием MoH также демонстрирует значительное улучшение производительности.",
  "categories": ["#nlp", "#cv", "#rlhf"],
  "emoji": "🧠",
  "title": "Смешивание голов внимания для повышения эффективности трансформеров"
}
[18.10.2024 06:17] Get embedding for a paper via LLM API.
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет MedMobile - компактную языковую модель для медицинских приложений, способную работать на мобильных устройствах. Модель, основанная на phi-3-mini, имеет всего 3,8 миллиарда параметров, но демонстрирует впечатляющие результаты на тесте MedQA (USMLE), превосходя проходной 
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет комплексный анализ роли нелинейных операций в трансформерных языковых моделях декодер-только архитектуры. Авторы предлагают AERO - четырехэтапную структуру оптимизации архитектуры, которая систематически удаляет нелинейности, такие как LayerNorm и GELU, и сокращает коли
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет метод ReSpect, позволяющий языковым моделям (LLM) учиться на неявных сигналах обратной связи в ходе взаимодействия с пользователями. Авторы применяют ReSpect в сценарии мультимодального взаимодействия, где люди инструктируют LLM для решения задач абстрактного мышления. 
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет новый метод эффективной настройки параметров (PEFT) под названием LoLDU. Этот подход использует LDU-разложение для инициализации матриц низкого ранга, что обеспечивает более быструю сходимость и ортогональность. LoLDU значительно сокращает количество обучаемых параметро
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья представляет метод синтеза панорамного видео из обычного панорамного видео, снятого вручную. Авторы рассматривают задачу как проблему заполнения пространственно-временного объема, используя генеративные модели видео. Предложенный подход позволяет создавать видеопанорамы для различны
[18.10.2024 06:17] Using data from previous issue: {"desc": "Статья исследует методы эффективного сокращения количества задач для оценки больших языковых моделей (LLM) без ущерба для качества оценки. Авторы предлагают метрику для оценки переносимости между задачами с помощью обучения в контексте (ICL). Анализируя попарную переносимость, можно сократ
[18.10.2024 06:17] Querying the API.
[18.10.2024 06:17] Got response. {
  "desc": "Авторы предлагают новый подход к решению математических текстовых задач, называемый SBI-RAG (Schema-Based Instruction Retrieval-Augmented Generation). Этот метод сочетает в себе схемо-ориентированное обучение (SBI) и большую языковую модель (LLM) для пошагового рассуждения при решении задач. Авторы оценивают производительность SBI-RAG на наборе данных GSM8K, сравнивая его с GPT-4 и GPT-3.5 Turbo. Результаты показывают, что SBI-RAG улучшает ясность рассуждений и точность решения задач, что потенциально может принести пользу учащимся.",
  "categories": ["#nlp", "#rag", "#dataset", "#benchmark"],
  "emoji": "🧮",
  "title": "Схемы + ИИ = Лучшее решение математических задач"
}
[18.10.2024 06:17] Get embedding for a paper via LLM API.
[18.10.2024 06:17] Loading Chinese text from previous data.
[18.10.2024 06:17] Renaming data file.
[18.10.2024 06:17] Renaming previous data. hf_papers.json to 2024-10-17_hf_papers.json
[18.10.2024 06:17] Saving new data file.
[18.10.2024 06:17] Generating page.
[18.10.2024 06:17] Generating Chinese page for reading.
[18.10.2024 06:17] Chinese vocab [{'word': '编码', 'pinyin': 'biān mǎ', 'trans': 'coding'}, {'word': '任务', 'pinyin': 'rèn wù', 'trans': 'task'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluation'}, {'word': '大型', 'pinyin': 'dà xíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔ yán mó xíng', 'trans': 'language model'}, {'word': '高级', 'pinyin': 'gāo jí', 'trans': 'advanced'}, {'word': '指令', 'pinyin': 'zhǐ lìng', 'trans': 'instructions'}, {'word': '复杂', 'pinyin': 'fù zá', 'trans': 'complex'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '功能', 'pinyin': 'gōng néng', 'trans': 'functional'}, {'word': '程序', 'pinyin': 'chéng xù', 'trans': 'program'}, {'word': '多模态', 'pinyin': 'duō mó shuài', 'trans': 'multimodal'}, {'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'}, {'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'perception'}, {'word': '理解', 'pinyin': 'lǐ jiě', 'trans': 'understanding'}, {'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'}, {'word': '严格', 'pinyin': 'yán gé', 'trans': 'strict'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '强调', 'pinyin': 'qiáng diào', 'trans': 'emphasize'}, {'word': '空白', 'pinyin': 'kòng bái', 'trans': 'gap'}, {'word': '引入', 'pinyin': 'yǐn rù', 'trans': 'introduce'}, {'word': '专门', 'pinyin': 'zhuān mén', 'trans': 'specifically'}, {'word': '设计', 'pinyin': 'shè jì', 'trans': 'design'}, {'word': '用于', 'pinyin': 'yòng yú', 'trans': 'used for'}, {'word': '轻量级', 'pinyin': 'qīng liàng jí', 'trans': 'lightweight'}, {'word': '初级', 'pinyin': 'chū jí', 'trans': 'entry-level'}, {'word': '精心', 'pinyin': 'jīng xīn', 'trans': 'carefully'}, {'word': '视觉元素', 'pinyin': 'shì jué yuán sù', 'trans': 'visual elements'}, {'word': '详细', 'pinyin': 'xiáng xì', 'trans': 'detailed'}, {'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'}, {'word': '用例', 'pinyin': 'yòng lì', 'trans': 'case'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'find'}, {'word': '先进', 'pinyin': 'xiān jìn', 'trans': 'advanced'}, {'word': '面临', 'pinyin': 'miàn lín', 'trans': 'face'}, {'word': '重大', 'pinyin': 'zhòng dà', 'trans': 'major'}, {'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'}]
[18.10.2024 06:17] Renaming previous page.
[18.10.2024 06:17] Renaming previous data. index.html to 2024-10-17_hf_papers.html
[18.10.2024 06:17] Renaming previous Chinese page.
[18.10.2024 06:17] Renaming previous data. zh.html to 2024-10-17_zh_reading_task.html
[18.10.2024 06:17] Writing result.
[18.10.2024 06:17] Writing Chinese reading task.
[18.10.2024 06:17] Renaming log file.
[18.10.2024 06:17] Renaming previous data. log.txt to 2024-10-17_last_log.txt
