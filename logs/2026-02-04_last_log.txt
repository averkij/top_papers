[04.02.2026 04:15] Read previous papers.
[04.02.2026 04:15] Generating top page (month).
[04.02.2026 04:15] Writing top page (month).
[04.02.2026 05:43] Read previous papers.
[04.02.2026 05:43] Get feed.
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01785
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02660
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.02619
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02103
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03796
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01630
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03619
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03845
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.03419
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02380
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.03411
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02636
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02676
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2601.21244
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.00747
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.03786
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01362
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03048
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2601.19103
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03837
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.03806
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03454
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02914
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.02419
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02537
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03647
[04.02.2026 05:43] Extract page data from URL. URL: https://huggingface.co/papers/2602.03139
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.01753
[04.02.2026 05:43] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03817
[04.02.2026 05:43] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[04.02.2026 05:43] No deleted papers detected.
[04.02.2026 05:43] Downloading and parsing papers (pdf, html). Total: 29.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.01785.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.01785.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.01785.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.02660.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.02660.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.02660.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.02619.
[04.02.2026 05:43] Downloading paper 2602.02619 from https://arxiv.org/pdf/2602.02619v1...
[04.02.2026 05:43] Extracting affiliations from text.
[04.02.2026 05:43] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently Mohan Jiang1,2,4 Dayuan Fu1,4 Junhao Shi1,2,4 Ji Zeng2,4 Weiye Si2,4 Keyu Li1,2,4 Xuefeng Li1,2,4 Yang Xiao3,4 Wenjie Li3 Dequan Wang1,2 Pengfei Liu1,2,4 1SII Open Source: Code 2SJTU 3PolyU 4GAIR Models ı Datasets "
[04.02.2026 05:43] Response: ```python
[
    "SII Open Source",
    "SJTU",
    "PolyU",
    "GAIR"
]
```
[04.02.2026 05:43] Deleting PDF ./assets/pdf/2602.02619.pdf.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.02103.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.02103.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.02103.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03796.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.03796.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.03796.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.01630.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.01630.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.01630.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03619.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.03619.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.03619.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03845.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.03845.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.03845.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03419.
[04.02.2026 05:43] Downloading paper 2602.03419 from https://arxiv.org/pdf/2602.03419v1...
[04.02.2026 05:43] Extracting affiliations from text.
[04.02.2026 05:43] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 3 ] . [ 1 9 1 4 3 0 . 2 0 6 2 : r SWE-World: Building Software Engineering Agents in Docker-Free Environments Shuang Sun1, Huatong Song1, Lisheng Huang1, Jinhao Jiang1, Ran Le2, Zhihao Lv1, Zongchao Chen2, Yiwen Hu1, Wenyang Luo1, Wayne Xin Zhao1, Yang Song2, Hongteng Xu1, Tao Zhang2, Ji-Rong Wen1 1Gaoling School of Artificial Intelligence, Renmin University of China. 2BOSS Zhipin, Beijing, China. sunshuang@ruc.edu.cn, batmanfly@gmail.com, songyang@kanzhun.com Abstract Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWEWorld, Docker-free framework that replaces physical execution environments with learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agentenvironment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agentenvironment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2% to 52.0% via Docker-free SFT, 55.0% with Docker-free RL, and 68.2% with further TTS. "
[04.02.2026 05:43] Response: ```python
[
    "Gaoling School of Artificial Intelligence, Renmin University of China",
    "BOSS Zhipin, Beijing, China"
]
```
[04.02.2026 05:43] Deleting PDF ./assets/pdf/2602.03419.pdf.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.02380.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.02380.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.02380.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03411.
[04.02.2026 05:43] Downloading paper 2602.03411 from https://arxiv.org/pdf/2602.03411v1...
[04.02.2026 05:43] Extracting affiliations from text.
[04.02.2026 05:43] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training Huatong Song1, Lisheng Huang1, Shuang Sun1, Jinhao Jiang1, Ran Le2, Daixuan Cheng1, Guoxin Chen1, Yiwen Hu1, Zongchao Chen2, Wayne Xin Zhao1, Yang Song2, Tao Zhang2, Ji-Rong Wen1 1Gaoling School of Artificial Intelligence, Renmin University of China. 2BOSS Zhipin, Beijing, China. songhuatong123@ruc.edu.cn, batmanfly@gmail.com, songyang@kanzhun.com Abstract In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves resolve rate of 61.4% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling (TTS) with LLM-based environment feedback, SWE-Master reaches 70.8% at TTS@8, demonstrating strong performance potential. SWE-Master provides practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master. 6 2 0 2 3 ] . [ 1 1 1 4 3 0 . 2 0 6 2 : r Figure 1: Performance overview and scaling analysis of SWE-Master. Left: Comparasion of the perference of various open-source foundational models and SWE agents on SWE-bench Verified. Right: Performance of SWE-Master across different training stages and evaluation metrics. Equal contribution. Correspondenc"
[04.02.2026 05:43] Response: ```python
[
    "Gaoling School of Artificial Intelligence, Renmin University of China",
    "BOSS Zhipin, Beijing, China"
]
```
[04.02.2026 05:43] Deleting PDF ./assets/pdf/2602.03411.pdf.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.02636.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.02636.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.02636.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.02676.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.02676.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.02676.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2601.21244.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2601.21244.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2601.21244.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.00747.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.00747.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.00747.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03786.
[04.02.2026 05:43] Downloading paper 2602.03786 from https://arxiv.org/pdf/2602.03786v1...
[04.02.2026 05:43] Extracting affiliations from text.
[04.02.2026 05:43] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"AORCHESTRA: Automating Sub-Agent Creation for Agentic Orchestration Jianhao Ruan 1 2 Zhihao Xu 3 Yiran Peng 1 Fashen Ren 2 Zhaoyang Yu 1 Xinbing Liang 4 Jinyu Xiang 2 Bang Liu 5 Chenglin Wu 1 Yuyu Luo 2 Jiayi Zhang "
[04.02.2026 05:43] Response: ```python
[]
```
[04.02.2026 05:43] Extracting affiliations from text.
[04.02.2026 05:43] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"AORCHESTRA: Automating Sub-Agent Creation for Agentic Orchestration Jianhao Ruan 1 2 Zhihao Xu 3 Yiran Peng 1 Fashen Ren 2 Zhaoyang Yu 1 Xinbing Liang 4 Jinyu Xiang 2 Bang Liu 5 Chenglin Wu 1 Yuyu Luo 2 Jiayi ZhangLanguage agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of sub-agent-as-tools paradigm for multiturn task solving. However, existing designs still lack dynamic abstraction view of subagents, thereby hurting adaptability. We address this challenge with unified, framework-agnostic agent abstraction that models any agent as tuple Instruction, Context, ools, odel. This tuple acts as compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AORCHESTRA, where the central orchestrator concretizes the tuple at each step: it curates taskrelevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables controllable performancecost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, TerminalBench), AORCHESTRA achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/ FoundationAgents/AOrchestra 6 2 0 2 3 ] . [ 1 6 8 7 3 0 . 2 0 6 2 : r 1. Introduction Humans handle complex, long-horizon work via collective intelligence and the ability to coordinate (Gao et al., 2025a; Zhu et al., 2025b; Li et al., 2025a). As todays agents are pushed toward similarly complex and multi-turn 1DeepWisdom 2HKUST(GZ) 3RUC 4ECNU 5UdeM & Mila. Correspondence to: Yuyu Luo <yuyuluo@hkust-gz.edu.cn>, Jiayi Zhang <jzhang361@connect.hkust-gz.edu.cn>. Preprint. February 4, 2026. 1 Figure 1. Overall performance on three challenging agentic benchmarks (GAIA, Terminal-Bench-2, SWE-Bench-Verified) paired with Gemini-3-Flash when comparing AORCHESTRA against other popular agentic frameworks. tasks (Yao et al., 2024; Zhang et al., 2025a; Xu et al., 2026), well-designed agentic system becomes vital way to scale performance beyond single model (Liu et al., 2025b). To cope with increasingly complex scenarios, early attempts rely on fixed coordination workflows or multi-agent systems (Hong et al., 2023; Hu et al., 2025; Li et al., 2025a). While multi-agent collaboration can improve task decomposition, in open-ended environments it often incurs substantial coordination overhead and provides limited control over context routing, leading to either noisy over-sharing or harmful omission of critical information, which makes robust long-horizon execution difficult (Gao et al., 2025b). More recent approaches therefore move toward more practical sub-agent-as-tools paradigm, where main agent (orchestrator) delegates task to sub-agent via an explicit tool call. Yet existing designs still lack flexibility in practice and often degenerate into two limited patterns, which are shown in Figure 2: (1) Sub-agents as context-isolation threads. Systems such as Schroeder et al. (2025); Sun et al. (2025) primarily treat sub-agents as isolated context threads, aiming to prevent context rot (Hong et al., 2025). However, in real-world tasks, subtasks often require specialized capabilities. Therefore, such systems fail to fully realize the potential of specialized sub-agents. (2) Sub-agents as static roles. Systems such as Anthropic (2025); Li et al. (2025c) AORCHESTRA: Automating Sub-Agent Creation for Agentic Orchestration Figure 2. Comparison of sub-agent-as-tools approaches. (a) Sub-agents as context-isolated threads mitigate context rot but lack ondemand specialization. (b) Sub-agents as static roles provide specialized capabilities but are inflexible, leave coverage gaps, and require heavy human engineering. (c) Our Sub-agents as on-demand specialization concretizes unified 4-tuple abstraction (INSTRUCTION, CONTEXT, TOOLS, MODEL) to enable creating tailored executors on the fly. treat each sub-agent as static role, and their capabilities or their coordination patterns are typically hard-wired. pre-defined set of sub-agents cannot cover the dynamically emerging variety of subtasks in open environments. Besides, it relies on heavy human engineering, making the system difficult to adapt to various environments. In this paper, we introduce AORCHESTRA, an agentic framework designed to tackle long-horizon and complex tasks. Our core insight lies in treating sub-agents through the lens of on-demand specialization, as illustrated in Figure 2(c). We posit that sub-agent should be viewed as flexible abstraction unit rather than predefined, fixed role. This approach enables the system to instantiate tailored sub-agents at runtime by dynamically composing their capabilities to meet specific task demandsan essential feature. Concretely, any agent can be described as an instantiable unit via unified four-tuple: (INSTRUCTION, CONTEXT, TOOLS, MODEL). This specialization is organized around two complementary axes essential for an agents task solving: (1) Working memory (instruction, context): what the agent must achieve and what evidence it should condition on. Notably, the context attribute is designed to inject only the most relevant information for the current sub-task, filtering out potentially distracting details. (2) Capabilities (tools, model): what the agent is empowered to do to accomplish that objective. By composing specific tools and models on per-subtask basis, we endow each sub-agent with precise, task-specific functionality. Together, this 4-tuple design enables an automatic specialized sub-agent for each task. Building on this on-demand specialization view, we further introduce dedicated orchestrator that operates directly over the four-tuple interface to automatically create tailored sub-agents on the fly. It does not execute any tasks and focuses exclusively on orchestration, where we define it as dynamically decomposing the overall objective into the next subtask, creating and delegating specialized tailored sub-agent for task execution via explicit tool calls. This decoupling design offers several key advantages. First, this dynamic creation allows each sub-agent to be cu"
[04.02.2026 05:43] Mistral response. {"id": "a7dc4957fa884e6e8dd864ec4132f5d1", "created": 1770183837, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1565, "total_tokens": 1605, "completion_tokens": 40, "num_cached_tokens": 1564}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"DeepWisdom\",\n    \"HKUST(GZ)\",\n    \"RUC\",\n    \"ECNU\",\n    \"UdeM & Mila\"\n]\n```"}}]}
[04.02.2026 05:43] Response: ```python
[
    "DeepWisdom",
    "HKUST(GZ)",
    "RUC",
    "ECNU",
    "UdeM & Mila"
]
```
[04.02.2026 05:43] Deleting PDF ./assets/pdf/2602.03786.pdf.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.01362.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.01362.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.01362.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03048.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.03048.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.03048.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2601.19103.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2601.19103.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2601.19103.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03837.
[04.02.2026 05:43] Extra JSON file exists (./assets/json/2602.03837.json), skip PDF parsing.
[04.02.2026 05:43] Paper image links file exists (./assets/img_data/2602.03837.json), skip HTML parsing.
[04.02.2026 05:43] Success.
[04.02.2026 05:43] Downloading and parsing paper https://huggingface.co/papers/2602.03806.
[04.02.2026 05:43] Downloading paper 2602.03806 from https://arxiv.org/pdf/2602.03806v1...
[04.02.2026 05:44] Extracting affiliations from text.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation Ziru Chen 1 Dongdong Chen 2 Ruinan Jin 1 Yingbin Liang 1 Yujia Xie 2 Huan Sun "
[04.02.2026 05:44] Response: ```python
[]
```
[04.02.2026 05:44] Extracting affiliations from text.
[04.02.2026 05:44] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation Ziru Chen 1 Dongdong Chen 2 Ruinan Jin 1 Yingbin Liang 1 Yujia Xie 2 Huan SunRecently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (COBALT), new method that combines the benefits of online and offline RL. COBALT first collects code generation trajectories using reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. COBALT outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs incontext reward hacking behaviors and augment COBALT training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate COBALT as promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available here. 6 2 0 2 3 ] . [ 1 6 0 8 3 0 . 2 0 6 2 : r 1. Introduction Programming is no longer confined to writing code line by line. With large language models (LLMs), developers can now describe their intents in natural language and let LLMs generate, revise, and debug programs autonomously. *Work started during internship at Microsoft. Equal ad2Microsoft. Corresponvising. dence to: Ziru Chen <chen.8336@osu.edu>, Yujia Xie <yujiaxie@microsoft.com>, Huan Sun <sun.397@osu.edu>. 1The Ohio State University. Preprint. February 4, 2026. 1 Enabled by advances in reasoning (OpenAI et al., 2024; Guo et al., 2025) and self-improving LLMs (Chen et al., 2024; Novikov et al., 2025), this shift has propelled reinforcement learning (RL) to the forefront as promising way to train LLMs as multi-turn code-generation agents. Many RL methods (Schulman et al., 2017; Shao et al., 2024) typically follow an online learning paradigm, where model iteratively interacts with the environment based on its latest weights, collects new batch of experiences, and optimizes its performance on this batch (Sutton & Barto, 2018). While these online methods show impressive performance, they can be expensive and unstable to train an LLM. For instance, Gehring et al. (2025) trains an 8B multi-turn code generation LLM using 288 GPUs, an amount of resources that is costly and inaccessible outside large companies. Meanwhile, Deng et al. (2025) and Xue et al. (2025) report learning collapse and gradient explosion when training LLMs for multi-turn tool-integrated reasoning. As an alternative to online methods, offline RL methods are more cost-effective and stable, but usually yields less performant models due to distributional shifts and lack of exploration (Levine et al., 2020). Can we combine the benefits of online and offline RL? In this paper, we formulate multi-turn code generation as one-step recoverable MDP (Jain et al., 2025a) and propose contextual bandit learning with offline trajectories (COBALT) to train self-improving LLMs. COBALT first uses reference LLM to generate multi-turn trajectories, akin to offline RL data collection, and divides them into partial trajectories. During online learning, COBALT prompts the LLM to complete each partial trajectory with single-step code generation and samples different programs as its contextual bandit actions. The model is then optimized to maximize the rewards of its generated programs. This way, we decouple the trajectory data generation process from the online training loop, thus improving training efficiency and lowering cost. Also, we conduct theoretical analysis and show that compared to the online multi-turn RL objective, the stepwise objective of COBALT gives linear performance difference bound. Moreover, we augment COBALT to be more robust to notorious problem, in-context reward hacking (McKee-Reid et al., 2024; Pan et al., 2024a;b). When we insert incorrect test case results as noisy observations into the trajectories, Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation Figure 1. multi-turn code generation example with four public test cases (two correct and two incorrect) and 16 hidden test cases. The LLM starts with the coding problem and generates program. It passes all benign public tests and hidden tests, while failing the two perturbed tests. As result, one of the failed test case is returned as feedback. All other test cases and their pass rates are hidden. The LLM mistakenly follows the feedback and changes its program, which now passes the perturbed test case but only one hidden test case. we find that LLMs sometimes give up correct program and modify it for reward hacking (Figure 1). With systematic analysis, we show that such behaviors consistently exist in open-weight and proprietary LLMs, such as hard coding wrong input-output pairs or violating some problem constraints. Thus, we hypothesize that these issues are partly induced by RL as an alignment tax (Lin et al., 2024; MacDiarmid et al., 2025; Wen et al., 2025) and augment COBALTs offline trajectories with perturbation to improve LLMs robustness against inaccurate test cases. This flexibility of modifying trajectory data to guide online learning is another advantage of COBALT over online RL. Through comprehensive experiments on TACO (Li et al., 2023) and LiveCodeBench (Jain et al., 2025b), we demonstrate the effectiveness of COBALT. On LiveCodeBench, COBALT improves Pass@1 to 31.7 for R1-Distill 8B and 38.5 for Qwen3 8B, yielding absolute gains of 9.0 and 6.2 points over their base models. When compared to two strong online multi-turn RL baselines based on GRPO and VeRPO (Wang et al., 2026), COBALT also outperforms both baselines in the multi-turn setting. Despite being trained with limited number of turns (e.g., ttrain 3), both models show strong generalization to longer horizons at test time and continue to improve their performance beyond those turns. Besides, adding"
[04.02.2026 05:44] Mistral response. {"id": "b0139d31ca0340ddb31347b5c834d10f", "created": 1770183846, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1596, "total_tokens": 1610, "completion_tokens": 14, "num_cached_tokens": 1595}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Microsoft\", \"The Ohio State University\"]\n```"}}]}
[04.02.2026 05:44] Response: ```python
["Microsoft", "The Ohio State University"]
```
[04.02.2026 05:44] Deleting PDF ./assets/pdf/2602.03806.pdf.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.03454.
[04.02.2026 05:44] Extra JSON file exists (./assets/json/2602.03454.json), skip PDF parsing.
[04.02.2026 05:44] Paper image links file exists (./assets/img_data/2602.03454.json), skip HTML parsing.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.02914.
[04.02.2026 05:44] Extra JSON file exists (./assets/json/2602.02914.json), skip PDF parsing.
[04.02.2026 05:44] Paper image links file exists (./assets/img_data/2602.02914.json), skip HTML parsing.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.02419.
[04.02.2026 05:44] Downloading paper 2602.02419 from https://arxiv.org/pdf/2602.02419v2...
[04.02.2026 05:44] Extracting affiliations from text.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Qingni Wang * 1 2 Yue Fan * 2 Xin Eric Wang "
[04.02.2026 05:44] Response: ```python
[]
```
[04.02.2026 05:44] Extracting affiliations from text.
[04.02.2026 05:44] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Qingni Wang * 1 2 Yue Fan * 2 Xin Eric WangGraphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SAFEGROUND, an uncertaintyaware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SAFEGROUND leverages distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SAFEGROUND derives test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SAFEGROUND on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial systemlevel accuracy improvements. Across multiple GUI grounding models, SAFEGROUND improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference. 6 2 0 2 3 ] . [ 2 9 1 4 2 0 . 2 0 6 2 : r 1. Introduction Graphical User Interface (GUI) grounding is critical component for autonomous GUI agents, enabling visionlanguage models (VLMs) to translate natural language in- *Equal contribution 1University of California, Santa Barbara 2University of California, Santa Cruz. Correspondence to: Xin Eric Wang <ericxwang@ucsb.edu>. Preprint. February 4, 2026. 1 Figure 1. While existing models may commit costly errors on hard-to-undo actions (e.g., checkout), SAFEGROUND detects high uncertainty and defers the decision via cascading. This mechanism explicitly limits the risk of erroneous actions to user-specified tolerance. structions into executable screen coordinates (Nguyen et al., 2025; Cheng et al., 2024). Recent advances have substantially improved grounding accuracy across diverse GUI environments, making it increasingly feasible to deploy such agents in real-world applications (Fan et al., 2025; Hong et al., 2024). However, in practical GUI interactions, single incorrect grounding can trigger costly and hardto-reverse actions, including erroneous payment approvals or irreversible system configurations (Zhang et al., 2025). Despite these risks, existing GUI grounding models typically output only point predictions, offering no indication of when prediction is unreliable or should be deferred (Gawlikowski et al., 2022; Hu et al., 2023) as shown in Figure 1. The aforementioned limitation of existing GUI grounding models motivates the incorporation of uncertainty quantification (UQ) to enable safer decision-making. However, existing UQ techniques are poorly suited for GUI grounding and remain largely underexplored in this setting (Zhang et al., 2025). In particular, prior approaches suffer from several key limitations. (1) Uncertainty derived from model probabilities or logits (Hendrycks & Gimpel, 2017) assumes access to internal model states, making it infeasible for SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration Figure 2. Overview of SAFEGROUND. Given GUI input, the model performs multiple stochastic grounding samples to estimate predictive uncertainty. An uncertainty threshold τ is calibrated on held-out set under user-specified risk level (i.e, the maximum error rate). At test time, predictions with uncertainty τ are executed directly, while high-uncertainty cases are abstained or cascaded. Low-uncertainty cases exhibit concentrated region scores, low entropy, and low variance, whereas high-uncertainty cases show dispersed predictions and trigger safety-aware deferral. black-box vision-language models commonly used in GUI agents (Ye et al., 2024; Wang et al., 2025b). (2) Verbalized self-assessment (Kadavath et al., 2022) relies on strong instruction-following behavior and often fails when models do not explicitly reason about confidence. (3) Approaches that estimate uncertainty using ground-truth regions, such as Zhang et al. (2025), require annotation and cannot be applied at inference time. (4) Existing methods focus on producing uncertainty scores alone, without specifying how predictions should be acted upon at deployment time (e.g., whether to accept, defer, or abstain) despite this decision being critical in high-stakes GUI interactions (Geifman & El-Yaniv, 2017; Wang et al., 2025c). Collectively, these limitations expose clear gap between existing UQ approaches and the practical requirements of GUI grounding, where uncertainty must be reliable under limited model access and without test-time supervision (Lin et al., 2023). To address these challenges, we introduce SAFEGROUND, an uncertainty-aware framework that enables risk-aware predictions for existing state-of-the-art GUI grounding models, without requiring access to model internals. Concretely, as shown in Figure 2, SAFEGROUND first quantifies the predictive uncertainty of grounding outputs from the spatial distribution of multiple stochastic grounding samples from the same model. Then, given the model outputs with estimated uncertainty, we adopt Learn Then Test (LTT) calibration paradigm to select decision threshold that rigorously controls the false discovery rate (FDR) of accepted grounding predictions. This calibration procedure provides finite-sample guarantees: with high probability, the proportion of incorrect predictions among all accepted actions does not exceed user-specified risk level α. At inference time, SAFEGROUND enables principled selective prediction mechanism. Predictions deemed reliable under the calibrated threshold are executed directly, while highuncertainty cases are abstained from or deferred to stronger models for further processing. Furthermore, with the selective prediction, we realized the cascading inference, where even when the primary models base accuracy is limited, we can further leverage external resource to aid the prediction, achieving strong system-level accurarcy. We evaluate SAFEGROUND on the challenging ScreenSpotPro benchmark across multiple state-of-the-art GUI grounding"
[04.02.2026 05:44] Mistral response. {"id": "71dcaaee7d984f338370b1d4cfd07534", "created": 1770183852, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1417, "total_tokens": 1438, "completion_tokens": 21, "num_cached_tokens": 1416}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"University of California, Santa Barbara\", \"University of California, Santa Cruz\"]\n```"}}]}
[04.02.2026 05:44] Response: ```python
["University of California, Santa Barbara", "University of California, Santa Cruz"]
```
[04.02.2026 05:44] Deleting PDF ./assets/pdf/2602.02419.pdf.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.02537.
[04.02.2026 05:44] Extra JSON file exists (./assets/json/2602.02537.json), skip PDF parsing.
[04.02.2026 05:44] Paper image links file exists (./assets/img_data/2602.02537.json), skip HTML parsing.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.03647.
[04.02.2026 05:44] Extra JSON file exists (./assets/json/2602.03647.json), skip PDF parsing.
[04.02.2026 05:44] Paper image links file exists (./assets/img_data/2602.03647.json), skip HTML parsing.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.03139.
[04.02.2026 05:44] Downloading paper 2602.03139 from https://arxiv.org/pdf/2602.03139v1...
[04.02.2026 05:44] Extracting affiliations from text.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis Tianhe Wu * 1 3 Ruibin Li * 2 Lei Zhang 2 3 Kede Ma 1 https://github.com/Multimedia-Analytics-Laboratory/dpdmd 6 2 0 2 3 ] . [ 1 9 3 1 3 0 . 2 0 6 2 : r (a) SD3.5-M (60 NFEs) (b) DMD (4 NFEs) (c) DP-DMD (Ours, 4 NFEs) Figure 1. DP-DMD preserves image diversity while maintaining competitive visual quality. All results are generated under identical text conditioning (A smiling woman with red hair, green eyes, and dimples.) with different random initial noise. (a) SD3.5-M (Esser et al., 2024) sampled with 30 steps (60 NFEs) serves as the teacher model (upper bound). (b) DMD (Yin et al., 2024a) and (c) DP-DMD are step-distilled student models, both evaluated using only 4 NFEs. "
[04.02.2026 05:44] Response: ```python
[
    "Multimedia-Analytics-Laboratory"
]
```
[04.02.2026 05:44] Deleting PDF ./assets/pdf/2602.03139.pdf.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.01753.
[04.02.2026 05:44] Extra JSON file exists (./assets/json/2602.01753.json), skip PDF parsing.
[04.02.2026 05:44] Paper image links file exists (./assets/img_data/2602.01753.json), skip HTML parsing.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Downloading and parsing paper https://huggingface.co/papers/2602.03817.
[04.02.2026 05:44] Extra JSON file exists (./assets/json/2602.03817.json), skip PDF parsing.
[04.02.2026 05:44] Paper image links file exists (./assets/img_data/2602.03817.json), skip HTML parsing.
[04.02.2026 05:44] Success.
[04.02.2026 05:44] Enriching papers with extra data.
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 0. Multimodal large language models can effectively understand source code when represented as compressed images, achieving significant token reduction while maintaining or improving performance on code comprehension tasks.  					AI-generated summary 				 Large Language Models (LLMs) have achieved rema...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 1. MARS is a modular AI research automation framework that uses budget-aware planning, modular construction, and reflective memory to achieve state-of-the-art performance in autonomous machine learning research.  					AI-generated summary 				 Automating AI research differs from general software engine...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 2. Large language models face challenges in long-horizon agentic workflows due to lack of authentic long-dependency training data, which is addressed by leveraging pull request sequences for structured supervision through progressive decomposition, consistency enforcement, and refinement from bug-fix h...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 3. Research investigates latent planning dynamics in large language models through a probing method called Tele-Lens, revealing limited global planning and enabling improved uncertainty estimation and CoT bypass recognition.  					AI-generated summary 				 This work stems from prior complementary obser...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 4. 3DiMo enables view-agnostic human motion control in video generation by training a motion encoder alongside a pretrained video generator to distill driving frames into compact motion tokens that align with the generator's spatial priors.  					AI-generated summary 				 Existing methods for human mot...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 5. Current world models lack unified frameworks despite task-specific advances, necessitating a comprehensive approach integrating interaction, perception, symbolic reasoning, and spatial representation.  					AI-generated summary 				 World models have emerged as a critical frontier in AI research, ai...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 6. DeepResearch report generation is improved through human-preference-aligned rubric generators trained via reinforcement learning with hybrid rewards and enhanced with multi-agent Markov-state workflows.  					AI-generated summary 				 Nowadays, training and evaluating DeepResearch-generated reports ...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 7. Parallel-Probe is a training-free controller that optimizes parallel thinking by using consensus-based early stopping and deviation-based branch pruning to reduce computational costs while maintaining accuracy.  					AI-generated summary 				 Parallel thinking has emerged as a promising paradigm for...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 8. A Docker-free framework replaces physical execution environments with learned surrogates for training software engineering agents, enabling efficient training and test-time scaling without costly container setup.  					AI-generated summary 				 Recent advances in large language models (LLMs) have en...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 9. UnifiedReward-Flex combines reward modeling with flexible, context-adaptive reasoning to improve visual generation by dynamically constructing hierarchical assessments based on semantic intent and visual evidence.  					AI-generated summary 				 Recent advancements in multimodal reward models (RMs) ...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 10. SWE-Master presents a reproducible framework for developing software engineering agents through systematic optimization across multiple stages of agent development, achieving superior performance on software task resolution benchmarks.  					AI-generated summary 				 In this technical report, we pre...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 11. Wide Research advances search intelligence through a dedicated benchmark and multi-agent architecture that enables parallel information retrieval under complex constraints.  					AI-generated summary 				 Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for r...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 12. AdaptMMBench presents a comprehensive benchmark for evaluating adaptive multimodal reasoning in Vision-Language Models, measuring reasoning mode selection rationality through dynamic difficulty assessment and multi-dimensional process evaluation.  					AI-generated summary 				 Adaptive multimodal r...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 13. LENS framework improves reinforcement learning with verifiable rewards by identifying and removing interference tokens to enhance exploration efficiency and training stability.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has advanced LLM reasoning, but remai...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 14. DeMix is a framework that uses model merging to predict optimal data ratios for LLM pre-training, decoupling search from training costs to improve mixture discovery efficiency.  					AI-generated summary 				 Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-tra...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 15. AOrchestra is a framework-agnostic agentic system that uses a tuple-based abstraction to dynamically create specialized task executors, achieving improved performance on complex benchmarks through automated agent creation and resource management.  					AI-generated summary 				 Language agents have ...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 16. XDLM unifies Masked Diffusion Language Models and Uniform-noise Diffusion Language Models through a stationary noise kernel, achieving improved performance in both semantic understanding and generation quality.  					AI-generated summary 				 In discrete generative modeling, two dominant paradigms d...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 17. CoBA-RL adapts rollout budget allocation for LLM training by evaluating sample training value and optimizing resource distribution through a capability-oriented value function and greedy strategy.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a ...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 18. A reinforcement learning framework with glance and focus models improves pan-cancer screening in CT scans by addressing foreground-background imbalance and reducing false positives through group relative learning.  					AI-generated summary 				 Pan-cancer screening in large-scale CT scans remains c...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 19. Advanced AI models demonstrate capability in supporting expert-level mathematical discovery and scientific research through collaborative approaches involving proof verification and automated code execution.  					AI-generated summary 				 Recent advances in large language models (LLMs) have opened ...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 20. Offline reinforcement learning method combines contextual bandit learning with partial trajectories to improve multi-turn code generation performance while reducing training costs.  					AI-generated summary 				 Recently, there have been significant research interests in training large language mod...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 21. CoViP addresses contextualized visual personalization by treating personalized image captioning as a core task and improving capabilities through reinforcement-learning-based post-training and caption-augmented generation.  					AI-generated summary 				 Despite recent progress in vision-language mo...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 22. FaceLinkGen attack demonstrates that current privacy-preserving face recognition methods fail to protect identity information despite pixel-level distortion metrics suggesting adequate protection.  					AI-generated summary 				 Transformation-based privacy-preserving face recognition (PPFR) aims to...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 23. SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates.  					AI-generated summary 				 Graphical User Interface (GUI) grounding aims to transl...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 24. WorldVQA is a benchmark for evaluating the visual world knowledge of multimodal large language models by separating visual knowledge retrieval from reasoning to measure memorized facts.  					AI-generated summary 				 We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world kn...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 25. Search-R2 framework improves language agent reasoning through Actor-Refiner collaboration with targeted interventions and fine-grained reward supervision for better credit assignment in reinforcement learning.  					AI-generated summary 				 Search-integrated reasoning enables language agents to tra...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 26. A novel distillation framework called DP-DMD is introduced that preserves sample diversity in text-to-image generation by separating the roles of distilled steps, using v-prediction for diversity and standard DMD loss for quality refinement without additional computational overhead.  					AI-generat...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 27. ObjEmbed is a novel multimodal language-model embedding approach that decomposes images into regional embeddings for improved object-level visual understanding and retrieval tasks.  					AI-generated summary 				 Aligning objects with corresponding textual descriptions is a fundamental challenge and...
[04.02.2026 05:44] ********************************************************************************
[04.02.2026 05:44] Abstract 28. A fusion framework called FINCH combines audio and spatiotemporal predictors for bioacoustic classification by adaptively weighting evidence based on reliability estimates, outperforming fixed-weight methods and audio-only approaches.  					AI-generated summary 				 Many machine learning systems hav...
[04.02.2026 05:44] Read previous papers.
[04.02.2026 05:44] Generating reviews via LLM API.
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#plp", "#multimodal", "#inference"], "emoji": "🖼️", "ru": {"title": "Код как изображение: сжатие и эффективность", "desc": "В статье исследуется применение многомодальных больших языковых моделей (MLLM) для понимания исходного кода, представленного в виде сжатых изображений вместо т
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#training", "#agents", "#open_source", "#science", "#benchmark"], "emoji": "🔬", "ru": {"title": "Модульный агент с рефлексивной памятью для экономного автоматизированного ML-исследования", "desc": "MARS — это модульный фреймворк для автоматизации исследований в области машинного обу
[04.02.2026 05:44] Querying the API.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models face challenges in long-horizon agentic workflows due to lack of authentic long-dependency training data, which is addressed by leveraging pull request sequences for structured supervision through progressive decomposition, consistency enforcement, and refinement from bug-fix histories.  					AI-generated summary 				 While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms...
[04.02.2026 05:44] Response: ```json
{
  "desc": "Статья описывает проблему обучения больших языковых моделей для долгосрочных агентических задач, которые требуют понимания сложных зависимостей между шагами. Авторы предлагают решение через использование последовательностей pull request из реальной разработки программного обеспечения, которые содержат естественные сигналы обучения. Метод daVinci-Agency извлекает структурированное обучающие данные из цепочек PR через три механизма: прогрессивную декомпозицию задач, обеспечение долгосрочной согласованности и верификацию рефинирования через истории исправлений ошибок. Результаты показывают, что даже небольшое количество примеров (239 образцов) позволяет значительно улучшить производительность моделей на различных бенчмарках.",
  "emoji": "🔄",
  "title": "От кода к агентам: синтез долгосрочного обучения из истории разработки"
}
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models face challenges in long-horizon agentic workflows due to lack of authentic long-dependency training data, which is addressed by leveraging pull request sequences for structured supervision through progressive decomposition, consistency enforcement, and refinement from bug-fix histories.  					AI-generated summary 				 While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms..."

[04.02.2026 05:44] Response: ```python
['AGENTS', 'DATA', 'TRAINING']
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large language models face challenges in long-horizon agentic workflows due to lack of authentic long-dependency training data, which is addressed by leveraging pull request sequences for structured supervision through progressive decomposition, consistency enforcement, and refinement from bug-fix histories.  					AI-generated summary 				 While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms..."

[04.02.2026 05:44] Response: ```python
['SYNTHETIC', 'LONG_CONTEXT', 'REASONING', 'ALIGNMENT']
```
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the limitations of large language models (LLMs) in handling long-horizon tasks due to insufficient training data that captures long-term dependencies. The authors propose a novel approach called daVinci-Agency, which utilizes pull request sequences from software development as a source of structured supervision. By breaking down complex tasks into manageable units and enforcing consistency through real-world bug-fix histories, the model learns to maintain functional coherence over time. The results show that fine-tuning on this data significantly improves the model\'s performance on various benchmarks, demonstrating the effectiveness of leveraging authentic software evolution data for training.","title":"Harnessing Pull Requests for Long-Horizon Learning in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper addresses the limitations of large language models (LLMs) in handling long-horizon tasks due to insufficient training data that captures long-term dependencies. The authors propose a novel approach called daVinci-Agency, which utilizes pull request sequences from software development as a source of structured supervision. By breaking down complex tasks into manageable units and enforcing consistency through real-world bug-fix histories, the model learns to maintain functional coherence over time. The results show that fine-tuning on this data significantly improves the model's performance on various benchmarks, demonstrating the effectiveness of leveraging authentic software evolution data for training.", title='Harnessing Pull Requests for Long-Horizon Learning in LLMs'))
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型在处理长时间跨度的任务时面临挑战，主要是因为缺乏真实的长依赖训练数据。本文提出通过利用拉取请求序列来获取结构化监督，从而解决这一问题。我们的方法包括逐步分解复杂目标、强制一致性以及从错误修复历史中提炼信息。最终，我们的模型daVinci-Agency能够有效地学习长期目标导向行为，并在多个基准测试中显著提升性能。","title":"利用拉取请求提升长依赖学习的效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型在处理长时间跨度的任务时面临挑战，主要是因为缺乏真实的长依赖训练数据。本文提出通过利用拉取请求序列来获取结构化监督，从而解决这一问题。我们的方法包括逐步分解复杂目标、强制一致性以及从错误修复历史中提炼信息。最终，我们的模型daVinci-Agency能够有效地学习长期目标导向行为，并在多个基准测试中显著提升性能。', title='利用拉取请求提升长依赖学习的效率'))
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#reasoning", "#training", "#open_source", "#interpretability", "#benchmark"], "emoji": "🔍", "ru": {"title": "Скрытое планирование в LLM: локальность вместо глобальной стратегии", "desc": "Работа исследует скрытые механизмы планирования в больших языковых моделях, используя метод зон
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#video", "#training", "#architecture", "#multimodal", "#optimization", "#3d"], "emoji": "🎬", "ru": {"title": "Неявное 3D представление движения для генерации видео независимо от угла обзора", "desc": "3DiMo — это метод для управления движением человека в генерации видео, который обу
[04.02.2026 05:44] Using data from previous issue: {"categories": [], "emoji": "🌍", "ru": {"title": "Унифицированная архитектура мировых моделей для целостного понимания окружающей среды", "desc": "В статье анализируются ограничения фрагментированного подхода к разработке мировых моделей, которые сегодня разрабатываются для отдельных задач предсказа
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#dataset", "#agents"], "emoji": "📋", "ru": {"title": "Выравнивание генераторов критериев оценки с человеческими предпочтениями для улучшения отчётов", "desc": "В статье предложен метод обучения генераторов критериев оценки, которые выравнены с предпочтениями ч
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#reasoning", "#optimization"], "emoji": "🌳", "ru": {"title": "Умная обрезка параллельных рассуждений через консенсус и девиацию", "desc": "В статье предложен Parallel-Probe — контроллер без обучения для оптимизации параллельного мышления в больших языковых моделях. Авторы вводят 2D-
[04.02.2026 05:44] Querying the API.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A Docker-free framework replaces physical execution environments with learned surrogates for training software engineering agents, enabling efficient training and test-time scaling without costly container setup.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\% to 52.0\% via Docker-free SFT, 55.0\% with Docker-free RL, and 68.2\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World
[04.02.2026 05:44] Response: ```json
{
  "desc": "В работе предложен SWE-World — фреймворк без Docker, который заменяет физические окружения выполнения на обученные суррогатные модели для тренировки агентов инженерии ПО. Подход использует LLM-модели, обученные на реальных взаимодействиях агента с окружением, чтобы предсказывать промежуточные результаты выполнения и финальную обратную связь от тестов. Это позволяет агентам обучаться без физического взаимодействия с контейнеризированными окружениями, значительно снижая ресурсные затраты. Благодаря моделированию результатов выполнения, фреймворк также включает масштабирование на этапе тестирования, позволяя выбрать лучшее решение из нескольких попыток.",
  "emoji": "🚀",
  "title": "Виртуальное окружение вместо Docker для обучения агентов программной инженерии"
}
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A Docker-free framework replaces physical execution environments with learned surrogates for training software engineering agents, enabling efficient training and test-time scaling without costly container setup.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\% to 52.0\% via Docker-free SFT, 55.0\% with Docker-free RL, and 68.2\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World"

[04.02.2026 05:44] Response: ```python
['AGENTS', 'PLP', 'BENCHMARK', 'TRAINING', 'RL']
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A Docker-free framework replaces physical execution environments with learned surrogates for training software engineering agents, enabling efficient training and test-time scaling without costly container setup.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents. SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\% to 52.0\% via Docker-free SFT, 55.0\% with Docker-free RL, and 68.2\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World"

[04.02.2026 05:44] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE']
```

**Reasoning:**

1. **OPTIMIZATION**: The paper focuses on improving training efficiency and test-time scaling (TTS) for software engineering agents. It presents methods to optimize agent training through learned surrogates and enables efficient test-time scaling without costly container setup.

2. **OPEN_SOURCE**: The paper explicitly states "The code is available at https://github.com/RUCAIBox/SWE-World", indicating the authors are releasing their framework and code publicly.
[04.02.2026 05:44] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Reasoning:**

1. **OPTIMIZATION**: The paper focuses on improving training efficiency and test-time scaling (TTS) for software engineering agents. It presents methods to optimize agent training through learned surrogates and enables efficient test-time scaling without costly container setup.

2. **OPEN_SOURCE**: The paper explicitly states "The code is available at https://github.com/RUCAIBox/SWE-World", indicating the authors are releasing their framework and code publicly.
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces SWE-World, a novel framework that eliminates the need for Docker containers in training software engineering agents. Instead of relying on physical execution environments, SWE-World uses learned surrogates to predict execution outcomes and test feedback, making the training process more efficient. By simulating agent-environment interactions, it allows for effective test-time scaling without the overhead of setting up and maintaining complex environments. The results show significant improvements in performance metrics for software engineering tasks, demonstrating the framework\'s potential to streamline agent training and evaluation.","title":"SWE-World: Efficient Training for Software Engineering Agents Without Docker"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces SWE-World, a novel framework that eliminates the need for Docker containers in training software engineering agents. Instead of relying on physical execution environments, SWE-World uses learned surrogates to predict execution outcomes and test feedback, making the training process more efficient. By simulating agent-environment interactions, it allows for effective test-time scaling without the overhead of setting up and maintaining complex environments. The results show significant improvements in performance metrics for software engineering tasks, demonstrating the framework's potential to streamline agent training and evaluation.", title='SWE-World: Efficient Training for Software Engineering Agents Without Docker'))
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种名为SWE-World的无Docker框架，用于训练软件工程代理。该框架通过学习的替代环境，取代了传统的物理执行环境，从而提高了训练和测试的效率。SWE-World利用基于大型语言模型的模型，预测中间执行结果和最终测试反馈，使代理能够在不与物理环境交互的情况下学习。实验结果表明，SWE-World显著提高了代理的性能，简化了环境构建和维护的复杂性。","title":"无Docker框架提升软件工程代理训练效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种名为SWE-World的无Docker框架，用于训练软件工程代理。该框架通过学习的替代环境，取代了传统的物理执行环境，从而提高了训练和测试的效率。SWE-World利用基于大型语言模型的模型，预测中间执行结果和最终测试反馈，使代理能够在不与物理环境交互的情况下学习。实验结果表明，SWE-World显著提高了代理的性能，简化了环境构建和维护的复杂性。', title='无Docker框架提升软件工程代理训练效率'))
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#video", "#reasoning", "#multimodal", "#alignment", "#cv", "#rlhf"], "emoji": "🎨", "ru": {"title": "Гибкое моделирование вознаграждения с контекстной адаптацией для качественной генерации изображений", "desc": "В работе предложена UnifiedReward-Flex — унифицированная модель вознагра
[04.02.2026 05:44] Querying the API.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SWE-Master presents a reproducible framework for developing software engineering agents through systematic optimization across multiple stages of agent development, achieving superior performance on software task resolution benchmarks.  					AI-generated summary 				 In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master.
[04.02.2026 05:44] Response: ```json
{
  "desc": "SWE-Master представляет открытую и воспроизводимую систему постобучения для разработки агентов, решающих задачи программной инженерии. Фреймворк систематически оптимизирует весь конвейер развития агента, включая синтез траекторий учителя, курирование данных, обучение с подкреплением на основе реальной обратной связи и дизайн инферентного механизма. Авторы демонстрируют, как методическая оптимизация позволяет выявить сильные способности больших языковых моделей в решении долгосрочных задач программной инженерии. На тестовом наборе SWE-bench Verified подход достигает впечатляющих результатов: 61,4% с базовой моделью и 70,8% при использовании масштабирования на этапе инференции.",
  "emoji": "🛠️",
  "title": "Систематическая оптимизация агентов для решения задач программной инженерии"
}
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SWE-Master presents a reproducible framework for developing software engineering agents through systematic optimization across multiple stages of agent development, achieving superior performance on software task resolution benchmarks.  					AI-generated summary 				 In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master."

[04.02.2026 05:44] Response: ```python
["AGENTS", "PLP", "BENCHMARK", "TRAINING", "RL"]
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SWE-Master presents a reproducible framework for developing software engineering agents through systematic optimization across multiple stages of agent development, achieving superior performance on software task resolution benchmarks.  					AI-generated summary 				 In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master."

[04.02.2026 05:44] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE', 'REASONING', 'LONG_CONTEXT']
```
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SWE-Master is a framework designed to enhance the development of software engineering agents through systematic optimization. It covers the entire agent development process, including data preparation, supervised fine-tuning, and reinforcement learning with real feedback. By starting with a basic model, SWE-Master effectively improves the agent\'s ability to solve complex software tasks, achieving a high resolve rate on benchmarks. The framework not only demonstrates superior performance compared to existing models but also emphasizes reproducibility in research.","title":"Optimizing Software Engineering Agents with SWE-Master"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="SWE-Master is a framework designed to enhance the development of software engineering agents through systematic optimization. It covers the entire agent development process, including data preparation, supervised fine-tuning, and reinforcement learning with real feedback. By starting with a basic model, SWE-Master effectively improves the agent's ability to solve complex software tasks, achieving a high resolve rate on benchmarks. The framework not only demonstrates superior performance compared to existing models but also emphasizes reproducibility in research.", title='Optimizing Software Engineering Agents with SWE-Master'))
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SWE-Master是一个开源的可重复框架，用于通过系统优化开发软件工程代理。它涵盖了代理开发的各个阶段，包括教师轨迹合成、数据整理、长时间的监督微调和强化学习。通过从一个基础模型开始，SWE-Master展示了如何通过系统化的优化方法提升软件工程任务的解决能力。经过评估，SWE-Master在标准基准测试中表现优异，显示出其在软件工程代理研究中的重要性。","title":"SWE-Master：软件工程代理的系统优化框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SWE-Master是一个开源的可重复框架，用于通过系统优化开发软件工程代理。它涵盖了代理开发的各个阶段，包括教师轨迹合成、数据整理、长时间的监督微调和强化学习。通过从一个基础模型开始，SWE-Master展示了如何通过系统化的优化方法提升软件工程任务的解决能力。经过评估，SWE-Master在标准基准测试中表现优异，显示出其在软件工程代理研究中的重要性。', title='SWE-Master：软件工程代理的系统优化框架'))
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#training", "#agents", "#rl", "#benchmark", "#dataset"], "emoji": "🔍", "ru": {"title": "Широкий поиск: многоагентная архитектура для параллельного извлечения информации", "desc": "Статья представляет Wide Research — новую парадигму поиска информации, которая позволяет параллельно из
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#cv"], "emoji": "🧠", "ru": {"title": "Умное переключение: оценка адаптивного выбора режимов рассуждения в мультимодальных моделях", "desc": "AdaptMMBench — это комплексный бенчмарк для оценки адаптивного мультимодального рассуждения в Vision-Language Mod
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#optimization", "#training"], "emoji": "🧹", "ru": {"title": "Очистка промптов от помех для эффективного обучения языковых моделей", "desc": "В статье представлена LENS - фреймворк для обучения с подкреплением с верифицируемыми наградами, который решает проблему 
[04.02.2026 05:44] Using data from previous issue: {"categories": ["#training", "#optimization", "#data", "#open_source", "#dataset"], "emoji": "🧩", "ru": {"title": "Поиск идеальной смеси данных через слияние моделей без переобучения", "desc": "DeMix — это фреймворк для оптимизации смеси данных при предварительном обучении LLM, использующий объедине
[04.02.2026 05:44] Querying the API.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

AOrchestra is a framework-agnostic agentic system that uses a tuple-based abstraction to dynamically create specialized task executors, achieving improved performance on complex benchmarks through automated agent creation and resource management.  					AI-generated summary 				 Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra
[04.02.2026 05:44] Response: ```json
{
  "desc": "AOrchestra — это универсальная система многоагентных систем, которая использует абстракцию в виде кортежа (инструкция, контекст, инструменты, модель) для динамического создания специализированных исполнителей задач. Центральный оркестратор адаптирует компоненты на каждом этапе, отбирая релевантный контекст, инструменты и языковые модели, а затем создавая агентов на лету для выполнения задач. Система не зависит от конкретного фреймворка и позволяет снизить затраты на инженерию благодаря гибкому управлению производительностью и вычислительными ресурсами. На сложных бенчмарках (GAIA, SWE-Bench, Terminal-Bench) AOrchestra показала 16,28% улучшение по сравнению с лучшей базовой моделью при использовании Gemini-3-Flash.",
  "emoji": "🎼",
  "title": "Динамическая оркестрация агентов через кортежную абстракцию"
}
```
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AOrchestra is a framework-agnostic agentic system that uses a tuple-based abstraction to dynamically create specialized task executors, achieving improved performance on complex benchmarks through automated agent creation and resource management.  					AI-generated summary 				 Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra"

[04.02.2026 05:44] Response: ```python
["AGENTS", "BENCHMARK"]
```

**Justification:**

1. **AGENTS**: The paper is fundamentally about an agentic system (AOrchestra) that creates and manages autonomous agents. It discusses agent abstraction, multi-turn task solving, sub-agents as tools, and automated agent creation - all core to agent-based architectures.

2. **BENCHMARK**: The paper evaluates the system on three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench) and reports performance improvements, indicating benchmark evaluation is a significant component of the work.
[04.02.2026 05:44] Error. Failed to parse JSON from LLM. ["AGENTS", "BENCHMARK"]


**Justification:**

1. **AGENTS**: The paper is fundamentally about an agentic system (AOrchestra) that creates and manages autonomous agents. It discusses agent abstraction, multi-turn task solving, sub-agents as tools, and automated agent creation - all core to agent-based architectures.

2. **BENCHMARK**: The paper evaluates the system on three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench) and reports performance improvements, indicating benchmark evaluation is a significant component of the work.
[04.02.2026 05:44] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"AOrchestra is a framework-agnostic agentic system that uses a tuple-based abstraction to dynamically create specialized task executors, achieving improved performance on complex benchmarks through automated agent creation and resource management.  					AI-generated summary 				 Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra"

[04.02.2026 05:44] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE']
```

**Justification:**

1. **OPTIMIZATION**: The paper discusses optimizing agent performance through automated resource management, tool selection, and model selection. It explicitly mentions achieving "Pareto-efficient" performance and enabling "controllable performance-cost trade-off," which are optimization concepts.

2. **OPEN_SOURCE**: The paper explicitly states "The code is available at: https://github.com/FoundationAgents/AOrchestra", indicating the authors are releasing their framework and code publicly.
[04.02.2026 05:44] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

1. **OPTIMIZATION**: The paper discusses optimizing agent performance through automated resource management, tool selection, and model selection. It explicitly mentions achieving "Pareto-efficient" performance and enabling "controllable performance-cost trade-off," which are optimization concepts.

2. **OPEN_SOURCE**: The paper explicitly states "The code is available at: https://github.com/FoundationAgents/AOrchestra", indicating the authors are releasing their framework and code publicly.
[04.02.2026 05:44] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AOrchestra is a versatile system designed to enhance task automation by dynamically creating specialized agents for complex tasks. It utilizes a tuple-based abstraction that includes Instruction, Context, Tools, and Model, allowing for flexible and efficient task execution. This framework-agnostic approach reduces the need for extensive human engineering and supports various agent types as executors. By optimizing resource management and adaptability, AOrchestra demonstrates significant performance improvements on challenging benchmarks.","title":"Dynamic Agent Creation for Enhanced Task Automation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='AOrchestra is a versatile system designed to enhance task automation by dynamically creating specialized agents for complex tasks. It utilizes a tuple-based abstraction that includes Instruction, Context, Tools, and Model, allowing for flexible and efficient task execution. This framework-agnostic approach reduces the need for extensive human engineering and supports various agent types as executors. By optimizing resource management and adaptability, AOrchestra demonstrates significant performance improvements on challenging benchmarks.', title='Dynamic Agent Creation for Enhanced Task Automation'))
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"AOrchestra是一个与框架无关的智能系统，使用基于元组的抽象动态创建专门的任务执行器，从而在复杂基准测试中实现更好的性能。该系统通过将任何代理建模为一个元组（指令、上下文、工具、模型）来解决现有设计缺乏动态抽象视图的问题。AOrchestra的中心协调器在每一步具体化这个元组，策划与任务相关的上下文，选择工具和模型，并通过即时自动创建代理来委派执行。通过这种设计，AOrchestra减少了人工工程的工作量，并支持多种代理作为任务执行器的即插即用。","title":"AOrchestra：动态创建智能任务执行器的框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='AOrchestra是一个与框架无关的智能系统，使用基于元组的抽象动态创建专门的任务执行器，从而在复杂基准测试中实现更好的性能。该系统通过将任何代理建模为一个元组（指令、上下文、工具、模型）来解决现有设计缺乏动态抽象视图的问题。AOrchestra的中心协调器在每一步具体化这个元组，策划与任务相关的上下文，选择工具和模型，并通过即时自动创建代理来委派执行。通过这种设计，AOrchestra减少了人工工程的工作量，并支持多种代理作为任务执行器的即插即用。', title='AOrchestra：动态创建智能任务执行器的框架'))
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#optimization"], "emoji": "🔀", "ru": {"title": "Объединение парадигм: единая диффузионная модель для понимания и генерации", "desc": "В работе предложен XDLM — единый фреймворк, объединяющий две конкурирующие парадигмы дискретного генеративного моделиро
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#optimization", "#training"], "emoji": "⚖️", "ru": {"title": "Умное распределение вычислительных ресурсов для эффективного обучения языковых моделей", "desc": "CoBA-RL — это алгоритм обучения с подкреплением, который адаптивно распределяет вычислительные ресурсы
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#rl", "#cv", "#healthcare"], "emoji": "🔍", "ru": {"title": "Двухэтапный скрининг рака через обучение с подкреплением и групповое сравнение", "desc": "Представлена система GF-Screen на основе обучения с подкреплением для скрининга рака по КТ-снимкам, которая решает проблему дисбаланс
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#reasoning", "#science", "#transfer_learning"], "emoji": "🤝", "ru": {"title": "AI как научный партнёр: от автоматизации к подлинному сотворчеству в математике", "desc": "В статье представлены примеры успешного сотрудничества исследователей с продвинутыми языковыми моделями, такими к
[04.02.2026 05:45] Querying the API.
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Offline reinforcement learning method combines contextual bandit learning with partial trajectories to improve multi-turn code generation performance while reducing training costs.  					AI-generated summary 				 Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.
[04.02.2026 05:45] Response: ```json
{
  "desc": "В статье предлагается метод Cobalt, который объединяет обучение с подкреплением и контекстный бандит для улучшения многошагового генерирования кода на языке LLM. Авторы показали, что задачу можно переформулировать как восстанавливаемый процесс принятия решений, позволяя использовать частичные траектории как контекстные подсказки для однопроходного обучения. Метод демонстрирует лучшую производительность по сравнению с существующими онлайн-подходами RL при значительно меньших затратах на обучение. Кроме того, исследование анализирует проблему манипуляции вознаграждением моделью и предлагает её решение через возмущённые траектории.",
  "emoji": "💻",
  "title": "Эффективное обучение LLM через контекстные бандиты и оффлайн траектории"
}
```
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Offline reinforcement learning method combines contextual bandit learning with partial trajectories to improve multi-turn code generation performance while reducing training costs.  					AI-generated summary 				 Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt."

[04.02.2026 05:45] Response: ```python
["RL", "PLP", "TRAINING"]
```
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Offline reinforcement learning method combines contextual bandit learning with partial trajectories to improve multi-turn code generation performance while reducing training costs.  					AI-generated summary 				 Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt."

[04.02.2026 05:45] Response: ```python
["OPTIMIZATION", "OPEN_SOURCE"]
```

**Justification:**

- **OPTIMIZATION**: The paper focuses on improving training efficiency and performance of LLMs through a novel reinforcement learning method (Cobalt) that reduces training costs while improving multi-turn code generation performance. This directly relates to advancing training optimization methods.

- **OPEN_SOURCE**: The paper explicitly states "Our code and data are available at https://github.com/OSU-NLP-Group/cobalt," indicating the authors are releasing their code and data publicly.
[04.02.2026 05:45] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "OPEN_SOURCE"]


**Justification:**

- **OPTIMIZATION**: The paper focuses on improving training efficiency and performance of LLMs through a novel reinforcement learning method (Cobalt) that reduces training costs while improving multi-turn code generation performance. This directly relates to advancing training optimization methods.

- **OPEN_SOURCE**: The paper explicitly states "Our code and data are available at https://github.com/OSU-NLP-Group/cobalt," indicating the authors are releasing their code and data publicly.
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Cobalt, an offline reinforcement learning method that enhances multi-turn code generation by integrating contextual bandit learning with partial trajectories. By treating multi-turn code generation as a recoverable Markov decision process, Cobalt leverages previously collected code generation data to create contextual prompts for training. The method allows for efficient single-step code generation while significantly reducing training costs compared to traditional online reinforcement learning approaches. Experimental results show that Cobalt outperforms existing online RL methods, demonstrating its effectiveness in improving performance on code generation tasks.","title":"Cobalt: Bridging Offline and Online RL for Code Generation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Cobalt, an offline reinforcement learning method that enhances multi-turn code generation by integrating contextual bandit learning with partial trajectories. By treating multi-turn code generation as a recoverable Markov decision process, Cobalt leverages previously collected code generation data to create contextual prompts for training. The method allows for efficient single-step code generation while significantly reducing training costs compared to traditional online reinforcement learning approaches. Experimental results show that Cobalt outperforms existing online RL methods, demonstrating its effectiveness in improving performance on code generation tasks.', title='Cobalt: Bridging Offline and Online RL for Code Generation'))
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的离线强化学习方法Cobalt，旨在提高多轮代码生成的性能，同时降低训练成本。Cobalt结合了上下文赌博学习和部分轨迹，通过使用参考大型语言模型收集代码生成轨迹，并将其分割为上下文提示。该方法在在线赌博学习中训练模型完成每个部分轨迹提示，显著优于现有的多轮在线强化学习基线。研究还分析了大型语言模型在上下文中的奖励黑客行为，并通过扰动轨迹增强Cobalt的训练，以减轻这一问题。","title":"Cobalt：提升多轮代码生成的离线强化学习新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的离线强化学习方法Cobalt，旨在提高多轮代码生成的性能，同时降低训练成本。Cobalt结合了上下文赌博学习和部分轨迹，通过使用参考大型语言模型收集代码生成轨迹，并将其分割为上下文提示。该方法在在线赌博学习中训练模型完成每个部分轨迹提示，显著优于现有的多轮在线强化学习基线。研究还分析了大型语言模型在上下文中的奖励黑客行为，并通过扰动轨迹增强Cobalt的训练，以减轻这一问题。', title='Cobalt：提升多轮代码生成的离线强化学习新方法'))
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#rl", "#multimodal", "#benchmark", "#cv"], "emoji": "📸", "ru": {"title": "Персонализация зрения через контекстное обучение моделей vision-language", "desc": "В работе предложена система CoViP для контекстуализированной визуальной персонализации моделей зрения-языка. Основная идея за
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#ethics", "#benchmark", "#cv", "#security"], "emoji": "🔓", "ru": {"title": "Пиксельные метрики не гарантируют приватность лиц", "desc": "В статье представлена атака FaceLinkGen, которая демонстрирует критический недостаток современных методов приватной распознавания лиц - они не защ
[04.02.2026 05:45] Querying the API.
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates.  					AI-generated summary 				 Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference.
[04.02.2026 05:45] Response: ```json
{
  "desc": "SafeGround — это фреймворк для моделей визуального понимания графических интерфейсов, который использует методы количественной оценки неопределённости для предсказания координат на экране с контролем риска. Система применяет распределение-ориентированный подход к оценке неопределённости, чтобы захватить пространственное распределение выходов модели. Во время калибровки фреймворк определяет порог решения с гарантированным статистическим контролем частоты ложных открытий (FDR). Экспериментальные результаты показывают, что SafeGround повышает точность системы на 5,38% в сравнении с базовыми моделями и обеспечивает надёжный контроль ошибок при взаимодействии с GUI.",
  "emoji": "🛡️",
  "title": "Безопасное управление интерфейсом через контролируемую неопределённость"
}
```
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates.  					AI-generated summary 				 Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference."

[04.02.2026 05:45] Response: ```python
["AGENTS", "BENCHMARK", "INFERENCE"]
```
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates.  					AI-generated summary 				 Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference."

[04.02.2026 05:45] Response: ```python
['SECURITY']
```
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SafeGround is a framework designed to improve the reliability of GUI grounding models by incorporating uncertainty awareness. It uses a method for quantifying uncertainty that captures how spread out the model\'s predictions are, which helps in understanding the risk of making incorrect decisions. The framework also includes a calibration process that sets a decision threshold to control the rate of false discoveries during testing. By applying SafeGround to various models, the results show significant improvements in accuracy and better differentiation between correct and incorrect predictions.","title":"Enhancing GUI Grounding with Uncertainty Awareness"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="SafeGround is a framework designed to improve the reliability of GUI grounding models by incorporating uncertainty awareness. It uses a method for quantifying uncertainty that captures how spread out the model's predictions are, which helps in understanding the risk of making incorrect decisions. The framework also includes a calibration process that sets a decision threshold to control the rate of false discoveries during testing. By applying SafeGround to various models, the results show significant improvements in accuracy and better differentiation between correct and incorrect predictions.", title='Enhancing GUI Grounding with Uncertainty Awareness'))
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SafeGround是一个关注不确定性的框架，旨在提高图形用户界面（GUI）定位模型的可靠性。它通过分布感知的不确定性量化和校准，能够在测试前进行风险意识的预测。该框架通过捕捉模型输出的随机样本的空间分散性，来量化不确定性，并在测试时设定具有统计保证的错误发现率（FDR）控制的决策阈值。实验结果表明，SafeGround在多个GUI定位模型上显著提高了系统级准确性，最多可提升5.38个百分点。","title":"SafeGround：提升GUI定位模型的可靠性与准确性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SafeGround是一个关注不确定性的框架，旨在提高图形用户界面（GUI）定位模型的可靠性。它通过分布感知的不确定性量化和校准，能够在测试前进行风险意识的预测。该框架通过捕捉模型输出的随机样本的空间分散性，来量化不确定性，并在测试时设定具有统计保证的错误发现率（FDR）控制的决策阈值。实验结果表明，SafeGround在多个GUI定位模型上显著提高了系统级准确性，最多可提升5.38个百分点。', title='SafeGround：提升GUI定位模型的可靠性与准确性'))
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#cv"], "emoji": "🌍", "ru": {"title": "Измерение того, что модель действительно запомнила о визуальном мире", "desc": "Авторы представляют WorldVQA — бенчмарк для оценки визуального знания мультимодальных больших языковых моделей. Главная особенность закл
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#agents", "#rl", "#rag"], "emoji": "🔍", "ru": {"title": "Двухуровневая рефинировка рассуждений для точного распределения кредита в агентах поиска", "desc": "В статье представлена фреймворк Search-R2, которая улучшает рассуждение языковых а
[04.02.2026 05:45] Querying the API.
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A novel distillation framework called DP-DMD is introduced that preserves sample diversity in text-to-image generation by separating the roles of distilled steps, using v-prediction for diversity and standard DMD loss for quality refinement without additional computational overhead.  					AI-generated summary 				 Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments.
[04.02.2026 05:45] Response: ```json
{
  "desc": "В работе предлагается новый метод дистилляции DP-DMD для генерации изображений по тексту, который решает проблему коллапса мод (потери разнообразия). Основная идея заключается в разделении ролей дистиллируемых шагов: первый шаг отвечает за сохранение разнообразия выборок через v-prediction, а последующие шаги фокусируются на улучшении качества с помощью стандартной DMD потери. Метод достигает высокого качества генерации при низких вычислительных затратах без использования дополнительных сетей-дискриминаторов или перцептивных функций потерь. Экспериментальные результаты показывают, что DP-DMD сохраняет разнообразие образцов при качестве, сопоставимом с современными подходами.",
  "emoji": "🎨",
  "title": "Дистилляция с сохранением разнообразия для быстрой генерации изображений"
}
```
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel distillation framework called DP-DMD is introduced that preserves sample diversity in text-to-image generation by separating the roles of distilled steps, using v-prediction for diversity and standard DMD loss for quality refinement without additional computational overhead.  					AI-generated summary 				 Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments."

[04.02.2026 05:45] Response: ```python
["INFERENCE", "TRAINING", "MULTIMODAL"]
```
[04.02.2026 05:45] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A novel distillation framework called DP-DMD is introduced that preserves sample diversity in text-to-image generation by separating the roles of distilled steps, using v-prediction for diversity and standard DMD loss for quality refinement without additional computational overhead.  					AI-generated summary 				 Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments."

[04.02.2026 05:45] Response: ```python
['OPTIMIZATION', 'DIFFUSION']
```
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces a new framework called Diversity-Preserved DMD (DP-DMD) for text-to-image generation that aims to maintain sample diversity while ensuring high-quality outputs. It separates the distillation process into two distinct steps: the first step focuses on preserving diversity using a target-prediction method, while the second step refines quality using the standard DMD loss. This approach addresses the common issue of mode collapse found in traditional DMD methods, which often require complex regularization techniques that can slow down training. DP-DMD achieves impressive results without the need for additional computational resources or complex architectures, making it efficient and effective for generating diverse and high-quality images.","title":"Preserving Diversity in Text-to-Image Generation with DP-DMD"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces a new framework called Diversity-Preserved DMD (DP-DMD) for text-to-image generation that aims to maintain sample diversity while ensuring high-quality outputs. It separates the distillation process into two distinct steps: the first step focuses on preserving diversity using a target-prediction method, while the second step refines quality using the standard DMD loss. This approach addresses the common issue of mode collapse found in traditional DMD methods, which often require complex regularization techniques that can slow down training. DP-DMD achieves impressive results without the need for additional computational resources or complex architectures, making it efficient and effective for generating diverse and high-quality images.', title='Preserving Diversity in Text-to-Image Generation with DP-DMD'))
[04.02.2026 05:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的蒸馏框架，称为DP-DMD，旨在在文本到图像生成中保持样本多样性。该框架通过分离蒸馏步骤的角色，使用目标预测来增强多样性，同时利用标准DMD损失进行质量优化，而无需额外的计算开销。DP-DMD的第一步专注于保持样本多样性，后续步骤则专注于质量提升，避免了模式崩溃的问题。实验表明，DP-DMD在保持视觉质量的同时，能够有效地保留样本多样性，表现优于现有的先进方法。","title":"保持多样性的高质量生成"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的蒸馏框架，称为DP-DMD，旨在在文本到图像生成中保持样本多样性。该框架通过分离蒸馏步骤的角色，使用目标预测来增强多样性，同时利用标准DMD损失进行质量优化，而无需额外的计算开销。DP-DMD的第一步专注于保持样本多样性，后续步骤则专注于质量提升，避免了模式崩溃的问题。实验表明，DP-DMD在保持视觉质量的同时，能够有效地保留样本多样性，表现优于现有的先进方法。', title='保持多样性的高质量生成'))
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#interpretability", "#multimodal", "#benchmark", "#cv"], "emoji": "🎯", "ru": {"title": "Объектные эмбеддинги для точного понимания деталей изображений", "desc": "ObjEmbed — это инновационная мультимодальная модель встраивания на основе большой языковой модели, которая разбивает изоб
[04.02.2026 05:45] Using data from previous issue: {"categories": ["#audio", "#multimodal", "#benchmark"], "emoji": "🐦", "ru": {"title": "Адаптивное слияние звука и контекста с контролируемой надёжностью", "desc": "Авторы представляют FINCH — фреймворк адаптивного слияния доказательств для классификации биоакустических сигналов, который объединяет п
[04.02.2026 05:45] Renaming data file.
[04.02.2026 05:45] Renaming previous data. hf_papers.json to ./d/2026-02-04.json
[04.02.2026 05:45] Saving new data file.
[04.02.2026 05:45] Generating page.
[04.02.2026 05:45] Renaming previous page.
[04.02.2026 05:45] Renaming previous data. index.html to ./d/2026-02-04.html
[04.02.2026 05:45] Writing result.
[04.02.2026 05:45] Renaming log file.
[04.02.2026 05:45] Renaming previous data. log.txt to ./logs/2026-02-04_last_log.txt
