[23.10.2024 09:59] Read previous papers.
[23.10.2024 09:59] Get feed.
[23.10.2024 09:59] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17247
[23.10.2024 09:59] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17249
[23.10.2024 09:59] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17131
[23.10.2024 09:59] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17250
[23.10.2024 09:59] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14649
[23.10.2024 09:59] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17215
[23.10.2024 09:59] ********************************************************************************
[23.10.2024 09:59] Abstract 0. In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information. As the idiom "A picture is worth a thousand words" implies, representing a single image in current LVLMs can require hundreds or even thousands of tokens. This results in significant computational cos...
[23.10.2024 09:59] ********************************************************************************
[23.10.2024 09:59] Abstract 1. We present SpectroMotion, a novel approach that combines 3D Gaussian Splatting (3DGS) with physically-based rendering (PBR) and deformation fields to reconstruct dynamic specular scenes. Previous methods extending 3DGS to model dynamic scenes have struggled to accurately represent specular surfaces....
[23.10.2024 09:59] ********************************************************************************
[23.10.2024 09:59] Abstract 2. Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce Self-Steering Optimization (SSO), an algorithm that...
[23.10.2024 09:59] ********************************************************************************
[23.10.2024 09:59] Abstract 3. Accelerating research on Large Multimodal Models (LMMs) in non-English languages is crucial for enhancing user experiences across broader populations. In this paper, we introduce JMMMU (Japanese MMMU), the first large-scale Japanese benchmark designed to evaluate LMMs on expert-level tasks based on ...
[23.10.2024 09:59] ********************************************************************************
[23.10.2024 09:59] Abstract 4. The high computational costs of large language models (LLMs) have led to a flurry of research on LLM compression, via methods such as quantization, sparsification, or structured pruning. A new frontier in this area is given by dynamic, non-uniform compression methods, which adjust the compression le...
[23.10.2024 09:59] ********************************************************************************
[23.10.2024 09:59] Abstract 5. Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness. Existing methods either incur high computational co...
[23.10.2024 09:59] Read previous papers.
[23.10.2024 09:59] Generating reviews via LLM API.
[23.10.2024 09:59] Using data from previous issue: {"desc": "Статья представляет новый метод PyramidDrop для повышения эффективности крупных визуально-языковых моделей (LVLM). Авторы обнаружили, что токены изображений становятся избыточными в глубоких слоях модели. PyramidDrop постепенно уменьшает количество токенов изображения на разных этапах обра
[23.10.2024 09:59] Using data from previous issue: {"desc": "SpectroMotion - это новый подход, объединяющий 3D гауссово сплаттинг (3DGS) с физически корректным рендерингом (PBR) и полями деформации для реконструкции динамических зеркальных сцен. Метод вводит технику остаточной коррекции для точного вычисления нормалей поверхности при деформации, а т
[23.10.2024 09:59] Using data from previous issue: {"desc": "Статья представляет алгоритм Self-Steering Optimization (SSO) для автоматизированного выравнивания языковых моделей. SSO генерирует качественные сигналы предпочтений без ручной разметки, поддерживая постоянный разрыв между выбранными и отвергнутыми ответами. Алгоритм улучшает онлайн и офла
[23.10.2024 09:59] Using data from previous issue: {"desc": "Статья представляет JMMMU - первый масштабный японский бенчмарк для оценки больших мультимодальных моделей (LMM) на экспертных задачах в японском культурном контексте. Бенчмарк состоит из двух подмножеств: культурно-агностического (CA) и культурно-специфического (CS). Исследование выявило 
[23.10.2024 09:59] Using data from previous issue: {"desc": "Статья представляет новый подход к динамической компрессии больших языковых моделей (LLM) под названием EvoPress. Авторы опровергают предположение о монотонности ошибок в LLM и предлагают эволюционный фреймворк с доказуемой сходимостью и низкой вычислительной сложностью. EvoPress показывае
[23.10.2024 09:59] Using data from previous issue: {"desc": "Статья представляет MiniPLM - новый фреймворк для дистилляции знаний при предварительном обучении языковых моделей. MiniPLM решает проблемы эффективности, гибкости и эффективности существующих методов, выполняя офлайн-вывод учительской модели и работая только с обучающим корпусом. Этот под
[23.10.2024 09:59] Trying to get texts in Chinese.
[23.10.2024 09:59] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information. As the idiom "A picture is worth a thousand words" implies, representing a single image in current LVLMs can require hundreds or even thousands of tokens. This results in significant computational costs, which grow quadratically as input image resolution increases, thereby severely impacting the efficiency of both training and inference. Previous approaches have attempted to reduce the number of image tokens either before or within the early layers of LVLMs. However, these strategies inevitably result in the loss of crucial image information, ultimately diminishing model performance. To address this challenge, we conduct an empirical study revealing that all visual tokens are necessary for LVLMs in the shallow layers, and token redundancy progressively increases in the deeper layers of the model. To this end, we propose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost their efficiency in both training and inference with neglectable performance loss. Specifically, we partition the LVLM into several stages and drop part of the image tokens at the end of each stage with a pre-defined ratio, creating pyramid-like visual tokens across model layers. The dropping is based on a lightweight similarity calculation with a negligible time overhead. Extensive experiments demonstrate that PyramidDrop can achieve a 40% training time and 55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance. Besides, the PyramidDrop could also serve as a plug-and-play strategy for inference acceleration without training, with better performance and lower inference cost than counterparts. We hope that the insights and approach introduced by PyramidDrop will inspire future research to further investigate the role of image tokens in LVLMs.
[23.10.2024 09:59] Mistral response. {"id": "1e6658261da140b4b9de2d3e5550f2bd", "object": "chat.completion", "created": 1729677555, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u8ba8\u8bba\u4e86\u5927\u89c4\u6a21\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u4e2d\u56fe\u50cf\u8868\u793a\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002\u56fe\u50cf\u5305\u542b\u5927\u91cf\u4fe1\u606f\uff0c\u8868\u793a\u4e00\u5f20\u56fe\u50cf\u9700\u8981\u5927\u91cf\u7684\u6807\u8bb0\uff0c\u8ba1\u7b97\u6210\u672c\u968f\u56fe\u50cf\u5206\u8fa8\u7387\u589e\u52a0\u800c\u589e\u52a0\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86PyramidDrop\u7b56\u7565\uff0c\u5728\u6a21\u578b\u7684\u4e0d\u540c\u9636\u6bb5\u9010\u6b65\u51cf\u5c11\u56fe\u50cf\u6807\u8bb0\uff0c\u4ece\u800c\u63d0\u9ad8\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\uff0c\u4e14\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cPyramidDrop\u53ef\u663e\u8457\u52a0\u5feb\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\uff0c\u5e76\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u7b56\u7565\u8fdb\u4e00\u6b65\u52a0\u901f\u63a8\u7406\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 411, "total_tokens": 595, "completion_tokens": 184}}
[23.10.2024 09:59] Response: 这篇文章讨论了大规模视觉-语言模型（LVLMs）中图像表示的计算成本问题。图像包含大量信息，表示一张图像需要大量的标记，计算成本随图像分辨率增加而增加。为解决这一问题，作者提出了PyramidDrop策略，在模型的不同阶段逐步减少图像标记，从而提高训练和推理效率，且性能损失可忽略。实验结果显示，PyramidDrop可显著加快训练和推理速度，并可作为即插即用的策略进一步加速推理。
[23.10.2024 09:59] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

这篇文章讨论了大规模视觉-语言模型（LVLMs）中图像表示的计算成本问题。图像包含大量信息，表示一张图像需要大量的标记，计算成本随图像分辨率增加而增加。为解决这一问题，作者提出了PyramidDrop策略，在模型的不同阶段逐步减少图像标记，从而提高训练和推理效率，且性能损失可忽略。实验结果显示，PyramidDrop可显著加快训练和推理速度，并可作为即插即用的策略进一步加速推理。
[23.10.2024 09:59] Mistral response. {"id": "6b016eff072e447e8a0b03f7219df1c3", "object": "chat.completion", "created": 1729677561, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "Zh\u00e8 pi\u0101n w\u00e9nzh\u0101ng t\u01ceol\u00f9n le d\u00e0gu\u012bm\u00f3 sh\u00ecju\u00e9-y\u01d4y\u00e1n m\u00f3x\u00edng (LVLMs) zh\u014dng t\u00faxi\u00e0ng bi\u01ceosh\u00ec de j\u00ecsu\u00e0n ch\u00e9ngb\u011bn w\u00e8nti. T\u00faxi\u00e0ng b\u0101oh\u00e1n d\u00e0li\u00e0ng x\u00ecnx\u012b, bi\u01ceosh\u00ec y\u012b zh\u0101ng t\u00faxi\u00e0ng x\u016by\u00e0o d\u00e0li\u00e0ng de bi\u0101oj\u00ec, j\u00ecsu\u00e0n ch\u00e9ngb\u011bn su\u00ed t\u00faxi\u00e0ng f\u0113nbi\u00e0nl\u01dc z\u0113ngji\u0101 \u00e9r z\u0113ngji\u0101. W\u00e8i ji\u011bju\u00e9 zh\u00e8 y\u012b w\u00e8nti, zu\u00f2zh\u011b t\u00edch\u016b le PyramidDrop c\u00e8l\u00fc\u00e8, z\u00e0i m\u00f3x\u00edng de b\u00f9t\u00f3ng ji\u0113du\u00e0n zh\u00fab\u00f9 ji\u01censh\u01ceo t\u00faxi\u00e0ng bi\u0101oj\u00ec, c\u00f3ng'\u00e9r t\u01d0g\u0101o x\u00f9nli\u00e0n h\u00e9 tu\u012bl\u01d0 xi\u00e0ol\u01dc, \u00e9rqi\u011b x\u00ecngn\u00e9ng s\u01d4nsh\u012b k\u011b h\u016bl\u00fc\u00e8. Sh\u00edy\u00e0n ji\u00e9gu\u01d2 xi\u01censh\u00ec, PyramidDrop k\u011b xi\u01cenzh\u00f9 ji\u0101ku\u00e0i x\u00f9nli\u00e0n h\u00e9 tu\u012bl\u01d0 s\u00f9d\u00f9, b\u00ecng k\u011b zu\u00f2w\u00e9i j\u00edch\u0101j\u00edy\u00f2ng de c\u00e8l\u00fc\u00e8 j\u00ecnx\u00edng ji\u0101s\u00f9 tu\u012bl\u01d0.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 199, "total_tokens": 574, "completion_tokens": 375}}
[23.10.2024 09:59] Response: Zhè piān wénzhāng tǎolùn le dàguīmó shìjué-yǔyán móxíng (LVLMs) zhōng túxiàng biǎoshì de jìsuàn chéngběn wènti. Túxiàng bāohán dàliàng xìnxī, biǎoshì yī zhāng túxiàng xūyào dàliàng de biāojì, jìsuàn chéngběn suí túxiàng fēnbiànlǜ zēngjiā ér zēngjiā. Wèi jiějué zhè yī wènti, zuòzhě tíchū le PyramidDrop cèlüè, zài móxíng de bùtóng jiēduàn zhúbù jiǎnshǎo túxiàng biāojì, cóng'ér tǐgāo xùnliàn hé tuīlǐ xiàolǜ, érqiě xìngnéng sǔnshī kě hūlüè. Shíyàn jiéguǒ xiǎnshì, PyramidDrop kě xiǎnzhù jiākuài xùnliàn hé tuīlǐ sùdù, bìng kě zuòwéi jíchājíyòng de cèlüè jìnxíng jiāsù tuīlǐ.
[23.10.2024 09:59] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

这篇文章讨论了大规模视觉-语言模型（LVLMs）中图像表示的计算成本问题。图像包含大量信息，表示一张图像需要大量的标记，计算成本随图像分辨率增加而增加。为解决这一问题，作者提出了PyramidDrop策略，在模型的不同阶段逐步减少图像标记，从而提高训练和推理效率，且性能损失可忽略。实验结果显示，PyramidDrop可显著加快训练和推理速度，并可作为即插即用的策略进一步加速推理。
[23.10.2024 09:59] Mistral response. {"id": "202ec34707274098af4453a8b178a68e", "object": "chat.completion", "created": 1729677571, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\n    {\"word\": \"\u8ba8\u8bba\", \"pinyin\": \"t\u01ceo l\u00f9n\", \"trans\": \"discuss\"},\n    {\"word\": \"\u5927\u89c4\u6a21\", \"pinyin\": \"d\u00e0 gu\u012b m\u00f3\", \"trans\": \"large-scale\"},\n    {\"word\": \"\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\", \"pinyin\": \"sh\u00ec ju\u00e9 y\u01d4 y\u00e1n m\u00f3 x\u00ecng\", \"trans\": \"vision-language model\"},\n    {\"word\": \"\u8ba1\u7b97\u6210\u672c\", \"pinyin\": \"j\u00ec su\u00e0n ch\u00e9ng b\u011bn\", \"trans\": \"computational cost\"},\n    {\"word\": \"\u8868\u793a\", \"pinyin\": \"bi\u01ceo sh\u00ec\", \"trans\": \"representation\"},\n    {\"word\": \"\u6807\u8bb0\", \"pinyin\": \"bi\u0101o j\u00ec\", \"trans\": \"token\"},\n    {\"word\": \"\u5206\u8fa8\u7387\", \"pinyin\": \"f\u0113n bi\u00e0n l\u01dc\", \"trans\": \"resolution\"},\n    {\"word\": \"\u63d0\u51fa\", \"pinyin\": \"t\u00ed ch\u016b\", \"trans\": \"propose\"},\n    {\"word\": \"\u7b56\u7565\", \"pinyin\": \"c\u00e8 l\u00fc\u00e8\", \"trans\": \"strategy\"},\n    {\"word\": \"\u9010\u6b65\", \"pinyin\": \"zh\u00fa b\u00f9\", \"trans\": \"gradually\"},\n    {\"word\": \"\u51cf\u5c11\", \"pinyin\": \"ji\u01cen sh\u01ceo\", \"trans\": \"reduce\"},\n    {\"word\": \"\u8bad\u7ec3\", \"pinyin\": \"x\u00f9n li\u00e0n\", \"trans\": \"training\"},\n    {\"word\": \"\u63a8\u7406\", \"pinyin\": \"tu\u012b l\u01d0\", \"trans\": \"inference\"},\n    {\"word\": \"\u6548\u7387\", \"pinyin\": \"xi\u00e0o l\u01dc\", \"trans\": \"efficiency\"},\n    {\"word\": \"\u635f\u5931\", \"pinyin\": \"s\u01d4n sh\u012b\", \"trans\": \"loss\"},\n    {\"word\": \"\u53ef\u5ffd\u7565\", \"pinyin\": \"k\u011b h\u016b l\u00fc\u00e8\", \"trans\": \"negligible\"},\n    {\"word\": \"\u663e\u8457\", \"pinyin\": \"xi\u01cen zh\u00f9\", \"trans\": \"significant\"},\n    {\"word\": \"\u52a0\u5feb\", \"pinyin\": \"ji\u0101 ku\u00e0i\", \"trans\": \"accelerate\"},\n    {\"word\": \"\u901f\u5ea6\", \"pinyin\": \"s\u00f9 d\u00f9\", \"trans\": \"speed\"},\n    {\"word\": \"\u5373\u63d2\u5373\u7528\", \"pinyin\": \"j\u00ed ch\u0101 j\u00ed y\u00f2ng\", \"trans\": \"plug-and-play\"},\n    {\"word\": \"\u8fdb\u4e00\u6b65\", \"pinyin\": \"j\u00ecn y\u012b b\u00f9\", \"trans\": \"further\"}\n]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 231, "total_tokens": 876, "completion_tokens": 645}}
[23.10.2024 09:59] Response: [
    {"word": "讨论", "pinyin": "tǎo lùn", "trans": "discuss"},
    {"word": "大规模", "pinyin": "dà guī mó", "trans": "large-scale"},
    {"word": "视觉-语言模型", "pinyin": "shì jué yǔ yán mó xìng", "trans": "vision-language model"},
    {"word": "计算成本", "pinyin": "jì suàn chéng běn", "trans": "computational cost"},
    {"word": "表示", "pinyin": "biǎo shì", "trans": "representation"},
    {"word": "标记", "pinyin": "biāo jì", "trans": "token"},
    {"word": "分辨率", "pinyin": "fēn biàn lǜ", "trans": "resolution"},
    {"word": "提出", "pinyin": "tí chū", "trans": "propose"},
    {"word": "策略", "pinyin": "cè lüè", "trans": "strategy"},
    {"word": "逐步", "pinyin": "zhú bù", "trans": "gradually"},
    {"word": "减少", "pinyin": "jiǎn shǎo", "trans": "reduce"},
    {"word": "训练", "pinyin": "xùn liàn", "trans": "training"},
    {"word": "推理", "pinyin": "tuī lǐ", "trans": "inference"},
    {"word": "效率", "pinyin": "xiào lǜ", "trans": "efficiency"},
    {"word": "损失", "pinyin": "sǔn shī", "trans": "loss"},
    {"word": "可忽略", "pinyin": "kě hū lüè", "trans": "negligible"},
    {"word": "显著", "pinyin": "xiǎn zhù", "trans": "significant"},
    {"word": "加快", "pinyin": "jiā kuài", "trans": "accelerate"},
    {"word": "速度", "pinyin": "sù dù", "trans": "speed"},
    {"word": "即插即用", "pinyin": "jí chā jí yòng", "trans": "plug-and-play"},
    {"word": "进一步", "pinyin": "jìn yī bù", "trans": "further"}
]
[23.10.2024 09:59] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

这篇文章讨论了大规模视觉-语言模型（LVLMs）中图像表示的计算成本问题。图像包含大量信息，表示一张图像需要大量的标记，计算成本随图像分辨率增加而增加。为解决这一问题，作者提出了PyramidDrop策略，在模型的不同阶段逐步减少图像标记，从而提高训练和推理效率，且性能损失可忽略。实验结果显示，PyramidDrop可显著加快训练和推理速度，并可作为即插即用的策略进一步加速推理。
[23.10.2024 09:59] Mistral response. {"id": "aab59d3cd5f8446fb0e0a24244adc6e7", "object": "chat.completion", "created": 1729677590, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article discusses the computational cost issue of image representation in large-scale vision-language models (LVLMs). Images contain a large amount of information, and representing an image requires a large number of tokens, with the computational cost increasing as the image resolution increases. To address this problem, the authors propose the PyramidDrop strategy, which gradually reduces image tokens at different stages of the model, thereby improving training and inference efficiency with negligible performance loss. Experimental results show that PyramidDrop can significantly accelerate training and inference speeds and can be used as a plug-and-play strategy to further speed up inference.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 197, "total_tokens": 330, "completion_tokens": 133}}
[23.10.2024 09:59] Response: This article discusses the computational cost issue of image representation in large-scale vision-language models (LVLMs). Images contain a large amount of information, and representing an image requires a large number of tokens, with the computational cost increasing as the image resolution increases. To address this problem, the authors propose the PyramidDrop strategy, which gradually reduces image tokens at different stages of the model, thereby improving training and inference efficiency with negligible performance loss. Experimental results show that PyramidDrop can significantly accelerate training and inference speeds and can be used as a plug-and-play strategy to further speed up inference.
[23.10.2024 09:59] Renaming data file.
[23.10.2024 09:59] Renaming previous data. hf_papers.json to ./d/2024-10-23.json
[23.10.2024 09:59] Saving new data file.
[23.10.2024 09:59] Generating page.
[23.10.2024 09:59] Renaming previous page.
[23.10.2024 09:59] Renaming previous data. index.html to ./d/2024-10-23.html
[23.10.2024 09:59] [Experimental] Generating Chinese page for reading.
[23.10.2024 09:59] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大规模', 'pinyin': 'dà guī mó', 'trans': 'large-scale'}, {'word': '视觉-语言模型', 'pinyin': 'shì jué yǔ yán mó xìng', 'trans': 'vision-language model'}, {'word': '计算成本', 'pinyin': 'jì suàn chéng běn', 'trans': 'computational cost'}, {'word': '表示', 'pinyin': 'biǎo shì', 'trans': 'representation'}, {'word': '标记', 'pinyin': 'biāo jì', 'trans': 'token'}, {'word': '分辨率', 'pinyin': 'fēn biàn lǜ', 'trans': 'resolution'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '逐步', 'pinyin': 'zhú bù', 'trans': 'gradually'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'training'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '损失', 'pinyin': 'sǔn shī', 'trans': 'loss'}, {'word': '可忽略', 'pinyin': 'kě hū lüè', 'trans': 'negligible'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '加快', 'pinyin': 'jiā kuài', 'trans': 'accelerate'}, {'word': '速度', 'pinyin': 'sù dù', 'trans': 'speed'}, {'word': '即插即用', 'pinyin': 'jí chā jí yòng', 'trans': 'plug-and-play'}, {'word': '进一步', 'pinyin': 'jìn yī bù', 'trans': 'further'}]
[23.10.2024 09:59] Renaming previous Chinese page.
[23.10.2024 09:59] Renaming previous data. zh.html to ./d/2024-10-22_zh_reading_task.html
[23.10.2024 09:59] Writing result.
[23.10.2024 09:59] Writing Chinese reading task.
[23.10.2024 09:59] Renaming log file.
[23.10.2024 09:59] Renaming previous data. log.txt to ./logs/2024-10-23_last_log.txt
