[21.11.2024 08:14] Read previous papers.
[21.11.2024 08:14] Generating top page (month).
[21.11.2024 08:14] Writing top page (month).
[21.11.2024 09:11] Read previous papers.
[21.11.2024 09:11] Get feed.
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.10958
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13503
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13281
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06559
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.11922
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13025
[21.11.2024 09:11] Downloading and parsing papers (pdf, html). Total: 6.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.10958.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.10958.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.10958.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.13503.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.13503.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.13503.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.13281.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.13281.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.13281.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.06559.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.06559.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.06559.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.11922.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.11922.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.11922.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.13025.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.13025.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.13025.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Enriching papers with extra data.
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 0. Although quantization for linear layers has been widely used, its application to accelerate the attention process remains limited. SageAttention utilizes 8-bit matrix multiplication, 16-bit matrix multiplication with 16-bit accumulator, and precision-enhancing methods, implementing an accurate and 2...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 1. Video generation has witnessed significant advancements, yet evaluating these models remains a challenge. A comprehensive evaluation benchmark for video generation is indispensable for two reasons: 1) Existing metrics do not fully align with human perceptions; 2) An ideal evaluation system should pr...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 2. Large multimodal models (LMMs) with advanced video analysis capabilities have recently garnered significant attention. However, most evaluations rely on traditional methods like multiple-choice questions in benchmarks such as VideoMME and LongVideoBench, which are prone to lack the depth needed to c...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 3. Language agents have demonstrated promising capabilities in automating web-based tasks, though their current reactive approaches still underperform largely compared to humans. While incorporating advanced planning algorithms, particularly tree search methods, could enhance these agents' performance,...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 4. The Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks but faces challenges in visual object tracking, particularly when managing crowded scenes with fast-moving or self-occluding objects. Furthermore, the fixed-window memory approach in the original mo...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 5. The objective of Radiology Report Generation (RRG) is to automatically generate coherent textual analyses of diseases based on radiological images, thereby alleviating the workload of radiologists. Current AI-based methods for RRG primarily focus on modifications to the encoder-decoder model archite...
[21.11.2024 09:11] Read previous papers.
[21.11.2024 09:11] Generating reviews via LLM API.
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#video", "#inference", "#training", "#optimization", "#cv"], "emoji": "‚ö°", "ru": {"title": "–ë—ã—Å—Ç—Ä–µ–µ –∏ —Ç–æ—á–Ω–µ–µ: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –º–µ—Ö–∞–Ω–∏–∑–º–µ –≤–Ω–∏–º–∞–Ω–∏—è", "desc": "SageAttention2 - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤–Ω–∏–º–∞–Ω–∏—è –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 4-–±–∏—Ç–Ω–æ–µ –º–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –∏ 
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#open_source", "#alignment", "#benchmark", "#video"], "emoji": "üé•", "ru": {"title": "VBench: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ", "desc": "VBench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ. –û–Ω —Ä–∞–∑–±–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ 16 –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#interpretability", "#multimodal", "#optimization", "#benchmark", "#video", "#games"], "emoji": "üé•", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ—Ü–µ–Ω–∫–µ –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑–∞: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä–µ–Ω–∞ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç VideoAutoArena - –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –º—É–ª—å—Ç–∏–º–æ–¥
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#architecture", "#agents", "#optimization", "#benchmark"], "emoji": "üåê", "ru": {"title": "WebDreamer: LLM –∫–∞–∫ –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –¥–ª—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ WebDreamer –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —è–∑—ã–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –≤–µ–±-–∑–∞–¥–∞—á. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à–∏–µ —è
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#transfer_learning", "#video", "#benchmark", "#optimization", "#cv"], "emoji": "ü•∑", "ru": {"title": "SAMURAI: –¢–æ—á–Ω–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "SAMURAI - —ç—Ç–æ —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ SAM 2, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ–±—ä–µ
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#multimodal", "#graphs", "#dataset", "#games", "#architecture"], "emoji": "üè•", "ru": {"title": "–£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –æ—Ä–≥–∞–Ω—ã", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π ORID (Organ-Regional
[21.11.2024 09:11] Trying to get texts in Chinese.
[21.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Although quantization for linear layers has been widely used, its application to accelerate the attention process remains limited. SageAttention utilizes 8-bit matrix multiplication, 16-bit matrix multiplication with 16-bit accumulator, and precision-enhancing methods, implementing an accurate and 2x speedup kernel compared to FlashAttention2. To further enhance the efficiency of attention computation while maintaining precision, we propose SageAttention2, which utilizes significantly faster 4-bit matrix multiplication (Matmul) alongside additional precision-enhancing techniques. First, we propose to quantize matrixes (Q, K) to INT4 in a warp-level granularity and quantize matrixes (widetilde P, V) to FP8. Second, we propose a method to smooth Q and V, enhancing the accuracy of attention with INT4 QK and FP8 PV. Third, we analyze the quantization accuracy across timesteps and layers, then propose an adaptive quantization method to ensure the end-to-end metrics over various models. The operations per second (OPS) of SageAttention2 surpass FlashAttention2 and xformers by about 3x and 5x on RTX4090, respectively. Comprehensive experiments confirm that our approach incurs negligible end-to-end metrics loss across diverse models, including those for large language processing, image generation, and video generation. The codes are available at https://github.com/thu-ml/SageAttention.
[21.11.2024 09:11] Mistral response. {"id": "a4c551eddd06426288bb4e69a61bf73f", "object": "chat.completion", "created": 1732180290, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u52a0\u901f\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a SageAttention2\u3002\u5b83\u4f7f\u7528 4-bit \u77e9\u9635\u4e58\u6cd5\u548c\u7cbe\u5ea6\u589e\u5f3a\u6280\u672f\u3002\u9996\u5148\uff0c\u5c06\u77e9\u9635 Q \u548c K \u91cf\u5316\u4e3a INT4\uff0c\u5c06\u77e9\u9635 P \u548c V \u91cf\u5316\u4e3a FP8\u3002\u7136\u540e\uff0c\u63d0\u51fa\u5e73\u6ed1 Q \u548c V \u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6ce8\u610f\u529b\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u51e0\u4e4e\u6ca1\u6709\u6027\u80fd\u635f\u5931\uff0c\u5e76\u4e14\u5728 RTX4090 \u4e0a\u7684\u64cd\u4f5c\u901f\u5ea6\u662f FlashAttention2 \u548c xformers \u7684 3 \u500d\u548c 5 \u500d\u3002\u4ee3\u7801\u5df2\u5728 GitHub \u4e0a\u516c\u5f00\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 360, "total_tokens": 540, "completion_tokens": 180}}
[21.11.2024 09:11] Response: ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÂä†ÈÄüÊ≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫ SageAttention2„ÄÇÂÆÉ‰ΩøÁî® 4-bit Áü©Èòµ‰πòÊ≥ïÂíåÁ≤æÂ∫¶Â¢ûÂº∫ÊäÄÊúØ„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÁü©Èòµ Q Âíå K ÈáèÂåñ‰∏∫ INT4ÔºåÂ∞ÜÁü©Èòµ P Âíå V ÈáèÂåñ‰∏∫ FP8„ÄÇÁÑ∂ÂêéÔºåÊèêÂá∫Âπ≥Êªë Q Âíå V ÁöÑÊñπÊ≥ïÔºåÊèêÈ´òÊ≥®ÊÑèÂäõÁ≤æÂ∫¶„ÄÇÂÆûÈ™åËØÅÊòéÔºåËøôÁßçÊñπÊ≥ïÂú®Â§öÁßçÊ®°Âûã‰∏äÂá†‰πéÊ≤°ÊúâÊÄßËÉΩÊçüÂ§±ÔºåÂπ∂‰∏îÂú® RTX4090 ‰∏äÁöÑÊìç‰ΩúÈÄüÂ∫¶ÊòØ FlashAttention2 Âíå xformers ÁöÑ 3 ÂÄçÂíå 5 ÂÄç„ÄÇ‰ª£Á†ÅÂ∑≤Âú® GitHub ‰∏äÂÖ¨ÂºÄ„ÄÇ
[21.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÂä†ÈÄüÊ≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫ SageAttention2„ÄÇÂÆÉ‰ΩøÁî® 4-bit Áü©Èòµ‰πòÊ≥ïÂíåÁ≤æÂ∫¶Â¢ûÂº∫ÊäÄÊúØ„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÁü©Èòµ Q Âíå K ÈáèÂåñ‰∏∫ INT4ÔºåÂ∞ÜÁü©Èòµ P Âíå V ÈáèÂåñ‰∏∫ FP8„ÄÇÁÑ∂ÂêéÔºåÊèêÂá∫Âπ≥Êªë Q Âíå V ÁöÑÊñπÊ≥ïÔºåÊèêÈ´òÊ≥®ÊÑèÂäõÁ≤æÂ∫¶„ÄÇÂÆûÈ™åËØÅÊòéÔºåËøôÁßçÊñπÊ≥ïÂú®Â§öÁßçÊ®°Âûã‰∏äÂá†‰πéÊ≤°ÊúâÊÄßËÉΩÊçüÂ§±ÔºåÂπ∂‰∏îÂú® RTX4090 ‰∏äÁöÑÊìç‰ΩúÈÄüÂ∫¶ÊòØ FlashAttention2 Âíå xformers ÁöÑ 3 ÂÄçÂíå 5 ÂÄç„ÄÇ‰ª£Á†ÅÂ∑≤Âú® GitHub ‰∏äÂÖ¨ÂºÄ„ÄÇ
[21.11.2024 09:11] Mistral response. {"id": "7ed1105ca1724b5eadf899423bf8ba35", "object": "chat.completion", "created": 1732180295, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u52a0\u901f\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a SageAttention2\u3002\u5b83\u4f7f\u7528 4-bit \u77e9\u9635\u4e58\u6cd5\u548c\u7cbe\u5ea6\u589e\u5f3a\u6280\u672f\u3002\u9996\u5148\uff0c\u5c06\u77e9\u9635 Q \u548c K \u91cf\u5316\u4e3a INT4\uff0c\u5c06\u77e9\u9635 P \u548c V \u91cf\u5316\u4e3a FP8\u3002\u7136\u540e\uff0c\u63d0\u51fa\u5e73\u6ed1 Q \u548c V \u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6ce8\u610f\u529b\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u51e0\u4e4e\u6ca1\u6709\u6027\u80fd\u635f\u5931\uff0c\u5e76\u4e14\u5728 RTX4090 \u4e0a\u7684\u64cd\u4f5c\u901f\u5ea6\u662f FlashAttention2 \u548c xformers \u7684 3 \u500d\u548c 5 \u500d\u3002\u4ee3\u7801\u5df2\u5728 GitHub \u4e0a\u516c\u5f00\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng ji\u00e8 sh\u00e0o le y\u012b zh\u01d2ng ji\u0101 s\u00f9 zh\u00f9 y\u00ec l\u00ec j\u00ec su\u00e0n de f\u0101ng f\u01ce, ch\u0113ng w\u00e9i SageAttention2. t\u0101 sh\u01d0 y\u00f2ng 4-bit j\u01d4 zh\u00e8n ch\u00e9ng f\u01ce h\u00e9 j\u012bng d\u00f9 z\u0113ng qi\u00e1ng j\u00ec sh\u00f9. sh\u01d2u xi\u0101n, ji\u0101ng j\u01d4 zh\u00e8n Q h\u00e9 K li\u00e0ng hu\u00e0 w\u00e9i INT4, ji\u0101ng j\u01d4 zh\u00e8n P h\u00e9 V li\u00e0ng hu\u00e0 w\u00e9i FP8. r\u00e1n h\u00f2u, t\u00ed ch\u016b p\u00edng hu\u00e1 Q h\u00e9 V de f\u0101ng f\u01ce, t\u00ed g\u0101o zh\u00f9 y\u00ec l\u00ec j\u012bng d\u00f9. sh\u00ed y\u00e0n zh\u00e8ng m\u00edng, zh\u00e8 zh\u01d2ng f\u0101ng f\u01ce z\u00e0i du\u014d zh\u01d2ng m\u00f3 x\u00edng sh\u00e0ng j\u012b h\u016b m\u00e9i y\u01d2u x\u00ecng n\u00e9ng s\u01d4n sh\u012b, b\u00ecng qi\u011b z\u00e0i RTX4090 sh\u00e0ng de c\u0101o zu\u00f2 s\u00f9 d\u00f9 sh\u00ec FlashAttention2 h\u00e9 xformers de 3 b\u00e8i h\u00e9 5 b\u00e8i. d\u00e0i m\u01ce y\u01d0 z\u00e0i GitHub sh\u00e0ng g\u014dng k\u0101i.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 195, "total_tokens": 717, "completion_tokens": 522}}
[21.11.2024 09:11] Response: ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÂä†ÈÄüÊ≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫ SageAttention2„ÄÇÂÆÉ‰ΩøÁî® 4-bit Áü©Èòµ‰πòÊ≥ïÂíåÁ≤æÂ∫¶Â¢ûÂº∫ÊäÄÊúØ„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÁü©Èòµ Q Âíå K ÈáèÂåñ‰∏∫ INT4ÔºåÂ∞ÜÁü©Èòµ P Âíå V ÈáèÂåñ‰∏∫ FP8„ÄÇÁÑ∂ÂêéÔºåÊèêÂá∫Âπ≥Êªë Q Âíå V ÁöÑÊñπÊ≥ïÔºåÊèêÈ´òÊ≥®ÊÑèÂäõÁ≤æÂ∫¶„ÄÇÂÆûÈ™åËØÅÊòéÔºåËøôÁßçÊñπÊ≥ïÂú®Â§öÁßçÊ®°Âûã‰∏äÂá†‰πéÊ≤°ÊúâÊÄßËÉΩÊçüÂ§±ÔºåÂπ∂‰∏îÂú® RTX4090 ‰∏äÁöÑÊìç‰ΩúÈÄüÂ∫¶ÊòØ FlashAttention2 Âíå xformers ÁöÑ 3 ÂÄçÂíå 5 ÂÄç„ÄÇ‰ª£Á†ÅÂ∑≤Âú® GitHub ‰∏äÂÖ¨ÂºÄ„ÄÇ

zh√® piƒÅn w√©n zhƒÅng ji√® sh√†o le yƒ´ zh«íng jiƒÅ s√π zh√π y√¨ l√¨ j√¨ su√†n de fƒÅng f«é, chƒìng w√©i SageAttention2. tƒÅ sh«ê y√≤ng 4-bit j«î zh√®n ch√©ng f«é h√© jƒ´ng d√π zƒìng qi√°ng j√¨ sh√π. sh«íu xiƒÅn, jiƒÅng j«î zh√®n Q h√© K li√†ng hu√† w√©i INT4, jiƒÅng j«î zh√®n P h√© V li√†ng hu√† w√©i FP8. r√°n h√≤u, t√≠ ch≈´ p√≠ng hu√° Q h√© V de fƒÅng f«é, t√≠ gƒÅo zh√π y√¨ l√¨ jƒ´ng d√π. sh√≠ y√†n zh√®ng m√≠ng, zh√® zh«íng fƒÅng f«é z√†i du≈ç zh«íng m√≥ x√≠ng sh√†ng jƒ´ h≈´ m√©i y«íu x√¨ng n√©ng s«în shƒ´, b√¨ng qiƒõ z√†i RTX4090 sh√†ng de cƒÅo zu√≤ s√π d√π sh√¨ FlashAttention2 h√© xformers de 3 b√®i h√© 5 b√®i. d√†i m«é y«ê z√†i GitHub sh√†ng g≈çng kƒÅi.
[21.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÂä†ÈÄüÊ≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫ SageAttention2„ÄÇÂÆÉ‰ΩøÁî® 4-bit Áü©Èòµ‰πòÊ≥ïÂíåÁ≤æÂ∫¶Â¢ûÂº∫ÊäÄÊúØ„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÁü©Èòµ Q Âíå K ÈáèÂåñ‰∏∫ INT4ÔºåÂ∞ÜÁü©Èòµ P Âíå V ÈáèÂåñ‰∏∫ FP8„ÄÇÁÑ∂ÂêéÔºåÊèêÂá∫Âπ≥Êªë Q Âíå V ÁöÑÊñπÊ≥ïÔºåÊèêÈ´òÊ≥®ÊÑèÂäõÁ≤æÂ∫¶„ÄÇÂÆûÈ™åËØÅÊòéÔºåËøôÁßçÊñπÊ≥ïÂú®Â§öÁßçÊ®°Âûã‰∏äÂá†‰πéÊ≤°ÊúâÊÄßËÉΩÊçüÂ§±ÔºåÂπ∂‰∏îÂú® RTX4090 ‰∏äÁöÑÊìç‰ΩúÈÄüÂ∫¶ÊòØ FlashAttention2 Âíå xformers ÁöÑ 3 ÂÄçÂíå 5 ÂÄç„ÄÇ‰ª£Á†ÅÂ∑≤Âú® GitHub ‰∏äÂÖ¨ÂºÄ„ÄÇ
[21.11.2024 09:12] Mistral response. {"id": "ead0b896b5054be7aa8cebaa087c7f05", "object": "chat.completion", "created": 1732180310, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[{'word': '\u52a0\u901f', 'pinyin': 'ji\u0101 s\u00f9', 'trans': 'accelerate'},\n{'word': '\u6ce8\u610f\u529b', 'pinyin': 'zh\u00f9 y\u00ec l\u00ec', 'trans': 'attention'},\n{'word': '\u8ba1\u7b97', 'pinyin': 'j\u00ec su\u00e0n', 'trans': 'calculation'},\n{'word': '\u65b9\u6cd5', 'pinyin': 'f\u0101ng f\u01ce', 'trans': 'method'},\n{'word': '\u79f0\u4e3a', 'pinyin': 'ch\u0113ng w\u00e9i', 'trans': 'called'},\n{'word': '\u77e9\u9635', 'pinyin': 'j\u01d4 zh\u00e8n', 'trans': 'matrix'},\n{'word': '\u4e58\u6cd5', 'pinyin': 'ch\u00e9n f\u01ce', 'trans': 'multiplication'},\n{'word': '\u7cbe\u5ea6', 'pinyin': 'j\u012bng d\u00f9', 'trans': 'precision'},\n{'word': '\u589e\u5f3a', 'pinyin': 'z\u0113ng qi\u00e1ng', 'trans': 'enhancement'},\n{'word': '\u6280\u672f', 'pinyin': 'j\u00ec sh\u00f9', 'trans': 'technology'},\n{'word': '\u91cf\u5316', 'pinyin': 'li\u00e0ng hu\u00e0', 'trans': 'quantization'},\n{'word': '\u5e73\u6ed1', 'pinyin': 'p\u00edng hu\u00e1', 'trans': 'smooth'},\n{'word': '\u63d0\u9ad8', 'pinyin': 't\u00ed g\u0101o', 'trans': 'improve'},\n{'word': '\u5b9e\u9a8c', 'pinyin': 'sh\u00ed y\u00e0n', 'trans': 'experiment'},\n{'word': '\u8bc1\u660e', 'pinyin': 'zh\u00e8ng m\u00edng', 'trans': 'prove'},\n{'word': '\u6027\u80fd', 'pinyin': 'x\u00ecng n\u00e9ng', 'trans': 'performance'},\n{'word': '\u635f\u5931', 'pinyin': 's\u01d4n sh\u012b', 'trans': 'loss'},\n{'word': '\u64cd\u4f5c', 'pinyin': 'c\u0101o zu\u00f2', 'trans': 'operation'},\n{'word': '\u901f\u5ea6', 'pinyin': 's\u00f9 d\u00f9', 'trans': 'speed'},\n{'word': '\u516c\u5f00', 'pinyin': 'g\u014dng k\u0101i', 'trans': 'public'},\n{'word': '\u4ee3\u7801', 'pinyin': 'd\u00e0i m\u01ce', 'trans': 'code'}]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 227, "total_tokens": 798, "completion_tokens": 571}}
[21.11.2024 09:12] Response: [{'word': 'Âä†ÈÄü', 'pinyin': 'jiƒÅ s√π', 'trans': 'accelerate'},
{'word': 'Ê≥®ÊÑèÂäõ', 'pinyin': 'zh√π y√¨ l√¨', 'trans': 'attention'},
{'word': 'ËÆ°ÁÆó', 'pinyin': 'j√¨ su√†n', 'trans': 'calculation'},
{'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'},
{'word': 'Áß∞‰∏∫', 'pinyin': 'chƒìng w√©i', 'trans': 'called'},
{'word': 'Áü©Èòµ', 'pinyin': 'j«î zh√®n', 'trans': 'matrix'},
{'word': '‰πòÊ≥ï', 'pinyin': 'ch√©n f«é', 'trans': 'multiplication'},
{'word': 'Á≤æÂ∫¶', 'pinyin': 'jƒ´ng d√π', 'trans': 'precision'},
{'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìng qi√°ng', 'trans': 'enhancement'},
{'word': 'ÊäÄÊúØ', 'pinyin': 'j√¨ sh√π', 'trans': 'technology'},
{'word': 'ÈáèÂåñ', 'pinyin': 'li√†ng hu√†', 'trans': 'quantization'},
{'word': 'Âπ≥Êªë', 'pinyin': 'p√≠ng hu√°', 'trans': 'smooth'},
{'word': 'ÊèêÈ´ò', 'pinyin': 't√≠ gƒÅo', 'trans': 'improve'},
{'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠ y√†n', 'trans': 'experiment'},
{'word': 'ËØÅÊòé', 'pinyin': 'zh√®ng m√≠ng', 'trans': 'prove'},
{'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'},
{'word': 'ÊçüÂ§±', 'pinyin': 's«în shƒ´', 'trans': 'loss'},
{'word': 'Êìç‰Ωú', 'pinyin': 'cƒÅo zu√≤', 'trans': 'operation'},
{'word': 'ÈÄüÂ∫¶', 'pinyin': 's√π d√π', 'trans': 'speed'},
{'word': 'ÂÖ¨ÂºÄ', 'pinyin': 'g≈çng kƒÅi', 'trans': 'public'},
{'word': '‰ª£Á†Å', 'pinyin': 'd√†i m«é', 'trans': 'code'}]
[21.11.2024 09:12] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫Ü‰∏ÄÁßçÂä†ÈÄüÊ≥®ÊÑèÂäõËÆ°ÁÆóÁöÑÊñπÊ≥ïÔºåÁß∞‰∏∫ SageAttention2„ÄÇÂÆÉ‰ΩøÁî® 4-bit Áü©Èòµ‰πòÊ≥ïÂíåÁ≤æÂ∫¶Â¢ûÂº∫ÊäÄÊúØ„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÁü©Èòµ Q Âíå K ÈáèÂåñ‰∏∫ INT4ÔºåÂ∞ÜÁü©Èòµ P Âíå V ÈáèÂåñ‰∏∫ FP8„ÄÇÁÑ∂ÂêéÔºåÊèêÂá∫Âπ≥Êªë Q Âíå V ÁöÑÊñπÊ≥ïÔºåÊèêÈ´òÊ≥®ÊÑèÂäõÁ≤æÂ∫¶„ÄÇÂÆûÈ™åËØÅÊòéÔºåËøôÁßçÊñπÊ≥ïÂú®Â§öÁßçÊ®°Âûã‰∏äÂá†‰πéÊ≤°ÊúâÊÄßËÉΩÊçüÂ§±ÔºåÂπ∂‰∏îÂú® RTX4090 ‰∏äÁöÑÊìç‰ΩúÈÄüÂ∫¶ÊòØ FlashAttention2 Âíå xformers ÁöÑ 3 ÂÄçÂíå 5 ÂÄç„ÄÇ‰ª£Á†ÅÂ∑≤Âú® GitHub ‰∏äÂÖ¨ÂºÄ„ÄÇ
[21.11.2024 09:12] Mistral response. {"id": "a4dcce3c57d440c5a6903d79b531b56b", "object": "chat.completion", "created": 1732180324, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article introduces a method for accelerating attention computation, called SageAttention2. It employs 4-bit matrix multiplication and precision enhancement techniques. First, matrices Q and K are quantized to INT4, while matrices P and V are quantized to FP8. Then, a method for smoothing Q and V is proposed to improve attention precision. Experiments demonstrate that this method incurs almost no performance loss across various models and operates at speeds that are 3 times and 5 times faster than FlashAttention2 and xformers, respectively, on the RTX4090. The code has been made publicly available on GitHub.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 193, "total_tokens": 333, "completion_tokens": 140}}
[21.11.2024 09:12] Response: This article introduces a method for accelerating attention computation, called SageAttention2. It employs 4-bit matrix multiplication and precision enhancement techniques. First, matrices Q and K are quantized to INT4, while matrices P and V are quantized to FP8. Then, a method for smoothing Q and V is proposed to improve attention precision. Experiments demonstrate that this method incurs almost no performance loss across various models and operates at speeds that are 3 times and 5 times faster than FlashAttention2 and xformers, respectively, on the RTX4090. The code has been made publicly available on GitHub.
[21.11.2024 09:12] Renaming data file.
[21.11.2024 09:12] Renaming previous data. hf_papers.json to ./d/2024-11-21.json
[21.11.2024 09:12] Saving new data file.
[21.11.2024 09:12] Generating page.
[21.11.2024 09:12] Renaming previous page.
[21.11.2024 09:12] Renaming previous data. index.html to ./d/2024-11-21.html
[21.11.2024 09:12] [Experimental] Generating Chinese page for reading.
[21.11.2024 09:12] Chinese vocab [{'word': 'Âä†ÈÄü', 'pinyin': 'jiƒÅ s√π', 'trans': 'accelerate'}, {'word': 'Ê≥®ÊÑèÂäõ', 'pinyin': 'zh√π y√¨ l√¨', 'trans': 'attention'}, {'word': 'ËÆ°ÁÆó', 'pinyin': 'j√¨ su√†n', 'trans': 'calculation'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': 'Áß∞‰∏∫', 'pinyin': 'chƒìng w√©i', 'trans': 'called'}, {'word': 'Áü©Èòµ', 'pinyin': 'j«î zh√®n', 'trans': 'matrix'}, {'word': '‰πòÊ≥ï', 'pinyin': 'ch√©n f«é', 'trans': 'multiplication'}, {'word': 'Á≤æÂ∫¶', 'pinyin': 'jƒ´ng d√π', 'trans': 'precision'}, {'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìng qi√°ng', 'trans': 'enhancement'}, {'word': 'ÊäÄÊúØ', 'pinyin': 'j√¨ sh√π', 'trans': 'technology'}, {'word': 'ÈáèÂåñ', 'pinyin': 'li√†ng hu√†', 'trans': 'quantization'}, {'word': 'Âπ≥Êªë', 'pinyin': 'p√≠ng hu√°', 'trans': 'smooth'}, {'word': 'ÊèêÈ´ò', 'pinyin': 't√≠ gƒÅo', 'trans': 'improve'}, {'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠ y√†n', 'trans': 'experiment'}, {'word': 'ËØÅÊòé', 'pinyin': 'zh√®ng m√≠ng', 'trans': 'prove'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'ÊçüÂ§±', 'pinyin': 's«în shƒ´', 'trans': 'loss'}, {'word': 'Êìç‰Ωú', 'pinyin': 'cƒÅo zu√≤', 'trans': 'operation'}, {'word': 'ÈÄüÂ∫¶', 'pinyin': 's√π d√π', 'trans': 'speed'}, {'word': 'ÂÖ¨ÂºÄ', 'pinyin': 'g≈çng kƒÅi', 'trans': 'public'}, {'word': '‰ª£Á†Å', 'pinyin': 'd√†i m«é', 'trans': 'code'}]
[21.11.2024 09:12] Renaming previous Chinese page.
[21.11.2024 09:12] Renaming previous data. zh.html to ./d/2024-11-20_zh_reading_task.html
[21.11.2024 09:12] Writing Chinese reading task.
[21.11.2024 09:12] Writing result.
[21.11.2024 09:12] Renaming log file.
[21.11.2024 09:12] Renaming previous data. log.txt to ./logs/2024-11-21_last_log.txt
