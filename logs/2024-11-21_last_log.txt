[21.11.2024 08:14] Read previous papers.
[21.11.2024 08:14] Generating top page (month).
[21.11.2024 08:14] Writing top page (month).
[21.11.2024 09:11] Read previous papers.
[21.11.2024 09:11] Get feed.
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.10958
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13503
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13281
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06559
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.11922
[21.11.2024 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.13025
[21.11.2024 09:11] Downloading and parsing papers (pdf, html). Total: 6.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.10958.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.10958.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.10958.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.13503.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.13503.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.13503.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.13281.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.13281.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.13281.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.06559.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.06559.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.06559.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.11922.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.11922.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.11922.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Downloading and parsing paper https://huggingface.co/papers/2411.13025.
[21.11.2024 09:11] Extra JSON file exists (./assets/json/2411.13025.json), skip PDF parsing.
[21.11.2024 09:11] Paper image links file exists (./assets/img_data/2411.13025.json), skip HTML parsing.
[21.11.2024 09:11] Success.
[21.11.2024 09:11] Enriching papers with extra data.
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 0. Although quantization for linear layers has been widely used, its application to accelerate the attention process remains limited. SageAttention utilizes 8-bit matrix multiplication, 16-bit matrix multiplication with 16-bit accumulator, and precision-enhancing methods, implementing an accurate and 2...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 1. Video generation has witnessed significant advancements, yet evaluating these models remains a challenge. A comprehensive evaluation benchmark for video generation is indispensable for two reasons: 1) Existing metrics do not fully align with human perceptions; 2) An ideal evaluation system should pr...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 2. Large multimodal models (LMMs) with advanced video analysis capabilities have recently garnered significant attention. However, most evaluations rely on traditional methods like multiple-choice questions in benchmarks such as VideoMME and LongVideoBench, which are prone to lack the depth needed to c...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 3. Language agents have demonstrated promising capabilities in automating web-based tasks, though their current reactive approaches still underperform largely compared to humans. While incorporating advanced planning algorithms, particularly tree search methods, could enhance these agents' performance,...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 4. The Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks but faces challenges in visual object tracking, particularly when managing crowded scenes with fast-moving or self-occluding objects. Furthermore, the fixed-window memory approach in the original mo...
[21.11.2024 09:11] ********************************************************************************
[21.11.2024 09:11] Abstract 5. The objective of Radiology Report Generation (RRG) is to automatically generate coherent textual analyses of diseases based on radiological images, thereby alleviating the workload of radiologists. Current AI-based methods for RRG primarily focus on modifications to the encoder-decoder model archite...
[21.11.2024 09:11] Read previous papers.
[21.11.2024 09:11] Generating reviews via LLM API.
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#video", "#inference", "#training", "#optimization", "#cv"], "emoji": "âš¡", "ru": {"title": "Ğ‘Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ: Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ", "desc": "SageAttention2 - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ 4-Ğ±Ğ¸Ñ‚Ğ½Ğ¾Ğµ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸ 
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#open_source", "#alignment", "#benchmark", "#video"], "emoji": "ğŸ¥", "ru": {"title": "VBench: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾", "desc": "VBench Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾. ĞĞ½ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° 16 Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑ
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#interpretability", "#multimodal", "#optimization", "#benchmark", "#video", "#games"], "emoji": "ğŸ¥", "ru": {"title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ°Ñ€ĞµĞ½Ğ° Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ VideoAutoArena - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#architecture", "#agents", "#optimization", "#benchmark"], "emoji": "ğŸŒ", "ru": {"title": "WebDreamer: LLM ĞºĞ°Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ Ğ²ĞµĞ±-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ WebDreamer Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ²ĞµĞ±-Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ñ
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#transfer_learning", "#video", "#benchmark", "#optimization", "#cv"], "emoji": "ğŸ¥·", "ru": {"title": "SAMURAI: Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", "desc": "SAMURAI - ÑÑ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ SAM 2, Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµ
[21.11.2024 09:11] Using data from previous issue: {"categories": ["#multimodal", "#graphs", "#dataset", "#games", "#architecture"], "emoji": "ğŸ¥", "ru": {"title": "Ğ£Ğ¼Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ñ Ñ„Ğ¾ĞºÑƒÑĞ¾Ğ¼ Ğ½Ğ° Ğ¾Ñ€Ğ³Ğ°Ğ½Ñ‹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ°Ğ´Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ², Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ ORID (Organ-Regional
[21.11.2024 09:11] Trying to get texts in Chinese.
[21.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Although quantization for linear layers has been widely used, its application to accelerate the attention process remains limited. SageAttention utilizes 8-bit matrix multiplication, 16-bit matrix multiplication with 16-bit accumulator, and precision-enhancing methods, implementing an accurate and 2x speedup kernel compared to FlashAttention2. To further enhance the efficiency of attention computation while maintaining precision, we propose SageAttention2, which utilizes significantly faster 4-bit matrix multiplication (Matmul) alongside additional precision-enhancing techniques. First, we propose to quantize matrixes (Q, K) to INT4 in a warp-level granularity and quantize matrixes (widetilde P, V) to FP8. Second, we propose a method to smooth Q and V, enhancing the accuracy of attention with INT4 QK and FP8 PV. Third, we analyze the quantization accuracy across timesteps and layers, then propose an adaptive quantization method to ensure the end-to-end metrics over various models. The operations per second (OPS) of SageAttention2 surpass FlashAttention2 and xformers by about 3x and 5x on RTX4090, respectively. Comprehensive experiments confirm that our approach incurs negligible end-to-end metrics loss across diverse models, including those for large language processing, image generation, and video generation. The codes are available at https://github.com/thu-ml/SageAttention.
[21.11.2024 09:11] Mistral response. {"id": "a4c551eddd06426288bb4e69a61bf73f", "object": "chat.completion", "created": 1732180290, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u52a0\u901f\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a SageAttention2\u3002\u5b83\u4f7f\u7528 4-bit \u77e9\u9635\u4e58\u6cd5\u548c\u7cbe\u5ea6\u589e\u5f3a\u6280\u672f\u3002\u9996\u5148\uff0c\u5c06\u77e9\u9635 Q \u548c K \u91cf\u5316\u4e3a INT4\uff0c\u5c06\u77e9\u9635 P \u548c V \u91cf\u5316\u4e3a FP8\u3002\u7136\u540e\uff0c\u63d0\u51fa\u5e73\u6ed1 Q \u548c V \u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6ce8\u610f\u529b\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u51e0\u4e4e\u6ca1\u6709\u6027\u80fd\u635f\u5931\uff0c\u5e76\u4e14\u5728 RTX4090 \u4e0a\u7684\u64cd\u4f5c\u901f\u5ea6\u662f FlashAttention2 \u548c xformers \u7684 3 \u500d\u548c 5 \u500d\u3002\u4ee3\u7801\u5df2\u5728 GitHub \u4e0a\u516c\u5f00\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 360, "total_tokens": 540, "completion_tokens": 180}}
[21.11.2024 09:11] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—çš„æ–¹æ³•ï¼Œç§°ä¸º SageAttention2ã€‚å®ƒä½¿ç”¨ 4-bit çŸ©é˜µä¹˜æ³•å’Œç²¾åº¦å¢å¼ºæŠ€æœ¯ã€‚é¦–å…ˆï¼Œå°†çŸ©é˜µ Q å’Œ K é‡åŒ–ä¸º INT4ï¼Œå°†çŸ©é˜µ P å’Œ V é‡åŒ–ä¸º FP8ã€‚ç„¶åï¼Œæå‡ºå¹³æ»‘ Q å’Œ V çš„æ–¹æ³•ï¼Œæé«˜æ³¨æ„åŠ›ç²¾åº¦ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šç§æ¨¡å‹ä¸Šå‡ ä¹æ²¡æœ‰æ€§èƒ½æŸå¤±ï¼Œå¹¶ä¸”åœ¨ RTX4090 ä¸Šçš„æ“ä½œé€Ÿåº¦æ˜¯ FlashAttention2 å’Œ xformers çš„ 3 å€å’Œ 5 å€ã€‚ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ã€‚
[21.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—çš„æ–¹æ³•ï¼Œç§°ä¸º SageAttention2ã€‚å®ƒä½¿ç”¨ 4-bit çŸ©é˜µä¹˜æ³•å’Œç²¾åº¦å¢å¼ºæŠ€æœ¯ã€‚é¦–å…ˆï¼Œå°†çŸ©é˜µ Q å’Œ K é‡åŒ–ä¸º INT4ï¼Œå°†çŸ©é˜µ P å’Œ V é‡åŒ–ä¸º FP8ã€‚ç„¶åï¼Œæå‡ºå¹³æ»‘ Q å’Œ V çš„æ–¹æ³•ï¼Œæé«˜æ³¨æ„åŠ›ç²¾åº¦ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šç§æ¨¡å‹ä¸Šå‡ ä¹æ²¡æœ‰æ€§èƒ½æŸå¤±ï¼Œå¹¶ä¸”åœ¨ RTX4090 ä¸Šçš„æ“ä½œé€Ÿåº¦æ˜¯ FlashAttention2 å’Œ xformers çš„ 3 å€å’Œ 5 å€ã€‚ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ã€‚
[21.11.2024 09:11] Mistral response. {"id": "7ed1105ca1724b5eadf899423bf8ba35", "object": "chat.completion", "created": 1732180295, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u52a0\u901f\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a SageAttention2\u3002\u5b83\u4f7f\u7528 4-bit \u77e9\u9635\u4e58\u6cd5\u548c\u7cbe\u5ea6\u589e\u5f3a\u6280\u672f\u3002\u9996\u5148\uff0c\u5c06\u77e9\u9635 Q \u548c K \u91cf\u5316\u4e3a INT4\uff0c\u5c06\u77e9\u9635 P \u548c V \u91cf\u5316\u4e3a FP8\u3002\u7136\u540e\uff0c\u63d0\u51fa\u5e73\u6ed1 Q \u548c V \u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6ce8\u610f\u529b\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u51e0\u4e4e\u6ca1\u6709\u6027\u80fd\u635f\u5931\uff0c\u5e76\u4e14\u5728 RTX4090 \u4e0a\u7684\u64cd\u4f5c\u901f\u5ea6\u662f FlashAttention2 \u548c xformers \u7684 3 \u500d\u548c 5 \u500d\u3002\u4ee3\u7801\u5df2\u5728 GitHub \u4e0a\u516c\u5f00\u3002\n\nzh\u00e8 pi\u0101n w\u00e9n zh\u0101ng ji\u00e8 sh\u00e0o le y\u012b zh\u01d2ng ji\u0101 s\u00f9 zh\u00f9 y\u00ec l\u00ec j\u00ec su\u00e0n de f\u0101ng f\u01ce, ch\u0113ng w\u00e9i SageAttention2. t\u0101 sh\u01d0 y\u00f2ng 4-bit j\u01d4 zh\u00e8n ch\u00e9ng f\u01ce h\u00e9 j\u012bng d\u00f9 z\u0113ng qi\u00e1ng j\u00ec sh\u00f9. sh\u01d2u xi\u0101n, ji\u0101ng j\u01d4 zh\u00e8n Q h\u00e9 K li\u00e0ng hu\u00e0 w\u00e9i INT4, ji\u0101ng j\u01d4 zh\u00e8n P h\u00e9 V li\u00e0ng hu\u00e0 w\u00e9i FP8. r\u00e1n h\u00f2u, t\u00ed ch\u016b p\u00edng hu\u00e1 Q h\u00e9 V de f\u0101ng f\u01ce, t\u00ed g\u0101o zh\u00f9 y\u00ec l\u00ec j\u012bng d\u00f9. sh\u00ed y\u00e0n zh\u00e8ng m\u00edng, zh\u00e8 zh\u01d2ng f\u0101ng f\u01ce z\u00e0i du\u014d zh\u01d2ng m\u00f3 x\u00edng sh\u00e0ng j\u012b h\u016b m\u00e9i y\u01d2u x\u00ecng n\u00e9ng s\u01d4n sh\u012b, b\u00ecng qi\u011b z\u00e0i RTX4090 sh\u00e0ng de c\u0101o zu\u00f2 s\u00f9 d\u00f9 sh\u00ec FlashAttention2 h\u00e9 xformers de 3 b\u00e8i h\u00e9 5 b\u00e8i. d\u00e0i m\u01ce y\u01d0 z\u00e0i GitHub sh\u00e0ng g\u014dng k\u0101i.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 195, "total_tokens": 717, "completion_tokens": 522}}
[21.11.2024 09:11] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—çš„æ–¹æ³•ï¼Œç§°ä¸º SageAttention2ã€‚å®ƒä½¿ç”¨ 4-bit çŸ©é˜µä¹˜æ³•å’Œç²¾åº¦å¢å¼ºæŠ€æœ¯ã€‚é¦–å…ˆï¼Œå°†çŸ©é˜µ Q å’Œ K é‡åŒ–ä¸º INT4ï¼Œå°†çŸ©é˜µ P å’Œ V é‡åŒ–ä¸º FP8ã€‚ç„¶åï¼Œæå‡ºå¹³æ»‘ Q å’Œ V çš„æ–¹æ³•ï¼Œæé«˜æ³¨æ„åŠ›ç²¾åº¦ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šç§æ¨¡å‹ä¸Šå‡ ä¹æ²¡æœ‰æ€§èƒ½æŸå¤±ï¼Œå¹¶ä¸”åœ¨ RTX4090 ä¸Šçš„æ“ä½œé€Ÿåº¦æ˜¯ FlashAttention2 å’Œ xformers çš„ 3 å€å’Œ 5 å€ã€‚ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ã€‚

zhÃ¨ piÄn wÃ©n zhÄng jiÃ¨ shÃ o le yÄ« zhÇ’ng jiÄ sÃ¹ zhÃ¹ yÃ¬ lÃ¬ jÃ¬ suÃ n de fÄng fÇ, chÄ“ng wÃ©i SageAttention2. tÄ shÇ yÃ²ng 4-bit jÇ” zhÃ¨n chÃ©ng fÇ hÃ© jÄ«ng dÃ¹ zÄ“ng qiÃ¡ng jÃ¬ shÃ¹. shÇ’u xiÄn, jiÄng jÇ” zhÃ¨n Q hÃ© K liÃ ng huÃ  wÃ©i INT4, jiÄng jÇ” zhÃ¨n P hÃ© V liÃ ng huÃ  wÃ©i FP8. rÃ¡n hÃ²u, tÃ­ chÅ« pÃ­ng huÃ¡ Q hÃ© V de fÄng fÇ, tÃ­ gÄo zhÃ¹ yÃ¬ lÃ¬ jÄ«ng dÃ¹. shÃ­ yÃ n zhÃ¨ng mÃ­ng, zhÃ¨ zhÇ’ng fÄng fÇ zÃ i duÅ zhÇ’ng mÃ³ xÃ­ng shÃ ng jÄ« hÅ« mÃ©i yÇ’u xÃ¬ng nÃ©ng sÇ”n shÄ«, bÃ¬ng qiÄ› zÃ i RTX4090 shÃ ng de cÄo zuÃ² sÃ¹ dÃ¹ shÃ¬ FlashAttention2 hÃ© xformers de 3 bÃ¨i hÃ© 5 bÃ¨i. dÃ i mÇ yÇ zÃ i GitHub shÃ ng gÅng kÄi.
[21.11.2024 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—çš„æ–¹æ³•ï¼Œç§°ä¸º SageAttention2ã€‚å®ƒä½¿ç”¨ 4-bit çŸ©é˜µä¹˜æ³•å’Œç²¾åº¦å¢å¼ºæŠ€æœ¯ã€‚é¦–å…ˆï¼Œå°†çŸ©é˜µ Q å’Œ K é‡åŒ–ä¸º INT4ï¼Œå°†çŸ©é˜µ P å’Œ V é‡åŒ–ä¸º FP8ã€‚ç„¶åï¼Œæå‡ºå¹³æ»‘ Q å’Œ V çš„æ–¹æ³•ï¼Œæé«˜æ³¨æ„åŠ›ç²¾åº¦ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šç§æ¨¡å‹ä¸Šå‡ ä¹æ²¡æœ‰æ€§èƒ½æŸå¤±ï¼Œå¹¶ä¸”åœ¨ RTX4090 ä¸Šçš„æ“ä½œé€Ÿåº¦æ˜¯ FlashAttention2 å’Œ xformers çš„ 3 å€å’Œ 5 å€ã€‚ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ã€‚
[21.11.2024 09:12] Mistral response. {"id": "ead0b896b5054be7aa8cebaa087c7f05", "object": "chat.completion", "created": 1732180310, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[{'word': '\u52a0\u901f', 'pinyin': 'ji\u0101 s\u00f9', 'trans': 'accelerate'},\n{'word': '\u6ce8\u610f\u529b', 'pinyin': 'zh\u00f9 y\u00ec l\u00ec', 'trans': 'attention'},\n{'word': '\u8ba1\u7b97', 'pinyin': 'j\u00ec su\u00e0n', 'trans': 'calculation'},\n{'word': '\u65b9\u6cd5', 'pinyin': 'f\u0101ng f\u01ce', 'trans': 'method'},\n{'word': '\u79f0\u4e3a', 'pinyin': 'ch\u0113ng w\u00e9i', 'trans': 'called'},\n{'word': '\u77e9\u9635', 'pinyin': 'j\u01d4 zh\u00e8n', 'trans': 'matrix'},\n{'word': '\u4e58\u6cd5', 'pinyin': 'ch\u00e9n f\u01ce', 'trans': 'multiplication'},\n{'word': '\u7cbe\u5ea6', 'pinyin': 'j\u012bng d\u00f9', 'trans': 'precision'},\n{'word': '\u589e\u5f3a', 'pinyin': 'z\u0113ng qi\u00e1ng', 'trans': 'enhancement'},\n{'word': '\u6280\u672f', 'pinyin': 'j\u00ec sh\u00f9', 'trans': 'technology'},\n{'word': '\u91cf\u5316', 'pinyin': 'li\u00e0ng hu\u00e0', 'trans': 'quantization'},\n{'word': '\u5e73\u6ed1', 'pinyin': 'p\u00edng hu\u00e1', 'trans': 'smooth'},\n{'word': '\u63d0\u9ad8', 'pinyin': 't\u00ed g\u0101o', 'trans': 'improve'},\n{'word': '\u5b9e\u9a8c', 'pinyin': 'sh\u00ed y\u00e0n', 'trans': 'experiment'},\n{'word': '\u8bc1\u660e', 'pinyin': 'zh\u00e8ng m\u00edng', 'trans': 'prove'},\n{'word': '\u6027\u80fd', 'pinyin': 'x\u00ecng n\u00e9ng', 'trans': 'performance'},\n{'word': '\u635f\u5931', 'pinyin': 's\u01d4n sh\u012b', 'trans': 'loss'},\n{'word': '\u64cd\u4f5c', 'pinyin': 'c\u0101o zu\u00f2', 'trans': 'operation'},\n{'word': '\u901f\u5ea6', 'pinyin': 's\u00f9 d\u00f9', 'trans': 'speed'},\n{'word': '\u516c\u5f00', 'pinyin': 'g\u014dng k\u0101i', 'trans': 'public'},\n{'word': '\u4ee3\u7801', 'pinyin': 'd\u00e0i m\u01ce', 'trans': 'code'}]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 227, "total_tokens": 798, "completion_tokens": 571}}
[21.11.2024 09:12] Response: [{'word': 'åŠ é€Ÿ', 'pinyin': 'jiÄ sÃ¹', 'trans': 'accelerate'},
{'word': 'æ³¨æ„åŠ›', 'pinyin': 'zhÃ¹ yÃ¬ lÃ¬', 'trans': 'attention'},
{'word': 'è®¡ç®—', 'pinyin': 'jÃ¬ suÃ n', 'trans': 'calculation'},
{'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'},
{'word': 'ç§°ä¸º', 'pinyin': 'chÄ“ng wÃ©i', 'trans': 'called'},
{'word': 'çŸ©é˜µ', 'pinyin': 'jÇ” zhÃ¨n', 'trans': 'matrix'},
{'word': 'ä¹˜æ³•', 'pinyin': 'chÃ©n fÇ', 'trans': 'multiplication'},
{'word': 'ç²¾åº¦', 'pinyin': 'jÄ«ng dÃ¹', 'trans': 'precision'},
{'word': 'å¢å¼º', 'pinyin': 'zÄ“ng qiÃ¡ng', 'trans': 'enhancement'},
{'word': 'æŠ€æœ¯', 'pinyin': 'jÃ¬ shÃ¹', 'trans': 'technology'},
{'word': 'é‡åŒ–', 'pinyin': 'liÃ ng huÃ ', 'trans': 'quantization'},
{'word': 'å¹³æ»‘', 'pinyin': 'pÃ­ng huÃ¡', 'trans': 'smooth'},
{'word': 'æé«˜', 'pinyin': 'tÃ­ gÄo', 'trans': 'improve'},
{'word': 'å®éªŒ', 'pinyin': 'shÃ­ yÃ n', 'trans': 'experiment'},
{'word': 'è¯æ˜', 'pinyin': 'zhÃ¨ng mÃ­ng', 'trans': 'prove'},
{'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'},
{'word': 'æŸå¤±', 'pinyin': 'sÇ”n shÄ«', 'trans': 'loss'},
{'word': 'æ“ä½œ', 'pinyin': 'cÄo zuÃ²', 'trans': 'operation'},
{'word': 'é€Ÿåº¦', 'pinyin': 'sÃ¹ dÃ¹', 'trans': 'speed'},
{'word': 'å…¬å¼€', 'pinyin': 'gÅng kÄi', 'trans': 'public'},
{'word': 'ä»£ç ', 'pinyin': 'dÃ i mÇ', 'trans': 'code'}]
[21.11.2024 09:12] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—çš„æ–¹æ³•ï¼Œç§°ä¸º SageAttention2ã€‚å®ƒä½¿ç”¨ 4-bit çŸ©é˜µä¹˜æ³•å’Œç²¾åº¦å¢å¼ºæŠ€æœ¯ã€‚é¦–å…ˆï¼Œå°†çŸ©é˜µ Q å’Œ K é‡åŒ–ä¸º INT4ï¼Œå°†çŸ©é˜µ P å’Œ V é‡åŒ–ä¸º FP8ã€‚ç„¶åï¼Œæå‡ºå¹³æ»‘ Q å’Œ V çš„æ–¹æ³•ï¼Œæé«˜æ³¨æ„åŠ›ç²¾åº¦ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šç§æ¨¡å‹ä¸Šå‡ ä¹æ²¡æœ‰æ€§èƒ½æŸå¤±ï¼Œå¹¶ä¸”åœ¨ RTX4090 ä¸Šçš„æ“ä½œé€Ÿåº¦æ˜¯ FlashAttention2 å’Œ xformers çš„ 3 å€å’Œ 5 å€ã€‚ä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ã€‚
[21.11.2024 09:12] Mistral response. {"id": "a4dcce3c57d440c5a6903d79b531b56b", "object": "chat.completion", "created": 1732180324, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article introduces a method for accelerating attention computation, called SageAttention2. It employs 4-bit matrix multiplication and precision enhancement techniques. First, matrices Q and K are quantized to INT4, while matrices P and V are quantized to FP8. Then, a method for smoothing Q and V is proposed to improve attention precision. Experiments demonstrate that this method incurs almost no performance loss across various models and operates at speeds that are 3 times and 5 times faster than FlashAttention2 and xformers, respectively, on the RTX4090. The code has been made publicly available on GitHub.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 193, "total_tokens": 333, "completion_tokens": 140}}
[21.11.2024 09:12] Response: This article introduces a method for accelerating attention computation, called SageAttention2. It employs 4-bit matrix multiplication and precision enhancement techniques. First, matrices Q and K are quantized to INT4, while matrices P and V are quantized to FP8. Then, a method for smoothing Q and V is proposed to improve attention precision. Experiments demonstrate that this method incurs almost no performance loss across various models and operates at speeds that are 3 times and 5 times faster than FlashAttention2 and xformers, respectively, on the RTX4090. The code has been made publicly available on GitHub.
[21.11.2024 09:12] Renaming data file.
[21.11.2024 09:12] Renaming previous data. hf_papers.json to ./d/2024-11-21.json
[21.11.2024 09:12] Saving new data file.
[21.11.2024 09:12] Generating page.
[21.11.2024 09:12] Renaming previous page.
[21.11.2024 09:12] Renaming previous data. index.html to ./d/2024-11-21.html
[21.11.2024 09:12] [Experimental] Generating Chinese page for reading.
[21.11.2024 09:12] Chinese vocab [{'word': 'åŠ é€Ÿ', 'pinyin': 'jiÄ sÃ¹', 'trans': 'accelerate'}, {'word': 'æ³¨æ„åŠ›', 'pinyin': 'zhÃ¹ yÃ¬ lÃ¬', 'trans': 'attention'}, {'word': 'è®¡ç®—', 'pinyin': 'jÃ¬ suÃ n', 'trans': 'calculation'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'ç§°ä¸º', 'pinyin': 'chÄ“ng wÃ©i', 'trans': 'called'}, {'word': 'çŸ©é˜µ', 'pinyin': 'jÇ” zhÃ¨n', 'trans': 'matrix'}, {'word': 'ä¹˜æ³•', 'pinyin': 'chÃ©n fÇ', 'trans': 'multiplication'}, {'word': 'ç²¾åº¦', 'pinyin': 'jÄ«ng dÃ¹', 'trans': 'precision'}, {'word': 'å¢å¼º', 'pinyin': 'zÄ“ng qiÃ¡ng', 'trans': 'enhancement'}, {'word': 'æŠ€æœ¯', 'pinyin': 'jÃ¬ shÃ¹', 'trans': 'technology'}, {'word': 'é‡åŒ–', 'pinyin': 'liÃ ng huÃ ', 'trans': 'quantization'}, {'word': 'å¹³æ»‘', 'pinyin': 'pÃ­ng huÃ¡', 'trans': 'smooth'}, {'word': 'æé«˜', 'pinyin': 'tÃ­ gÄo', 'trans': 'improve'}, {'word': 'å®éªŒ', 'pinyin': 'shÃ­ yÃ n', 'trans': 'experiment'}, {'word': 'è¯æ˜', 'pinyin': 'zhÃ¨ng mÃ­ng', 'trans': 'prove'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'æŸå¤±', 'pinyin': 'sÇ”n shÄ«', 'trans': 'loss'}, {'word': 'æ“ä½œ', 'pinyin': 'cÄo zuÃ²', 'trans': 'operation'}, {'word': 'é€Ÿåº¦', 'pinyin': 'sÃ¹ dÃ¹', 'trans': 'speed'}, {'word': 'å…¬å¼€', 'pinyin': 'gÅng kÄi', 'trans': 'public'}, {'word': 'ä»£ç ', 'pinyin': 'dÃ i mÇ', 'trans': 'code'}]
[21.11.2024 09:12] Renaming previous Chinese page.
[21.11.2024 09:12] Renaming previous data. zh.html to ./d/2024-11-20_zh_reading_task.html
[21.11.2024 09:12] Writing Chinese reading task.
[21.11.2024 09:12] Writing result.
[21.11.2024 09:12] Renaming log file.
[21.11.2024 09:12] Renaming previous data. log.txt to ./logs/2024-11-21_last_log.txt
