[31.08.2025 01:57] Read previous papers.
[31.08.2025 01:57] Generating top page (month).
[31.08.2025 01:57] Writing top page (month).
[31.08.2025 06:33] Read previous papers.
[31.08.2025 06:33] Get feed.
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20751
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20722
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18966
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20453
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20404
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21058
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20374
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20766
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21060
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21066
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17450
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21046
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21052
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20755
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18633
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21070
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15228
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21061
[31.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17502
[31.08.2025 06:33] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[31.08.2025 06:33] No deleted papers detected.
[31.08.2025 06:33] Downloading and parsing papers (pdf, html). Total: 19.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20751.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20751.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20751.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20722.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20722.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20722.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.18966.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.18966.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.18966.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20453.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20453.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20453.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20404.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20404.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20404.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21058.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21058.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21058.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20374.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20374.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20374.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20766.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20766.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20766.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21060.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21060.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21060.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21066.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21066.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21066.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.17450.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.17450.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.17450.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21046.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21046.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21046.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21052.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21052.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21052.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.20755.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.20755.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.20755.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.18633.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.18633.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.18633.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21070.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21070.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21070.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15228.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15228.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15228.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.21061.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.21061.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.21061.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.17502.
[31.08.2025 06:33] Extra JSON file exists (./assets/json/2508.17502.json), skip PDF parsing.
[31.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.17502.json), skip HTML parsing.
[31.08.2025 06:33] Success.
[31.08.2025 06:33] Enriching papers with extra data.
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 0. Pref-GRPO, a pairwise preference reward-based GRPO method, enhances text-to-image generation by mitigating reward hacking and improving stability, while UniGenBench provides a comprehensive benchmark for evaluating T2I models.  					AI-generated summary 				 Recent advancements highlight the importa...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 1. rStar2-Agent, a 14B math reasoning model trained with agentic reinforcement learning, achieves state-of-the-art performance by efficiently handling complex problem-solving with advanced cognitive behaviors and minimal computational resources.  					AI-generated summary 				 We introduce rStar2-Agent...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 2. USO, a unified model, achieves state-of-the-art performance in both style similarity and subject consistency by disentangling and re-composing content and style through a disentangled learning scheme and style reward-learning paradigm.  					AI-generated summary 				 Existing literature typically tr...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 3. MCP-Bench evaluates large language models on complex, multi-step tasks requiring tool use, coordination, and planning across various domains.  					AI-generated summary 				 We introduce MCP-Bench, a benchmark for evaluating large language models (LLMs) on realistic, multi-step tasks that demand too...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 4. AWorld, an open-source system for large-scale agent-environment interaction, accelerates experience collection and enhances reinforcement learning, leading to significant improvements in agentic AI performance on complex benchmarks.  					AI-generated summary 				 The learning from practice paradigm...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 5. Long video generation is addressed by introducing a sparse attention routing module, Mixture of Contexts, to efficiently manage long-term memory and retrieval in diffusion transformers.  					AI-generated summary 				 Long video generation is fundamentally a long context memory problem: models must ...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 6. Task Centric Instruction Augmentation (TCIA) enhances large language models' performance on specific tasks while maintaining general instruction-following ability.  					AI-generated summary 				 Diverse instruction data is vital for effective instruction tuning of large language models, as it enabl...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 7. Rank-One Safety Injection (ROSI) enhances Large Language Model safety by amplifying refusal-mediating subspace activations without fine-tuning.  					AI-generated summary 				 Safety alignment in Large Language Models (LLMs) often involves mediating internal representations to refuse harmful request...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 8. A multi-view 3D point tracker using a feed-forward model with transformers and k-nearest-neighbors achieves robust tracking with fewer cameras and less optimization compared to existing methods.  					AI-generated summary 				 We introduce the first data-driven multi-view 3D point tracker, designed ...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 9. A unified reinforcement learning framework using a single vision-language model enhances generative capabilities across multiple tasks without task-specific fine-tuning.  					AI-generated summary 				 In this paper, we introduce OneReward, a unified reinforcement learning framework that enhances th...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 10. DuET-PD evaluates LLMs in persuasive dialogues, revealing challenges with misinformation and corrections, and introduces Holistic DPO to improve model reliability.  					AI-generated summary 				 Large Language Models (LLMs) can struggle to balance gullibility to misinformation and resistance to val...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 11. CogVLA, a Cognition-Aligned Vision-Language-Action framework, enhances efficiency and performance through instruction-driven routing and sparsification, achieving state-of-the-art results with reduced computational costs.  					AI-generated summary 				 Recent Vision-Language-Action (VLA) models bui...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 12. FakeParts introduces a new type of deepfake with subtle, localized manipulations that are difficult to detect, and FakePartsBench provides a large-scale dataset to evaluate detection methods.  					AI-generated summary 				 We introduce FakeParts, a new class of deepfakes characterized by subtle, lo...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 13. Tool-augmented language models achieve better factual recall and scalability through external retrieval rather than memorization in their weights.  					AI-generated summary 				 Tool-augmented language models, equipped with retrieval, memory, or external APIs, are reshaping AI, yet their theoretica...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 14. ROSE, a video inpainting framework using diffusion transformers, effectively removes objects and their side effects like shadows and reflections by leveraging synthetic data and differential masks.  					AI-generated summary 				 Video object removal has achieved advanced performance due to the rece...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 15. A video diffusion framework generates high-quality virtual try-on videos using a conditioning network that unifies multi-modal inputs, outperforming existing solutions.  					AI-generated summary 				 We present Dress&Dance, a video diffusion framework that generates high quality 5-second-long 24 FP...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 16. TriMM, a feed-forward 3D-native generative model, integrates multi-modal data (RGB, RGBD, point clouds) to enhance 3D asset generation quality and robustness.  					AI-generated summary 				 3D content inherently encompasses multi-modal characteristics and can be projected into different modalities ...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 17. OnGoal, an LLM chat interface with goal tracking, improves user efficiency and engagement in complex dialogues by providing real-time feedback and visualizations.  					AI-generated summary 				 As multi-turn dialogues with large language models (LLMs) grow longer and more complex, how can users bet...
[31.08.2025 06:33] ********************************************************************************
[31.08.2025 06:33] Abstract 18. Social-MAE, an extended Contrastive Audio-Visual Masked Auto-Encoder, achieves state-of-the-art performance in multimodal emotion and laughter recognition through in-domain self-supervised pre-training.  					AI-generated summary 				 Human social behaviors are inherently multimodal necessitating th...
[31.08.2025 06:33] Read previous papers.
[31.08.2025 06:33] Generating reviews via LLM API.
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#rl", "#survey", "#games"], "emoji": "üé®", "ru": {"title": "–°—Ç–∞–±–∏–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å Pref-GRPO –∏ –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å UniGenBench", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Pref-GRPO - –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ø–æ–ø–∞—Ä–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ—á
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#agents", "#alignment", "#optimization", "#rlhf", "#science"], "emoji": "üß†", "ru": {"title": "–ê–≥–µ–Ω—Ç–Ω–æ–µ RL —Å–æ–∑–¥–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–µ–Ω–∏—è —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏", "desc": "rStar2-Agent - —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å 14 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—É
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#story_generation", "#open_source", "#training", "#benchmark", "#dataset", "#cv"], "emoji": "üé®", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ç–∏–ª—è –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "USO - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#benchmark", "#agents"], "emoji": "üß†", "ru": {"title": "MCP-Bench: –ù–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –æ—Ü–µ–Ω–∫–µ –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "MCP-Bench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –∏—Å–ø–æ–ª—å
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#benchmark", "#games", "#open_source", "#agents", "#rl", "#training"], "emoji": "üöÄ", "ru": {"title": "AWorld: —É—Å–∫–æ—Ä—è–µ–º –æ–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –ò–ò –≤ –º–∞—Å—à—Ç–∞–±–µ", "desc": "AWorld - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∏ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã, –∫–æ—Ç–æ—Ä–∞—è —É—Å–∫–æ—Ä—è–µ—Ç —Å–±–æ—Ä –æ–ø—ã—Ç–∞
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#architecture", "#diffusion", "#video", "#long_context", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#data", "#optimization", "#open_source", "#training", "#dataset"], "emoji": "üéØ", "ru": {"title": "–¢–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç–∏", "desc": "–ú–µ—Ç–æ–¥ Task Centric Instruction Augmentation (TCIA) —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#training", "#alignment", "#security", "#rlhf"], "emoji": "üõ°Ô∏è", "ru": {"title": "–£—Å–∏–ª–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Rank-One Safety Injection (ROSI) –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). ROSI —É—Å–∏–ª–∏–≤–∞–µ—Ç –∞–∫
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#synthetic", "#benchmark", "#3d", "#optimization", "#dataset", "#open_source"], "emoji": "üé•", "ru": {"title": "–ù–∞–¥–µ–∂–Ω–æ–µ –º–Ω–æ–≥–æ—Ä–∞–∫—É—Ä—Å–Ω–æ–µ 3D-–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å –º–µ–Ω—å—à–∏–º —á–∏—Å–ª–æ–º –∫–∞–º–µ—Ä", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø–µ—Ä–≤—ã–π –º–Ω–æ–≥–æ—Ä–∞–∫—É—Ä—Å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä 3D-—Ç–æ—á–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#open_source", "#rlhf", "#cv", "#games", "#optimization", "#training", "#rl", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω OneReward - —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#alignment", "#rlhf", "#open_source", "#training", "#hallucinations"], "emoji": "üß†", "ru": {"title": "–ü–æ–≤—ã—à–µ–Ω–∏–µ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —É–±–µ–∂–¥–∞—é—â–∏—Ö –¥–∏–∞–ª–æ–≥–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç DuET-PD - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ —É–±–µ–∂–¥–∞—é—â–∏—Ö –¥–∏–∞–ª–æ–≥–∞—Ö. –ò—Å—Å–ª–µ
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#video", "#training", "#optimization", "#robotics", "#open_source"], "emoji": "üß†", "ru": {"title": "–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º", "desc": "CogVLA - —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∑–∞–¥–∞—á –∑—Ä–µ–Ω–∏—è-—è–∑—ã–∫–∞-–¥–µ–π—Å—Ç–≤–∏—è, –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–∞—è
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#security", "#video", "#dataset", "#benchmark"], "emoji": "üé≠", "ru": {"title": "FakeParts: –Ω–æ–≤—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–∏–ø—Ñ–µ–π–∫–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ç–∏–ø –¥–∏–ø—Ñ–µ–π–∫–æ–≤ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º FakeParts, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–∏–π—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è–º–∏ –≤ –≤–∏–¥–µ–æ. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ —Å–æ–∑–¥–∞–ª–∏ –Ω–∞–±–æ—Ä
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#rag", "#optimization", "#multimodal", "#alignment"], "emoji": "üîç", "ru": {"title": "–í–Ω–µ—à–Ω–∏–π –ø–æ–∏—Å–∫ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ø–∞–º—è—Ç—å –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–æ–∏—Å–∫–∞, –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –º–æ–¥–µ–ª—è–º–∏, –ø–æ–ª–∞–≥–∞—é—â
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#synthetic", "#diffusion", "#benchmark", "#video", "#dataset"], "emoji": "üé≠", "ru": {"title": "ROSE: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –∏—Ö —Å–ª–µ–¥–æ–≤ –∏–∑ –≤–∏–¥–µ–æ", "desc": "ROSE - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã. –û–Ω —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —É—Å—Ç—Ä–∞–Ω—è–µ
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#multimodal", "#video", "#training", "#diffusion", "#open_source"], "emoji": "üëö", "ru": {"title": "–í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∏–º–µ—Ä–∫–∞ –æ–¥–µ–∂–¥—ã –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ Dress&Dance –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–∏ –æ–¥–µ–∂–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#synthetic", "#diffusion", "#multimodal", "#3d"], "emoji": "üé®", "ru": {"title": "TriMM: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "TriMM - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ 3D-–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (RGB, RGBD, –æ–±–ª–∞–∫–∞ —Ç–æ—á–µ–∫). –û–Ω–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–ª–ª–∞–±–æ—Ä–∞
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#interpretability", "#training", "#multimodal", "#alignment"], "emoji": "üéØ", "ru": {"title": "OnGoal: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–ª—è–º–∏ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –ò–ò", "desc": "OnGoal - —ç—Ç–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —á–∞—Ç–∞ —Å –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (LLM), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –¥
[31.08.2025 06:33] Using data from previous issue: {"categories": ["#multimodal", "#training", "#dataset"], "emoji": "üé≠", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é —Å–∞–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "Social-MAE - —ç—Ç–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –∞—É–¥–∏–æ–≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —ç
[31.08.2025 06:33] Renaming data file.
[31.08.2025 06:33] Renaming previous data. hf_papers.json to ./d/2025-08-29.json
[31.08.2025 06:33] Saving new data file.
[31.08.2025 06:33] Generating page.
[31.08.2025 06:33] Renaming previous page.
[31.08.2025 06:33] Renaming previous data. index.html to ./d/2025-08-29.html
[31.08.2025 06:33] Writing result.
[31.08.2025 06:33] Renaming log file.
[31.08.2025 06:33] Renaming previous data. log.txt to ./logs/2025-08-31_last_log.txt
