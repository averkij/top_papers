[27.02.2025 08:15] Read previous papers.
[27.02.2025 08:15] Generating top page (month).
[27.02.2025 08:15] Writing top page (month).
[27.02.2025 09:11] Read previous papers.
[27.02.2025 09:11] Get feed.
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18934
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19400
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19361
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19328
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17955
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19414
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18864
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16776
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18906
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18772
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19204
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19279
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17540
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16284
[27.02.2025 09:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.19187
[27.02.2025 09:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.02.2025 09:11] No deleted papers detected.
[27.02.2025 09:11] Downloading and parsing papers (pdf, html). Total: 15.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.18934.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.18934.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.18934.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19400.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19400.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19400.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19361.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19361.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19361.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19328.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19328.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19328.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.17955.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.17955.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.17955.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19414.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19414.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19414.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.18864.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.18864.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.18864.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.16776.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.16776.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.16776.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.18906.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.18906.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.18906.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.18772.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.18772.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.18772.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19204.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19204.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19204.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19279.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19279.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19279.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.17540.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.17540.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.17540.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.16284.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.16284.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.16284.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Downloading and parsing paper https://huggingface.co/papers/2502.19187.
[27.02.2025 09:11] Extra JSON file exists (./assets/json/2502.19187.json), skip PDF parsing.
[27.02.2025 09:11] Paper image links file exists (./assets/img_data/2502.19187.json), skip HTML parsing.
[27.02.2025 09:11] Success.
[27.02.2025 09:11] Enriching papers with extra data.
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 0. We introduce Kanana, a series of bilingual language models that demonstrate exceeding performance in Korean and competitive performance in English. The computational cost of Kanana is significantly lower than that of state-of-the-art models of similar size. The report details the techniques employed...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 1. Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their abil...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 2. Recently, o1-like models have drawn significant attention, where these models produce the long Chain-of-Thought (CoT) reasoning steps to improve the reasoning abilities of existing Large Language Models (LLMs). In this paper, to understand the qualities of these long CoTs and measure the critique ab...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 3. Reward models (RMs) are crucial for the training and inference-time scaling up of large language models (LLMs). However, existing reward models primarily focus on human preferences, neglecting verifiable correctness signals which have shown strong potential in training LLMs. In this paper, we propos...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 4. Multilingual language models (LMs) are expected to recall factual knowledge consistently across languages, yet they often fail to transfer knowledge between languages even when they possess the correct information in one of the languages. For example, we find that an LM may correctly identify Rashed...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 5. There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant researcher effort, reasoning, and ingenuity. Ye...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 6. Scientific discovery relies on scientists generating novel hypotheses that undergo rigorous experimental validation. To augment this process, we introduce an AI co-scientist, a multi-agent system built on Gemini 2.0. The AI co-scientist is intended to help uncover new, original knowledge and to form...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 7. As AI models are increasingly deployed across diverse real-world scenarios, ensuring their safety remains a critical yet underexplored challenge. While substantial efforts have been made to evaluate and enhance AI safety, the lack of a standardized framework and comprehensive toolkit poses significa...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 8. Training Vision-Language Models (VLMs) for Graphical User Interfaces (GUI) agents via Reinforcement Learning (RL) faces critical challenges: environment-based RL requires costly interactions, while environment-free methods struggle with distribution shift and reward generalization. We propose an env...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 9. Despite Greece's pivotal role in the global economy, large language models (LLMs) remain underexplored for Greek financial context due to the linguistic complexity of Greek and the scarcity of domain-specific datasets. Previous efforts in multilingual financial natural language processing (NLP) have...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 10. Monocular depth estimation (MDE) aims to predict scene depth from a single RGB image and plays a crucial role in 3D scene understanding. Recent advances in zero-shot MDE leverage normalized depth representations and distillation-based learning to improve generalization across diverse scenes. However...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 11. Language model heavily depends on high-quality data for optimal performance. Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, or careful prompt engineering, which require significant expert experience and human annotation effort while...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 12. Generating accurate and concise textual summaries from multimodal documents is challenging, especially when dealing with visually complex content like scientific posters. We introduce PosterSum, a novel benchmark to advance the development of vision-language models that can understand and summarize ...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 13. Establishing the relationship between 3D structures and the energy states of molecular systems has proven to be a promising approach for learning 3D molecular representations. However, existing methods are limited to modeling the molecular energy states from classical mechanics. This limitation resu...
[27.02.2025 09:11] ********************************************************************************
[27.02.2025 09:11] Abstract 14. Large language models (LLMs) are increasingly deployed in everyday applications, demanding robust general reasoning capabilities and diverse reasoning skillset. However, current LLM reasoning benchmarks predominantly focus on mathematical and coding abilities, leaving a gap in evaluating broader rea...
[27.02.2025 09:11] Read previous papers.
[27.02.2025 09:11] Generating reviews via LLM API.
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#rag", "#open_source", "#machine_translation", "#low_resource", "#dataset", "#multilingual", "#data", "#small_models", "#training"], "emoji": "ğŸ‡°ğŸ‡·", "ru": {"title": "Kanana: ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ´Ğ²ÑƒÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ĞºĞ¾Ñ€ĞµĞ¹ÑĞºĞ¾Ğ³Ğ¾ Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾", "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° ÑĞµÑ€Ğ¸Ñ Ğ´Ğ²ÑƒÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ñ
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#reasoning", "#video", "#agents", "#interpretability", "#multimodal", "#benchmark"], "emoji": "ğŸ§®", "ru": {"title": "ĞĞ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ Ñ‚ĞµĞ¾Ñ€ĞµĞ¼", "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ TheoremExplainAgent - Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾-Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ñ‚ĞµĞ¾Ñ€
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#long_context", "#dataset", "#benchmark", "#training", "#reasoning"], "emoji": "ğŸ§ ", "ru": {"title": "DeltaBench: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ˜Ğ˜", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ DeltaBench - Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ² Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ…
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#alignment", "#training", "#open_source", "#rlhf", "#benchmark"], "emoji": "ğŸ¤–", "ru": {"title": "ĞĞ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑˆĞ°Ğ³ Ğ² ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¸ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´ Ğ´Ğ»Ñ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ°
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#multilingual", "#benchmark", "#transfer_learning", "#low_resource"], "emoji": "ğŸŒ", "ru": {"title": "ĞŸÑ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ±Ğ°Ñ€ÑŒĞµÑ€Ğ¾Ğ² Ğ² Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸ÑÑ… Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹", "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ½Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ñ‚ÑŒ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#reasoning", "#science", "#plp", "#benchmark"], "emoji": "ğŸ”", "ru": {"title": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ›Ğœ: Ğ¾Ñ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğº Ğ¾Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¶ĞµĞ½Ğ¸Ñ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (Ğ›Ğœ) Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº REF
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#agents", "#science", "#healthcare", "#architecture"], "emoji": "ğŸ§¬", "ru": {"title": "Ğ˜Ğ˜-ÑĞ¾ÑƒÑ‡ĞµĞ½Ñ‹Ğ¹: Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¼ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ˜Ğ˜-ÑĞ¾ÑƒÑ‡ĞµĞ½Ğ¾Ğ³Ğ¾, Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ Gemini 2.0, Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½ÑƒÑ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ ÑƒÑ‡ĞµĞ½Ñ‹Ğ¼ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ· 
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#dataset", "#security"], "emoji": "ğŸ›¡ï¸", "ru": {"title": "Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ˜Ğ˜", "desc": "AISafetyLab - ÑÑ‚Ğ¾ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°. ĞĞ½Ğ° Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#reasoning", "#training", "#agents", "#rl", "#optimization"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ GUI Ğ±ĞµĞ· Ğ¿Ñ€ÑĞ¼Ğ¾Ğ³Ğ¾ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ·Ñ‹ĞºĞ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#dataset", "#low_resource", "#multilingual"], "emoji": "ğŸ’¶", "ru": {"title": "ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ³Ñ€ĞµÑ‡ĞµÑĞºĞ¾Ğ¼ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ğ¾Ğ¼ NLP: Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ³Ñ€ĞµÑ‡ĞµÑĞºĞ¸Ğ¹ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Plutus-ben Ğ¸ Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ³Ñ€ĞµÑ‡ĞµÑĞºÑƒÑ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²ÑƒÑ
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#3d", "#cv", "#training", "#benchmark"], "emoji": "ğŸ”", "ru": {"title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ½Ğ¾ĞºÑƒĞ»ÑÑ€Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½ÑƒÑ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Ğ¼Ğ¾Ğ½Ğ¾ĞºÑƒĞ»ÑÑ€Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ ÑÑ†ĞµĞ½Ñ‹ Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ RGB-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Cross-Context Distillati
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#data", "#optimization", "#interpretability", "#dataset", "#agents", "#training"], "emoji": "ğŸ”", "ru": {"title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "CritiQ - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#benchmark", "#science", "#dataset", "#multimodal"], "emoji": "ğŸ“Š", "ru": {"title": "PosterSum: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑÑ‚ĞµÑ€Ğ¾Ğ²", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº PosterSum Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ¸ ÑÑƒĞ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ°Ñƒ
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#science", "#dataset", "#3d", "#benchmark", "#architecture"], "emoji": "ğŸ”¬", "ru": {"title": "ĞšĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ÑĞºĞ°Ñ‡Ğ¾Ğº Ğ² Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ 3D-Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ» Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑĞ½ĞµÑ€Ğ³ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¿ĞµĞºÑ‚Ñ€Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€
[27.02.2025 09:11] Using data from previous issue: {"categories": ["#reasoning", "#benchmark"], "emoji": "ğŸ§ ", "ru": {"title": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°: ÑƒÑĞ»Ğ¾Ğ¶Ğ½ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ½Ğ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… BIG-Bench Extra Hard (BBEH) Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. B
[27.02.2025 09:11] Trying to get texts in Chinese.
[27.02.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

We introduce Kanana, a series of bilingual language models that demonstrate exceeding performance in Korean and competitive performance in English. The computational cost of Kanana is significantly lower than that of state-of-the-art models of similar size. The report details the techniques employed during pre-training to achieve compute-efficient yet competitive models, including high quality data filtering, staged pre-training, depth up-scaling, and pruning and distillation. Furthermore, the report outlines the methodologies utilized during the post-training of the Kanana models, encompassing supervised fine-tuning and preference optimization, aimed at enhancing their capability for seamless interaction with users. Lastly, the report elaborates on plausible approaches used for language model adaptation to specific scenarios, such as embedding, retrieval augmented generation, and function calling. The Kanana model series spans from 2.1B to 32.5B parameters with 2.1B models (base, instruct, embedding) publicly released to promote research on Korean language models.
[27.02.2025 09:11] Mistral response. {"id": "9812def5ae9345298f85fa69043a9f60", "object": "chat.completion", "created": 1740647479, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u6211\u4eec\u4ecb\u7ecd\u4e86Kanana\uff0c\u4e00\u7cfb\u5217\u5728\u97e9\u8bed\u548c\u82f1\u8bed\u4e2d\u8868\u73b0\u51fa\u8272\u7684\u53cc\u8bed\u6a21\u578b\u3002Kanana\u7684\u8ba1\u7b97\u6210\u672c\u663e\u8457\u4f4e\u4e8e\u7c7b\u4f3c\u89c4\u6a21\u7684\u9876\u7ea7\u6a21\u578b\u3002\u62a5\u544a\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u9884\u8bad\u7ec3\u4e2d\u4f7f\u7528\u7684\u6280\u672f\uff0c\u5305\u62ec\u9ad8\u8d28\u91cf\u6570\u636e\u8fc7\u6ee4\u3001\u5206\u9636\u6bb5\u9884\u8bad\u7ec3\u3001\u6df1\u5ea6\u6269\u5c55\u3001\u526a\u679d\u548c\u84b8\u998f\u3002\u6b64\u5916\uff0c\u62a5\u544a\u8fd8\u6982\u8ff0\u4e86Kanana\u6a21\u578b\u5728\u8bad\u7ec3\u540e\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u5176\u4e0e\u7528\u6237\u4e92\u52a8\u7684\u80fd\u529b\u3002\u6700\u540e\uff0c\u62a5\u544a\u8fd8\u8ba8\u8bba\u4e86\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u7279\u5b9a\u573a\u666f\u7684\u53ef\u80fd\u65b9\u6cd5\uff0c\u5982\u5d4c\u5165\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u51fd\u6570\u8c03\u7528\u3002Kanana\u6a21\u578b\u7cfb\u5217\u4ece2.1B\u523032.5B\u53c2\u6570\u4e0d\u7b49\uff0c2.1B\u6a21\u578b\uff08\u57fa\u7840\u3001\u6307\u4ee4\u3001\u5d4c\u5165\uff09\u5df2\u516c\u5f00\u53d1\u5e03\uff0c\u4ee5\u4fc3\u8fdb\u97e9\u8bed\u6a21\u578b\u7814\u7a76\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 252, "total_tokens": 509, "completion_tokens": 257}}
[27.02.2025 09:11] Response: æˆ‘ä»¬ä»‹ç»äº†Kananaï¼Œä¸€ç³»åˆ—åœ¨éŸ©è¯­å’Œè‹±è¯­ä¸­è¡¨ç°å‡ºè‰²çš„åŒè¯­æ¨¡å‹ã€‚Kananaçš„è®¡ç®—æˆæœ¬æ˜¾è‘—ä½äºç±»ä¼¼è§„æ¨¡çš„é¡¶çº§æ¨¡å‹ã€‚æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†é¢„è®­ç»ƒä¸­ä½¿ç”¨çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬é«˜è´¨é‡æ•°æ®è¿‡æ»¤ã€åˆ†é˜¶æ®µé¢„è®­ç»ƒã€æ·±åº¦æ‰©å±•ã€å‰ªæå’Œè’¸é¦ã€‚æ­¤å¤–ï¼ŒæŠ¥å‘Šè¿˜æ¦‚è¿°äº†Kananaæ¨¡å‹åœ¨è®­ç»ƒåä½¿ç”¨çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒå’Œåå¥½ä¼˜åŒ–ï¼Œä»¥æé«˜å…¶ä¸ç”¨æˆ·äº’åŠ¨çš„èƒ½åŠ›ã€‚æœ€åï¼ŒæŠ¥å‘Šè¿˜è®¨è®ºäº†è¯­è¨€æ¨¡å‹é€‚åº”ç‰¹å®šåœºæ™¯çš„å¯èƒ½æ–¹æ³•ï¼Œå¦‚åµŒå…¥ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œå‡½æ•°è°ƒç”¨ã€‚Kananaæ¨¡å‹ç³»åˆ—ä»2.1Båˆ°32.5Bå‚æ•°ä¸ç­‰ï¼Œ2.1Bæ¨¡å‹ï¼ˆåŸºç¡€ã€æŒ‡ä»¤ã€åµŒå…¥ï¼‰å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›éŸ©è¯­æ¨¡å‹ç ”ç©¶ã€‚
[27.02.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

æˆ‘ä»¬ä»‹ç»äº†Kananaï¼Œä¸€ç³»åˆ—åœ¨éŸ©è¯­å’Œè‹±è¯­ä¸­è¡¨ç°å‡ºè‰²çš„åŒè¯­æ¨¡å‹ã€‚Kananaçš„è®¡ç®—æˆæœ¬æ˜¾è‘—ä½äºç±»ä¼¼è§„æ¨¡çš„é¡¶çº§æ¨¡å‹ã€‚æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†é¢„è®­ç»ƒä¸­ä½¿ç”¨çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬é«˜è´¨é‡æ•°æ®è¿‡æ»¤ã€åˆ†é˜¶æ®µé¢„è®­ç»ƒã€æ·±åº¦æ‰©å±•ã€å‰ªæå’Œè’¸é¦ã€‚æ­¤å¤–ï¼ŒæŠ¥å‘Šè¿˜æ¦‚è¿°äº†Kananaæ¨¡å‹åœ¨è®­ç»ƒåä½¿ç”¨çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒå’Œåå¥½ä¼˜åŒ–ï¼Œä»¥æé«˜å…¶ä¸ç”¨æˆ·äº’åŠ¨çš„èƒ½åŠ›ã€‚æœ€åï¼ŒæŠ¥å‘Šè¿˜è®¨è®ºäº†è¯­è¨€æ¨¡å‹é€‚åº”ç‰¹å®šåœºæ™¯çš„å¯èƒ½æ–¹æ³•ï¼Œå¦‚åµŒå…¥ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œå‡½æ•°è°ƒç”¨ã€‚Kananaæ¨¡å‹ç³»åˆ—ä»2.1Båˆ°32.5Bå‚æ•°ä¸ç­‰ï¼Œ2.1Bæ¨¡å‹ï¼ˆåŸºç¡€ã€æŒ‡ä»¤ã€åµŒå…¥ï¼‰å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›éŸ©è¯­æ¨¡å‹ç ”ç©¶ã€‚
[27.02.2025 09:11] Mistral response. {"id": "9072c37095a44eb2a0852e06fd61cd6e", "object": "chat.completion", "created": 1740647485, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "W\u01d2men ji\u00e8sh\u00e0o le Kanana, y\u012b x\u00ecli\u00e8 z\u00e0i h\u00e1ny\u01d4 h\u00e9 y\u012bngy\u01d4 zh\u014dng bi\u01ceoxi\u00e0n ch\u016bs\u00e8 de shu\u0101ngy\u01d4 m\u00f3x\u00edng. Kanana de j\u00ecsu\u00e0n ch\u00e9ngb\u011bn xi\u01cenzh\u00f9 d\u012by\u00fa l\u00e8is\u00ec gu\u012bm\u00f3 de d\u01d0ngj\u00ed m\u00f3x\u00edng. B\u00e0og\u00e0o xi\u00e1ngx\u00ec ji\u00e8sh\u00e0o le y\u00f9x\u00f9nli\u00e0n zh\u014dng sh\u01d0y\u00f2ng de j\u00ecsh\u00f9, b\u0101oku\u00f2 g\u0101o zh\u00ecli\u00e0ng sh\u00f9j\u00f9 gu\u00f2l\u01dc, f\u0113n ji\u0113du\u00e0n y\u00f9x\u00f9nli\u00e0n, sh\u0113nd\u00f9 ku\u00f2zh\u01cen, ji\u01cenzh\u012b h\u00e9 zh\u0113ngli\u00fa. C\u01d0w\u00e0i, b\u00e0og\u00e0o h\u00e1i g\u00e0iku\u00e0ng le Kanana m\u00f3x\u00edng z\u00e0i x\u00f9nli\u00e0n h\u00f2u sh\u01d0y\u00f2ng de f\u0101ngf\u01ce, b\u0101oku\u00f2 ji\u00e0nd\u016b w\u0113iti\u00e1o h\u00e9 pi\u0101nh\u01ceo y\u014duhu\u00e0, y\u01d0 t\u00edg\u0101o q\u00ed y\u01d4 y\u00f2ngh\u00f9 h\u00f9d\u00f2ng de n\u00e9ngl\u00ec. Z\u00f9ih\u00f2u, b\u00e0og\u00e0o h\u00e1i t\u01ceol\u00f9n le y\u01d4y\u00e1n m\u00f3x\u00edng sh\u00ecy\u00ecng t\u00e8d\u00ecng ch\u01cengj\u012bng de k\u011bn\u00e9ng f\u0101ngf\u01ce, r\u00fa qi\u00e0nr\u00f9, ji\u01censu\u01d2 z\u0113ngqi\u00e1ng sh\u0113ngch\u00e9ng h\u00e9 h\u00e1nsh\u00f9 di\u00e0oy\u00f2ng. Kanana m\u00f3x\u00edng x\u00ecli\u00e8 c\u00f3ng 2.1B d\u00e0o 32.5B c\u0101nsh\u00f9 b\u00f9d\u011bng, 2.1B m\u00f3x\u00edng (j\u012bch\u01d4, zh\u01d0l\u00ecng, qi\u00e0nr\u00f9) y\u01d0 g\u014dngk\u0101i f\u0101b\u00f9, y\u01d0 c\u00f9j\u00ecn h\u00e1ny\u01d4 m\u00f3x\u00edng y\u00e1nji\u016b."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 272, "total_tokens": 774, "completion_tokens": 502}}
[27.02.2025 09:11] Response: WÇ’men jiÃ¨shÃ o le Kanana, yÄ« xÃ¬liÃ¨ zÃ i hÃ¡nyÇ” hÃ© yÄ«ngyÇ” zhÅng biÇoxiÃ n chÅ«sÃ¨ de shuÄngyÇ” mÃ³xÃ­ng. Kanana de jÃ¬suÃ n chÃ©ngbÄ›n xiÇnzhÃ¹ dÄ«yÃº lÃ¨isÃ¬ guÄ«mÃ³ de dÇngjÃ­ mÃ³xÃ­ng. BÃ ogÃ o xiÃ¡ngxÃ¬ jiÃ¨shÃ o le yÃ¹xÃ¹nliÃ n zhÅng shÇyÃ²ng de jÃ¬shÃ¹, bÄokuÃ² gÄo zhÃ¬liÃ ng shÃ¹jÃ¹ guÃ²lÇœ, fÄ“n jiÄ“duÃ n yÃ¹xÃ¹nliÃ n, shÄ“ndÃ¹ kuÃ²zhÇn, jiÇnzhÄ« hÃ© zhÄ“ngliÃº. CÇwÃ i, bÃ ogÃ o hÃ¡i gÃ ikuÃ ng le Kanana mÃ³xÃ­ng zÃ i xÃ¹nliÃ n hÃ²u shÇyÃ²ng de fÄngfÇ, bÄokuÃ² jiÃ ndÅ« wÄ“itiÃ¡o hÃ© piÄnhÇo yÅuhuÃ , yÇ tÃ­gÄo qÃ­ yÇ” yÃ²nghÃ¹ hÃ¹dÃ²ng de nÃ©nglÃ¬. ZÃ¹ihÃ²u, bÃ ogÃ o hÃ¡i tÇolÃ¹n le yÇ”yÃ¡n mÃ³xÃ­ng shÃ¬yÃ¬ng tÃ¨dÃ¬ng chÇngjÄ«ng de kÄ›nÃ©ng fÄngfÇ, rÃº qiÃ nrÃ¹, jiÇnsuÇ’ zÄ“ngqiÃ¡ng shÄ“ngchÃ©ng hÃ© hÃ¡nshÃ¹ diÃ oyÃ²ng. Kanana mÃ³xÃ­ng xÃ¬liÃ¨ cÃ³ng 2.1B dÃ o 32.5B cÄnshÃ¹ bÃ¹dÄ›ng, 2.1B mÃ³xÃ­ng (jÄ«chÇ”, zhÇlÃ¬ng, qiÃ nrÃ¹) yÇ gÅngkÄi fÄbÃ¹, yÇ cÃ¹jÃ¬n hÃ¡nyÇ” mÃ³xÃ­ng yÃ¡njiÅ«.
[27.02.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

æˆ‘ä»¬ä»‹ç»äº†Kananaï¼Œä¸€ç³»åˆ—åœ¨éŸ©è¯­å’Œè‹±è¯­ä¸­è¡¨ç°å‡ºè‰²çš„åŒè¯­æ¨¡å‹ã€‚Kananaçš„è®¡ç®—æˆæœ¬æ˜¾è‘—ä½äºç±»ä¼¼è§„æ¨¡çš„é¡¶çº§æ¨¡å‹ã€‚æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†é¢„è®­ç»ƒä¸­ä½¿ç”¨çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬é«˜è´¨é‡æ•°æ®è¿‡æ»¤ã€åˆ†é˜¶æ®µé¢„è®­ç»ƒã€æ·±åº¦æ‰©å±•ã€å‰ªæå’Œè’¸é¦ã€‚æ­¤å¤–ï¼ŒæŠ¥å‘Šè¿˜æ¦‚è¿°äº†Kananaæ¨¡å‹åœ¨è®­ç»ƒåä½¿ç”¨çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒå’Œåå¥½ä¼˜åŒ–ï¼Œä»¥æé«˜å…¶ä¸ç”¨æˆ·äº’åŠ¨çš„èƒ½åŠ›ã€‚æœ€åï¼ŒæŠ¥å‘Šè¿˜è®¨è®ºäº†è¯­è¨€æ¨¡å‹é€‚åº”ç‰¹å®šåœºæ™¯çš„å¯èƒ½æ–¹æ³•ï¼Œå¦‚åµŒå…¥ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œå‡½æ•°è°ƒç”¨ã€‚Kananaæ¨¡å‹ç³»åˆ—ä»2.1Båˆ°32.5Bå‚æ•°ä¸ç­‰ï¼Œ2.1Bæ¨¡å‹ï¼ˆåŸºç¡€ã€æŒ‡ä»¤ã€åµŒå…¥ï¼‰å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›éŸ©è¯­æ¨¡å‹ç ”ç©¶ã€‚
[27.02.2025 09:11] Mistral response. {"id": "9b0807c3265d46c69faab7e6771b8d1c", "object": "chat.completion", "created": 1740647495, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[{'word': '\u4ecb\u7ecd', 'pinyin': 'ji\u00e8sh\u00e0o', 'trans': 'introduce'},\n{'word': '\u53cc\u8bed', 'pinyin': 'shu\u0101ngy\u01d4', 'trans': 'bilingual'},\n{'word': '\u8ba1\u7b97\u6210\u672c', 'pinyin': 'j\u00ecsu\u00e0n ch\u00e9ngb\u011bn', 'trans': 'computational cost'},\n{'word': '\u663e\u8457', 'pinyin': 'xi\u01cenzh\u00f9', 'trans': 'significant'},\n{'word': '\u9884\u8bad\u7ec3', 'pinyin': 'y\u00f9 x\u00f9nli\u00e0n', 'trans': 'pre-training'},\n{'word': '\u9ad8\u8d28\u91cf', 'pinyin': 'g\u0101o zh\u00ecli\u00e0ng', 'trans': 'high-quality'},\n{'word': '\u8fc7\u6ee4', 'pinyin': 'gu\u00f2l\u01dc', 'trans': 'filter'},\n{'word': '\u5206\u9636\u6bb5', 'pinyin': 'f\u0113n ji\u0113du\u00e0n', 'trans': 'phased'},\n{'word': '\u6df1\u5ea6\u6269\u5c55', 'pinyin': 'sh\u0113nd\u00f9 ku\u00f2zh\u01cen', 'trans': 'deep expansion'},\n{'word': '\u526a\u679d', 'pinyin': 'ji\u01cenzh\u012b', 'trans': 'pruning'},\n{'word': '\u84b8\u998f', 'pinyin': 'zh\u0113ngli\u00fa', 'trans': 'distillation'},\n{'word': '\u76d1\u7763\u5fae\u8c03', 'pinyin': 'ji\u00e0nd\u016b w\u0113iti\u00e1o', 'trans': 'supervised fine-tuning'},\n{'word': '\u504f\u597d\u4f18\u5316', 'pinyin': 'pi\u0101nh\u00e0o y\u014duhu\u00e0', 'trans': 'preference optimization'},\n{'word': '\u4e92\u52a8', 'pinyin': 'h\u00f9d\u00f2ng', 'trans': 'interaction'},\n{'word': '\u5d4c\u5165', 'pinyin': 'qi\u00e0nr\u00f9', 'trans': 'embedding'},\n{'word': '\u68c0\u7d22\u589e\u5f3a\u751f\u6210', 'pinyin': 'ji\u01censu\u01d2 z\u0113ngqi\u00e1ng sh\u0113ngch\u00e9ng', 'trans': 'retrieval-augmented generation'},\n{'word': '\u51fd\u6570\u8c03\u7528', 'pinyin': 'h\u00e1nsh\u00f9 di\u00e0oy\u00f2ng', 'trans': 'function call'},\n{'word': '\u53c2\u6570', 'pinyin': 'c\u0101nsh\u00f9', 'trans': 'parameters'},\n{'word': '\u516c\u5f00\u53d1\u5e03', 'pinyin': 'g\u014dngk\u0101i f\u0101b\u00f9', 'trans': 'publicly released'},\n{'word': '\u4fc3\u8fdb', 'pinyin': 'c\u00f9j\u00ecn', 'trans': 'promote'}]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 304, "total_tokens": 943, "completion_tokens": 639}}
[27.02.2025 09:11] Response: [{'word': 'ä»‹ç»', 'pinyin': 'jiÃ¨shÃ o', 'trans': 'introduce'},
{'word': 'åŒè¯­', 'pinyin': 'shuÄngyÇ”', 'trans': 'bilingual'},
{'word': 'è®¡ç®—æˆæœ¬', 'pinyin': 'jÃ¬suÃ n chÃ©ngbÄ›n', 'trans': 'computational cost'},
{'word': 'æ˜¾è‘—', 'pinyin': 'xiÇnzhÃ¹', 'trans': 'significant'},
{'word': 'é¢„è®­ç»ƒ', 'pinyin': 'yÃ¹ xÃ¹nliÃ n', 'trans': 'pre-training'},
{'word': 'é«˜è´¨é‡', 'pinyin': 'gÄo zhÃ¬liÃ ng', 'trans': 'high-quality'},
{'word': 'è¿‡æ»¤', 'pinyin': 'guÃ²lÇœ', 'trans': 'filter'},
{'word': 'åˆ†é˜¶æ®µ', 'pinyin': 'fÄ“n jiÄ“duÃ n', 'trans': 'phased'},
{'word': 'æ·±åº¦æ‰©å±•', 'pinyin': 'shÄ“ndÃ¹ kuÃ²zhÇn', 'trans': 'deep expansion'},
{'word': 'å‰ªæ', 'pinyin': 'jiÇnzhÄ«', 'trans': 'pruning'},
{'word': 'è’¸é¦', 'pinyin': 'zhÄ“ngliÃº', 'trans': 'distillation'},
{'word': 'ç›‘ç£å¾®è°ƒ', 'pinyin': 'jiÃ ndÅ« wÄ“itiÃ¡o', 'trans': 'supervised fine-tuning'},
{'word': 'åå¥½ä¼˜åŒ–', 'pinyin': 'piÄnhÃ o yÅuhuÃ ', 'trans': 'preference optimization'},
{'word': 'äº’åŠ¨', 'pinyin': 'hÃ¹dÃ²ng', 'trans': 'interaction'},
{'word': 'åµŒå…¥', 'pinyin': 'qiÃ nrÃ¹', 'trans': 'embedding'},
{'word': 'æ£€ç´¢å¢å¼ºç”Ÿæˆ', 'pinyin': 'jiÇnsuÇ’ zÄ“ngqiÃ¡ng shÄ“ngchÃ©ng', 'trans': 'retrieval-augmented generation'},
{'word': 'å‡½æ•°è°ƒç”¨', 'pinyin': 'hÃ¡nshÃ¹ diÃ oyÃ²ng', 'trans': 'function call'},
{'word': 'å‚æ•°', 'pinyin': 'cÄnshÃ¹', 'trans': 'parameters'},
{'word': 'å…¬å¼€å‘å¸ƒ', 'pinyin': 'gÅngkÄi fÄbÃ¹', 'trans': 'publicly released'},
{'word': 'ä¿ƒè¿›', 'pinyin': 'cÃ¹jÃ¬n', 'trans': 'promote'}]
[27.02.2025 09:11] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

æˆ‘ä»¬ä»‹ç»äº†Kananaï¼Œä¸€ç³»åˆ—åœ¨éŸ©è¯­å’Œè‹±è¯­ä¸­è¡¨ç°å‡ºè‰²çš„åŒè¯­æ¨¡å‹ã€‚Kananaçš„è®¡ç®—æˆæœ¬æ˜¾è‘—ä½äºç±»ä¼¼è§„æ¨¡çš„é¡¶çº§æ¨¡å‹ã€‚æŠ¥å‘Šè¯¦ç»†ä»‹ç»äº†é¢„è®­ç»ƒä¸­ä½¿ç”¨çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬é«˜è´¨é‡æ•°æ®è¿‡æ»¤ã€åˆ†é˜¶æ®µé¢„è®­ç»ƒã€æ·±åº¦æ‰©å±•ã€å‰ªæå’Œè’¸é¦ã€‚æ­¤å¤–ï¼ŒæŠ¥å‘Šè¿˜æ¦‚è¿°äº†Kananaæ¨¡å‹åœ¨è®­ç»ƒåä½¿ç”¨çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒå’Œåå¥½ä¼˜åŒ–ï¼Œä»¥æé«˜å…¶ä¸ç”¨æˆ·äº’åŠ¨çš„èƒ½åŠ›ã€‚æœ€åï¼ŒæŠ¥å‘Šè¿˜è®¨è®ºäº†è¯­è¨€æ¨¡å‹é€‚åº”ç‰¹å®šåœºæ™¯çš„å¯èƒ½æ–¹æ³•ï¼Œå¦‚åµŒå…¥ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œå‡½æ•°è°ƒç”¨ã€‚Kananaæ¨¡å‹ç³»åˆ—ä»2.1Båˆ°32.5Bå‚æ•°ä¸ç­‰ï¼Œ2.1Bæ¨¡å‹ï¼ˆåŸºç¡€ã€æŒ‡ä»¤ã€åµŒå…¥ï¼‰å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›éŸ©è¯­æ¨¡å‹ç ”ç©¶ã€‚
[27.02.2025 09:12] Mistral response. {"id": "ce639dc20eaf4aadab5d7a4e996139db", "object": "chat.completion", "created": 1740647518, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "We introduced Kanana, a series of bilingual models that perform excellently in Korean and English. Kanana's computational cost is significantly lower than that of top models of similar scale. The report details the techniques used during pre-training, including high-quality data filtering, staged pre-training, deep scaling, pruning, and distillation. Additionally, the report outlines the methods used with the Kanana models post-training, such as supervised fine-tuning and preference optimization, to enhance their ability to interact with users. Finally, the report discusses potential methods for adapting language models to specific scenarios, such as embedding, retrieval-augmented generation, and function calling. The Kanana model series ranges from 2.1B to 32.5B parameters, with the 2.1B model (base, instruction, embedding) already publicly released to promote research on Korean language models."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 270, "total_tokens": 466, "completion_tokens": 196}}
[27.02.2025 09:12] Response: We introduced Kanana, a series of bilingual models that perform excellently in Korean and English. Kanana's computational cost is significantly lower than that of top models of similar scale. The report details the techniques used during pre-training, including high-quality data filtering, staged pre-training, deep scaling, pruning, and distillation. Additionally, the report outlines the methods used with the Kanana models post-training, such as supervised fine-tuning and preference optimization, to enhance their ability to interact with users. Finally, the report discusses potential methods for adapting language models to specific scenarios, such as embedding, retrieval-augmented generation, and function calling. The Kanana model series ranges from 2.1B to 32.5B parameters, with the 2.1B model (base, instruction, embedding) already publicly released to promote research on Korean language models.
[27.02.2025 09:12] Renaming data file.
[27.02.2025 09:12] Renaming previous data. hf_papers.json to ./d/2025-02-27.json
[27.02.2025 09:12] Saving new data file.
[27.02.2025 09:12] Generating page.
[27.02.2025 09:12] Renaming previous page.
[27.02.2025 09:12] Renaming previous data. index.html to ./d/2025-02-27.html
[27.02.2025 09:12] [Experimental] Generating Chinese page for reading.
[27.02.2025 09:12] Chinese vocab [{'word': 'ä»‹ç»', 'pinyin': 'jiÃ¨shÃ o', 'trans': 'introduce'}, {'word': 'åŒè¯­', 'pinyin': 'shuÄngyÇ”', 'trans': 'bilingual'}, {'word': 'è®¡ç®—æˆæœ¬', 'pinyin': 'jÃ¬suÃ n chÃ©ngbÄ›n', 'trans': 'computational cost'}, {'word': 'æ˜¾è‘—', 'pinyin': 'xiÇnzhÃ¹', 'trans': 'significant'}, {'word': 'é¢„è®­ç»ƒ', 'pinyin': 'yÃ¹ xÃ¹nliÃ n', 'trans': 'pre-training'}, {'word': 'é«˜è´¨é‡', 'pinyin': 'gÄo zhÃ¬liÃ ng', 'trans': 'high-quality'}, {'word': 'è¿‡æ»¤', 'pinyin': 'guÃ²lÇœ', 'trans': 'filter'}, {'word': 'åˆ†é˜¶æ®µ', 'pinyin': 'fÄ“n jiÄ“duÃ n', 'trans': 'phased'}, {'word': 'æ·±åº¦æ‰©å±•', 'pinyin': 'shÄ“ndÃ¹ kuÃ²zhÇn', 'trans': 'deep expansion'}, {'word': 'å‰ªæ', 'pinyin': 'jiÇnzhÄ«', 'trans': 'pruning'}, {'word': 'è’¸é¦', 'pinyin': 'zhÄ“ngliÃº', 'trans': 'distillation'}, {'word': 'ç›‘ç£å¾®è°ƒ', 'pinyin': 'jiÃ ndÅ« wÄ“itiÃ¡o', 'trans': 'supervised fine-tuning'}, {'word': 'åå¥½ä¼˜åŒ–', 'pinyin': 'piÄnhÃ o yÅuhuÃ ', 'trans': 'preference optimization'}, {'word': 'äº’åŠ¨', 'pinyin': 'hÃ¹dÃ²ng', 'trans': 'interaction'}, {'word': 'åµŒå…¥', 'pinyin': 'qiÃ nrÃ¹', 'trans': 'embedding'}, {'word': 'æ£€ç´¢å¢å¼ºç”Ÿæˆ', 'pinyin': 'jiÇnsuÇ’ zÄ“ngqiÃ¡ng shÄ“ngchÃ©ng', 'trans': 'retrieval-augmented generation'}, {'word': 'å‡½æ•°è°ƒç”¨', 'pinyin': 'hÃ¡nshÃ¹ diÃ oyÃ²ng', 'trans': 'function call'}, {'word': 'å‚æ•°', 'pinyin': 'cÄnshÃ¹', 'trans': 'parameters'}, {'word': 'å…¬å¼€å‘å¸ƒ', 'pinyin': 'gÅngkÄi fÄbÃ¹', 'trans': 'publicly released'}, {'word': 'ä¿ƒè¿›', 'pinyin': 'cÃ¹jÃ¬n', 'trans': 'promote'}]
[27.02.2025 09:12] Renaming previous Chinese page.
[27.02.2025 09:12] Renaming previous data. zh.html to ./d/2025-02-26_zh_reading_task.html
[27.02.2025 09:12] Writing Chinese reading task.
[27.02.2025 09:12] Writing result.
[27.02.2025 09:12] Renaming log file.
[27.02.2025 09:12] Renaming previous data. log.txt to ./logs/2025-02-27_last_log.txt
