[04.02.2025 21:09] Read previous papers.
[04.02.2025 21:09] Generating top page (month).
[04.02.2025 21:09] Writing top page (month).
[04.02.2025 22:09] Read previous papers.
[04.02.2025 22:09] Get feed.
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01237
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01061
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01456
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18636
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01341
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01534
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01639
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.00698
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01068
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.00094
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01142
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01637
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01100
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01081
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01591
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01208
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01441
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01584
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01636
[04.02.2025 22:09] Extract page data from URL. URL: https://huggingface.co/papers/2502.01619
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18055
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.00314
[04.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01126
[04.02.2025 22:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[04.02.2025 22:09] No deleted papers detected.
[04.02.2025 22:09] Downloading and parsing papers (pdf, html). Total: 23.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01237.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01237.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01237.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01061.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01061.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01061.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01456.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01456.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01456.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18636.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18636.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18636.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01341.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01341.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01341.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01534.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01534.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01534.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01639.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01639.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01639.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.00698.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.00698.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.00698.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01068.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01068.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01068.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.00094.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.00094.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.00094.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01142.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01142.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01142.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01637.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01637.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01637.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01100.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01100.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01100.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01081.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01081.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01081.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01591.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01591.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01591.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01208.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01208.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01208.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01441.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01441.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01441.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01584.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01584.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01584.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01636.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01636.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01636.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01619.
[04.02.2025 22:09] Downloading paper 2502.01619 from http://arxiv.org/pdf/2502.01619v1...
[04.02.2025 22:09] Extracting affiliations from text.
[04.02.2025 22:09] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Archiki Prasad * 1 Elias Stengel-Eskin * 1 Justin Chih-Yao Chen 1 Zaid Khan 1 Mohit Bansal "
[04.02.2025 22:09] Response: []
[04.02.2025 22:09] Extracting affiliations from text.
[04.02.2025 22:09] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Archiki Prasad * 1 Elias Stengel-Eskin * 1 Justin Chih-Yao Chen 1 Zaid Khan 1 Mohit BansalUnit tests (UTs) play an instrumental role in assessing code correctness as well as providing feedback to large language model (LLM) as it iteratively debugs faulty code, motivating automated test generation. However, we uncover trade-off between generating unit test inputs that reveal errors when given faulty code and correctly predicting the unit test output without access to the gold solution. To address this trade-off, we propose UTGEN, which teaches LLMs to generate unit test inputs that reveal errors along with their correct expected outputs based on task descriptions and candidate code. We integrate UTGEN into UTDEBUG, robust debugging pipeline that uses generated tests to help LLMs debug effectively. Since model-generated tests can provide noisy signals (e.g., from incorrectly predicted outputs), UTDEBUG (i) scales UTGEN via test-time compute to improve UT output prediction, and (ii) validates and back-tracks edits based on multiple generated UTs to avoid overfitting. We show that UTGEN outperforms UT generation baselines by 7.59% based on metric measuring the presence of both error-revealing UT inputs and correct UT outputs. When used with UTDEBUG, we find that feedback from UTGENs unit tests improves pass@1 accuracy of Qwen-2.5 7B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3% and 12.35% (respectively) over other LLM-based UT generation baselines. 5 2 0 2 3 ] . [ 1 9 1 6 1 0 . 2 0 5 2 : r 1. Introduction With rapid advancements in training large language models (LLMs; Achiam et al., 2023; Anthropic, 2024; Gemini et al., 2023; Dubey et al., 2024), enhancing their coding abilities has garnered significant attention (Chen et al., 2021; Li et al., 2023; Roziere et al., 2023; Guo et al., 2024b; Hui et al., 2024, inter alia). However, these models are far from perfect and much like human-written code model-written *Equal contribution 1Department of Computer Science, UNC Chapel Hill. Correspondence to: Archiki Prasad <archiki@cs.unc.edu>. Link to datasets and code: https: //github.com/archiki/UTGenDebug 1 Figure 1. Overview: Self-evaluating code correctness using LLMs can be unreliable and collecting human-written unit tests can be laborious; we propose UTGEN, which automatically generates failing unit tests for faulty code (triggering errors) without access to the gold solution. The generated unit tests can in turn be used for LLM debugging based on unit test feedback via UTDEBUG, leading to improved downstream code accuracy. code contains errors. Human developers often improve their code through test-driven development with iterative debugging, i.e., identifying failure cases by providing example inputs and their expected outputs, reasoning over causes of failure, and modifying the code to address the issues. Unit tests (UTs) are one form of such pairings: code inputs and expected outputs that test individual functionalities in piece of code. failing unit test provides targeted feedback, not only identifying that piece of code is not operating as expected but also helping to localize the error to one part of the code (Maximilien & Williams, 2003; Nagappan et al., 2008; Ficco et al., 2011). Models have similarly been shown to benefit from iterative debugging based on explicit or implicit feedback stemming from failing unit tests (Chen et al., 2023b; Moon et al., 2023). However, the ability to provide feedback and debug incorrect code is often bottlenecked by the availability of (failing) unit tests for given problem. While several coding benchmarks come with human-written UTs for evaluation purposes, these suites of UTs are typically small due to the laborious annotation process (Liu et al., 2024). Unit test collection is challenging for two reasons: first, it requires sampling inputs that are likely to trigger an error. For example in Figure 1, the unit test: Learning to Generate Unit Tests for Automated Debugging next smallest pld(120) == 121 would not trigger any error (despite the fact that the code is incorrect since the error happens to not be triggered for multiples of 10), while another unit test: next smallest pld(123) == 131 would lead to an incorrect output, revealing bug in the function. Secondly, UTs require expected outputs, i.e., the desired behavior of the code being tested must be known. For example, in Figure 1, the expected output 131 must be given in advance. Due to these challenges, prior work employs LLMs to generate unit test inputs at random (i.e., without conditioning on faulty code to generate failing inputs) and often uses the gold (correct) code solution for generating outputs (Chen et al., 2023a; Chae et al., 2024), which is generally not available at test time. Therefore, these approaches do not scale to automated debugging, which requires an online and automated method for dynamically generating UTs as problems are iteratively debugged by the model. To address this gap, we pose the following research questions: RQ1: What are desirable properties for UT generators, and how do we measure them? RQ2: How well do LLMs perform zero-shot UT generation, and how can we improve their abilities? RQ3: How do we best use an automated but potentially noisy UT generator to improve code debugging? To address RQ1, we characterize two desirable properties of unit test generators (in Section 3.1): 1) high attack rate, i.e., given faulty code, the unit test generator should generate UT inputs that are likely to trigger errors;1 2) high output accuracy, ensuring that the corresponding output of the unit test is consistent with the task description (and that of correct solution). For instance, in Figure 1, next smallest pld(120) would lead to lower attack rate, as it does not trigger any errors, while the generated UT next smallest pld(123) == 131 does trigger the error. While one test is attacking and another is not, both have high output accuracy, since in both cases the output is correct. By design, we can measure these properties via three intrinsic metrics: measuring attack rate and output accuracy independently and then, crucially, how often UT generator can generate both failing inputs along with correct UT outputs based only on the problem description and faulty code, i.e., without access to the gold solution. We benchmark the ability of various LLMs to act as zero-shot unit test generators using attack rate and output accuracy (i.e., intrinsic "
[04.02.2025 22:09] Mistral response. {"id": "22527186fcbb449c8c93fe282b2db8a8", "object": "chat.completion", "created": 1738706979, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\"Department of Computer Science, UNC Chapel Hill\"]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1693, "total_tokens": 1706, "completion_tokens": 13}}
[04.02.2025 22:09] Response: ["Department of Computer Science, UNC Chapel Hill"]
[04.02.2025 22:09] Deleting PDF ./assets/pdf/2502.01619.pdf.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18055.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18055.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18055.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.00314.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.00314.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.00314.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2502.01126.
[04.02.2025 22:09] Extra JSON file exists (./assets/json/2502.01126.json), skip PDF parsing.
[04.02.2025 22:09] Paper image links file exists (./assets/img_data/2502.01126.json), skip HTML parsing.
[04.02.2025 22:09] Success.
[04.02.2025 22:09] Enriching papers with extra data.
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 0. Direct Alignment Algorithms (DAAs) simplify language model alignment by replacing reinforcement learning (RL) and reward modeling (RM) in Reinforcement Learning from Human Feedback (RLHF) with direct policy optimization. DAAs can be classified by their ranking losses (pairwise vs. pointwise), by the...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 1. End-to-end human animation, such as audio-driven talking human generation, has undergone notable advancements in the recent few years. However, existing methods still struggle to scale up as large general video generation models, limiting their potential in real applications. In this paper, we propo...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 2. Dense process rewards have proven a more effective alternative to the sparse outcome-level rewards in the inference-time scaling of large language models (LLMs), particularly in tasks requiring complex multi-step reasoning. While dense rewards also offer an appealing choice for the reinforcement lea...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 3. The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulner...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 4. Aligning visual features with language embeddings is a key challenge in vision-language models (VLMs). The performance of such models hinges on having a good connector that maps visual features generated by a vision encoder to a shared embedding space with the LLM while preserving semantic similarit...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 5. Large Language Models (LLMs) as judges and LLM-based data synthesis have emerged as two fundamental LLM-driven data annotation methods in model development. While their combination significantly enhances the efficiency of model training and evaluation, little attention has been given to the potentia...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 6. We present SliderSpace, a framework for automatically decomposing the visual capabilities of diffusion models into controllable and human-understandable directions. Unlike existing control methods that require a user to specify attributes for each edit direction individually, SliderSpace discovers m...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 7. IQ testing has served as a foundational methodology for evaluating human cognitive capabilities, deliberately decoupling assessment from linguistic background, language proficiency, or domain-specific knowledge to isolate core competencies in abstraction and reasoning. Yet, artificial intelligence r...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 8. While large language models (LLMs) excel at handling long-context sequences, they require substantial key-value (KV) caches to store contextual information, which can heavily burden computational efficiency and memory usage. Previous efforts to compress these KV caches primarily focused on reducing ...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 9. Amid the swift progress of large language models (LLMs) and their evolution into large multimodal models (LMMs), significant strides have been made in high-resource languages such as English and Chinese. While Arabic LLMs have seen notable progress, Arabic LMMs remain largely unexplored, often narro...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 10. Large Language Models (LLMs) have shown remarkable potential in reasoning while they still suffer from severe factual hallucinations due to timeliness, accuracy, and coverage of parametric knowledge. Meanwhile, integrating reasoning with retrieval-augmented generation (RAG) remains challenging due t...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 11. We propose SCONE (Scalable, Contextualized, Offloaded, N-gram Embedding), a method for extending input embedding layers to enhance language model performance as layer size scales. To avoid increased decoding costs, SCONE retains the original vocabulary while introducing embeddings for a set of frequ...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 12. We investigate the logical reasoning capabilities of large language models (LLMs) and their scalability in complex non-monotonic reasoning. To this end, we introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM reasoning performance on logic grid puzzles derived from constraint...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 13. The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, o3 outperformed humans in novel problem-solving and skill acquisition on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI)....
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 14. We present an approach to model-based RL that achieves a new state of the art performance on the challenging Craftax-classic benchmark, an open-world 2D survival game that requires agents to exhibit a wide range of general abilities -- such as strong generalization, deep exploration, and long-term r...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 15. Even highly capable large language models (LLMs) can produce biased or unsafe responses, and alignment techniques, such as RLHF, aimed at mitigating this issue, are expensive and prone to overfitting as they retrain the LLM. This paper introduces a novel inference-time alignment approach that ensure...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 16. Consistency models are a new family of generative models capable of producing high-quality samples in either a single step or multiple steps. Recently, consistency models have demonstrated impressive performance, achieving results on par with diffusion models in the pixel space. However, the success...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 17. Existing benchmarks for frontier models often test specialized, ``PhD-level'' knowledge that is difficult for non-experts to grasp. In contrast, we present a benchmark based on the NPR Sunday Puzzle Challenge that requires only general knowledge. Our benchmark is challenging for both humans and mode...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 18. Prior work in parameter-modifying knowledge editing has shown that large-scale sequential editing leads to significant model degradation. In this paper, we study the reasons behind this and scale sequential knowledge editing to 10,000 sequential edits, while maintaining the downstream performance of...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 19. Unit tests (UTs) play an instrumental role in assessing code correctness as well as providing feedback to a large language model (LLM) as it iteratively debugs faulty code, motivating automated test generation. However, we uncover a trade-off between generating unit test inputs that reveal errors wh...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 20. Pathology Foundation Models (FMs) hold great promise for healthcare. Before they can be used in clinical practice, it is essential to ensure they are robust to variations between medical centers. We measure whether pathology FMs focus on biological features like tissue and cancer type, or on the wel...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 21. The retroperitoneum hosts a variety of tumors, including rare benign and malignant types, which pose diagnostic and treatment challenges due to their infrequency and proximity to vital structures. Estimating tumor volume is difficult due to their irregular shapes, and manual segmentation is time-con...
[04.02.2025 22:09] ********************************************************************************
[04.02.2025 22:09] Abstract 22. Language models (LMs) should provide reliable confidence estimates to help users detect mistakes in their outputs and defer to human experts when necessary. Asking a language model to assess its confidence ("Score your confidence from 0-1.") is a natural way of evaluating its uncertainty. However, m...
[04.02.2025 22:09] Read previous papers.
[04.02.2025 22:09] Generating reviews via LLM API.
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#rlhf", "#training", "#alignment"], "emoji": "🎯", "ru": {"title": "Прямое выравнивание: простой путь к улучшению языковых моделей", "desc": "В статье рассматриваются алгоритмы прямого выравнивания (DAA) как альтернатива обучению с подкреплением в контексте выравнивания языковых моде
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#video", "#training", "#diffusion"], "emoji": "🎭", "ru": {"title": "OmniHuman: универсальная модель для генерации реалистичных видео с людьми", "desc": "OmniHuman - это новая модель на основе Diffusion Transformer для генерации реалистичных видео с лю
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "PRIME: Эффективное обучение ИИ-моделей с неявными процессными наградами", "desc": "Эта статья представляет новый метод обучения с подкреплением для больших языковых моделей, называемый PRIME. Он исполь
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#rag", "#security", "#dataset", "#benchmark"], "emoji": "🛡️", "ru": {"title": "SafeRAG: оценка уязвимостей генерации с дополнением на основе извлечения", "desc": "В статье представлен бенчмарк SafeRAG для оценки безопасности генерации с дополнением на основе извлечения (RAG). Авторы
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#alignment", "#cv", "#multimodal"], "emoji": "🔀", "ru": {"title": "Улучшение выравнивания модальностей в мультимодальных моделях", "desc": "AlignVLM - это новый метод выравнивания визуальных и текстовых признаков в мультимодальных моделях. Он отображает визуальные признаки в виде вз
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#training", "#dataset", "#leakage"], "emoji": "🕵️", "ru": {"title": "Осторожно: LLM-судьи могут быть предвзяты!", "desc": "Исследование выявляет проблему 'утечки предпочтений' при использовании больших языковых моделей (LLM) в качестве судей для оценки 
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#dataset", "#open_source", "#multimodal", "#interpretability", "#cv"], "emoji": "🎚️", "ru": {"title": "SliderSpace: Раскрытие скрытых возможностей диффузионных моделей", "desc": "SliderSpace - это фреймворк для автоматической декомпозиции визуальных во
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#reasoning", "#multimodal"], "emoji": "🧠", "ru": {"title": "Мультимодальный ИИ проваливает тест на интеллект", "desc": "Статья представляет новый фреймворк MM-IQ для оценки когнитивных способностей мультимодальных систем искусственного интеллекта. Фрейм
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#long_context", "#training", "#inference", "#optimization"], "emoji": "🚀", "ru": {"title": "FastKV: Ускорение обработки длинных последовательностей в LLM", "desc": "Статья представляет FastKV - новый метод сжатия кэша ключ-значение (KV) для больших языковых моделей (LLM), направленн
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#low_resource", "#multimodal", "#multilingual"], "emoji": "🌍", "ru": {"title": "AIN: Прорыв в арабоязычном мультимодальном ИИ", "desc": "Представлена модель AIN - двуязычная мультимодальная языковая модель для арабского и английского языков. Модель обучена 
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#optimization", "#hallucinations", "#reasoning", "#rag", "#rl"], "emoji": "🧠", "ru": {"title": "DeepRAG: умное сочетание поиска и рассуждений для ИИ", "desc": "DeepRAG - это новый фреймворк, моделирующий рассуждения с поиском информации как марковский процесс принятия решений. Он ит
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#architecture", "#inference", "#long_context", "#training", "#optimization"], "emoji": "🚀", "ru": {"title": "Ускорение языковых моделей без увеличения вычислительных затрат", "desc": "SCONE - это новый метод расширения слоёв входных эмбеддингов для улучшения производительности языко
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#reasoning", "#training", "#inference", "#benchmark"], "emoji": "🧩", "ru": {"title": "Проклятие сложности в логическом мышлении LLM", "desc": "В статье исследуются возможности логического рассуждения больших языковых моделей (LLM) и их масштабируемость в сложных задачах немонотонног
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#agi", "#open_source", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эволюция рассуждений: от символов к мультимодальности", "desc": "Статья рассматривает эволюцию возможностей рассуждения в мультимодальных задачах у языковых моделей серий G
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#rl", "#architecture", "#benchmark", "#games", "#training", "#reasoning", "#optimization"], "emoji": "🚀", "ru": {"title": "Новый рубеж в model-based RL: превосходя человека в Craftax-classic", "desc": "Статья представляет новый подход к обучению с подкреплением на основе модели, дос
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#ethics", "#rlhf", "#inference", "#alignment"], "emoji": "🛡️", "ru": {"title": "Безопасная генерация ответов LLM без переобучения", "desc": "Статья представляет новый подход к выравниванию больших языковых моделей (LLM) во время вывода, обеспечивающий генерацию безопасных ответов с 
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#dataset", "#training", "#optimization", "#architecture", "#open_source", "#diffusion", "#video"], "emoji": "🧠", "ru": {"title": "Преодоление выбросов в латентном пространстве для улучшения консистентных моделей", "desc": "Эта статья представляет новый подход к обучению консистентны
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#inference", "#benchmark"], "emoji": "🧩", "ru": {"title": "Новый бенчмарк раскрывает скрытые возможности и недостатки языковых моделей", "desc": "Авторы представляют новый бенчмарк для оценки языковых моделей, основанный на головоломках NPR Sunday Puzz
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#training", "#interpretability", "#architecture", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное масштабирование редактирования знаний в нейросетях", "desc": "Статья посвящена улучшению методов последовательного редактирования знаний в больших языковых моделях. Авторы 
[04.02.2025 22:09] Querying the API.
[04.02.2025 22:09] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Unit tests (UTs) play an instrumental role in assessing code correctness as well as providing feedback to a large language model (LLM) as it iteratively debugs faulty code, motivating automated test generation. However, we uncover a trade-off between generating unit test inputs that reveal errors when given a faulty code and correctly predicting the unit test output without access to the gold solution. To address this trade-off, we propose UTGen, which teaches LLMs to generate unit test inputs that reveal errors along with their correct expected outputs based on task descriptions and candidate code. We integrate UTGen into UTDebug, a robust debugging pipeline that uses generated tests to help LLMs debug effectively. Since model-generated tests can provide noisy signals (e.g., from incorrectly predicted outputs), UTDebug (i) scales UTGen via test-time compute to improve UT output prediction, and (ii) validates and back-tracks edits based on multiple generated UTs to avoid overfitting. We show that UTGen outperforms UT generation baselines by 7.59% based on a metric measuring the presence of both error-revealing UT inputs and correct UT outputs. When used with UTDebug, we find that feedback from UTGen's unit tests improves pass@1 accuracy of Qwen-2.5 7B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3% and 12.35% (respectively) over other LLM-based UT generation baselines.
[04.02.2025 22:09] Response: {
  "desc": "Статья представляет UTGen - метод обучения языковых моделей генерации юнит-тестов, выявляющих ошибки в коде и предсказывающих корректные выходные данные. UTGen интегрирован в конвейер отладки UTDebug, который использует сгенерированные тесты для эффективной отладки кода языковыми моделями. UTDebug масштабирует UTGen во время выполнения для улучшения предсказания выходных данных тестов и проверяет изменения на основе нескольких сгенерированных юнит-тестов. Результаты показывают, что UTGen превосходит базовые методы генерации юнит-тестов, а UTDebug улучшает точность отладки кода языковыми моделями.",
  "emoji": "🧪",
  "title": "Автоматическая генерация юнит-тестов для улучшения отладки кода языковыми моделями"
}
[04.02.2025 22:09] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Unit tests (UTs) play an instrumental role in assessing code correctness as well as providing feedback to a large language model (LLM) as it iteratively debugs faulty code, motivating automated test generation. However, we uncover a trade-off between generating unit test inputs that reveal errors when given a faulty code and correctly predicting the unit test output without access to the gold solution. To address this trade-off, we propose UTGen, which teaches LLMs to generate unit test inputs that reveal errors along with their correct expected outputs based on task descriptions and candidate code. We integrate UTGen into UTDebug, a robust debugging pipeline that uses generated tests to help LLMs debug effectively. Since model-generated tests can provide noisy signals (e.g., from incorrectly predicted outputs), UTDebug (i) scales UTGen via test-time compute to improve UT output prediction, and (ii) validates and back-tracks edits based on multiple generated UTs to avoid overfitting. We show that UTGen outperforms UT generation baselines by 7.59% based on a metric measuring the presence of both error-revealing UT inputs and correct UT outputs. When used with UTDebug, we find that feedback from UTGen's unit tests improves pass@1 accuracy of Qwen-2.5 7B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3% and 12.35% (respectively) over other LLM-based UT generation baselines."

[04.02.2025 22:09] Response: ```python
["PLP", "TRAINING"]
```
[04.02.2025 22:09] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Unit tests (UTs) play an instrumental role in assessing code correctness as well as providing feedback to a large language model (LLM) as it iteratively debugs faulty code, motivating automated test generation. However, we uncover a trade-off between generating unit test inputs that reveal errors when given a faulty code and correctly predicting the unit test output without access to the gold solution. To address this trade-off, we propose UTGen, which teaches LLMs to generate unit test inputs that reveal errors along with their correct expected outputs based on task descriptions and candidate code. We integrate UTGen into UTDebug, a robust debugging pipeline that uses generated tests to help LLMs debug effectively. Since model-generated tests can provide noisy signals (e.g., from incorrectly predicted outputs), UTDebug (i) scales UTGen via test-time compute to improve UT output prediction, and (ii) validates and back-tracks edits based on multiple generated UTs to avoid overfitting. We show that UTGen outperforms UT generation baselines by 7.59% based on a metric measuring the presence of both error-revealing UT inputs and correct UT outputs. When used with UTDebug, we find that feedback from UTGen's unit tests improves pass@1 accuracy of Qwen-2.5 7B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3% and 12.35% (respectively) over other LLM-based UT generation baselines."

[04.02.2025 22:09] Response: ```python
["OPTIMIZATION", "INTERPRETABILITY"]
```
[04.02.2025 22:09] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces UTGen, a method that helps large language models (LLMs) generate unit test inputs that can effectively reveal errors in faulty code while also predicting the correct outputs. The authors highlight a challenge where generating tests that expose errors can lead to incorrect output predictions without having the correct solutions available. To overcome this, UTGen is integrated into a debugging pipeline called UTDebug, which enhances the debugging process by validating and refining the generated tests. The results show that UTGen significantly improves the accuracy of LLMs in debugging tasks, outperforming existing methods in generating effective unit tests.","title":"Enhancing Debugging with Smart Unit Test Generation"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper introduces UTGen, a method that helps large language models (LLMs) generate unit test inputs that can effectively reveal errors in faulty code while also predicting the correct outputs. The authors highlight a challenge where generating tests that expose errors can lead to incorrect output predictions without having the correct solutions available. To overcome this, UTGen is integrated into a debugging pipeline called UTDebug, which enhances the debugging process by validating and refining the generated tests. The results show that UTGen significantly improves the accuracy of LLMs in debugging tasks, outperforming existing methods in generating effective unit tests.', title='Enhancing Debugging with Smart Unit Test Generation'))
[04.02.2025 22:09] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为UTGen的自动化单元测试生成方法，旨在帮助大型语言模型（LLM）生成能够揭示错误的单元测试输入及其正确的预期输出。研究发现，生成的单元测试输入在揭示错误和正确预测输出之间存在权衡。UTGen被集成到UTDebug调试管道中，以提高LLM的调试效果，并通过多次生成的测试来验证和回溯编辑，避免过拟合。实验结果表明，UTGen在生成有效单元测试方面优于现有基线，并显著提高了LLM在调试任务中的准确性。","title":"自动化单元测试生成与调试的创新方案"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='本文提出了一种名为UTGen的自动化单元测试生成方法，旨在帮助大型语言模型（LLM）生成能够揭示错误的单元测试输入及其正确的预期输出。研究发现，生成的单元测试输入在揭示错误和正确预测输出之间存在权衡。UTGen被集成到UTDebug调试管道中，以提高LLM的调试效果，并通过多次生成的测试来验证和回溯编辑，避免过拟合。实验结果表明，UTGen在生成有效单元测试方面优于现有基线，并显著提高了LLM在调试任务中的准确性。', title='自动化单元测试生成与调试的创新方案'))
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#healthcare", "#ethics", "#security", "#dataset"], "emoji": "🔬", "ru": {"title": "Путь к надежным фундаментальным моделям в патологии: преодоление влияния медицинских центров", "desc": "Статья рассматривает проблему надежности фундаментальных моделей (ФМ) в патологии для использован
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#architecture", "#cv", "#training", "#dataset"], "emoji": "🧠", "ru": {"title": "Эффективная сегментация опухолей с помощью усовершенствованных нейросетей", "desc": "Статья посвящена автоматической сегментации опухолей забрюшинного пространства с использованием различных архитектур г
[04.02.2025 22:09] Using data from previous issue: {"categories": ["#interpretability", "#rlhf", "#reasoning", "#benchmark", "#data"], "emoji": "🧠", "ru": {"title": "Повышение надежности языковых моделей через относительную оценку уверенности", "desc": "Исследование предлагает метод относительной оценки уверенности языковых моделей, где модель сравн
[04.02.2025 22:09] Loading Chinese text from previous data.
[04.02.2025 22:09] Renaming data file.
[04.02.2025 22:09] Renaming previous data. hf_papers.json to ./d/2025-02-04.json
[04.02.2025 22:09] Saving new data file.
[04.02.2025 22:09] Generating page.
[04.02.2025 22:09] Renaming previous page.
[04.02.2025 22:09] Renaming previous data. index.html to ./d/2025-02-04.html
[04.02.2025 22:09] [Experimental] Generating Chinese page for reading.
[04.02.2025 22:09] Chinese vocab [{'word': '直接对齐算法', 'pinyin': 'zhíjiē duìqí suànfǎ', 'trans': 'direct alignment algorithm'}, {'word': '策略', 'pinyin': 'cèlüè', 'trans': 'strategy'}, {'word': '优化', 'pinyin': 'yōuhuà', 'trans': 'optimize'}, {'word': '简化', 'pinyin': 'jiǎnhuà', 'trans': 'simplify'}, {'word': '语言模型', 'pinyin': 'yǔyán móxíng', 'trans': 'language model'}, {'word': '对齐', 'pinyin': 'duìqí', 'trans': 'align'}, {'word': '排名', 'pinyin': 'páimíng', 'trans': 'rank'}, {'word': '损失', 'pinyin': 'sǔnshī', 'trans': 'loss'}, {'word': '奖励', 'pinyin': 'jiǎnglì', 'trans': 'reward'}, {'word': '类型', 'pinyin': 'lèixíng', 'trans': 'type'}, {'word': '监督', 'pinyin': 'jiàndū', 'trans': 'supervise'}, {'word': '微调', 'pinyin': 'wēitiáo', 'trans': 'fine-tune'}, {'word': '阶段', 'pinyin': 'jiēduàn', 'trans': 'stage'}, {'word': '单阶段', 'pinyin': 'dān jiēduàn', 'trans': 'single-stage'}, {'word': '双阶段', 'pinyin': 'shuāng jiēduàn', 'trans': 'two-stage'}, {'word': '方法', 'pinyin': 'fāngfǎ', 'trans': 'method'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '显式', 'pinyin': 'xiǎnshì', 'trans': 'explicit'}, {'word': '参数', 'pinyin': 'cānshǔ', 'trans': 'parameter'}, {'word': '性能', 'pinyin': 'xíngnéng', 'trans': 'performance'}, {'word': '分析', 'pinyin': 'fēnxī', 'trans': 'analysis'}, {'word': '显示', 'pinyin': 'xiǎnshì', 'trans': 'show'}, {'word': '关键', 'pinyin': 'guǎnjiàn', 'trans': 'key'}, {'word': '因素', 'pinyin': 'yīnsù', 'trans': 'factor'}, {'word': '成对', 'pinyin': 'chéngduì', 'trans': 'pair'}, {'word': '目标', 'pinyin': 'mùbiāo', 'trans': 'target'}, {'word': '点', 'pinyin': 'diǎn', 'trans': 'point'}, {'word': '隐式', 'pinyin': 'yǐnshì', 'trans': 'implicit'}, {'word': '函数', 'pinyin': 'hánshù', 'trans': 'function'}, {'word': '结果', 'pinyin': 'jiéguǒ', 'trans': 'result'}, {'word': '强调', 'pinyin': 'qiángdiào', 'trans': 'emphasize'}, {'word': '仔细', 'pinyin': 'zǐxì', 'trans': 'careful'}, {'word': '评估', 'pinyin': 'pínggū', 'trans': 'evaluate'}, {'word': '重要性', 'pinyin': 'zhòngyàoxìng', 'trans': 'importance'}, {'word': '避免', 'pinyin': 'bìmiǎn', 'trans': 'avoid'}, {'word': '过早', 'pinyin': 'guòzǎo', 'trans': 'premature'}, {'word': '声称', 'pinyin': 'shēngchēng', 'trans': 'claim'}, {'word': '提升', 'pinyin': 'tíshēng', 'trans': 'improvement'}, {'word': '整体', 'pinyin': 'zhěngtǐ', 'trans': 'overall'}, {'word': '优越性', 'pinyin': 'yōuyuèxìng', 'trans': 'superiority'}]
[04.02.2025 22:09] Renaming previous Chinese page.
[04.02.2025 22:09] Renaming previous data. zh.html to ./d/2025-02-03_zh_reading_task.html
[04.02.2025 22:09] Writing Chinese reading task.
[04.02.2025 22:09] Writing result.
[04.02.2025 22:09] Renaming log file.
[04.02.2025 22:09] Renaming previous data. log.txt to ./logs/2025-02-04_last_log.txt
