[04.02.2025 13:18] Read previous papers.
[04.02.2025 13:18] Generating top page (month).
[04.02.2025 13:18] Writing top page (month).
[04.02.2025 14:09] Read previous papers.
[04.02.2025 14:09] Get feed.
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01237
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01061
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01456
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01534
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18636
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01068
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.00094
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01142
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.00698
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01208
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01100
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01081
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01591
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01441
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01637
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01639
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01584
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.01636
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18055
[04.02.2025 14:09] Get page data from previous paper. URL: https://huggingface.co/papers/2502.00314
[04.02.2025 14:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[04.02.2025 14:09] No deleted papers detected.
[04.02.2025 14:09] Downloading and parsing papers (pdf, html). Total: 20.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01237.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01237.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01237.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01061.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01061.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01061.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01456.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01456.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01456.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01534.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01534.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01534.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2501.18636.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2501.18636.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2501.18636.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01068.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01068.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01068.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.00094.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.00094.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.00094.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01142.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01142.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01142.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.00698.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.00698.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.00698.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01208.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01208.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01208.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01100.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01100.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01100.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01081.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01081.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01081.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01591.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01591.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01591.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01441.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01441.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01441.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01637.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01637.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01637.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01639.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01639.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01639.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01584.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01584.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01584.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.01636.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.01636.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.01636.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2501.18055.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2501.18055.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2501.18055.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Downloading and parsing paper https://huggingface.co/papers/2502.00314.
[04.02.2025 14:09] Extra JSON file exists (./assets/json/2502.00314.json), skip PDF parsing.
[04.02.2025 14:09] Paper image links file exists (./assets/img_data/2502.00314.json), skip HTML parsing.
[04.02.2025 14:09] Success.
[04.02.2025 14:09] Enriching papers with extra data.
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 0. Direct Alignment Algorithms (DAAs) simplify language model alignment by replacing reinforcement learning (RL) and reward modeling (RM) in Reinforcement Learning from Human Feedback (RLHF) with direct policy optimization. DAAs can be classified by their ranking losses (pairwise vs. pointwise), by the...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 1. End-to-end human animation, such as audio-driven talking human generation, has undergone notable advancements in the recent few years. However, existing methods still struggle to scale up as large general video generation models, limiting their potential in real applications. In this paper, we propo...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 2. Dense process rewards have proven a more effective alternative to the sparse outcome-level rewards in the inference-time scaling of large language models (LLMs), particularly in tasks requiring complex multi-step reasoning. While dense rewards also offer an appealing choice for the reinforcement lea...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 3. Large Language Models (LLMs) as judges and LLM-based data synthesis have emerged as two fundamental LLM-driven data annotation methods in model development. While their combination significantly enhances the efficiency of model training and evaluation, little attention has been given to the potentia...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 4. The indexing-retrieval-generation paradigm of retrieval-augmented generation (RAG) has been highly successful in solving knowledge-intensive tasks by integrating external knowledge into large language models (LLMs). However, the incorporation of external and unverified knowledge increases the vulner...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 5. While large language models (LLMs) excel at handling long-context sequences, they require substantial key-value (KV) caches to store contextual information, which can heavily burden computational efficiency and memory usage. Previous efforts to compress these KV caches primarily focused on reducing ...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 6. Amid the swift progress of large language models (LLMs) and their evolution into large multimodal models (LMMs), significant strides have been made in high-resource languages such as English and Chinese. While Arabic LLMs have seen notable progress, Arabic LMMs remain largely unexplored, often narro...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 7. Large Language Models (LLMs) have shown remarkable potential in reasoning while they still suffer from severe factual hallucinations due to timeliness, accuracy, and coverage of parametric knowledge. Meanwhile, integrating reasoning with retrieval-augmented generation (RAG) remains challenging due t...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 8. IQ testing has served as a foundational methodology for evaluating human cognitive capabilities, deliberately decoupling assessment from linguistic background, language proficiency, or domain-specific knowledge to isolate core competencies in abstraction and reasoning. Yet, artificial intelligence r...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 9. Even highly capable large language models (LLMs) can produce biased or unsafe responses, and alignment techniques, such as RLHF, aimed at mitigating this issue, are expensive and prone to overfitting as they retrain the LLM. This paper introduces a novel inference-time alignment approach that ensure...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 10. We investigate the logical reasoning capabilities of large language models (LLMs) and their scalability in complex non-monotonic reasoning. To this end, we introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM reasoning performance on logic grid puzzles derived from constraint...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 11. The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, o3 outperformed humans in novel problem-solving and skill acquisition on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI)....
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 12. We present an approach to model-based RL that achieves a new state of the art performance on the challenging Craftax-classic benchmark, an open-world 2D survival game that requires agents to exhibit a wide range of general abilities -- such as strong generalization, deep exploration, and long-term r...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 13. Consistency models are a new family of generative models capable of producing high-quality samples in either a single step or multiple steps. Recently, consistency models have demonstrated impressive performance, achieving results on par with diffusion models in the pixel space. However, the success...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 14. We propose SCONE (Scalable, Contextualized, Offloaded, N-gram Embedding), a method for extending input embedding layers to enhance language model performance as layer size scales. To avoid increased decoding costs, SCONE retains the original vocabulary while introducing embeddings for a set of frequ...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 15. We present SliderSpace, a framework for automatically decomposing the visual capabilities of diffusion models into controllable and human-understandable directions. Unlike existing control methods that require a user to specify attributes for each edit direction individually, SliderSpace discovers m...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 16. Existing benchmarks for frontier models often test specialized, ``PhD-level'' knowledge that is difficult for non-experts to grasp. In contrast, we present a benchmark based on the NPR Sunday Puzzle Challenge that requires only general knowledge. Our benchmark is challenging for both humans and mode...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 17. Prior work in parameter-modifying knowledge editing has shown that large-scale sequential editing leads to significant model degradation. In this paper, we study the reasons behind this and scale sequential knowledge editing to 10,000 sequential edits, while maintaining the downstream performance of...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 18. Pathology Foundation Models (FMs) hold great promise for healthcare. Before they can be used in clinical practice, it is essential to ensure they are robust to variations between medical centers. We measure whether pathology FMs focus on biological features like tissue and cancer type, or on the wel...
[04.02.2025 14:09] ********************************************************************************
[04.02.2025 14:09] Abstract 19. The retroperitoneum hosts a variety of tumors, including rare benign and malignant types, which pose diagnostic and treatment challenges due to their infrequency and proximity to vital structures. Estimating tumor volume is difficult due to their irregular shapes, and manual segmentation is time-con...
[04.02.2025 14:09] Read previous papers.
[04.02.2025 14:09] Generating reviews via LLM API.
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#rlhf", "#training", "#alignment"], "emoji": "🎯", "ru": {"title": "Прямое выравнивание: простой путь к улучшению языковых моделей", "desc": "В статье рассматриваются алгоритмы прямого выравнивания (DAA) как альтернатива обучению с подкреплением в контексте выравнивания языковых моде
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#multimodal", "#architecture", "#video", "#training", "#diffusion"], "emoji": "🎭", "ru": {"title": "OmniHuman: универсальная модель для генерации реалистичных видео с людьми", "desc": "OmniHuman - это новая модель на основе Diffusion Transformer для генерации реалистичных видео с лю
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "PRIME: Эффективное обучение ИИ-моделей с неявными процессными наградами", "desc": "Эта статья представляет новый метод обучения с подкреплением для больших языковых моделей, называемый PRIME. Он исполь
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#training", "#dataset", "#leakage"], "emoji": "🕵️", "ru": {"title": "Осторожно: LLM-судьи могут быть предвзяты!", "desc": "Исследование выявляет проблему 'утечки предпочтений' при использовании больших языковых моделей (LLM) в качестве судей для оценки 
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#rag", "#security", "#dataset", "#benchmark"], "emoji": "🛡️", "ru": {"title": "SafeRAG: оценка уязвимостей генерации с дополнением на основе извлечения", "desc": "В статье представлен бенчмарк SafeRAG для оценки безопасности генерации с дополнением на основе извлечения (RAG). Авторы
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#long_context", "#training", "#inference", "#optimization"], "emoji": "🚀", "ru": {"title": "FastKV: Ускорение обработки длинных последовательностей в LLM", "desc": "Статья представляет FastKV - новый метод сжатия кэша ключ-значение (KV) для больших языковых моделей (LLM), направленн
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#low_resource", "#multimodal", "#multilingual"], "emoji": "🌍", "ru": {"title": "AIN: Прорыв в арабоязычном мультимодальном ИИ", "desc": "Представлена модель AIN - двуязычная мультимодальная языковая модель для арабского и английского языков. Модель обучена 
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#optimization", "#hallucinations", "#reasoning", "#rag", "#rl"], "emoji": "🧠", "ru": {"title": "DeepRAG: умное сочетание поиска и рассуждений для ИИ", "desc": "DeepRAG - это новый фреймворк, моделирующий рассуждения с поиском информации как марковский процесс принятия решений. Он ит
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#reasoning", "#multimodal"], "emoji": "🧠", "ru": {"title": "Мультимодальный ИИ проваливает тест на интеллект", "desc": "Статья представляет новый фреймворк MM-IQ для оценки когнитивных способностей мультимодальных систем искусственного интеллекта. Фрейм
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#ethics", "#rlhf", "#inference", "#alignment"], "emoji": "🛡️", "ru": {"title": "Безопасная генерация ответов LLM без переобучения", "desc": "Статья представляет новый подход к выравниванию больших языковых моделей (LLM) во время вывода, обеспечивающий генерацию безопасных ответов с 
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#reasoning", "#training", "#inference", "#benchmark"], "emoji": "🧩", "ru": {"title": "Проклятие сложности в логическом мышлении LLM", "desc": "В статье исследуются возможности логического рассуждения больших языковых моделей (LLM) и их масштабируемость в сложных задачах немонотонног
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#agi", "#open_source", "#training", "#reasoning"], "emoji": "🧠", "ru": {"title": "Эволюция рассуждений: от символов к мультимодальности", "desc": "Статья рассматривает эволюцию возможностей рассуждения в мультимодальных задачах у языковых моделей серий G
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#rl", "#architecture", "#benchmark", "#games", "#training", "#reasoning", "#optimization"], "emoji": "🚀", "ru": {"title": "Новый рубеж в model-based RL: превосходя человека в Craftax-classic", "desc": "Статья представляет новый подход к обучению с подкреплением на основе модели, дос
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#dataset", "#training", "#optimization", "#architecture", "#open_source", "#diffusion", "#video"], "emoji": "🧠", "ru": {"title": "Преодоление выбросов в латентном пространстве для улучшения консистентных моделей", "desc": "Эта статья представляет новый подход к обучению консистентны
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#architecture", "#inference", "#long_context", "#training", "#optimization"], "emoji": "🚀", "ru": {"title": "Ускорение языковых моделей без увеличения вычислительных затрат", "desc": "SCONE - это новый метод расширения слоёв входных эмбеддингов для улучшения производительности языко
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#dataset", "#open_source", "#multimodal", "#interpretability", "#cv"], "emoji": "🎚️", "ru": {"title": "SliderSpace: Раскрытие скрытых возможностей диффузионных моделей", "desc": "SliderSpace - это фреймворк для автоматической декомпозиции визуальных во
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#inference", "#benchmark"], "emoji": "🧩", "ru": {"title": "Новый бенчмарк раскрывает скрытые возможности и недостатки языковых моделей", "desc": "Авторы представляют новый бенчмарк для оценки языковых моделей, основанный на головоломках NPR Sunday Puzz
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#training", "#interpretability", "#architecture", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное масштабирование редактирования знаний в нейросетях", "desc": "Статья посвящена улучшению методов последовательного редактирования знаний в больших языковых моделях. Авторы 
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#healthcare", "#ethics", "#security", "#dataset"], "emoji": "🔬", "ru": {"title": "Путь к надежным фундаментальным моделям в патологии: преодоление влияния медицинских центров", "desc": "Статья рассматривает проблему надежности фундаментальных моделей (ФМ) в патологии для использован
[04.02.2025 14:09] Using data from previous issue: {"categories": ["#architecture", "#cv", "#training", "#dataset"], "emoji": "🧠", "ru": {"title": "Эффективная сегментация опухолей с помощью усовершенствованных нейросетей", "desc": "Статья посвящена автоматической сегментации опухолей забрюшинного пространства с использованием различных архитектур г
[04.02.2025 14:09] Loading Chinese text from previous data.
[04.02.2025 14:09] Renaming data file.
[04.02.2025 14:09] Renaming previous data. hf_papers.json to ./d/2025-02-04.json
[04.02.2025 14:09] Saving new data file.
[04.02.2025 14:09] Generating page.
[04.02.2025 14:09] Renaming previous page.
[04.02.2025 14:09] Renaming previous data. index.html to ./d/2025-02-04.html
[04.02.2025 14:09] [Experimental] Generating Chinese page for reading.
[04.02.2025 14:09] Chinese vocab [{'word': '直接对齐算法', 'pinyin': 'zhíjiē duìqí suànfǎ', 'trans': 'direct alignment algorithm'}, {'word': '策略', 'pinyin': 'cèlüè', 'trans': 'strategy'}, {'word': '优化', 'pinyin': 'yōuhuà', 'trans': 'optimize'}, {'word': '简化', 'pinyin': 'jiǎnhuà', 'trans': 'simplify'}, {'word': '语言模型', 'pinyin': 'yǔyán móxíng', 'trans': 'language model'}, {'word': '对齐', 'pinyin': 'duìqí', 'trans': 'align'}, {'word': '排名', 'pinyin': 'páimíng', 'trans': 'rank'}, {'word': '损失', 'pinyin': 'sǔnshī', 'trans': 'loss'}, {'word': '奖励', 'pinyin': 'jiǎnglì', 'trans': 'reward'}, {'word': '类型', 'pinyin': 'lèixíng', 'trans': 'type'}, {'word': '监督', 'pinyin': 'jiàndū', 'trans': 'supervise'}, {'word': '微调', 'pinyin': 'wēitiáo', 'trans': 'fine-tune'}, {'word': '阶段', 'pinyin': 'jiēduàn', 'trans': 'stage'}, {'word': '单阶段', 'pinyin': 'dān jiēduàn', 'trans': 'single-stage'}, {'word': '双阶段', 'pinyin': 'shuāng jiēduàn', 'trans': 'two-stage'}, {'word': '方法', 'pinyin': 'fāngfǎ', 'trans': 'method'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '显式', 'pinyin': 'xiǎnshì', 'trans': 'explicit'}, {'word': '参数', 'pinyin': 'cānshǔ', 'trans': 'parameter'}, {'word': '性能', 'pinyin': 'xíngnéng', 'trans': 'performance'}, {'word': '分析', 'pinyin': 'fēnxī', 'trans': 'analysis'}, {'word': '显示', 'pinyin': 'xiǎnshì', 'trans': 'show'}, {'word': '关键', 'pinyin': 'guǎnjiàn', 'trans': 'key'}, {'word': '因素', 'pinyin': 'yīnsù', 'trans': 'factor'}, {'word': '成对', 'pinyin': 'chéngduì', 'trans': 'pair'}, {'word': '目标', 'pinyin': 'mùbiāo', 'trans': 'target'}, {'word': '点', 'pinyin': 'diǎn', 'trans': 'point'}, {'word': '隐式', 'pinyin': 'yǐnshì', 'trans': 'implicit'}, {'word': '函数', 'pinyin': 'hánshù', 'trans': 'function'}, {'word': '结果', 'pinyin': 'jiéguǒ', 'trans': 'result'}, {'word': '强调', 'pinyin': 'qiángdiào', 'trans': 'emphasize'}, {'word': '仔细', 'pinyin': 'zǐxì', 'trans': 'careful'}, {'word': '评估', 'pinyin': 'pínggū', 'trans': 'evaluate'}, {'word': '重要性', 'pinyin': 'zhòngyàoxìng', 'trans': 'importance'}, {'word': '避免', 'pinyin': 'bìmiǎn', 'trans': 'avoid'}, {'word': '过早', 'pinyin': 'guòzǎo', 'trans': 'premature'}, {'word': '声称', 'pinyin': 'shēngchēng', 'trans': 'claim'}, {'word': '提升', 'pinyin': 'tíshēng', 'trans': 'improvement'}, {'word': '整体', 'pinyin': 'zhěngtǐ', 'trans': 'overall'}, {'word': '优越性', 'pinyin': 'yōuyuèxìng', 'trans': 'superiority'}]
[04.02.2025 14:09] Renaming previous Chinese page.
[04.02.2025 14:09] Renaming previous data. zh.html to ./d/2025-02-03_zh_reading_task.html
[04.02.2025 14:09] Writing Chinese reading task.
[04.02.2025 14:09] Writing result.
[04.02.2025 14:09] Renaming log file.
[04.02.2025 14:09] Renaming previous data. log.txt to ./logs/2025-02-04_last_log.txt
