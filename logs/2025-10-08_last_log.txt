[08.10.2025 17:13] Read previous papers.
[08.10.2025 17:13] Generating top page (month).
[08.10.2025 17:13] Writing top page (month).
[08.10.2025 18:19] Read previous papers.
[08.10.2025 18:19] Get feed.
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04871
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06217
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24107
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26328
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03270
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04162
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04081
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06052
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06062
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06208
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23379
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06182
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06131
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05485
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05592
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05560
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05432
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06036
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05367
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05342
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05251
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03506
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05318
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02300
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05137
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06219
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06218
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05571
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05156
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05122
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06030
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04506
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03978
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02341
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06213
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06139
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06107
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06071
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06056
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05681
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04087
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06101
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05934
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04514
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00880
[08.10.2025 18:19] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21499
[08.10.2025 18:19] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[08.10.2025 18:19] No deleted papers detected.
[08.10.2025 18:19] Downloading and parsing papers (pdf, html). Total: 46.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.04871.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.04871.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.04871.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06217.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06217.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06217.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2509.24107.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2509.24107.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2509.24107.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2509.26328.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2509.26328.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2509.26328.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.03270.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.03270.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.03270.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.04162.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.04162.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.04162.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.04081.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.04081.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.04081.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06052.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06052.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06052.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06062.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06062.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06062.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06208.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06208.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06208.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2509.23379.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2509.23379.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2509.23379.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06182.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06182.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06182.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06131.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06131.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06131.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05485.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05485.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05485.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05592.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05592.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05592.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05560.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05560.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05560.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05432.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05432.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05432.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06036.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06036.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06036.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05367.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05367.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05367.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05342.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05342.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05342.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05251.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05251.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05251.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.03506.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.03506.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.03506.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05318.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05318.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05318.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.02300.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.02300.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.02300.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05137.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05137.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05137.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06219.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06219.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06219.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06218.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06218.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06218.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05571.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05571.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05571.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05156.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05156.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05156.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05122.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05122.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05122.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06030.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06030.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06030.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.04506.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.04506.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.04506.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.03978.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.03978.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.03978.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.02341.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.02341.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.02341.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06213.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06213.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06213.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06139.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06139.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06139.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06107.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06107.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06107.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06071.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06071.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06071.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06056.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06056.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06056.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05681.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05681.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05681.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.04087.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.04087.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.04087.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.06101.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.06101.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.06101.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.05934.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.05934.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.05934.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.04514.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.04514.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.04514.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2510.00880.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2510.00880.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2510.00880.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Downloading and parsing paper https://huggingface.co/papers/2509.21499.
[08.10.2025 18:19] Extra JSON file exists (./assets/json/2509.21499.json), skip PDF parsing.
[08.10.2025 18:19] Paper image links file exists (./assets/img_data/2509.21499.json), skip HTML parsing.
[08.10.2025 18:19] Success.
[08.10.2025 18:19] Enriching papers with extra data.
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 0. Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.  					AI-generated summary 				 Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recur...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 1. TaTToo, a novel table-grounded Process Reward Model, enhances tabular reasoning by explicitly addressing table-specific operations and integrating tool-based verification, leading to significant performance improvements over existing PRMs.  					AI-generated summary 				 Process Reward Models (PRMs)...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 2. Fathom-DeepResearch, an agentic system with specialized models for web search and report synthesis, achieves state-of-the-art performance on open-ended information-seeking tasks and diverse reasoning tasks.  					AI-generated summary 				 Tool-integrated reasoning has emerged as a key focus for enab...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 3. Fast-dLLM v2, a block diffusion language model, efficiently converts pretrained autoregressive models for parallel text generation, achieving significant speedup without compromising accuracy.  					AI-generated summary 				 Autoregressive (AR) large language models (LLMs) have achieved remarkable p...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 4. CoDA, a 1.7B-parameter diffusion coder, achieves competitive performance with smaller models through confidence-guided sampling and is released with open-source tools.  					AI-generated summary 				 Diffusion language models promise bidirectional context and infilling capabilities that autoregressi...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 5. Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.  					AI-generated summary 				 Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 6. Caco, a code-assisted chain-of-thought framework, automates the generation of high-quality, verifiable, and diverse reasoning data, enhancing the performance of large language models on mathematical reasoning tasks.  					AI-generated summary 				 Reasoning capability is pivotal for Large Language M...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 7. MixReasoning dynamically adjusts reasoning depth in models to improve efficiency without sacrificing accuracy.  					AI-generated summary 				 Reasoning models enhance performance by tackling problems in a step-by-step manner, decomposing them into sub-problems and exploring long chains of thought b...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 8. ASPO addresses the imbalance in token weighting during OSRL by flipping Importance Sampling ratios and incorporating a soft dual-clipping mechanism, improving training stability and performance in LLMs.  					AI-generated summary 				 Recent Large Language Model (LLM) post-training methods rely on t...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 9. A video-to-4D shape generation framework uses temporal attention, time-aware point sampling, and noise sharing to produce dynamic 3D representations from videos, enhancing temporal stability and perceptual fidelity.  					AI-generated summary 				 Video-conditioned 4D shape generation aims to recove...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 10. Clinical Contrastive Cecoding (CCD) enhances radiology report generation by integrating structured clinical signals, reducing medical hallucinations without altering the base MLLM.  					AI-generated summary 				 Multimodal large language models (MLLMs) have recently achieved remarkable progress in ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 11. Language models use positional, lexical, and reflexive mechanisms to bind and retrieve entities, with a causal model achieving high accuracy in predicting next tokens across various tasks and input lengths.  					AI-generated summary 				 A key component of in-context reasoning is the ability of lan...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 12. MeDiM, a medical discrete diffusion model, integrates multimodal biomedical data by learning shared distributions across images, text, and clinical notes, achieving high-fidelity generation and enhanced downstream performance.  					AI-generated summary 				 Recent advances in generative medical mod...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 13. TensorBLEU is a GPU-accelerated BLEU metric implementation for efficient in-training evaluation of natural language processing models, offering significant speedups over CPU-based methods.  					AI-generated summary 				 Modern natural language processing models have achieved unprecedented scale, ye...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 14. AgentFlow, a trainable agentic framework with in-the-flow optimization, enhances reasoning in large language models by coordinating specialized modules and outperforms top baselines across various tasks.  					AI-generated summary 				 Outcome-driven reinforcement learning has advanced reasoning in ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 15. HoloScene is an interactive 3D reconstruction framework that achieves geometry completeness, object interactivity, physical plausibility, photorealistic rendering, and realistic physical properties through an energy-based optimization problem.  					AI-generated summary 				 Digitizing the physical ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 16. AInstein evaluates the problem-solving capabilities of large language models by testing their ability to generate valid solutions to AI research problems using only pretrained knowledge, revealing both their potential and limitations.  					AI-generated summary 				 Large language models (LLMs) demo...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 17. Research identifies a mechanism called the refusal cliff in large reasoning models, where refusal intentions drop sharply before output generation, and proposes a method to improve safety by focusing on specific attention heads and training examples.  					AI-generated summary 				 Large reasoning m...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 18. The paper proposes stage-specific strategies to accelerate diffusion model inference in video generation, reducing memory usage and maintaining quality.  					AI-generated summary 				 Training-free acceleration has emerged as an advanced research area in video generation based on diffusion models. ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 19. MADPO, a margin-adaptive method, enhances preference alignment in large language models by providing instance-level adaptive weighting to the DPO loss, improving performance across datasets.  					AI-generated summary 				 Direct Preference Optimization (DPO) has emerged as a simple and effective me...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 20. Exploratory Annealed Decoding (EAD) improves sample efficiency in reinforcement learning with verifiable rewards by dynamically adjusting the sampling temperature during generation.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) is a powerful paradigm for enhan...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 21. OneFlow, a non-autoregressive multimodal model, achieves superior performance in text-image generation and understanding tasks with reduced computational cost compared to autoregressive and diffusion-based models.  					AI-generated summary 				 We present OneFlow, the first non-autoregressive multi...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 22. BIRD-INTERACT is a benchmark for multi-turn text-to-SQL tasks that simulates realistic database assistant challenges through dynamic interactions, hierarchical knowledge bases, and autonomous decision-making.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable p...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 23. Equilibrium Matching (EqM) is a generative modeling framework that learns an equilibrium gradient of an implicit energy landscape, enabling efficient sampling and outperforming traditional diffusion and flow models.  					AI-generated summary 				 We introduce Equilibrium Matching (EqM), a generativ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 24. WebDetective is a benchmark for evaluating multi-hop reasoning in RAG systems and web agents, addressing issues of reasoning path leakage and single-pass evaluation, and introducing a framework to improve knowledge utilization and refusal behavior.  					AI-generated summary 				 RAG (Retrieval-Augm...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 25. Human3R is a unified, feed-forward framework for real-time 4D human-scene reconstruction from monocular videos, achieving state-of-the-art performance with a single model and minimal dependencies.  					AI-generated summary 				 We present Human3R, a unified, feed-forward framework for online 4D hum...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 26. EgoNight is a comprehensive benchmark for nighttime egocentric vision, focusing on visual question answering and revealing performance gaps between day and night conditions for multimodal large language models.  					AI-generated summary 				 Most existing benchmarks for egocentric vision understand...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 27. EvoPresent, a self-improvement agent framework using multi-task reinforcement learning, enhances academic paper promotion by generating coherent narratives, aesthetically pleasing designs, and realistic presentations, supported by a comprehensive benchmark.  					AI-generated summary 				 The promot...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 28. VeriGuard is a framework that ensures formal safety guarantees for LLM-based agents through offline validation and online monitoring.  					AI-generated summary 				 The deployment of autonomous AI agents in sensitive domains, such as healthcare, introduces critical risks to safety, security, and pr...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 29. CARE is a framework that enhances cognitive reasoning in emotional support conversations through reinforcement learning, improving response quality and empathy without relying on large-scale synthetic data.  					AI-generated summary 				 Emotional Support Conversation (ESC) plays a vital role in al...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 30. Geometry-aware optimal transport and active pruning enhance Gaussian process regression for efficient saddle point searches on high-dimensional energy surfaces.  					AI-generated summary 				 Gaussian process (GP) regression provides a strategy for accelerating saddle point searches on high-dimensi...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 31. GRACE uses contrastive policy optimization to train LLMs as generative agents that produce interpretable rationales, improving embeddings and transparency.  					AI-generated summary 				 Prevailing methods for training Large Language Models (LLMs) as text encoders rely on contrastive losses that tr...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 32. Extending the context length of text encoders in vision-language models improves performance on biomedical caption tasks by utilizing longer and more detailed descriptions.  					AI-generated summary 				 Embedding vision-language models (VLMs) are typically pretrained with short text windows (<77 t...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 33. DRIFT, a dissatisfaction-refined iterative preference training method, improves large language models using implicit user dissatisfaction signals, achieving better performance than existing methods on real-world datasets.  					AI-generated summary 				 Real-world large language model deployments (e...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 34. Quantization robustness in large language models is influenced by learning rate and other hyperparameters, not dataset scale, as demonstrated through controlled training experiments.  					AI-generated summary 				 While post-training quantization is widely adopted for efficient deployment of large ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 35. FlowRVS addresses the challenges of Referring Video Object Segmentation by reformulating the task as a continuous flow problem, leveraging pretrained T2V models and achieving state-of-the-art results.  					AI-generated summary 				 Referring Video Object Segmentation (RVOS) requires segmenting spec...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 36. A framework called Distributional Semantics Tracing identifies the layers and pathways in Transformers where hallucinations occur, revealing a correlation between internal semantic coherence and hallucination rates.  					AI-generated summary 				 Large Language Models (LLMs) are prone to hallucinat...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 37. A benchmark for scatterplot-specific tasks using synthetic datasets evaluates AI models' performance in counting clusters and identifying outliers, with mixed results for localization tasks.  					AI-generated summary 				 AI models are increasingly used for data analysis and visualization, yet benc...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 38. DeepEvolve integrates deep research with algorithm evolution to propose, refine, implement, and test new hypotheses, improving initial algorithms across various scientific domains.  					AI-generated summary 				 Large language models hold promise as scientific assistants, yet existing agents either...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 39. MG-Select, a novel test-time scaling framework for Vision-Language-Action models, improves performance by using KL divergence from a reference distribution generated with masked inputs, achieving significant gains in both in-distribution and out-of-distribution tasks.  					AI-generated summary 				...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 40. A new framework using an outside option in preference data collection and modeling improves reliability and efficiency in preference alignment techniques.  					AI-generated summary 				 Modern preference alignment techniques, such as Best-of-N (BoN) sampling, rely on reward models trained with pair...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 41. Research on distilling coding skills from large language models to smaller ones reveals a "valley of code reasoning" where performance initially decreases with more data before improving sharply, and that small models benefit more from easier questions during distillation.  					AI-generated summary...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 42. Embracing minority ratings, multiple annotators, and multi-emotion predictions in speech emotion recognition improves system robustness and alignment with human perception.  					AI-generated summary 				 Over the past two decades, speech emotion recognition (SER) has received growing attention. To ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 43. ChartAgent, a novel agentic framework, performs visual reasoning directly within charts, achieving state-of-the-art accuracy on ChartBench and ChartX benchmarks by iteratively decomposing queries and using specialized visual actions.  					AI-generated summary 				 Recent multimodal LLMs have shown ...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 44. HalluGuard, a 4B-parameter Small Reasoning Model, effectively mitigates hallucinations in Retrieval-Augmented Generation by classifying document-claim pairs and providing evidence-grounded justifications, achieving high balanced accuracy on the LLM-AggreFact benchmark.  					AI-generated summary 			...
[08.10.2025 18:19] ********************************************************************************
[08.10.2025 18:19] Abstract 45. Systematic investigation reveals that large language models are more sensitive to structural than semantic code perturbations, with implications for training data design.  					AI-generated summary 				 Code data has been shown to enhance the reasoning capabilities of large language models (LLMs), b...
[08.10.2025 18:19] Read previous papers.
[08.10.2025 18:19] Generating reviews via LLM API.
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#agi", "#training", "#reasoning", "#small_models"], "emoji": "ðŸ”„", "ru": {"title": "ÐœÐ°Ð»ÐµÐ½ÑŒÐºÐ°Ñ Ñ€ÐµÐºÑƒÑ€ÑÐ¸Ñ Ð¿Ð¾Ð±ÐµÐ¶Ð´Ð°ÐµÑ‚ Ð³Ð¸Ð³Ð°Ð½Ñ‚Ð¾Ð²: 7M Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² LLM", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Tiny Recursive Model (TRM) â€” Ð¼Ð¸Ð½Ð¸Ð°Ñ‚ÑŽÑ€Ð½ÑƒÑŽ Ñ€ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð²ÑÐµÐ³Ð¾ Ð¸Ð· 2 ÑÐ»Ð¾Ñ‘Ð² Ð¸ 7 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#training", "#data", "#benchmark", "#optimization", "#dataset"], "emoji": "ðŸ“Š", "ru": {"title": "TaTToo: Process Reward Model Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ð¼Ð¸", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ TaTToo â€” Ð½Ð¾Ð²ÑƒÑŽ Process Reward Model Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#agents", "#rl", "#dataset", "#optimization"], "emoji": "ðŸ”", "ru": {"title": "Ð“Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¹ Ð²ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²", "desc": "ÐŸÑ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð° ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Fathom-DeepResearch, ÑÐ¾ÑÑ‚Ð¾ÑÑ‰Ð°Ñ Ð¸Ð· Ð´Ð²ÑƒÑ… ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿Ð¾ 4 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#training", "#inference", "#open_source", "#diffusion", "#optimization", "#architecture"], "emoji": "âš¡", "ru": {"title": "Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Ð±Ð»Ð¾Ñ‡Ð½ÑƒÑŽ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸ÑŽ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Fast-dLLM v2 â€” Ð±Ð»Ð¾Ñ‡Ð½ÑƒÑŽ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½ÑƒÑŽ ÑÐ·Ñ‹ÐºÐ¾Ð²ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#inference", "#training", "#open_source", "#diffusion", "#small_models", "#dataset"], "emoji": "ðŸŒŠ", "ru": {"title": "Ð›ÐµÐ³ÐºÐ¾Ð²ÐµÑÐ½Ñ‹Ð¹ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð´ÐµÑ€ Ñ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÐµÐ¹", "desc": "CoDA â€” ÑÑ‚Ð¾ ÑÐ·Ñ‹ÐºÐ¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¸ Ñ 1.7 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð°Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð², ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð°Ñ Ð´
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#diffusion", "#audio", "#optimization"], "emoji": "ðŸŽ¤", "ru": {"title": "Drax: ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸ Ñ‡ÐµÑ€ÐµÐ· Ð´Ð¸ÑÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ flow matching", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Drax â€” Ð½Ð¾Ð²Ñ‹Ð¹ framework Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÑ‡Ð¸ (ASR) Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ discrete flow matching. Ð’Ð¼ÐµÑ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#math", "#data", "#training"], "emoji": "ðŸ”¢", "ru": {"title": "ÐšÐ¾Ð´ ÐºÐ°Ðº Ð¾ÑÐ½Ð¾Ð²Ð° Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹", "desc": "Caco â€” ÑÑ‚Ð¾ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐº
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#math", "#training"], "emoji": "ðŸŽšï¸", "ru": {"title": "ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð° Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹: Ð´ÑƒÐ¼Ð°Ð¹ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ð°Ð¼, Ð³Ð´Ðµ ÑÑ‚Ð¾ Ð½ÑƒÐ¶Ð½Ð¾", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ MixReasoning â€” Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð³Ð»ÑƒÐ±Ð¸Ð½Ñƒ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ðº
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#training", "#rl", "#optimization"], "emoji": "âš–ï¸", "ru": {"title": "ÐÑÐ¸Ð¼Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡Ð½Ð°Ñ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ LLM", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ð»Ð¸ Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð² Ð¼ÐµÑ‚Ð¾Ð´Ð°Ñ… Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð²Ð·Ð²ÐµÑˆÐ¸Ð²Ð°Ð½
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#video", "#3d"], "emoji": "ðŸŽ¬", "ru": {"title": "ÐžÑ‚ Ð²Ð¸Ð´ÐµÐ¾ Ðº Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ 3D-Ñ„Ð¾Ñ€Ð¼Ðµ: Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ 4D-Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹ Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒÑŽ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ 4D-Ñ„Ð¾Ñ€Ð¼ Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ 3D-Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ð¸Ð· Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð³Ð¾
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#healthcare", "#training", "#multimodal", "#hallucinations", "#data", "#science"], "emoji": "ðŸ©»", "ru": {"title": "Ð‘Ð¾Ñ€ÑŒÐ±Ð° Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ð¼Ð¸ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð² AI-Ñ€Ð°Ð´Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ð¸ Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ Clinical Contrastive Decoding (CCD) Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡Ñˆ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#long_context", "#data", "#multimodal", "#interpretability", "#architecture"], "emoji": "ðŸ”—", "ru": {"title": "Ð¢Ñ€Ð¸ Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð° ÑÐ²ÑÐ·Ñ‹Ð²Ð°Ð½Ð¸Ñ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð² ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÑÑ…", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚, ÐºÐ°Ðº ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ²ÑÐ·Ñ‹Ð²Ð°ÑŽÑ‚ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÑŽÑ‚ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚Ð¸ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ, Ð¸ÑÐ¿Ð¾Ð»
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#diffusion", "#science", "#healthcare", "#multimodal"], "emoji": "ðŸ¥", "ru": {"title": "Ð•Ð´Ð¸Ð½Ð°Ñ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð²ÑÐµÑ… Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÐµÐ¹", "desc": "MeDiM â€” ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ð°Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð¸ÑÐºÑ€ÐµÑ‚Ð½Ð¾Ð¹ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð±Ð¸Ð¾Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#training", "#open_source", "#optimization", "#benchmark"], "emoji": "âš¡", "ru": {"title": "ÐœÐ¾Ð»Ð½Ð¸ÐµÐ½Ð¾ÑÐ½Ð°Ñ BLEU Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° Ð½Ð° GPU Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "TensorBLEU â€” ÑÑ‚Ð¾ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ BLEU, Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð½Ð° GPU Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ NLP. ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#training", "#agents", "#rl", "#optimization", "#reasoning", "#architecture"], "emoji": "ðŸ”„", "ru": {"title": "ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼Ð°Ñ Ð°Ð³ÐµÐ½Ñ‚Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ", "desc": "AgentFlow â€” ÑÑ‚Ð¾ Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² LLM Ñ‡ÐµÑ€ÐµÐ· ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ð¸ÑŽ Ñ‡ÐµÑ‚Ñ‹
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#3d", "#optimization", "#games", "#benchmark"], "emoji": "ðŸ—ï¸", "ru": {"title": "Ð¦Ð¸Ñ„Ñ€Ð¾Ð²Ñ‹Ðµ Ð´Ð²Ð¾Ð¹Ð½Ð¸ÐºÐ¸ Ñ Ñ„Ð¸Ð·Ð¸ÐºÐ¾Ð¹ Ð¸ Ñ„Ð¾Ñ‚Ð¾Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¼Ð¾Ð¼", "desc": "HoloScene â€” ÑÑ‚Ð¾ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ 3D-Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¼Ð¸Ñ€Ð° Ð² Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÑÑ€ÐµÐ´Ñ‹, Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ðº ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ð¸. Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð³Ñ€Ð°Ñ„ ÑÑ†ÐµÐ½
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#science", "#reasoning", "#benchmark", "#rlhf", "#agents"], "emoji": "ðŸ§ª", "ru": {"title": "ÐœÐ¾Ð¶ÐµÑ‚ Ð»Ð¸ AI ÑÑ‚Ð°Ñ‚ÑŒ ÑÐ°Ð¼Ð¾ÑÑ‚Ð¾ÑÑ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼ Ð² Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸?", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ AInstein â€” Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (LLM) Ñ€ÐµÑˆÐ°Ñ‚ÑŒ Ð¸ÑÑ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#data", "#alignment", "#interpretability", "#training"], "emoji": "ðŸ§—", "ru": {"title": "ÐžÐ±Ñ€Ñ‹Ð² Ð¾Ñ‚ÐºÐ°Ð·Ð°: Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð²Ð½ÐµÐ·Ð°Ð¿Ð½Ð¾ ÑÑ‚Ð°Ð½Ð¾Ð²ÑÑ‚ÑÑ Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¼Ð¸", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ð»Ð¸ Ñ„ÐµÐ½Ð¾Ð¼ÐµÐ½ Â«Ð¾Ð±Ñ€Ñ‹Ð²Ð° Ð¾Ñ‚ÐºÐ°Ð·Ð°Â» Ð² Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… reasoning-Ð¼Ð¾Ð´ÐµÐ»ÑÑ…: Ð¼Ð¾Ð´ÐµÐ»Ð¸ 
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#diffusion", "#open_source", "#video", "#optimization", "#inference"], "emoji": "ðŸŽ¬", "ru": {"title": "Ð£ÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ‡ÐµÑ€ÐµÐ· ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚ÑŒÑŽ Ð½Ð° Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑÑ‚Ð°Ð´Ð¸ÑÑ…", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð±ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#optimization", "#alignment", "#training", "#rlhf"], "emoji": "âš–ï¸", "ru": {"title": "ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð²ÐµÑÐ° Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð° Ð´ÐµÐ»Ð°ÑŽÑ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸ÑÐ¼ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½ÐµÐµ", "desc": "MADPO â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð²Ñ‹Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿Ð¾ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸ÑÐ¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ DP
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#rl"], "emoji": "ðŸŒ¡ï¸", "ru": {"title": "Ð˜ÑÑÐ»ÐµÐ´ÑƒÐ¹ ÑÐ½Ð°Ñ‡Ð°Ð»Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¿Ð¾Ñ‚Ð¾Ð¼: Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ LLM", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ Exploratory Annealed Decoding (EAD) Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð² ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#training", "#optimization", "#games", "#architecture", "#diffusion", "#multimodal"], "emoji": "ðŸ”„", "ru": {"title": "ÐžÐ´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð±ÐµÐ· Ð°Ð²Ñ‚Ð¾Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¸", "desc": "OneFlow â€” ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ð°Ñ Ð½ÐµÐ°Ð²Ñ‚Ð¾Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¾Ð½Ð½Ð°Ñ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#agents", "#interpretability", "#benchmark", "#reasoning"], "emoji": "ðŸ—£ï¸", "ru": {"title": "Ð ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð¼Ð½Ð¾Ð³Ð¾Ñ…Ð¾Ð´Ð¾Ð²Ñ‹Ñ… SQL-Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² Ñ Ð±Ð°Ð·Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ BIRD-INTERACT â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ LLM Ð² Ð¼Ð½Ð¾Ð³Ð¾Ñ…Ð¾Ð´Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡Ð°Ñ… Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð²
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#inference", "#optimization", "#cv", "#diffusion", "#multimodal"], "emoji": "âš–ï¸", "ru": {"title": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· ÑÐ½ÐµÑ€Ð³ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð»Ð°Ð½Ð´ÑˆÐ°Ñ„Ñ‚ Ð²Ð¼ÐµÑÑ‚Ð¾ Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¸", "desc": "Equilibrium Matching (EqM) â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð¼Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÑŽ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ñ‚ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¾Ñ‚ Ð·Ð°Ð²Ð¸ÑÑÑ‰ÐµÐ¹ Ð¾Ñ‚ Ð²Ñ€Ðµ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#rag", "#benchmark", "#leakage", "#architecture", "#agents"], "emoji": "ðŸ”", "ru": {"title": "WebDetective: ÐšÐ°Ðº Ð½Ð°ÑƒÑ‡Ð¸Ñ‚ÑŒ AI-Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² Ð´ÑƒÐ¼Ð°Ñ‚ÑŒ ÑÐ°Ð¼Ð¾ÑÑ‚Ð¾ÑÑ‚ÐµÐ»ÑŒÐ½Ð¾, Ð° Ð½Ðµ ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ°Ð¼", "desc": "WebDetective â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¼Ð½Ð¾Ð³Ð¾ÑˆÐ°Ð³Ð¾Ð²Ñ‹Ñ… Ñ€Ð°ÑÑÑƒÐ¶
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#cv", "#video", "#3d"], "emoji": "ðŸŽ¥", "ru": {"title": "Ð ÐµÐ°Ð»ÑŒÐ½Ð°Ñ 4D Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ ÑÑ†ÐµÐ½ Ñ Ð»ÑŽÐ´ÑŒÐ¼Ð¸ Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾", "desc": "Human3R â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð´Ð»Ñ Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ 4D ÑÑ†ÐµÐ½ Ñ Ð»ÑŽÐ´ÑŒÐ¼Ð¸ Ð¸Ð· Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð²Ð¸Ð´ÐµÐ¾, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸. Ð’ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ñ‚ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð², Human3R Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ ÑÐ»
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#multimodal", "#long_context", "#benchmark", "#games", "#transfer_learning", "#synthetic", "#cv"], "emoji": "ðŸŒ™", "ru": {"title": "ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° AI-Ð·Ñ€ÐµÐ½Ð¸Ñ Ð² Ñ‚ÐµÐ¼Ð½Ð¾Ñ‚Ðµ Ð¾Ñ‚ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð»Ð¸Ñ†Ð°", "desc": "EgoNight â€” ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ egocentric-Ð²Ð¸Ð´ÐµÐ½Ð¸Ñ Ð² Ð½Ð¾Ñ‡Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ… Ñ Ñ„Ð¾ÐºÑƒ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#benchmark", "#story_generation", "#rl", "#multimodal", "#agents", "#optimization", "#games"], "emoji": "ðŸŽ¨", "ru": {"title": "Ð¡Ð°Ð¼Ð¾ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ÑÑ Ð°Ð³ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¹ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ñ… ÑÑ‚Ð°Ñ‚ÐµÐ¹", "desc": "EvoPresent â€” ÑÑ‚Ð¾ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð°Ð³ÐµÐ½Ñ‚Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ 
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#inference", "#alignment", "#agents", "#security", "#healthcare"], "emoji": "ðŸ›¡ï¸", "ru": {"title": "Ð¤Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¸ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ LLM-Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²", "desc": "VeriGuard â€” ÑÑ‚Ð¾ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð¾Ð±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ AI-Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ LLM Ð² ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¾Ð±Ð»Ð°ÑÑ‚ÑÑ… Ð²
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#reasoning"], "emoji": "ðŸ¤—", "ru": {"title": "Ð£ÑÐ¸Ð»ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð³Ð½Ð¸Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ CARE â€” Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²Ñ‹Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸. Ð’ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ñ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ„Ð¾ÐºÑƒÑÐ¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð½
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#optimization", "#data", "#science", "#training"], "emoji": "ðŸ”ï¸", "ru": {"title": "Ð£ÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð¸ÑÐºÐ° ÑÐµÐ´Ð»Ð¾Ð²Ñ‹Ñ… Ñ‚Ð¾Ñ‡ÐµÐº Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð³ÐµÐ¾Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾ÑÐ²ÐµÐ´Ð¾Ð¼Ð»Ñ‘Ð½Ð½Ð¾Ð¹ Ð³Ð°ÑƒÑÑÐ¾Ð²ÑÐºÐ¾Ð¹ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ð¸", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ð¾ÑÐ²ÑÑ‰ÐµÐ½Ð° ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸ÑŽ Ð¿Ð¾Ð¸ÑÐºÐ° ÑÐµÐ´Ð»Ð¾Ð²Ñ‹Ñ… Ñ‚Ð¾Ñ‡ÐµÐº Ð½Ð° Ð²Ñ‹ÑÐ¾ÐºÐ¾Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ñ‹Ñ… ÑÐ½ÐµÑ€Ð³ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ð¾Ð²ÐµÑ€Ñ…Ð½Ð¾ÑÑ‚ÑÑ… Ñ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#rl", "#interpretability", "#optimization", "#training", "#benchmark"], "emoji": "ðŸŽ­", "ru": {"title": "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ‡ÐµÑ€ÐµÐ· Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ð¹ Ñ ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚Ð½Ñ‹Ð¼ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ GRACE, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ð±ÑƒÑ‡Ð°ÐµÑ‚ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ñ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#data", "#benchmark", "#long_context", "#healthcare", "#dataset", "#multimodal"], "emoji": "ðŸ”¬", "ru": {"title": "Ð”Ð»Ð¸Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð±Ð¸Ð¾Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: Ð±Ð¾Ð»ÑŒÑˆÐµ ÑÐ»Ð¾Ð² â€” Ð»ÑƒÑ‡ÑˆÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ð»Ð¸, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ðµ vision-language Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¼ ÐºÐ¾Ð½Ñ‚
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#optimization", "#alignment", "#training", "#rlhf"], "emoji": "ðŸ”„", "ru": {"title": "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ LLM Ð½Ð° Ð½ÐµÐ´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹: Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð² Ð² ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾", "desc": "Ð’ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ Ð¼ÐµÑ‚Ð¾Ð´ DRIFT Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð½ÐµÐ´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#optimization", "#inference", "#training"], "emoji": "âš–ï¸", "ru": {"title": "Ð£ÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ÑÑ‚ÑŒ Ðº ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ Ð³Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð², Ð° Ð½Ðµ Ð¾Ñ‚ Ð¾Ð±ÑŠÑ‘Ð¼Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¸Ð·ÑƒÑ‡Ð¸Ð»Ð¸, ÐºÐ°Ðº post-training ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð² Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÑÑ… Ð´Ð¾ 32B Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð², Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð½
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#video", "#multimodal", "#benchmark", "#games", "#alignment"], "emoji": "ðŸŒŠ", "ru": {"title": "Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ñ‡ÐµÑ€ÐµÐ· Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½ÑƒÑŽ Ð´ÐµÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾Ð´ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚Ð°", "desc": "FlowRVS Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð² Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð¼Ñƒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ (RVOS), Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÑ ÐµÑ‘ ÐºÐ°Ðº Ð¿Ñ€Ð¾Ð±
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#hallucinations", "#inference", "#interpretability"], "emoji": "ðŸ”", "ru": {"title": "ÐšÐ°Ñ€Ñ‚Ð° Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: ÐºÐ°Ðº Ð¸ Ð³Ð´Ðµ LLM Ñ‚ÐµÑ€ÑÑŽÑ‚ ÑÐ²ÑÐ·ÑŒ Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ Distributional Semantics Tracing (DST), ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¾Ñ‚ÑÐ»Ðµ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#dataset", "#optimization"], "emoji": "ðŸ“Š", "ru": {"title": "LLM ÑƒÑ‡Ð°Ñ‚ÑÑ Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸, Ð½Ð¾ Ð½Ðµ Ð²ÑÐµÐ³Ð´Ð° Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÑŽÑ‚ Ð³Ð´Ðµ Ñ‡Ñ‚Ð¾ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ AI-Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ñ€Ð°ÑÑÐµÑÐ½Ð¸Ñ (scatterplots), Ð¸Ñ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#science", "#benchmark", "#agents", "#optimization", "#data", "#math"], "emoji": "ðŸ§¬", "ru": {"title": "Ð­Ð²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÑŽ", "desc": "DeepEvolve â€” ÑÑ‚Ð¾ AI-Ð°Ð³ÐµÐ½Ñ‚, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ ÑÐ²Ð¾Ð»ÑŽÑ†Ð¸ÐµÐ¹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² Ð´Ð»Ñ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ñ… Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#cv", "#training", "#robotics", "#agents", "#optimization"], "emoji": "ðŸŽ¯", "ru": {"title": "Ð£Ð¼Ð½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹ Ñ€Ð¾Ð±Ð¾Ñ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…", "desc": "Ð’ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ MG-Select â€” Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Vision-Language-Action Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð°Ð¼Ð¸ Ð½
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#inference", "#training", "#data", "#rlhf", "#alignment"], "emoji": "ðŸš¦", "ru": {"title": "ÐÐ°ÑƒÑ‡Ð¸Ñ‚ÑŒ AI Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾, Ð° Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‡Ñ‚Ð¾ Ð»ÑƒÑ‡ÑˆÐµ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÑŽÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ð¹, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ Â«Ð²Ð½ÐµÑˆÐ½ÑŽÑŽ Ð¾Ð¿Ñ†Ð¸ÑŽÂ» Ð² Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ð¹. Ð¢Ñ€Ð°Ð´Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ñ‹
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#transfer_learning", "#reasoning", "#small_models", "#training", "#optimization"], "emoji": "ðŸ”ï¸", "ru": {"title": "Ð”Ð¾Ð»Ð¸Ð½Ð° Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹: ÐºÐ°Ðº Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑƒÑ‡Ð°Ñ‚ÑÑ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ· Ð´Ð¸ÑÑ‚Ð¸Ð»Ð»ÑÑ†Ð¸ÑŽ", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¸Ð·ÑƒÑ‡Ð°Ð»Ð¸, ÐºÐ°Ðº Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‚ÑŒ Ð½Ð°Ð²Ñ‹ÐºÐ¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¾Ñ‚ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹Ðº
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#audio", "#alignment", "#interpretability"], "emoji": "ðŸŽ­", "ru": {"title": "Ð¡ÑƒÐ±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ ÑÐ¼Ð¾Ñ†Ð¸Ð¹ ÐºÐ°Ðº Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð¾: ÑƒÑ‡Ñ‘Ñ‚ Ð¼Ð½ÐµÐ½Ð¸Ñ Ð¼ÐµÐ½ÑŒÑˆÐ¸Ð½ÑÑ‚Ð²Ð° Ð² Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸ Ñ€ÐµÑ‡Ð¸", "desc": "Ð”Ð¸ÑÑÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð¿Ð¾ÑÐ²ÑÑ‰ÐµÐ½Ð° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸ÑŽ ÑÐ¼Ð¾Ñ†Ð¸Ð¹ Ð² Ñ€ÐµÑ‡Ð¸ (SER) Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð¾Ñ‚ÐºÐ°Ð·Ð°Ñ‚ÑŒÑÑ Ð¾Ñ‚ Ñ‚Ñ€Ð°Ð´Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð°, Ð³Ð´Ðµ Ñ€
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#multimodal", "#interpretability", "#benchmark", "#cv"], "emoji": "ðŸ“Š", "ru": {"title": "Ð’Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ‹Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹", "desc": "ChartAgent â€” ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð² Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð²Ñ‹Ð¿Ð¾Ð»Ð½
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#training", "#hallucinations", "#dataset", "#rag", "#small_models", "#synthetic", "#benchmark", "#optimization"], "emoji": "ðŸ›¡ï¸", "ru": {"title": "HalluGuard: Ð—Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹ Ð² Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°", "desc": "HalluGuard â€” ÑÑ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ 4 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð°Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ ÑƒÐ¼Ðµ
[08.10.2025 18:19] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#data", "#optimization", "#training", "#plp"], "emoji": "ðŸ—ï¸", "ru": {"title": "Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° ÐºÐ¾Ð´Ð° Ð²Ð°Ð¶Ð½ÐµÐµ ÑÐ¼Ñ‹ÑÐ»Ð° Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ LLM", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÐ»Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð³Ð¾, ÐºÐ°Ðº Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ²Ð¾Ð¹ÑÑ‚Ð²Ð° Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ð° Ð²Ð»Ð¸ÑÑŽÑ‚ Ð½Ð° ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ðº Ñ€Ð°ÑÑÑƒ
[08.10.2025 18:19] Renaming data file.
[08.10.2025 18:19] Renaming previous data. hf_papers.json to ./d/2025-10-08.json
[08.10.2025 18:19] Saving new data file.
[08.10.2025 18:19] Generating page.
[08.10.2025 18:19] Renaming previous page.
[08.10.2025 18:19] Renaming previous data. index.html to ./d/2025-10-08.html
[08.10.2025 18:19] Writing result.
[08.10.2025 18:19] Renaming log file.
[08.10.2025 18:19] Renaming previous data. log.txt to ./logs/2025-10-08_last_log.txt
