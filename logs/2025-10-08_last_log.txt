[08.10.2025 12:24] Read previous papers.
[08.10.2025 12:24] Generating top page (month).
[08.10.2025 12:24] Writing top page (month).
[08.10.2025 13:24] Read previous papers.
[08.10.2025 13:24] Get feed.
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06217
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2509.24107
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2509.26328
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03270
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04081
[08.10.2025 13:24] Extract page data from URL. URL: https://huggingface.co/papers/2510.04871
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06062
[08.10.2025 13:24] Extract page data from URL. URL: https://huggingface.co/papers/2510.04162
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05485
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06182
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05432
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2509.23379
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06131
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06036
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05560
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05342
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06052
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05367
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05137
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06218
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05318
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05156
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05122
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06219
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06208
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03978
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02300
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06213
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06139
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06107
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.06071
[08.10.2025 13:24] Extract page data from URL. URL: https://huggingface.co/papers/2510.05681
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05592
[08.10.2025 13:24] Extract page data from URL. URL: https://huggingface.co/papers/2510.05571
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.04087
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.02341
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.05934
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.03506
[08.10.2025 13:24] Get page data from previous paper. URL: https://huggingface.co/papers/2510.00880
[08.10.2025 13:24] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[08.10.2025 13:24] No deleted papers detected.
[08.10.2025 13:24] Downloading and parsing papers (pdf, html). Total: 39.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06217.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06217.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06217.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2509.24107.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2509.24107.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2509.24107.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2509.26328.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2509.26328.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2509.26328.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.03270.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.03270.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.03270.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.04081.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.04081.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.04081.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.04871.
[08.10.2025 13:24] Downloading paper 2510.04871 from http://arxiv.org/pdf/2510.04871v1...
[08.10.2025 13:24] Extracting affiliations from text.
[08.10.2025 13:24] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Less is More: Recursive Reasoning with Tiny Networks Alexia Jolicoeur-Martineau Samsung SAIL Montreal alexia.j@samsung.com 5 2 0 2 6 ] . [ 1 1 7 8 4 0 . 0 1 5 2 : r a "
[08.10.2025 13:24] Response: ```python
["Samsung SAIL Montreal"]
```
[08.10.2025 13:24] Deleting PDF ./assets/pdf/2510.04871.pdf.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06062.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06062.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06062.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.04162.
[08.10.2025 13:24] Downloading paper 2510.04162 from http://arxiv.org/pdf/2510.04162v1...
[08.10.2025 13:24] Extracting affiliations from text.
[08.10.2025 13:24] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 ] . e [ 1 2 6 1 4 0 . 0 1 5 2 : r Drax: Speech Recognition with Discrete Flow Matching Aviv Navon, Aviv Shamsian, Neta Glazer, Yael Segal-Feldman, Gill Hetz, Joseph Keshet, Ethan Fetaya aiOla Research Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as promising direction for advancing NAR ASR. Automatic speech recognition (ASR) has become core component of modern machine learning systems, enabling speech-based interfaces, multilingual communication, and accessibility applications. Recent progress has been driven by large-scale autoregressive (AR) encoder-decoder models such as Whisper (Radford et al., 2023) and Qwen2-Audio (Chu et al., 2024), which achieve remarkable accuracy across languages and domains. However, the sequential nature of AR decoding creates an inherent efficiency bottleneck: tokens must be generated one by one, resulting in inference latency that scales with sequence length and limits the deployment of low-latency or large-scale applications (Gu et al., 2018; Chen et al., 2023; Fu et al., 2024). Non-autoregressive (NAR) generative models based on diffus"
[08.10.2025 13:24] Response: ```python
["aiOla Research"]
```
[08.10.2025 13:24] Deleting PDF ./assets/pdf/2510.04162.pdf.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05485.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05485.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05485.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06182.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06182.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06182.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05432.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05432.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05432.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2509.23379.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2509.23379.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2509.23379.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06131.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06131.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06131.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06036.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06036.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06036.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05560.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05560.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05560.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05342.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05342.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05342.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06052.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06052.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06052.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05367.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05367.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05367.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05137.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05137.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05137.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06218.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06218.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06218.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05318.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05318.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05318.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05156.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05156.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05156.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05122.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05122.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05122.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06219.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06219.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06219.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06208.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06208.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06208.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.03978.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.03978.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.03978.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.02300.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.02300.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.02300.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06213.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06213.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06213.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06139.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06139.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06139.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06107.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06107.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06107.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.06071.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.06071.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.06071.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05681.
[08.10.2025 13:24] Downloading paper 2510.05681 from http://arxiv.org/pdf/2510.05681v1...
[08.10.2025 13:24] Extracting affiliations from text.
[08.10.2025 13:24] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"VERIFIER-FREE TEST-TIME SAMPLING FOR VISION LANGUAGE ACTION MODELS Suhyeok Jang1 Dongyoung Kim1,3 Changyeon Kim1 Youngsuk Kim2 1KAIST 2Seoul National University 3RLWRLD Jinwoo Shin1,3 5 2 0 O 7 ] . [ 1 1 8 6 5 0 . 0 1 5 2 : r a "
[08.10.2025 13:24] Response: ```python
["KAIST", "Seoul National University", "RLWRLD"]
```
[08.10.2025 13:24] Deleting PDF ./assets/pdf/2510.05681.pdf.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05592.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05592.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05592.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05571.
[08.10.2025 13:24] Downloading paper 2510.05571 from http://arxiv.org/pdf/2510.05571v1...
[08.10.2025 13:24] Extracting affiliations from text.
[08.10.2025 13:24] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Preprint Presenting Paper is an Art: SELF-IMPROVEMENT AESTHETIC AGENTS FOR ACADEMIC PRESENTATIONS Chengzhi Liu1, Yuzhe Yang1, Kaiwen Zhou2, Zhen Zhang1, Yue Fan2, Yanan Xie3, Peng Qi3, Xin Eric Wang1 1University of California, Santa Barbara {chengzhi,yuzheyang,ericxwang}@ucsb.edu 2University of California, Santa Cruz 3Uniphore 5 2 0 O 7 ] . [ 1 1 7 5 5 0 . 0 1 5 2 : r Project Page: https://evopresent.github.io/ "
[08.10.2025 13:24] Response: ```python
["University of California, Santa Barbara", "University of California, Santa Cruz", "Uniphore"]
```
[08.10.2025 13:24] Deleting PDF ./assets/pdf/2510.05571.pdf.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.04087.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.04087.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.04087.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.02341.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.02341.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.02341.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.05934.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.05934.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.05934.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.03506.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.03506.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.03506.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Downloading and parsing paper https://huggingface.co/papers/2510.00880.
[08.10.2025 13:24] Extra JSON file exists (./assets/json/2510.00880.json), skip PDF parsing.
[08.10.2025 13:24] Paper image links file exists (./assets/img_data/2510.00880.json), skip HTML parsing.
[08.10.2025 13:24] Success.
[08.10.2025 13:24] Enriching papers with extra data.
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 0. TaTToo, a novel table-grounded Process Reward Model, enhances tabular reasoning by explicitly addressing table-specific operations and integrating tool-based verification, leading to significant performance improvements over existing PRMs.  					AI-generated summary 				 Process Reward Models (PRMs)...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 1. Fathom-DeepResearch, an agentic system with specialized models for web search and report synthesis, achieves state-of-the-art performance on open-ended information-seeking tasks and diverse reasoning tasks.  					AI-generated summary 				 Tool-integrated reasoning has emerged as a key focus for enab...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 2. Fast-dLLM v2, a block diffusion language model, efficiently converts pretrained autoregressive models for parallel text generation, achieving significant speedup without compromising accuracy.  					AI-generated summary 				 Autoregressive (AR) large language models (LLMs) have achieved remarkable p...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 3. CoDA, a 1.7B-parameter diffusion coder, achieves competitive performance with smaller models through confidence-guided sampling and is released with open-source tools.  					AI-generated summary 				 Diffusion language models promise bidirectional context and infilling capabilities that autoregressi...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 4. Caco, a code-assisted chain-of-thought framework, automates the generation of high-quality, verifiable, and diverse reasoning data, enhancing the performance of large language models on mathematical reasoning tasks.  					AI-generated summary 				 Reasoning capability is pivotal for Large Language M...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 5. Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.  					AI-generated summary 				 Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recur...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 6. ASPO addresses the imbalance in token weighting during OSRL by flipping Importance Sampling ratios and incorporating a soft dual-clipping mechanism, improving training stability and performance in LLMs.  					AI-generated summary 				 Recent Large Language Model (LLM) post-training methods rely on t...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 7. Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.  					AI-generated summary 				 Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 8. TensorBLEU is a GPU-accelerated BLEU metric implementation for efficient in-training evaluation of natural language processing models, offering significant speedups over CPU-based methods.  					AI-generated summary 				 Modern natural language processing models have achieved unprecedented scale, ye...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 9. Language models use positional, lexical, and reflexive mechanisms to bind and retrieve entities, with a causal model achieving high accuracy in predicting next tokens across various tasks and input lengths.  					AI-generated summary 				 A key component of in-context reasoning is the ability of lan...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 10. AInstein evaluates the problem-solving capabilities of large language models by testing their ability to generate valid solutions to AI research problems using only pretrained knowledge, revealing both their potential and limitations.  					AI-generated summary 				 Large language models (LLMs) demo...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 11. Clinical Contrastive Cecoding (CCD) enhances radiology report generation by integrating structured clinical signals, reducing medical hallucinations without altering the base MLLM.  					AI-generated summary 				 Multimodal large language models (MLLMs) have recently achieved remarkable progress in ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 12. MeDiM, a medical discrete diffusion model, integrates multimodal biomedical data by learning shared distributions across images, text, and clinical notes, achieving high-fidelity generation and enhanced downstream performance.  					AI-generated summary 				 Recent advances in generative medical mod...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 13. Research identifies a mechanism called the refusal cliff in large reasoning models, where refusal intentions drop sharply before output generation, and proposes a method to improve safety by focusing on specific attention heads and training examples.  					AI-generated summary 				 Large reasoning m...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 14. HoloScene is an interactive 3D reconstruction framework that achieves geometry completeness, object interactivity, physical plausibility, photorealistic rendering, and realistic physical properties through an energy-based optimization problem.  					AI-generated summary 				 Digitizing the physical ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 15. MADPO, a margin-adaptive method, enhances preference alignment in large language models by providing instance-level adaptive weighting to the DPO loss, improving performance across datasets.  					AI-generated summary 				 Direct Preference Optimization (DPO) has emerged as a simple and effective me...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 16. MixReasoning dynamically adjusts reasoning depth in models to improve efficiency without sacrificing accuracy.  					AI-generated summary 				 Reasoning models enhance performance by tackling problems in a step-by-step manner, decomposing them into sub-problems and exploring long chains of thought b...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 17. The paper proposes stage-specific strategies to accelerate diffusion model inference in video generation, reducing memory usage and maintaining quality.  					AI-generated summary 				 Training-free acceleration has emerged as an advanced research area in video generation based on diffusion models. ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 18. WebDetective is a benchmark for evaluating multi-hop reasoning in RAG systems and web agents, addressing issues of reasoning path leakage and single-pass evaluation, and introducing a framework to improve knowledge utilization and refusal behavior.  					AI-generated summary 				 RAG (Retrieval-Augm...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 19. EgoNight is a comprehensive benchmark for nighttime egocentric vision, focusing on visual question answering and revealing performance gaps between day and night conditions for multimodal large language models.  					AI-generated summary 				 Most existing benchmarks for egocentric vision understand...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 20. BIRD-INTERACT is a benchmark for multi-turn text-to-SQL tasks that simulates realistic database assistant challenges through dynamic interactions, hierarchical knowledge bases, and autonomous decision-making.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable p...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 21. VeriGuard is a framework that ensures formal safety guarantees for LLM-based agents through offline validation and online monitoring.  					AI-generated summary 				 The deployment of autonomous AI agents in sensitive domains, such as healthcare, introduces critical risks to safety, security, and pr...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 22. CARE is a framework that enhances cognitive reasoning in emotional support conversations through reinforcement learning, improving response quality and empathy without relying on large-scale synthetic data.  					AI-generated summary 				 Emotional Support Conversation (ESC) plays a vital role in al...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 23. Human3R is a unified, feed-forward framework for real-time 4D human-scene reconstruction from monocular videos, achieving state-of-the-art performance with a single model and minimal dependencies.  					AI-generated summary 				 We present Human3R, a unified, feed-forward framework for online 4D hum...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 24. A video-to-4D shape generation framework uses temporal attention, time-aware point sampling, and noise sharing to produce dynamic 3D representations from videos, enhancing temporal stability and perceptual fidelity.  					AI-generated summary 				 Video-conditioned 4D shape generation aims to recove...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 25. Extending the context length of text encoders in vision-language models improves performance on biomedical caption tasks by utilizing longer and more detailed descriptions.  					AI-generated summary 				 Embedding vision-language models (VLMs) are typically pretrained with short text windows (<77 t...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 26. Equilibrium Matching (EqM) is a generative modeling framework that learns an equilibrium gradient of an implicit energy landscape, enabling efficient sampling and outperforming traditional diffusion and flow models.  					AI-generated summary 				 We introduce Equilibrium Matching (EqM), a generativ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 27. Quantization robustness in large language models is influenced by learning rate and other hyperparameters, not dataset scale, as demonstrated through controlled training experiments.  					AI-generated summary 				 While post-training quantization is widely adopted for efficient deployment of large ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 28. FlowRVS addresses the challenges of Referring Video Object Segmentation by reformulating the task as a continuous flow problem, leveraging pretrained T2V models and achieving state-of-the-art results.  					AI-generated summary 				 Referring Video Object Segmentation (RVOS) requires segmenting spec...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 29. A framework called Distributional Semantics Tracing identifies the layers and pathways in Transformers where hallucinations occur, revealing a correlation between internal semantic coherence and hallucination rates.  					AI-generated summary 				 Large Language Models (LLMs) are prone to hallucinat...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 30. A benchmark for scatterplot-specific tasks using synthetic datasets evaluates AI models' performance in counting clusters and identifying outliers, with mixed results for localization tasks.  					AI-generated summary 				 AI models are increasingly used for data analysis and visualization, yet benc...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 31. MG-Select, a novel test-time scaling framework for Vision-Language-Action models, improves performance by using KL divergence from a reference distribution generated with masked inputs, achieving significant gains in both in-distribution and out-of-distribution tasks.  					AI-generated summary 				...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 32. AgentFlow, a trainable agentic framework with in-the-flow optimization, enhances reasoning in large language models by coordinating specialized modules and outperforms top baselines across various tasks.  					AI-generated summary 				 Outcome-driven reinforcement learning has advanced reasoning in ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 33. EvoPresent, a self-improvement agent framework using multi-task reinforcement learning, enhances academic paper promotion by generating coherent narratives, aesthetically pleasing designs, and realistic presentations, supported by a comprehensive benchmark.  					AI-generated summary 				 The promot...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 34. A new framework using an outside option in preference data collection and modeling improves reliability and efficiency in preference alignment techniques.  					AI-generated summary 				 Modern preference alignment techniques, such as Best-of-N (BoN) sampling, rely on reward models trained with pair...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 35. DRIFT, a dissatisfaction-refined iterative preference training method, improves large language models using implicit user dissatisfaction signals, achieving better performance than existing methods on real-world datasets.  					AI-generated summary 				 Real-world large language model deployments (e...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 36. Embracing minority ratings, multiple annotators, and multi-emotion predictions in speech emotion recognition improves system robustness and alignment with human perception.  					AI-generated summary 				 Over the past two decades, speech emotion recognition (SER) has received growing attention. To ...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 37. OneFlow, a non-autoregressive multimodal model, achieves superior performance in text-image generation and understanding tasks with reduced computational cost compared to autoregressive and diffusion-based models.  					AI-generated summary 				 We present OneFlow, the first non-autoregressive multi...
[08.10.2025 13:24] ********************************************************************************
[08.10.2025 13:24] Abstract 38. HalluGuard, a 4B-parameter Small Reasoning Model, effectively mitigates hallucinations in Retrieval-Augmented Generation by classifying document-claim pairs and providing evidence-grounded justifications, achieving high balanced accuracy on the LLM-AggreFact benchmark.  					AI-generated summary 			...
[08.10.2025 13:24] Read previous papers.
[08.10.2025 13:24] Generating reviews via LLM API.
[08.10.2025 13:24] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#training", "#data", "#benchmark", "#optimization", "#dataset"], "emoji": "📊", "ru": {"title": "TaTToo: Process Reward Model с инструментами для работы с таблицами", "desc": "Исследователи представили TaTToo — новую Process Reward Model для улучшения рассуждений
[08.10.2025 13:24] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#agents", "#rl", "#dataset", "#optimization"], "emoji": "🔍", "ru": {"title": "Глубокий веб-поиск с помощью специализированных агентов", "desc": "Представлена система Fathom-DeepResearch, состоящая из двух специализированных моделей по 4 миллиарда параметр
[08.10.2025 13:24] Using data from previous issue: {"categories": ["#training", "#inference", "#open_source", "#diffusion", "#optimization", "#architecture"], "emoji": "⚡", "ru": {"title": "Быстрая параллельная генерация текста через блочную диффузию", "desc": "Статья представляет Fast-dLLM v2 — блочную диффузионную языковую модель, которая эффектив
[08.10.2025 13:24] Using data from previous issue: {"categories": ["#inference", "#training", "#open_source", "#diffusion", "#small_models", "#dataset"], "emoji": "🌊", "ru": {"title": "Легковесный диффузионный кодер с направленной генерацией", "desc": "CoDA — это языковая модель на основе диффузии с 1.7 миллиардами параметров, специально обученная д
[08.10.2025 13:24] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#benchmark", "#math", "#data", "#training"], "emoji": "🔢", "ru": {"title": "Код как основа для автоматической генерации качественных рассуждений", "desc": "Caco — это фреймворк для автоматической генерации высококачественных данных для обучения математическ
[08.10.2025 13:24] Querying the API.
[08.10.2025 13:24] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.  					AI-generated summary 				 Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters.
[08.10.2025 13:25] Response: ```json
{
  "desc": "Исследователи представили Tiny Recursive Model (TRM) — миниатюрную рекурсивную модель всего из 2 слоёв и 7 миллионов параметров, которая решает сложные логические задачи лучше больших языковых моделей. TRM показывает 45% точности на ARC-AGI-1 и 8% на ARC-AGI-2, превосходя большинство LLM при использовании менее 0.01% их параметров. Модель обучается на малых данных (около 1000 примеров) и успешно справляется с задачами типа судоку, лабиринтов и ARC-AGI. Этот подход, вдохновлённый биологическими принципами, демонстрирует, что для сложного рассуждения не всегда нужны огромные AI-модели.",
  "emoji": "🔄",
  "title": "Маленькая рекурсия побеждает гигантов: 7M параметров против LLM"
}
```
[08.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.  					AI-generated summary 				 Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters."

[08.10.2025 13:25] Response: ```python
['SMALL_MODELS', 'TRAINING']
```
[08.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.  					AI-generated summary 				 Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters."

[08.10.2025 13:25] Response: ```python
["REASONING", "AGI"]
```
[08.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Tiny Recursive Model (TRM) is a compact neural network architecture designed to solve complex puzzle tasks with high generalization. It utilizes a simple two-layer structure with only 7 million parameters, significantly fewer than larger language models. TRM outperforms existing models on challenging tasks like ARC-AGI, demonstrating that smaller networks can achieve competitive accuracy. This approach highlights the potential of minimalistic designs in machine learning for effective problem-solving.","title":"Small Network, Big Solutions: TRM\'s Power in Puzzle Solving"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Tiny Recursive Model (TRM) is a compact neural network architecture designed to solve complex puzzle tasks with high generalization. It utilizes a simple two-layer structure with only 7 million parameters, significantly fewer than larger language models. TRM outperforms existing models on challenging tasks like ARC-AGI, demonstrating that smaller networks can achieve competitive accuracy. This approach highlights the potential of minimalistic designs in machine learning for effective problem-solving.', title="Small Network, Big Solutions: TRM's Power in Puzzle Solving"))
[08.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Tiny Recursive Model (TRM) 是一种新颖的递归推理模型，使用一个只有两层的小型神经网络，参数仅为700万。它在复杂的拼图任务上表现出色，超越了许多大型语言模型。TRM 的设计灵感来源于生物学，能够在小数据集上实现高泛化能力。尽管 TRM 结构简单，但在解决困难问题时展现了巨大的潜力。","title":"小型递归模型，超越大型语言模型的解决方案"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Tiny Recursive Model (TRM) 是一种新颖的递归推理模型，使用一个只有两层的小型神经网络，参数仅为700万。它在复杂的拼图任务上表现出色，超越了许多大型语言模型。TRM 的设计灵感来源于生物学，能够在小数据集上实现高泛化能力。尽管 TRM 结构简单，但在解决困难问题时展现了巨大的潜力。', title='小型递归模型，超越大型语言模型的解决方案'))
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#rl", "#optimization"], "emoji": "⚖️", "ru": {"title": "Асимметричная важность токенов для стабильного обучения LLM", "desc": "Исследователи обнаружили фундаментальную проблему в методах обучения с подкреплением для больших языковых моделей: несбалансированное взвешиван
[08.10.2025 13:25] Querying the API.
[08.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.  					AI-generated summary 				 Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, a discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as a promising direction for advancing NAR ASR.
[08.10.2025 13:25] Response: ```json
{
  "title": "Drax: эффективное распознавание речи через дискретное flow matching",
  "desc": "Исследователи представили Drax — новый framework для автоматического распознавания речи (ASR) на основе discrete flow matching. Вместо традиционного авторегрессионного подхода используется параллельное декодирование с вероятностным путём, обусловленным аудио. Ключевая идея — обучать модель на траекториях, похожих на ошибки инференса, а не на случайном шуме, что уменьшает разрыв между обучением и применением. Результаты показывают точность на уровне state-of-the-art моделей при улучшенном балансе между качеством и скоростью работы.",
  "emoji": "🎤"
}
```
[08.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.  					AI-generated summary 				 Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, a discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as a promising direction for advancing NAR ASR."

[08.10.2025 13:25] Response: ```python
['AUDIO']
```
[08.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.  					AI-generated summary 				 Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, a discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as a promising direction for advancing NAR ASR."

[08.10.2025 13:25] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[08.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Drax is a new framework designed for automatic speech recognition (ASR) that uses discrete flow matching to enhance recognition accuracy and efficiency. It introduces an audio-conditioned probability path that helps the model navigate through common inference errors, improving the decoding process. The framework addresses the gap between training and inference by managing cumulative velocity errors, which helps in better generalization. Empirical results show that Drax achieves competitive accuracy compared to leading speech models while also being more efficient, suggesting a valuable advancement in non-autoregressive ASR techniques.","title":"Drax: Efficient and Accurate ASR with Discrete Flow Matching"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Drax is a new framework designed for automatic speech recognition (ASR) that uses discrete flow matching to enhance recognition accuracy and efficiency. It introduces an audio-conditioned probability path that helps the model navigate through common inference errors, improving the decoding process. The framework addresses the gap between training and inference by managing cumulative velocity errors, which helps in better generalization. Empirical results show that Drax achieves competitive accuracy compared to leading speech models while also being more efficient, suggesting a valuable advancement in non-autoregressive ASR techniques.', title='Drax: Efficient and Accurate ASR with Discrete Flow Matching'))
[08.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Drax是一种用于自动语音识别（ASR）的离散流匹配框架，通过构建音频条件概率路径，实现了更高的识别准确率和效率。该框架支持高效的并行解码，能够更好地将训练与推理对齐。我们通过理论分析将泛化误差与训练和推理的占用差异联系起来，从而推动了设计选择。实证评估表明，Drax在识别准确性上与最先进的语音模型相当，同时在准确性和效率之间提供了更好的权衡。","title":"Drax：提升ASR效率与准确性的离散流匹配框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Drax是一种用于自动语音识别（ASR）的离散流匹配框架，通过构建音频条件概率路径，实现了更高的识别准确率和效率。该框架支持高效的并行解码，能够更好地将训练与推理对齐。我们通过理论分析将泛化误差与训练和推理的占用差异联系起来，从而推动了设计选择。实证评估表明，Drax在识别准确性上与最先进的语音模型相当，同时在准确性和效率之间提供了更好的权衡。', title='Drax：提升ASR效率与准确性的离散流匹配框架'))
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#open_source", "#optimization", "#benchmark"], "emoji": "⚡", "ru": {"title": "Молниеносная BLEU метрика на GPU для обучения моделей", "desc": "TensorBLEU — это реализация метрики BLEU, оптимизированная специально для работы на GPU во время обучения моделей NLP. Основная
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#reasoning", "#long_context", "#data", "#multimodal", "#interpretability", "#architecture"], "emoji": "🔗", "ru": {"title": "Три механизма связывания сущностей в языковых моделях", "desc": "Исследование показывает, как языковые модели связывают и извлекают сущности в контексте, испол
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#science", "#reasoning", "#benchmark", "#rlhf", "#agents"], "emoji": "🧪", "ru": {"title": "Может ли AI стать самостоятельным исследователем в машинном обучении?", "desc": "Исследование представляет AInstein — фреймворк для оценки способности больших языковых моделей (LLM) решать исс
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#healthcare", "#training", "#multimodal", "#hallucinations", "#data", "#science"], "emoji": "🩻", "ru": {"title": "Борьба с медицинскими галлюцинациями в AI-радиологии через контрастивное декодирование", "desc": "Статья представляет метод Clinical Contrastive Decoding (CCD) для улучш
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#diffusion", "#science", "#healthcare", "#multimodal"], "emoji": "🏥", "ru": {"title": "Единая диффузионная модель для всех медицинских модальностей", "desc": "MeDiM — это первая медицинская модель дискретной диффузии, которая объединяет разные типы биомедицинских данных (изображения
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#data", "#alignment", "#interpretability", "#training"], "emoji": "🧗", "ru": {"title": "Обрыв отказа: почему безопасные модели внезапно становятся опасными", "desc": "Исследователи обнаружили феномен «обрыва отказа» в больших reasoning-моделях: модели 
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#3d", "#optimization", "#games", "#benchmark"], "emoji": "🏗️", "ru": {"title": "Цифровые двойники с физикой и фотореализмом", "desc": "HoloScene — это фреймворк для интерактивной 3D-реконструкции физического мира в виртуальные среды, готовые к симуляции. Система использует граф сцен
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#optimization", "#alignment", "#training", "#rlhf"], "emoji": "⚖️", "ru": {"title": "Адаптивные веса для каждого примера делают обучение по предпочтениям эффективнее", "desc": "MADPO — это новый метод выравнивания больших языковых моделей по предпочтениям, который решает проблему DP
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#reasoning", "#math", "#training"], "emoji": "🎚️", "ru": {"title": "Адаптивная глубина рассуждений: думай глубоко только там, где это нужно", "desc": "Статья представляет MixReasoning — фреймворк, который динамически адаптирует глубину рассуждений модели в зависимости от сложности к
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#diffusion", "#open_source", "#video", "#optimization", "#inference"], "emoji": "🎬", "ru": {"title": "Ускорение видеогенерации через управление памятью на разных стадиях", "desc": "Исследователи предложили метод ускорения генерации видео с помощью диффузионных моделей без дополнител
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#rag", "#benchmark", "#leakage", "#architecture", "#agents"], "emoji": "🔍", "ru": {"title": "WebDetective: Как научить AI-агентов думать самостоятельно, а не следовать подсказкам", "desc": "WebDetective — это новый бенчмарк для оценки многошаговых рассуж
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#multimodal", "#long_context", "#benchmark", "#games", "#transfer_learning", "#synthetic", "#cv"], "emoji": "🌙", "ru": {"title": "Проверка AI-зрения в темноте от первого лица", "desc": "EgoNight — это первый комплексный бенчмарк для оценки egocentric-видения в ночных условиях с фоку
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#agents", "#interpretability", "#benchmark", "#reasoning"], "emoji": "🗣️", "ru": {"title": "Реалистичный бенчмарк для многоходовых SQL-диалогов с базами данных", "desc": "Статья представляет BIRD-INTERACT — новый бенчмарк для оценки LLM в многоходовых задачах преобразования текста в
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#inference", "#alignment", "#agents", "#security", "#healthcare"], "emoji": "🛡️", "ru": {"title": "Формальные гарантии безопасности для LLM-агентов", "desc": "VeriGuard — это фреймворк для обеспечения формальных гарантий безопасности AI-агентов на основе LLM в критических областях в
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#rlhf", "#rl", "#reasoning"], "emoji": "🤗", "ru": {"title": "Усиление когнитивного мышления для эмоциональной поддержки", "desc": "Статья представляет CARE — фреймворк для улучшения диалоговых систем эмоциональной поддержки. В отличие от существующих подходов, которые фокусируются н
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#cv", "#video", "#3d"], "emoji": "🎥", "ru": {"title": "Реальная 4D реконструкция сцен с людьми из видео", "desc": "Human3R — это новая система для реконструкции 4D сцен с людьми из обычных видео, которая работает в реальном времени. В отличие от других методов, Human3R не требует сл
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#video", "#3d"], "emoji": "🎬", "ru": {"title": "От видео к динамической 3D-форме: генерация 4D-представлений с временной согласованностью", "desc": "Статья представляет новый фреймворк для генерации 4D-форм из видео, который создаёт динамическое 3D-представление напрямую из входного
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#data", "#benchmark", "#long_context", "#healthcare", "#dataset", "#multimodal"], "emoji": "🔬", "ru": {"title": "Длинный контекст для биомедицинских изображений: больше слов — лучше результат", "desc": "Исследователи обнаружили, что стандартные vision-language модели с коротким конт
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#inference", "#optimization", "#cv", "#diffusion", "#multimodal"], "emoji": "⚖️", "ru": {"title": "Генерация через энергетический ландшафт вместо диффузии", "desc": "Equilibrium Matching (EqM) — это новый подход к генеративному моделированию, который отказывается от зависящей от вре
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#optimization", "#inference", "#training"], "emoji": "⚖️", "ru": {"title": "Устойчивость к квантизации зависит от гиперпараметров, а не от объёма данных", "desc": "Исследователи изучили, как post-training квантизация работает в больших языковых моделях до 32B параметров, обученных н
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#video", "#multimodal", "#benchmark", "#games", "#alignment"], "emoji": "🌊", "ru": {"title": "Сегментация видео через непрерывную деформацию под управлением текста", "desc": "FlowRVS решает задачу сегментации объектов в видео по текстовому описанию (RVOS), переформулируя её как проб
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#hallucinations", "#inference", "#interpretability"], "emoji": "🔍", "ru": {"title": "Карта галлюцинаций: как и где LLM теряют связь с реальностью", "desc": "Исследователи разработали метод Distributional Semantics Tracing (DST), который позволяет отсле
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#benchmark", "#synthetic", "#dataset", "#optimization"], "emoji": "📊", "ru": {"title": "LLM учатся читать графики, но не всегда понимают где что находится", "desc": "Исследователи создали бенчмарк для оценки способности AI-моделей анализировать диаграммы рассеяния (scatterplots), ис
[08.10.2025 13:25] Querying the API.
[08.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MG-Select, a novel test-time scaling framework for Vision-Language-Action models, improves performance by using KL divergence from a reference distribution generated with masked inputs, achieving significant gains in both in-distribution and out-of-distribution tasks.  					AI-generated summary 				 Vision-Language-Action models (VLAs) have demonstrated remarkable performance in robot control. However, they remain fundamentally limited in tasks that require high precision due to their single-inference paradigm. While test-time scaling approaches using external verifiers have shown promise, they require additional training and fail to generalize to unseen conditions. We propose Masking Distribution Guided Selection (MG-Select), a novel test-time scaling framework for VLAs that leverages the model's internal properties without requiring additional training or external modules. Our approach utilizes KL divergence from a reference action token distribution as a confidence metric for selecting the optimal action from multiple candidates. We introduce a reference distribution generated by the same VLA but with randomly masked states and language conditions as inputs, ensuring maximum uncertainty while remaining aligned with the target task distribution. Additionally, we propose a joint training strategy that enables the model to learn both conditional and unconditional distributions by applying dropout to state and language conditions, thereby further improving the quality of the reference distribution. Our experiments demonstrate that MG-Select achieves significant performance improvements, including a 28%/35% improvement in real-world in-distribution/out-of-distribution tasks, along with a 168% relative gain on RoboCasa pick-and-place tasks trained with 30 demonstrations.
[08.10.2025 13:25] Response: ```json
{
  "title": "Умный выбор действий робота через маскирование входных данных",
  "desc": "В статье представлен MG-Select — новый метод улучшения работы Vision-Language-Action моделей для управления роботами на этапе тестирования. Подход использует KL-дивергенцию между распределением действий модели и референсным распределением, полученным при случайном маскировании входных данных, для выбора оптимального действия из нескольких кандидатов. Метод не требует дополнительного обучения или внешних модулей, используя только внутренние свойства самой модели. Эксперименты показывают улучшение на 28-35% на реальных задачах и 168% прирост на задачах манипуляции объектами.",
  "emoji": "🎯",
  "desc_en": ""
}
```
[08.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MG-Select, a novel test-time scaling framework for Vision-Language-Action models, improves performance by using KL divergence from a reference distribution generated with masked inputs, achieving significant gains in both in-distribution and out-of-distribution tasks.  					AI-generated summary 				 Vision-Language-Action models (VLAs) have demonstrated remarkable performance in robot control. However, they remain fundamentally limited in tasks that require high precision due to their single-inference paradigm. While test-time scaling approaches using external verifiers have shown promise, they require additional training and fail to generalize to unseen conditions. We propose Masking Distribution Guided Selection (MG-Select), a novel test-time scaling framework for VLAs that leverages the model's internal properties without requiring additional training or external modules. Our approach utilizes KL divergence from a reference action token distribution as a confidence metric for selecting the optimal action from multiple candidates. We introduce a reference distribution generated by the same VLA but with randomly masked states and language conditions as inputs, ensuring maximum uncertainty while remaining aligned with the target task distribution. Additionally, we propose a joint training strategy that enables the model to learn both conditional and unconditional distributions by applying dropout to state and language conditions, thereby further improving the quality of the reference distribution. Our experiments demonstrate that MG-Select achieves significant performance improvements, including a 28%/35% improvement in real-world in-distribution/out-of-distribution tasks, along with a 168% relative gain on RoboCasa pick-and-place tasks trained with 30 demonstrations."

[08.10.2025 13:25] Response: ```python
['AGENTS', 'CV', 'TRAINING', 'ROBOTICS']
```
[08.10.2025 13:25] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MG-Select, a novel test-time scaling framework for Vision-Language-Action models, improves performance by using KL divergence from a reference distribution generated with masked inputs, achieving significant gains in both in-distribution and out-of-distribution tasks.  					AI-generated summary 				 Vision-Language-Action models (VLAs) have demonstrated remarkable performance in robot control. However, they remain fundamentally limited in tasks that require high precision due to their single-inference paradigm. While test-time scaling approaches using external verifiers have shown promise, they require additional training and fail to generalize to unseen conditions. We propose Masking Distribution Guided Selection (MG-Select), a novel test-time scaling framework for VLAs that leverages the model's internal properties without requiring additional training or external modules. Our approach utilizes KL divergence from a reference action token distribution as a confidence metric for selecting the optimal action from multiple candidates. We introduce a reference distribution generated by the same VLA but with randomly masked states and language conditions as inputs, ensuring maximum uncertainty while remaining aligned with the target task distribution. Additionally, we propose a joint training strategy that enables the model to learn both conditional and unconditional distributions by applying dropout to state and language conditions, thereby further improving the quality of the reference distribution. Our experiments demonstrate that MG-Select achieves significant performance improvements, including a 28%/35% improvement in real-world in-distribution/out-of-distribution tasks, along with a 168% relative gain on RoboCasa pick-and-place tasks trained with 30 demonstrations."

[08.10.2025 13:25] Response: ```python
["OPTIMIZATION"]
```
[08.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MG-Select is a new framework designed to enhance the performance of Vision-Language-Action (VLA) models during test time. It uses KL divergence to compare the model\'s action choices against a reference distribution created from masked inputs, allowing for better decision-making without needing extra training. This method helps the model select the best action from several options by measuring confidence based on internal properties. The results show that MG-Select significantly boosts performance in both familiar and unfamiliar tasks, making it a valuable advancement in robot control applications.","title":"Enhancing VLA Performance with MG-Select Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="MG-Select is a new framework designed to enhance the performance of Vision-Language-Action (VLA) models during test time. It uses KL divergence to compare the model's action choices against a reference distribution created from masked inputs, allowing for better decision-making without needing extra training. This method helps the model select the best action from several options by measuring confidence based on internal properties. The results show that MG-Select significantly boosts performance in both familiar and unfamiliar tasks, making it a valuable advancement in robot control applications.", title='Enhancing VLA Performance with MG-Select Framework'))
[08.10.2025 13:25] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MG-Select是一种新颖的测试时缩放框架，专为视觉-语言-动作模型设计。它通过使用从掩蔽输入生成的参考分布的KL散度来提高模型的性能，显著提升了模型在分布内和分布外任务的表现。该方法不需要额外的训练或外部模块，利用模型的内部特性来选择最佳动作。实验结果表明，MG-Select在真实世界任务中实现了显著的性能提升，特别是在RoboCasa的拾取和放置任务中表现尤为突出。","title":"MG-Select：提升视觉-语言-动作模型性能的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MG-Select是一种新颖的测试时缩放框架，专为视觉-语言-动作模型设计。它通过使用从掩蔽输入生成的参考分布的KL散度来提高模型的性能，显著提升了模型在分布内和分布外任务的表现。该方法不需要额外的训练或外部模块，利用模型的内部特性来选择最佳动作。实验结果表明，MG-Select在真实世界任务中实现了显著的性能提升，特别是在RoboCasa的拾取和放置任务中表现尤为突出。', title='MG-Select：提升视觉-语言-动作模型性能的新方法'))
[08.10.2025 13:25] Using data from previous issue: {"categories": ["#training", "#agents", "#rl", "#optimization", "#reasoning", "#architecture"], "emoji": "🔄", "ru": {"title": "Обучаемая агентная система с оптимизацией в процессе взаимодействия", "desc": "AgentFlow — это обучаемый фреймворк, который улучшает рассуждения в LLM через координацию четы
[08.10.2025 13:25] Querying the API.
[08.10.2025 13:25] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

EvoPresent, a self-improvement agent framework using multi-task reinforcement learning, enhances academic paper promotion by generating coherent narratives, aesthetically pleasing designs, and realistic presentations, supported by a comprehensive benchmark.  					AI-generated summary 				 The promotion of academic papers has become an important means of enhancing research visibility. However, existing automated methods struggle limited storytelling, insufficient aesthetic quality, and constrained self-adjustment, making it difficult to achieve efficient and engaging dissemination. At the heart of those challenges is a simple principle: there is no way to improve it when you cannot evaluate it right. To address this, we introduce EvoPresent, a self-improvement agent framework that unifies coherent narratives, aesthetic-aware designs, and realistic presentation delivery via virtual characters. Central to EvoPresent is PresAesth, a multi-task reinforcement learning (RL) aesthetic model that provides reliable aesthetic scoring, defect adjustment, and comparative feedback, enabling iterative self-improvement even under limited aesthetic training data. To systematically evaluate the methods, we introduce EvoPresent Benchmark, a comprehensive benchmark comprising: Presentation Generation Quality, built on 650 top-tier AI conference papers with multimodal resources (slides, videos and scripts) to assess both content and design; and Aesthetic Awareness, consisting of 2,000 slide pairs with varying aesthetic levels, supporting joint training and evaluation on scoring, defect adjustment, and comparison. Our findings highlight that (i) High-quality feedback is essential for agent self-improvement, while initial capability alone does not guarantee effective self-correction. (ii) Automated generation pipelines exhibit a trade-off between visual design and content construction. (iii) Multi-task RL training shows stronger generalization in aesthetic awareness tasks.
[08.10.2025 13:26] Response: ```json
{
  "title": "Самосовершенствующийся агент для создания презентаций научных статей",
  "desc": "EvoPresent — это фреймворк агента, который автоматически создаёт презентации научных работ, используя multi-task reinforcement learning для улучшения качества. В основе системы лежит модель PresAesth, которая оценивает эстетику слайдов, исправляет недостатки и даёт сравнительную обратную связь для итеративного самосовершенствования. Авторы представили комплексный бенчмарк на базе 650 статей с топовых AI-конференций и 2000 пар слайдов для оценки качества контента и дизайна. Исследование показало, что качественная обратная связь критически важна для самоулучшения агента, а multi-task RL демонстрирует лучшую генерализацию в задачах оценки эстетики.",
  "emoji": "🎨",
  "desc_backup": "В статье представлен EvoPresent — фреймворк для автоматического создания презентаций научных статей с помощью reinforcement learning агента. Ключевой компонент системы — модель PresAesth, обученная через multi-task RL для оценки эстетики, исправления дефектов и предоставления обратной связи. Для оценки разработан бенчмарк из 650 статей ведущих AI-конференций и 2000 пар слайдов разного качества. Результаты показывают важность качественного feedback для самоулучшения и превосходство multi-task подхода в задачах эстетической оценки."
}
```
[08.10.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"EvoPresent, a self-improvement agent framework using multi-task reinforcement learning, enhances academic paper promotion by generating coherent narratives, aesthetically pleasing designs, and realistic presentations, supported by a comprehensive benchmark.  					AI-generated summary 				 The promotion of academic papers has become an important means of enhancing research visibility. However, existing automated methods struggle limited storytelling, insufficient aesthetic quality, and constrained self-adjustment, making it difficult to achieve efficient and engaging dissemination. At the heart of those challenges is a simple principle: there is no way to improve it when you cannot evaluate it right. To address this, we introduce EvoPresent, a self-improvement agent framework that unifies coherent narratives, aesthetic-aware designs, and realistic presentation delivery via virtual characters. Central to EvoPresent is PresAesth, a multi-task reinforcement learning (RL) aesthetic model that provides reliable aesthetic scoring, defect adjustment, and comparative feedback, enabling iterative self-improvement even under limited aesthetic training data. To systematically evaluate the methods, we introduce EvoPresent Benchmark, a comprehensive benchmark comprising: Presentation Generation Quality, built on 650 top-tier AI conference papers with multimodal resources (slides, videos and scripts) to assess both content and design; and Aesthetic Awareness, consisting of 2,000 slide pairs with varying aesthetic levels, supporting joint training and evaluation on scoring, defect adjustment, and comparison. Our findings highlight that (i) High-quality feedback is essential for agent self-improvement, while initial capability alone does not guarantee effective self-correction. (ii) Automated generation pipelines exhibit a trade-off between visual design and content construction. (iii) Multi-task RL training shows stronger generalization in aesthetic awareness tasks."

[08.10.2025 13:26] Response: ```python
['AGENTS', 'RL', 'BENCHMARK', 'MULTIMODAL']
```
[08.10.2025 13:26] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"EvoPresent, a self-improvement agent framework using multi-task reinforcement learning, enhances academic paper promotion by generating coherent narratives, aesthetically pleasing designs, and realistic presentations, supported by a comprehensive benchmark.  					AI-generated summary 				 The promotion of academic papers has become an important means of enhancing research visibility. However, existing automated methods struggle limited storytelling, insufficient aesthetic quality, and constrained self-adjustment, making it difficult to achieve efficient and engaging dissemination. At the heart of those challenges is a simple principle: there is no way to improve it when you cannot evaluate it right. To address this, we introduce EvoPresent, a self-improvement agent framework that unifies coherent narratives, aesthetic-aware designs, and realistic presentation delivery via virtual characters. Central to EvoPresent is PresAesth, a multi-task reinforcement learning (RL) aesthetic model that provides reliable aesthetic scoring, defect adjustment, and comparative feedback, enabling iterative self-improvement even under limited aesthetic training data. To systematically evaluate the methods, we introduce EvoPresent Benchmark, a comprehensive benchmark comprising: Presentation Generation Quality, built on 650 top-tier AI conference papers with multimodal resources (slides, videos and scripts) to assess both content and design; and Aesthetic Awareness, consisting of 2,000 slide pairs with varying aesthetic levels, supporting joint training and evaluation on scoring, defect adjustment, and comparison. Our findings highlight that (i) High-quality feedback is essential for agent self-improvement, while initial capability alone does not guarantee effective self-correction. (ii) Automated generation pipelines exhibit a trade-off between visual design and content construction. (iii) Multi-task RL training shows stronger generalization in aesthetic awareness tasks."

[08.10.2025 13:26] Response: ```python
["GAMES", "OPTIMIZATION", "STORY_GENERATION"]
```
[08.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"EvoPresent is a framework designed to improve the promotion of academic papers using multi-task reinforcement learning. It addresses challenges in storytelling, aesthetic quality, and self-adjustment by integrating coherent narratives and visually appealing designs. The core of EvoPresent is the PresAesth model, which provides aesthetic scoring and feedback for iterative self-improvement. The framework is evaluated using the EvoPresent Benchmark, which assesses presentation quality and aesthetic awareness based on a large dataset of academic resources.","title":"Enhancing Academic Paper Promotion with EvoPresent: A Self-Improvement Framework"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='EvoPresent is a framework designed to improve the promotion of academic papers using multi-task reinforcement learning. It addresses challenges in storytelling, aesthetic quality, and self-adjustment by integrating coherent narratives and visually appealing designs. The core of EvoPresent is the PresAesth model, which provides aesthetic scoring and feedback for iterative self-improvement. The framework is evaluated using the EvoPresent Benchmark, which assesses presentation quality and aesthetic awareness based on a large dataset of academic resources.', title='Enhancing Academic Paper Promotion with EvoPresent: A Self-Improvement Framework'))
[08.10.2025 13:26] Response: ParsedChatCompletionMessage[Article](content='{"desc":"EvoPresent是一个自我改进的智能代理框架，利用多任务强化学习来提升学术论文的推广效果。它通过生成连贯的叙述、美观的设计和逼真的演示，解决了现有自动化方法在讲故事、审美质量和自我调整方面的不足。EvoPresent的核心是PresAesth，一个多任务强化学习美学模型，能够提供可靠的美学评分和缺陷调整，支持在有限的美学训练数据下进行迭代自我改进。通过EvoPresent基准测试，我们评估了演示生成质量和美学意识，发现高质量反馈对代理自我改进至关重要。","title":"EvoPresent：提升学术论文推广的智能代理框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='EvoPresent是一个自我改进的智能代理框架，利用多任务强化学习来提升学术论文的推广效果。它通过生成连贯的叙述、美观的设计和逼真的演示，解决了现有自动化方法在讲故事、审美质量和自我调整方面的不足。EvoPresent的核心是PresAesth，一个多任务强化学习美学模型，能够提供可靠的美学评分和缺陷调整，支持在有限的美学训练数据下进行迭代自我改进。通过EvoPresent基准测试，我们评估了演示生成质量和美学意识，发现高质量反馈对代理自我改进至关重要。', title='EvoPresent：提升学术论文推广的智能代理框架'))
[08.10.2025 13:26] Using data from previous issue: {"categories": ["#inference", "#training", "#data", "#rlhf", "#alignment"], "emoji": "🚦", "ru": {"title": "Научить AI понимать, что хорошо, а не только что лучше", "desc": "Исследователи предлагают новый подход к обучению моделей предпочтений, добавляя «внешнюю опцию» в данные сравнений. Традиционны
[08.10.2025 13:26] Using data from previous issue: {"categories": ["#optimization", "#alignment", "#training", "#rlhf"], "emoji": "🔄", "ru": {"title": "Обучение LLM на недовольстве пользователей: превращаем негатив в качество", "desc": "В статье представлен метод DRIFT для обучения больших языковых моделей на основе сигналов недовольства пользовател
[08.10.2025 13:26] Using data from previous issue: {"categories": ["#audio", "#alignment", "#interpretability"], "emoji": "🎭", "ru": {"title": "Субъективность эмоций как преимущество: учёт мнения меньшинства в распознавании речи", "desc": "Диссертация посвящена распознаванию эмоций в речи (SER) и предлагает отказаться от традиционного подхода, где р
[08.10.2025 13:26] Using data from previous issue: {"categories": ["#training", "#optimization", "#games", "#architecture", "#diffusion", "#multimodal"], "emoji": "🔄", "ru": {"title": "Одновременная генерация текста и изображений без авторегрессии", "desc": "OneFlow — это первая неавторегрессионная мультимодальная модель, способная генерировать текс
[08.10.2025 13:26] Using data from previous issue: {"categories": ["#training", "#hallucinations", "#dataset", "#rag", "#small_models", "#synthetic", "#benchmark", "#optimization"], "emoji": "🛡️", "ru": {"title": "HalluGuard: Защита от галлюцинаций в генерации текста", "desc": "HalluGuard — это модель с 4 миллиардами параметров, которая помогает уме
[08.10.2025 13:26] Renaming data file.
[08.10.2025 13:26] Renaming previous data. hf_papers.json to ./d/2025-10-08.json
[08.10.2025 13:26] Saving new data file.
[08.10.2025 13:26] Generating page.
[08.10.2025 13:26] Renaming previous page.
[08.10.2025 13:26] Renaming previous data. index.html to ./d/2025-10-08.html
[08.10.2025 13:26] Writing result.
[08.10.2025 13:26] Renaming log file.
[08.10.2025 13:26] Renaming previous data. log.txt to ./logs/2025-10-08_last_log.txt
