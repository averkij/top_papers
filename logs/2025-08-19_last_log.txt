[19.08.2025 16:14] Read previous papers.
[19.08.2025 16:14] Generating top page (month).
[19.08.2025 16:14] Writing top page (month).
[19.08.2025 17:10] Read previous papers.
[19.08.2025 17:10] Get feed.
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11737
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10419
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13154
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12811
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09834
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11383
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13142
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12782
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13009
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11379
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12945
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12880
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11598
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12466
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13104
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12790
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.12730
[19.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11252
[19.08.2025 17:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[19.08.2025 17:10] No deleted papers detected.
[19.08.2025 17:10] Downloading and parsing papers (pdf, html). Total: 18.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.11737.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.11737.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.11737.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.10419.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.10419.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.10419.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.13154.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.13154.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.13154.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12811.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12811.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12811.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.09834.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.09834.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.09834.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.11383.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.11383.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.11383.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.13142.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.13142.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.13142.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12782.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12782.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12782.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.13009.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.13009.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.13009.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.11379.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.11379.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.11379.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12945.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12945.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12945.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12880.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12880.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12880.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.11598.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.11598.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.11598.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12466.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12466.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12466.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.13104.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.13104.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.13104.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12790.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12790.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12790.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.12730.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.12730.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.12730.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.11252.
[19.08.2025 17:10] Extra JSON file exists (./assets/json/2508.11252.json), skip PDF parsing.
[19.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.11252.json), skip HTML parsing.
[19.08.2025 17:10] Success.
[19.08.2025 17:10] Enriching papers with extra data.
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 0. Ovis2.5, a native-resolution vision transformer with multimodal reasoning, achieves state-of-the-art performance on various benchmarks through advanced training techniques and efficient scaling methods.  					AI-generated summary 				 We present Ovis2.5, a successor to Ovis2 designed for native-reso...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 1. ComoRAG, an iterative retrieval-based approach, enhances long-context narrative comprehension by dynamically updating memory and generating probing queries, outperforming traditional RAG methods.  					AI-generated summary 				 Narrative comprehension on long stories and novels has been a challengin...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 2. 4DNeX generates high-quality dynamic 3D scene representations from a single image using a fine-tuned pretrained video diffusion model, outperforming existing methods in efficiency and generalizability.  					AI-generated summary 				 We present 4DNeX, the first feed-forward framework for generating ...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 3. A novel Next Visual Granularity (NVG) framework generates images by iteratively refining a sequence of visual granularities, outperforming existing methods in class-conditional image generation.  					AI-generated summary 				 We propose a novel approach to image generation by decomposing an image i...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 4. This survey examines innovative architectures for large language models to enhance efficiency, covering linear and sparse sequence modeling, efficient attention mechanisms, sparse mixture-of-experts, hybrid models, and diffusion LLMs.  					AI-generated summary 				 Large Language Models (LLMs) have...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 5. A systematic evaluation of prompt robustness methods for Large Language Models across various models and tasks reveals insights into their effectiveness against format perturbations.  					AI-generated summary 				 Large Language Models (LLMs) are highly sensitive to subtle, non-semantic variations ...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 6. Recent multi-modal models, including GPT-5, show significant progress in spatial intelligence but still lag behind human performance across various benchmarks.  					AI-generated summary 				 Multi-modal models have achieved remarkable progress in recent years. Nevertheless, they continue to exhibit...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 7. HeroBench evaluates long-horizon planning and structured reasoning in complex virtual worlds, revealing performance disparities in state-of-the-art LLMs.  					AI-generated summary 				 Large language models (LLMs) have shown remarkable capabilities in isolated step-by-step reasoning tasks such as m...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 8. Matrix-Game 2.0 generates real-time interactive videos using few-step auto-regressive diffusion, addressing the limitations of lengthy inference in existing models.  					AI-generated summary 				 Recent advances in interactive video generations have demonstrated diffusion model's potential as world...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 9. G-CUT3R enhances 3D scene reconstruction by integrating auxiliary data through dedicated encoders and zero convolution, improving performance across benchmarks.  					AI-generated summary 				 We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene reconstruction that enhances the CU...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 10. Lumen is an end-to-end video relighting framework that uses a large-scale dataset of realistic and synthetic videos to achieve consistent lighting and foreground preservation in edited videos.  					AI-generated summary 				 Video relighting is a challenging yet valuable task, aiming to replace the ...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 11. S^2-Guidance, a novel method using stochastic block-dropping, improves sample quality and prompt adherence in diffusion models by refining suboptimal predictions, outperforming Classifier-free Guidance and other advanced strategies.  					AI-generated summary 				 Classifier-free Guidance (CFG) is a...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 12. AuriStream, a biologically inspired two-stage model, encodes speech using cochlear tokens and an autoregressive sequence model, achieving state-of-the-art performance on speech tasks and generating interpretable audio continuations.  					AI-generated summary 				 We introduce AuriStream, a biologic...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 13. Inverse-LLaVA eliminates alignment pre-training by mapping text embeddings into continuous visual representation space, improving reasoning tasks while reducing computational requirements.  					AI-generated summary 				 Traditional multimodal learning approaches require expensive alignment pre-trai...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 14. Visual action prompts, using visual skeletons, enable precise action control in video generation while maintaining cross-domain transferability.  					AI-generated summary 				 We present visual action prompts, a unified action representation for action-to-video generation of complex high-DoF intera...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 15. RLVR is extended to open-ended tasks using rubric-based rewards, improving performance on benchmarks and providing stylistic control in LLMs.  					AI-generated summary 				 Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing Large Language Models (...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 16. A visual analytics system, Unlearning Comparator, facilitates the evaluation of Machine Unlearning methods by comparing model behaviors and simulating membership inference attacks to assess privacy.  					AI-generated summary 				 Machine Unlearning (MU) aims to remove target training data from a tr...
[19.08.2025 17:10] ********************************************************************************
[19.08.2025 17:10] Abstract 17. Systematic evaluation of Large Reasoning Models on incomplete problems reveals their inability to proactively seek information, highlighting issues like overthinking and hallucination, and the challenges of supervised fine-tuning for developing genuine intelligence.  					AI-generated summary 				 L...
[19.08.2025 17:10] Read previous papers.
[19.08.2025 17:10] Generating reviews via LLM API.
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#low_resource", "#open_source", "#science", "#interpretability", "#benchmark", "#small_models", "#training", "#architecture", "#agi", "#cv"], "emoji": "üß†", "ru": {"title": "–ûvis2.5: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è", "desc": "Ovis2.5 - 
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#long_context", "#rag"], "emoji": "üìö", "ru": {"title": "ComoRAG: –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤", "desc": "ComoRAG - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –û–Ω –¥–∏–Ω–∞–º–∏—á–µ—Å
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#cv", "#synthetic", "#3d", "#dataset", "#diffusion"], "emoji": "üåü", "ru": {"title": "–û—Ç 2D –∫ 4D: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö 3D-—Å—Ü–µ–Ω", "desc": "4DNeX - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö 3D-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å—Ü–µ–Ω –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#open_source", "#diffusion", "#cv", "#training", "#dataset"], "emoji": "üñºÔ∏è", "ru": {"title": "–ü–æ—Å–ª–æ–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π Next Visual Granularity (NVG). –û–Ω —Ä–∞–∑–±–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä—É
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#multimodal", "#survey", "#architecture", "#agi", "#optimization"], "emoji": "üß†", "ru": {"title": "–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ LLM: –ø—É—Ç—å –∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏", "desc": "–≠—Ç–æ –æ–±–∑–æ—Ä –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–∞ –ø–æ–≤—ã—à–µ–Ω–∏–µ –∏—Ö —ç—Ñ—Ñ–µ
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#interpretability", "#optimization", "#security", "#benchmark", "#training"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ó–∞—â–∏—Ç–∞ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç –∫–∞–ø—Ä–∏–∑–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤ –ø–æ–≤—ã—à–µ–Ω–∏—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#survey", "#agi", "#benchmark", "#multimodal", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏: –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –∞–Ω–∞–ª–∏–∑—É –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –≤–∫–ª—é—á–∞—è GPT-5. –ê–≤—Ç–æ—Ä—ã –ø
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#long_context", "#agents", "#benchmark"], "emoji": "üéÆ", "ru": {"title": "HeroBench: —Ä–∞—Å–∫—Ä—ã–≤–∞—è –∏—Å—Ç–∏–Ω–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ò–ò –≤ —Å–ª–æ–∂–Ω–æ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏", "desc": "HeroBench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –∏ —Å—Ç—Ä—É
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#video", "#data", "#open_source", "#diffusion", "#dataset", "#games", "#architecture"], "emoji": "üéÆ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–∏–¥–µ–æ–∏–≥—Ä–∞—Ö: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å Matrix-Game 2.0", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Matrix-Game 2.0 - –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#3d"], "emoji": "üèõÔ∏è", "ru": {"title": "–£–ª—É—á—à–µ–Ω–Ω–∞—è 3D-—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "G-CUT3R - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ 3D-—Å—Ü–µ–Ω, —É–ª—É—á—à–∞—é—â–∏–π –º–æ–¥–µ–ª—å CUT3R –ø—É—Ç–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —ç–Ω
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#video", "#synthetic", "#benchmark"], "emoji": "üí°", "ru": {"title": "Lumen: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ—Ä–∏—Å–æ–≤–∫–∞ –æ—Å–≤–µ—â–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–µ—Ä–µ–¥–Ω–µ–≥–æ –ø–ª–∞–Ω–∞", "desc": "Lumen - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ—Ä–∏—Å–æ–≤–∫–∏ –æ—Å–≤–µ—â–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∞–ª–∏—Å—Ç
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#video", "#open_source", "#diffusion", "#training", "#cv", "#optimization"], "emoji": "üé®", "ru": {"title": "S^2-Guidance: –Ω–æ–≤—ã–π –ø—É—Ç—å –∫ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "S^2-Guidance - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–Ω–∏–µ –±–ª–æ–∫–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#science", "#audio", "#interpretability"], "emoji": "üëÇ", "ru": {"title": "–ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ—á–∏", "desc": "AuriStream - —ç—Ç–æ –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–µ—Ä–≤—ã–π —ç—Ç–∞–ø –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä–æ–π –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª –≤ —á–∞—Å—Ç
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#open_source", "#reasoning", "#architecture", "#alignment"], "emoji": "üîÑ", "ru": {"title": "–ò–Ω–≤–µ—Ä—Å–∏—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "Inverse-LLaVA - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é, –∫–æ—Ç–æ—Ä—ã–π —É—Å—Ç—Ä–∞–Ω—è–µ—Ç –Ω–µ–æ
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#games", "#training", "#transfer_learning", "#multimodal", "#video"], "emoji": "ü¶¥", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω—ã–µ —Å–∫–µ–ª–µ—Ç—ã: —Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Å–∫–µ–ª–µ—Ç—ã –∫–∞–∫ –Ω–æ–≤—ã–π —Å–ø–æ—Å–æ–± –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ. –≠—Ç–æ—Ç –º
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#training", "#alignment", "#rlhf", "#reasoning", "#rl", "#open_source"], "emoji": "üìù", "ru": {"title": "–†—É–±—Ä–∏–∫–∏ –æ—Ç–∫—Ä—ã–≤–∞—é—Ç –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã—Ö –Ω–∞–≥—Ä
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#data", "#security", "#ethics", "#benchmark"], "emoji": "üïµÔ∏è", "ru": {"title": "–í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏—è", "desc": "–°–∏—Å—Ç–µ–º–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ 'Unlearning Comparator' –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –º–µ—Ç–æ–¥—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏—è (Machine Unlearning), —Å—Ä–∞–≤–Ω–∏–≤–∞—è 
[19.08.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#hallucinations", "#training", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ö—Ä—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π: —Ä–µ—à–∞—Ç–µ–ª–∏ –∑–∞–¥–∞—á, –Ω–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–∏–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫—Ä—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (LRM) —Ä–µ—à–∞—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–µ –∑–∞–¥–∞—á–∏. –†–µ–∑—É–ª—å
[19.08.2025 17:10] Renaming data file.
[19.08.2025 17:10] Renaming previous data. hf_papers.json to ./d/2025-08-19.json
[19.08.2025 17:10] Saving new data file.
[19.08.2025 17:10] Generating page.
[19.08.2025 17:10] Renaming previous page.
[19.08.2025 17:10] Renaming previous data. index.html to ./d/2025-08-19.html
[19.08.2025 17:10] Writing result.
[19.08.2025 17:10] Renaming log file.
[19.08.2025 17:10] Renaming previous data. log.txt to ./logs/2025-08-19_last_log.txt
