[24.07.2025 22:12] Read previous papers.
[24.07.2025 22:12] Generating top page (month).
[24.07.2025 22:12] Writing top page (month).
[24.07.2025 23:12] Read previous papers.
[24.07.2025 23:12] Get feed.
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16863
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.17744
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.17202
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16725
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.17512
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16331
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.17745
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.11465
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16880
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.16116
[24.07.2025 23:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.14241
[24.07.2025 23:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.07.2025 23:12] No deleted papers detected.
[24.07.2025 23:12] Downloading and parsing papers (pdf, html). Total: 11.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.16863.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.16863.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.16863.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.17744.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.17744.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.17744.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.17202.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.17202.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.17202.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.16725.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.16725.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.16725.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.17512.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.17512.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.17512.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.16331.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.16331.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.16331.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.17745.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.17745.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.17745.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.11465.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.11465.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.11465.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.16880.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.16880.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.16880.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.16116.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.16116.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.16116.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Downloading and parsing paper https://huggingface.co/papers/2507.14241.
[24.07.2025 23:12] Extra JSON file exists (./assets/json/2507.14241.json), skip PDF parsing.
[24.07.2025 23:12] Paper image links file exists (./assets/img_data/2507.14241.json), skip HTML parsing.
[24.07.2025 23:12] Success.
[24.07.2025 23:12] Enriching papers with extra data.
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 0. The Turing Eye Test evaluates MLLMs' perceptual abilities through synthetic images, revealing that vision tower generalization is a significant gap compared to human perception.  					AI-generated summary 				 Achieving human-like perception and reasoning in Multimodal Large Language Models (MLLMs) ...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 1. A framework for generating and exploring interactive video worlds from images using Masked Video Diffusion Transformer, Anti-Artifact Mechanism, Time Travel Sampling, and model acceleration techniques.  					AI-generated summary 				 Yume aims to use images, text, or videos to create an interactive,...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 2. DesignLab uses fine-tuned large language models to iteratively improve presentation slides through a design reviewer and contributor system, outperforming existing tools.  					AI-generated summary 				 Designing high-quality presentation slides can be challenging for non-experts due to the complexi...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 3. A new evaluation framework called RAVine is proposed to assess agentic search systems by focusing on realistic queries, accurate ground truth, and iterative process efficiency.  					AI-generated summary 				 Agentic search, as a more autonomous and adaptive paradigm of retrieval augmentation, is dr...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 4. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing research has predominantly concentrated on isolated reasoning domains such as mathematical problem-solving, coding tasks, or logical reasoning. However,...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 5. Formal language-based reasoning and automatic verification improve the reliability and scalability of Large Language Models for generating verifiable programs.  					AI-generated summary 				 Existing informal language-based (e.g., human language) Large Language Models (LLMs) trained with Reinforcem...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 6. Ultra3D uses VecSet and Part Attention to accelerate 3D voxel generation while maintaining high quality and resolution.  					AI-generated summary 				 Recent advances in sparse voxel representations have significantly improved the quality of 3D content generation, enabling high-resolution modeling ...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 7. Elevate3D enhances both texture and geometry of low-quality 3D assets using HFS-SDEdit and monocular geometry predictors, achieving superior refinement quality.  					AI-generated summary 				 High-quality 3D assets are essential for various applications in computer graphics and 3D vision but remain...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 8. Pruning-based defenses in text-to-image diffusion models are ineffective as minor adjustments to text embeddings can re-trigger data replication, necessitating methods that truly remove memorized content.  					AI-generated summary 				 Text-to-image diffusion models (DMs) have achieved remarkable s...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 9. Pusa, a vectorized timestep adaptation approach, enhances video diffusion models for efficient and versatile video generation, improving performance and reducing costs.  					AI-generated summary 				 The rapid advancement of video diffusion models has been hindered by fundamental limitations in tem...
[24.07.2025 23:12] ********************************************************************************
[24.07.2025 23:12] Abstract 10. Large Language Models (LLMs) perform best with well-crafted prompts, yet prompt engineering remains manual, inconsistent, and inaccessible to non-experts. We introduce Promptomatix, an automatic prompt optimization framework that transforms natural language task descriptions into high-quality prompt...
[24.07.2025 23:12] Read previous papers.
[24.07.2025 23:12] Generating reviews via LLM API.
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#synthetic", "#benchmark", "#multimodal", "#reasoning", "#perception", "#cv"], "emoji": "üëÅÔ∏è", "ru": {"title": "–¢–µ—Å—Ç –¢—å—é—Ä–∏–Ω–≥–∞ –¥–ª—è –∑—Ä–µ–Ω–∏—è: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ç–µ—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#dataset", "#architecture", "#open_source", "#diffusion", "#cv", "#video"], "emoji": "üé•", "ru": {"title": "–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–∏–¥–µ–æ–º–∏—Ä–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Yume –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–∏–¥–µ–æ–º–∏—Ä–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω –∏—Å–ø–æ–ª—å–∑
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#multimodal"], "emoji": "üé®", "ru": {"title": "–ò–ò-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π", "desc": "DesignLab - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–ª–∞–π–¥–æ–≤. –û–Ω–∞ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –ø—Ä
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#rag", "#optimization", "#agents", "#benchmark", "#alignment"], "emoji": "üîç", "ru": {"title": "RAVine: –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ RAVine –¥–ª—è –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#rl", "#optimization"], "emoji": "üß†", "ru": {"title": "–ú–Ω–æ–≥–æ–¥–æ–º–µ–Ω–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ: —Ä–∞—Å–∫—Ä—ã–≤–∞—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ò–ò —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏ (RLVR) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#rl", "#dataset", "#reasoning", "#training", "#optimization", "#small_models", "#rlhf", "#benchmark"], "emoji": "üß†", "ru": {"title": "–§–æ—Ä–º–∞–ª—å–Ω—ã–µ —è–∑—ã–∫–∏ –ø–æ–≤—ã—à–∞—é—Ç –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ò–ò –≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –∏ –º–∞—Å
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#optimization", "#3d"], "emoji": "üßä", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö 3D-–º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è", "desc": "Ultra3D - —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ VecSet –∏ –º–µ—Ö–∞–Ω–∏–∑–º Part Attention. VecSet 
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#3d", "#open_source", "#synthetic"], "emoji": "üî¨", "ru": {"title": "–ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ 3D-–º–æ–¥–µ–ª–∏ –≤ —à–µ–¥–µ–≤—Ä—ã", "desc": "Elevate3D - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ 3D-–º–æ–¥–µ–ª–µ–π –Ω–∏–∑–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥ HFS-SDEdit –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ–∫—Å—Ç—É—Ä –∏ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –≥–µ–æ–º
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#security", "#cv", "#training", "#hallucinations", "#data"], "emoji": "üîê", "ru": {"title": "–ó–∞—â–∏—Ç–∞ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö: –Ω–æ–≤—ã–µ –≤—ã–∑–æ–≤—ã –∏ —Ä–µ—à–µ–Ω–∏—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –∑–∞—â–∏—Ç—ã –æ—Ç –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#training", "#video", "#diffusion"], "emoji": "üé¨", "ru": {"title": "Pusa: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤", "desc": "Pusa - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤ –≤ –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö, –∏—Å–ø–æ–ª
[24.07.2025 23:12] Using data from previous issue: {"categories": ["#optimization", "#synthetic", "#data", "#training"], "emoji": "ü§ñ", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ LLM", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Promptomatix - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –°–∏
[24.07.2025 23:12] Renaming data file.
[24.07.2025 23:12] Renaming previous data. hf_papers.json to ./d/2025-07-24.json
[24.07.2025 23:12] Saving new data file.
[24.07.2025 23:12] Generating page.
[24.07.2025 23:12] Renaming previous page.
[24.07.2025 23:12] Renaming previous data. index.html to ./d/2025-07-24.html
[24.07.2025 23:12] Writing result.
[24.07.2025 23:12] Renaming log file.
[24.07.2025 23:12] Renaming previous data. log.txt to ./logs/2025-07-24_last_log.txt
