[28.11.2024 14:10] Read previous papers.
[28.11.2024 14:10] Generating top page (month).
[28.11.2024 14:10] Writing top page (month).
[28.11.2024 17:42] Read previous papers.
[28.11.2024 17:42] Get feed.
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17949
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18613
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17188
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17945
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18279
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17786
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17787
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17440
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.15139
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14974
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18197
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17769
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18363
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.16781
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18462
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17991
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18412
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.15872
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17698
[28.11.2024 17:42] Get page data from previous paper. URL: https://huggingface.co/papers/2411.18104
[28.11.2024 17:42] Downloading and parsing papers (pdf, html). Total: 20.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17949.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17949.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17949.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18613.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18613.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18613.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17188.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17188.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17188.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17945.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17945.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17945.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18279.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18279.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18279.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17786.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17786.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17786.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17787.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17787.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17787.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17440.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17440.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17440.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.15139.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.15139.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.15139.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.14974.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.14974.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.14974.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18197.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18197.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18197.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17769.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17769.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17769.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18363.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18363.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18363.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.16781.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.16781.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.16781.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18462.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18462.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18462.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17991.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17991.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17991.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18412.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18412.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18412.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.15872.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.15872.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.15872.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.17698.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.17698.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.17698.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Downloading and parsing paper https://huggingface.co/papers/2411.18104.
[28.11.2024 17:42] Extra JSON file exists (./assets/json/2411.18104.json), skip PDF parsing.
[28.11.2024 17:42] Paper image links file exists (./assets/img_data/2411.18104.json), skip HTML parsing.
[28.11.2024 17:42] Success.
[28.11.2024 17:42] Enriching papers with extra data.
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 0. Natural language often struggles to accurately associate positional and attribute information with multiple instances, which limits current text-based visual generation models to simpler compositions featuring only a few dominant instances. To address this limitation, this work enhances diffusion mo...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 1. We present CAT4D, a method for creating 4D (dynamic 3D) scenes from monocular video. CAT4D leverages a multi-view video diffusion model trained on a diverse combination of datasets to enable novel view synthesis at any specified camera poses and timestamps. Combined with a novel sampling approach, t...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 2. Many real-world user queries (e.g. "How do to make egg fried rice?") could benefit from systems capable of generating responses with both textual steps with accompanying images, similar to a cookbook. Models designed to generate interleaved text and images face challenges in ensuring consistency wit...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 3. Generating high-fidelity 3D content from text prompts remains a significant challenge in computer vision due to the limited size, diversity, and annotation depth of the existing datasets. To address this, we introduce MARVEL-40M+, an extensive dataset with 40 million text annotations for over 8.9 mi...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 4. GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in na...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 5. Personalized image generation requires text-to-image generative models that capture the core features of a reference subject to allow for controlled generation across different contexts. Existing methods face challenges due to complex training requirements, high inference costs, limited flexibility,...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 6. In the rapidly advancing field of image generation, Visual Auto-Regressive (VAR) modeling has garnered considerable attention for its innovative next-scale prediction approach. This paradigm offers substantial improvements in efficiency, scalability, and zero-shot generalization. Yet, the inherently...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 7. Identity-preserving text-to-video (IPT2V) generation aims to create high-fidelity videos with consistent human identity. It is an important task in video generation but remains an open problem for generative models. This paper pushes the technical frontier of IPT2V in two directions that have not be...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 8. Recently, the diffusion model has emerged as a powerful generative technique for robotic policy learning, capable of modeling multi-mode action distributions. Leveraging its capability for end-to-end autonomous driving is a promising direction. However, the numerous denoising steps in the robotic di...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 9. Recent advances in radiance field reconstruction, such as 3D Gaussian Splatting (3DGS), have achieved high-quality novel view synthesis and fast rendering by representing scenes with compositions of Gaussian primitives. However, 3D Gaussians present several limitations for scene reconstruction. Accu...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 10. 3D characters are essential to modern creative industries, but making them animatable often demands extensive manual work in tasks like rigging and skinning. Existing automatic rigging tools face several limitations, including the necessity for manual annotations, rigid skeleton topologies, and limi...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 11. In this work, we introduce a single parameter omega, to effectively control granularity in diffusion-based synthesis. This parameter is incorporated during the denoising steps of the diffusion model's reverse process. Our approach does not require model retraining, architectural modifications, or ad...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 12. Perception and understanding are two pillars of computer vision. While multimodal large language models (MLLM) have demonstrated remarkable visual understanding capabilities, they arguably lack accurate perception abilities, e.g. the stage-of-the-art model Qwen2-VL only achieves a 43.9 recall rate o...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 13. Human pose plays a crucial role in the digital age. While recent works have achieved impressive progress in understanding and generating human poses, they often support only a single modality of control signals and operate in isolation, limiting their application in real-world scenarios. This paper ...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 14. Speculative Decoding (SD) has become an important technique in accelerating the inference speed of large language models. Conventional SD methods employ a fixed draft length, which ignores the token generation difficulty across tasks. Consequently, in this paper, we address such an issue and introdu...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 15. Recent researches on video large language models (VideoLLM) predominantly focus on model architectures and training datasets, leaving the interaction format between the user and the model under-explored. In existing works, users often interact with VideoLLMs by using the entire video and a query as ...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 16. Blind all-in-one image restoration models aim to recover a high-quality image from an input degraded with unknown distortions. However, these models require all the possible degradation types to be defined during the training stage while showing limited generalization to unseen degradations, which l...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 17. Identifying key pathological features in brain MRIs is crucial for the long-term survival of glioma patients. However, manual segmentation is time-consuming, requiring expert intervention and is susceptible to human error. Therefore, significant research has been devoted to developing machine learni...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 18. Generating sound effects for videos often requires creating artistic sound effects that diverge significantly from real-life sources and flexible control in the sound design. To address this problem, we introduce MultiFoley, a model designed for video-guided sound generation that supports multimodal...
[28.11.2024 17:42] ********************************************************************************
[28.11.2024 17:42] Abstract 19. The rapid advancement of large language models (LLMs) such as GPT-3, PaLM, and Llama has significantly transformed natural language processing, showcasing remarkable capabilities in understanding and generating language. However, these models often struggle with tasks requiring complex reasoning, pa...
[28.11.2024 17:42] Read previous papers.
[28.11.2024 17:42] Generating reviews via LLM API.
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#multimodal"], "emoji": "🖼️", "ru": {"title": "Точный контроль над областями в генеративных моделях изображений", "desc": "Статья представляет новый метод улучшения диффузионных моделей для генерации изображений - ROICtrl. Он позволяет точно контролировать отдел
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#video", "#3d", "#optimization", "#benchmark", "#diffusion"], "emoji": "🎥", "ru": {"title": "Превращение 2D-видео в динамичные 3D-сцены", "desc": "CAT4D - это метод создания динамических 3D-сцен из монокулярного видео с использованием многоракурсной видео-диффузионной модели. Модель
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#interpretability", "#multimodal", "#agents", "#games", "#benchmark"], "emoji": "🔄", "ru": {"title": "ISG: Новый подход к оценке генерации мультимодального контента", "desc": "Статья представляет ISG - комплексную систему оценки для генерации чередующегося текста и изображений. ISG 
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#3d", "#open_source", "#diffusion", "#hallucinations", "#dataset"], "emoji": "🌟", "ru": {"title": "Революция в 3D: от текста к реалистичным объектам", "desc": "Статья представляет MARVEL-40M+, масштабный набор данных с 40 миллионами текстовых аннотаций для более чем 8,9 миллионов 3D
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#dataset", "#survey", "#benchmark"], "emoji": "🤖", "ru": {"title": "LLM-агенты революционизируют взаимодействие человека с компьютером через GUI", "desc": "Статья представляет обзор агентов с графическим интерфейсом пользователя (GUI), основанных на больших
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#diffusion", "#architecture", "#cv", "#training"], "emoji": "🎨", "ru": {"title": "DreamCache: эффективная персонализация генерации изображений", "desc": "DreamCache - это новый подход к персонализированной генерации изображений, использующий кэширование признаков из подмножества сло
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#architecture", "#inference", "#optimization", "#small_models", "#cv"], "emoji": "🖼️", "ru": {"title": "Эффективное сотрудничество моделей для быстрой генерации изображений", "desc": "Статья представляет новую стратегию декодирования для визуального авторегрессионного моделирования 
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#video", "#architecture", "#diffusion", "#optimization", "#training", "#multimodal"], "emoji": "🎭", "ru": {"title": "Сохранение идентичности в видео через частотный анализ", "desc": "Статья представляет ConsisID - модель для генерации видео с сохранением идентичности человека на осн
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#agents", "#optimization", "#robotics", "#dataset", "#diffusion"], "emoji": "🚗", "ru": {"title": "Ускоренная диффузионная модель для разнообразного и эффективного автономного вождения", "desc": "Статья представляет новую модель DiffusionDrive для автономного вождения, основанную на 
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#benchmark", "#3d"], "emoji": "📐", "ru": {"title": "3D Convex Splatting: Новый уровень реконструкции сцен с помощью выпуклых примитивов", "desc": "Статья представляет новый метод 3D Convex Splatting (3DCS) для реконструкции радиационных полей из многоракурсных изображений. В отличие
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#3d"], "emoji": "🦾", "ru": {"title": "Мгновенная анимация для любого 3D-персонажа", "desc": "Статья представляет новый метод под названием Make-It-Animatable для автоматической подготовки 3D-моделей гуманоидных персонажей к анимации. Метод использует нейронные сети для генерации вес
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#video", "#inference"], "emoji": "🔍", "ru": {"title": "Омега-параметр: тонкая настройка детализации в диффузионных моделях", "desc": "Статья представляет новый параметр омега для контроля детализации в диффузионных моделях. Этот параметр внедряется в процесс ден
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#agi", "#architecture", "#multimodal", "#dataset", "#cv", "#optimization", "#games"], "emoji": "🧠", "ru": {"title": "ChatRex: объединение восприятия и понимания в компьютерном зрении", "desc": "Статья представляет ChatRex - новую мультимодальную большую языковую модель (MLLM) с улуч
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#multimodal", "#transfer_learning", "#3d", "#cv"], "emoji": "🤖", "ru": {"title": "UniPose: универсальная система для работы с позами человека на основе LLM", "desc": "UniPose - это новая система, использующая большие языковые модели (LLM) для понимания, генерации и редактирования по
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#training", "#inference", "#optimization", "#long_context", "#benchmark"], "emoji": "🚀", "ru": {"title": "Адаптивное спекулятивное декодирование для ускорения языковых моделей", "desc": "Статья представляет SVIP - новый метод для ускорения вывода больших языковых моделей с помощью с
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#benchmark", "#games", "#video"], "emoji": "🎭", "ru": {"title": "Видео-текстовый дуэт: новый формат взаимодействия для VideoLLM", "desc": "Эта статья представляет новый формат взаимодействия с видео-языковыми моделями (VideoLLM), названный 'видео-текстов
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#dataset", "#training", "#cv"], "emoji": "🖼️", "ru": {"title": "Адаптивное восстановление изображений с улучшенным обобщением", "desc": "Статья представляет адаптивную модель ABAIR для всестороннего восстановления изображений. Модель способна обрабатывать множественные искажения, хо
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#multimodal", "#healthcare", "#optimization", "#cv", "#3d", "#open_source", "#dataset"], "emoji": "🧠", "ru": {"title": "MedNeXt: точная сегментация опухолей мозга для разных групп пациентов", "desc": "Статья описывает метод сегментации опухолей головного мозга на МРТ-снимках с испол
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#audio", "#dataset", "#multimodal"], "emoji": "🎬", "ru": {"title": "MultiFoley: Искусственный интеллект озвучивает ваши видео", "desc": "MultiFoley - это модель для генерации звуковых эффектов для видео с поддержкой мультимодального ввода (текст, аудио, видео). Она позволяет создава
[28.11.2024 17:42] Using data from previous issue: {"categories": ["#synthetic", "#data", "#reasoning", "#open_source", "#dataset"], "emoji": "🧮", "ru": {"title": "Автоматическая генерация математических задач для обучения ИИ", "desc": "В статье представлен новый подход к генерации данных для обучения языковых моделей (LLM) решению математических за
[28.11.2024 17:42] Loading Chinese text from previous data.
[28.11.2024 17:42] Renaming data file.
[28.11.2024 17:42] Renaming previous data. hf_papers.json to ./d/2024-11-28.json
[28.11.2024 17:42] Saving new data file.
[28.11.2024 17:42] Generating page.
[28.11.2024 17:42] Renaming previous page.
[28.11.2024 17:42] Renaming previous data. index.html to ./d/2024-11-28.html
[28.11.2024 17:42] [Experimental] Generating Chinese page for reading.
[28.11.2024 17:42] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '自然语言', 'pinyin': 'zì rán yǔ yán', 'trans': 'natural language'}, {'word': '处理', 'pinyin': 'chǔ lǐ', 'trans': 'process'}, {'word': '多实例', 'pinyin': 'duō shí lì', 'trans': 'multiple instances'}, {'word': '位置', 'pinyin': 'wèi zhì', 'trans': 'position'}, {'word': '属性', 'pinyin': 'shǔ xìng', 'trans': 'attribute'}, {'word': '信息', 'pinyin': 'xìn xī', 'trans': 'information'}, {'word': '局限性', 'pinyin': 'jú xiàn xìng', 'trans': 'limitation'}, {'word': '解决', 'pinyin': 'jiě jué', 'trans': 'solve'}, {'word': '问题', 'pinyin': 'wèn tí', 'trans': 'problem'}, {'word': '作者', 'pinyin': 'zuò zhě', 'trans': 'author'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '基于', 'pinyin': 'jī yú', 'trans': 'based on'}, {'word': '区域', 'pinyin': 'qū yù', 'trans': 'region'}, {'word': '实例', 'pinyin': 'shí lì', 'trans': 'instance'}, {'word': '控制', 'pinyin': 'kòng zhì', 'trans': 'control'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': '引入', 'pinyin': 'yǐn rù', 'trans': 'introduce'}, {'word': 'ROI-Unpool', 'pinyin': 'ROI-Unpool', 'trans': 'ROI-Unpool'}, {'word': '操作', 'pinyin': 'cāo zuò', 'trans': 'operation'}, {'word': '结合', 'pinyin': 'jié hé', 'trans': 'combine'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}, {'word': '高效', 'pinyin': 'gāo xiào', 'trans': 'efficient'}, {'word': '准确', 'pinyin': 'zhǔn què', 'trans': 'accurate'}, {'word': '适配器', 'pinyin': 'shì pèi qì', 'trans': 'adapter'}, {'word': '精确', 'pinyin': 'jīng què', 'trans': 'precise'}, {'word': '表明', 'pinyin': 'biǎo míng', 'trans': 'indicate'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '优异', 'pinyin': 'yōu yì', 'trans': 'excellent'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '降低', 'pinyin': 'jiàng dī', 'trans': 'reduce'}, {'word': '计算', 'pinyin': 'jì suàn', 'trans': 'computation'}, {'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'}]
[28.11.2024 17:42] Renaming previous Chinese page.
[28.11.2024 17:42] Renaming previous data. zh.html to ./d/2024-11-27_zh_reading_task.html
[28.11.2024 17:42] Writing Chinese reading task.
[28.11.2024 17:42] Writing result.
[28.11.2024 17:42] Renaming log file.
[28.11.2024 17:42] Renaming previous data. log.txt to ./logs/2024-11-28_last_log.txt
