[21.08.2025 08:16] Read previous papers.
[21.08.2025 08:16] Generating top page (month).
[21.08.2025 08:16] Writing top page (month).
[21.08.2025 09:12] Read previous papers.
[21.08.2025 09:12] Get feed.
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13491
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.11987
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14811
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14879
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14111
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14896
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14160
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14460
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14444
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14187
[21.08.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2508.13680
[21.08.2025 09:12] Extract page data from URL. URL: https://huggingface.co/papers/2508.11408
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10137
[21.08.2025 09:12] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13745
[21.08.2025 09:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.08.2025 09:12] No deleted papers detected.
[21.08.2025 09:12] Downloading and parsing papers (pdf, html). Total: 14.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.13491.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.13491.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.13491.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.11987.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.11987.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.11987.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14811.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14811.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14811.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14879.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14879.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14879.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14111.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14111.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14111.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14896.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14896.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14896.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14160.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14160.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14160.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14460.
[21.08.2025 09:12] Downloading paper 2508.14460 from http://arxiv.org/pdf/2508.14460v1...
[21.08.2025 09:12] Failed to download and parse paper https://huggingface.co/papers/2508.14460: 'LTChar' object is not iterable
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14444.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14444.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14444.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.14187.
[21.08.2025 09:12] Extra JSON file exists (./assets/json/2508.14187.json), skip PDF parsing.
[21.08.2025 09:12] Paper image links file exists (./assets/img_data/2508.14187.json), skip HTML parsing.
[21.08.2025 09:12] Success.
[21.08.2025 09:12] Downloading and parsing paper https://huggingface.co/papers/2508.13680.
[21.08.2025 09:12] Downloading paper 2508.13680 from http://arxiv.org/pdf/2508.13680v1...
[21.08.2025 09:13] Extracting affiliations from text.
[21.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 0 8 6 3 1 . 8 0 5 2 : r ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions? Vy Tuong Dang*, An Vo*, Quang Tau, Duc Dm, Daeyoung Kim KAIST {vydang, anvo, quangtau, ducdm200158, kimd}@kaist.ac.kr Abstract VLMs fail to interpret traffic signals and rules Vision language models (VLMs) demonstrate remarkable capabilities on English multimodal tasks, but their performance on low-resource languages with genuinely multimodal educational content remains largely unexplored. In this work, we test how VLMs perform on Vietnamese educational assessments, investigating whether VLMs trained predominantly on English data can handle real-world cross-lingual multimodal reasoning. Our work presents the first comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams through proposing ViExam, benchmark containing 2,548 mulimodal questions. We find that state-of-the-art VLMs achieve only 57.74% while open-source models achieved 27.70% mean accuracy across 7 academic domains, including Mathematics, Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs underperform average human testtakers (66.54%), with only the thinking VLM o3 (74.07%) exceeding human average performance, yet still falling substantially short of human best performance (99.60%). Crosslingual prompting with English instructions while maintaining Vietnamese content fails to improve performance, decreasing accuracy by 1 percentage point for SOTA VLMs. Humanin-the-loop collaboration can partially improve VLM performance by 5 percentage points. Code and data are available at: https://vi-exam.github.io. Vision Language Models (VLMs) have achieved remarkable success on English multimodal benchmarks (e.g., o3 achieving 82.9% on MMMU (Yue et al. 2024)). However, their performance on low-resource languages remains largely unexplored. Vietnamese is the worlds 10th most spoken language with over 100 million native speakers, making i"
[21.08.2025 09:13] Response: ```python
["KAIST"]
```
[21.08.2025 09:13] Deleting PDF ./assets/pdf/2508.13680.pdf.
[21.08.2025 09:13] Success.
[21.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.11408.
[21.08.2025 09:13] Downloading paper 2508.11408 from http://arxiv.org/pdf/2508.11408v1...
[21.08.2025 09:13] Extracting affiliations from text.
[21.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ON-POLICY RL MEETS OFF-POLICY EXPERTS: HARMONIZING SUPERVISED FINE-TUNING AND REINFORCEMENT LEARNING VIA DYNAMIC WEIGHTING 5 2 0 2 5 1 ] . [ 1 8 0 4 1 1 . 8 0 5 2 : r Wenhao Zhang, Yuexiang Xie, Yuchang Sun, Yanxi Chen, Guoyin Wang, Yaliang Li, Bolin Ding, Jingren Zhou Alibaba Group "
[21.08.2025 09:13] Response: ```python
["Alibaba Group"]
```
[21.08.2025 09:13] Deleting PDF ./assets/pdf/2508.11408.pdf.
[21.08.2025 09:13] Success.
[21.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.10137.
[21.08.2025 09:13] Extra JSON file exists (./assets/json/2508.10137.json), skip PDF parsing.
[21.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.10137.json), skip HTML parsing.
[21.08.2025 09:13] Success.
[21.08.2025 09:13] Downloading and parsing paper https://huggingface.co/papers/2508.13745.
[21.08.2025 09:13] Extra JSON file exists (./assets/json/2508.13745.json), skip PDF parsing.
[21.08.2025 09:13] Paper image links file exists (./assets/img_data/2508.13745.json), skip HTML parsing.
[21.08.2025 09:13] Success.
[21.08.2025 09:13] Enriching papers with extra data.
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 0. FinCDM, a cognitive diagnosis framework, evaluates financial LLMs at the knowledge-skill level using a comprehensive dataset, revealing hidden knowledge gaps and supporting more trustworthy model development.  					AI-generated summary 				 Large Language Models (LLMs) have shown promise for financi...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 1. FutureX is a dynamic, live benchmark for evaluating LLM agents in future prediction tasks, addressing challenges in real-time updates and data contamination.  					AI-generated summary 				 Future prediction is a complex task for LLM agents, requiring a high level of analytical thinking, information...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 2. Tinker is a framework for high-fidelity 3D editing using pretrained diffusion models, enabling multi-view consistency with minimal per-scene training.  					AI-generated summary 				 We introduce Tinker, a versatile framework for high-fidelity 3D editing that operates in both one-shot and few-shot r...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 3. MeshCoder reconstructs complex 3D objects from point clouds into editable Blender Python scripts, enhancing shape-to-code reconstruction and 3D shape understanding through a multimodal large language model.  					AI-generated summary 				 Reconstructing 3D objects into editable programs is pivotal f...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 4. Agentic Science leverages large language models, multimodal systems, and integrated platforms to enable autonomous scientific discovery across various domains, encompassing hypothesis generation, experimental design, execution, analysis, and iterative refinement.  					AI-generated summary 				 Arti...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 5. A systematic study on quantizing diffusion large language models identifies challenges and evaluates state-of-the-art methods across various configurations to improve deployment on edge devices.  					AI-generated summary 				 Recent advances in diffusion large language models (dLLMs) have introduce...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 6. RynnEC, a video multimodal large language model with a region-centric approach, achieves state-of-the-art performance in object property understanding, segmentation, and spatial reasoning, using an egocentric video pipeline and a region-centered benchmark.  					AI-generated summary 				 We introduc...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 7. DuPO is a dual learning framework that generates annotation-free feedback using a generalized duality, enhancing performance across various tasks without relying on costly labels.  					AI-generated summary 				 We present DuPO, a dual learning-based preference optimization framework that generates ...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 8. Nemotron-Nano-9B-v2, a hybrid Mamba-Transformer model, enhances reasoning workload throughput and accuracy by replacing self-attention layers with Mamba-2 layers and using the Minitron strategy for compression.  					AI-generated summary 				 We introduce Nemotron-Nano-9B-v2, a hybrid Mamba-Transfor...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 9. A deep equilibrium canonicalizer (DEC) enhances local scale equivariance in deep networks, improving performance and consistency on ImageNet.  					AI-generated summary 				 Scale variation is a fundamental challenge in computer vision. Objects of the same class can have different sizes, and their p...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 10. VLMs perform poorly on Vietnamese educational assessments, with state-of-the-art models achieving lower accuracy than human test-takers, and cross-lingual prompting does not significantly improve performance.  					AI-generated summary 				 Vision language models (VLMs) demonstrate remarkable capabi...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 11. CHORD integrates supervised fine-tuning and reinforcement learning by dynamically weighting off-policy and on-policy data to improve model stability and performance.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 12. A multilingual benchmark evaluates the reasoning skills of large language models across different languages and cultures, revealing their limitations in nuanced commonsense understanding.  					AI-generated summary 				 Recent advancements in reasoning-reinforced Large Language Models (LLMs) have sh...
[21.08.2025 09:13] ********************************************************************************
[21.08.2025 09:13] Abstract 13. A novel framework, REARM, enhances multi-modal recommender systems by refining contrastive learning and homography relations, improving feature representation and user-item interaction mining.  					AI-generated summary 				 Multi-modal recommender system focuses on utilizing rich modal information ...
[21.08.2025 09:13] Read previous papers.
[21.08.2025 09:13] Generating reviews via LLM API.
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#dataset", "#interpretability", "#science"], "emoji": "💹", "ru": {"title": "FinCDM: Точная диагностика финансовых ИИ-моделей", "desc": "FinCDM - это новая система оценки больших языковых моделей (LLM) в финансовой сфере на уровне знаний и навыков. Она и
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#agents", "#survey", "#benchmark", "#reasoning"], "emoji": "🔮", "ru": {"title": "FutureX: Живой бенчмарк для оценки прогнозирования будущего ИИ-агентами", "desc": "FutureX - это динамический живой бенчмарк для оценки агентов на основе больших языковых моделей (LLM) в задачах прогноз
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#diffusion", "#3d"], "emoji": "🎨", "ru": {"title": "Tinker: Революция в 3D-редактировании без дополнительного обучения", "desc": "Tinker - это фреймворк для высокоточного 3D-редактирования с использованием предобученных диффузионных моделей. Он обеспечив
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#multimodal", "#dataset", "#synthetic", "#3d", "#reasoning"], "emoji": "🧊", "ru": {"title": "От облака точек к коду: MeshCoder открывает новые возможности 3D-реконструкции", "desc": "MeshCoder - это новая система, которая преобразует сложные 3D-объекты из облаков точек в редактируем
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#healthcare", "#survey", "#science", "#multimodal", "#agents"], "emoji": "🧪", "ru": {"title": "ИИ как автономный научный исследователь", "desc": "Статья представляет концепцию 'Агентной науки', которая использует большие языковые модели, мультимодальные системы и интегрированные пла
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference", "#diffusion", "#open_source"], "emoji": "🔬", "ru": {"title": "Квантование диффузионных ЯМ: вызовы и решения", "desc": "Это исследование посвящено квантованию диффузионных больших языковых моделей (dLLMs) для их развертывания на устройствах 
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#multimodal", "#agents", "#video", "#3d", "#games", "#agi", "#reasoning"], "emoji": "🤖", "ru": {"title": "RynnEC: Новый уровень понимания видео для воплощенного ИИ", "desc": "RynnEC - это мультимодальная языковая модель большого масштаба для видео, исп
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#machine_translation", "#rlhf", "#reasoning", "#optimization", "#training", "#rl"], "emoji": "🔄", "ru": {"title": "DuPO: Оптимизация без аннотаций через двойственность", "desc": "DuPO - это фреймворк двойного обучения, который генерирует обратную связь без аннотаций, используя обобщ
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#optimization", "#training", "#inference", "#open_source", "#architecture"], "emoji": "🧠", "ru": {"title": "Nemotron-Nano-9B-v2: Быстрее думай, лучше рассуждай", "desc": "Nemotron-Nano-9B-v2 - это гибридная модель языка, сочетающая архитектуры Mamba и Trans
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#architecture"], "emoji": "🔍", "ru": {"title": "Повышение устойчивости нейросетей к изменениям масштаба объектов", "desc": "Статья представляет глубокий эквилибриумный канонизатор (DEC) для улучшения локальной масштабной эквивариантности в глубоких нейронных сет
[21.08.2025 09:13] Querying the API.
[21.08.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

VLMs perform poorly on Vietnamese educational assessments, with state-of-the-art models achieving lower accuracy than human test-takers, and cross-lingual prompting does not significantly improve performance.  					AI-generated summary 				 Vision language models (VLMs) demonstrate remarkable capabilities on English multimodal tasks, but their performance on low-resource languages with genuinely multimodal educational content remains largely unexplored. In this work, we test how VLMs perform on Vietnamese educational assessments, investigating whether VLMs trained predominantly on English data can handle real-world cross-lingual multimodal reasoning. Our work presents the first comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams through proposing ViExam, a benchmark containing 2,548 multimodal questions. We find that state-of-the-art VLMs achieve only 57.74% while open-source models achieve 27.70% mean accuracy across 7 academic domains, including Mathematics, Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs underperform average human test-takers (66.54%), with only the thinking VLM o3 (74.07%) exceeding human average performance, yet still falling substantially short of human best performance (99.60%). Cross-lingual prompting with English instructions while maintaining Vietnamese content fails to improve performance, decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop collaboration can partially improve VLM performance by 5 percentage points. Code and data are available at: https://vi-exam.github.io.
[21.08.2025 09:13] Response: {
  "desc": "Исследование оценивает производительность визуально-языковых моделей (VLM) на вьетнамских образовательных тестах. Создан бенчмарк ViExam, содержащий 2,548 мультимодальных вопросов по 7 академическим областям. Результаты показывают, что современные VLM достигают точности только 57.74%, что ниже среднего результата человека (66.54%). Кросс-языковые подсказки на английском не улучшают производительность моделей.",
  "emoji": "🇻🇳",
  "title": "VLM отстают от людей на вьетнамских образовательных тестах"
}
[21.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VLMs perform poorly on Vietnamese educational assessments, with state-of-the-art models achieving lower accuracy than human test-takers, and cross-lingual prompting does not significantly improve performance.  					AI-generated summary 				 Vision language models (VLMs) demonstrate remarkable capabilities on English multimodal tasks, but their performance on low-resource languages with genuinely multimodal educational content remains largely unexplored. In this work, we test how VLMs perform on Vietnamese educational assessments, investigating whether VLMs trained predominantly on English data can handle real-world cross-lingual multimodal reasoning. Our work presents the first comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams through proposing ViExam, a benchmark containing 2,548 multimodal questions. We find that state-of-the-art VLMs achieve only 57.74% while open-source models achieve 27.70% mean accuracy across 7 academic domains, including Mathematics, Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs underperform average human test-takers (66.54%), with only the thinking VLM o3 (74.07%) exceeding human average performance, yet still falling substantially short of human best performance (99.60%). Cross-lingual prompting with English instructions while maintaining Vietnamese content fails to improve performance, decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop collaboration can partially improve VLM performance by 5 percentage points. Code and data are available at: https://vi-exam.github.io."

[21.08.2025 09:13] Response: ```python
['DATASET', 'BENCHMARK', 'MULTILINGUAL']
```
[21.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"VLMs perform poorly on Vietnamese educational assessments, with state-of-the-art models achieving lower accuracy than human test-takers, and cross-lingual prompting does not significantly improve performance.  					AI-generated summary 				 Vision language models (VLMs) demonstrate remarkable capabilities on English multimodal tasks, but their performance on low-resource languages with genuinely multimodal educational content remains largely unexplored. In this work, we test how VLMs perform on Vietnamese educational assessments, investigating whether VLMs trained predominantly on English data can handle real-world cross-lingual multimodal reasoning. Our work presents the first comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams through proposing ViExam, a benchmark containing 2,548 multimodal questions. We find that state-of-the-art VLMs achieve only 57.74% while open-source models achieve 27.70% mean accuracy across 7 academic domains, including Mathematics, Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs underperform average human test-takers (66.54%), with only the thinking VLM o3 (74.07%) exceeding human average performance, yet still falling substantially short of human best performance (99.60%). Cross-lingual prompting with English instructions while maintaining Vietnamese content fails to improve performance, decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop collaboration can partially improve VLM performance by 5 percentage points. Code and data are available at: https://vi-exam.github.io."

[21.08.2025 09:13] Response: ```python
["LOW_RESOURCE", "OPEN_SOURCE"]
```
[21.08.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper evaluates the performance of Vision Language Models (VLMs) on Vietnamese educational assessments, revealing that these models struggle significantly compared to human test-takers. The study introduces ViExam, a benchmark with 2,548 multimodal questions across various academic domains, highlighting that state-of-the-art VLMs achieve only 57.74% accuracy. Despite attempts to enhance performance through cross-lingual prompting, results show a decline in accuracy, indicating that VLMs trained on English data are not effectively handling Vietnamese content. The findings suggest that while human-in-the-loop strategies can improve outcomes, VLMs still fall short of human performance, emphasizing the need for better adaptation to low-resource languages.","title":"Bridging the Gap: VLMs Struggle with Vietnamese Education"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper evaluates the performance of Vision Language Models (VLMs) on Vietnamese educational assessments, revealing that these models struggle significantly compared to human test-takers. The study introduces ViExam, a benchmark with 2,548 multimodal questions across various academic domains, highlighting that state-of-the-art VLMs achieve only 57.74% accuracy. Despite attempts to enhance performance through cross-lingual prompting, results show a decline in accuracy, indicating that VLMs trained on English data are not effectively handling Vietnamese content. The findings suggest that while human-in-the-loop strategies can improve outcomes, VLMs still fall short of human performance, emphasizing the need for better adaptation to low-resource languages.', title='Bridging the Gap: VLMs Struggle with Vietnamese Education'))
[21.08.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究探讨了视觉语言模型（VLMs）在越南教育评估中的表现，发现这些模型在处理低资源语言的多模态内容时效果不佳。尽管在英语多模态任务上表现出色，但在越南的多模态考试中，最先进的模型仅达到57.74%的准确率，远低于人类考生的66.54%。我们提出了ViExam基准，包含2548个多模态问题，以全面评估VLM在越南教育中的能力。研究还发现，跨语言提示并未显著提高模型性能，反而使准确率下降。","title":"越南教育评估中的视觉语言模型表现不佳"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究探讨了视觉语言模型（VLMs）在越南教育评估中的表现，发现这些模型在处理低资源语言的多模态内容时效果不佳。尽管在英语多模态任务上表现出色，但在越南的多模态考试中，最先进的模型仅达到57.74%的准确率，远低于人类考生的66.54%。我们提出了ViExam基准，包含2548个多模态问题，以全面评估VLM在越南教育中的能力。研究还发现，跨语言提示并未显著提高模型性能，反而使准确率下降。', title='越南教育评估中的视觉语言模型表现不佳'))
[21.08.2025 09:13] Querying the API.
[21.08.2025 09:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CHORD integrates supervised fine-tuning and reinforcement learning by dynamically weighting off-policy and on-policy data to improve model stability and performance.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms for refining the capabilities and aligning the behavior of Large Language Models (LLMs). Existing approaches that integrate SFT and RL often face the risk of disrupting established model patterns and inducing overfitting to expert data. To address this, we present a novel investigation into the unified view of SFT and RL through an off-policy versus on-policy lens. We propose CHORD, a framework for the Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting, which reframes SFT not as a separate stage but as a dynamically weighted auxiliary objective within the on-policy RL process. Based on an analysis of off-policy expert data's influence at both holistic and granular levels, we incorporate a dual-control mechanism in CHORD. Specifically, the framework first employs a global coefficient to holistically guide the transition from off-policy imitation to on-policy exploration, and then applies a token-wise weighting function that enables granular learning from expert tokens, which preserves on-policy exploration and mitigates disruption from off-policy data. We conduct extensive experiments on widely used benchmarks, providing empirical evidence that CHORD achieves a stable and efficient learning process. By effectively harmonizing off-policy expert data with on-policy exploration, CHORD demonstrates significant improvements over baselines. We release the implementation at https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to inspire further research.
[21.08.2025 09:13] Response: {
  "desc": "Статья представляет новый метод CHORD для интеграции обучения с учителем и обучения с подкреплением в контексте больших языковых моделей. CHORD динамически взвешивает офф-полиси и он-полиси данные, что позволяет улучшить стабильность и производительность модели. Метод использует глобальный коэффициент для перехода от имитации к исследованию, а также токен-специфичную функцию взвешивания. Эксперименты показывают, что CHORD достигает значительных улучшений по сравнению с базовыми методами.",
  "emoji": "🎼",
  "title": "Гармоничное объединение обучения с учителем и с подкреплением для больших языковых моделей"
}
[21.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CHORD integrates supervised fine-tuning and reinforcement learning by dynamically weighting off-policy and on-policy data to improve model stability and performance.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms for refining the capabilities and aligning the behavior of Large Language Models (LLMs). Existing approaches that integrate SFT and RL often face the risk of disrupting established model patterns and inducing overfitting to expert data. To address this, we present a novel investigation into the unified view of SFT and RL through an off-policy versus on-policy lens. We propose CHORD, a framework for the Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting, which reframes SFT not as a separate stage but as a dynamically weighted auxiliary objective within the on-policy RL process. Based on an analysis of off-policy expert data's influence at both holistic and granular levels, we incorporate a dual-control mechanism in CHORD. Specifically, the framework first employs a global coefficient to holistically guide the transition from off-policy imitation to on-policy exploration, and then applies a token-wise weighting function that enables granular learning from expert tokens, which preserves on-policy exploration and mitigates disruption from off-policy data. We conduct extensive experiments on widely used benchmarks, providing empirical evidence that CHORD achieves a stable and efficient learning process. By effectively harmonizing off-policy expert data with on-policy exploration, CHORD demonstrates significant improvements over baselines. We release the implementation at https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to inspire further research."

[21.08.2025 09:13] Response: ```python
["RL", "RLHF", "TRAINING", "BENCHMARK"]
```
[21.08.2025 09:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CHORD integrates supervised fine-tuning and reinforcement learning by dynamically weighting off-policy and on-policy data to improve model stability and performance.  					AI-generated summary 				 Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two prominent post-training paradigms for refining the capabilities and aligning the behavior of Large Language Models (LLMs). Existing approaches that integrate SFT and RL often face the risk of disrupting established model patterns and inducing overfitting to expert data. To address this, we present a novel investigation into the unified view of SFT and RL through an off-policy versus on-policy lens. We propose CHORD, a framework for the Controllable Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic Weighting, which reframes SFT not as a separate stage but as a dynamically weighted auxiliary objective within the on-policy RL process. Based on an analysis of off-policy expert data's influence at both holistic and granular levels, we incorporate a dual-control mechanism in CHORD. Specifically, the framework first employs a global coefficient to holistically guide the transition from off-policy imitation to on-policy exploration, and then applies a token-wise weighting function that enables granular learning from expert tokens, which preserves on-policy exploration and mitigates disruption from off-policy data. We conduct extensive experiments on widely used benchmarks, providing empirical evidence that CHORD achieves a stable and efficient learning process. By effectively harmonizing off-policy expert data with on-policy exploration, CHORD demonstrates significant improvements over baselines. We release the implementation at https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to inspire further research."

[21.08.2025 09:13] Response: ```python
["OPTIMIZATION"]
```
[21.08.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CHORD is a new framework that combines supervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the performance of large language models. It addresses the common issue of model instability and overfitting by dynamically adjusting the influence of off-policy and on-policy data during training. By treating SFT as a flexible part of the RL process, CHORD allows for better integration of expert data while maintaining effective exploration. The framework\'s dual-control mechanism ensures that learning is both stable and efficient, leading to improved outcomes in various benchmarks.","title":"Harmonizing Learning: CHORD\'s Dynamic Integration of SFT and RL"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="CHORD is a new framework that combines supervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the performance of large language models. It addresses the common issue of model instability and overfitting by dynamically adjusting the influence of off-policy and on-policy data during training. By treating SFT as a flexible part of the RL process, CHORD allows for better integration of expert data while maintaining effective exploration. The framework's dual-control mechanism ensures that learning is both stable and efficient, leading to improved outcomes in various benchmarks.", title="Harmonizing Learning: CHORD's Dynamic Integration of SFT and RL"))
[21.08.2025 09:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CHORD框架通过动态加权的方式，将监督微调（SFT）和强化学习（RL）结合起来，以提高模型的稳定性和性能。该方法将SFT视为在强化学习过程中动态加权的辅助目标，而不是一个独立的阶段。CHORD采用双重控制机制，首先通过全局系数引导从离策略模仿到在策略探索的过渡，然后通过逐标记加权函数实现对专家标记的细粒度学习。实验结果表明，CHORD在多个基准测试中表现出显著的学习稳定性和效率提升。","title":"动态加权，提升模型稳定性与性能"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CHORD框架通过动态加权的方式，将监督微调（SFT）和强化学习（RL）结合起来，以提高模型的稳定性和性能。该方法将SFT视为在强化学习过程中动态加权的辅助目标，而不是一个独立的阶段。CHORD采用双重控制机制，首先通过全局系数引导从离策略模仿到在策略探索的过渡，然后通过逐标记加权函数实现对专家标记的细粒度学习。实验结果表明，CHORD在多个基准测试中表现出显著的学习稳定性和效率提升。', title='动态加权，提升模型稳定性与性能'))
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#survey", "#benchmark", "#multilingual", "#reasoning"], "emoji": "🌍", "ru": {"title": "Многоязычный тест раскрывает пробелы в здравом смысле ИИ", "desc": "Предложен многоязычный эталонный тест mSCoRe для оценки навыков рассуждений больших языковых моделей (LLM) в разных языках и кул
[21.08.2025 09:13] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#graphs", "#optimization", "#games"], "emoji": "🎯", "ru": {"title": "Точные рекомендации через улучшенное мультимодальное обучение", "desc": "REARM - это новая система для улучшения мультимодальных рекомендательных систем. Она использует усовершенствованно
[21.08.2025 09:13] Renaming data file.
[21.08.2025 09:13] Renaming previous data. hf_papers.json to ./d/2025-08-21.json
[21.08.2025 09:13] Saving new data file.
[21.08.2025 09:13] Generating page.
[21.08.2025 09:13] Renaming previous page.
[21.08.2025 09:13] Renaming previous data. index.html to ./d/2025-08-21.html
[21.08.2025 09:13] Writing result.
[21.08.2025 09:13] Renaming log file.
[21.08.2025 09:13] Renaming previous data. log.txt to ./logs/2025-08-21_last_log.txt
