[27.01.2025 10:11] Read previous papers.
[27.01.2025 10:11] Generating top page (month).
[27.01.2025 10:11] Writing top page (month).
[27.01.2025 11:08] Read previous papers.
[27.01.2025 11:08] Get feed.
[27.01.2025 11:08] Get page data from previous paper. URL: https://huggingface.co/papers/2501.14249
[27.01.2025 11:08] Get page data from previous paper. URL: https://huggingface.co/papers/2501.13953
[27.01.2025 11:08] Get page data from previous paper. URL: https://huggingface.co/papers/2501.14342
[27.01.2025 11:08] Get page data from previous paper. URL: https://huggingface.co/papers/2501.14492
[27.01.2025 11:08] Get page data from previous paper. URL: https://huggingface.co/papers/2501.14726
[27.01.2025 11:08] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.01.2025 11:08] No deleted papers detected.
[27.01.2025 11:08] Downloading and parsing papers (pdf, html). Total: 5.
[27.01.2025 11:08] Downloading and parsing paper https://huggingface.co/papers/2501.14249.
[27.01.2025 11:08] Extra JSON file exists (./assets/json/2501.14249.json), skip PDF parsing.
[27.01.2025 11:08] Paper image links file exists (./assets/img_data/2501.14249.json), skip HTML parsing.
[27.01.2025 11:08] Success.
[27.01.2025 11:08] Downloading and parsing paper https://huggingface.co/papers/2501.13953.
[27.01.2025 11:08] Extra JSON file exists (./assets/json/2501.13953.json), skip PDF parsing.
[27.01.2025 11:08] Paper image links file exists (./assets/img_data/2501.13953.json), skip HTML parsing.
[27.01.2025 11:08] Success.
[27.01.2025 11:08] Downloading and parsing paper https://huggingface.co/papers/2501.14342.
[27.01.2025 11:08] Extra JSON file exists (./assets/json/2501.14342.json), skip PDF parsing.
[27.01.2025 11:08] Paper image links file exists (./assets/img_data/2501.14342.json), skip HTML parsing.
[27.01.2025 11:08] Success.
[27.01.2025 11:08] Downloading and parsing paper https://huggingface.co/papers/2501.14492.
[27.01.2025 11:08] Extra JSON file exists (./assets/json/2501.14492.json), skip PDF parsing.
[27.01.2025 11:08] Paper image links file exists (./assets/img_data/2501.14492.json), skip HTML parsing.
[27.01.2025 11:08] Success.
[27.01.2025 11:08] Downloading and parsing paper https://huggingface.co/papers/2501.14726.
[27.01.2025 11:08] Extra JSON file exists (./assets/json/2501.14726.json), skip PDF parsing.
[27.01.2025 11:08] Paper image links file exists (./assets/img_data/2501.14726.json), skip HTML parsing.
[27.01.2025 11:08] Success.
[27.01.2025 11:08] Enriching papers with extra data.
[27.01.2025 11:08] ********************************************************************************
[27.01.2025 11:08] Abstract 0. Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabiliti...
[27.01.2025 11:08] ********************************************************************************
[27.01.2025 11:08] Abstract 1. With the rapid iteration of Multi-modality Large Language Models (MLLMs) and the evolving demands of the field, the number of benchmarks produced annually has surged into the hundreds. The rapid growth has inevitably led to significant redundancy among benchmarks. Therefore, it is crucial to take a ...
[27.01.2025 11:08] ********************************************************************************
[27.01.2025 11:08] Abstract 2. This paper introduces an approach for training o1-like RAG models that retrieve and reason over relevant information step by step before generating the final answer. Conventional RAG methods usually perform a single retrieval step before the generation process, which limits their effectiveness in ad...
[27.01.2025 11:08] ********************************************************************************
[27.01.2025 11:08] Abstract 3. Critiques are important for enhancing the performance of Large Language Models (LLMs), enabling both self-improvement and constructive feedback for others by identifying flaws and suggesting improvements. However, evaluating the critique capabilities of LLMs presents a significant challenge due to t...
[27.01.2025 11:08] ********************************************************************************
[27.01.2025 11:08] Abstract 4. We propose Relightable Full-Body Gaussian Codec Avatars, a new approach for modeling relightable full-body avatars with fine-grained details including face and hands. The unique challenge for relighting full-body avatars lies in the large deformations caused by body articulation and the resulting im...
[27.01.2025 11:08] Read previous papers.
[27.01.2025 11:08] Generating reviews via LLM API.
[27.01.2025 11:08] Using data from previous issue: {"categories": ["#benchmark", "#science", "#multimodal"], "emoji": "üß†", "ru": {"title": "–ù–æ–≤—ã–π —Ä—É–±–µ–∂ –¥–ª—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞: —Ç–µ—Å—Ç –Ω–∞ –ø—Ä–µ–¥–µ–ª–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º '–ü
[27.01.2025 11:08] Using data from previous issue: {"categories": ["#benchmark", "#survey"], "emoji": "üîç", "ru": {"title": "–ë–æ—Ä—å–±–∞ —Å –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å—é: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM). –ê–≤—Ç–æ—Ä—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç –∏–∑–±—ã—Ç–æ—á–Ω
[27.01.2025 11:08] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#rag", "#reasoning"], "emoji": "üîó", "ru": {"title": "CoRAG: –ü–æ—à–∞–≥–æ–≤—ã–π –ø–æ–∏—Å–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (RAG), –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ—à–∞–≥–æ–≤—ã–π –ø–æ–∏—Å–∫ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ
[27.01.2025 11:08] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ù–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –∏—Å—Ç–∏–Ω–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª LLM –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –º—ã—à–ª–µ–Ω–∏–∏", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –∫—Ä–∏—Ç–∏–∫–µ. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É
[27.01.2025 11:08] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "üï¥Ô∏è", "ru": {"title": "–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∞–≤–∞—Ç–∞—Ä–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –∞–≤–∞—Ç–∞—Ä–æ–≤ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é –ª–∏—Ü–∞ –∏ —Ä—É–∫. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –¥–µ–∫–æ–º–ø–æ
[27.01.2025 11:08] Loading Chinese text from previous data.
[27.01.2025 11:08] Renaming data file.
[27.01.2025 11:08] Renaming previous data. hf_papers.json to ./d/2025-01-27.json
[27.01.2025 11:08] Saving new data file.
[27.01.2025 11:08] Generating page.
[27.01.2025 11:08] Renaming previous page.
[27.01.2025 11:08] Renaming previous data. index.html to ./d/2025-01-27.html
[27.01.2025 11:08] [Experimental] Generating Chinese page for reading.
[27.01.2025 11:08] Chinese vocab [{'word': 'ËÆ®ËÆ∫', 'pinyin': 't«éo l√πn', 'trans': 'discuss'}, {'word': 'Â§ßÂûã', 'pinyin': 'd√† x√≠ng', 'trans': 'large-scale'}, {'word': 'ËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'y«î y√°n m√≥ x√≠ng', 'trans': 'language model'}, {'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ng l√¨', 'trans': 'ability'}, {'word': 'ËØÑ‰º∞', 'pinyin': 'p√≠ng g≈´', 'trans': 'evaluate'}, {'word': 'ÈáçË¶ÅÊÄß', 'pinyin': 'zh√≤ng y√†o x√¨ng', 'trans': 'importance'}, {'word': 'Áé∞Êúâ', 'pinyin': 'xi√†n y«íu', 'trans': 'existing'}, {'word': 'Âü∫ÂáÜÊµãËØï', 'pinyin': 'jƒ´ zh«în c√® sh√¨', 'trans': 'benchmark test'}, {'word': 'Êó†Ê≥ï', 'pinyin': 'w√∫ f«é', 'trans': 'unable'}, {'word': 'Ë∑ü‰∏ä', 'pinyin': 'gƒìn sh√†ng', 'trans': 'keep up with'}, {'word': 'ËøõÊ≠•', 'pinyin': 'j√¨n b√π', 'trans': 'progress'}, {'word': 'ÊµÅË°å', 'pinyin': 'li√∫ x√≠ng', 'trans': 'popular'}, {'word': 'ÂáÜÁ°ÆÁéá', 'pinyin': 'zh«în qu√® l«ú', 'trans': 'accuracy rate'}, {'word': 'Ëß£ÂÜ≥', 'pinyin': 'jiƒõ ju√©', 'trans': 'solve'}, {'word': 'ÂºïÂÖ•', 'pinyin': 'y«ên r√π', 'trans': 'introduce'}, {'word': '‰∫∫Á±ª', 'pinyin': 'r√©n l√®i', 'trans': 'human'}, {'word': 'ÊúÄÂêé', 'pinyin': 'zu√¨ h√≤u', 'trans': 'final'}, {'word': 'ËÄÉËØï', 'pinyin': 'k«éo sh√¨', 'trans': 'exam'}, {'word': 'Ë∑®Â≠¶Áßë', 'pinyin': 'ku√† xu√© kƒì', 'trans': 'interdisciplinary'}, {'word': 'Â§öÊ®°ÊÄÅ', 'pinyin': 'du≈ç m√≥ t√†i', 'trans': 'multimodal'}, {'word': 'ÂåÖÂê´', 'pinyin': 'bƒÅo h√°n', 'trans': 'contain'}, {'word': 'Êï∞Â≠¶', 'pinyin': 'sh√π xu√©', 'trans': 'mathematics'}, {'word': '‰∫∫ÊñáÂ≠¶Áßë', 'pinyin': 'r√©n w√©n xu√© kƒì', 'trans': 'humanities'}, {'word': 'Ëá™ÁÑ∂ÁßëÂ≠¶', 'pinyin': 'z√¨ r√°n kƒì xu√©', 'trans': 'natural sciences'}, {'word': 'È¢ÜÂüü', 'pinyin': 'l«êng y√π', 'trans': 'field'}, {'word': 'ÂºÄÂèë', 'pinyin': 'kƒÅi fƒÅ', 'trans': 'develop'}, {'word': '‰∏ìÂÆ∂', 'pinyin': 'zhuƒÅn jiƒÅ', 'trans': 'expert'}, {'word': 'ÊòéÁ°Æ', 'pinyin': 'm√≠ng qu√®', 'trans': 'clear'}, {'word': '‰∫íËÅîÁΩë', 'pinyin': 'h√π li√°n w«éng', 'trans': 'internet'}]
[27.01.2025 11:08] Renaming previous Chinese page.
[27.01.2025 11:08] Renaming previous data. zh.html to ./d/2025-01-26_zh_reading_task.html
[27.01.2025 11:08] Writing Chinese reading task.
[27.01.2025 11:08] Writing result.
[27.01.2025 11:08] Renaming log file.
[27.01.2025 11:08] Renaming previous data. log.txt to ./logs/2025-01-27_last_log.txt
