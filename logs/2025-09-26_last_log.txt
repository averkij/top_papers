[25.09.2025 23:10] Read previous papers.
[25.09.2025 23:10] Generating top page (month).
[25.09.2025 23:10] Writing top page (month).
[26.09.2025 00:50] Read previous papers.
[26.09.2025 00:50] Get feed.
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20328
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20317
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20354
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16990
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20360
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19580
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19244
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20358
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19760
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18480
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.18400
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14745
[26.09.2025 00:50] Get page data from previous paper. URL: https://huggingface.co/papers/2509.16080
[26.09.2025 00:50] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.09.2025 00:50] No deleted papers detected.
[26.09.2025 00:50] Downloading and parsing papers (pdf, html). Total: 13.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.20328.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.20328.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.20328.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.20317.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.20317.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.20317.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.20354.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.20354.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.20354.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16990.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16990.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16990.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.20360.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.20360.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.20360.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.19580.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.19580.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.19580.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.19244.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.19244.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.19244.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.20358.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.20358.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.20358.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.19760.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.19760.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.19760.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18480.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18480.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18480.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.18400.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.18400.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.18400.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.14745.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.14745.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.14745.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Downloading and parsing paper https://huggingface.co/papers/2509.16080.
[26.09.2025 00:50] Extra JSON file exists (./assets/json/2509.16080.json), skip PDF parsing.
[26.09.2025 00:50] Paper image links file exists (./assets/img_data/2509.16080.json), skip HTML parsing.
[26.09.2025 00:50] Success.
[26.09.2025 00:50] Enriching papers with extra data.
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 0. Veo 3, a generative video model, exhibits zero-shot capabilities across various visual tasks, suggesting a trajectory towards becoming a unified, generalist vision foundation model.  					AI-generated summary 				 The remarkable zero-shot capabilities of Large Language Models (LLMs) have propelled n...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 1. SIM-CoT, a plug-and-play training module, introduces step-level supervision to stabilize and enrich the latent reasoning space of implicit Chain-of-Thought methods, enhancing their performance and efficiency.  					AI-generated summary 				 Implicit Chain-of-Thought (CoT) methods present a promising...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 2. EmbeddingGemma, a lightweight text embedding model based on Gemma 3, achieves state-of-the-art performance with fewer parameters through encoder-decoder initialization, geometric embedding distillation, and spread-out regularization.  					AI-generated summary 				 We introduce EmbeddingGemma, a new...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 3. A Group Relative Policy Optimization (GRPO)-based method using BLEU as a reward signal outperforms standard SFT for open-format speech understanding tasks like Spoken Question Answering and Automatic Speech Translation.  					AI-generated summary 				 In this paper, we introduce a Group Relative Pol...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 4. EditVerse is a unified framework using self-attention for image and video generation and editing, achieving state-of-the-art performance with a scalable data pipeline and benchmark.  					AI-generated summary 				 Recent advances in foundation models highlight a clear trend toward unification and sc...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 5. Large Language Models are transforming various academic disciplines by enabling human-like conversation and enhancing performance in language-related tasks, while also presenting limitations and future challenges.  					AI-generated summary 				 Cutting-edge Artificial Intelligence (AI) techniques k...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 6. Lavida-O, a unified Masked Diffusion Model, excels in multimodal understanding and generation tasks, including object grounding, image editing, and high-resolution text-to-image synthesis, outperforming existing models with improved efficiency and quality.  					AI-generated summary 				 We propose ...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 7. PhysCtrl is a physics-grounded framework for generating realistic, controllable videos from images using a diffusion model with spatiotemporal attention and physics-based constraints.  					AI-generated summary 				 Existing video generation models excel at producing photo-realistic videos from text...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 8. Logics-Parsing, an end-to-end LVLM model enhanced with reinforcement learning, improves document parsing by optimizing layout analysis and reading order inference, achieving state-of-the-art performance on a diverse benchmark.  					AI-generated summary 				 Recent advances in Large Vision-Language ...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 9. SimpleFold, a flow-matching based protein folding model using general-purpose transformer blocks, achieves competitive performance with reduced complexity and improved efficiency.  					AI-generated summary 				 Protein folding models have achieved groundbreaking results typically via a combination ...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 10. A fine-tuned Atlas model (LLaMA-3.3-70B) achieves significant improvements in HTS code classification accuracy and cost-effectiveness compared to existing models.  					AI-generated summary 				 Accurate classification of products under the Harmonized Tariff Schedule (HTS) is a critical bottleneck i...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 11. Agent-assisted pull requests generated by Claude Code are largely accepted in open-source projects, with most requiring minimal human modification.  					AI-generated summary 				 Large language models (LLMs) are increasingly being integrated into software development processes. The ability to gener...
[26.09.2025 00:50] ********************************************************************************
[26.09.2025 00:50] Abstract 12. We present an open-source Python library for simulating two-dimensional incompressible Kelvin-Helmholtz instabilities in stratified shear flows. The solver employs a fractional-step projection method with spectral Poisson solution via Fast Sine Transform, achieving second-order spatial accuracy. Imp...
[26.09.2025 00:50] Read previous papers.
[26.09.2025 00:50] Generating reviews via LLM API.
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#video", "#multimodal", "#cv", "#reasoning", "#agi"], "emoji": "üé¨", "ru": {"title": "–û—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º—É –ø–æ–Ω–∏–º–∞–Ω–∏—é –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –º–∏—Ä–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤–∏–¥–µ–æ Veo 3 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–µ zero-shot —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#interpretability", "#training", "#reasoning", "#architecture"], "emoji": "üîó", "ru": {"title": "–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –Ω–µ—è–≤–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ø–æ—à–∞–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –≤—ã—è–≤–∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –≤ –Ω–µ—è–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö Chain-of-Thought (CoT) –¥–ª—è LLM, –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–∑-–∑–∞ 
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#low_resource", "#dataset", "#training", "#data", "#open_source", "#benchmark", "#architecture", "#small_models"], "emoji": "ü™∂", "ru": {"title": "–õ–µ–≥–∫–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ EmbeddingGemma - –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#training", "#machine_translation", "#audio", "#optimization", "#rl", "#rlhf"], "emoji": "üé§", "ru": {"title": "GRPO —Å BLEU-–≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ–º –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ—á–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç–æ–¥ Group Relative Policy Optimization (GRPO) –¥–ª—è –æ–±—É—á
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#games", "#dataset", "#video", "#multimodal", "#data", "#open_source", "#benchmark", "#cv", "#architecture", "#transfer_learning"], "emoji": "üé¨", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ", "desc": "EditVerse –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –µ–¥–∏–Ω—É—é –º–æ–¥–µ–ª—å –¥
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#survey", "#multimodal", "#science", "#machine_translation", "#dataset"], "emoji": "üéì", "ru": {"title": "LLM —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É—é—Ç –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–∑–æ—Ä —Ç–æ–≥–æ, –∫–∞–∫ Large Language Models (LLM) —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã, –æ—Ç –≥—É
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#multimodal", "#inference", "#benchmark", "#games", "#architecture", "#diffusion"], "emoji": "üé®", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Lavida-O - –µ–¥–∏–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Masked Diffusion Model –¥
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#dataset", "#video", "#diffusion", "#synthetic", "#3d", "#architecture"], "emoji": "‚öõÔ∏è", "ru": {"title": "–§–∏–∑–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤", "desc": "PhysCtrl - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#rl", "#dataset", "#survey", "#benchmark", "#cv", "#optimization"], "emoji": "üìÑ", "ru": {"title": "–£–º–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ Logics-Parsing - –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (LVLM), –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–µ–Ω–∞ 
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#inference", "#training", "#optimization", "#benchmark", "#architecture", "#dataset", "#science"], "emoji": "üß¨", "ru": {"title": "–ü—Ä–æ—Å—Ç–æ—Ç–∞ –ø–æ–±–µ–∂–¥–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤ —Å–≤–æ—Ä–∞—á–∏–≤–∞–Ω–∏–∏ –±–µ–ª–∫–æ–≤", "desc": "SimpleFold ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–æ—Ä–∞—á–∏–≤–∞–Ω–∏—è –±–µ–ª–∫–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ flow-matc
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#open_source", "#alignment", "#benchmark", "#dataset"], "emoji": "üì¶", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Ç–∞–º–æ–∂–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é AI", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –ø–µ—Ä–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≥–∞—Ä–º–æ–Ω–∏–∑–∏—Ä–æ–≤
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#agents", "#data", "#open_source"], "emoji": "ü§ñ", "ru": {"title": "AI-–∞–≥–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –ø–æ–º–æ–≥–∞—é—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º –≤ open-source –ø—Ä–æ–µ–∫—Ç–∞—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ 567 pull request'–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é Claude Code - –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ AI-–∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –≤ 157 open-
[26.09.2025 00:50] Using data from previous issue: {"categories": ["#science", "#open_source"], "emoji": "üåä", "ru": {"title": "–û—Ç–∫—Ä—ã—Ç–∞—è —Å–∏–º—É–ª—è—Ü–∏—è —Ç—É—Ä–±—É–ª–µ–Ω—Ç–Ω–æ–≥–æ —Å–º–µ—à–∏–≤–∞–Ω–∏—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Å–æ–∑–¥–∞–ª–∏ –æ—Ç–∫—Ä—ã—Ç—É—é Python –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–≤—É–º–µ—Ä–Ω—ã—Ö –Ω–µ—Å–∂–∏–º–∞–µ–º—ã—Ö –Ω–µ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–µ–π –ö–µ–ª—å–≤–∏–Ω–∞-–ì–µ–ª—å–º–≥–æ–ª—å—Ü–∞ –≤ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏
[26.09.2025 00:50] Renaming data file.
[26.09.2025 00:50] Renaming previous data. hf_papers.json to ./d/2025-09-26.json
[26.09.2025 00:50] Saving new data file.
[26.09.2025 00:50] Generating page.
[26.09.2025 00:50] Renaming previous page.
[26.09.2025 00:50] Renaming previous data. index.html to ./d/2025-09-26.html
[26.09.2025 00:50] Writing result.
[26.09.2025 00:50] Renaming log file.
[26.09.2025 00:50] Renaming previous data. log.txt to ./logs/2025-09-26_last_log.txt
