[26.09.2025 05:15] Read previous papers.
[26.09.2025 05:15] Generating top page (month).
[26.09.2025 05:15] Writing top page (month).
[26.09.2025 06:16] Read previous papers.
[26.09.2025 06:16] Get feed.
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21268
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21320
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20427
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.19803
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21240
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20712
[26.09.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.21117
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21278
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21245
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21114
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20136
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21317
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20186
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20414
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21318
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21070
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14662
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21042
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20878
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.21113
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20868
[26.09.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2509.20109
[26.09.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.20394
[26.09.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2509.20706
[26.09.2025 06:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.09.2025 06:16] No deleted papers detected.
[26.09.2025 06:16] Downloading and parsing papers (pdf, html). Total: 24.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.21268.
[26.09.2025 06:16] Extra JSON file exists (./assets/json/2509.21268.json), skip PDF parsing.
[26.09.2025 06:16] Paper image links file exists (./assets/img_data/2509.21268.json), skip HTML parsing.
[26.09.2025 06:16] Success.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.21320.
[26.09.2025 06:16] Extra JSON file exists (./assets/json/2509.21320.json), skip PDF parsing.
[26.09.2025 06:16] Paper image links file exists (./assets/img_data/2509.21320.json), skip HTML parsing.
[26.09.2025 06:16] Success.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.20427.
[26.09.2025 06:16] Extra JSON file exists (./assets/json/2509.20427.json), skip PDF parsing.
[26.09.2025 06:16] Paper image links file exists (./assets/img_data/2509.20427.json), skip HTML parsing.
[26.09.2025 06:16] Success.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.19803.
[26.09.2025 06:16] Extra JSON file exists (./assets/json/2509.19803.json), skip PDF parsing.
[26.09.2025 06:16] Paper image links file exists (./assets/img_data/2509.19803.json), skip HTML parsing.
[26.09.2025 06:16] Success.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.21240.
[26.09.2025 06:16] Extra JSON file exists (./assets/json/2509.21240.json), skip PDF parsing.
[26.09.2025 06:16] Paper image links file exists (./assets/img_data/2509.21240.json), skip HTML parsing.
[26.09.2025 06:16] Success.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.20712.
[26.09.2025 06:16] Extra JSON file exists (./assets/json/2509.20712.json), skip PDF parsing.
[26.09.2025 06:16] Paper image links file exists (./assets/img_data/2509.20712.json), skip HTML parsing.
[26.09.2025 06:16] Success.
[26.09.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2509.21117.
[26.09.2025 06:16] Downloading paper 2509.21117 from http://arxiv.org/pdf/2509.21117v1...
[26.09.2025 06:16] Extracting affiliations from text.
[26.09.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 2 ] . [ 1 7 1 1 1 2 . 9 0 5 2 : r a TRUSTJUDGE: JUDGE AND HOW TO ALLEVIATE THEM INCONSISTENCIES OF LLM-AS-AYidong Wang1 Yunze Song2 Tingyuan Zhu3 Xuanwang Zhang4 Zhuohao Yu1 Hao Chen5 Chiyu Song6 Qiufeng Wang7 Cunxiang Wang6 Zhen Wu4 Xinyu Dai4 Yue Zhang6 Wei Ye1 Shikun Zhang1 1 Peking University 2 National University of Singapore 3 Institute of Science Tokyo 4 Nanjing University 5 Google DeepMind 6 Westlake University 7 Southeast University "
[26.09.2025 06:17] Response: ```python
[
    "Peking University",
    "National University of Singapore",
    "Institute of Science Tokyo",
    "Nanjing University",
    "Google DeepMind",
    "Westlake University",
    "Southeast University"
]
```
[26.09.2025 06:17] Deleting PDF ./assets/pdf/2509.21117.pdf.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21278.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21278.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21278.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21245.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21245.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21245.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21114.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21114.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21114.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20136.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.20136.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.20136.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21317.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21317.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21317.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20186.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.20186.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.20186.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20414.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.20414.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.20414.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21318.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21318.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21318.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21070.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21070.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21070.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.14662.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.14662.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.14662.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21042.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21042.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21042.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20878.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.20878.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.20878.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.21113.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.21113.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.21113.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20868.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.20868.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.20868.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20109.
[26.09.2025 06:17] Extra JSON file exists (./assets/json/2509.20109.json), skip PDF parsing.
[26.09.2025 06:17] Paper image links file exists (./assets/img_data/2509.20109.json), skip HTML parsing.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20394.
[26.09.2025 06:17] Downloading paper 2509.20394 from http://arxiv.org/pdf/2509.20394v1...
[26.09.2025 06:17] Extracting affiliations from text.
[26.09.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Blueprints of Trust: AI System Cards for EndtoEnd Transparency and Governance huzaifas@redhat.com efox@redhat.com Garth Mollett gmollett@redhat.com Florencio Cano Gabarda fcanogab@redhat.com Roman Zhukov rzhukov@redhat.com "
[26.09.2025 06:17] Response: ```python
["Red Hat"]
```
[26.09.2025 06:17] Deleting PDF ./assets/pdf/2509.20394.pdf.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2509.20706.
[26.09.2025 06:17] Downloading paper 2509.20706 from http://arxiv.org/pdf/2509.20706v1...
[26.09.2025 06:17] Extracting affiliations from text.
[26.09.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"MI-FUSE: LABEL FUSION FOR UNSUPERVISED DOMAIN ADAPTATION WITH CLOSED-SOURCE LARGE AUDIO-LANGUAGE MODEL Hsiao-Ying Huang*, Yi-Cheng Lin*, Hung-yi Lee National Taiwan University, Taiwan 5 2 0 2 5 2 ] . [ 1 6 0 7 0 2 . 9 0 5 2 : r ABSTRACT Large audiolanguage models (LALMs) show strong zero-shot ability on speech tasks, suggesting promise for speech emotion recognition (SER). However, SER in real-world deployments often fails under domain mismatch, where source data are unavailable and powerful LALMs are accessible only through an API. We ask: given only unlabeled target-domain audio and an API-only LALM, can student model be adapted to outperform the LALM in the target domain? To this end, we propose MI-Fuse, denoised label fusion framework that supplements the LALM with source-domain trained SER classifier as an auxiliary teacher. The framework draws multiple stochastic predictions from both teachers, weights their mean distributions by mutual-information-based uncertainty, and stabilizes training with an exponential moving average teacher. Experiments across three public emotion datasets and six cross-domain transfers show consistent gains, with the student surpassing the LALM and outperforming the strongest baseline by 3.9%. This approach strengthens emotion-aware speech systems without sharing source data, enabling realistic adaptation. Index Terms Speech emotion recognition, Source-free unsupervised domain adaptation, Large audiolanguage models, Mutual information 1. INTRODUCTION LALMs such as Desta2.5-Audio [1], Qwen2.5-Omni [2], and Gemini 2.5 [3] have recently demonstrated impressive general-purpose capabilities across spoken language understanding, paralinguistics, and speaker-related tasks [4, 5]. Their versatility and strong zeroshot performance highlight their potential as universal backbones for various speech processing problems, including speech emotion recognition (SER) [6]. SER is essential in applications ranging from healthcare and mental health mon"
[26.09.2025 06:17] Response: ```python
["National Taiwan University, Taiwan"]
```
[26.09.2025 06:17] Deleting PDF ./assets/pdf/2509.20706.pdf.
[26.09.2025 06:17] Success.
[26.09.2025 06:17] Enriching papers with extra data.
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 0. Variance-Aware Sampling and large-scale CoT data improve multimodal reasoning models by stabilizing RL fine-tuning and enhancing performance on benchmarks.  					AI-generated summary 				 Large multimodal reasoning models have achieved rapid progress, but their advancement is constrained by two majo...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 1. A scientific reasoning foundation model pre-trained on diverse scientific data supports multiple tasks and enhances cross-domain generalization and fidelity through specialized training techniques.  					AI-generated summary 				 We present a scientific reasoning foundation model that aligns natural...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 2. Seedream 4.0 is a high-performance multimodal image generation system that integrates text-to-image synthesis, image editing, and multi-image composition using a diffusion transformer and VAE, achieving state-of-the-art results with efficient training and inference.  					AI-generated summary 				 W...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 3. A curriculum reinforcement learning framework dynamically adjusts training sample difficulty based on reward variance, improving LLM performance on mathematical reasoning tasks.  					AI-generated summary 				 Policy-based reinforcement learning currently plays an important role in improving LLMs on...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 4. Tree-based Group Relative Policy Optimization (Tree-GRPO) enhances reinforcement learning for large language models by using tree search to improve rollouts and estimate grouped relative advantages, outperforming chain-based methods.  					AI-generated summary 				 Recent advances in reinforcement l...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 5. A novel reinforcement learning algorithm, CE-GPPO, reintroduces gradients from clipped tokens to improve the exploration-exploitation balance in training large language models.  					AI-generated summary 				 Reinforcement learning (RL) has become a powerful paradigm for optimizing large language mo...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 6. TrustJudge, a probabilistic framework, addresses inconsistencies in LLM-as-a-judge evaluation by using distribution-sensitive scoring and likelihood-aware aggregation, improving accuracy and reliability.  					AI-generated summary 				 The adoption of Large Language Models (LLMs) as automated evalua...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 7. SHINE is a training-free framework that uses manifold-steered anchor loss and pretrained customization adapters to seamlessly insert objects into new scenes with high fidelity, addressing challenges like complex lighting and diverse inputs.  					AI-generated summary 				 Image composition aims to s...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 8. Hunyuan3D-Omni is a unified 3D asset generation framework that accepts multiple conditioning signals, improving controllability and robustness in production workflows.  					AI-generated summary 				 Recent advances in 3D-native generative models have accelerated asset creation for games, film, and ...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 9. CHARM uses a control-point-based parameterization and autoregressive transformer to generate high-fidelity anime hairstyles efficiently.  					AI-generated summary 				 We present CHARM, a novel parametric representation and generative framework for anime hairstyle modeling. While traditional hair m...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 10. V-GameGym is a comprehensive benchmark for evaluating code generation in game development, focusing on multimodal evaluation including playability, visual aesthetics, and user engagement.  					AI-generated summary 				 Code large language models have demonstrated remarkable capabilities in programm...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 11. IRF, a new recommendation system using natural language commands, improves user satisfaction and business outcomes through a dual-agent architecture and simulation-augmented knowledge distillation.  					AI-generated summary 				 Traditional recommender systems rely on passive feedback mechanisms th...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 12. Thinking augmented pre-training improves data efficiency and performance of large language models by augmenting text with automatically generated thinking trajectories.  					AI-generated summary 				 This paper introduces a simple and scalable approach to improve the data efficiency of large langua...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 13. SceneWeaver, a reflective agentic framework, uses a language model-based planner to iteratively refine 3D scene synthesis, achieving high physical, visual, and semantic quality across diverse instructions.  					AI-generated summary 				 Indoor scene synthesis has become increasingly important with ...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 14. SD3.5-Flash is an efficient few-step distillation framework that enhances image generation on consumer devices using rectified flow models with innovations like timestep sharing and split-timestep fine-tuning.  					AI-generated summary 				 We present SD3.5-Flash, an efficient few-step distillation...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 15. ScaleDiff uses an adaptive thinking model to identify and generate difficult mathematical problems, improving the performance of large reasoning models with cost-efficient training.  					AI-generated summary 				 Large Reasoning Models (LRMs) have shown impressive capabilities in complex problem-so...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 16. A novel framework using Schoenfeld's Episode Theory is introduced to analyze the reasoning patterns of Large Reasoning Models in solving math problems, providing a benchmark for machine reasoning.  					AI-generated summary 				 While Large Reasoning Models (LRMs) generate extensive chain-of-thought...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 17. The causal mask in Transformer decoders induces position-dependent attention patterns, which can interact with explicit positional encodings like RoPE, affecting their relative attention score patterns.  					AI-generated summary 				 While explicit positional encodings such as RoPE are a primary so...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 18. The study reveals an asymmetry between perceptual optimization and image quality assessment, showing that effective IQA metrics are not always suitable for perceptual optimization, especially under adversarial training, and highlights the importance of discriminator design in optimization.  					AI-...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 19. MOSS-ChatV, a reinforcement learning framework with a DTW-based reward, improves video reasoning consistency and performance across various benchmarks.  					AI-generated summary 				 Video reasoning has emerged as a critical capability for multimodal large language models (MLLMs), requiring models ...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 20. StyleBench evaluates various reasoning styles across tasks and models, revealing that strategy efficacy depends on model scale and task type.  					AI-generated summary 				 The effectiveness of Large Language Models (LLMs) is heavily influenced by the reasoning strategies, or styles of thought, emp...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 21. ReflectDrive uses a reflection mechanism with discrete diffusion and pre-trained Diffusion Language Models to generate safe trajectories for autonomous driving systems.  					AI-generated summary 				 End-to-End (E2E) solutions have emerged as a mainstream approach for autonomous driving systems, wi...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 22. The Hazard-Aware System Card (HASC) enhances AI system safety and accountability by integrating security and safety identifiers into a standardized framework.  					AI-generated summary 				 This paper introduces the Hazard-Aware System Card (HASC), a novel framework designed to enhance transparency...
[26.09.2025 06:17] ********************************************************************************
[26.09.2025 06:17] Abstract 23. MI-Fuse, a denoised label fusion framework, enhances speech emotion recognition in target domains using an API-only LALM and a source-domain SER classifier, achieving better performance than the LALM and other baselines.  					AI-generated summary 				 Large audio-language models (LALMs) show strong...
[26.09.2025 06:17] Read previous papers.
[26.09.2025 06:17] Generating reviews via LLM API.
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#dataset", "#training", "#architecture", "#reasoning", "#benchmark", "#rl", "#optimization", "#multimodal", "#data", "#open_source"], "emoji": "🎯", "ru": {"title": "Стабилизация RL-обучения через управление дисперсией вознаграждений", "desc": "Исследователи предложили метод Variance
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#dataset", "#training", "#reasoning", "#transfer_learning", "#multimodal", "#data", "#science", "#open_source"], "emoji": "🔬", "ru": {"title": "Универсальный AI для научных рассуждений во всех дисциплинах", "desc": "Исследователи создали foundation модель для научных рассуждений, ко
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#inference", "#training", "#games", "#multimodal", "#cv", "#diffusion"], "emoji": "🎨", "ru": {"title": "Универсальная система для генерации и редактирования изображений нового поколения", "desc": "Seedream 4.0 — это высокопроизводительная мультимодальная система генерации изображени
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#math", "#training", "#rl", "#optimization", "#reasoning"], "emoji": "📈", "ru": {"title": "Обучение через дисперсию: адаптивная сложность для математического мышления LLM", "desc": "Исследователи предложили VCRL - новый подход к обучению языковых моделей решению математических задач
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#rl", "#optimization"], "emoji": "🌳", "ru": {"title": "Древовидный поиск для умного обучения AI-агентов", "desc": "Исследователи предложили Tree-GRPO - новый метод обучения с подкреплением для больших языковых моделей, основанный на поиске по дереву. Метод реш
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#rl"], "emoji": "⚖️", "ru": {"title": "Сохраняем градиенты для лучшего баланса в обучении LLM", "desc": "В работе предлагается новый алгоритм обучения с подкреплением CE-GPPO для оптимизации больших языковых моделей. Основная проблема суще
[26.09.2025 06:17] Querying the API.
[26.09.2025 06:17] Claude request. Model: claude-sonnet-4-20250514. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

TrustJudge, a probabilistic framework, addresses inconsistencies in LLM-as-a-judge evaluation by using distribution-sensitive scoring and likelihood-aware aggregation, improving accuracy and reliability.  					AI-generated summary 				 The adoption of Large Language Models (LLMs) as automated evaluators (LLM-as-a-judge) has revealed critical inconsistencies in current evaluation frameworks. We identify two fundamental types of inconsistencies: (1) Score-Comparison Inconsistency, where lower-rated responses outperform higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity Inconsistency, manifested through circular preference chains (A>B>C>A) and equivalence contradictions (A=B=C\neq A). We argue that these issues come from information loss in discrete rating systems and ambiguous tie judgments during pairwise evaluation. We propose TrustJudge, a probabilistic framework that addresses these limitations through two key innovations: 1) distribution-sensitive scoring that computes continuous expectations from discrete rating probabilities, preserving information entropy for more precise scoring, and 2) likelihood-aware aggregation that resolves transitivity violations using bidirectional preference probabilities or perplexity. We also formalize the theoretical limitations of current LLM-as-a-judge frameworks and demonstrate how TrustJudge's components overcome them. When evaluated with Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining higher evaluation accuracy. Our work provides the first systematic analysis of evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both theoretical insights and practical solutions for reliable automated assessment. The framework demonstrates consistent improvements across various model architectures and scales, enabling more trustworthy LLM evaluation without requiring additional training or human annotations. The codes can be found at https://github.com/TrustJudge/TrustJudge.
[26.09.2025 06:17] Response: ```json
{
  "desc": "Исследователи выявили критические проблемы в системах оценки, где LLM выступают в роли судей - несогласованность в скоринге и нарушения транзитивности в парных сравнениях. Они предложили TrustJudge - вероятностную систему, которая использует непрерывные оценки вместо дискретных рейтингов и учитывает вероятности предпочтений для устранения логических противоречий. Фреймворк значительно снижает несогласованность: на 8.43% в сравнении оценок и на 10.82% в транзитивности парных сравнений. Это первый систематический анализ проблем оценочных систем с LLM-судьями, предлагающий как теоретическое понимание, так и практические решения для надежной автоматической оценки.",
  "emoji": "⚖️",
  "title": "Делаем LLM-судей честными: вероятностный подход против противоречий в оценках"
}
```
[26.09.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TrustJudge, a probabilistic framework, addresses inconsistencies in LLM-as-a-judge evaluation by using distribution-sensitive scoring and likelihood-aware aggregation, improving accuracy and reliability.  					AI-generated summary 				 The adoption of Large Language Models (LLMs) as automated evaluators (LLM-as-a-judge) has revealed critical inconsistencies in current evaluation frameworks. We identify two fundamental types of inconsistencies: (1) Score-Comparison Inconsistency, where lower-rated responses outperform higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity Inconsistency, manifested through circular preference chains (A>B>C>A) and equivalence contradictions (A=B=C\neq A). We argue that these issues come from information loss in discrete rating systems and ambiguous tie judgments during pairwise evaluation. We propose TrustJudge, a probabilistic framework that addresses these limitations through two key innovations: 1) distribution-sensitive scoring that computes continuous expectations from discrete rating probabilities, preserving information entropy for more precise scoring, and 2) likelihood-aware aggregation that resolves transitivity violations using bidirectional preference probabilities or perplexity. We also formalize the theoretical limitations of current LLM-as-a-judge frameworks and demonstrate how TrustJudge's components overcome them. When evaluated with Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining higher evaluation accuracy. Our work provides the first systematic analysis of evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both theoretical insights and practical solutions for reliable automated assessment. The framework demonstrates consistent improvements across various model architectures and scales, enabling more trustworthy LLM evaluation without requiring additional training or human annotations. The codes can be found at https://github.com/TrustJudge/TrustJudge."

[26.09.2025 06:17] Response: ```python
['BENCHMARK', 'DATA', 'ARCHITECTURE']
```
[26.09.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"TrustJudge, a probabilistic framework, addresses inconsistencies in LLM-as-a-judge evaluation by using distribution-sensitive scoring and likelihood-aware aggregation, improving accuracy and reliability.  					AI-generated summary 				 The adoption of Large Language Models (LLMs) as automated evaluators (LLM-as-a-judge) has revealed critical inconsistencies in current evaluation frameworks. We identify two fundamental types of inconsistencies: (1) Score-Comparison Inconsistency, where lower-rated responses outperform higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity Inconsistency, manifested through circular preference chains (A>B>C>A) and equivalence contradictions (A=B=C\neq A). We argue that these issues come from information loss in discrete rating systems and ambiguous tie judgments during pairwise evaluation. We propose TrustJudge, a probabilistic framework that addresses these limitations through two key innovations: 1) distribution-sensitive scoring that computes continuous expectations from discrete rating probabilities, preserving information entropy for more precise scoring, and 2) likelihood-aware aggregation that resolves transitivity violations using bidirectional preference probabilities or perplexity. We also formalize the theoretical limitations of current LLM-as-a-judge frameworks and demonstrate how TrustJudge's components overcome them. When evaluated with Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining higher evaluation accuracy. Our work provides the first systematic analysis of evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both theoretical insights and practical solutions for reliable automated assessment. The framework demonstrates consistent improvements across various model architectures and scales, enabling more trustworthy LLM evaluation without requiring additional training or human annotations. The codes can be found at https://github.com/TrustJudge/TrustJudge."

[26.09.2025 06:17] Response: ```python
["INTERPRETABILITY", "ALIGNMENT"]
```
[26.09.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TrustJudge is a new framework designed to improve the evaluation of Large Language Models (LLMs) acting as judges. It tackles two main problems: inconsistencies in score comparisons and transitivity, which can lead to confusing results in evaluations. By using distribution-sensitive scoring, TrustJudge captures more information from ratings, and likelihood-aware aggregation helps resolve contradictions in preferences. This approach significantly reduces inconsistencies and enhances the accuracy of automated assessments without needing extra training or human input.","title":"TrustJudge: Enhancing Reliability in LLM Evaluations"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TrustJudge is a new framework designed to improve the evaluation of Large Language Models (LLMs) acting as judges. It tackles two main problems: inconsistencies in score comparisons and transitivity, which can lead to confusing results in evaluations. By using distribution-sensitive scoring, TrustJudge captures more information from ratings, and likelihood-aware aggregation helps resolve contradictions in preferences. This approach significantly reduces inconsistencies and enhances the accuracy of automated assessments without needing extra training or human input.', title='TrustJudge: Enhancing Reliability in LLM Evaluations'))
[26.09.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"TrustJudge是一个概率框架，旨在解决大型语言模型（LLM）作为评估者时的评估不一致性问题。它通过分布敏感评分和考虑似然性的聚合方法，提升了评估的准确性和可靠性。研究发现，当前评估框架存在评分比较不一致和成对传递不一致等问题，这些问题源于离散评分系统的信息损失。TrustJudge通过计算连续期望和双向偏好概率，成功克服了这些限制，提供了更精确的评估结果。","title":"TrustJudge：提升LLM评估一致性的创新框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='TrustJudge是一个概率框架，旨在解决大型语言模型（LLM）作为评估者时的评估不一致性问题。它通过分布敏感评分和考虑似然性的聚合方法，提升了评估的准确性和可靠性。研究发现，当前评估框架存在评分比较不一致和成对传递不一致等问题，这些问题源于离散评分系统的信息损失。TrustJudge通过计算连续期望和双向偏好概率，成功克服了这些限制，提供了更精确的评估结果。', title='TrustJudge：提升LLM评估一致性的创新框架'))
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#benchmark", "#cv", "#open_source"], "emoji": "✨", "ru": {"title": "Безупречная вставка объектов в сцены без переобучения", "desc": "Статья представляет SHINE - фреймворк без обучения для бесшовной вставки объектов в новые сцены с высокой 
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#3d", "#training", "#architecture", "#games", "#synthetic", "#multimodal"], "emoji": "🎮", "ru": {"title": "Многомодальный контроль 3D-генерации для игровой индустрии", "desc": "Исследователи представили Hunyuan3D-Omni — единую систему для генерации 3D-объектов с множественным контро
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#games", "#synthetic", "#training", "#cv", "#architecture", "#dataset"], "emoji": "💇", "ru": {"title": "AI создаёт аниме-причёски через \"язык волос\"", "desc": "В статье представлена CHARM - новая система для создания аниме-причёсок с помощью AI. Вместо традиционных методов моделир
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#games", "#multimodal", "#dataset"], "emoji": "🎮", "ru": {"title": "Новый стандарт оценки AI в геймдеве: от кода к играбельности", "desc": "V-GameGym - это комплексный бенчмарк для оценки генерации кода в разработке игр, который включает мультимодальну
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#training", "#architecture", "#reasoning", "#optimization", "#multimodal", "#agents"], "emoji": "🗣️", "ru": {"title": "Управляй рекомендациями голосом - говори системе, что хочешь увидеть", "desc": "Исследователи представили Interactive Recommendation Feed (IRF) - новую парадигму ре
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#data", "#training", "#reasoning", "#optimization"], "emoji": "🧠", "ru": {"title": "Думающие данные: как траектории рассуждений ускоряют обучение LLM в три раза", "desc": "В статье представлена методология Thinking augmented Pre-Training (TPT), которая улучшает эффективность обучени
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#3d", "#reasoning", "#games", "#alignment", "#agents"], "emoji": "🏠", "ru": {"title": "Умный архитектор: AI-агент создает реалистичные 3D интерьеры через саморефлексию", "desc": "SceneWeaver - это агентная система для синтеза 3D сцен, которая использует языковую модель-планировщик д
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#dataset", "#training", "#inference", "#optimization", "#data", "#cv", "#diffusion"], "emoji": "⚡", "ru": {"title": "Быстрая генерация изображений для всех устройств", "desc": "SD3.5-Flash представляет эффективный фреймворк дистилляции для генерации изображений за несколько шагов на
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#math", "#training", "#optimization", "#transfer_learning", "#reasoning", "#dataset"], "emoji": "🧮", "ru": {"title": "Масштабируемая генерация сложных математических задач для обучения моделей рассуждения", "desc": "ScaleDiff представляет новый подход для создания сложных математиче
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#math", "#reasoning", "#interpretability", "#benchmark"], "emoji": "🧠", "ru": {"title": "Картография мышления AI через призму человеческого познания", "desc": "Исследователи применили теорию эпизодов Шёнфельда, классическую когнитивную модель решения математических задач человеком, 
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#math", "#optimization", "#architecture", "#interpretability"], "emoji": "🎭", "ru": {"title": "Каузальная маска как скрытый источник позиционной информации", "desc": "Исследователи доказали, что каузальная маска в декодерах Transformer создаёт зависящие от позиции паттерны внимания 
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#training", "#cv", "#optimization"], "emoji": "🔄", "ru": {"title": "Асимметрия между оптимизацией и оценкой качества изображений", "desc": "Исследование выявляет асимметрию между перцептуальной оптимизацией и оценкой качества изображений. Метрики IQA, которые хорошо работают для оце
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#video", "#rl", "#interpretability", "#multimodal"], "emoji": "🎬", "ru": {"title": "Согласованные рассуждения о видео через обучение с подкреплением", "desc": "В статье представлена MOSS-ChatV — фреймворк обучения с подкреплением для улучшения рассуждений
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "Размер модели решает, какой стиль рассуждений работает лучше", "desc": "Исследование представляет StyleBench - бенчмарк для оценки различных стилей рассуждений в больших языковых моделях. Автор
[26.09.2025 06:17] Using data from previous issue: {"categories": ["#optimization", "#agents", "#diffusion", "#benchmark", "#multimodal", "#rl"], "emoji": "🚗", "ru": {"title": "Безопасное автономное вождение через рефлексию и дискретную диффузию", "desc": "ReflectDrive представляет новый подход для автономного вождения, использующий механизм рефлекс
[26.09.2025 06:17] Querying the API.
[26.09.2025 06:17] Claude request. Model: claude-sonnet-4-20250514. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Hazard-Aware System Card (HASC) enhances AI system safety and accountability by integrating security and safety identifiers into a standardized framework.  					AI-generated summary 				 This paper introduces the Hazard-Aware System Card (HASC), a novel framework designed to enhance transparency and accountability in the development and deployment of AI systems. The HASC builds upon existing model card and system card concepts by integrating a comprehensive, dynamic record of an AI system's security and safety posture. The framework proposes a standardized system of identifiers, including a novel AI Safety Hazard (ASH) ID, to complement existing security identifiers like CVEs, allowing for clear and consistent communication of fixed flaws. By providing a single, accessible source of truth, the HASC empowers developers and stakeholders to make more informed decisions about AI system safety throughout its lifecycle. Ultimately, we also compare our proposed AI system cards with the ISO/IEC 42001:2023 standard and discuss how they can be used to complement each other, providing greater transparency and accountability for AI systems.
[26.09.2025 06:17] Response: ```json
{
  "desc": "В статье представлена новая система Hazard-Aware System Card (HASC), которая расширяет существующие концепции model card и system card для повышения прозрачности AI систем. Фреймворк предлагает стандартизированную систему идентификаторов, включая новый AI Safety Hazard (ASH) ID, который дополняет существующие идентификаторы безопасности типа CVE. HASC создает единый источник информации о состоянии безопасности AI системы на протяжении всего жизненного цикла. Авторы также сравнивают предложенный подход со стандартом ISO/IEC 42001:2023 и показывают, как они могут дополнять друг друга.",
  "emoji": "🛡️",
  "title": "Стандартизация безопасности AI через карточки систем с идентификаторами угроз"
}
```
[26.09.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Hazard-Aware System Card (HASC) enhances AI system safety and accountability by integrating security and safety identifiers into a standardized framework.  					AI-generated summary 				 This paper introduces the Hazard-Aware System Card (HASC), a novel framework designed to enhance transparency and accountability in the development and deployment of AI systems. The HASC builds upon existing model card and system card concepts by integrating a comprehensive, dynamic record of an AI system's security and safety posture. The framework proposes a standardized system of identifiers, including a novel AI Safety Hazard (ASH) ID, to complement existing security identifiers like CVEs, allowing for clear and consistent communication of fixed flaws. By providing a single, accessible source of truth, the HASC empowers developers and stakeholders to make more informed decisions about AI system safety throughout its lifecycle. Ultimately, we also compare our proposed AI system cards with the ISO/IEC 42001:2023 standard and discuss how they can be used to complement each other, providing greater transparency and accountability for AI systems."

[26.09.2025 06:17] Response: ```python
["DATASET", "DATA", "BENCHMARK", "ARCHITECTURE"]
```
[26.09.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Hazard-Aware System Card (HASC) enhances AI system safety and accountability by integrating security and safety identifiers into a standardized framework.  					AI-generated summary 				 This paper introduces the Hazard-Aware System Card (HASC), a novel framework designed to enhance transparency and accountability in the development and deployment of AI systems. The HASC builds upon existing model card and system card concepts by integrating a comprehensive, dynamic record of an AI system's security and safety posture. The framework proposes a standardized system of identifiers, including a novel AI Safety Hazard (ASH) ID, to complement existing security identifiers like CVEs, allowing for clear and consistent communication of fixed flaws. By providing a single, accessible source of truth, the HASC empowers developers and stakeholders to make more informed decisions about AI system safety throughout its lifecycle. Ultimately, we also compare our proposed AI system cards with the ISO/IEC 42001:2023 standard and discuss how they can be used to complement each other, providing greater transparency and accountability for AI systems."

[26.09.2025 06:17] Response: ```python
['SECURITY', 'ETHICS']
```
[26.09.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Hazard-Aware System Card (HASC) is a new framework aimed at improving the safety and accountability of AI systems. It combines security and safety identifiers into a standardized format, enhancing transparency in AI development and deployment. The HASC introduces a unique AI Safety Hazard (ASH) ID alongside existing security identifiers, facilitating better communication about vulnerabilities. By serving as a centralized resource, the HASC helps developers and stakeholders make informed decisions regarding AI system safety throughout its lifecycle.","title":"Enhancing AI Safety with the Hazard-Aware System Card"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Hazard-Aware System Card (HASC) is a new framework aimed at improving the safety and accountability of AI systems. It combines security and safety identifiers into a standardized format, enhancing transparency in AI development and deployment. The HASC introduces a unique AI Safety Hazard (ASH) ID alongside existing security identifiers, facilitating better communication about vulnerabilities. By serving as a centralized resource, the HASC helps developers and stakeholders make informed decisions regarding AI system safety throughout its lifecycle.', title='Enhancing AI Safety with the Hazard-Aware System Card'))
[26.09.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种新颖的框架——危险意识系统卡（HASC），旨在提高人工智能系统的透明度和问责制。HASC在现有的模型卡和系统卡概念基础上，整合了AI系统安全和安全状态的动态记录。该框架提出了一套标准化的标识符，包括新颖的AI安全危险（ASH）ID，以补充现有的安全标识符，如CVE，从而实现缺陷修复的清晰和一致的沟通。通过提供一个单一、可访问的真实信息来源，HASC使开发者和利益相关者能够在AI系统的整个生命周期中做出更明智的安全决策。","title":"提升AI系统安全与透明度的关键"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一种新颖的框架——危险意识系统卡（HASC），旨在提高人工智能系统的透明度和问责制。HASC在现有的模型卡和系统卡概念基础上，整合了AI系统安全和安全状态的动态记录。该框架提出了一套标准化的标识符，包括新颖的AI安全危险（ASH）ID，以补充现有的安全标识符，如CVE，从而实现缺陷修复的清晰和一致的沟通。通过提供一个单一、可访问的真实信息来源，HASC使开发者和利益相关者能够在AI系统的整个生命周期中做出更明智的安全决策。', title='提升AI系统安全与透明度的关键'))
[26.09.2025 06:17] Querying the API.
[26.09.2025 06:17] Claude request. Model: claude-sonnet-4-20250514. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MI-Fuse, a denoised label fusion framework, enhances speech emotion recognition in target domains using an API-only LALM and a source-domain SER classifier, achieving better performance than the LALM and other baselines.  					AI-generated summary 				 Large audio-language models (LALMs) show strong zero-shot ability on speech tasks, suggesting promise for speech emotion recognition (SER). However, SER in real-world deployments often fails under domain mismatch, where source data are unavailable and powerful LALMs are accessible only through an API. We ask: given only unlabeled target-domain audio and an API-only LALM, can a student model be adapted to outperform the LALM in the target domain? To this end, we propose MI-Fuse, a denoised label fusion framework that supplements the LALM with a source-domain trained SER classifier as an auxiliary teacher. The framework draws multiple stochastic predictions from both teachers, weights their mean distributions by mutual-information-based uncertainty, and stabilizes training with an exponential moving average teacher. Experiments across three public emotion datasets and six cross-domain transfers show consistent gains, with the student surpassing the LALM and outperforming the strongest baseline by 3.9%. This approach strengthens emotion-aware speech systems without sharing source data, enabling realistic adaptation.
[26.09.2025 06:18] Response: ```json
{
  "desc": "В статье предлагается фреймворк MI-Fuse для адаптации моделей распознавания эмоций в речи к новому домену без доступа к исходным данным. Метод использует большую аудио-языковую модель (LALM), доступную только через API, и классификатор из исходного домена в качестве учителей для обучения студенческой модели. Фреймворк объединяет предсказания учителей с помощью весов, основанных на взаимной информации, и стабилизирует обучение экспоненциальным скользящим средним. Эксперименты показывают, что студенческая модель превосходит LALM и другие базовые методы на 3.9% в задачах кросс-доменного переноса.",
  "emoji": "🎭",
  "title": "Слияние знаний для распознавания эмоций без исходных данных"
}
```
[26.09.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MI-Fuse, a denoised label fusion framework, enhances speech emotion recognition in target domains using an API-only LALM and a source-domain SER classifier, achieving better performance than the LALM and other baselines.  					AI-generated summary 				 Large audio-language models (LALMs) show strong zero-shot ability on speech tasks, suggesting promise for speech emotion recognition (SER). However, SER in real-world deployments often fails under domain mismatch, where source data are unavailable and powerful LALMs are accessible only through an API. We ask: given only unlabeled target-domain audio and an API-only LALM, can a student model be adapted to outperform the LALM in the target domain? To this end, we propose MI-Fuse, a denoised label fusion framework that supplements the LALM with a source-domain trained SER classifier as an auxiliary teacher. The framework draws multiple stochastic predictions from both teachers, weights their mean distributions by mutual-information-based uncertainty, and stabilizes training with an exponential moving average teacher. Experiments across three public emotion datasets and six cross-domain transfers show consistent gains, with the student surpassing the LALM and outperforming the strongest baseline by 3.9%. This approach strengthens emotion-aware speech systems without sharing source data, enabling realistic adaptation."

[26.09.2025 06:18] Response: ```python
["AUDIO", "MULTIMODAL", "TRAINING"]
```
[26.09.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MI-Fuse, a denoised label fusion framework, enhances speech emotion recognition in target domains using an API-only LALM and a source-domain SER classifier, achieving better performance than the LALM and other baselines.  					AI-generated summary 				 Large audio-language models (LALMs) show strong zero-shot ability on speech tasks, suggesting promise for speech emotion recognition (SER). However, SER in real-world deployments often fails under domain mismatch, where source data are unavailable and powerful LALMs are accessible only through an API. We ask: given only unlabeled target-domain audio and an API-only LALM, can a student model be adapted to outperform the LALM in the target domain? To this end, we propose MI-Fuse, a denoised label fusion framework that supplements the LALM with a source-domain trained SER classifier as an auxiliary teacher. The framework draws multiple stochastic predictions from both teachers, weights their mean distributions by mutual-information-based uncertainty, and stabilizes training with an exponential moving average teacher. Experiments across three public emotion datasets and six cross-domain transfers show consistent gains, with the student surpassing the LALM and outperforming the strongest baseline by 3.9%. This approach strengthens emotion-aware speech systems without sharing source data, enabling realistic adaptation."

[26.09.2025 06:18] Response: ```python
["TRANSFER_LEARNING", "OPTIMIZATION"]
```
[26.09.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces MI-Fuse, a framework designed to improve speech emotion recognition (SER) in situations where there is a mismatch between the source and target domains. It utilizes an API-only large audio-language model (LALM) alongside a source-domain SER classifier to enhance performance. By employing a denoised label fusion technique, MI-Fuse combines predictions from both models, using mutual information to weigh their contributions effectively. The results demonstrate that this method allows a student model to outperform the LALM and other baseline models, achieving significant improvements in emotion recognition tasks.","title":"Enhancing Speech Emotion Recognition with MI-Fuse"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces MI-Fuse, a framework designed to improve speech emotion recognition (SER) in situations where there is a mismatch between the source and target domains. It utilizes an API-only large audio-language model (LALM) alongside a source-domain SER classifier to enhance performance. By employing a denoised label fusion technique, MI-Fuse combines predictions from both models, using mutual information to weigh their contributions effectively. The results demonstrate that this method allows a student model to outperform the LALM and other baseline models, achieving significant improvements in emotion recognition tasks.', title='Enhancing Speech Emotion Recognition with MI-Fuse'))
[26.09.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MI-Fuse是一种去噪标签融合框架，旨在提高目标领域的语音情感识别（SER）性能。该框架结合了仅通过API访问的大型音频语言模型（LALM）和源领域训练的SER分类器，作为辅助教师。通过从两个教师模型中获取多个随机预测，并根据互信息的不确定性加权其均值分布，MI-Fuse能够稳定训练过程。实验结果表明，该方法在多个情感数据集上表现优异，学生模型的性能超过了LALM，提升幅度达到3.9%。","title":"MI-Fuse：提升语音情感识别的去噪标签融合框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MI-Fuse是一种去噪标签融合框架，旨在提高目标领域的语音情感识别（SER）性能。该框架结合了仅通过API访问的大型音频语言模型（LALM）和源领域训练的SER分类器，作为辅助教师。通过从两个教师模型中获取多个随机预测，并根据互信息的不确定性加权其均值分布，MI-Fuse能够稳定训练过程。实验结果表明，该方法在多个情感数据集上表现优异，学生模型的性能超过了LALM，提升幅度达到3.9%。', title='MI-Fuse：提升语音情感识别的去噪标签融合框架'))
[26.09.2025 06:18] Renaming data file.
[26.09.2025 06:18] Renaming previous data. hf_papers.json to ./d/2025-09-26.json
[26.09.2025 06:18] Saving new data file.
[26.09.2025 06:18] Generating page.
[26.09.2025 06:18] Renaming previous page.
[26.09.2025 06:18] Renaming previous data. index.html to ./d/2025-09-26.html
[26.09.2025 06:18] Writing result.
[26.09.2025 06:18] Renaming log file.
[26.09.2025 06:18] Renaming previous data. log.txt to ./logs/2025-09-26_last_log.txt
