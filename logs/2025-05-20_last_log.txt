[20.05.2025 05:13] Read previous papers.
[20.05.2025 05:13] Generating top page (month).
[20.05.2025 05:13] Writing top page (month).
[20.05.2025 06:17] Read previous papers.
[20.05.2025 06:17] Get feed.
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11820
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11896
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11254
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13417
[20.05.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2505.13227
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13427
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13215
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12805
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13379
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12504
[20.05.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2505.12992
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12081
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11932
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12849
[20.05.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2505.11855
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13444
[20.05.2025 06:17] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13437
[20.05.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2505.12257
[20.05.2025 06:17] Extract page data from URL. URL: https://huggingface.co/papers/2505.03332
[20.05.2025 06:17] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.05.2025 06:17] No deleted papers detected.
[20.05.2025 06:17] Downloading and parsing papers (pdf, html). Total: 19.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.11820.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.11820.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.11820.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.11896.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.11896.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.11896.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.11254.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.11254.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.11254.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13417.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.13417.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.13417.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13227.
[20.05.2025 06:17] Downloading paper 2505.13227 from http://arxiv.org/pdf/2505.13227v1...
[20.05.2025 06:17] Extracting affiliations from text.
[20.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 7 2 2 3 1 . 5 0 5 2 : r Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis Tianbao Xie Jiaqi Deng Xiaochuan Li Junlin Yang Haoyuan Wu Jixuan Chen Wenjing Hu Xinyuan Wang Yuhui Xu Zekun Wang Yiheng Xu Junli Wang Doyen Sahoo Tao Yu Caiming Xiong The University of Hong Kong sSalesforce AI Research "
[20.05.2025 06:17] Response: ```python
["The University of Hong Kong", "Salesforce AI Research"]
```
[20.05.2025 06:17] Deleting PDF ./assets/pdf/2505.13227.pdf.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13427.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.13427.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.13427.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13215.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.13215.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.13215.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.12805.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.12805.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.12805.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13379.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.13379.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.13379.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.12504.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.12504.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.12504.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.12992.
[20.05.2025 06:17] Downloading paper 2505.12992 from http://arxiv.org/pdf/2505.12992v1...
[20.05.2025 06:17] Extracting affiliations from text.
[20.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 2 9 9 2 1 . 5 0 5 2 : r Fractured Chain-of-Thought Reasoning Baohao Liao Hanze Dong Yuhui Xu Doyen Sahoo Christof Monz Junnan Li Caiming Xiong University of Amsterdam Salesforce AI Research Abstract Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning. Recent advances in large language models (LLMs) have enabled impressive capabilities in complex reasoning and problem solving (Guo et al., 2025; Kojima et al., 2022; Jaech et al., 2024; Brown et al., 2020; Hurst et al., 2024; Anthropic, 2024; Team et al., 2024). While much progress has been driven by scaling model size and training data Hestness et al. (2017); Kaplan "
[20.05.2025 06:17] Response: ```python
["University of Amsterdam", "Salesforce AI Research"]
```
[20.05.2025 06:17] Deleting PDF ./assets/pdf/2505.12992.pdf.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.12081.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.12081.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.12081.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.11932.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.11932.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.11932.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.12849.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.12849.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.12849.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.11855.
[20.05.2025 06:17] Downloading paper 2505.11855 from http://arxiv.org/pdf/2505.11855v1...
[20.05.2025 06:17] Extracting affiliations from text.
[20.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 1 ] . [ 1 5 5 8 1 1 . 5 0 5 2 : r When AI Co-Scientists Fail: SPOTa Benchmark for Automated Verification of Scientific Research Guijin Son1,2 Hyunwoo Ko Jiwoo Hong3 Honglu Fan2 Heejeong Nam4 Jinha Choi5 Seungwon Lim5 Jinyeop Song6 Gonçalo Paulo2 Youngjae Yu5 Stella Biderman2 OneLineAI1 EleutherAI2 Yonsei University MIT6 KAIST AI3 Boeing Korea4 spthsrbwls123@yonsei.ac.kr "
[20.05.2025 06:17] Response: ```python
["OneLineAI", "EleutherAI", "Yonsei University", "MIT", "KAIST", "Boeing Korea"]
```
[20.05.2025 06:17] Deleting PDF ./assets/pdf/2505.11855.pdf.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13444.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.13444.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.13444.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.13437.
[20.05.2025 06:17] Extra JSON file exists (./assets/json/2505.13437.json), skip PDF parsing.
[20.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.13437.json), skip HTML parsing.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.12257.
[20.05.2025 06:17] Downloading paper 2505.12257 from http://arxiv.org/pdf/2505.12257v1...
[20.05.2025 06:17] Extracting affiliations from text.
[20.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Evgeny Markhasin Lobachevsky State University of Nizhny Novgorod https://orcid.org/0000-0002-7419-3605 https://linkedin.com/in/evgenymarkhasin "
[20.05.2025 06:17] Response: ```python
["Lobachevsky State University of Nizhny Novgorod"]
```
[20.05.2025 06:17] Deleting PDF ./assets/pdf/2505.12257.pdf.
[20.05.2025 06:17] Success.
[20.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.03332.
[20.05.2025 06:17] Downloading paper 2505.03332 from http://arxiv.org/pdf/2505.03332v3...
[20.05.2025 06:18] Extracting affiliations from text.
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning Evgeny Markhasin Lobachevsky State University of Nizhny Novgorod https://orcid.org/0000-0002-7419-3605 https://linkedin.com/in/evgenymarkhasin "
[20.05.2025 06:18] Response: ```python
["Lobachevsky State University of Nizhny Novgorod"]
```
[20.05.2025 06:18] Deleting PDF ./assets/pdf/2505.03332.pdf.
[20.05.2025 06:18] Success.
[20.05.2025 06:18] Enriching papers with extra data.
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 0. In this paper, we propose a novel learning paradigm, termed Chain-of-Model (CoM), which incorporates the causal relationship into the hidden states of each layer as a chain style, thereby introducing great scaling efficiency in model training and inference flexibility in deployment. We introduce the...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 1. Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to su...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 2. The attention mechanism of a transformer has a quadratic complexity, leading to high inference costs and latency for long sequences. However, attention matrices are mostly sparse, which implies that many entries may be omitted from computation for efficient inference. Sparse attention inference meth...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 3. Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking,...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 4. Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to cap...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 5. While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervisi...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 6. Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 7. Low-Rank Adaptation (LoRA), which introduces a product of two trainable low-rank matrices into frozen pre-trained weights, is widely used for efficient fine-tuning of language models in federated learning (FL). However, when combined with differentially private stochastic gradient descent (DP-SGD), ...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 8. Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many pr...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 9. Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates a...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 10. Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by genera...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 11. Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 12. Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic gra...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 13. Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computatio...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 14. Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we ...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 15. Chart understanding presents a unique challenge for large vision-language models (LVLMs), as it requires the integration of sophisticated textual and visual reasoning capabilities. However, current LVLMs exhibit a notable imbalance between these skills, falling short on visual reasoning that is diff...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 16. Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as "switch leap with 0.5 turn" poses subs...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 17. Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. Thi...
[20.05.2025 06:18] ********************************************************************************
[20.05.2025 06:18] Abstract 18. Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering met...
[20.05.2025 06:18] Read previous papers.
[20.05.2025 06:18] Generating reviews via LLM API.
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#training", "#open_source", "#inference", "#agi", "#architecture", "#optimization"], "emoji": "🔗", "ru": {"title": "Цепная революция в языковых моделях: гибкость и эффективность", "desc": "В этой статье представлена новая парадигма обучения под названием Chain-of-Model (CoM), котора
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rlhf", "#rl", "#training"], "emoji": "🧠", "ru": {"title": "AdaCoT: Умное рассуждение для языковых моделей", "desc": "AdaCoT - это новый фреймворк, позволяющий крупным языковым моделям (LLM) адаптивно решать, когда использовать метод цепочки рассуждени
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#architecture", "#inference", "#benchmark"], "emoji": "🔍", "ru": {"title": "Коррекция распределения для эффективного разреженного внимания", "desc": "Статья предлагает новый метод для повышения эффективности разреженного внимания в трансформерах. Ав
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#math", "#reasoning", "#inference", "#training", "#optimization", "#rl"], "emoji": "🧠", "ru": {"title": "Адаптивное мышление для оптимизации рассуждений ИИ", "desc": "Исследователи представили новый алгоритм AdaptThink, который учит модели рассуждения адаптивно выбирать оптимальный 
[20.05.2025 06:18] Querying the API.
[20.05.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at https://osworld-grounding.github.io.
[20.05.2025 06:18] Response: {
  "desc": "Статья представляет новый бенчмарк OSWorld-G для оценки способности моделей машинного обучения к интерпретации естественного языка в контексте графических интерфейсов. Авторы также создали крупнейший датасет Jedi, содержащий 4 миллиона примеров для обучения моделей взаимодействию с компьютерными интерфейсами. Модели, обученные на Jedi, превзошли существующие подходы на нескольких бенчмарках, включая OSWorld-G. Исследование показало, что улучшенное понимание интерфейсов значительно повышает способности крупных языковых моделей выполнять сложные компьютерные задачи.",
  "emoji": "🖥️",
  "title": "Революция в обучении ИИ работе с компьютерными интерфейсами"
}
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at https://osworld-grounding.github.io."

[20.05.2025 06:18] Response: ```python
['DATASET', 'BENCHMARK', 'DATA', 'AGENTS']
```
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at https://osworld-grounding.github.io."

[20.05.2025 06:18] Response: ```python
['GRAPHS', 'OPEN_SOURCE']
```
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of GUI grounding, which is the process of translating natural language commands into actions on graphical user interfaces. Current benchmarks are limited as they only focus on simple tasks, neglecting the complexities of real-world interactions that require understanding of software context and layout. The authors introduce OSWorld-G, a new benchmark with 564 detailed samples and the Jedi dataset, which contains 4 million examples to improve grounding tasks. Their findings show that using the Jedi dataset significantly enhances the performance of multi-scale models in executing complex computer tasks, demonstrating the importance of specialized data for effective grounding.","title":"Enhancing GUI Grounding with Comprehensive Datasets and Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenge of GUI grounding, which is the process of translating natural language commands into actions on graphical user interfaces. Current benchmarks are limited as they only focus on simple tasks, neglecting the complexities of real-world interactions that require understanding of software context and layout. The authors introduce OSWorld-G, a new benchmark with 564 detailed samples and the Jedi dataset, which contains 4 million examples to improve grounding tasks. Their findings show that using the Jedi dataset significantly enhances the performance of multi-scale models in executing complex computer tasks, demonstrating the importance of specialized data for effective grounding.', title='Enhancing GUI Grounding with Comprehensive Datasets and Models'))
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文探讨了图形用户界面（GUI）基础的自然语言指令映射问题，指出现有基准测试过于简化，无法反映真实世界的复杂交互。为了解决这一问题，作者提出了OSWorld-G基准，包含564个精细注释的样本，涵盖文本匹配、元素识别、布局理解和精确操作等多种任务类型。此外，作者合成并发布了最大的计算机使用基础数据集Jedi，包含400万个示例，展示了其在复杂计算机任务中的有效性。通过详细的消融研究，论文还识别了影响基础性能的关键因素，并验证了不同界面元素的专门数据结合能够实现对新界面的组合泛化。","title":"提升计算机使用代理的基础能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文探讨了图形用户界面（GUI）基础的自然语言指令映射问题，指出现有基准测试过于简化，无法反映真实世界的复杂交互。为了解决这一问题，作者提出了OSWorld-G基准，包含564个精细注释的样本，涵盖文本匹配、元素识别、布局理解和精确操作等多种任务类型。此外，作者合成并发布了最大的计算机使用基础数据集Jedi，包含400万个示例，展示了其在复杂计算机任务中的有效性。通过详细的消融研究，论文还识别了影响基础性能的关键因素，并验证了不同界面元素的专门数据结合能够实现对新界面的组合泛化。', title='提升计算机使用代理的基础能力'))
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#multimodal", "#math", "#training", "#open_source", "#benchmark", "#data", "#dataset"], "emoji": "🧠", "ru": {"title": "Автоматизированное обучение мультимодальных моделей пошаговым рассуждениям", "desc": "В статье представлена модель MM-PRM, обучающаяс
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#3d"], "emoji": "🎥", "ru": {"title": "Гибридный 3D-4D подход для эффективной реконструкции динамических сцен", "desc": "Статья представляет новый метод 3D-4DGS для реконструкции динамических 3D-сцен. Он комбинирует 3D гауссианы для статичных областей и 4D гауссианы для динамических 
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#training", "#data", "#benchmark", "#security", "#optimization"], "emoji": "🔒", "ru": {"title": "FedSVD: Защищенное федеративное обучение языковых моделей с сохранением эффективности", "desc": "Статья представляет новый метод FedSVD для эффективного федеративного обучения языковых м
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#benchmark", "#training"], "emoji": "🧠", "ru": {"title": "Умное переключение между кратким и развернутым мышлением в языковых моделях", "desc": "Статья представляет Thinkless - обучаемую систему, позволяющую языковым моделям адаптивно выбирать м
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "🧠", "ru": {"title": "Стабильное обучение с подкреплением для языковых моделей", "desc": "Статья представляет новый алгоритм CPGD для стабилизации обучения с подкреплением языковых моделей. CPGD вводит ограничение на дрейф 
[20.05.2025 06:18] Querying the API.
[20.05.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, a unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning.
[20.05.2025 06:18] Response: {
  "desc": "Эта статья представляет новый метод под названием Fractured Sampling для улучшения рассуждений больших языковых моделей (БЯМ) во время вывода. Метод основан на идее усечения цепочки рассуждений (Chain-of-Thought, CoT) и позволяет балансировать между полным CoT и генерацией только ответа по трем осям: количество траекторий рассуждений, количество финальных решений на траекторию и глубина усечения. Авторы показывают, что Fractured Sampling достигает лучшего соотношения точности и вычислительных затрат на пяти эталонных наборах данных для задач рассуждения. Результаты демонстрируют значительное улучшение масштабирования производительности БЯМ при рассуждениях без необходимости переобучения модели.",

  "emoji": "🧠",

  "title": "Эффективное масштабирование рассуждений языковых моделей без переобучения"
}
[20.05.2025 06:18] Renaming some terms.
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, a unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning."

[20.05.2025 06:18] Response: ```python
["INFERENCE", "BENCHMARK", "TRAINING"]
```
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, a unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning."

[20.05.2025 06:18] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new method called Fractured Sampling that enhances the reasoning abilities of large language models (LLMs) during inference without the need for retraining. It builds on the concept of Chain-of-Thought (CoT) prompting, which improves accuracy by generating intermediate reasoning steps, but often at a high token cost. The authors demonstrate that a truncated version of CoT can achieve similar results with significantly fewer tokens. By exploring different ways to balance reasoning depth and the number of solutions, Fractured Sampling offers a more efficient approach that improves accuracy while reducing computational costs.","title":"Efficient Reasoning with Fractured Sampling"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new method called Fractured Sampling that enhances the reasoning abilities of large language models (LLMs) during inference without the need for retraining. It builds on the concept of Chain-of-Thought (CoT) prompting, which improves accuracy by generating intermediate reasoning steps, but often at a high token cost. The authors demonstrate that a truncated version of CoT can achieve similar results with significantly fewer tokens. By exploring different ways to balance reasoning depth and the number of solutions, Fractured Sampling offers a more efficient approach that improves accuracy while reducing computational costs.', title='Efficient Reasoning with Fractured Sampling'))
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了一种新的推理时间缩放技术，称为Fractured Sampling，旨在提高大型语言模型（LLMs）的推理能力。通过截断链式思维（CoT），该方法在生成最终答案时减少了所需的token数量，同时保持了与完整CoT相似的准确性。Fractured Sampling在推理轨迹数量、每条轨迹的最终解决方案数量和推理深度等三个维度上进行插值，从而优化了准确性与成本的平衡。实验结果表明，该方法在多个推理基准上表现出色，能够实现更高效和可扩展的LLM推理。","title":"高效推理：Fractured Sampling的创新之路"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了一种新的推理时间缩放技术，称为Fractured Sampling，旨在提高大型语言模型（LLMs）的推理能力。通过截断链式思维（CoT），该方法在生成最终答案时减少了所需的token数量，同时保持了与完整CoT相似的准确性。Fractured Sampling在推理轨迹数量、每条轨迹的最终解决方案数量和推理深度等三个维度上进行插值，从而优化了准确性与成本的平衡。实验结果表明，该方法在多个推理基准上表现出色，能够实现更高效和可扩展的LLM推理。', title='高效推理：Fractured Sampling的创新之路'))
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#benchmark", "#reasoning"], "emoji": "🧠", "ru": {"title": "Единая модель для многозадачного визуального восприятия", "desc": "В статье представлен VisionReasoner - унифицированная модель для решения различных задач визуального восприятия. Модель использует новы
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rag", "#multimodal"], "emoji": "🧠", "ru": {"title": "Компиляция запросов для точного поиска в RAG-системах", "desc": "QCompiler - это нейро-символическая система для улучшения понимания сложных запросов в RAG-системах. Она использует минимальную грамм
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#open_source", "#cv", "#training"], "emoji": "🚀", "ru": {"title": "Ускорение генерации изображений в TarFlow с помощью оптимизированных итераций", "desc": "Данная статья представляет метод ускорения процесса сэмплирования в модели TarFlow для генера
[20.05.2025 06:18] Querying the API.
[20.05.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we explore a complementary application: using LLMs as verifiers to automate the academic verification of scientific manuscripts. To that end, we introduce SPOT, a dataset of 83 published papers paired with 91 errors significant enough to prompt errata or retraction, cross-validated with actual authors and human annotators. Evaluating state-of-the-art LLMs on SPOT, we find that none surpasses 21.1\% recall or 6.1\% precision (o3 achieves the best scores, with all others near zero). Furthermore, confidence estimates are uniformly low, and across eight independent runs, models rarely rediscover the same errors, undermining their reliability. Finally, qualitative analysis with domain experts reveals that even the strongest models make mistakes resembling student-level misconceptions derived from misunderstandings. These findings highlight the substantial gap between current LLM capabilities and the requirements for dependable AI-assisted academic verification.
[20.05.2025 06:18] Response: {
  "desc": "Статья представляет SPOT - набор данных из 83 опубликованных научных работ с 91 значительной ошибкой, приведшей к опечаткам или отзыву. Авторы оценивают способность современных больших языковых моделей (LLM) обнаруживать эти ошибки в качестве автоматических верификаторов научных рукописей. Результаты показывают, что даже лучшие модели достигают лишь 21.1% полноты и 6.1% точности, демонстрируя ненадежность и непоследовательность. Качественный анализ выявляет, что ошибки моделей напоминают студенческие заблуждения, указывая на значительный разрыв между текущими возможностями LLM и требованиями к надежной ИИ-assisted верификации научных работ.",
  "emoji": "🔍",
  "title": "Большие языковые модели пока не готовы быть научными рецензентами"
}
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we explore a complementary application: using LLMs as verifiers to automate the academic verification of scientific manuscripts. To that end, we introduce SPOT, a dataset of 83 published papers paired with 91 errors significant enough to prompt errata or retraction, cross-validated with actual authors and human annotators. Evaluating state-of-the-art LLMs on SPOT, we find that none surpasses 21.1\% recall or 6.1\% precision (o3 achieves the best scores, with all others near zero). Furthermore, confidence estimates are uniformly low, and across eight independent runs, models rarely rediscover the same errors, undermining their reliability. Finally, qualitative analysis with domain experts reveals that even the strongest models make mistakes resembling student-level misconceptions derived from misunderstandings. These findings highlight the substantial gap between current LLM capabilities and the requirements for dependable AI-assisted academic verification."

[20.05.2025 06:18] Response: ```python
['DATASET', 'DATA', 'BENCHMARK']
```
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we explore a complementary application: using LLMs as verifiers to automate the academic verification of scientific manuscripts. To that end, we introduce SPOT, a dataset of 83 published papers paired with 91 errors significant enough to prompt errata or retraction, cross-validated with actual authors and human annotators. Evaluating state-of-the-art LLMs on SPOT, we find that none surpasses 21.1\% recall or 6.1\% precision (o3 achieves the best scores, with all others near zero). Furthermore, confidence estimates are uniformly low, and across eight independent runs, models rarely rediscover the same errors, undermining their reliability. Finally, qualitative analysis with domain experts reveals that even the strongest models make mistakes resembling student-level misconceptions derived from misunderstandings. These findings highlight the substantial gap between current LLM capabilities and the requirements for dependable AI-assisted academic verification."

[20.05.2025 06:18] Response: ```python
["SCIENCE"]
```
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the use of large language models (LLMs) as tools for verifying scientific manuscripts, rather than just generating content. The authors introduce a dataset called SPOT, which includes published papers with significant errors that could lead to errata or retraction. They evaluate various state-of-the-art LLMs on this dataset and find that their performance is lacking, with low recall and precision rates. The study concludes that current LLMs are not yet reliable enough for academic verification, as they often make errors similar to those of novice students.","title":"Bridging the Gap: LLMs as Verifiers in Scientific Discovery"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the use of large language models (LLMs) as tools for verifying scientific manuscripts, rather than just generating content. The authors introduce a dataset called SPOT, which includes published papers with significant errors that could lead to errata or retraction. They evaluate various state-of-the-art LLMs on this dataset and find that their performance is lacking, with low recall and precision rates. The study concludes that current LLMs are not yet reliable enough for academic verification, as they often make errors similar to those of novice students.', title='Bridging the Gap: LLMs as Verifiers in Scientific Discovery'))
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文探讨了大型语言模型（LLMs）在学术验证中的应用，提出了一个名为SPOT的数据集，包含83篇已发表论文和91个显著错误。研究发现，当前最先进的LLMs在识别错误方面的表现不佳，最高召回率仅为21.1%，精确率为6.1%。此外，模型的置信度普遍较低，且在多次独立测试中，模型很少能重新发现相同的错误。通过与领域专家的定性分析，发现即使是最强的模型也会犯类似学生级别的误解错误，显示出当前LLMs在可靠的学术验证中存在显著差距。","title":"大型语言模型在学术验证中的挑战"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文探讨了大型语言模型（LLMs）在学术验证中的应用，提出了一个名为SPOT的数据集，包含83篇已发表论文和91个显著错误。研究发现，当前最先进的LLMs在识别错误方面的表现不佳，最高召回率仅为21.1%，精确率为6.1%。此外，模型的置信度普遍较低，且在多次独立测试中，模型很少能重新发现相同的错误。通过与领域专家的定性分析，发现即使是最强的模型也会犯类似学生级别的误解错误，显示出当前LLMs在可靠的学术验证中存在显著差距。', title='大型语言模型在学术验证中的挑战'))
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#open_source", "#interpretability", "#cv", "#benchmark", "#synthetic", "#reasoning", "#dataset"], "emoji": "📊", "ru": {"title": "Раскрывая пробелы в визуальном мышлении ИИ при анализе диаграмм", "desc": "Статья представляет новый тестовый набор данных ChartMuseum для оценки понимани
[20.05.2025 06:18] Using data from previous issue: {"categories": ["#3d", "#optimization", "#diffusion", "#video"], "emoji": "🤸", "ru": {"title": "Точная генерация движений человека с помощью физического моделирования", "desc": "Статья представляет FinePhys - фреймворк для генерации точных движений человека с использованием физических моделей. Систе
[20.05.2025 06:18] Querying the API.
[20.05.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. This exploratory proof-of-concept (PoC) study investigates structured LLM context conditioning, informed by Persistent Workflow Prompting (PWP) principles, as a methodological strategy to modulate this LLM behavior at inference time. The approach is designed to enhance the reliability of readily available, general-purpose LLMs (specifically Gemini 2.5 Pro and ChatGPT Plus o3) for precise validation tasks, crucially relying only on their standard chat interfaces without API access or model modifications. To explore this methodology, we focused on validating chemical formulas within a single, complex test paper with known textual and image-based errors. Several prompting strategies were evaluated: while basic prompts proved unreliable, an approach adapting PWP structures to rigorously condition the LLM's analytical mindset appeared to improve textual error identification with both models. Notably, this method also guided Gemini 2.5 Pro to repeatedly identify a subtle image-based formula error previously overlooked during manual review, a task where ChatGPT Plus o3 failed in our tests. These preliminary findings highlight specific LLM operational modes that impede detail-oriented validation and suggest that PWP-informed context conditioning offers a promising and highly accessible technique for developing more robust LLM-driven analytical workflows, particularly for tasks requiring meticulous error detection in scientific and technical documents. Extensive validation beyond this limited PoC is necessary to ascertain broader applicability.
[20.05.2025 06:18] Response: {
  "desc": "Это исследование изучает структурированный подход к настройке контекста больших языковых моделей (БЯМ) для улучшения их способности выявлять технические ошибки в сложных научных документах. Методология основана на принципах устойчивого рабочего процесса запросов (PWP) и направлена на повышение надежности общедоступных БЯМ для задач точной валидации. Эксперименты показали, что адаптированный PWP-подход улучшил идентификацию текстовых ошибок и даже позволил модели Gemini 2.5 Pro обнаружить скрытую ошибку в формуле на изображении. Результаты указывают на потенциал этого метода для разработки более надежных аналитических рабочих процессов на основе БЯМ, особенно для задач, требующих тщательного обнаружения ошибок в научно-технических документах.",
  "emoji": "🔍",
  "title": "Повышение точности БЯМ в обнаружении ошибок через структурированную настройку контекста"
}
[20.05.2025 06:18] Renaming some terms.
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. This exploratory proof-of-concept (PoC) study investigates structured LLM context conditioning, informed by Persistent Workflow Prompting (PWP) principles, as a methodological strategy to modulate this LLM behavior at inference time. The approach is designed to enhance the reliability of readily available, general-purpose LLMs (specifically Gemini 2.5 Pro and ChatGPT Plus o3) for precise validation tasks, crucially relying only on their standard chat interfaces without API access or model modifications. To explore this methodology, we focused on validating chemical formulas within a single, complex test paper with known textual and image-based errors. Several prompting strategies were evaluated: while basic prompts proved unreliable, an approach adapting PWP structures to rigorously condition the LLM's analytical mindset appeared to improve textual error identification with both models. Notably, this method also guided Gemini 2.5 Pro to repeatedly identify a subtle image-based formula error previously overlooked during manual review, a task where ChatGPT Plus o3 failed in our tests. These preliminary findings highlight specific LLM operational modes that impede detail-oriented validation and suggest that PWP-informed context conditioning offers a promising and highly accessible technique for developing more robust LLM-driven analytical workflows, particularly for tasks requiring meticulous error detection in scientific and technical documents. Extensive validation beyond this limited PoC is necessary to ascertain broader applicability."

[20.05.2025 06:18] Response: ```python
["MULTIMODAL", "INFERENCE"]
```
[20.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. This exploratory proof-of-concept (PoC) study investigates structured LLM context conditioning, informed by Persistent Workflow Prompting (PWP) principles, as a methodological strategy to modulate this LLM behavior at inference time. The approach is designed to enhance the reliability of readily available, general-purpose LLMs (specifically Gemini 2.5 Pro and ChatGPT Plus o3) for precise validation tasks, crucially relying only on their standard chat interfaces without API access or model modifications. To explore this methodology, we focused on validating chemical formulas within a single, complex test paper with known textual and image-based errors. Several prompting strategies were evaluated: while basic prompts proved unreliable, an approach adapting PWP structures to rigorously condition the LLM's analytical mindset appeared to improve textual error identification with both models. Notably, this method also guided Gemini 2.5 Pro to repeatedly identify a subtle image-based formula error previously overlooked during manual review, a task where ChatGPT Plus o3 failed in our tests. These preliminary findings highlight specific LLM operational modes that impede detail-oriented validation and suggest that PWP-informed context conditioning offers a promising and highly accessible technique for developing more robust LLM-driven analytical workflows, particularly for tasks requiring meticulous error detection in scientific and technical documents. Extensive validation beyond this limited PoC is necessary to ascertain broader applicability."

[20.05.2025 06:18] Response: ```python
["INTERPRETABILITY", "SCIENCE"]
```
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how to improve Large Language Models (LLMs) in identifying subtle errors in complex scientific documents, especially those with images and formulas. It introduces a method called Persistent Workflow Prompting (PWP) to better condition LLMs during their analysis, enhancing their ability to detect inaccuracies. The study specifically tests this approach on Gemini 2.5 Pro and ChatGPT Plus o3, showing that PWP can significantly improve error detection compared to basic prompting strategies. The findings suggest that this method could lead to more reliable LLMs for validating technical content, although further research is needed to confirm its effectiveness across different contexts.","title":"Enhancing LLM Accuracy in Scientific Error Detection with PWP"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how to improve Large Language Models (LLMs) in identifying subtle errors in complex scientific documents, especially those with images and formulas. It introduces a method called Persistent Workflow Prompting (PWP) to better condition LLMs during their analysis, enhancing their ability to detect inaccuracies. The study specifically tests this approach on Gemini 2.5 Pro and ChatGPT Plus o3, showing that PWP can significantly improve error detection compared to basic prompting strategies. The findings suggest that this method could lead to more reliable LLMs for validating technical content, although further research is needed to confirm its effectiveness across different contexts.', title='Enhancing LLM Accuracy in Scientific Error Detection with PWP'))
[20.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究探讨了如何利用结构化的上下文条件来改善大型语言模型（LLMs）在复杂科学和技术文档中的错误识别能力。研究采用了持久工作提示（PWP）原则，旨在提高LLMs在推理时的表现，尤其是在验证化学公式时。通过对不同提示策略的评估，发现适应PWP结构的提示能够有效提高文本错误的识别率，并成功发现了之前未被手动审查识别的图像公式错误。该方法为开发更强大的LLM驱动分析工作流提供了有希望的技术，尤其是在需要细致错误检测的任务中。","title":"提升LLM在科学文档中的错误识别能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究探讨了如何利用结构化的上下文条件来改善大型语言模型（LLMs）在复杂科学和技术文档中的错误识别能力。研究采用了持久工作提示（PWP）原则，旨在提高LLMs在推理时的表现，尤其是在验证化学公式时。通过对不同提示策略的评估，发现适应PWP结构的提示能够有效提高文本错误的识别率，并成功发现了之前未被手动审查识别的图像公式错误。该方法为开发更强大的LLM驱动分析工作流提供了有希望的技术，尤其是在需要细致错误检测的任务中。', title='提升LLM在科学文档中的错误识别能力'))
[20.05.2025 06:18] Querying the API.
[20.05.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering methodology designed to bridge this gap using standard LLM chat interfaces (zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical analysis of experimental chemistry manuscripts, featuring a hierarchical, modular architecture (structured via Markdown) that defines detailed analysis workflows. We develop this PWP prompt through iterative application of meta-prompting techniques and meta-reasoning aimed at systematically codifying expert review workflows, including tacit knowledge. Submitted once at the start of a session, this PWP prompt equips the LLM with persistent workflows triggered by subsequent queries, guiding modern reasoning LLMs through systematic, multimodal evaluations. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case while mitigating LLM input bias and performing complex tasks, including distinguishing claims from evidence, integrating text/photo/figure analysis to infer parameters, executing quantitative feasibility checks, comparing estimates against claims, and assessing a priori plausibility. To ensure transparency and facilitate replication, we provide full prompts, detailed demonstration analyses, and logs of interactive chats as supplementary resources. Beyond the specific application, this work offers insights into the meta-development process itself, highlighting the potential of PWP, informed by detailed workflow formalization, to enable sophisticated analysis using readily available LLMs for complex scientific tasks.
[20.05.2025 06:19] Response: {
  "desc": "Статья представляет новый метод инженерии промптов под названием Persistent Workflow Prompting (PWP) для улучшения способности больших языковых моделей (LLM) проводить критический анализ научных рукописей. PWP использует иерархическую модульную архитектуру для определения детальных рабочих процессов анализа, которые сохраняются в течение сессии. Метод был разработан с помощью итеративного применения мета-промптинга и мета-рассуждений для систематической кодификации экспертных процессов рецензирования. Демонстрации показывают, что PWP-управляемая LLM способна выявлять серьезные методологические недостатки и выполнять сложные задачи анализа.",

  "emoji": "🔬",

  "title": "PWP: Новый подход к критическому анализу научных работ с помощью LLM"
}
[20.05.2025 06:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering methodology designed to bridge this gap using standard LLM chat interfaces (zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical analysis of experimental chemistry manuscripts, featuring a hierarchical, modular architecture (structured via Markdown) that defines detailed analysis workflows. We develop this PWP prompt through iterative application of meta-prompting techniques and meta-reasoning aimed at systematically codifying expert review workflows, including tacit knowledge. Submitted once at the start of a session, this PWP prompt equips the LLM with persistent workflows triggered by subsequent queries, guiding modern reasoning LLMs through systematic, multimodal evaluations. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case while mitigating LLM input bias and performing complex tasks, including distinguishing claims from evidence, integrating text/photo/figure analysis to infer parameters, executing quantitative feasibility checks, comparing estimates against claims, and assessing a priori plausibility. To ensure transparency and facilitate replication, we provide full prompts, detailed demonstration analyses, and logs of interactive chats as supplementary resources. Beyond the specific application, this work offers insights into the meta-development process itself, highlighting the potential of PWP, informed by detailed workflow formalization, to enable sophisticated analysis using readily available LLMs for complex scientific tasks."

[20.05.2025 06:19] Response: ```python
['DATA', 'MULTIMODAL', 'ARCHITECTURE']
```
[20.05.2025 06:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering methodology designed to bridge this gap using standard LLM chat interfaces (zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical analysis of experimental chemistry manuscripts, featuring a hierarchical, modular architecture (structured via Markdown) that defines detailed analysis workflows. We develop this PWP prompt through iterative application of meta-prompting techniques and meta-reasoning aimed at systematically codifying expert review workflows, including tacit knowledge. Submitted once at the start of a session, this PWP prompt equips the LLM with persistent workflows triggered by subsequent queries, guiding modern reasoning LLMs through systematic, multimodal evaluations. Demonstrations show the PWP-guided LLM identifying major methodological flaws in a test case while mitigating LLM input bias and performing complex tasks, including distinguishing claims from evidence, integrating text/photo/figure analysis to infer parameters, executing quantitative feasibility checks, comparing estimates against claims, and assessing a priori plausibility. To ensure transparency and facilitate replication, we provide full prompts, detailed demonstration analyses, and logs of interactive chats as supplementary resources. Beyond the specific application, this work offers insights into the meta-development process itself, highlighting the potential of PWP, informed by detailed workflow formalization, to enable sophisticated analysis using readily available LLMs for complex scientific tasks."

[20.05.2025 06:19] Response: ```python
["REASONING", "SCIENCE", "INTERPRETABILITY"]
```
[20.05.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenges faced by Large Language Models (LLMs) in performing critical peer reviews of scientific manuscripts, particularly due to data limitations and the intricacies of expert reasoning. It introduces a new methodology called Persistent Workflow Prompting (PWP), which allows users to create structured prompts that guide LLMs through detailed analysis workflows without needing coding skills. The PWP framework is designed to help LLMs systematically evaluate scientific content by integrating various forms of data, such as text and images, to identify flaws and assess claims. The authors demonstrate the effectiveness of PWP in analyzing experimental chemistry manuscripts, showcasing its ability to enhance LLM performance in complex scientific evaluations.","title":"Empowering LLMs for Expert Scientific Review with Persistent Workflow Prompting"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenges faced by Large Language Models (LLMs) in performing critical peer reviews of scientific manuscripts, particularly due to data limitations and the intricacies of expert reasoning. It introduces a new methodology called Persistent Workflow Prompting (PWP), which allows users to create structured prompts that guide LLMs through detailed analysis workflows without needing coding skills. The PWP framework is designed to help LLMs systematically evaluate scientific content by integrating various forms of data, such as text and images, to identify flaws and assess claims. The authors demonstrate the effectiveness of PWP in analyzing experimental chemistry manuscripts, showcasing its ability to enhance LLM performance in complex scientific evaluations.', title='Empowering LLMs for Expert Scientific Review with Persistent Workflow Prompting'))
[20.05.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文介绍了一种新的提示工程方法，称为持久工作流提示（PWP），旨在帮助大型语言模型（LLMs）进行科学手稿的批判性同行评审。PWP通过标准的LLM聊天界面，使用分层模块化的架构，定义详细的分析工作流程，能够系统化地编码专家评审的工作流程。通过迭代的元提示技术和元推理，PWP能够引导LLM进行多模态评估，识别实验化学手稿中的主要方法论缺陷。该方法不仅提供了具体应用的示例，还展示了如何利用现有的LLM进行复杂科学任务的深入分析。","title":"持久工作流提示：提升科学评审的智能化"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文介绍了一种新的提示工程方法，称为持久工作流提示（PWP），旨在帮助大型语言模型（LLMs）进行科学手稿的批判性同行评审。PWP通过标准的LLM聊天界面，使用分层模块化的架构，定义详细的分析工作流程，能够系统化地编码专家评审的工作流程。通过迭代的元提示技术和元推理，PWP能够引导LLM进行多模态评估，识别实验化学手稿中的主要方法论缺陷。该方法不仅提供了具体应用的示例，还展示了如何利用现有的LLM进行复杂科学任务的深入分析。', title='持久工作流提示：提升科学评审的智能化'))
[20.05.2025 06:19] Loading Chinese text from previous data.
[20.05.2025 06:19] Renaming data file.
[20.05.2025 06:19] Renaming previous data. hf_papers.json to ./d/2025-05-20.json
[20.05.2025 06:19] Saving new data file.
[20.05.2025 06:19] Generating page.
[20.05.2025 06:19] Renaming previous page.
[20.05.2025 06:19] Renaming previous data. index.html to ./d/2025-05-20.html
[20.05.2025 06:19] [Experimental] Generating Chinese page for reading.
[20.05.2025 06:19] Chinese vocab [{'word': '系列', 'pinyin': 'xìliè', 'trans': 'series'}, {'word': '版本', 'pinyin': 'bǎnběn', 'trans': 'version'}, {'word': '旨在', 'pinyin': 'zhǐzài', 'trans': 'aim to'}, {'word': '效率', 'pinyin': 'xiàolǜ', 'trans': 'efficiency'}, {'word': '多语言', 'pinyin': 'duōyǔyán', 'trans': 'multilingual'}, {'word': '能力', 'pinyin': 'nénglì', 'trans': 'ability'}, {'word': '包含', 'pinyin': 'bāohán', 'trans': 'contain'}, {'word': '密集', 'pinyin': 'mìjí', 'trans': 'dense'}, {'word': '混合', 'pinyin': 'hùnhé', 'trans': 'hybrid'}, {'word': '专家', 'pinyin': 'zhuānjiā', 'trans': 'expert'}, {'word': '架构', 'pinyin': 'jiàgòu', 'trans': 'architecture'}, {'word': '参数', 'pinyin': 'cānshǔ', 'trans': 'parameter'}, {'word': '规模', 'pinyin': 'guīmó', 'trans': 'scale'}, {'word': '创新', 'pinyin': 'chuàngxīn', 'trans': 'innovation'}, {'word': '之处', 'pinyin': 'zhīchù', 'trans': 'place'}, {'word': '思考', 'pinyin': 'sīkǎo', 'trans': 'think'}, {'word': '模式', 'pinyin': 'móshì', 'trans': 'mode'}, {'word': '结合', 'pinyin': 'jiéhé', 'trans': 'combine'}, {'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'}, {'word': '消除', 'pinyin': 'xiāochú', 'trans': 'eliminate'}, {'word': '切换', 'pinyin': 'qiēhuàn', 'trans': 'switch'}, {'word': '需要', 'pinyin': 'xūyào', 'trans': 'need'}, {'word': '引入', 'pinyin': 'yǐnrù', 'trans': 'introduce'}, {'word': '预算', 'pinyin': 'yùsuàn', 'trans': 'budget'}, {'word': '机制', 'pinyin': 'jīzhì', 'trans': 'mechanism'}, {'word': '允许', 'pinyin': 'yǔnxǔ', 'trans': 'allow'}, {'word': '根据', 'pinyin': 'gēnjù', 'trans': 'according to'}, {'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'}, {'word': '复杂性', 'pinyin': 'fùzáxìng', 'trans': 'complexity'}, {'word': '动态', 'pinyin': 'dòngtài', 'trans': 'dynamic'}, {'word': '分配', 'pinyin': 'fēnpèi', 'trans': 'allocate'}, {'word': '计算', 'pinyin': 'jìsuàn', 'trans': 'compute'}, {'word': '资源', 'pinyin': 'zīyuán', 'trans': 'resources'}]
[20.05.2025 06:19] Renaming previous Chinese page.
[20.05.2025 06:19] Renaming previous data. zh.html to ./d/2025-05-19_zh_reading_task.html
[20.05.2025 06:19] Writing Chinese reading task.
[20.05.2025 06:19] Writing result.
[20.05.2025 06:19] Renaming log file.
[20.05.2025 06:19] Renaming previous data. log.txt to ./logs/2025-05-20_last_log.txt
