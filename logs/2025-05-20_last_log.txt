[20.05.2025 09:14] Read previous papers.
[20.05.2025 09:14] Generating top page (month).
[20.05.2025 09:14] Writing top page (month).
[20.05.2025 10:13] Read previous papers.
[20.05.2025 10:13] Get feed.
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11820
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13417
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11896
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11254
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13227
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13379
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13427
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13308
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13215
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12805
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12504
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13389
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12992
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12081
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11932
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13180
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12849
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11855
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13444
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10238
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13437
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12996
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11484
[20.05.2025 10:13] Extract page data from URL. URL: https://huggingface.co/papers/2505.12872
[20.05.2025 10:13] Extract page data from URL. URL: https://huggingface.co/papers/2505.12058
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11497
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12257
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.11988
[20.05.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2505.03332
[20.05.2025 10:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.05.2025 10:13] No deleted papers detected.
[20.05.2025 10:13] Downloading and parsing papers (pdf, html). Total: 29.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11820.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11820.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11820.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13417.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13417.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13417.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11896.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11896.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11896.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11254.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11254.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11254.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13227.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13227.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13227.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13379.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13379.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13379.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13427.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13427.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13427.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13308.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13308.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13308.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13215.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13215.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13215.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12805.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12805.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12805.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12504.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12504.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12504.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13389.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13389.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13389.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12992.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12992.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12992.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12081.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12081.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12081.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11932.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11932.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11932.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13180.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13180.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13180.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12849.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12849.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12849.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11855.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11855.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11855.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13444.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13444.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13444.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.10238.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.10238.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.10238.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.13437.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.13437.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.13437.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12996.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12996.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12996.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11484.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11484.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11484.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12872.
[20.05.2025 10:13] Downloading paper 2505.12872 from http://arxiv.org/pdf/2505.12872v1...
[20.05.2025 10:13] Extracting affiliations from text.
[20.05.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 2 7 8 2 1 . 5 0 5 2 : r From Grunts to Grammar: Emergent Language from Cooperative Foraging Maytus Piriyajitakonkij1,2,3 Mingfei Sun3 Wei Pan3 Rujikorn Charakorn5 Cheston Tan1,4 Weicheng Tao2 Mengmi Zhang1,2,4 1Institute for Infocomm Research (I2R), ASTAR, Singapore 2College of Computing and Data Science, Nanyang Technological University, Singapore 3Department of Computer Science, The University of Manchester, United Kingdom 4Centre for Frontier AI Research (CFAR), ASTAR, Singapore 5Sakana AI, Japan Address correspondence to mengmi.zhang@ntu.edu.sg "
[20.05.2025 10:13] Response: ```python
[
    "Institute for Infocomm Research (I2R), ASTAR, Singapore",
    "College of Computing and Data Science, Nanyang Technological University, Singapore",
    "Department of Computer Science, The University of Manchester, United Kingdom",
    "Centre for Frontier AI Research (CFAR), ASTAR, Singapore",
    "Sakana AI, Japan"
]
```
[20.05.2025 10:13] Deleting PDF ./assets/pdf/2505.12872.pdf.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12058.
[20.05.2025 10:13] Downloading paper 2505.12058 from http://arxiv.org/pdf/2505.12058v1...
[20.05.2025 10:13] Extracting affiliations from text.
[20.05.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 1 ] . [ 1 8 5 0 2 1 . 5 0 5 2 : r Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation Vincent Koc Comet ML, Inc. New York, NY, USA vincentk@comet.com Abstract Tiny QA Benchmark++ (TQB++) is an ultra-lightweight evaluation suite designed to expose critical failures in Large Language Model (LLM) systems within seconds, contrasting with extensive benchmarks like MMLU or BIG-Bench. At its heart lies <20KB golden dataset of 52 hand-crafted English Question-Answering (QA) triples, ideal for rapid CI/CD checks and prompt engineering. This paper details the evolution into Tiny QA Benchmark++, which significantly expands upon the original TQB. Key enhancements include: (i) synthetic, on-demand generation toolkita Python LiteLLM script (<300 lines)that produces schema-validated micro-benchmarks in any language, domain, or difficulty, with SHA-256 hashing for provenance; and (ii) pre-built multilingual packs <20KB for Arabic (AR), German (DE), English (EN), Spanish (ES), French (FR), Japanese (JA), Russian (RU), Korean (KO), Portuguese (PT), Turkish (TR), and Chinese (ZH), enabling immediate cross-lingual smoke tests. We position TQB++ as the LLM analogue of software unit tests. Empirically, top-tier models achieve high accuracy ( 90% Exact Match) on the core English set, while performance significantly varies for low-resource languages, demonstrating TQB++s utility in rapidly detecting regressions or quality shifts in LLMOps workflows. The dataset, generator script, and related tools are released under open-source licenses (see Section 1.1 for details) and hosted on the Hugging Face Hub (https://huggingface.co /datasets/vincentkoc/tiny_qa_benchmark_pp) and GitHub (https://github.com/v incentkoc/tiny_qa_benchmark_pp) (Koc, 2025e), promoting accessible and continuous quality assurance in modern LLMOps. Keywords: LLM Evaluation, QA Benchmarks, Synthetic Data, LLMOps, Continuous Integration, Smoke"
[20.05.2025 10:13] Response: ```python
["Comet ML, Inc. New York, NY, USA"]
```
[20.05.2025 10:13] Deleting PDF ./assets/pdf/2505.12058.pdf.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11497.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11497.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11497.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.12257.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.12257.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.12257.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.11988.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.11988.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.11988.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2505.03332.
[20.05.2025 10:13] Extra JSON file exists (./assets/json/2505.03332.json), skip PDF parsing.
[20.05.2025 10:13] Paper image links file exists (./assets/img_data/2505.03332.json), skip HTML parsing.
[20.05.2025 10:13] Success.
[20.05.2025 10:13] Enriching papers with extra data.
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 0. In this paper, we propose a novel learning paradigm, termed Chain-of-Model (CoM), which incorporates the causal relationship into the hidden states of each layer as a chain style, thereby introducing great scaling efficiency in model training and inference flexibility in deployment. We introduce the...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 1. Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking,...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 2. Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to su...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 3. The attention mechanism of a transformer has a quadratic complexity, leading to high inference costs and latency for long sequences. However, attention matrices are mostly sparse, which implies that many entries may be omitted from computation for efficient inference. Sparse attention inference meth...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 4. Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to cap...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 5. Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many pr...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 6. While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervisi...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 7. Reasoning ability, a core component of human intelligence, continues to pose a significant challenge for Large Language Models (LLMs) in the pursuit of AGI. Although model performance has improved under the training scaling law, significant challenges remain, particularly with respect to training al...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 8. Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 9. Low-Rank Adaptation (LoRA), which introduces a product of two trainable low-rank matrices into frozen pre-trained weights, is widely used for efficient fine-tuning of language models in federated learning (FL). However, when combined with differentially private stochastic gradient descent (DP-SGD), ...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 10. Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates a...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 11. Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D attention, even though most of the attention mass concentrates on a small subset of positions. We turn this observation into VSA, a trainable, hardware-efficient sparse attention that replaces full attention at both trainin...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 12. Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by genera...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 13. Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 14. Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic gra...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 15. Integrating Large Language Models with symbolic planners is a promising direction for obtaining verifiable and grounded plans compared to planning in natural language, with recent works extending this idea to visual domains using Vision-Language Models (VLMs). However, rigorous comparison between VL...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 16. Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computatio...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 17. Recent advances in large language models (LLMs) have fueled the vision of automated scientific discovery, often called AI Co-Scientists. To date, prior work casts these systems as generative co-authors responsible for crafting hypotheses, synthesizing code, or drafting manuscripts. In this work, we ...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 18. Chart understanding presents a unique challenge for large vision-language models (LVLMs), as it requires the integration of sophisticated textual and visual reasoning capabilities. However, current LVLMs exhibit a notable imbalance between these skills, falling short on visual reasoning that is diff...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 19. Human image animation has gained increasing attention and developed rapidly due to its broad applications in digital humans. However, existing methods rely largely on 2D-rendered pose images for motion guidance, which limits generalization and discards essential 3D information for open-world animati...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 20. Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as "switch leap with 0.5 turn" poses subs...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 21. In recent years, the emergence of large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex problems, e.g., mathematics and coding. Some pioneering studies attempt to bring the success of LRMs in neural machine translation (MT). They try to build ...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 22. Test-Time Scaling (TTS) refers to approaches that improve reasoning performance by allocating extra computation during inference, without altering the model's parameters. While existing TTS methods operate in a discrete token space by generating more intermediate steps, recent studies in Coconut and...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 23. Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vit...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 24. Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual smoke-test suite designed to give large-language-model (LLM) pipelines a unit-test style safety net dataset that runs in seconds with minimal cost. Born out of the tight feedback-loop demands building the Comet Opik prompt-optim...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 25. Video diffusion models (DMs) have enabled high-quality video synthesis. Yet, their substantial computational and memory demands pose serious challenges to real-world deployment, even on high-end GPUs. As a commonly adopted solution, quantization has proven notable success in reducing cost for image ...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 26. Identifying subtle technical errors within complex scientific and technical documents, especially those requiring multimodal interpretation (e.g., formulas in images), presents a significant hurdle for Large Language Models (LLMs) whose inherent error-correction tendencies can mask inaccuracies. Thi...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 27. Accurately identifying adversarial techniques in security texts is critical for effective cyber defense. However, existing methods face a fundamental trade-off: they either rely on generic models with limited domain precision or require resource-intensive pipelines that depend on large labeled datas...
[20.05.2025 10:13] ********************************************************************************
[20.05.2025 10:13] Abstract 28. Critical peer review of scientific manuscripts presents a significant challenge for Large Language Models (LLMs), partly due to data limitations and the complexity of expert reasoning. This report introduces Persistent Workflow Prompting (PWP), a potentially broadly applicable prompt engineering met...
[20.05.2025 10:13] Read previous papers.
[20.05.2025 10:13] Generating reviews via LLM API.
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#training", "#open_source", "#inference", "#agi", "#architecture", "#optimization"], "emoji": "ðŸ”—", "ru": {"title": "Ð¦ÐµÐ¿Ð½Ð°Ñ Ñ€ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÑÑ…: Ð³Ð¸Ð±ÐºÐ¾ÑÑ‚ÑŒ Ð¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ", "desc": "Ð’ ÑÑ‚Ð¾Ð¹ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð° Ð½Ð¾Ð²Ð°Ñ Ð¿Ð°Ñ€Ð°Ð´Ð¸Ð³Ð¼Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Chain-of-Model (CoM), ÐºÐ¾Ñ‚Ð¾Ñ€Ð°
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#math", "#reasoning", "#inference", "#training", "#optimization", "#rl"], "emoji": "ðŸ§ ", "ru": {"title": "ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ð˜Ð˜", "desc": "Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Ð½Ð¾Ð²Ñ‹Ð¹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ AdaptThink, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑƒÑ‡Ð¸Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾ Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ñ‚ÑŒ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ 
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rlhf", "#rl", "#training"], "emoji": "ðŸ§ ", "ru": {"title": "AdaCoT: Ð£Ð¼Ð½Ð¾Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "AdaCoT - ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº, Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‰Ð¸Ð¹ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ð¼ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ð¼ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼ (LLM) Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾ Ñ€ÐµÑˆÐ°Ñ‚ÑŒ, ÐºÐ¾Ð³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼ÐµÑ‚Ð¾Ð´ Ñ†ÐµÐ¿Ð¾Ñ‡ÐºÐ¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#architecture", "#inference", "#benchmark"], "emoji": "ðŸ”", "ru": {"title": "ÐšÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ñ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ñ€ÐµÐ¶ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð°Ð·Ñ€ÐµÐ¶ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð² Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð°Ñ…. ÐÐ²
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#data", "#dataset", "#graphs", "#agents", "#benchmark", "#open_source"], "emoji": "ðŸ–¥ï¸", "ru": {"title": "Ð ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð˜Ð˜ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ñ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ñ‹Ð¼Ð¸ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°Ð¼Ð¸", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº OSWorld-G Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ðº Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#benchmark", "#training"], "emoji": "ðŸ§ ", "ru": {"title": "Ð£Ð¼Ð½Ð¾Ðµ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼ Ð¸ Ñ€Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚Ñ‹Ð¼ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð² ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÑÑ…", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Thinkless - Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ, Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÑŽÑ‰ÑƒÑŽ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ð¼ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾ Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ñ‚ÑŒ Ð¼
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#multimodal", "#math", "#training", "#open_source", "#benchmark", "#data", "#dataset"], "emoji": "ðŸ§ ", "ru": {"title": "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ñ‹Ð¼ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸ÑÐ¼", "desc": "Ð’ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ MM-PRM, Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð°ÑÑ
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#architecture", "#reasoning", "#training", "#agi"], "emoji": "ðŸ§ ", "ru": {"title": "LatentSeek: ÐŸÐ¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ðµ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð°ÑÑÑƒÐ¶Ð´Ð°Ñ‚ÑŒ Ñƒ Ð˜Ð˜ Ñ‡ÐµÑ€ÐµÐ· Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸ÑŽ Ð² Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²Ðµ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ LatentSeek - Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ ÑÐ¿Ð¾Ñ
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#3d"], "emoji": "ðŸŽ¥", "ru": {"title": "Ð“Ð¸Ð±Ñ€Ð¸Ð´Ð½Ñ‹Ð¹ 3D-4D Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑÑ†ÐµÐ½", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ 3D-4DGS Ð´Ð»Ñ Ñ€ÐµÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… 3D-ÑÑ†ÐµÐ½. ÐžÐ½ ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€ÑƒÐµÑ‚ 3D Ð³Ð°ÑƒÑÑÐ¸Ð°Ð½Ñ‹ Ð´Ð»Ñ ÑÑ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¾Ð±Ð»Ð°ÑÑ‚ÐµÐ¹ Ð¸ 4D Ð³Ð°ÑƒÑÑÐ¸Ð°Ð½Ñ‹ Ð´Ð»Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… 
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#training", "#data", "#benchmark", "#security", "#optimization"], "emoji": "ðŸ”’", "ru": {"title": "FedSVD: Ð—Ð°Ñ‰Ð¸Ñ‰ÐµÐ½Ð½Ð¾Ðµ Ñ„ÐµÐ´ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸ÐµÐ¼ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ FedSVD Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ„ÐµÐ´ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "ðŸ§ ", "ru": {"title": "Ð¡Ñ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ CPGD Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹. CPGD Ð²Ð²Ð¾Ð´Ð¸Ñ‚ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ð´Ñ€ÐµÐ¹Ñ„ 
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#diffusion", "#training", "#open_source", "#video"], "emoji": "ðŸŽ¥", "ru": {"title": "Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ñ€Ð°Ð·Ñ€ÐµÐ¶ÐµÐ½Ð½Ð¾Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾-Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ñ€Ð°Ð·Ñ€ÐµÐ¶ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ (VSA) Ð´Ð»Ñ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#benchmark", "#inference"], "emoji": "ðŸ§ ", "ru": {"title": "Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð±ÐµÐ· Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ", "desc": "Ð­Ñ‚Ð° ÑÑ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Fractured Sampling Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ 
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#benchmark", "#reasoning"], "emoji": "ðŸ§ ", "ru": {"title": "Ð•Ð´Ð¸Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¼Ð½Ð¾Ð³Ð¾Ð·Ð°Ð´Ð°Ñ‡Ð½Ð¾Ð³Ð¾ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ð¾ÑÐ¿Ñ€Ð¸ÑÑ‚Ð¸Ñ", "desc": "Ð’ ÑÑ‚Ð°Ñ‚ÑŒÐµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ VisionReasoner - ÑƒÐ½Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ð¾ÑÐ¿Ñ€Ð¸ÑÑ‚Ð¸Ñ. ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð½Ð¾Ð²Ñ‹
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rag", "#multimodal"], "emoji": "ðŸ§ ", "ru": {"title": "ÐšÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð´Ð»Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² RAG-ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ…", "desc": "QCompiler - ÑÑ‚Ð¾ Ð½ÐµÐ¹Ñ€Ð¾-ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð² RAG-ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ…. ÐžÐ½Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð³Ñ€Ð°Ð¼Ð¼
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#benchmark", "#video", "#cv", "#games", "#reasoning", "#agents", "#open_source"], "emoji": "ðŸ¤–", "ru": {"title": "ViPlan: Ð½Ð¾Ð²Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ ÑÐ¸Ð¼Ð²Ð¾Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¸ Ð¿Ñ€ÑÐ¼Ð¾Ð³Ð¾ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ViPlan - Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ñ‹Ð¹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð»Ð°Ð½Ð¸
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#open_source", "#cv", "#training"], "emoji": "ðŸš€", "ru": {"title": "Ð£ÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ðµ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² TarFlow Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹", "desc": "Ð”Ð°Ð½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° ÑÑÐ¼Ð¿Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ TarFlow Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#data", "#science", "#dataset", "#benchmark"], "emoji": "ðŸ”", "ru": {"title": "Ð‘Ð¾Ð»ÑŒÑˆÐ¸Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ð¼Ð¸ Ñ€ÐµÑ†ÐµÐ½Ð·ÐµÐ½Ñ‚Ð°Ð¼Ð¸", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ SPOT - Ð½Ð°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· 83 Ð¾Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ñ… Ñ€Ð°Ð±Ð¾Ñ‚ Ñ 91 Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹, Ð¿Ñ€Ð¸Ð²ÐµÐ´ÑˆÐµÐ¹ Ðº Ð¾Ð¿ÐµÑ‡Ð°Ñ‚ÐºÐ°Ð¼ Ð¸Ð»Ð¸ 
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#open_source", "#interpretability", "#cv", "#benchmark", "#synthetic", "#reasoning", "#dataset"], "emoji": "ðŸ“Š", "ru": {"title": "Ð Ð°ÑÐºÑ€Ñ‹Ð²Ð°Ñ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð² Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸Ð¸ Ð˜Ð˜ Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… ChartMuseum Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#3d", "#video"], "emoji": "ðŸ•º", "ru": {"title": "Ð ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² Ð°Ð½Ð¸Ð¼Ð°Ñ†Ð¸Ð¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°: Ð¾Ñ‚ 2D Ðº 4D Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸ÑŽ", "desc": "MTVCrafter - ÑÑ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð°Ð½Ð¸Ð¼Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‰Ð¸Ð¹ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸ÑŽ 4D Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð²Ð¼ÐµÑÑ‚Ð¾ 2D-Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¿Ð¾Ð·. ÐœÐµÑ‚Ð¾Ð´ Ð²Ð²Ð¾Ð´Ð¸Ñ‚ 4DMoT Ð´Ð»Ñ ÐºÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ñ 3D Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#3d", "#optimization", "#diffusion", "#video"], "emoji": "ðŸ¤¸", "ru": {"title": "Ð¢Ð¾Ñ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ FinePhys - Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹. Ð¡Ð¸ÑÑ‚Ðµ
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#reasoning", "#multilingual", "#rl", "#low_resource", "#machine_translation"], "emoji": "ðŸŒ", "ru": {"title": "Ð ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð¼ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ðµ: Ð¾Ñ‚ Ð¾Ð´Ð½Ð¾ÑÐ·Ñ‹Ñ‡Ð½Ð¾Ð³Ð¾ Ðº Ð¼Ð½Ð¾Ð³Ð¾ÑÐ·Ñ‹Ñ‡Ð½Ð¾Ð¼Ñƒ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½ÑÑ‚Ð²Ñƒ", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²Ð¾Ð·Ð½Ð°Ð³Ñ€Ð°Ð¶Ð´ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼
[20.05.2025 10:13] Using data from previous issue: {"categories": ["#optimization", "#inference", "#benchmark", "#reasoning", "#training"], "emoji": "ðŸ§ ", "ru": {"title": "Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹ Ð˜Ð˜ Ñ‡ÐµÑ€ÐµÐ· Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹Ðµ Ð¼Ñ‹ÑÐ»Ð¸", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¼ÐµÑ‚Ð¾Ð´ SoftCoT++, ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÑŽÑ‰Ð¸Ð¹ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð² Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ð¾Ð¼ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°
[20.05.2025 10:13] Querying the API.
[20.05.2025 10:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vital for teamwork? Understanding the origins of language remains a challenge. A leading hypothesis in linguistics and anthropology posits that language evolved to meet the ecological and social demands of early human cooperation. Language did not arise in isolation, but through shared survival goals. Inspired by this view, we investigate the emergence of language in multi-agent Foraging Games. These environments are designed to reflect the cognitive and ecological constraints believed to have influenced the evolution of communication. Agents operate in a shared grid world with only partial knowledge about other agents and the environment, and must coordinate to complete games like picking up high-value targets or executing temporally ordered actions. Using end-to-end deep reinforcement learning, agents learn both actions and communication strategies from scratch. We find that agents develop communication protocols with hallmark features of natural language: arbitrariness, interchangeability, displacement, cultural transmission, and compositionality. We quantify each property and analyze how different factors, such as population size and temporal dependencies, shape specific aspects of the emergent language. Our framework serves as a platform for studying how language can evolve from partial observability, temporal reasoning, and cooperative goals in embodied multi-agent settings. We will release all data, code, and models publicly.
[20.05.2025 10:13] Response: {
  "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÑ‚ ÑÐ²Ð¾Ð»ÑŽÑ†Ð¸ÑŽ ÑÐ·Ñ‹ÐºÐ° Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ Ð¼Ð½Ð¾Ð³Ð¾Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ‹Ñ… Ð¸Ð³Ñ€ Ð¿Ð¾ Ð´Ð¾Ð±Ñ‹Ñ‡Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð², Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼. ÐÐ²Ñ‚Ð¾Ñ€Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€ÑƒÑŽÑ‚ ÑÑ€ÐµÐ´Ñƒ, Ð¾Ñ‚Ñ€Ð°Ð¶Ð°ÑŽÑ‰ÑƒÑŽ ÐºÐ¾Ð³Ð½Ð¸Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¸ ÑÐºÐ¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ, Ð¿Ð¾Ð²Ð»Ð¸ÑÐ²ÑˆÐ¸Ðµ Ð½Ð° Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ñƒ Ñ€Ð°Ð½Ð½Ð¸Ñ… Ð»ÑŽÐ´ÐµÐ¹. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽÑ‚, Ñ‡Ñ‚Ð¾ Ð°Ð³ÐµÐ½Ñ‚Ñ‹ Ñ€Ð°Ð·Ð²Ð¸Ð²Ð°ÑŽÑ‚ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð»Ñ‹ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ñ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼Ð¸ ÑÐ²Ð¾Ð¹ÑÑ‚Ð²Ð°Ð¼Ð¸ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ°: Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ, Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼Ð¾ÑÑ‚ÑŒ, ÑÐ¼ÐµÑ‰ÐµÐ½Ð¸Ðµ, ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð½ÑƒÑŽ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ñƒ Ð¸ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ð¾ÑÑ‚ÑŒ. Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ñƒ Ð´Ð»Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ²Ð¾Ð»ÑŽÑ†Ð¸Ð¸ ÑÐ·Ñ‹ÐºÐ° Ð² ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ… Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾Ð¹ Ð½Ð°Ð±Ð»ÑŽÐ´Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸, Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ Ð¸ ÐºÐ¾Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ†ÐµÐ»ÐµÐ¹ Ð² Ð¼Ð½Ð¾Ð³Ð¾Ð°Ð³ÐµÐ½Ñ‚Ð½Ñ‹Ñ… ÑÑ€ÐµÐ´Ð°Ñ….",
  "emoji": "ðŸ—£ï¸",
  "title": "Ð­Ð²Ð¾Ð»ÑŽÑ†Ð¸Ñ ÑÐ·Ñ‹ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¸Ð·Ð¼Ñƒ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð°"
}
[20.05.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vital for teamwork? Understanding the origins of language remains a challenge. A leading hypothesis in linguistics and anthropology posits that language evolved to meet the ecological and social demands of early human cooperation. Language did not arise in isolation, but through shared survival goals. Inspired by this view, we investigate the emergence of language in multi-agent Foraging Games. These environments are designed to reflect the cognitive and ecological constraints believed to have influenced the evolution of communication. Agents operate in a shared grid world with only partial knowledge about other agents and the environment, and must coordinate to complete games like picking up high-value targets or executing temporally ordered actions. Using end-to-end deep reinforcement learning, agents learn both actions and communication strategies from scratch. We find that agents develop communication protocols with hallmark features of natural language: arbitrariness, interchangeability, displacement, cultural transmission, and compositionality. We quantify each property and analyze how different factors, such as population size and temporal dependencies, shape specific aspects of the emergent language. Our framework serves as a platform for studying how language can evolve from partial observability, temporal reasoning, and cooperative goals in embodied multi-agent settings. We will release all data, code, and models publicly."

[20.05.2025 10:13] Response: ```python
['AGENTS', 'RL', 'RLHF', 'MULTIMODAL']
```
[20.05.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vital for teamwork? Understanding the origins of language remains a challenge. A leading hypothesis in linguistics and anthropology posits that language evolved to meet the ecological and social demands of early human cooperation. Language did not arise in isolation, but through shared survival goals. Inspired by this view, we investigate the emergence of language in multi-agent Foraging Games. These environments are designed to reflect the cognitive and ecological constraints believed to have influenced the evolution of communication. Agents operate in a shared grid world with only partial knowledge about other agents and the environment, and must coordinate to complete games like picking up high-value targets or executing temporally ordered actions. Using end-to-end deep reinforcement learning, agents learn both actions and communication strategies from scratch. We find that agents develop communication protocols with hallmark features of natural language: arbitrariness, interchangeability, displacement, cultural transmission, and compositionality. We quantify each property and analyze how different factors, such as population size and temporal dependencies, shape specific aspects of the emergent language. Our framework serves as a platform for studying how language can evolve from partial observability, temporal reasoning, and cooperative goals in embodied multi-agent settings. We will release all data, code, and models publicly."

[20.05.2025 10:13] Response: ```python
['GAMES', 'REASONING', 'OPEN_SOURCE']
```
[20.05.2025 10:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how language can emerge in multi-agent systems through the lens of Foraging Games, which simulate the ecological and social conditions of early human cooperation. Using end-to-end deep reinforcement learning, agents learn to communicate and coordinate their actions in a shared environment with limited information. The study reveals that these agents develop communication protocols that exhibit characteristics similar to natural language, such as arbitrariness and compositionality. By analyzing how factors like population size and temporal dependencies influence language features, the research provides insights into the evolutionary processes of communication.","title":"Evolving Language Through Cooperative Learning in Multi-Agent Systems"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how language can emerge in multi-agent systems through the lens of Foraging Games, which simulate the ecological and social conditions of early human cooperation. Using end-to-end deep reinforcement learning, agents learn to communicate and coordinate their actions in a shared environment with limited information. The study reveals that these agents develop communication protocols that exhibit characteristics similar to natural language, such as arbitrariness and compositionality. By analyzing how factors like population size and temporal dependencies influence language features, the research provides insights into the evolutionary processes of communication.', title='Evolving Language Through Cooperative Learning in Multi-Agent Systems'))
[20.05.2025 10:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"è¿™ç¯‡è®ºæ–‡æŽ¢è®¨äº†è¯­è¨€å¦‚ä½•åœ¨å¤šæ™ºèƒ½ä½“è§…é£Ÿæ¸¸æˆä¸­å‡ºçŽ°ã€‚ç ”ç©¶è¡¨æ˜Žï¼Œæ™ºèƒ½ä½“åœ¨å…±äº«çš„çŽ¯å¢ƒä¸­ï¼Œé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ å­¦ä¹ è¡ŒåŠ¨å’Œæ²Ÿé€šç­–ç•¥ï¼Œé€æ¸å‘å±•å‡ºå…·æœ‰è‡ªç„¶è¯­è¨€ç‰¹å¾çš„æ²Ÿé€šåè®®ã€‚è®ºæ–‡é‡åŒ–äº†è¯­è¨€çš„ä¸åŒç‰¹æ€§ï¼Œå¦‚ä»»æ„æ€§ã€å¯äº’æ¢æ€§å’Œæ–‡åŒ–ä¼ é€’ç­‰ï¼Œå¹¶åˆ†æžäº†äººå£è§„æ¨¡å’Œæ—¶é—´ä¾èµ–æ€§ç­‰å› ç´ å¦‚ä½•å½±å“è¯­è¨€çš„æ¼”å˜ã€‚è¯¥æ¡†æž¶ä¸ºç ”ç©¶è¯­è¨€å¦‚ä½•åœ¨åˆä½œç›®æ ‡å’Œéƒ¨åˆ†å¯è§‚å¯Ÿæ€§ä¸­æ¼”åŒ–æä¾›äº†å¹³å°ã€‚","title":"è¯­è¨€çš„æ¼”åŒ–ï¼šä»Žåˆä½œåˆ°æ²Ÿé€šçš„æ—…ç¨‹"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='è¿™ç¯‡è®ºæ–‡æŽ¢è®¨äº†è¯­è¨€å¦‚ä½•åœ¨å¤šæ™ºèƒ½ä½“è§…é£Ÿæ¸¸æˆä¸­å‡ºçŽ°ã€‚ç ”ç©¶è¡¨æ˜Žï¼Œæ™ºèƒ½ä½“åœ¨å…±äº«çš„çŽ¯å¢ƒä¸­ï¼Œé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ å­¦ä¹ è¡ŒåŠ¨å’Œæ²Ÿé€šç­–ç•¥ï¼Œé€æ¸å‘å±•å‡ºå…·æœ‰è‡ªç„¶è¯­è¨€ç‰¹å¾çš„æ²Ÿé€šåè®®ã€‚è®ºæ–‡é‡åŒ–äº†è¯­è¨€çš„ä¸åŒç‰¹æ€§ï¼Œå¦‚ä»»æ„æ€§ã€å¯äº’æ¢æ€§å’Œæ–‡åŒ–ä¼ é€’ç­‰ï¼Œå¹¶åˆ†æžäº†äººå£è§„æ¨¡å’Œæ—¶é—´ä¾èµ–æ€§ç­‰å› ç´ å¦‚ä½•å½±å“è¯­è¨€çš„æ¼”å˜ã€‚è¯¥æ¡†æž¶ä¸ºç ”ç©¶è¯­è¨€å¦‚ä½•åœ¨åˆä½œç›®æ ‡å’Œéƒ¨åˆ†å¯è§‚å¯Ÿæ€§ä¸­æ¼”åŒ–æä¾›äº†å¹³å°ã€‚', title='è¯­è¨€çš„æ¼”åŒ–ï¼šä»Žåˆä½œåˆ°æ²Ÿé€šçš„æ—…ç¨‹'))
[20.05.2025 10:13] Querying the API.
[20.05.2025 10:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual smoke-test suite designed to give large-language-model (LLM) pipelines a unit-test style safety net dataset that runs in seconds with minimal cost. Born out of the tight feedback-loop demands building the Comet Opik prompt-optimization SDK, where waiting on heavyweight benchmarks breaks developer flow. TQB++ couples a 52-item English gold set (less than 20 kB) with a tiny synthetic-data generator pypi package built on provider-agnostic LiteLLM. The generator lets practitioners mint their own tiny packs in any language, domain, or difficulty, while ten ready-made packs already cover Arabic, Chinese, French, German, Japanese, Korean, Portuguese, Russian, Spanish, and Turkish. Every dataset ships with Croissant metadata and plug-and-play files for OpenAI-Evals, LangChain, and standard CI tools, so teams can drop deterministic micro-benchmarks directly into pull-request gates, prompt-engineering loops, and production dashboards without touching GPU budgets. A complete TQB++ run adds only a few seconds to pipeline latency yet reliably flags prompt-template errors, tokenizer drift, and fine-tuning side-effects long before full-scale suites like MMLU or BIG-Bench would finish configuring. The entire framework is released to accelerate continuous, resource-efficient quality assurance across the generative-AI ecosystem.
[20.05.2025 10:13] Response: {
  "desc": "TQB++ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÑÐ¾Ð±Ð¾Ð¹ Ð»ÐµÐ³ÐºÐ¾Ð²ÐµÑÐ½Ñ‹Ð¹ Ð¼Ð½Ð¾Ð³Ð¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€ Ñ‚ÐµÑÑ‚Ð¾Ð² Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹. ÐžÐ½ Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ð² ÑÐµÐ±Ñ Ð·Ð¾Ð»Ð¾Ñ‚Ð¾Ð¹ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚ Ð¸Ð· 52 Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð½Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð² Ð½Ð° Ð´Ñ€ÑƒÐ³Ð¸Ñ… ÑÐ·Ñ‹ÐºÐ°Ñ…. TQB++ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ Ð¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÑ Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð². Ð­Ñ‚Ð¾Ñ‚ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ Ð¿Ð¾Ð»ÐµÐ·ÐµÐ½ Ð´Ð»Ñ Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ð¾Ð¹ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ Ð¸ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.",
  "emoji": "ðŸš€",
  "title": "ÐœÐ¾Ð»Ð½Ð¸ÐµÐ½Ð¾ÑÐ½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ Ð²ÑÐµÑ…"
}
[20.05.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual smoke-test suite designed to give large-language-model (LLM) pipelines a unit-test style safety net dataset that runs in seconds with minimal cost. Born out of the tight feedback-loop demands building the Comet Opik prompt-optimization SDK, where waiting on heavyweight benchmarks breaks developer flow. TQB++ couples a 52-item English gold set (less than 20 kB) with a tiny synthetic-data generator pypi package built on provider-agnostic LiteLLM. The generator lets practitioners mint their own tiny packs in any language, domain, or difficulty, while ten ready-made packs already cover Arabic, Chinese, French, German, Japanese, Korean, Portuguese, Russian, Spanish, and Turkish. Every dataset ships with Croissant metadata and plug-and-play files for OpenAI-Evals, LangChain, and standard CI tools, so teams can drop deterministic micro-benchmarks directly into pull-request gates, prompt-engineering loops, and production dashboards without touching GPU budgets. A complete TQB++ run adds only a few seconds to pipeline latency yet reliably flags prompt-template errors, tokenizer drift, and fine-tuning side-effects long before full-scale suites like MMLU or BIG-Bench would finish configuring. The entire framework is released to accelerate continuous, resource-efficient quality assurance across the generative-AI ecosystem."

[20.05.2025 10:13] Response: ```python
['DATASET', 'BENCHMARK', 'MULTILINGUAL']
```
[20.05.2025 10:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual smoke-test suite designed to give large-language-model (LLM) pipelines a unit-test style safety net dataset that runs in seconds with minimal cost. Born out of the tight feedback-loop demands building the Comet Opik prompt-optimization SDK, where waiting on heavyweight benchmarks breaks developer flow. TQB++ couples a 52-item English gold set (less than 20 kB) with a tiny synthetic-data generator pypi package built on provider-agnostic LiteLLM. The generator lets practitioners mint their own tiny packs in any language, domain, or difficulty, while ten ready-made packs already cover Arabic, Chinese, French, German, Japanese, Korean, Portuguese, Russian, Spanish, and Turkish. Every dataset ships with Croissant metadata and plug-and-play files for OpenAI-Evals, LangChain, and standard CI tools, so teams can drop deterministic micro-benchmarks directly into pull-request gates, prompt-engineering loops, and production dashboards without touching GPU budgets. A complete TQB++ run adds only a few seconds to pipeline latency yet reliably flags prompt-template errors, tokenizer drift, and fine-tuning side-effects long before full-scale suites like MMLU or BIG-Bench would finish configuring. The entire framework is released to accelerate continuous, resource-efficient quality assurance across the generative-AI ecosystem."

[20.05.2025 10:14] Response: ```python
['OPEN_SOURCE', 'SYNTHETIC']
```
[20.05.2025 10:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Tiny QA Benchmark++ (TQB++) is a lightweight, multilingual testing suite designed for large-language-model (LLM) pipelines, providing a quick and cost-effective way to ensure model quality. It includes a small set of gold-standard tests and a synthetic data generator that allows users to create custom test packs in various languages and domains. TQB++ integrates easily with existing tools, enabling developers to incorporate micro-benchmarks into their workflows without significant resource expenditure. This framework aims to enhance continuous quality assurance in generative AI by quickly identifying issues like prompt errors and tokenizer drift before more extensive testing is conducted.","title":"Quick and Efficient Testing for Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Tiny QA Benchmark++ (TQB++) is a lightweight, multilingual testing suite designed for large-language-model (LLM) pipelines, providing a quick and cost-effective way to ensure model quality. It includes a small set of gold-standard tests and a synthetic data generator that allows users to create custom test packs in various languages and domains. TQB++ integrates easily with existing tools, enabling developers to incorporate micro-benchmarks into their workflows without significant resource expenditure. This framework aims to enhance continuous quality assurance in generative AI by quickly identifying issues like prompt errors and tokenizer drift before more extensive testing is conducted.', title='Quick and Efficient Testing for Language Models'))
[20.05.2025 10:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Tiny QA Benchmark++ï¼ˆTQB++ï¼‰æ˜¯ä¸€ä¸ªè¶…è½»é‡çº§çš„å¤šè¯­è¨€æµ‹è¯•å¥—ä»¶ï¼Œæ—¨åœ¨ä¸ºå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰æä¾›å¿«é€Ÿçš„å•å…ƒæµ‹è¯•æ•°æ®é›†ï¼Œè¿è¡Œæ—¶é—´çŸ­ä¸”æˆæœ¬ä½Žã€‚å®ƒç»“åˆäº†ä¸€ä¸ª52é¡¹çš„è‹±è¯­é‡‘æ ‡å‡†é›†å’Œä¸€ä¸ªåŸºäºŽLiteLLMçš„åˆæˆæ•°æ®ç”Ÿæˆå™¨ï¼Œå…è®¸ç”¨æˆ·ç”Ÿæˆé€‚åˆä»»ä½•è¯­è¨€ã€é¢†åŸŸæˆ–éš¾åº¦çš„å°æ•°æ®åŒ…ã€‚TQB++æä¾›äº†åä¸ªçŽ°æˆçš„æ•°æ®åŒ…ï¼Œè¦†ç›–å¤šç§è¯­è¨€ï¼Œå¹¶ä¸”æ¯ä¸ªæ•°æ®é›†éƒ½é™„å¸¦äº†å…ƒæ•°æ®å’Œå¯ç›´æŽ¥ä½¿ç”¨çš„æ–‡ä»¶ï¼Œæ–¹ä¾¿é›†æˆåˆ°çŽ°æœ‰çš„å¼€å‘æµç¨‹ä¸­ã€‚è¿™ä¸ªæ¡†æž¶çš„è®¾è®¡æ—¨åœ¨åŠ é€Ÿç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç”Ÿæ€ç³»ç»Ÿä¸­çš„æŒç»­ã€èµ„æºé«˜æ•ˆçš„è´¨é‡ä¿è¯ã€‚","title":"è½»é‡çº§å¤šè¯­è¨€æµ‹è¯•ï¼Œæå‡AIè´¨é‡ä¿éšœ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Tiny QA Benchmark++ï¼ˆTQB++ï¼‰æ˜¯ä¸€ä¸ªè¶…è½»é‡çº§çš„å¤šè¯­è¨€æµ‹è¯•å¥—ä»¶ï¼Œæ—¨åœ¨ä¸ºå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰æä¾›å¿«é€Ÿçš„å•å…ƒæµ‹è¯•æ•°æ®é›†ï¼Œè¿è¡Œæ—¶é—´çŸ­ä¸”æˆæœ¬ä½Žã€‚å®ƒç»“åˆäº†ä¸€ä¸ª52é¡¹çš„è‹±è¯­é‡‘æ ‡å‡†é›†å’Œä¸€ä¸ªåŸºäºŽLiteLLMçš„åˆæˆæ•°æ®ç”Ÿæˆå™¨ï¼Œå…è®¸ç”¨æˆ·ç”Ÿæˆé€‚åˆä»»ä½•è¯­è¨€ã€é¢†åŸŸæˆ–éš¾åº¦çš„å°æ•°æ®åŒ…ã€‚TQB++æä¾›äº†åä¸ªçŽ°æˆçš„æ•°æ®åŒ…ï¼Œè¦†ç›–å¤šç§è¯­è¨€ï¼Œå¹¶ä¸”æ¯ä¸ªæ•°æ®é›†éƒ½é™„å¸¦äº†å…ƒæ•°æ®å’Œå¯ç›´æŽ¥ä½¿ç”¨çš„æ–‡ä»¶ï¼Œæ–¹ä¾¿é›†æˆåˆ°çŽ°æœ‰çš„å¼€å‘æµç¨‹ä¸­ã€‚è¿™ä¸ªæ¡†æž¶çš„è®¾è®¡æ—¨åœ¨åŠ é€Ÿç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç”Ÿæ€ç³»ç»Ÿä¸­çš„æŒç»­ã€èµ„æºé«˜æ•ˆçš„è´¨é‡ä¿è¯ã€‚', title='è½»é‡çº§å¤šè¯­è¨€æµ‹è¯•ï¼Œæå‡AIè´¨é‡ä¿éšœ'))
[20.05.2025 10:14] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#inference", "#video"], "emoji": "ðŸŽ¬", "ru": {"title": "Ð ÐµÐ²Ð¾Ð»ÑŽÑ†Ð¸Ñ Ð² ÐºÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾-Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "QVGen - ÑÑ‚Ð¾ Ð½Ð¾Ð²Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÐºÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸ Ð²Ñ‹Ð²Ð¾Ð´Ðµ Ð²Ð¸Ð´ÐµÐ¾-Ð´Ð¸Ñ„Ñ„ÑƒÐ·Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ 
[20.05.2025 10:14] Using data from previous issue: {"categories": ["#science", "#multimodal", "#interpretability", "#inference"], "emoji": "ðŸ”", "ru": {"title": "ÐŸÐ¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ LLM Ð² Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ð¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ñ‡ÐµÑ€ÐµÐ· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÑƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°", "desc": "Ð­Ñ‚Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·ÑƒÑ‡Ð°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ñ… Ð¼Ð¾
[20.05.2025 10:14] Using data from previous issue: {"categories": ["#security", "#data", "#hallucinations", "#rag", "#benchmark"], "emoji": "ðŸ›¡ï¸", "ru": {"title": "Ð¢Ð¾Ñ‡Ð½Ð¾Ðµ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÑ…Ð½Ð¸Ðº Ð·Ð»Ð¾ÑƒÐ¼Ñ‹ÑˆÐ»ÐµÐ½Ð½Ð¸ÐºÐ¾Ð² Ñ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð¾Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…", "desc": "TechniqueRAG - ÑÑ‚Ð¾ Ð½Ð¾Ð²Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð´Ð»Ñ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ñ‚ÐµÑ…Ð½Ð¸Ðº Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð½Ð¸ÐºÐ¾Ð² Ð² Ñ‚ÐµÐºÑÑ‚Ð°Ñ… Ð¿Ð¾ ÐºÐ¸Ð±ÐµÑ€Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸. ÐžÐ½Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ñƒ
[20.05.2025 10:14] Using data from previous issue: {"categories": ["#reasoning", "#data", "#science", "#multimodal", "#interpretability", "#architecture"], "emoji": "ðŸ”¬", "ru": {"title": "PWP: ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ñ… Ñ€Ð°Ð±Ð¾Ñ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ LLM", "desc": "Ð¡Ñ‚Ð°Ñ‚ÑŒÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€Ð¸Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð² Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Persistent Workflow
[20.05.2025 10:14] Loading Chinese text from previous data.
[20.05.2025 10:14] Renaming data file.
[20.05.2025 10:14] Renaming previous data. hf_papers.json to ./d/2025-05-20.json
[20.05.2025 10:14] Saving new data file.
[20.05.2025 10:14] Generating page.
[20.05.2025 10:14] Renaming previous page.
[20.05.2025 10:14] Renaming previous data. index.html to ./d/2025-05-20.html
[20.05.2025 10:14] [Experimental] Generating Chinese page for reading.
[20.05.2025 10:14] Chinese vocab [{'word': 'èŒƒå¼', 'pinyin': 'fÃ n shÃ¬', 'trans': 'paradigm'}, {'word': 'Chain-of-Model', 'pinyin': 'ChÃ¨in-Ã²f-MÃ³del', 'trans': 'Chain-of-Model'}, {'word': 'å› æžœå…³ç³»', 'pinyin': 'yÄ«n guÇ’ guÄn xÃ¬', 'trans': 'causal relationship'}, {'word': 'éšè—çŠ¶æ€', 'pinyin': 'yÇn cÃ¡ng zhuÃ ng tÃ i', 'trans': 'hidden state'}, {'word': 'é“¾å¼ç»“æž„', 'pinyin': 'liÃ n shÃ¬ jiÃ©gÃ²u', 'trans': 'chain structure'}, {'word': 'æ‰©å±•æ•ˆçŽ‡', 'pinyin': 'kuÃ² zhÇŽn xiÃ o lÇœ', 'trans': 'scalability'}, {'word': 'éƒ¨ç½²', 'pinyin': 'bÃ¹ shÇ”', 'trans': 'deployment'}, {'word': 'çµæ´»æ€§', 'pinyin': 'lÃ­ng huÃ³ xÃ¬ng', 'trans': 'flexibility'}, {'word': 'Chain-of-Representation', 'pinyin': 'ChÃ¨in-Ã²f-RÄ›prizen tÃ©i shÄ“n', 'trans': 'Chain-of-Representation'}, {'word': 'å­è¡¨ç¤º', 'pinyin': 'zÇ biÇŽo shÃ¬', 'trans': 'sub-representation'}, {'word': 'ç»„åˆ', 'pinyin': 'zÇ” hÃ©', 'trans': 'combination'}, {'word': 'å‰åºé“¾', 'pinyin': 'qiÃ¡n xÃ¹ liÃ n', 'trans': 'preceding chain'}, {'word': 'å¼¹æ€§æŽ¨ç†', 'pinyin': 'tÃ¡n xÃ¬ng tuÄ« lÇ', 'trans': 'elastic inference'}, {'word': 'Chain-of-Language-Model', 'pinyin': 'ChÃ¨in-Ã²f-LÃ¡nggÃ¹ MÃ³del', 'trans': 'Chain-of-Language-Model'}, {'word': 'KVå…±äº«æœºåˆ¶', 'pinyin': 'KV gÃ²ng xiÇŽng jÄ« zhÃ¬', 'trans': 'KV sharing mechanism'}, {'word': 'CoLM-Air', 'pinyin': 'CoLM-Ã‰ir', 'trans': 'CoLM-Air'}, {'word': 'æ‰©å±•åŠŸèƒ½', 'pinyin': 'kuÃ² zhÇŽn gÅng nÃ©ng', 'trans': 'extended functionality'}, {'word': 'Transformer', 'pinyin': 'TÃ¨inshÃ¨in fÅmÄ›i', 'trans': 'Transformer'}]
[20.05.2025 10:14] Renaming previous Chinese page.
[20.05.2025 10:14] Renaming previous data. zh.html to ./d/2025-05-19_zh_reading_task.html
[20.05.2025 10:14] Writing Chinese reading task.
[20.05.2025 10:14] Writing result.
[20.05.2025 10:14] Renaming log file.
[20.05.2025 10:14] Renaming previous data. log.txt to ./logs/2025-05-20_last_log.txt
