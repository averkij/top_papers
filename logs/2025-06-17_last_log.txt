[17.06.2025 02:47] Read previous papers.
[17.06.2025 02:47] Generating top page (month).
[17.06.2025 02:47] Writing top page (month).
[17.06.2025 03:43] Read previous papers.
[17.06.2025 03:43] Get feed.
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13585
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11763
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13759
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08343
[17.06.2025 03:43] Extract page data from URL. URL: https://huggingface.co/papers/2506.12915
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03968
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.07961
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13750
[17.06.2025 03:43] Extract page data from URL. URL: https://huggingface.co/papers/2506.10521
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12953
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12623
[17.06.2025 03:43] Extract page data from URL. URL: https://huggingface.co/papers/2506.12450
[17.06.2025 03:43] Extract page data from URL. URL: https://huggingface.co/papers/2506.13752
[17.06.2025 03:43] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12189
[17.06.2025 03:43] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.06.2025 03:43] No deleted papers detected.
[17.06.2025 03:43] Downloading and parsing papers (pdf, html). Total: 14.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.13585.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.13585.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.13585.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.11763.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.11763.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.11763.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.13759.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.13759.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.13759.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.08343.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.08343.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.08343.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.12915.
[17.06.2025 03:43] Downloading paper 2506.12915 from http://arxiv.org/pdf/2506.12915v1...
[17.06.2025 03:43] Extracting affiliations from text.
[17.06.2025 03:43] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"PersonaFeedback: Large-scale Human-annotated Benchmark For Personalization Meiling Tao1,, Chenghao Zhu2,, Dongyi Ding3,, Tiannan Wang4, Yuchen Eleanor Jiang4, Wangchunshu Zhou4, 1University of Electronic Science and Technology of China, 2The Chinese University of Hong Kong, Shenzhen, 3South China Agricultural University, 4OPPO Equal contribution, Corresponding authors "
[17.06.2025 03:43] Response: ```python
["University of Electronic Science and Technology of China", "The Chinese University of Hong Kong, Shenzhen", "South China Agricultural University", "OPPO"]
```
[17.06.2025 03:43] Deleting PDF ./assets/pdf/2506.12915.pdf.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.03968.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.03968.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.03968.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.07961.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.07961.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.07961.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.13750.
[17.06.2025 03:43] Extra JSON file exists (./assets/json/2506.13750.json), skip PDF parsing.
[17.06.2025 03:43] Paper image links file exists (./assets/img_data/2506.13750.json), skip HTML parsing.
[17.06.2025 03:43] Success.
[17.06.2025 03:43] Downloading and parsing paper https://huggingface.co/papers/2506.10521.
[17.06.2025 03:44] Downloading paper 2506.10521 from http://arxiv.org/pdf/2506.10521v2...
[17.06.2025 03:44] Extracting affiliations from text.
[17.06.2025 03:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 1 ] . [ 2 1 2 5 0 1 . 6 0 5 2 : r Scientists First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning PrismaX Team Shanghai Artificial Intelligence Laboratory Dataset: https://huggingface.co/datasets/PrismaX/SFE Website: https://prismax.opencompass.org.cn/ "
[17.06.2025 03:44] Response: ```python
["Shanghai Artificial Intelligence Laboratory"]
```
[17.06.2025 03:44] Deleting PDF ./assets/pdf/2506.10521.pdf.
[17.06.2025 03:44] Success.
[17.06.2025 03:44] Downloading and parsing paper https://huggingface.co/papers/2506.12953.
[17.06.2025 03:44] Extra JSON file exists (./assets/json/2506.12953.json), skip PDF parsing.
[17.06.2025 03:44] Paper image links file exists (./assets/img_data/2506.12953.json), skip HTML parsing.
[17.06.2025 03:44] Success.
[17.06.2025 03:44] Downloading and parsing paper https://huggingface.co/papers/2506.12623.
[17.06.2025 03:44] Extra JSON file exists (./assets/json/2506.12623.json), skip PDF parsing.
[17.06.2025 03:44] Paper image links file exists (./assets/img_data/2506.12623.json), skip HTML parsing.
[17.06.2025 03:44] Success.
[17.06.2025 03:44] Downloading and parsing paper https://huggingface.co/papers/2506.12450.
[17.06.2025 03:44] Downloading paper 2506.12450 from http://arxiv.org/pdf/2506.12450v1...
[17.06.2025 03:44] Extracting affiliations from text.
[17.06.2025 03:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Joanito Agili Lopo1,2, Muhammad Ravi Shulthan Habibi1,3, Tack Hwa Wong1, Muhammad Ilham Ghozali1,3, Fajri Koto1,4, Genta Indra Winata1,5, Peerat Limkonchotiwat1,6, Alham Fikri Aji1,4, Samuel Cahyawijaya*1,7 1SEACrowd 2Kreasof AI 4MBZUAI 5Capital One 3Universitas Indonesia 7Cohere 6AI Singapore {amalopo99,muhammadravi251001,tackhwawong00}@gmail.com muhammad.ilham.gozali@gmail.com,samuelcahyawijaya@cohere.com 5 2 0 J 4 1 ] . [ 1 0 5 4 2 1 . 6 0 5 2 : r a "
[17.06.2025 03:44] Response: ```python
[
    "SEACrowd",
    "Kreasof AI",
    "MBZUAI",
    "Capital One",
    "Universitas Indonesia",
    "Cohere",
    "AI Singapore"
]
```
[17.06.2025 03:44] Deleting PDF ./assets/pdf/2506.12450.pdf.
[17.06.2025 03:44] Success.
[17.06.2025 03:44] Downloading and parsing paper https://huggingface.co/papers/2506.13752.
[17.06.2025 03:44] Downloading paper 2506.13752 from http://arxiv.org/pdf/2506.13752v1...
[17.06.2025 03:44] Extracting affiliations from text.
[17.06.2025 03:44] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 2 5 7 3 1 . 6 0 5 2 : r a Junyan Li UMass Amherst junyanli@umass.edu Wenshuo Zhao Zhejiang University zhao_ws@zju.edu.cn Yang Zhang MIT-IBM Watson AI Lab yang.zhang2@ibm.com Chuang Gan UMass Amherst chuangg@cics.umass.edu "
[17.06.2025 03:44] Response: ```python
["UMass Amherst", "Zhejiang University", "MIT-IBM Watson AI Lab"]
```
[17.06.2025 03:44] Deleting PDF ./assets/pdf/2506.13752.pdf.
[17.06.2025 03:44] Success.
[17.06.2025 03:44] Downloading and parsing paper https://huggingface.co/papers/2506.12189.
[17.06.2025 03:44] Extra JSON file exists (./assets/json/2506.12189.json), skip PDF parsing.
[17.06.2025 03:44] Paper image links file exists (./assets/img_data/2506.12189.json), skip HTML parsing.
[17.06.2025 03:44] Success.
[17.06.2025 03:44] Enriching papers with extra data.
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 0. A hybrid-attention reasoning model called MiniMax-M1, featuring a Mixture-of-Experts architecture and lightning attention mechanism, is introduced for efficient long-input processing and reinforcement learning.  					AI-generated summary 				 We introduce MiniMax-M1, the world's first open-weight, l...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 1. DeepResearch Bench offers a benchmark framework to evaluate the capabilities of Deep Research Agents in terms of research quality and information retrieval accuracy across multiple fields.  					AI-generated summary 				 Deep Research Agents are a prominent category of LLM-based agents. By autonomou...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 2. Discrete Diffusion Language Models (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs) enable parallel generation and faster inference compared to autoregressive models through denoising-based strategies and full attention mechanisms.  					AI-generated summary 				 In this work, we p...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 3. NoWait suppresses explicit self-reflection tokens during inference to enhance efficiency in multimodal reasoning without reducing model utility.  					AI-generated summary 				 Recent advances in large reasoning models have enabled complex, step-by-step reasoning but often introduce significant over...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 4. A new benchmark, PersonaFeedback, evaluates Large Language Models' ability to generate personalized responses given explicit user personas, revealing limitations in current systems.  					AI-generated summary 				 With the rapid improvement in the general capabilities of LLMs, LLM personalization, i...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 5. The paper presents a method for generating diverse and complex instruction data for large language models using attributed grounding, achieving top performance on benchmarks with a large synthesized dataset.  					AI-generated summary 				 The pursuit of diverse, complex, and large-scale instruction...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 6. BridgeVLA is a 3D vision-language-action model that projects 3D inputs to 2D images and uses 2D heatmaps for efficient and effective action prediction, outperforming baselines in various benchmarks.  					AI-generated summary 				 Recently, leveraging pre-trained vision-language models (VLMs) for bu...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 7. Test3R, a test-time learning technique for 3D reconstruction, enhances geometric accuracy by optimizing network consistency using self-supervised learning on image triplets.  					AI-generated summary 				 Dense matching methods like DUSt3R regress pairwise pointmaps for 3D reconstruction. However, ...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 8. Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.  					AI-generated summary 				 Scientific discoveries increasingly rely on complex multimodal reasoning based on informat...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 9. PatchInstruct enhances LLM forecasting quality through specialized prompting methods that include time series decomposition, patch-based tokenization, and similarity-based neighbor augmentation.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have demonstrated new pos...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 10. A novel benchmark and dataset are proposed for multi-modal summarization of UI instructional videos, addressing the need for step-by-step executable instructions and key video frames.  					AI-generated summary 				 We study multi-modal summarization for instructional videos, whose goal is to provid...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 11. Research confirms natural representation alignment in large language models and introduces Inference-Time Language Control to enhance cross-lingual performance.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and lang...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 12. Budget guidance is a method that steers LLM reasoning within a targeted budget without fine-tuning and achieves improved efficiency and performance on math benchmarks.  					AI-generated summary 				 Recent deep-thinking large language models often reason extensively to improve performance, but such...
[17.06.2025 03:44] ********************************************************************************
[17.06.2025 03:44] Abstract 13. The study evaluates various LLMs on diverse text tasks using a new dataset, revealing distinct personality traits and improving model interpretability.  					AI-generated summary 				 Large Language Models (LLMs) are increasingly integrated into everyday applications. As their influence grows, under...
[17.06.2025 03:44] Read previous papers.
[17.06.2025 03:44] Generating reviews via LLM API.
[17.06.2025 03:44] Using data from previous issue: {"categories": ["#rl", "#training", "#open_source", "#architecture", "#reasoning", "#long_context", "#optimization"], "emoji": "🧠", "ru": {"title": "MiniMax-M1: Гибридный ИИ для эффективной обработки сложных задач", "desc": "MiniMax-M1 - это гибридная модель рассуждений с архитектурой Mixture-of-Exp
[17.06.2025 03:44] Using data from previous issue: {"categories": ["#open_source", "#science", "#agents", "#alignment", "#benchmark"], "emoji": "🔬", "ru": {"title": "Комплексная оценка ИИ-агентов для глубоких исследований", "desc": "DeepResearch Bench - это система оценки возможностей агентов глубоких исследований в области качества исследований и т
[17.06.2025 03:44] Using data from previous issue: {"categories": ["#math", "#training", "#diffusion", "#inference", "#multimodal", "#survey"], "emoji": "🧠", "ru": {"title": "Революция в языковом моделировании: дискретные диффузионные модели", "desc": "Статья представляет собой систематический обзор дискретных диффузионных языковых моделей (dLLMs) и
[17.06.2025 03:44] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#inference", "#multimodal"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение без лишних слов", "desc": "Исследование представляет метод NoWait, который подавляет токены явной саморефлексии в больших языковых моделях во время вывода. Это позволяет с
[17.06.2025 03:44] Querying the API.
[17.06.2025 03:44] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A new benchmark, PersonaFeedback, evaluates Large Language Models' ability to generate personalized responses given explicit user personas, revealing limitations in current systems.  					AI-generated summary 				 With the rapid improvement in the general capabilities of LLMs, LLM personalization, i.e., how to build LLM systems that can generate personalized responses or services that are tailored to distinct user personas, has become an increasingly important research and engineering problem. However, unlike many new challenging benchmarks being released for evaluating the general/reasoning capabilities, the lack of high-quality benchmarks for evaluating LLM personalization greatly hinders progress in this field. To address this, we introduce PersonaFeedback, a new benchmark that directly evaluates LLMs' ability to provide personalized responses given pre-defined user personas and queries. Unlike existing benchmarks that require models to infer implicit user personas from historical interactions, PersonaFeedback decouples persona inference from personalization, focusing on evaluating the model's ability to generate responses tailored to explicit personas. PersonaFeedback consists of 8298 human-annotated test cases, which are categorized into easy, medium, and hard tiers based on the contextual complexity of the user personas and the difficulty in distinguishing subtle differences between two personalized responses. We conduct comprehensive evaluations across a wide range of models. The empirical results reveal that even state-of-the-art LLMs that can solve complex real-world reasoning tasks could fall short on the hard tier of PersonaFeedback where even human evaluators may find the distinctions challenging. Furthermore, we conduct an in-depth analysis of failure modes across various types of systems, demonstrating that the current retrieval-augmented framework should not be seen as a de facto solution for personalization tasks. All benchmark data, annotation protocols, and the evaluation pipeline will be publicly available to facilitate future research on LLM personalization.
[17.06.2025 03:44] Response: {
  "desc": "Представлен новый бенчмарк PersonaFeedback для оценки способности больших языковых моделей (LLM) генерировать персонализированные ответы на основе явно заданных пользовательских персон. Бенчмарк состоит из 8298 аннотированных тестовых примеров, разделенных на легкие, средние и сложные уровни. Результаты показывают, что даже современные LLM, способные решать сложные задачи рассуждений, испытывают трудности на сложном уровне PersonaFeedback. Анализ выявил ограничения текущих подходов к персонализации LLM, включая retrieval-augmented фреймворки.",
  "emoji": "🎭",
  "title": "PersonaFeedback: новый стандарт оценки персонализации языковых моделей"
}
[17.06.2025 03:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new benchmark, PersonaFeedback, evaluates Large Language Models' ability to generate personalized responses given explicit user personas, revealing limitations in current systems.  					AI-generated summary 				 With the rapid improvement in the general capabilities of LLMs, LLM personalization, i.e., how to build LLM systems that can generate personalized responses or services that are tailored to distinct user personas, has become an increasingly important research and engineering problem. However, unlike many new challenging benchmarks being released for evaluating the general/reasoning capabilities, the lack of high-quality benchmarks for evaluating LLM personalization greatly hinders progress in this field. To address this, we introduce PersonaFeedback, a new benchmark that directly evaluates LLMs' ability to provide personalized responses given pre-defined user personas and queries. Unlike existing benchmarks that require models to infer implicit user personas from historical interactions, PersonaFeedback decouples persona inference from personalization, focusing on evaluating the model's ability to generate responses tailored to explicit personas. PersonaFeedback consists of 8298 human-annotated test cases, which are categorized into easy, medium, and hard tiers based on the contextual complexity of the user personas and the difficulty in distinguishing subtle differences between two personalized responses. We conduct comprehensive evaluations across a wide range of models. The empirical results reveal that even state-of-the-art LLMs that can solve complex real-world reasoning tasks could fall short on the hard tier of PersonaFeedback where even human evaluators may find the distinctions challenging. Furthermore, we conduct an in-depth analysis of failure modes across various types of systems, demonstrating that the current retrieval-augmented framework should not be seen as a de facto solution for personalization tasks. All benchmark data, annotation protocols, and the evaluation pipeline will be publicly available to facilitate future research on LLM personalization."

[17.06.2025 03:44] Response: ```python
['BENCHMARK', 'MULTIMODAL']
```
[17.06.2025 03:44] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new benchmark, PersonaFeedback, evaluates Large Language Models' ability to generate personalized responses given explicit user personas, revealing limitations in current systems.  					AI-generated summary 				 With the rapid improvement in the general capabilities of LLMs, LLM personalization, i.e., how to build LLM systems that can generate personalized responses or services that are tailored to distinct user personas, has become an increasingly important research and engineering problem. However, unlike many new challenging benchmarks being released for evaluating the general/reasoning capabilities, the lack of high-quality benchmarks for evaluating LLM personalization greatly hinders progress in this field. To address this, we introduce PersonaFeedback, a new benchmark that directly evaluates LLMs' ability to provide personalized responses given pre-defined user personas and queries. Unlike existing benchmarks that require models to infer implicit user personas from historical interactions, PersonaFeedback decouples persona inference from personalization, focusing on evaluating the model's ability to generate responses tailored to explicit personas. PersonaFeedback consists of 8298 human-annotated test cases, which are categorized into easy, medium, and hard tiers based on the contextual complexity of the user personas and the difficulty in distinguishing subtle differences between two personalized responses. We conduct comprehensive evaluations across a wide range of models. The empirical results reveal that even state-of-the-art LLMs that can solve complex real-world reasoning tasks could fall short on the hard tier of PersonaFeedback where even human evaluators may find the distinctions challenging. Furthermore, we conduct an in-depth analysis of failure modes across various types of systems, demonstrating that the current retrieval-augmented framework should not be seen as a de facto solution for personalization tasks. All benchmark data, annotation protocols, and the evaluation pipeline will be publicly available to facilitate future research on LLM personalization."

[17.06.2025 03:44] Response: ```python
['ALIGNMENT', 'INTERPRETABILITY']
```
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces PersonaFeedback, a new benchmark designed to assess the ability of Large Language Models (LLMs) to generate personalized responses based on explicit user personas. This benchmark addresses the gap in evaluating LLM personalization, which has been overlooked compared to general reasoning capabilities. PersonaFeedback includes 8,298 human-annotated test cases categorized by complexity, revealing that even advanced LLMs struggle with nuanced personalization tasks. The findings highlight the limitations of current models and emphasize the need for improved frameworks in LLM personalization.","title":"Enhancing Personalization in LLMs with PersonaFeedback"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces PersonaFeedback, a new benchmark designed to assess the ability of Large Language Models (LLMs) to generate personalized responses based on explicit user personas. This benchmark addresses the gap in evaluating LLM personalization, which has been overlooked compared to general reasoning capabilities. PersonaFeedback includes 8,298 human-annotated test cases categorized by complexity, revealing that even advanced LLMs struggle with nuanced personalization tasks. The findings highlight the limitations of current models and emphasize the need for improved frameworks in LLM personalization.', title='Enhancing Personalization in LLMs with PersonaFeedback'))
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一个新的基准测试，名为PersonaFeedback，旨在评估大型语言模型（LLM）生成个性化响应的能力。随着LLM能力的快速提升，个性化生成已成为一个重要的研究问题，但缺乏高质量的基准测试限制了这一领域的进展。PersonaFeedback通过提供预定义的用户角色和查询，直接评估模型生成针对特定用户角色的响应能力。研究结果表明，即使是最先进的LLM在处理复杂的个性化任务时也可能表现不佳，强调了当前模型在个性化生成方面的局限性。","title":"个性化生成的新基准：PersonaFeedback"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文介绍了一个新的基准测试，名为PersonaFeedback，旨在评估大型语言模型（LLM）生成个性化响应的能力。随着LLM能力的快速提升，个性化生成已成为一个重要的研究问题，但缺乏高质量的基准测试限制了这一领域的进展。PersonaFeedback通过提供预定义的用户角色和查询，直接评估模型生成针对特定用户角色的响应能力。研究结果表明，即使是最先进的LLM在处理复杂的个性化任务时也可能表现不佳，强调了当前模型在个性化生成方面的局限性。', title='个性化生成的新基准：PersonaFeedback'))
[17.06.2025 03:45] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#alignment", "#data", "#benchmark"], "emoji": "🧠", "ru": {"title": "Синтез сложных инструкций для эффективного обучения языковых моделей", "desc": "Статья представляет метод генерации разнообразных и сложных инструкций для обучения больших языковых моделей 
[17.06.2025 03:45] Using data from previous issue: {"categories": ["#rl", "#3d", "#games", "#optimization", "#agents", "#benchmark"], "emoji": "🤖", "ru": {"title": "BridgeVLA: Эффективное обучение роботов через проекцию 3D в 2D", "desc": "BridgeVLA - это новая модель машинного обучения для роботизированных манипуляций, объединяющая 3D-зрение, язык и
[17.06.2025 03:45] Using data from previous issue: {"categories": ["#3d", "#training", "#optimization"], "emoji": "🏛️", "ru": {"title": "Test3R: Повышение точности 3D-реконструкции через самообучение на тестовых данных", "desc": "Test3R - это новая техника обучения во время тестирования для 3D-реконструкции, которая улучшает геометрическую точность.
[17.06.2025 03:45] Querying the API.
[17.06.2025 03:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.  					AI-generated summary 				 Scientific discoveries increasingly rely on complex multimodal reasoning based on information-intensive scientific data and domain-specific expertise. Empowered by expert-level scientific benchmarks, scientific Multimodal Large Language Models (MLLMs) hold the potential to significantly enhance this discovery process in realistic workflows. However, current scientific benchmarks mostly focus on evaluating the knowledge understanding capabilities of MLLMs, leading to an inadequate assessment of their perception and reasoning abilities. To address this gap, we present the Scientists' First Exam (SFE) benchmark, designed to evaluate the scientific cognitive capacities of MLLMs through three interconnected levels: scientific signal perception, scientific attribute understanding, scientific comparative reasoning. Specifically, SFE comprises 830 expert-verified VQA pairs across three question types, spanning 66 multimodal tasks across five high-value disciplines. Extensive experiments reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08% and 26.52% on SFE, highlighting significant room for MLLMs to improve in scientific realms. We hope the insights obtained in SFE will facilitate further developments in AI-enhanced scientific discoveries.
[17.06.2025 03:45] Response: {
  "desc": "Учёные разработали новый бенчмарк под названием Scientists' First Exam (SFE) для оценки научных когнитивных способностей мультимодальных больших языковых моделей (MLLM). SFE оценивает восприятие, понимание и сравнительное рассуждение в научном контексте. Бенчмарк состоит из 830 экспертно проверенных пар вопросов-ответов по визуальным данным, охватывающих 66 мультимодальных задач в пяти важных научных дисциплинах. Эксперименты показали, что современные модели GPT-4 и InternVL-3 достигают лишь 34.08% и 26.52% соответственно на SFE, что указывает на значительный потенциал для улучшения MLLM в научной сфере.",
  "emoji": "🔬",
  "title": "Новый бенчмарк для оценки научного мышления ИИ"
}
[17.06.2025 03:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.  					AI-generated summary 				 Scientific discoveries increasingly rely on complex multimodal reasoning based on information-intensive scientific data and domain-specific expertise. Empowered by expert-level scientific benchmarks, scientific Multimodal Large Language Models (MLLMs) hold the potential to significantly enhance this discovery process in realistic workflows. However, current scientific benchmarks mostly focus on evaluating the knowledge understanding capabilities of MLLMs, leading to an inadequate assessment of their perception and reasoning abilities. To address this gap, we present the Scientists' First Exam (SFE) benchmark, designed to evaluate the scientific cognitive capacities of MLLMs through three interconnected levels: scientific signal perception, scientific attribute understanding, scientific comparative reasoning. Specifically, SFE comprises 830 expert-verified VQA pairs across three question types, spanning 66 multimodal tasks across five high-value disciplines. Extensive experiments reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08% and 26.52% on SFE, highlighting significant room for MLLMs to improve in scientific realms. We hope the insights obtained in SFE will facilitate further developments in AI-enhanced scientific discoveries."

[17.06.2025 03:45] Response: ```python
['BENCHMARK', 'MULTIMODAL']
```
[17.06.2025 03:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.  					AI-generated summary 				 Scientific discoveries increasingly rely on complex multimodal reasoning based on information-intensive scientific data and domain-specific expertise. Empowered by expert-level scientific benchmarks, scientific Multimodal Large Language Models (MLLMs) hold the potential to significantly enhance this discovery process in realistic workflows. However, current scientific benchmarks mostly focus on evaluating the knowledge understanding capabilities of MLLMs, leading to an inadequate assessment of their perception and reasoning abilities. To address this gap, we present the Scientists' First Exam (SFE) benchmark, designed to evaluate the scientific cognitive capacities of MLLMs through three interconnected levels: scientific signal perception, scientific attribute understanding, scientific comparative reasoning. Specifically, SFE comprises 830 expert-verified VQA pairs across three question types, spanning 66 multimodal tasks across five high-value disciplines. Extensive experiments reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08% and 26.52% on SFE, highlighting significant room for MLLMs to improve in scientific realms. We hope the insights obtained in SFE will facilitate further developments in AI-enhanced scientific discoveries."

[17.06.2025 03:45] Response: ```python
['REASONING', 'SCIENCE']
```
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Scientists\' First Exam (SFE) benchmark evaluates the cognitive abilities of Multimodal Large Language Models (MLLMs) in scientific contexts. It focuses on three key areas: perception of scientific signals, understanding of scientific attributes, and comparative reasoning. The benchmark includes 830 expert-verified visual question-answering pairs across various multimodal tasks in five important scientific disciplines. Results show that leading models like GPT-o3 and InternVL-3 perform below expectations, indicating a need for improvement in their scientific reasoning capabilities.","title":"Enhancing Scientific Discovery with MLLMs: The SFE Benchmark"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The Scientists' First Exam (SFE) benchmark evaluates the cognitive abilities of Multimodal Large Language Models (MLLMs) in scientific contexts. It focuses on three key areas: perception of scientific signals, understanding of scientific attributes, and comparative reasoning. The benchmark includes 830 expert-verified visual question-answering pairs across various multimodal tasks in five important scientific disciplines. Results show that leading models like GPT-o3 and InternVL-3 perform below expectations, indicating a need for improvement in their scientific reasoning capabilities.", title='Enhancing Scientific Discovery with MLLMs: The SFE Benchmark'))
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"科学家首次考试（SFE）基准测试评估多模态大型语言模型（MLLMs）的科学认知能力，主要通过感知、理解和比较推理三个方面进行评估。当前的科学基准主要关注MLLMs的知识理解能力，未能充分评估其感知和推理能力。SFE基准包含830个经过专家验证的视觉问答对，涵盖66个多模态任务，涉及五个高价值学科。实验结果显示，现有的最先进模型在SFE上的表现仍有很大提升空间，表明MLLMs在科学领域的应用潜力巨大。","title":"科学认知能力的新评估标准"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='科学家首次考试（SFE）基准测试评估多模态大型语言模型（MLLMs）的科学认知能力，主要通过感知、理解和比较推理三个方面进行评估。当前的科学基准主要关注MLLMs的知识理解能力，未能充分评估其感知和推理能力。SFE基准包含830个经过专家验证的视觉问答对，涵盖66个多模态任务，涉及五个高价值学科。实验结果显示，现有的最先进模型在SFE上的表现仍有很大提升空间，表明MLLMs在科学领域的应用潜力巨大。', title='科学认知能力的新评估标准'))
[17.06.2025 03:45] Using data from previous issue: {"categories": ["#data", "#training", "#optimization"], "emoji": "📈", "ru": {"title": "Точное прогнозирование временных рядов с помощью языковых моделей", "desc": "Статья представляет метод PatchInstruct для улучшения качества прогнозирования временных рядов с помощью больших языковых моделей (LLM).
[17.06.2025 03:45] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#video", "#dataset"], "emoji": "🎬", "ru": {"title": "Новый подход к сумматизации обучающих видео по UI", "desc": "Предложен новый бенчмарк и набор данных для мультимодальной сумматизации обучающих видео по пользовательским интерфейсам. Исследование напра
[17.06.2025 03:45] Querying the API.
[17.06.2025 03:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Research confirms natural representation alignment in large language models and introduces Inference-Time Language Control to enhance cross-lingual performance.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and languages, revolutionizing natural language processing. This paper investigates the naturally emerging representation alignment in LLMs, particularly in the middle layers, and its implications for disentangling language-specific and language-agnostic information. We empirically confirm the existence of this alignment, analyze its behavior in comparison to explicitly designed alignment models, and demonstrate its potential for language-specific manipulation without semantic degradation. Building on these findings, we propose Inference-Time Language Control (ITLC), a novel method that leverages latent injection to enable precise cross-lingual language control and mitigate language confusion in LLMs. Our experiments highlight ITLC's strong cross-lingual control capabilities while preserving semantic integrity in target languages. Furthermore, we demonstrate its effectiveness in alleviating the cross-lingual language confusion problem, which persists even in current large-scale LLMs, leading to inconsistent language generation. This work advances our understanding of representation alignment in LLMs and introduces a practical solution for enhancing their cross-lingual performance.
[17.06.2025 03:45] Response: {
  "desc": "Исследование подтверждает естественное выравнивание представлений в больших языковых моделях (LLM), особенно в средних слоях. Авторы предлагают метод Inference-Time Language Control (ITLC), который использует латентную инъекцию для точного межъязыкового контроля. ITLC позволяет улучшить кросс-языковую производительность LLM и уменьшить языковую путаницу. Эксперименты показывают эффективность ITLC в сохранении семантической целостности при переключении между языками.",
  "emoji": "🌐",
  "title": "Улучшение кросс-языковых возможностей LLM через контроль скрытых представлений"
}
[17.06.2025 03:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research confirms natural representation alignment in large language models and introduces Inference-Time Language Control to enhance cross-lingual performance.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and languages, revolutionizing natural language processing. This paper investigates the naturally emerging representation alignment in LLMs, particularly in the middle layers, and its implications for disentangling language-specific and language-agnostic information. We empirically confirm the existence of this alignment, analyze its behavior in comparison to explicitly designed alignment models, and demonstrate its potential for language-specific manipulation without semantic degradation. Building on these findings, we propose Inference-Time Language Control (ITLC), a novel method that leverages latent injection to enable precise cross-lingual language control and mitigate language confusion in LLMs. Our experiments highlight ITLC's strong cross-lingual control capabilities while preserving semantic integrity in target languages. Furthermore, we demonstrate its effectiveness in alleviating the cross-lingual language confusion problem, which persists even in current large-scale LLMs, leading to inconsistent language generation. This work advances our understanding of representation alignment in LLMs and introduces a practical solution for enhancing their cross-lingual performance."

[17.06.2025 03:45] Response: ```python
['MULTILINGUAL', 'INFERENCE']
```
[17.06.2025 03:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Research confirms natural representation alignment in large language models and introduces Inference-Time Language Control to enhance cross-lingual performance.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and languages, revolutionizing natural language processing. This paper investigates the naturally emerging representation alignment in LLMs, particularly in the middle layers, and its implications for disentangling language-specific and language-agnostic information. We empirically confirm the existence of this alignment, analyze its behavior in comparison to explicitly designed alignment models, and demonstrate its potential for language-specific manipulation without semantic degradation. Building on these findings, we propose Inference-Time Language Control (ITLC), a novel method that leverages latent injection to enable precise cross-lingual language control and mitigate language confusion in LLMs. Our experiments highlight ITLC's strong cross-lingual control capabilities while preserving semantic integrity in target languages. Furthermore, we demonstrate its effectiveness in alleviating the cross-lingual language confusion problem, which persists even in current large-scale LLMs, leading to inconsistent language generation. This work advances our understanding of representation alignment in LLMs and introduces a practical solution for enhancing their cross-lingual performance."

[17.06.2025 03:45] Response: ```python
['ALIGNMENT', 'TRANSLATION']
```
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how large language models (LLMs) naturally align their representations across different languages, particularly in their middle layers. It confirms that this alignment allows for the separation of language-specific and language-agnostic information, which can be manipulated without losing meaning. The authors introduce a new technique called Inference-Time Language Control (ITLC) that uses latent injection to improve control over language generation in cross-lingual contexts. Their experiments show that ITLC effectively reduces language confusion while maintaining semantic integrity, enhancing the overall performance of LLMs in multilingual tasks.","title":"Enhancing Cross-Lingual Performance with Natural Representation Alignment"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how large language models (LLMs) naturally align their representations across different languages, particularly in their middle layers. It confirms that this alignment allows for the separation of language-specific and language-agnostic information, which can be manipulated without losing meaning. The authors introduce a new technique called Inference-Time Language Control (ITLC) that uses latent injection to improve control over language generation in cross-lingual contexts. Their experiments show that ITLC effectively reduces language confusion while maintaining semantic integrity, enhancing the overall performance of LLMs in multilingual tasks.', title='Enhancing Cross-Lingual Performance with Natural Representation Alignment'))
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究确认了大型语言模型（LLMs）中自然出现的表示对齐现象，特别是在中间层的表现。我们实证验证了这种对齐的存在，并分析了其与显式设计的对齐模型的行为比较。基于这些发现，我们提出了一种新方法——推理时语言控制（ITLC），它利用潜在注入技术实现精确的跨语言控制。实验结果表明，ITLC在保持目标语言语义完整性的同时，显著提升了跨语言控制能力，解决了当前大型LLMs中存在的语言混淆问题。","title":"提升跨语言性能的推理时语言控制"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究确认了大型语言模型（LLMs）中自然出现的表示对齐现象，特别是在中间层的表现。我们实证验证了这种对齐的存在，并分析了其与显式设计的对齐模型的行为比较。基于这些发现，我们提出了一种新方法——推理时语言控制（ITLC），它利用潜在注入技术实现精确的跨语言控制。实验结果表明，ITLC在保持目标语言语义完整性的同时，显著提升了跨语言控制能力，解决了当前大型LLMs中存在的语言混淆问题。', title='提升跨语言性能的推理时语言控制'))
[17.06.2025 03:45] Querying the API.
[17.06.2025 03:45] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Budget guidance is a method that steers LLM reasoning within a targeted budget without fine-tuning and achieves improved efficiency and performance on math benchmarks.  					AI-generated summary 				 Recent deep-thinking large language models often reason extensively to improve performance, but such lengthy reasoning is not always desirable, as it incurs excessive inference costs with disproportionate performance gains. Controlling reasoning length without sacrificing performance is therefore important, but remains challenging, especially under tight thinking budgets. We propose budget guidance, a simple yet effective method for steering the reasoning process of LLMs toward a target budget without requiring any LLM fine-tuning. Our approach introduces a lightweight predictor that models a Gamma distribution over the remaining thinking length during next-token generation. This signal is then used to guide generation in a soft, token-level manner, ensuring that the overall reasoning trace adheres to the specified thinking budget. Budget guidance enables natural control of the thinking length, along with significant token efficiency improvements over baseline methods on challenging math benchmarks. For instance, it achieves up to a 26% accuracy gain on the MATH-500 benchmark under tight budgets compared to baseline methods, while maintaining competitive accuracy with only 63% of the thinking tokens used by the full-thinking model. Budget guidance also generalizes to broader task domains and exhibits emergent capabilities, such as estimating question difficulty. The source code is available at: https://github.com/UMass-Embodied-AGI/BudgetGuidance.
[17.06.2025 03:45] Response: {
  "desc": "Метод 'бюджетного руководства' позволяет управлять рассуждениями языковых моделей в рамках заданного бюджета без дополнительного обучения. Он использует легковесный предиктор, моделирующий гамма-распределение оставшейся длины рассуждения при генерации следующего токена. Этот подход обеспечивает естественный контроль длины рассуждения и значительно повышает эффективность использования токенов на сложных математических тестах. Метод также демонстрирует обобщающую способность на более широкий спектр задач и проявляет эмерджентные свойства, такие как оценка сложности вопросов.",
  "emoji": "💡",
  "title": "Эффективное управление рассуждениями ИИ в рамках бюджета"
}
[17.06.2025 03:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Budget guidance is a method that steers LLM reasoning within a targeted budget without fine-tuning and achieves improved efficiency and performance on math benchmarks.  					AI-generated summary 				 Recent deep-thinking large language models often reason extensively to improve performance, but such lengthy reasoning is not always desirable, as it incurs excessive inference costs with disproportionate performance gains. Controlling reasoning length without sacrificing performance is therefore important, but remains challenging, especially under tight thinking budgets. We propose budget guidance, a simple yet effective method for steering the reasoning process of LLMs toward a target budget without requiring any LLM fine-tuning. Our approach introduces a lightweight predictor that models a Gamma distribution over the remaining thinking length during next-token generation. This signal is then used to guide generation in a soft, token-level manner, ensuring that the overall reasoning trace adheres to the specified thinking budget. Budget guidance enables natural control of the thinking length, along with significant token efficiency improvements over baseline methods on challenging math benchmarks. For instance, it achieves up to a 26% accuracy gain on the MATH-500 benchmark under tight budgets compared to baseline methods, while maintaining competitive accuracy with only 63% of the thinking tokens used by the full-thinking model. Budget guidance also generalizes to broader task domains and exhibits emergent capabilities, such as estimating question difficulty. The source code is available at: https://github.com/UMass-Embodied-AGI/BudgetGuidance."

[17.06.2025 03:45] Response: ```python
["TRAINING", "MATH", "INFERENCE"]
```
[17.06.2025 03:45] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Budget guidance is a method that steers LLM reasoning within a targeted budget without fine-tuning and achieves improved efficiency and performance on math benchmarks.  					AI-generated summary 				 Recent deep-thinking large language models often reason extensively to improve performance, but such lengthy reasoning is not always desirable, as it incurs excessive inference costs with disproportionate performance gains. Controlling reasoning length without sacrificing performance is therefore important, but remains challenging, especially under tight thinking budgets. We propose budget guidance, a simple yet effective method for steering the reasoning process of LLMs toward a target budget without requiring any LLM fine-tuning. Our approach introduces a lightweight predictor that models a Gamma distribution over the remaining thinking length during next-token generation. This signal is then used to guide generation in a soft, token-level manner, ensuring that the overall reasoning trace adheres to the specified thinking budget. Budget guidance enables natural control of the thinking length, along with significant token efficiency improvements over baseline methods on challenging math benchmarks. For instance, it achieves up to a 26% accuracy gain on the MATH-500 benchmark under tight budgets compared to baseline methods, while maintaining competitive accuracy with only 63% of the thinking tokens used by the full-thinking model. Budget guidance also generalizes to broader task domains and exhibits emergent capabilities, such as estimating question difficulty. The source code is available at: https://github.com/UMass-Embodied-AGI/BudgetGuidance."

[17.06.2025 03:45] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a method called budget guidance, which helps large language models (LLMs) reason effectively within a specified budget of thinking tokens. By using a lightweight predictor that models a Gamma distribution, the method controls the reasoning length during the generation of each token without needing to fine-tune the LLM. This approach not only improves efficiency but also enhances performance on math benchmarks, achieving significant accuracy gains while using fewer tokens. Additionally, budget guidance shows versatility across different tasks and can even estimate the difficulty of questions.","title":"Steering LLM Reasoning with Budget Guidance for Efficiency and Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a method called budget guidance, which helps large language models (LLMs) reason effectively within a specified budget of thinking tokens. By using a lightweight predictor that models a Gamma distribution, the method controls the reasoning length during the generation of each token without needing to fine-tune the LLM. This approach not only improves efficiency but also enhances performance on math benchmarks, achieving significant accuracy gains while using fewer tokens. Additionally, budget guidance shows versatility across different tasks and can even estimate the difficulty of questions.', title='Steering LLM Reasoning with Budget Guidance for Efficiency and Performance'))
[17.06.2025 03:45] Response: ParsedChatCompletionMessage[Article](content='{"desc":"预算引导是一种方法，可以在不进行微调的情况下，引导大型语言模型（LLM）在目标预算内进行推理，从而提高效率和性能。该方法通过引入一个轻量级预测器，建模剩余思考长度的伽马分布，来控制推理长度。预算引导确保生成过程遵循指定的思考预算，同时在数学基准测试中显著提高了令牌效率。与基线方法相比，在紧张预算下，预算引导在MATH-500基准上实现了高达26%的准确率提升，同时仅使用全思考模型63%的思考令牌。","title":"预算引导：高效推理的新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='预算引导是一种方法，可以在不进行微调的情况下，引导大型语言模型（LLM）在目标预算内进行推理，从而提高效率和性能。该方法通过引入一个轻量级预测器，建模剩余思考长度的伽马分布，来控制推理长度。预算引导确保生成过程遵循指定的思考预算，同时在数学基准测试中显著提高了令牌效率。与基线方法相比，在紧张预算下，预算引导在MATH-500基准上实现了高达26%的准确率提升，同时仅使用全思考模型63%的思考令牌。', title='预算引导：高效推理的新方法'))
[17.06.2025 03:45] Using data from previous issue: {"categories": ["#dataset", "#small_models", "#reasoning", "#long_context", "#interpretability", "#multimodal", "#benchmark"], "emoji": "🧠", "ru": {"title": "Раскрывая личность искусственного интеллекта: новый подход к интерпретации языковых моделей", "desc": "Исследование оценивает различные больши
[17.06.2025 03:45] Renaming data file.
[17.06.2025 03:45] Renaming previous data. hf_papers.json to ./d/2025-06-17.json
[17.06.2025 03:45] Saving new data file.
[17.06.2025 03:45] Generating page.
[17.06.2025 03:45] Renaming previous page.
[17.06.2025 03:45] Renaming previous data. index.html to ./d/2025-06-17.html
[17.06.2025 03:45] Writing result.
[17.06.2025 03:45] Renaming log file.
[17.06.2025 03:45] Renaming previous data. log.txt to ./logs/2025-06-17_last_log.txt
