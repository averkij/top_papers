[17.06.2025 03:45] Read previous papers.
[17.06.2025 03:45] Generating top page (month).
[17.06.2025 03:45] Writing top page (month).
[17.06.2025 04:21] Read previous papers.
[17.06.2025 04:21] Get feed.
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13585
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.11763
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13759
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12915
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.08343
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.03968
[17.06.2025 04:21] Extract page data from URL. URL: https://huggingface.co/papers/2506.13654
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.07961
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13750
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.10521
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12953
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12623
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12450
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.12189
[17.06.2025 04:21] Extract page data from URL. URL: https://huggingface.co/papers/2506.06366
[17.06.2025 04:21] Get page data from previous paper. URL: https://huggingface.co/papers/2506.13752
[17.06.2025 04:21] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.06.2025 04:21] No deleted papers detected.
[17.06.2025 04:21] Downloading and parsing papers (pdf, html). Total: 16.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.13585.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.13585.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.13585.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.11763.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.11763.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.11763.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.13759.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.13759.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.13759.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.12915.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.12915.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.12915.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.08343.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.08343.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.08343.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.03968.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.03968.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.03968.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.13654.
[17.06.2025 04:21] Downloading paper 2506.13654 from http://arxiv.org/pdf/2506.13654v1...
[17.06.2025 04:21] Extracting affiliations from text.
[17.06.2025 04:21] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 1 ] . [ 1 4 5 6 3 1 . 6 0 5 2 : r Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning Hongming Guo4 Penghao Wu1 Yuhao Dong1 Xiuying Wang1 Shulin Tian1,2 Ruiqi Wang1,3 Jingkang Yang1 Hao Zhang3 Hongyuan Zhu2 Ziwei Liu1 2A*STAR, Singapore 1S-Lab, Nanyang Technological University 3Simon Fraser University 4Shanghai AI Lab Figure 1: Overview of Ego-R1. In this figure, we demonstrate how the Ego-R1 Agent orchestrates specialized tools (e.g., Hierarchical_RAG, Video LLM, and VLM) to answer the question step-by-step, based on the observations and previous actions. The system effectively answers questions that require careful searching within ultra-long videos and precise analysis of frame details. Abstract We introduce Ego-R1, novel framework for reasoning over ultra-long (i.e., in days and weeks) egocentric videos, which leverages structured Chain-ofTool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained via reinforcement learning (RL). Inspired by human problem-solving strategies, CoTT decomposes complex reasoning into modular steps, with the RL agent invoking specific tools, one per step, to iteratively and collaboratively answer sub-questions tackling such tasks as temporal retrieval and multi-modal understanding. We design two-stage training paradigm involving supervised finetuning (SFT) of pretrained language model using CoTT data and RL to enable our agent to dynamically propose step-by-step tools for long-range reasoning. To facilitate training, we construct dataset called Ego-R1 Data, which consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our Ego-R1 agent is evaluated on newly curated week-long video QA benchmark, Ego-R1 Bench, which contains human-verified QA pairs from hybrid sources. Extensive results demonstrate that the dynamic, tool-augmented chain-of-thought reasoning by our Ego-R1 Agent can effectively tackle the unique challenges of understanding ultra-long egocentric videos, significantly ext"
[17.06.2025 04:21] Response: ```python
["A*STAR, Singapore", "S-Lab, Nanyang Technological University", "Simon Fraser University", "Shanghai AI Lab"]
```
[17.06.2025 04:21] Deleting PDF ./assets/pdf/2506.13654.pdf.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.07961.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.07961.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.07961.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.13750.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.13750.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.13750.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.10521.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.10521.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.10521.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.12953.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.12953.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.12953.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.12623.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.12623.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.12623.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.12450.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.12450.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.12450.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.12189.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.12189.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.12189.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.06366.
[17.06.2025 04:21] Downloading paper 2506.06366 from http://arxiv.org/pdf/2506.06366v3...
[17.06.2025 04:21] Extracting affiliations from text.
[17.06.2025 04:21] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 1 ] . - [ 3 6 6 3 6 0 . 6 0 5 2 : r a Lin Chen1 Yunke Zhang2 Bingbing Fan2 Yibo Ma2 Jie Feng2 Haoye Chai2 Honglin Zhang2 Shiyuan Zhang2 Nian Li2 Tianhui Liu2 Nicholas Sukiennik2 Keyu Zhao2 Yu Li2 Ziyi Liu2 Fengli Xu2 Yong Li2 1 Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; 2 Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China fenglixu@tsinghua.edu.cn, liyong07@tsinghua.edu.cn "
[17.06.2025 04:21] Response: ```python
[
    "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
    "Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China"
]
```
[17.06.2025 04:21] Deleting PDF ./assets/pdf/2506.06366.pdf.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Downloading and parsing paper https://huggingface.co/papers/2506.13752.
[17.06.2025 04:21] Extra JSON file exists (./assets/json/2506.13752.json), skip PDF parsing.
[17.06.2025 04:21] Paper image links file exists (./assets/img_data/2506.13752.json), skip HTML parsing.
[17.06.2025 04:21] Success.
[17.06.2025 04:21] Enriching papers with extra data.
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 0. A hybrid-attention reasoning model called MiniMax-M1, featuring a Mixture-of-Experts architecture and lightning attention mechanism, is introduced for efficient long-input processing and reinforcement learning.  					AI-generated summary 				 We introduce MiniMax-M1, the world's first open-weight, l...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 1. DeepResearch Bench offers a benchmark framework to evaluate the capabilities of Deep Research Agents in terms of research quality and information retrieval accuracy across multiple fields.  					AI-generated summary 				 Deep Research Agents are a prominent category of LLM-based agents. By autonomou...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 2. Discrete Diffusion Language Models (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs) enable parallel generation and faster inference compared to autoregressive models through denoising-based strategies and full attention mechanisms.  					AI-generated summary 				 In this work, we p...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 3. A new benchmark, PersonaFeedback, evaluates Large Language Models' ability to generate personalized responses given explicit user personas, revealing limitations in current systems.  					AI-generated summary 				 With the rapid improvement in the general capabilities of LLMs, LLM personalization, i...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 4. NoWait suppresses explicit self-reflection tokens during inference to enhance efficiency in multimodal reasoning without reducing model utility.  					AI-generated summary 				 Recent advances in large reasoning models have enabled complex, step-by-step reasoning but often introduce significant over...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 5. The paper presents a method for generating diverse and complex instruction data for large language models using attributed grounding, achieving top performance on benchmarks with a large synthesized dataset.  					AI-generated summary 				 The pursuit of diverse, complex, and large-scale instruction...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 6. Ego-R1, a reinforcement learning-based framework, uses a structured tool-augmented chain-of-thought process to reason over ultra-long egocentric videos, achieving better performance than existing methods by extending time coverage to a week.  					AI-generated summary 				 We introduce Ego-R1, a nov...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 7. BridgeVLA is a 3D vision-language-action model that projects 3D inputs to 2D images and uses 2D heatmaps for efficient and effective action prediction, outperforming baselines in various benchmarks.  					AI-generated summary 				 Recently, leveraging pre-trained vision-language models (VLMs) for bu...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 8. Test3R, a test-time learning technique for 3D reconstruction, enhances geometric accuracy by optimizing network consistency using self-supervised learning on image triplets.  					AI-generated summary 				 Dense matching methods like DUSt3R regress pairwise pointmaps for 3D reconstruction. However, ...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 9. Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.  					AI-generated summary 				 Scientific discoveries increasingly rely on complex multimodal reasoning based on informat...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 10. PatchInstruct enhances LLM forecasting quality through specialized prompting methods that include time series decomposition, patch-based tokenization, and similarity-based neighbor augmentation.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have demonstrated new pos...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 11. A novel benchmark and dataset are proposed for multi-modal summarization of UI instructional videos, addressing the need for step-by-step executable instructions and key video frames.  					AI-generated summary 				 We study multi-modal summarization for instructional videos, whose goal is to provid...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 12. Research confirms natural representation alignment in large language models and introduces Inference-Time Language Control to enhance cross-lingual performance.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable generalization capabilities across tasks and lang...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 13. The study evaluates various LLMs on diverse text tasks using a new dataset, revealing distinct personality traits and improving model interpretability.  					AI-generated summary 				 Large Language Models (LLMs) are increasingly integrated into everyday applications. As their influence grows, under...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 14. A new field, AI Agent Behavioral Science, is proposed to systematically study the behaviors of AI agents in diverse contexts, emphasizing external factors and their interactions, and addressing responsible AI aspects.  					AI-generated summary 				 Recent advances in large language models (LLMs) ha...
[17.06.2025 04:21] ********************************************************************************
[17.06.2025 04:21] Abstract 15. Budget guidance is a method that steers LLM reasoning within a targeted budget without fine-tuning and achieves improved efficiency and performance on math benchmarks.  					AI-generated summary 				 Recent deep-thinking large language models often reason extensively to improve performance, but such...
[17.06.2025 04:21] Read previous papers.
[17.06.2025 04:21] Generating reviews via LLM API.
[17.06.2025 04:21] Using data from previous issue: {"categories": ["#rl", "#training", "#open_source", "#architecture", "#reasoning", "#long_context", "#optimization"], "emoji": "🧠", "ru": {"title": "MiniMax-M1: Гибридный ИИ для эффективной обработки сложных задач", "desc": "MiniMax-M1 - это гибридная модель рассуждений с архитектурой Mixture-of-Exp
[17.06.2025 04:21] Using data from previous issue: {"categories": ["#open_source", "#science", "#agents", "#alignment", "#benchmark"], "emoji": "🔬", "ru": {"title": "Комплексная оценка ИИ-агентов для глубоких исследований", "desc": "DeepResearch Bench - это система оценки возможностей агентов глубоких исследований в области качества исследований и т
[17.06.2025 04:21] Using data from previous issue: {"categories": ["#math", "#training", "#diffusion", "#inference", "#multimodal", "#survey"], "emoji": "🧠", "ru": {"title": "Революция в языковом моделировании: дискретные диффузионные модели", "desc": "Статья представляет собой систематический обзор дискретных диффузионных языковых моделей (dLLMs) и
[17.06.2025 04:21] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#multimodal", "#benchmark"], "emoji": "🎭", "ru": {"title": "PersonaFeedback: новый стандарт оценки персонализации языковых моделей", "desc": "Представлен новый бенчмарк PersonaFeedback для оценки способности больших языковых моделей (LLM) генериров
[17.06.2025 04:21] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#inference", "#multimodal"], "emoji": "🧠", "ru": {"title": "Эффективное рассуждение без лишних слов", "desc": "Исследование представляет метод NoWait, который подавляет токены явной саморефлексии в больших языковых моделях во время вывода. Это позволяет с
[17.06.2025 04:21] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#alignment", "#data", "#benchmark"], "emoji": "🧠", "ru": {"title": "Синтез сложных инструкций для эффективного обучения языковых моделей", "desc": "Статья представляет метод генерации разнообразных и сложных инструкций для обучения больших языковых моделей 
[17.06.2025 04:21] Querying the API.
[17.06.2025 04:21] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Ego-R1, a reinforcement learning-based framework, uses a structured tool-augmented chain-of-thought process to reason over ultra-long egocentric videos, achieving better performance than existing methods by extending time coverage to a week.  					AI-generated summary 				 We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e., in days and weeks) egocentric videos, which leverages a structured Chain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained via reinforcement learning (RL). Inspired by human problem-solving strategies, CoTT decomposes complex reasoning into modular steps, with the RL agent invoking specific tools, one per step, to iteratively and collaboratively answer sub-questions tackling such tasks as temporal retrieval and multi-modal understanding. We design a two-stage training paradigm involving supervised finetuning (SFT) of a pretrained language model using CoTT data and RL to enable our agent to dynamically propose step-by-step tools for long-range reasoning. To facilitate training, we construct a dataset called Ego-R1 Data, which consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our Ego-R1 agent is evaluated on a newly curated week-long video QA benchmark, Ego-R1 Bench, which contains human-verified QA pairs from hybrid sources. Extensive results demonstrate that the dynamic, tool-augmented chain-of-thought reasoning by our Ego-R1 Agent can effectively tackle the unique challenges of understanding ultra-long egocentric videos, significantly extending the time coverage from few hours to a week.
[17.06.2025 04:22] Response: {
  "desc": "Ego-R1 - это новая система обработки сверхдлинных эгоцентрических видео, использующая структурированный процесс цепочки рассуждений с инструментами (Chain-of-Tool-Thought). Система применяет агента, обученного с помощью обучения с подкреплением, для декомпозиции сложных задач на модульные шаги. Ego-R1 использует двухэтапную парадигму обучения, включающую тонкую настройку предобученной языковой модели и обучение с подкреплением. Система значительно расширяет временной охват анализа видео с нескольких часов до недели, превосходя существующие методы.",
  "emoji": "🎥",
  "title": "Ego-R1: Революция в анализе длительных эгоцентрических видео"
}
[17.06.2025 04:22] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Ego-R1, a reinforcement learning-based framework, uses a structured tool-augmented chain-of-thought process to reason over ultra-long egocentric videos, achieving better performance than existing methods by extending time coverage to a week.  					AI-generated summary 				 We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e., in days and weeks) egocentric videos, which leverages a structured Chain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained via reinforcement learning (RL). Inspired by human problem-solving strategies, CoTT decomposes complex reasoning into modular steps, with the RL agent invoking specific tools, one per step, to iteratively and collaboratively answer sub-questions tackling such tasks as temporal retrieval and multi-modal understanding. We design a two-stage training paradigm involving supervised finetuning (SFT) of a pretrained language model using CoTT data and RL to enable our agent to dynamically propose step-by-step tools for long-range reasoning. To facilitate training, we construct a dataset called Ego-R1 Data, which consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our Ego-R1 agent is evaluated on a newly curated week-long video QA benchmark, Ego-R1 Bench, which contains human-verified QA pairs from hybrid sources. Extensive results demonstrate that the dynamic, tool-augmented chain-of-thought reasoning by our Ego-R1 Agent can effectively tackle the unique challenges of understanding ultra-long egocentric videos, significantly extending the time coverage from few hours to a week."

[17.06.2025 04:22] Response: ```python
['RL', 'DATASET', 'BENCHMARK', 'MULTIMODAL', 'TRAINING']
```
[17.06.2025 04:22] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Ego-R1, a reinforcement learning-based framework, uses a structured tool-augmented chain-of-thought process to reason over ultra-long egocentric videos, achieving better performance than existing methods by extending time coverage to a week.  					AI-generated summary 				 We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e., in days and weeks) egocentric videos, which leverages a structured Chain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained via reinforcement learning (RL). Inspired by human problem-solving strategies, CoTT decomposes complex reasoning into modular steps, with the RL agent invoking specific tools, one per step, to iteratively and collaboratively answer sub-questions tackling such tasks as temporal retrieval and multi-modal understanding. We design a two-stage training paradigm involving supervised finetuning (SFT) of a pretrained language model using CoTT data and RL to enable our agent to dynamically propose step-by-step tools for long-range reasoning. To facilitate training, we construct a dataset called Ego-R1 Data, which consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our Ego-R1 agent is evaluated on a newly curated week-long video QA benchmark, Ego-R1 Bench, which contains human-verified QA pairs from hybrid sources. Extensive results demonstrate that the dynamic, tool-augmented chain-of-thought reasoning by our Ego-R1 Agent can effectively tackle the unique challenges of understanding ultra-long egocentric videos, significantly extending the time coverage from few hours to a week."

[17.06.2025 04:22] Response: ```python
['REASONING', 'LONG_CONTEXT']
```
[17.06.2025 04:22] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ego-R1 is a new framework designed to analyze ultra-long egocentric videos, which can last for days or even weeks. It employs a structured Chain-of-Tool-Thought (CoTT) process, allowing the system to break down complex reasoning tasks into manageable steps. The framework is powered by a reinforcement learning agent that learns to select and use specific tools for each step, enhancing its ability to answer questions about the video content. By training on a specially created dataset and evaluating on a new benchmark, Ego-R1 demonstrates improved performance in understanding long-duration videos compared to existing methods.","title":"Revolutionizing Video Understanding with Ego-R1"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ego-R1 is a new framework designed to analyze ultra-long egocentric videos, which can last for days or even weeks. It employs a structured Chain-of-Tool-Thought (CoTT) process, allowing the system to break down complex reasoning tasks into manageable steps. The framework is powered by a reinforcement learning agent that learns to select and use specific tools for each step, enhancing its ability to answer questions about the video content. By training on a specially created dataset and evaluating on a new benchmark, Ego-R1 demonstrates improved performance in understanding long-duration videos compared to existing methods.', title='Revolutionizing Video Understanding with Ego-R1'))
[17.06.2025 04:22] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Ego-R1是一个基于强化学习的框架，旨在处理超长的自我中心视频。它采用了一种结构化的工具增强思维链（CoTT）过程，将复杂的推理分解为模块化步骤。通过强化学习训练的Ego-R1代理能够动态地提出逐步工具，以应对长时间范围内的推理任务。实验结果表明，Ego-R1在理解超长视频方面表现优异，时间覆盖范围从几小时扩展到一周。","title":"Ego-R1：超长视频推理的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Ego-R1是一个基于强化学习的框架，旨在处理超长的自我中心视频。它采用了一种结构化的工具增强思维链（CoTT）过程，将复杂的推理分解为模块化步骤。通过强化学习训练的Ego-R1代理能够动态地提出逐步工具，以应对长时间范围内的推理任务。实验结果表明，Ego-R1在理解超长视频方面表现优异，时间覆盖范围从几小时扩展到一周。', title='Ego-R1：超长视频推理的新突破'))
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#rl", "#3d", "#games", "#optimization", "#agents", "#benchmark"], "emoji": "🤖", "ru": {"title": "BridgeVLA: Эффективное обучение роботов через проекцию 3D в 2D", "desc": "BridgeVLA - это новая модель машинного обучения для роботизированных манипуляций, объединяющая 3D-зрение, язык и
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#3d", "#training", "#optimization"], "emoji": "🏛️", "ru": {"title": "Test3R: Повышение точности 3D-реконструкции через самообучение на тестовых данных", "desc": "Test3R - это новая техника обучения во время тестирования для 3D-реконструкции, которая улучшает геометрическую точность.
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#reasoning", "#science", "#multimodal", "#benchmark"], "emoji": "🔬", "ru": {"title": "Новый бенчмарк для оценки научного мышления ИИ", "desc": "Учёные разработали новый бенчмарк под названием Scientists' First Exam (SFE) для оценки научных когнитивных способностей мультимодальных бо
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#data", "#training", "#optimization"], "emoji": "📈", "ru": {"title": "Точное прогнозирование временных рядов с помощью языковых моделей", "desc": "Статья представляет метод PatchInstruct для улучшения качества прогнозирования временных рядов с помощью больших языковых моделей (LLM).
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#video", "#dataset"], "emoji": "🎬", "ru": {"title": "Новый подход к сумматизации обучающих видео по UI", "desc": "Предложен новый бенчмарк и набор данных для мультимодальной сумматизации обучающих видео по пользовательским интерфейсам. Исследование напра
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#alignment", "#translation", "#inference", "#multilingual"], "emoji": "🌐", "ru": {"title": "Улучшение кросс-языковых возможностей LLM через контроль скрытых представлений", "desc": "Исследование подтверждает естественное выравнивание представлений в больших языковых моделях (LLM), о
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#dataset", "#small_models", "#reasoning", "#long_context", "#interpretability", "#multimodal", "#benchmark"], "emoji": "🧠", "ru": {"title": "Раскрывая личность искусственного интеллекта: новый подход к интерпретации языковых моделей", "desc": "Исследование оценивает различные больши
[17.06.2025 04:22] Querying the API.
[17.06.2025 04:22] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A new field, AI Agent Behavioral Science, is proposed to systematically study the behaviors of AI agents in diverse contexts, emphasizing external factors and their interactions, and addressing responsible AI aspects.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled the development of AI agents that exhibit increasingly human-like behaviors, including planning, adaptation, and social dynamics across diverse, interactive, and open-ended scenarios. These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts, where environmental factors, social cues, and interaction feedbacks shape behavior over time. This evolution necessitates a new scientific perspective: AI Agent Behavioral Science. Rather than focusing only on internal mechanisms, this perspective emphasizes the systematic observation of behavior, design of interventions to test hypotheses, and theory-guided interpretation of how AI agents act, adapt, and interact over time. We systematize a growing body of research across individual agent, multi-agent, and human-agent interaction settings, and further demonstrate how this perspective informs responsible AI by treating fairness, safety, interpretability, accountability, and privacy as behavioral properties. By unifying recent findings and laying out future directions, we position AI Agent Behavioral Science as a necessary complement to traditional model-centric approaches, providing essential tools for understanding, evaluating, and governing the real-world behavior of increasingly autonomous AI systems.
[17.06.2025 04:22] Response: {
  "desc": "Предлагается новая область исследований - поведенческая наука ИИ-агентов. Она направлена на систематическое изучение поведения ИИ-агентов в различных контекстах, уделяя особое внимание внешним факторам и их взаимодействию. Исследования охватывают индивидуальных агентов, многоагентные системы и взаимодействие человека с агентами. Этот подход дополняет традиционные модельно-ориентированные методы и предоставляет инструменты для понимания, оценки и управления поведением автономных ИИ-систем в реальном мире.",
  "emoji": "🧠",
  "title": "От модели к поведению: новый взгляд на изучение ИИ-агентов"
}
[17.06.2025 04:22] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new field, AI Agent Behavioral Science, is proposed to systematically study the behaviors of AI agents in diverse contexts, emphasizing external factors and their interactions, and addressing responsible AI aspects.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled the development of AI agents that exhibit increasingly human-like behaviors, including planning, adaptation, and social dynamics across diverse, interactive, and open-ended scenarios. These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts, where environmental factors, social cues, and interaction feedbacks shape behavior over time. This evolution necessitates a new scientific perspective: AI Agent Behavioral Science. Rather than focusing only on internal mechanisms, this perspective emphasizes the systematic observation of behavior, design of interventions to test hypotheses, and theory-guided interpretation of how AI agents act, adapt, and interact over time. We systematize a growing body of research across individual agent, multi-agent, and human-agent interaction settings, and further demonstrate how this perspective informs responsible AI by treating fairness, safety, interpretability, accountability, and privacy as behavioral properties. By unifying recent findings and laying out future directions, we position AI Agent Behavioral Science as a necessary complement to traditional model-centric approaches, providing essential tools for understanding, evaluating, and governing the real-world behavior of increasingly autonomous AI systems."

[17.06.2025 04:22] Response: ```python
['AGENTS', 'MULTIMODAL', 'HEALTHCARE']
```
[17.06.2025 04:22] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A new field, AI Agent Behavioral Science, is proposed to systematically study the behaviors of AI agents in diverse contexts, emphasizing external factors and their interactions, and addressing responsible AI aspects.  					AI-generated summary 				 Recent advances in large language models (LLMs) have enabled the development of AI agents that exhibit increasingly human-like behaviors, including planning, adaptation, and social dynamics across diverse, interactive, and open-ended scenarios. These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts, where environmental factors, social cues, and interaction feedbacks shape behavior over time. This evolution necessitates a new scientific perspective: AI Agent Behavioral Science. Rather than focusing only on internal mechanisms, this perspective emphasizes the systematic observation of behavior, design of interventions to test hypotheses, and theory-guided interpretation of how AI agents act, adapt, and interact over time. We systematize a growing body of research across individual agent, multi-agent, and human-agent interaction settings, and further demonstrate how this perspective informs responsible AI by treating fairness, safety, interpretability, accountability, and privacy as behavioral properties. By unifying recent findings and laying out future directions, we position AI Agent Behavioral Science as a necessary complement to traditional model-centric approaches, providing essential tools for understanding, evaluating, and governing the real-world behavior of increasingly autonomous AI systems."

[17.06.2025 04:22] Response: ```python
['ETHICS', 'INTERPRETABILITY', 'AGI']
```
[17.06.2025 04:22] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces AI Agent Behavioral Science, a new field focused on studying the behaviors of AI agents in various contexts. It highlights that these behaviors arise not just from the AI\'s internal design but also from interactions with their environment and social dynamics. The approach emphasizes systematic observation, hypothesis testing, and theory-driven analysis to understand how AI agents adapt and interact over time. This perspective also addresses responsible AI considerations, such as fairness and accountability, making it a vital complement to traditional model-centric methods.","title":"Understanding AI Behavior: A New Scientific Approach"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="The paper introduces AI Agent Behavioral Science, a new field focused on studying the behaviors of AI agents in various contexts. It highlights that these behaviors arise not just from the AI's internal design but also from interactions with their environment and social dynamics. The approach emphasizes systematic observation, hypothesis testing, and theory-driven analysis to understand how AI agents adapt and interact over time. This perspective also addresses responsible AI considerations, such as fairness and accountability, making it a vital complement to traditional model-centric methods.", title='Understanding AI Behavior: A New Scientific Approach'))
[17.06.2025 04:22] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一个新的领域——人工智能代理行为科学，旨在系统研究人工智能代理在不同环境中的行为。随着大型语言模型的发展，AI代理展现出越来越人性化的行为，如规划、适应和社交动态。这些行为不仅源于模型的内部结构，还受到环境因素、社交线索和互动反馈的影响。该领域强调对行为的系统观察和干预设计，以促进对AI代理行为的理解和负责任的应用。","title":"探索人工智能代理的行为科学"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一个新的领域——人工智能代理行为科学，旨在系统研究人工智能代理在不同环境中的行为。随着大型语言模型的发展，AI代理展现出越来越人性化的行为，如规划、适应和社交动态。这些行为不仅源于模型的内部结构，还受到环境因素、社交线索和互动反馈的影响。该领域强调对行为的系统观察和干预设计，以促进对AI代理行为的理解和负责任的应用。', title='探索人工智能代理的行为科学'))
[17.06.2025 04:22] Using data from previous issue: {"categories": ["#optimization", "#inference", "#training", "#reasoning", "#math"], "emoji": "💡", "ru": {"title": "Эффективное управление рассуждениями ИИ в рамках бюджета", "desc": "Метод 'бюджетного руководства' позволяет управлять рассуждениями языковых моделей в рамках заданного бюджета без допо
[17.06.2025 04:22] Renaming data file.
[17.06.2025 04:22] Renaming previous data. hf_papers.json to ./d/2025-06-17.json
[17.06.2025 04:22] Saving new data file.
[17.06.2025 04:22] Generating page.
[17.06.2025 04:22] Renaming previous page.
[17.06.2025 04:22] Renaming previous data. index.html to ./d/2025-06-17.html
[17.06.2025 04:22] Writing result.
[17.06.2025 04:22] Renaming log file.
[17.06.2025 04:22] Renaming previous data. log.txt to ./logs/2025-06-17_last_log.txt
