[02.07.2025 05:15] Read previous papers.
[02.07.2025 05:15] Generating top page (month).
[02.07.2025 05:15] Writing top page (month).
[02.07.2025 06:18] Read previous papers.
[02.07.2025 06:18] Get feed.
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.01006
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2506.23115
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.01001
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.00432
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2506.20639
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.00951
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2506.21277
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2506.19852
[02.07.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2506.22960
[02.07.2025 06:18] Extract page data from URL. URL: https://huggingface.co/papers/2506.21545
[02.07.2025 06:18] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[02.07.2025 06:18] No deleted papers detected.
[02.07.2025 06:18] Downloading and parsing papers (pdf, html). Total: 10.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2507.01006.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2507.01006.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2507.01006.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2506.23115.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2506.23115.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2506.23115.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2507.01001.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2507.01001.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2507.01001.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2507.00432.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2507.00432.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2507.00432.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2506.20639.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2506.20639.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2506.20639.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2507.00951.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2507.00951.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2507.00951.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2506.21277.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2506.21277.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2506.21277.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2506.19852.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2506.19852.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2506.19852.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2506.22960.
[02.07.2025 06:18] Extra JSON file exists (./assets/json/2506.22960.json), skip PDF parsing.
[02.07.2025 06:18] Paper image links file exists (./assets/img_data/2506.22960.json), skip HTML parsing.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2506.21545.
[02.07.2025 06:18] Downloading paper 2506.21545 from http://arxiv.org/pdf/2506.21545v1...
[02.07.2025 06:18] Extracting affiliations from text.
[02.07.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Yalun Dai Yangyu Huang Xin Zhang Wenshan Wu Chong Li Wenhui Lu Shijie Cao Li Dong Scarlett Li "
[02.07.2025 06:18] Response: []
[02.07.2025 06:18] Extracting affiliations from text.
[02.07.2025 06:18] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Yalun Dai Yangyu Huang Xin Zhang Wenshan Wu Chong Li Wenhui Lu Shijie Cao Li Dong Scarlett LiData is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Data Scoring assigns score for each data sample based on its properties, such as quality, difficulty, and learnability. Data Selection optionally selects subset from the original training data based on the scores. Data Ordering utilizes these scores to organize the training data in new, optimized order, rather than the traditional random shuffling. Furthermore, we design Learnability-Quality Scoring (LQS), as new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, different DELT instances enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and FO for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is promising foundational area in LM training. The Code is publicly available now. 5 2 0 2 6 2 ] . [ 1 5 4 5 1 2 . 6 0 5 2 : r Figure 1: Average result across 8 benchmarks for different methods. High performance at the same selection ratio indicates high efficacy, while achieving similar performance with smaller selection ratio demonstrates high efficiency. Our method excels in both efficacy and efficiency. Corresponding author Preprint. Under review.The significance of language models [1, 2, 3] is immense in modern computational applications. From natural language processing tasks such as translation [4] and sentiment analysis [5] to more complex applications like automated reasoning [6] and conversational agents [7], language models have revolutionized the way machines understand, generate, and interact with human beings using natural language. To empower language models having these abilities, data is central to their training and serves as the foundation from which models learn knowledge based on linguistic patterns and structures. Consequently, meticulous data curation is essential to ensure consistently high model performance across various applications. Recent research has therefore concentrated on data efficiency, selecting the smallest or highestquality subset of the corpus that still yields strong results [8, 9, 10]. Once that subset is chosen, however, every surviving sample is ordinarily treated the same, and the order in which samples are shown to the model is random. In this work, we define data efficacy as improving model performance by optimizing the organization of training data. This area complements data efficacy and is still in its early stage, with its potential demonstrated through curriculum learning [11, 12] that feeds examples to model from easy to hard. In this context, we notice that the latest generation of language models [13, 3, 14] typically trains for only few epochs, usually just one, due to the vast scale of training datasets but limited computing power. These models contrast with previous generations [15, 16] by the scaling law [17], which trained over many epochs and often led to overfitting. This aligns with the findings of QQT [18], which shows that high-quality data quickly loses its utility after being used repeatedly. In other words, it is more effective to utilize large amount of training data with few epochs rather than rely on high-quality data with many epochs. Consequently, effectively organizing the training dataset is essential for enhancing the performance of language models trained with only few epochs. Expanding on this insight, we propose general paradigm for data efficacy that achieves benefits without altering the dataset content and the model architecture, which makes it an almost cost-free approach. Specifically, this paradigm incorporates data scoring, data selection, and data ordering components. Data scoring assigns score to each sample, which reflects factors like difficulty, quality, diversity, and learnability. Data selection involves optionally choosing subset of the original training data based on these scores. Data ordering then organizes the training data according to these scores, either in ascending, descending, or other arrangements. Curriculum learning [11, 12] can be viewed as specific example within our paradigm, with ascending ordering based on difficulty scoring. To verify the proposed paradigm, we integrate some baseline methods into it and also design new methods respectively for data scoring and ordering. The key results from Figure 1 highlight that the proposed DELT significantly improves data efficacy in LM training on set of typical benchmarks. Meanwhile, it outperforms existing methods [10, 19] in data efficiency that further boosts LM performance across all selection ratios. The main contributions of this paper are as below: We identified the potential of the underexplored area, data efficacy, in language model training and proposed general paradigm for this area, DELT, which consists of data scoring, data selection, and data ordering. We designed an innovative method for data scoring, called Learnability-Quality Scoring (LQS), which evaluates the score for each data sample based on learnability and quality from the gradient consistency perspective. We devised novel method for data ordering, named Folding Ordering (FO), which optimizes LM training and mitigates the issues of model forgetting and data distributio"
[02.07.2025 06:18] Mistral response. {"id": "9028e8b0c391434295e069c32d71e5c4", "object": "chat.completion", "created": 1751437092, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1439, "total_tokens": 1441, "completion_tokens": 2}}
[02.07.2025 06:18] Response: []
[02.07.2025 06:18] Deleting PDF ./assets/pdf/2506.21545.pdf.
[02.07.2025 06:18] Success.
[02.07.2025 06:18] Enriching papers with extra data.
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 0. A vision-language model, GLM-4.1V-Thinking, enhances general-purpose multimodal reasoning through large-scale pre-training and reinforcement learning, achieving state-of-the-art performance across various tasks.  					AI-generated summary 				 We present GLM-4.1V-Thinking, a vision-language model (V...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 1. MoCa, a two-stage framework, enhances pre-trained causal vision-language models for multimodal embedding by introducing bidirectional attention, scaling with unlabeled data, and diverse training objectives.  					AI-generated summary 				 Multimodal embedding models, built upon causal Vision Languag...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 2. SciArena is a community-driven platform for evaluating foundation models on scientific literature tasks, using collective voter judgments to rank models and address the need for reliable automated evaluation.  					AI-generated summary 				 We present SciArena, an open and collaborative platform for...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 3. Reinforcement learning-tuned models outperform supervised fine-tuned models in generalizing mathematical problem-solving abilities to other domains, indicating a need to re-evaluate training methods for reasoning models.  					AI-generated summary 				 Math reasoning has become the poster child of p...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 4. Diffusion large language models are applied to code generation, revealing their unique denoising processes and benefiting from a novel reinforcement learning sampling scheme.  					AI-generated summary 				 Diffusion large language models (dLLMs) are compelling alternatives to autoregressive (AR) mo...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 5. The paper synthesizes the interdisciplinary approach to achieving Artificial General Intelligence, emphasizing modular reasoning, memory, multi-agent coordination, and the integration of neurosymbolic systems and reinforcement learning to overcome current model limitations.  					AI-generated summar...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 6. A reinforcement learning-based approach enhances multimodal reasoning by addressing context understanding and shortcut problems, using context, format, accuracy, and logical rewards, and achieving superior performance on the IntentBench benchmark.  					AI-generated summary 				 With the rapid evolu...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 7. Radial Attention, a scalable sparse attention mechanism, improves efficiency and preserves video quality in diffusion models by leveraging spatiotemporal energy decay.  					AI-generated summary 				 Recent advances in diffusion models have enabled high-quality video generation, but the additional t...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 8. PECCAVI is a robust image watermarking technique that is resistant to visual paraphrase attacks and distortions, utilizing NMPs and multi-channel frequency domain watermarking.  					AI-generated summary 				 A report by the European Union Law Enforcement Agency predicts that by 2026, up to 90 perce...
[02.07.2025 06:18] ********************************************************************************
[02.07.2025 06:18] Abstract 9. DELT, a paradigm for enhancing language model performance through data efficacy, consists of data scoring, selection, and ordering, demonstrating significant improvements without increasing data scale or model size.  					AI-generated summary 				 Data is fundamental to the training of language mode...
[02.07.2025 06:18] Read previous papers.
[02.07.2025 06:18] Generating reviews via LLM API.
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#open_source", "#rl", "#architecture", "#reasoning", "#multimodal", "#benchmark", "#training"], "emoji": "üß†", "ru": {"title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤–æ–º —É—Ä–æ–≤–Ω–µ", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å GLM-4.1V-Thinking - –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#training", "#optimization", "#multimodal", "#alignment", "#architecture"], "emoji": "üß†", "ru": {"title": "MoCa: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–∏", "desc": "MoCa - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#open_source", "#science", "#benchmark", "#survey", "#dataset"], "emoji": "üß™", "ru": {"title": "–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—É–º –≤ –æ—Ü–µ–Ω–∫–µ –ò–ò –¥–ª—è –Ω–∞—É—á–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã", "desc": "SciArena - —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö —Ä–∞–±–æ—Ç—ã —Å –Ω–∞—É—á–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–æ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –∫–æ–ª–ª–µ–∫—Ç–∏–≤
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#training", "#rl", "#transfer_learning", "#optimization", "#math"], "emoji": "üß†", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º –≤ –æ–±–æ–±—â–µ–Ω–∏–∏ –Ω–∞–≤—ã–∫–æ–≤ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å 
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#training", "#rl", "#architecture", "#optimization", "#dataset", "#diffusion"], "emoji": "üß†", "ru": {"title": "–†–∞—Å–∫—Ä—ã—Ç–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (dLLM) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞. –ê–≤—Ç–æ—Ä—ã
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#agents", "#agi", "#rl", "#architecture", "#multimodal", "#rag", "#ethics", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ü—É—Ç—å –∫ AGI: –æ–±—ä–µ–¥–∏–Ω—è—è –º–æ–¥—É–ª—å–Ω–æ—Å—Ç—å, –ø–∞–º—è—Ç—å –∏ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ—Å—Ç—å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—â–µ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#games", "#rl", "#multimodal", "#survey"], "emoji": "üß†", "ru": {"title": "–£—Å–∏–ª–µ–Ω–∏–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –ø–æ–¥—Ö–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ 
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#video", "#optimization", "#diffusion", "#architecture", "#inference", "#training"], "emoji": "üé•", "ru": {"title": "–†–∞–¥–∏–∞–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º '–†–∞–¥–∏–∞–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ' –¥–ª—è 
[02.07.2025 06:18] Using data from previous issue: {"categories": ["#security", "#synthetic", "#data", "#open_source", "#multimodal", "#cv"], "emoji": "üîê", "ru": {"title": "–ù–µ–ø–æ–±–µ–¥–∏–º—ã–µ –≤–æ–¥—è–Ω—ã–µ –∑–Ω–∞–∫–∏ –¥–ª—è —ç–ø–æ—Ö–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ò–ò", "desc": "PECCAVI - —ç—Ç–æ —É—Å—Ç–æ–π—á–∏–≤–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ—Ç–∏–≤–æ—Å—Ç–æ–∏—Ç –∞—Ç–∞–∫–∞–º –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏
[02.07.2025 06:18] Querying the API.
[02.07.2025 06:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DELT, a paradigm for enhancing language model performance through data efficacy, consists of data scoring, selection, and ordering, demonstrating significant improvements without increasing data scale or model size.  					AI-generated summary 				 Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training.
[02.07.2025 06:18] Response: {
  "desc": "DELT - —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—É—Ç–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∞ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞: –æ—Ü–µ–Ω–∫—É –¥–∞–Ω–Ω—ã—Ö, –æ—Ç–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –¥–∞–Ω–Ω—ã—Ö LQS, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π –æ–±—É—á–∞–µ–º–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞, –∞ —Ç–∞–∫–∂–µ –º–µ—Ç–æ–¥ —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö FO –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –∑–∞–±—ã–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ —Å–º–µ—â–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ DELT –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏.",

  "emoji": "üß†",

  "title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö - –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
}
[02.07.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DELT, a paradigm for enhancing language model performance through data efficacy, consists of data scoring, selection, and ordering, demonstrating significant improvements without increasing data scale or model size.  					AI-generated summary 				 Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training."

[02.07.2025 06:18] Response: ```python
["DATA", "TRAINING"]
```
[02.07.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DELT, a paradigm for enhancing language model performance through data efficacy, consists of data scoring, selection, and ordering, demonstrating significant improvements without increasing data scale or model size.  					AI-generated summary 				 Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training."

[02.07.2025 06:18] Response: ```python
["OPTIMIZATION"]
```
[02.07.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces DELT, a new approach to improve language model performance by focusing on data efficacy, which is about how well training data is organized. It consists of three main components: Data Scoring, Data Selection, and Data Ordering, which work together to enhance model training without needing more data or larger models. A key innovation is the Learnability-Quality Scoring (LQS), which evaluates data samples based on their learnability and quality. The results show that using DELT can significantly boost performance, especially when combining LQS with Folding Ordering, while also achieving data efficiency.","title":"Maximizing Language Model Performance through Data Efficacy"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces DELT, a new approach to improve language model performance by focusing on data efficacy, which is about how well training data is organized. It consists of three main components: Data Scoring, Data Selection, and Data Ordering, which work together to enhance model training without needing more data or larger models. A key innovation is the Learnability-Quality Scoring (LQS), which evaluates data samples based on their learnability and quality. The results show that using DELT can significantly boost performance, especially when combining LQS with Folding Ordering, while also achieving data efficiency.', title='Maximizing Language Model Performance through Data Efficacy'))
[02.07.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DELTÊòØ‰∏ÄÁßçÊèêÈ´òËØ≠Ë®ÄÊ®°ÂûãÊÄßËÉΩÁöÑÊñ∞ÊñπÊ≥ïÔºå‰∏ìÊ≥®‰∫éÊï∞ÊçÆÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂåÖÊã¨Êï∞ÊçÆËØÑÂàÜ„ÄÅÈÄâÊã©ÂíåÊéíÂ∫è‰∏â‰∏™ÈÉ®ÂàÜÔºåÊó®Âú®‰ºòÂåñËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁªÑÁªáÊñπÂºè„ÄÇÈÄöËøáËÆæËÆ°Â≠¶‰π†Ë¥®ÈáèËØÑÂàÜÔºàLQSÔºâÂíåÊäòÂè†ÊéíÂ∫èÔºàFOÔºâÔºåDELTËÉΩÂ§üÂú®‰∏çÂ¢ûÂä†Êï∞ÊçÆËßÑÊ®°ÊàñÊ®°ÂûãÂ§ßÂ∞èÁöÑÊÉÖÂÜµ‰∏ãÊòæËëóÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊï∞ÊçÆÊúâÊïàÊÄß‰∏éÊï∞ÊçÆÊïàÁéáÂèØ‰ª•ÁªìÂêà‰ΩøÁî®Ôºå‰ªéËÄå‰∏∫ËØ≠Ë®ÄÊ®°ÂûãËÆ≠ÁªÉÊèê‰æõÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ","title":"ÊèêÂçáËØ≠Ë®ÄÊ®°ÂûãÊÄßËÉΩÁöÑÊñ∞ÊñπÊ≥ïÔºöDELT"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DELTÊòØ‰∏ÄÁßçÊèêÈ´òËØ≠Ë®ÄÊ®°ÂûãÊÄßËÉΩÁöÑÊñ∞ÊñπÊ≥ïÔºå‰∏ìÊ≥®‰∫éÊï∞ÊçÆÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂåÖÊã¨Êï∞ÊçÆËØÑÂàÜ„ÄÅÈÄâÊã©ÂíåÊéíÂ∫è‰∏â‰∏™ÈÉ®ÂàÜÔºåÊó®Âú®‰ºòÂåñËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁªÑÁªáÊñπÂºè„ÄÇÈÄöËøáËÆæËÆ°Â≠¶‰π†Ë¥®ÈáèËØÑÂàÜÔºàLQSÔºâÂíåÊäòÂè†ÊéíÂ∫èÔºàFOÔºâÔºåDELTËÉΩÂ§üÂú®‰∏çÂ¢ûÂä†Êï∞ÊçÆËßÑÊ®°ÊàñÊ®°ÂûãÂ§ßÂ∞èÁöÑÊÉÖÂÜµ‰∏ãÊòæËëóÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊï∞ÊçÆÊúâÊïàÊÄß‰∏éÊï∞ÊçÆÊïàÁéáÂèØ‰ª•ÁªìÂêà‰ΩøÁî®Ôºå‰ªéËÄå‰∏∫ËØ≠Ë®ÄÊ®°ÂûãËÆ≠ÁªÉÊèê‰æõÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ', title='ÊèêÂçáËØ≠Ë®ÄÊ®°ÂûãÊÄßËÉΩÁöÑÊñ∞ÊñπÊ≥ïÔºöDELT'))
[02.07.2025 06:18] Renaming data file.
[02.07.2025 06:18] Renaming previous data. hf_papers.json to ./d/2025-07-02.json
[02.07.2025 06:18] Saving new data file.
[02.07.2025 06:18] Generating page.
[02.07.2025 06:18] Renaming previous page.
[02.07.2025 06:18] Renaming previous data. index.html to ./d/2025-07-02.html
[02.07.2025 06:18] Writing result.
[02.07.2025 06:18] Renaming log file.
[02.07.2025 06:18] Renaming previous data. log.txt to ./logs/2025-07-02_last_log.txt
