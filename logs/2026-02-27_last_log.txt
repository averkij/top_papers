[27.02.2026 11:28] Read previous papers.
[27.02.2026 11:28] Generating top page (month).
[27.02.2026 11:28] Writing top page (month).
[27.02.2026 12:40] Read previous papers.
[27.02.2026 12:40] Get feed.
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22859
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23152
[27.02.2026 12:40] Extract page data from URL. URL: https://huggingface.co/papers/2602.22638
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22897
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22766
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23008
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23258
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22675
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23363
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.21760
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23205
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.17594
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22594
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22437
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23259
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23058
[27.02.2026 12:40] Extract page data from URL. URL: https://huggingface.co/papers/2602.22045
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.23165
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.22479
[27.02.2026 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2602.20981
[27.02.2026 12:40] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.02.2026 12:40] No deleted papers detected.
[27.02.2026 12:40] Downloading and parsing papers (pdf, html). Total: 20.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22859.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22859.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22859.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23152.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23152.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23152.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22638.
[27.02.2026 12:40] Downloading paper 2602.22638 from https://arxiv.org/pdf/2602.22638v1...
[27.02.2026 12:40] Extracting affiliations from text.
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 6 2 ] . [ 1 8 3 6 2 2 . 2 0 6 2 : r MobilityBench: Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios Zhiheng Song Computer Network Information Center, Chinese Academy of Sciences AMAP, Alibaba Group Beijing, China songzhiheng2004@gmail.com Chao Wang University of Science and Technology of China Heifei, China wangchaoai@ustc.edu.cn Jingshuai Zhang AMAP, Alibaba Group Beijing, China zhangjingshuai0@gamil.com Chuan Qin Computer Network Information Center, Chinese Academy of Sciences Beijing, China chuanqin0426@gmail.com Chao Chen AMAP, Alibaba Group Beijing, China cc201598@alibaba-inc.com Longfei Xu AMAP, Alibaba Group Beijing, China longfei.xl@alibaba-inc.com Kaikui Liu AMAP, Alibaba Group Beijing, China damon@alibaba-inc.com Xiangxiang Chu AMAP, Alibaba Group Beijing, China cxxgtxy@gmail.com Hengshu Zhu Computer Network Information Center, Chinese Academy of Sciences Beijing, China zhuhengshu@gmail.com Abstract Route-planning agents powered by large language models (LLMs) have emerged as promising paradigm for supporting everyday human mobility through natural language interaction and toolmediated decision making. However, systematic evaluation in realworld mobility settings is hindered by diverse routing demands, nondeterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using Mobi"
[27.02.2026 12:40] Response: ```python
[
    "Computer Network Information Center, Chinese Academy of Sciences",
    "AMAP, Alibaba Group",
    "University of Science and Technology of China"
]
```
[27.02.2026 12:40] Deleting PDF ./assets/pdf/2602.22638.pdf.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22897.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22897.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22897.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22766.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22766.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22766.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23008.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23008.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23008.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23258.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23258.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23258.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22675.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22675.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22675.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23363.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23363.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23363.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.21760.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.21760.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.21760.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23205.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23205.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23205.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.17594.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.17594.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.17594.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22594.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22594.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22594.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22437.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22437.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22437.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23259.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23259.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23259.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23058.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23058.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23058.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22045.
[27.02.2026 12:40] Downloading paper 2602.22045 from https://arxiv.org/pdf/2602.22045v1...
[27.02.2026 12:40] Extracting affiliations from text.
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 5 2 ] . [ 1 5 4 0 2 2 . 2 0 6 2 : r DLT-Corpus: Large-Scale Text Collection for the Distributed Ledger Technology Domain Walter Hernandez Cruz1,3, Peter Devine2, Nikhil Vadgama1,3, Paolo Tasca1,3, Jiahua Xu1,3 1Centre for Blockchain Technologies, University College London 2School of Informatics, University of Edinburgh 3Exponential Science {walter.hernandez.18,nikhil.vadgama,p.tasca,jiahua.xu}@ucl.ac.uk,pdevine2@ed.ac.uk Abstract We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language underexplored despite the sectors $3 trillion market capitalization and rapid technological evolution. We demonstrate DLT-Corpus utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in virtuous cycle where research precedes and enables economic growth that funds further innovation. We publicly release the full DLT-Corpus; LedgerBERT, domainadapted model achieving 23% improvement over BERT-base on DLT-specific Named Entity Recognition (NER) task; and all associated tools and code. CCS Concepts Computing methodologies Language resources; Natural language processing; Information systems Data mining. Keywords Distributed Ledger Technology, Blockchain,"
[27.02.2026 12:40] Response: ```python
[
    "Centre for Blockchain Technologies, University College London",
    "School of Informatics, University of Edinburgh",
    "Exponential Science"
]
```
[27.02.2026 12:40] Deleting PDF ./assets/pdf/2602.22045.pdf.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.23165.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.23165.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.23165.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.22479.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.22479.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.22479.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Downloading and parsing paper https://huggingface.co/papers/2602.20981.
[27.02.2026 12:40] Extra JSON file exists (./assets/json/2602.20981.json), skip PDF parsing.
[27.02.2026 12:40] Paper image links file exists (./assets/img_data/2602.20981.json), skip HTML parsing.
[27.02.2026 12:40] Success.
[27.02.2026 12:40] Enriching papers with extra data.
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 0. Abstract Diagnostic-driven Progressive Evolution enables continuous improvement of large multimodal models through iterative diagnosis and targeted data generation guided by identified weaknesses.  					AI-generated summary As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) m...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 1. Abstract World Models require three consistency principles‚Äîmodal, spatial, and temporal‚Äîfor general artificial intelligence, with a proposed benchmark evaluating multimodal learning systems.  					AI-generated summary The construction of World Models capable of learning, simulating, and reasoning ab...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 2. Abstract MobileBench is a scalable benchmark for evaluating LLM-based route-planning agents in real-world scenarios, featuring anonymized user queries and a deterministic sandbox for reproducible testing.  					AI-generated summary Route-planning agents powered by large language models (LLMs) have e...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 3. Abstract OmniGAIA benchmark evaluates multi-modal agents on complex reasoning tasks across video, audio, and image modalities, while OmniAtlas agent improves tool-use capabilities through hindsight-guided tree exploration and OmniDPO fine-tuning.  					AI-generated summary Human intelligence natural...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 4. Abstract Research reveals that latent visual reasoning in multimodal models suffers from input-latent and latent-answer disconnects, leading to the proposal of CapImagine, a text-based approach that outperforms complex latent-space methods.  					AI-generated summary Latent visual reasoning aims to ...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 5. Abstract EMPO¬≤ is a hybrid reinforcement learning framework that enhances exploration for large language model agents by integrating memory mechanisms with on- and off-policy updates, demonstrating improved performance and adaptability in complex environments.  					AI-generated summary Exploration ...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 6. Abstract AgentDropoutV2 is a test-time framework that dynamically optimizes multi-agent system information flow through error correction and pruning mechanisms without requiring retraining.  					AI-generated summary While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the ca...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 7. Abstract A deep learning framework called SMTL improves efficient long-horizon agentic search by replacing sequential reasoning with parallel evidence acquisition, achieving state-of-the-art performance across multiple research benchmarks while reducing reasoning steps by 70.7%.  					AI-generated s...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 8. Abstract MediX-R1 presents an open-ended reinforcement learning framework for medical multimodal large language models that uses diverse reward signals and LLM-based evaluation to improve clinical reasoning beyond multiple-choice formats.  					AI-generated summary We introduce MediX-R1, an open-end...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 9. Abstract A hybrid parallelism framework for diffusion models that combines condition-based partitioning and adaptive pipeline scheduling to reduce inference latency while maintaining image quality across different architectures.  					AI-generated summary Diffusion models have achieved remarkable pr...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 10. Abstract A portable dual-iPhone system enables metric-scale human-scene reconstruction and supports embodied AI tasks including physics-based animation and robot motion control.  					AI-generated summary Human behaviors in the real world naturally encode rich, long-term contextual information that ...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 11. Abstract AI systems were evaluated across a diverse set of human-designed games to assess general intelligence, revealing significant gaps in performance compared to human players, particularly in complex cognitive tasks.  					AI-generated summary Rigorously evaluating machine intelligence against ...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 12. Abstract Causal Motion Diffusion Models introduce a unified framework for autoregressive motion generation using a causal diffusion transformer in a semantically aligned latent space, enabling fast, high-quality text-to-motion synthesis with improved temporal smoothness.  					AI-generated summary R...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 13. Abstract veScale-FSDP introduces a redesigned fully sharded data parallel system with flexible sharding and structure-aware planning to improve scalability and efficiency for large-scale model training.  					AI-generated summary Fully Sharded Data Parallel (FSDP), also known as ZeRO, is widely used...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 14. Abstract A risk-aware framework for autonomous driving that uses world modeling and risk evaluation to generalize beyond expert demonstrations without requiring explicit expert supervision.  					AI-generated summary With advances in imitation learning (IL) and large-scale driving datasets, end-to-e...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 15. Abstract GeoWorld addresses limitations in energy-based predictive world models by utilizing hyperbolic geometry to preserve latent state structures and improve long-horizon prediction performance.  					AI-generated summary Energy-based predictive world models provide a powerful approach for multi-...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 16. Abstract The DLT-Corpus dataset, containing 2.98 billion tokens from diverse sources, enables analysis of technology emergence patterns and market-innovation correlations in the distributed ledger technology sector.  					AI-generated summary We introduce DLT-Corpus, the largest domain-specific text...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 17. Abstract DyaDiT is a multi-modal diffusion transformer that generates contextually appropriate human motion from dyadic audio signals by capturing interaction dynamics between two speakers.  					AI-generated summary Generating realistic conversational gestures are essential for achieving natural, s...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 18. Abstract TRC¬≤ addresses continual learning challenges in language models through a sparse, chunk-parallel architectural design that enables rapid adaptation without catastrophic forgetting.  					AI-generated summary Continual learning is a core requirement for deployed language models, yet standard...
[27.02.2026 12:40] ********************************************************************************
[27.02.2026 12:40] Abstract 19. Abstract MMHNet enables long-form audio generation from video by integrating hierarchical methods and non-causal Mamba, achieving superior performance over existing video-to-audio approaches.  					AI-generated summary Scaling multimodal alignment between video and audio is challenging, particularly...
[27.02.2026 12:40] Read previous papers.
[27.02.2026 12:40] Generating reviews via LLM API.
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#rl", "#dataset", "#training", "#benchmark"], "emoji": "üîÑ", "ru": {"title": "–°–ø–∏—Ä–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –∏–∑ —Å–ª–∞–±–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏ –≤ —Å–∏–ª—É", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ Diagnostic-driven Progressive Evolution (DPE) –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#benchmark", "#video", "#architecture", "#multimodal"], "emoji": "üåç", "ru": {"title": "–°–≤—è—Ç–∞—è –¢—Ä–æ–∏—Ü–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: –ø—Ä–∏–Ω—Ü–∏–ø—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∏—Ä–∞", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∏—Ä–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ —Ç—Ä—ë—Ö –ø—Ä–∏–Ω
[27.02.2026 12:40] Querying the API.
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Abstract MobileBench is a scalable benchmark for evaluating LLM-based route-planning agents in real-world scenarios, featuring anonymized user queries and a deterministic sandbox for reproducible testing.  					AI-generated summary Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench .
[27.02.2026 12:40] Response: ```json
{
  "desc": "–†–∞–±–æ—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MobileBench ‚Äî –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö, –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –º–æ–±–∏–ª—å–Ω–æ—Å—Ç–∏. –ë–µ–Ω—á–º–∞—Ä–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Å–µ—Ä–≤–∏—Å–∞ Amap –∏ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –≤ –≥–æ—Ä–æ–¥–∞—Ö –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É. –î–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–µ—Å–æ—á–Ω–∏—Ü—É —Å API-replay, –∫–æ—Ç–æ—Ä–∞—è —É—Å—Ç—Ä–∞–Ω—è–µ—Ç –Ω–µ–¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º –∂–∏–≤—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –ø—Ä–æ—Å—Ç—ã–º –ø–æ–∏—Å–∫–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –∏—Å–ø—ã—Ç—ã–≤–∞—é—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–∞—Ä—à—Ä—É—Ç–æ–≤ —Å —É—á—ë—Ç–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.",
  "emoji": "üó∫Ô∏è",
  "title": "–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ LLM-–∞–≥–µ–Ω—Ç–æ–≤ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö"
}
```
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract MobileBench is a scalable benchmark for evaluating LLM-based route-planning agents in real-world scenarios, featuring anonymized user queries and a deterministic sandbox for reproducible testing.  					AI-generated summary Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench ."

[27.02.2026 12:40] Response: ```python
["BENCHMARK", "AGENTS", "DATASET"]
```
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract MobileBench is a scalable benchmark for evaluating LLM-based route-planning agents in real-world scenarios, featuring anonymized user queries and a deterministic sandbox for reproducible testing.  					AI-generated summary Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox that eliminates environmental variance from live services. We further propose a multi-dimensional evaluation protocol centered on outcome validity, complemented by assessments of instruction understanding, planning, tool use, and efficiency. Using MobilityBench, we evaluate multiple LLM-based route-planning agents across diverse real-world mobility scenarios and provide an in-depth analysis of their behaviors and performance. Our findings reveal that current models perform competently on Basic information retrieval and Route Planning tasks, yet struggle considerably with Preference-Constrained Route Planning, underscoring significant room for improvement in personalized mobility applications. We publicly release the benchmark data, evaluation toolkit, and documentation at https://github.com/AMAP-ML/MobilityBench ."

[27.02.2026 12:40] Response: ```python
['OPEN_SOURCE']
```
[27.02.2026 12:40] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"MobileBench is a new benchmark designed to assess route-planning agents that use large language models (LLMs) in real-world situations. It addresses challenges like varying routing needs and the unpredictability of mapping services by using anonymized user queries and a controlled testing environment. The benchmark includes a comprehensive evaluation framework that measures how well these agents understand instructions, plan routes, and utilize tools efficiently. Results show that while current models excel at basic tasks, they need improvement in handling personalized route planning based on user preferences.","title":"Revolutionizing Route Planning with MobileBench"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MobileBench is a new benchmark designed to assess route-planning agents that use large language models (LLMs) in real-world situations. It addresses challenges like varying routing needs and the unpredictability of mapping services by using anonymized user queries and a controlled testing environment. The benchmark includes a comprehensive evaluation framework that measures how well these agents understand instructions, plan routes, and utilize tools efficiently. Results show that while current models excel at basic tasks, they need improvement in handling personalized route planning based on user preferences.', title='Revolutionizing Route Planning with MobileBench'))
[27.02.2026 12:40] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"MobileBenchÊòØ‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÂü∫ÂáÜÊµãËØïÔºåÁî®‰∫éËØÑ‰º∞Âü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑË∑ØÁ∫øËßÑÂàí‰ª£ÁêÜÂú®Áé∞ÂÆûÂú∫ÊôØ‰∏≠ÁöÑË°®Áé∞„ÄÇËØ•Âü∫ÂáÜÊµãËØï‰ΩøÁî®Êù•Ëá™AmapÁöÑÂ§ßËßÑÊ®°ÂåøÂêçÁî®Êà∑Êü•ËØ¢ÔºåÊ∂µÁõñ‰∫ÜÂÖ®ÁêÉÂ§ö‰∏™ÂüéÂ∏ÇÁöÑÂ§öÊ†∑ÂåñË∑ØÁ∫øËßÑÂàíÈúÄÊ±Ç„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞ÂèØÈáçÂ§çÁöÑËØÑ‰º∞ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Á°ÆÂÆöÊÄßÁöÑAPIÈáçÊîæÊ≤ôÁÆ±ÔºåÊ∂àÈô§‰∫ÜÊù•Ëá™ÂÆûÊó∂ÊúçÂä°ÁöÑÁéØÂ¢ÉÂèòÂåñ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂΩìÂâçÊ®°ÂûãÂú®Âü∫Êú¨‰ø°ÊÅØÊ£ÄÁ¥¢ÂíåË∑ØÁ∫øËßÑÂàí‰ªªÂä°‰∏äË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®‰∏™ÊÄßÂåñË∑ØÁ∫øËßÑÂàíÊñπÈù¢‰ªçÊúâÊòæËëóÊîπËøõÁ©∫Èó¥„ÄÇ","title":"ËØÑ‰º∞LLMË∑ØÁ∫øËßÑÂàí‰ª£ÁêÜÁöÑÂèØÊâ©Â±ïÂü∫ÂáÜÊµãËØï"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MobileBenchÊòØ‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÂü∫ÂáÜÊµãËØïÔºåÁî®‰∫éËØÑ‰º∞Âü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑË∑ØÁ∫øËßÑÂàí‰ª£ÁêÜÂú®Áé∞ÂÆûÂú∫ÊôØ‰∏≠ÁöÑË°®Áé∞„ÄÇËØ•Âü∫ÂáÜÊµãËØï‰ΩøÁî®Êù•Ëá™AmapÁöÑÂ§ßËßÑÊ®°ÂåøÂêçÁî®Êà∑Êü•ËØ¢ÔºåÊ∂µÁõñ‰∫ÜÂÖ®ÁêÉÂ§ö‰∏™ÂüéÂ∏ÇÁöÑÂ§öÊ†∑ÂåñË∑ØÁ∫øËßÑÂàíÈúÄÊ±Ç„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞ÂèØÈáçÂ§çÁöÑËØÑ‰º∞ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Á°ÆÂÆöÊÄßÁöÑAPIÈáçÊîæÊ≤ôÁÆ±ÔºåÊ∂àÈô§‰∫ÜÊù•Ëá™ÂÆûÊó∂ÊúçÂä°ÁöÑÁéØÂ¢ÉÂèòÂåñ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂΩìÂâçÊ®°ÂûãÂú®Âü∫Êú¨‰ø°ÊÅØÊ£ÄÁ¥¢ÂíåË∑ØÁ∫øËßÑÂàí‰ªªÂä°‰∏äË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®‰∏™ÊÄßÂåñË∑ØÁ∫øËßÑÂàíÊñπÈù¢‰ªçÊúâÊòæËëóÊîπËøõÁ©∫Èó¥„ÄÇ', title='ËØÑ‰º∞LLMË∑ØÁ∫øËßÑÂàí‰ª£ÁêÜÁöÑÂèØÊâ©Â±ïÂü∫ÂáÜÊµãËØï'))
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#agents", "#audio", "#video", "#training", "#multimodal", "#rlhf", "#benchmark"], "emoji": "üé¨", "ru": {"title": "–û—Ç –±–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM –∫ –∏—Å—Ç–∏–Ω–Ω—ã–º –æ–º–Ω–∏–º–æ–¥–∞–ª—å–Ω—ã–º –∞–≥–µ–Ω—Ç–∞–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã OmniGAIA ‚Äî —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, —Å–ø–æ—Å–æ–±–Ω—ã—Ö —Ä–µ—à–∞—Ç—å —Å–ª–æ–∂–Ω
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#reasoning", "#multimodal"], "emoji": "üß†", "ru": {"title": "–Ø–≤–Ω–æ–µ –≤–æ–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª—É—á—à–µ —Å–∫—Ä—ã—Ç–æ–≥–æ: –æ—Ç –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –º–µ—Ö–∞–Ω–∏–∑–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM —Å –ø–æ–º–æ—â—å—é –ø—Ä–∏—á–∏–Ω–Ω
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#agents", "#rl", "#training"], "emoji": "üß†", "ru": {"title": "–ü–∞–º—è—Ç—å –∏ –≥–∏–±—Ä–∏–¥–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "EMPO¬≤ ‚Äî —ç—Ç–æ –≥–∏–±—Ä–∏–¥–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#rag", "#math", "#dataset"], "emoji": "üî•", "ru": {"title": "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—à–∏–±–æ–∫ –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", "desc": "AgentDropoutV2 - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –Ω–∞ —ç—Ç–∞–ø–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Ç–æ–∫
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#training", "#synthetic", "#dataset", "#reasoning", "#rl", "#optimization"], "emoji": "‚ö°", "ru": {"title": "–ò—â–∏ –±–æ–ª—å—à–µ, –¥—É–º–∞–π –º–µ–Ω—å—à–µ: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤–º–µ—Å—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ SMTL –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ 
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#training", "#healthcare", "#open_source", "#reasoning", "#rl", "#optimization", "#rlhf"], "emoji": "üè•", "ru": {"title": "–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º–Ω–æ–≥–æ—Å–∏–≥–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "MediX-R1 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#diffusion"], "emoji": "‚ö°", "ru": {"title": "–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –≥–∏–±—Ä–∏–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π –¥–∏—Ñ—Ñ—É–∑–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —É—Å–ª–æ–≤–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è 
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#3d", "#robotics", "#dataset", "#rl"], "emoji": "üì±", "ru": {"title": "–î–≤–µ –∫–∞–º–µ—Ä—ã –≤–º–µ—Å—Ç–æ —Å—Ç—É–¥–∏–∏: –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π –∑–∞—Ö–≤–∞—Ç –¥–≤–∏–∂–µ–Ω–∏—è –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤ –∏ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç EmbodMocap ‚Äî –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∑–∞—Ö–≤–∞—Ç–∞ –¥–≤–∏–∂–µ–Ω–∏—è –Ω–∞ –±–∞–∑–µ –¥–≤—É—Ö iPhone –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —á–µ–ª–æ–≤–µ–∫–∞
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#agi", "#multimodal", "#games"], "emoji": "üéÆ", "ru": {"title": "–û—Ç —É–∑–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤ –∫ –æ–±—â–µ–º—É –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É: –æ—Ü–µ–Ω–∫–∞ AI —á–µ—Ä–µ–∑ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –∏–≥—Ä—ã", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –æ—Ü–µ–Ω–∫–∏ –æ–±—â–µ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ AI-—Å–∏—Å—Ç–µ–º —á–µ—Ä–µ–∑ –∏–≥—Ä—ã, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ª—é–¥—å–º–∏ –¥–ª—è –ª
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#video", "#training", "#multimodal", "#architecture", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–ü—Ä–∏—á–∏–Ω–Ω–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è –¥–ª—è –ø–ª–∞–≤–Ω–æ–π –∏ –±—ã—Å—Ç—Ä–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Causal Motion Diffusion Models –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≤—Ç–æ—Ä–µ
[27.02.2026 12:40] Using data from previous issue: {"categories": [], "emoji": "‚ö°", "ru": {"title": "–ì–∏–±–∫–æ–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ Fully Sharded Data Parallel (FSDP) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º veScale-FSDP, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö 
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#agents", "#training", "#robotics"], "emoji": "üöó", "ru": {"title": "–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –≤–æ–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ –±–µ–∑ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ –Ω–∞–¥–∑–æ—Ä–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç RaWMPC ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –≤–æ–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ–±–æ–±—â–∞–µ–º–æ—Å—Ç–∏ –∏–º–∏—Ç–∞—Ü–∏–æ
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#optimization", "#video", "#architecture", "#rl", "#long_context"], "emoji": "üåç", "ru": {"title": "–ì–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—è –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –º–æ–¥–µ–ª—è—Ö –º–∏—Ä–∞", "desc": "GeoWorld ‚Äî —ç—Ç–æ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç
[27.02.2026 12:40] Querying the API.
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Abstract The DLT-Corpus dataset, containing 2.98 billion tokens from diverse sources, enables analysis of technology emergence patterns and market-innovation correlations in the distributed ledger technology sector.  					AI-generated summary We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.   We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.   We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.
[27.02.2026 12:40] Response: ```json
{
  "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç DLT-Corpus ‚Äî —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –ø—Ä–µ–¥–º–µ—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö —Ä–µ–µ—Å—Ç—Ä–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 2.98 –º–∏–ª–ª–∏–∞—Ä–¥–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –Ω–∞—É—á–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã, –ø–∞—Ç–µ–Ω—Ç–æ–≤ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π. –° –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø–æ—è–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∏–Ω–Ω–æ–≤–∞—Ü–∏—è–º–∏ –∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —Ç—Ä–µ–Ω–¥–∞–º–∏ –≤ —ç—Ç–æ–º —Å–µ–∫—Ç–æ—Ä–µ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é —Ü–µ–ø–æ—á–∫—É —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π: –∏–¥–µ–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –≤ –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞—Ö, –∑–∞—Ç–µ–º –ø–µ—Ä–µ—Ö–æ–¥—è—Ç –≤ –ø–∞—Ç–µ–Ω—Ç—ã –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏, –ø—Ä–∏ —ç—Ç–æ–º –Ω–∞—É—á–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–∑–≤–∏–≤–∞–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ä—ã–Ω–æ—á–Ω—ã—Ö –∫–æ–ª–µ–±–∞–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –≤—ã–ø—É—Å—Ç–∏–ª–∏ LedgerBERT ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ BERT –Ω–∞ 23% –¥–ª—è –∑–∞–¥–∞—á–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ DLT-–¥–æ–º–µ–Ω–µ.",
  "emoji": "‚õìÔ∏è",
  "title": "–û—Ç –Ω–∞—É–∫–∏ –∫ —Ä—ã–Ω–∫—É: –∫–∞–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –±–ª–æ–∫—á–µ–π–Ω–∞ –ø—Ä–æ—Ö–æ–¥—è—Ç –ø—É—Ç—å –∏–Ω–Ω–æ–≤–∞—Ü–∏–π"
}
```
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract The DLT-Corpus dataset, containing 2.98 billion tokens from diverse sources, enables analysis of technology emergence patterns and market-innovation correlations in the distributed ledger technology sector.  					AI-generated summary We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.   We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.   We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code."

[27.02.2026 12:40] Response: ```python
["DATASET", "DATA", "MULTILINGUAL"]
```
[27.02.2026 12:40] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Abstract The DLT-Corpus dataset, containing 2.98 billion tokens from diverse sources, enables analysis of technology emergence patterns and market-innovation correlations in the distributed ledger technology sector.  					AI-generated summary We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.   We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.   We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code."

[27.02.2026 12:40] Response: ```python
['OPEN_SOURCE', 'SCIENCE']
```
[27.02.2026 12:40] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"The DLT-Corpus dataset is a comprehensive collection of 2.98 billion tokens from various sources, aimed at enhancing research in Distributed Ledger Technology (DLT). It includes scientific literature, patents, and social media posts, providing a rich resource for analyzing technology emergence and market-innovation relationships. The study reveals that scientific research often precedes patent filings and social media discussions, indicating a traditional pattern of technology transfer. Additionally, the findings suggest that while social media sentiment can be overly optimistic, scientific and patent activities are more stable and contribute to sustained economic growth in the DLT sector.","title":"Unlocking Insights from the DLT-Corpus: Mapping Innovation in Distributed Ledger Technology"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The DLT-Corpus dataset is a comprehensive collection of 2.98 billion tokens from various sources, aimed at enhancing research in Distributed Ledger Technology (DLT). It includes scientific literature, patents, and social media posts, providing a rich resource for analyzing technology emergence and market-innovation relationships. The study reveals that scientific research often precedes patent filings and social media discussions, indicating a traditional pattern of technology transfer. Additionally, the findings suggest that while social media sentiment can be overly optimistic, scientific and patent activities are more stable and contribute to sustained economic growth in the DLT sector.', title='Unlocking Insights from the DLT-Corpus: Mapping Innovation in Distributed Ledger Technology'))
[27.02.2026 12:40] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"DLT-CorpusÊï∞ÊçÆÈõÜÂåÖÂê´29.8‰∫ø‰∏™Ê†áËÆ∞ÔºåÊù•Ëá™Â§öÁßçÊù•Ê∫êÔºåÊîØÊåÅÂØπÂàÜÂ∏ÉÂºèË¥¶Êú¨ÊäÄÊúØÈ¢ÜÂüüÁöÑÊäÄÊúØÂá∫Áé∞Ê®°ÂºèÂíåÂ∏ÇÂú∫ÂàõÊñ∞Áõ∏ÂÖ≥ÊÄßÁöÑÂàÜÊûê„ÄÇËØ•Êï∞ÊçÆÈõÜÊòØËøÑ‰ªä‰∏∫Ê≠¢ÊúÄÂ§ßÁöÑÁâπÂÆöÈ¢ÜÂüüÊñáÊú¨ÈõÜÂêàÔºåÊ∂µÁõñÁßëÂ≠¶ÊñáÁåÆ„ÄÅ‰∏ìÂà©ÂíåÁ§æ‰∫§Â™í‰ΩìÂÜÖÂÆπ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÊäÄÊúØÈÄöÂ∏∏ÂÖàÂú®ÁßëÂ≠¶ÊñáÁåÆ‰∏≠Âá∫Áé∞ÔºåÁÑ∂ÂêéÊâçËøõÂÖ•‰∏ìÂà©ÂíåÁ§æ‰∫§Â™í‰ΩìÔºåÈÅµÂæ™‰º†ÁªüÁöÑÊäÄÊúØËΩ¨ÁßªÊ®°Âºè„ÄÇÊàë‰ª¨ËøòÂèëÂ∏É‰∫ÜLedgerBERTÊ®°ÂûãÔºåÈíàÂØπÁâπÂÆöÈ¢ÜÂüüÁöÑÂëΩÂêçÂÆû‰ΩìËØÜÂà´‰ªªÂä°ÔºåÊÄßËÉΩÊØîBERT-baseÊèêÈ´ò‰∫Ü23%„ÄÇ","title":"DLT-CorpusÔºöÂàÜÂ∏ÉÂºèË¥¶Êú¨ÊäÄÊúØÁ†îÁ©∂ÁöÑÊñ∞ËßÜÈáé"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DLT-CorpusÊï∞ÊçÆÈõÜÂåÖÂê´29.8‰∫ø‰∏™Ê†áËÆ∞ÔºåÊù•Ëá™Â§öÁßçÊù•Ê∫êÔºåÊîØÊåÅÂØπÂàÜÂ∏ÉÂºèË¥¶Êú¨ÊäÄÊúØÈ¢ÜÂüüÁöÑÊäÄÊúØÂá∫Áé∞Ê®°ÂºèÂíåÂ∏ÇÂú∫ÂàõÊñ∞Áõ∏ÂÖ≥ÊÄßÁöÑÂàÜÊûê„ÄÇËØ•Êï∞ÊçÆÈõÜÊòØËøÑ‰ªä‰∏∫Ê≠¢ÊúÄÂ§ßÁöÑÁâπÂÆöÈ¢ÜÂüüÊñáÊú¨ÈõÜÂêàÔºåÊ∂µÁõñÁßëÂ≠¶ÊñáÁåÆ„ÄÅ‰∏ìÂà©ÂíåÁ§æ‰∫§Â™í‰ΩìÂÜÖÂÆπ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÊäÄÊúØÈÄöÂ∏∏ÂÖàÂú®ÁßëÂ≠¶ÊñáÁåÆ‰∏≠Âá∫Áé∞ÔºåÁÑ∂ÂêéÊâçËøõÂÖ•‰∏ìÂà©ÂíåÁ§æ‰∫§Â™í‰ΩìÔºåÈÅµÂæ™‰º†ÁªüÁöÑÊäÄÊúØËΩ¨ÁßªÊ®°Âºè„ÄÇÊàë‰ª¨ËøòÂèëÂ∏É‰∫ÜLedgerBERTÊ®°ÂûãÔºåÈíàÂØπÁâπÂÆöÈ¢ÜÂüüÁöÑÂëΩÂêçÂÆû‰ΩìËØÜÂà´‰ªªÂä°ÔºåÊÄßËÉΩÊØîBERT-baseÊèêÈ´ò‰∫Ü23%„ÄÇ', title='DLT-CorpusÔºöÂàÜÂ∏ÉÂºèË¥¶Êú¨ÊäÄÊúØÁ†îÁ©∂ÁöÑÊñ∞ËßÜÈáé'))
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#audio", "#video", "#multimodal", "#architecture", "#diffusion"], "emoji": "ü§ù", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∂–µ—Å—Ç–æ–≤ —á–µ–ª–æ–≤–µ–∫–∞ —Å —É—á—ë—Ç–æ–º —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö", "desc": "DyaDiT ‚Äî —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#benchmark", "#architecture", "#training"], "emoji": "üß†", "ru": {"title": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –±–µ–∑ –∑–∞–±—ã–≤–∞–Ω–∏—è", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ TRC¬≤ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω
[27.02.2026 12:40] Using data from previous issue: {"categories": ["#audio", "#video", "#long_context", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö", "desc": "MMHNet ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –∏ –Ω–µ–∫–∞—É–∑–∞–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ
[27.02.2026 12:40] Renaming data file.
[27.02.2026 12:40] Renaming previous data. hf_papers.json to ./d/2026-02-27.json
[27.02.2026 12:40] Saving new data file.
[27.02.2026 12:40] Generating page.
[27.02.2026 12:40] Renaming previous page.
[27.02.2026 12:40] Renaming previous data. index.html to ./d/2026-02-27.html
[27.02.2026 12:40] Writing result.
[27.02.2026 12:40] Renaming log file.
[27.02.2026 12:40] Renaming previous data. log.txt to ./logs/2026-02-27_last_log.txt
