[20.01.2026 13:49] Read previous papers.
[20.01.2026 13:49] Generating top page (month).
[20.01.2026 13:49] Writing top page (month).
[20.01.2026 14:33] Read previous papers.
[20.01.2026 14:33] Get feed.
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11077
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.08808
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11096
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10880
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11061
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10387
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10108
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.08441
[20.01.2026 14:33] Get page data from previous paper. URL: https://huggingface.co/papers/2601.09512
[20.01.2026 14:33] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[20.01.2026 14:33] No deleted papers detected.
[20.01.2026 14:33] Downloading and parsing papers (pdf, html). Total: 9.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.11077.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.11077.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.11077.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.08808.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.08808.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.08808.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.11096.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.11096.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.11096.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.10880.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.10880.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.10880.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.11061.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.11061.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.11061.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.10387.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.10387.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.10387.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.10108.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.10108.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.10108.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.08441.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.08441.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.08441.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Downloading and parsing paper https://huggingface.co/papers/2601.09512.
[20.01.2026 14:33] Extra JSON file exists (./assets/json/2601.09512.json), skip PDF parsing.
[20.01.2026 14:33] Paper image links file exists (./assets/img_data/2601.09512.json), skip HTML parsing.
[20.01.2026 14:33] Success.
[20.01.2026 14:33] Enriching papers with extra data.
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 0. ABC-Bench evaluates LLM agents on realistic backend coding tasks requiring full development lifecycle management from repository exploration to containerized service deployment and API testing.  					AI-generated summary 				 The evolution of Large Language Models (LLMs) into autonomous agents has e...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 1. Multiplex Thinking introduces a stochastic soft reasoning mechanism that samples multiple candidate tokens at each step to optimize reasoning trajectories with reinforcement learning while maintaining shorter sequences than traditional chain-of-thought methods.  					AI-generated summary 				 Large ...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 2. CoDance introduces an Unbind-Rebind framework for animating multiple subjects with flexible spatial configurations, using pose shift encoding and semantic/textual guidance for motion reassignment.  					AI-generated summary 				 Character image animation is gaining significant importance across vari...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 3. Medical SAM3 adapts the SAM3 foundation model through comprehensive fine-tuning on diverse medical imaging datasets to achieve robust prompt-driven segmentation across various modalities and anatomical structures.  					AI-generated summary 				 Promptable segmentation foundation models such as SAM3...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 4. Spurious rewards in reinforcement learning with verifiable rewards trigger a memorization shortcut in LLMs, identified through neural circuit analysis and causal steering techniques.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) is highly effective for enhanci...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 5. Research reveals that large language models operate within a persona space where an "Assistant Axis" controls helpfulness and behavioral stability, with steering techniques able to influence model responses and prevent harmful behavior drift.  					AI-generated summary 				 Large language models can...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 6. Researchers introduce the Fish-in-the-Ocean paradigm and SIN-Bench dataset to evaluate multimodal language models' ability to reason over scientific documents with evidence chains, revealing a gap between answer accuracy and traceable support.  					AI-generated summary 				 Evaluating whether multi...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 7. YaPO learns sparse steering vectors through sparse autoencoder latent space optimization, enabling more effective and stable control of large language model behaviors compared to dense methods.  					AI-generated summary 				 Steering Large Language Models (LLMs) through activation interventions has...
[20.01.2026 14:33] ********************************************************************************
[20.01.2026 14:33] Abstract 8. CLARE is a parameter-efficient, exemplar-free continual learning framework for vision-language-action models that enables robots to adapt to new tasks while preserving previously learned knowledge through lightweight adapters and dynamic routing mechanisms.  					AI-generated summary 				 To teach r...
[20.01.2026 14:33] Read previous papers.
[20.01.2026 14:33] Generating reviews via LLM API.
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#plp", "#benchmark", "#agents", "#open_source"], "emoji": "üê≥", "ru": {"title": "–û—Ç –∫–æ–¥–∞ –∫ –±–æ–µ–≤–æ–º—É —Å–µ—Ä–≤–∏—Å—É: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –ø–æ–ª–Ω–æ–º —Ü–∏–∫–ª–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏", "desc": "ABC-Bench ‚Äî —ç—Ç–æ –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ LLM-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –±—ç–∫–µ–Ω–¥–∞, —Ç—Ä–µ–±—É—é—â–∏—Ö –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Ä
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#open_source", "#math", "#rl", "#reasoning", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "–ú—è–≥–∫–æ–µ –º—É–ª—å—Ç–∏–ø–ª–µ–Ω–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ: –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ö–∞–Ω–∏–∑–º –º—É–ª—å—Ç–∏–ø–ª–µ–Ω–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –Ω
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#architecture", "#video", "#dataset", "#open_source"], "emoji": "üíÉ", "ru": {"title": "–ì–∏–±–∫–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–æ—Å–≤—è–∑—ã–≤–∞–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏–π", "desc": "CoDance –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Unbind-Rebind –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–º–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#training", "#multimodal", "#healthcare", "#cv"], "emoji": "üè•", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —É–ø—Ä–∞–≤–ª—è–µ–º–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø–æ–¥—Å–∫–∞–∑–∫–∞–º", "desc": "Medical SAM3 ‚Äî —ç—Ç–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ SAM3, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –Ω–∞ –±–æ–ª—å—à–∏—Ö –º–µ
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#training", "#architecture", "#rlhf", "#interpretability", "#security", "#rl", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ö–∞–∫ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã –∑–∞—Å—Ç–∞–≤–ª—è—é—Ç —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –≤–º–µ—Å—Ç–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –ø–∞—Ä–∞–¥–æ–∫—Å–∞–ª—å–Ω–æ–µ —è–≤–ª–µ–Ω–∏–µ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#security", "#interpretability", "#architecture", "#training", "#alignment"], "emoji": "üß≠", "ru": {"title": "–ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É –ø–µ—Ä—Å–æ–Ω: —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è LLM —á–µ—Ä–µ–∑ –æ—Å—å –ø–æ–º–æ—â–Ω–∏–∫–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É—é—Ç –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ 
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#interpretability", "#science", "#dataset", "#reasoning", "#multimodal", "#long_context", "#benchmark"], "emoji": "üêü", "ru": {"title": "–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–æ–≤ –≤ –º–æ—Ä–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: –æ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –∫ –¥–æ–∫–∞–∑—É–µ–º–æ—Å—Ç–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –ø–∞—Ä–∞–¥–∏–≥–º—É Fish-in-the-Ocean –∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö SI
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#interpretability", "#training", "#rlhf", "#hallucinations", "#open_source", "#alignment"], "emoji": "üéØ", "ru": {"title": "–†–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è LLM", "desc": "YaPO ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[20.01.2026 14:33] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#training", "#cv", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–†–æ–±–æ—Ç—ã —É—á–∞—Ç—Å—è –Ω–æ–≤–æ–º—É, –Ω–µ –∑–∞–±—ã–≤–∞—è —Å—Ç–∞—Ä–æ–≥–æ", "desc": "CLARE ‚Äî —ç—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è continual learning, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Å–∏—Å—Ç–µ–º–∞–º –Ω–∞ –±–∞–∑–µ vision-lan
[20.01.2026 14:33] Renaming data file.
[20.01.2026 14:33] Renaming previous data. hf_papers.json to ./d/2026-01-20.json
[20.01.2026 14:33] Saving new data file.
[20.01.2026 14:33] Generating page.
[20.01.2026 14:33] Renaming previous page.
[20.01.2026 14:33] Renaming previous data. index.html to ./d/2026-01-20.html
[20.01.2026 14:33] Writing result.
[20.01.2026 14:33] Renaming log file.
[20.01.2026 14:33] Renaming previous data. log.txt to ./logs/2026-01-20_last_log.txt
