[11.02.2025 02:11] Read previous papers.
[11.02.2025 02:11] Generating top page (month).
[11.02.2025 02:11] Writing top page (month).
[11.02.2025 03:15] Read previous papers.
[11.02.2025 03:15] Get feed.
[11.02.2025 03:15] Extract page data from URL. URL: https://huggingface.co/papers/2502.03628
[11.02.2025 03:15] Extract page data from URL. URL: https://huggingface.co/papers/2502.06155
[11.02.2025 03:15] Extract page data from URL. URL: https://huggingface.co/papers/2502.06049
[11.02.2025 03:15] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.02.2025 03:15] Downloading and parsing papers (pdf, html). Total: 3.
[11.02.2025 03:15] Downloading and parsing paper https://huggingface.co/papers/2502.03628.
[11.02.2025 03:15] Downloading paper 2502.03628 from http://arxiv.org/pdf/2502.03628v1...
[11.02.2025 03:15] Extracting affiliations from text.
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 ] . [ 1 8 2 6 3 0 . 2 0 5 2 : r The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering Zhuowei Li 1 Haizhou Shi 1 Yunhe Gao 2 Di Liu 1 Zhenting Wang 1 Yuxiao Chen 1 Ting Liu 3 Long Zhao 3 Hao Wang 1 Dimitris N. Metaxas "
[11.02.2025 03:15] Response: ```python
[]
```
[11.02.2025 03:15] Extracting affiliations from text.
[11.02.2025 03:15] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 5 ] . [ 1 8 2 6 3 0 . 2 0 5 2 : r The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering Zhuowei Li 1 Haizhou Shi 1 Yunhe Gao 2 Di Liu 1 Zhenting Wang 1 Yuxiao Chen 1 Ting Liu 3 Long Zhao 3 Hao Wang 1 Dimitris N. Metaxas1. Introduction Large Vision-Language Models (LVLMs) can reason effectively over both textual and visual inputs, but they tend to hallucinate syntactically coherent yet visually ungrounded contents. In this paper, we investigate the internal dynamics of hallucination by examining the tokens logits ranking throughout the generation process, revealing three key patterns in how LVLMs pro- (1) gradual visual informacess information: tion loss visually grounded tokens gradually become less favored throughout generation, and (2) early excitation semantically meaningful tokens achieve peak activation in the layers earlier than the final layer. (3) hidden genuine information visually grounded tokens though not being eventually decoded still retain relatively high rankings at inference. Based on these insights, we propose VISTA (Visual Information Steering with Token-logit Augmentation), training-free inference-time intervention framework that reduces hallucination while promoting genuine information. VISTA works by combining two complementary approaches: reinforcing visual information in activation space and leveraging early layer activations to promote semantically meaningful decoding. Compared to existing methods, VISTA requires no external supervision and is applicable to various decoding strategies. Extensive experiments show that VISTA on average reduces hallucination by about 40% on evaluated open-ended generation task, and it consistently outperforms existing methods on four benchmarks across four architectures under three decoding strategies. Code is available at: https: //github.com/LzVv123456/VISTA 1Rutgers University 2Stanford University 3Google DeepMind. Correspondence to: Zhuowei Li <zhuowei.li@rutgers.edu>, Haizhou Shi <haizhou.shi@rutgers.edu>. Pre-print, work in progress 1 Large Vision-Language Models (LVLMs) (Dai et al., 2023; Bai et al., 2023; Chen et al., 2023; Zhu et al., 2023; Liu et al., 2024c) have revolutionized multimodal AI by enabling seamless integration of visual and textual information, powering applications from interactive assistance to autonomous systems (Lin et al., 2023; Yang et al., 2024; Lai et al., 2024). However, LVLMs frequently hallucinate semantically coherent yet visually ungrounded contents, hindering their reliability in real-world applications. Though LVLM hallucination is considered multifaceted (Liu et al., 2024d), critical cause stems from the overwhelming influence of language priors over visual contexts, and has been studied from the perspective of attention patterns (Huang et al., 2024; Liu et al., 2024f) and distribution divergence within logits space (Leng et al., 2024; Favero et al., 2024). Despite these insights, it remains unclear how hallucination emerges and propagates during the generation process. Inspecting Token Dynamics in LVLMs. In this work, we take novel perspective by examining LVLMs generation dynamics through the lens of token logits ranking. Given an image its corresponding description (produced by an LVLM), we identify three categories of tokens (elaborated in Sec. 3.4): Hidden Genuine Tokens tokens that are missing in generated contents yet clearly visible from visual input; Decoded Genuine Tokens tokens that appear in continuation with visual groundings; Hallucinated Tokens tokens extracted from the hallucinated contents within generation. We then track each token types corresponding logits rankings throughout the generation across temporal (Fig. 1 left) and layer sequences (Fig. 1 right). Our analysis makes three prominent observations: (OBS-1) Gradual Visual Information Loss. As generation progresses, genuine token rankings gradually decline while hallucinated tokens are surfaced (see Fig. 1 left and Fig. 2). This aligns with recent findings (Yue VISTA: Visual Information Steering with Token-logit Augmentation Figure 1. Analysis of token logits ranking patterns across 500 randomly selected images from MSCOCO dataset. Higher ranking indicates higher generation probability. Left: Average token ranking from the last five layers, showing temporal progression across early, mid, and late generation stages. Right: Layer-wise evolution of token rankings averaged across all time steps, demonstrating early-excitation phenomenon. et al., 2024; Favero et al., 2024), exhibiting increasing hallucination in late generation phase. We hypothesize that this occurs as accumulated language priors in residual streams progressively dilute visual information, leading to syntactically coherent but visually ungrounded generation. (OBS-2) Early Excitation of Semantically Meaningful Tokens. Semantically meaningful tokens 1 exhibit peak excitation in penultimate layer (Fig. 1 right) or within window of layers preceding the final layer  (Fig. 2)  . In contrast, the final layer prioritizes functional tokens like this, a, and other stopwords, suggesting that the models decision process may overemphasize syntactic elements in its final stage. (OBS-3) Hidden Genuine Information. LVLMs may perceive more visual clues than they express. We observe that hidden genuine tokens, though not eventually decoded, consistently maintain relatively high rankings (around 5K in 32K vocabulary) during the course of generation (see Fig. 1). Reducing Hallucination of LVLMs. Inspired by above findings, we propose VISTA (Visual Information Steering with Token-logit Augmentation), simple and novel training-free framework that can be applied on top of various decoding methods to reduce hallucination while promoting genuine information. VISTA introduces two complementary modules: Visual Steering Vector (VSV) that counteracts gradual visual information loss by extracting and reinforcing visual cues in activation space, and SelfLogits Augmentation (SLA) which utilizes early excitation patterns to prioritize semantically meaningful tokens. VSV and SLA work synergistically and can effectively mitigate hallucination in LVLMs. Technical Contributions. This study presents the first systematic investigation of token dynamics in LVLMs through the lens of token logits ranking, revealing novel insights into how visual information is processed and potentially 1We refer to categorized tokens as sem"
[11.02.2025 03:15] Mistral response. {"id": "f360a1c9c0d24e3fb1ca26c65a1f6e2e", "object": "chat.completion", "created": 1739243712, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n['Rutgers University', 'Stanford University', 'Google DeepMind']\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1656, "total_tokens": 1680, "completion_tokens": 24}}
[11.02.2025 03:15] Response: ```python
['Rutgers University', 'Stanford University', 'Google DeepMind']
```
[11.02.2025 03:15] Deleting PDF ./assets/pdf/2502.03628.pdf.
[11.02.2025 03:15] Success.
[11.02.2025 03:15] Downloading and parsing paper https://huggingface.co/papers/2502.06155.
[11.02.2025 03:15] Downloading paper 2502.06155 from http://arxiv.org/pdf/2502.06155v1...
[11.02.2025 03:15] Extracting affiliations from text.
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"EFFICIENT-VDIT: Efficient Video Diffusion Transformers with Attention Tile Hangliang Ding * 1 Dacheng Li * 2 Runlong Su 3 Peiyuan Zhang 3 Zhijie Deng 4 Ion Stoica 2 Hao Zhang 3 5 2 0 2 0 1 ] . [ 1 5 5 1 6 0 . 2 0 5 2 : r Abstract Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for generating single video of 29 frames. This paper addresses the inefficiency issue from two aspects: 1) Prune the 3D full attention based on the redundancy within video data; We identify prevalent tile-style repetitive pattern in the 3D attention maps for video data, and advocate new family of sparse 3D attention that holds linear complexity w.r.t. the number of video frames. 2) Shorten the sampling process by adopting existing multi-step consistency distillation; We split the entire sampling trajectory into several segments and perform consistency distillation within each one to activate fewstep generation capacities. We further devise three-stage training pipeline to conjoin the lowcomplexity attention and few-step generation capacities. Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into an efficient one that is 7.4 7.8 faster for 29 and 93 frames 720p video generation with marginal performance trade-off in VBench. In addition, we demonstrate that our approach is amenable to distributed inference, achieving an additional 3.91 speedup when running on 4 GPUs with sequence parallelism. 1. Introduction Diffusion Transformers (DiTs) based video generators can synthesize long-horizon, high-resolution, and high-fidelity videos (Peebles & Xie, 2023; OpenAI, 2024; Kuaishou, *Equal contribution 1Tsinghua University 2University of California, Berkeley 3University of California, San Diego 4Shanghai Jiao Tong University. Corresponde"
[11.02.2025 03:15] Response: ```python
[
    "Tsinghua University",
    "University of California, Berkeley",
    "University of California, San Diego",
    "Shanghai Jiao Tong University"
]
```
[11.02.2025 03:15] Deleting PDF ./assets/pdf/2502.06155.pdf.
[11.02.2025 03:15] Success.
[11.02.2025 03:15] Downloading and parsing paper https://huggingface.co/papers/2502.06049.
[11.02.2025 03:15] Downloading paper 2502.06049 from http://arxiv.org/pdf/2502.06049v1...
[11.02.2025 03:15] Extracting affiliations from text.
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 ] . [ 1 9 4 0 6 0 . 2 0 5 2 : r LM2: Large Memory Models Jikun Kang1, Wenqi Wu1, Filippos Christianos1, Alex J. Chan1, Fraser Greenlee1, George Thomas1, Marvin Purtorab1, and Andy Toulis.1 1Convergence Labs Ltd. This paper introduces the Large Memory Model (LM2), decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates memory module that acts as contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves 5.0% improvement over pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures. Correspondence: Jikun Kang at jikun@convergence.ai Website: https://convergence.ai Code: https://github.com/convergence-ai/lm Transformer-based models have achieved remarkable success. Landmark architectures such as GPT-3 Brown et al. (2020), BERT Kenton and Toutanova (2019), and Vision Transformers Dosovitskiy (2020) have established state-of-the-art performance across wide array of applications, including machine translatio"
[11.02.2025 03:15] Response: ```python
["Convergence Labs Ltd."]
```
[11.02.2025 03:15] Deleting PDF ./assets/pdf/2502.06049.pdf.
[11.02.2025 03:15] Success.
[11.02.2025 03:15] Enriching papers with extra data.
[11.02.2025 03:15] ********************************************************************************
[11.02.2025 03:15] Abstract 0. Large Vision-Language Models (LVLMs) can reason effectively over both textual and visual inputs, but they tend to hallucinate syntactically coherent yet visually ungrounded contents. In this paper, we investigate the internal dynamics of hallucination by examining the tokens logits rankings througho...
[11.02.2025 03:15] ********************************************************************************
[11.02.2025 03:15] Abstract 1. Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for ge...
[11.02.2025 03:15] ********************************************************************************
[11.02.2025 03:15] Abstract 2. This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long con...
[11.02.2025 03:15] Read previous papers.
[11.02.2025 03:15] Generating reviews via LLM API.
[11.02.2025 03:15] Querying the API.
[11.02.2025 03:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Vision-Language Models (LVLMs) can reason effectively over both textual and visual inputs, but they tend to hallucinate syntactically coherent yet visually ungrounded contents. In this paper, we investigate the internal dynamics of hallucination by examining the tokens logits rankings throughout the generation process, revealing three key patterns in how LVLMs process information: (1) gradual visual information loss -- visually grounded tokens gradually become less favored throughout generation, and (2) early excitation -- semantically meaningful tokens achieve peak activation in the layers earlier than the final layer. (3) hidden genuine information -- visually grounded tokens though not being eventually decided still retain relatively high rankings at inference. Based on these insights, we propose VISTA (Visual Information Steering with Token-logit Augmentation), a training-free inference-time intervention framework that reduces hallucination while promoting genuine information. VISTA works by combining two complementary approaches: reinforcing visual information in activation space and leveraging early layer activations to promote semantically meaningful decoding. Compared to existing methods, VISTA requires no external supervision and is applicable to various decoding strategies. Extensive experiments show that VISTA on average reduces hallucination by abount 40% on evaluated open-ended generation task, and it consistently outperforms existing methods on four benchmarks across four architectures under three decoding strategies.
[11.02.2025 03:15] Response: {
  "desc": "Эта статья исследует проблему галлюцинаций в крупных визуально-языковых моделях (LVLM) при обработке текстовых и визуальных входных данных. Авторы анализируют внутренние механизмы возникновения галлюцинаций, изучая ранжирование логитов токенов в процессе генерации. На основе выявленных закономерностей предлагается метод VISTA для уменьшения галлюцинаций и усиления достоверной информации во время вывода. Эксперименты показывают, что VISTA в среднем снижает уровень галлюцинаций на 40% в задачах открытой генерации и превосходит существующие методы на четырех бенчмарках.",
  "emoji": "🔍",
  "title": "Борьба с галлюцинациями в визуально-языковых моделях: метод VISTA"
}
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Vision-Language Models (LVLMs) can reason effectively over both textual and visual inputs, but they tend to hallucinate syntactically coherent yet visually ungrounded contents. In this paper, we investigate the internal dynamics of hallucination by examining the tokens logits rankings throughout the generation process, revealing three key patterns in how LVLMs process information: (1) gradual visual information loss -- visually grounded tokens gradually become less favored throughout generation, and (2) early excitation -- semantically meaningful tokens achieve peak activation in the layers earlier than the final layer. (3) hidden genuine information -- visually grounded tokens though not being eventually decided still retain relatively high rankings at inference. Based on these insights, we propose VISTA (Visual Information Steering with Token-logit Augmentation), a training-free inference-time intervention framework that reduces hallucination while promoting genuine information. VISTA works by combining two complementary approaches: reinforcing visual information in activation space and leveraging early layer activations to promote semantically meaningful decoding. Compared to existing methods, VISTA requires no external supervision and is applicable to various decoding strategies. Extensive experiments show that VISTA on average reduces hallucination by abount 40% on evaluated open-ended generation task, and it consistently outperforms existing methods on four benchmarks across four architectures under three decoding strategies."

[11.02.2025 03:15] Response: ```python
['CV', 'MULTIMODAL', 'INFERENCE', 'TRAINING', 'BENCHMARK']
```
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Vision-Language Models (LVLMs) can reason effectively over both textual and visual inputs, but they tend to hallucinate syntactically coherent yet visually ungrounded contents. In this paper, we investigate the internal dynamics of hallucination by examining the tokens logits rankings throughout the generation process, revealing three key patterns in how LVLMs process information: (1) gradual visual information loss -- visually grounded tokens gradually become less favored throughout generation, and (2) early excitation -- semantically meaningful tokens achieve peak activation in the layers earlier than the final layer. (3) hidden genuine information -- visually grounded tokens though not being eventually decided still retain relatively high rankings at inference. Based on these insights, we propose VISTA (Visual Information Steering with Token-logit Augmentation), a training-free inference-time intervention framework that reduces hallucination while promoting genuine information. VISTA works by combining two complementary approaches: reinforcing visual information in activation space and leveraging early layer activations to promote semantically meaningful decoding. Compared to existing methods, VISTA requires no external supervision and is applicable to various decoding strategies. Extensive experiments show that VISTA on average reduces hallucination by abount 40% on evaluated open-ended generation task, and it consistently outperforms existing methods on four benchmarks across four architectures under three decoding strategies."

[11.02.2025 03:15] Response: ```python
["HALLUCINATIONS", "INTERPRETABILITY"]
```
[11.02.2025 03:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the issue of hallucination in Large Vision-Language Models (LVLMs), where the models generate plausible text that does not correspond to visual inputs. The authors identify three patterns in the generation process: a gradual loss of visual information, early activation of semantically meaningful tokens, and the presence of high-ranking visually grounded tokens that are not ultimately chosen. To address these issues, they introduce VISTA, a framework that enhances visual information during inference without requiring additional training. VISTA effectively reduces hallucination by about 40% and outperforms existing methods across multiple benchmarks and architectures.","title":"VISTA: Reducing Hallucination in Vision-Language Models"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper explores the issue of hallucination in Large Vision-Language Models (LVLMs), where the models generate plausible text that does not correspond to visual inputs. The authors identify three patterns in the generation process: a gradual loss of visual information, early activation of semantically meaningful tokens, and the presence of high-ranking visually grounded tokens that are not ultimately chosen. To address these issues, they introduce VISTA, a framework that enhances visual information during inference without requiring additional training. VISTA effectively reduces hallucination by about 40% and outperforms existing methods across multiple benchmarks and architectures.', title='VISTA: Reducing Hallucination in Vision-Language Models'))
[11.02.2025 03:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型视觉语言模型（LVLMs）能够有效地处理文本和视觉输入，但它们往往会产生语法上连贯但视觉上不真实的内容。本文研究了幻觉的内部动态，发现LVLMs在生成过程中处理信息的三种关键模式：逐渐丧失视觉信息、早期激活和隐藏的真实信息。基于这些发现，我们提出了VISTA（视觉信息引导与标记逻辑增强），这是一种无需训练的推理时干预框架，旨在减少幻觉并促进真实信息的生成。实验表明，VISTA在开放式生成任务中平均减少了约40%的幻觉，并在四个基准测试中在三种解码策略下始终优于现有方法。","title":"减少幻觉，提升真实信息的VISTA框架"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='大型视觉语言模型（LVLMs）能够有效地处理文本和视觉输入，但它们往往会产生语法上连贯但视觉上不真实的内容。本文研究了幻觉的内部动态，发现LVLMs在生成过程中处理信息的三种关键模式：逐渐丧失视觉信息、早期激活和隐藏的真实信息。基于这些发现，我们提出了VISTA（视觉信息引导与标记逻辑增强），这是一种无需训练的推理时干预框架，旨在减少幻觉并促进真实信息的生成。实验表明，VISTA在开放式生成任务中平均减少了约40%的幻觉，并在四个基准测试中在三种解码策略下始终优于现有方法。', title='减少幻觉，提升真实信息的VISTA框架'))
[11.02.2025 03:15] Querying the API.
[11.02.2025 03:15] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for generating a single video of 29 frames. This paper addresses the inefficiency issue from two aspects: 1) Prune the 3D full attention based on the redundancy within video data; We identify a prevalent tile-style repetitive pattern in the 3D attention maps for video data, and advocate a new family of sparse 3D attention that holds a linear complexity w.r.t. the number of video frames. 2) Shorten the sampling process by adopting existing multi-step consistency distillation; We split the entire sampling trajectory into several segments and perform consistency distillation within each one to activate few-step generation capacities. We further devise a three-stage training pipeline to conjoin the low-complexity attention and few-step generation capacities. Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video generation with a marginal performance trade-off in VBench. In addition, we demonstrate that our approach is amenable to distributed inference, achieving an additional 3.91x speedup when running on 4 GPUs with sequence parallelism.
[11.02.2025 03:15] Response: {
  "desc": "Статья представляет новый подход к ускорению генерации видео с помощью Диффузионных Трансформеров (DiTs). Авторы предлагают прореживание 3D-внимания на основе избыточности видеоданных и сокращение процесса сэмплирования с помощью многошаговой дистилляции согласованности. Разработан трехэтапный процесс обучения для объединения внимания с низкой сложностью и возможностей генерации за несколько шагов. Результаты показывают ускорение в 7.4-7.8 раз для генерации видео 720p с 29 и 93 кадрами при использовании всего 0.1% данных предобучения.",
  "emoji": "🎬",
  "title": "Ускорение генерации видео: эффективность без потери качества"
}
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for generating a single video of 29 frames. This paper addresses the inefficiency issue from two aspects: 1) Prune the 3D full attention based on the redundancy within video data; We identify a prevalent tile-style repetitive pattern in the 3D attention maps for video data, and advocate a new family of sparse 3D attention that holds a linear complexity w.r.t. the number of video frames. 2) Shorten the sampling process by adopting existing multi-step consistency distillation; We split the entire sampling trajectory into several segments and perform consistency distillation within each one to activate few-step generation capacities. We further devise a three-stage training pipeline to conjoin the low-complexity attention and few-step generation capacities. Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video generation with a marginal performance trade-off in VBench. In addition, we demonstrate that our approach is amenable to distributed inference, achieving an additional 3.91x speedup when running on 4 GPUs with sequence parallelism."

[11.02.2025 03:15] Response: ```python
["INFERENCE", "VIDEO", "TRAINING"]
```
[11.02.2025 03:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Despite the promise of synthesizing high-fidelity videos, Diffusion Transformers (DiTs) with 3D full attention suffer from expensive inference due to the complexity of attention computation and numerous sampling steps. For example, the popular Open-Sora-Plan model consumes more than 9 minutes for generating a single video of 29 frames. This paper addresses the inefficiency issue from two aspects: 1) Prune the 3D full attention based on the redundancy within video data; We identify a prevalent tile-style repetitive pattern in the 3D attention maps for video data, and advocate a new family of sparse 3D attention that holds a linear complexity w.r.t. the number of video frames. 2) Shorten the sampling process by adopting existing multi-step consistency distillation; We split the entire sampling trajectory into several segments and perform consistency distillation within each one to activate few-step generation capacities. We further devise a three-stage training pipeline to conjoin the low-complexity attention and few-step generation capacities. Notably, with 0.1% pretraining data, we turn the Open-Sora-Plan-1.2 model into an efficient one that is 7.4x -7.8x faster for 29 and 93 frames 720p video generation with a marginal performance trade-off in VBench. In addition, we demonstrate that our approach is amenable to distributed inference, achieving an additional 3.91x speedup when running on 4 GPUs with sequence parallelism."

[11.02.2025 03:15] Response: ```python
["OPTIMIZATION", "DIFFUSION"]
```
[11.02.2025 03:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a solution to the inefficiency of Diffusion Transformers (DiTs) in generating high-fidelity videos. It introduces a method to prune 3D full attention by recognizing repetitive patterns in video data, leading to a sparse attention mechanism that reduces computational complexity. Additionally, the authors propose a multi-step consistency distillation approach to shorten the sampling process, allowing for faster video generation. The resulting model, Open-Sora-Plan-1.2, achieves significant speed improvements while maintaining performance, especially when utilizing distributed inference across multiple GPUs.","title":"Speeding Up Video Generation with Efficient Attention Mechanisms"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper presents a solution to the inefficiency of Diffusion Transformers (DiTs) in generating high-fidelity videos. It introduces a method to prune 3D full attention by recognizing repetitive patterns in video data, leading to a sparse attention mechanism that reduces computational complexity. Additionally, the authors propose a multi-step consistency distillation approach to shorten the sampling process, allowing for faster video generation. The resulting model, Open-Sora-Plan-1.2, achieves significant speed improvements while maintaining performance, especially when utilizing distributed inference across multiple GPUs.', title='Speeding Up Video Generation with Efficient Attention Mechanisms'))
[11.02.2025 03:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种改进的Diffusion Transformers（DiTs）模型，以解决生成高保真视频时的效率问题。我们通过识别视频数据中的冗余，提出了一种稀疏的3D注意力机制，使其在视频帧数量上具有线性复杂度。其次，我们采用多步一致性蒸馏技术，缩短了采样过程，从而实现了更快速的视频生成。最终，我们的模型在使用极少的预训练数据时，生成速度提高了7.4到7.8倍，同时保持了良好的性能。","title":"高效视频生成的新方法"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='本论文提出了一种改进的Diffusion Transformers（DiTs）模型，以解决生成高保真视频时的效率问题。我们通过识别视频数据中的冗余，提出了一种稀疏的3D注意力机制，使其在视频帧数量上具有线性复杂度。其次，我们采用多步一致性蒸馏技术，缩短了采样过程，从而实现了更快速的视频生成。最终，我们的模型在使用极少的预训练数据时，生成速度提高了7.4到7.8倍，同时保持了良好的性能。', title='高效视频生成的新方法'))
[11.02.2025 03:16] Querying the API.
[11.02.2025 03:16] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates a memory module that acts as a contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating a complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures.
[11.02.2025 03:16] Response: {
  "desc": "В статье представлена модель Large Memory Model (LM2), архитектура декодер-трансформер с дополнительным модулем памяти. LM2 решает проблемы стандартных трансформеров в многошаговых рассуждениях и обработке длинных контекстов. Модель показала значительное улучшение производительности на бенчмарке BABILong по сравнению с базовыми моделями. LM2 также продемонстрировала улучшенные возможности в многоходовых выводах, числовых вычислениях и ответах на вопросы с большим контекстом.",
  "emoji": "🧠",
  "title": "LM2: Трансформер с памятью для улучшенных рассуждений"
}
[11.02.2025 03:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates a memory module that acts as a contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating a complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures."

[11.02.2025 03:16] Response: ```python
['ARCHITECTURE', 'BENCHMARK', 'DATASET']
```
[11.02.2025 03:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates a memory module that acts as a contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating a complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures."

[11.02.2025 03:16] Response: ```python
["REASONING", "LONG_CONTEXT", "INTERPRETABILITY"]
```
[11.02.2025 03:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper presents the Large Memory Model (LM2), a new type of Transformer designed to improve multi-step reasoning and information synthesis over long contexts. LM2 features an auxiliary memory module that stores contextual information and interacts with input data through cross attention, allowing it to update its memory dynamically. This model retains the original capabilities of Transformers while adding a memory pathway that enhances performance on complex tasks. Experimental results show that LM2 significantly outperforms existing models in reasoning tasks and maintains strong performance on general tasks, highlighting the value of integrating explicit memory into Transformer architectures.","title":"Enhancing Transformers with Memory for Superior Reasoning"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='The paper presents the Large Memory Model (LM2), a new type of Transformer designed to improve multi-step reasoning and information synthesis over long contexts. LM2 features an auxiliary memory module that stores contextual information and interacts with input data through cross attention, allowing it to update its memory dynamically. This model retains the original capabilities of Transformers while adding a memory pathway that enhances performance on complex tasks. Experimental results show that LM2 significantly outperforms existing models in reasoning tasks and maintains strong performance on general tasks, highlighting the value of integrating explicit memory into Transformer architectures.', title='Enhancing Transformers with Memory for Superior Reasoning'))
[11.02.2025 03:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文介绍了一种名为大型记忆模型（LM2）的解码器仅Transformer架构，旨在解决标准Transformer在多步推理、关系论证和长上下文信息综合方面的局限性。LM2引入了一个辅助记忆模块，作为上下文表示的存储库，通过交叉注意力与输入标记交互，并通过门控机制进行更新。实验结果表明，LM2在BABILong基准测试中，平均性能比记忆增强的RMT模型提高了37.1%，比基线Llama-3.2模型提高了86.3%。LM2在多跳推理、数值推理和大上下文问答方面表现出色，证明了显式记忆在增强Transformer架构中的重要性。","title":"大型记忆模型：提升Transformer推理能力的关键"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='本文介绍了一种名为大型记忆模型（LM2）的解码器仅Transformer架构，旨在解决标准Transformer在多步推理、关系论证和长上下文信息综合方面的局限性。LM2引入了一个辅助记忆模块，作为上下文表示的存储库，通过交叉注意力与输入标记交互，并通过门控机制进行更新。实验结果表明，LM2在BABILong基准测试中，平均性能比记忆增强的RMT模型提高了37.1%，比基线Llama-3.2模型提高了86.3%。LM2在多跳推理、数值推理和大上下文问答方面表现出色，证明了显式记忆在增强Transformer架构中的重要性。', title='大型记忆模型：提升Transformer推理能力的关键'))
[11.02.2025 03:16] Loading Chinese text from previous data.
[11.02.2025 03:16] Renaming data file.
[11.02.2025 03:16] Renaming previous data. hf_papers.json to ./d/2025-02-11.json
[11.02.2025 03:16] Saving new data file.
[11.02.2025 03:16] Generating page.
[11.02.2025 03:16] Renaming previous page.
[11.02.2025 03:16] Renaming previous data. index.html to ./d/2025-02-11.html
[11.02.2025 03:16] [Experimental] Generating Chinese page for reading.
[11.02.2025 03:16] Chinese vocab [{'word': '注意力', 'pinyin': 'zhùyìlì', 'trans': 'attention'}, {'word': '机制', 'pinyin': 'jīzhì', 'trans': 'mechanism'}, {'word': '滑动', 'pinyin': 'huádòng', 'trans': 'sliding'}, {'word': '磁贴', 'pinyin': 'cítiē', 'trans': 'magnetic tile'}, {'word': '扩散', 'pinyin': 'kuòsàn', 'trans': 'diffusion'}, {'word': '变压器', 'pinyin': 'biànyāqì', 'trans': 'transformer'}, {'word': '计算', 'pinyin': 'jìsuàn', 'trans': 'computation'}, {'word': '成本', 'pinyin': 'chéngběn', 'trans': 'cost'}, {'word': '传统', 'pinyin': 'chuántǒng', 'trans': 'traditional'}, {'word': '全', 'pinyin': 'quán', 'trans': 'full'}, {'word': '耗时', 'pinyin': 'hàoshí', 'trans': 'time-consuming'}, {'word': '极长', 'pinyin': 'jícháng', 'trans': 'extremely long'}, {'word': '局部', 'pinyin': 'júbù', 'trans': 'local'}, {'word': '3D', 'pinyin': '', 'trans': '3D'}, {'word': '窗口', 'pinyin': 'chuāngkǒu', 'trans': 'window'}, {'word': '冗余', 'pinyin': 'rǒngyú', 'trans': 'redundancy'}, {'word': '硬件', 'pinyin': 'yìngjiàn', 'trans': 'hardware'}, {'word': '感知', 'pinyin': 'gǎnzhī', 'trans': 'perception'}, {'word': '设计', 'pinyin': 'shèjì', 'trans': 'design'}, {'word': '效率', 'pinyin': 'xiàolǜ', 'trans': 'efficiency'}, {'word': '实验', 'pinyin': 'shíyàn', 'trans': 'experiment'}, {'word': '显示', 'pinyin': 'xiǎnshì', 'trans': 'display'}, {'word': '显著', 'pinyin': 'xiǎnzhù', 'trans': 'significant'}, {'word': '减少', 'pinyin': 'jiǎnshǎo', 'trans': 'reduce'}, {'word': '延迟', 'pinyin': 'yánchí', 'trans': 'latency'}]
[11.02.2025 03:16] Renaming previous Chinese page.
[11.02.2025 03:16] Renaming previous data. zh.html to ./d/2025-02-10_zh_reading_task.html
[11.02.2025 03:16] Writing Chinese reading task.
[11.02.2025 03:16] Writing result.
[11.02.2025 03:16] Renaming log file.
[11.02.2025 03:16] Renaming previous data. log.txt to ./logs/2025-02-11_last_log.txt
