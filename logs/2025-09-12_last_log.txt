[11.09.2025 23:11] Read previous papers.
[11.09.2025 23:11] Generating top page (month).
[11.09.2025 23:11] Writing top page (month).
[12.09.2025 00:48] Read previous papers.
[12.09.2025 00:48] Get feed.
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08827
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08826
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07996
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08755
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06784
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.05209
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08358
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06870
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08088
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07054
[12.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08494
[12.09.2025 00:48] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[12.09.2025 00:48] No deleted papers detected.
[12.09.2025 00:48] Downloading and parsing papers (pdf, html). Total: 11.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.08827.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.08827.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.08827.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.08826.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.08826.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.08826.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.07996.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.07996.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.07996.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.08755.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.08755.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.08755.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.06784.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.06784.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.06784.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.05209.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.05209.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.05209.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.08358.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.08358.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.08358.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.06870.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.06870.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.06870.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.08088.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.08088.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.08088.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.07054.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.07054.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.07054.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.08494.
[12.09.2025 00:48] Extra JSON file exists (./assets/json/2509.08494.json), skip PDF parsing.
[12.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.08494.json), skip HTML parsing.
[12.09.2025 00:48] Success.
[12.09.2025 00:48] Enriching papers with extra data.
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 0. Reinforcement Learning enhances Large Language Models for complex reasoning tasks, facing challenges in scalability and infrastructure as the field advances.  					AI-generated summary 				 In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Mode...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 1. RewardDance is a scalable reward modeling framework that aligns with VLM architectures, enabling effective scaling of RMs and resolving reward hacking issues in generation models.  					AI-generated summary 				 Reward Models (RMs) are critical for improving generation models via Reinforcement Learn...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 2. This survey provides a comprehensive review of 3D and 4D world modeling and generation, establishing definitions, taxonomy, datasets, and evaluation metrics, and discussing applications and challenges.  					AI-generated summary 				 World modeling has become a cornerstone in AI research, enabling a...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 3. AgentGym-RL is a modular RL framework for training LLM agents in diverse environments without supervised fine-tuning, featuring ScalingInter-RL for balanced exploration-exploitation.  					AI-generated summary 				 Developing autonomous LLM agents capable of making a series of intelligent decisions ...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 4. P3-SAM, a native 3D point-promptable part segmentation model, achieves precise and robust segmentation of complex 3D objects using a feature extractor, multiple segmentation heads, and an IoU predictor.  					AI-generated summary 				 Segmenting 3D assets into their constituent parts is crucial for ...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 5. Hunyuan-MT-7B and Hunyuan-MT-Chimera-7B are multilingual translation models that outperform existing models, especially in translating between Mandarin and minority languages, through a combination of pre-training, supervised fine-tuning, and reinforcement learning.  					AI-generated summary 				 I...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 6. Models fine-tuned on synthetic toxic data generated by LLMs perform worse than those trained on human data due to a lexical diversity gap in the synthetic content.  					AI-generated summary 				 Modern Large Language Models (LLMs) are excellent at generating synthetic data. However, their performan...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 7. A reinforcement learning approach to aggregating multiple solutions for large language models improves performance on reasoning tasks by learning to synthesize correct answers from candidate solutions.  					AI-generated summary 				 Scaling up test-time compute, by generating multiple independent s...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 8. EnvX leverages Agentic AI to transform GitHub repositories into intelligent agents capable of natural language interaction and collaboration, automating the entire process of understanding, initializing, and operationalizing repository functionality.  					AI-generated summary 				 The widespread av...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 9. Statistical methods are reviewed for improving the reliability, quality, and efficiency of generative AI techniques, highlighting their applications and limitations.  					AI-generated summary 				 Generative Artificial Intelligence is emerging as an important technology, promising to be transformat...
[12.09.2025 00:48] ********************************************************************************
[12.09.2025 00:48] Abstract 10. A benchmark evaluates human agency in AI assistants using large language models, finding varying support across systems and dimensions.  					AI-generated summary 				 As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective...
[12.09.2025 00:48] Read previous papers.
[12.09.2025 00:48] Generating reviews via LLM API.
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#training", "#rl", "#rlhf", "#survey", "#reasoning"], "emoji": "üß†", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º: –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–∑–æ—Ä –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#rlhf", "#alignment", "#multimodal"], "emoji": "üíÉ", "ru": {"title": "RewardDance: –¢–∞–Ω—Ü—É—è —Å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è–º–∏ –≤ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–º –æ–±—É—á–µ–Ω–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RewardDance - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π, —Å–æ–≤–º–µ—Å—Ç–∏–º
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#survey", "#3d", "#dataset"], "emoji": "üåê", "ru": {"title": "–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è 3D –∏ 4D –º–∏—Ä–æ–≤: –æ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π", "desc": "–≠—Ç–æ—Ç –æ–±–∑–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D –∏ 4D –º–∏—Ä–æ–≤. –í –Ω–µ–º —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#rl", "#training", "#agents", "#games"], "emoji": "ü§ñ", "ru": {"title": "AgentGym-RL: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "AgentGym-RL - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥—É–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#optimization", "#3d", "#dataset", "#training", "#games"], "emoji": "üß©", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "P3-SAM - —ç—Ç–æ –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —á–∞—Å—Ç–µ–π 3D-–æ–±—ä–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#low_resource", "#multilingual", "#rl", "#training"], "emoji": "üåê", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–º –º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ", "desc": "–ú–æ–¥–µ–ª–∏ Hunyuan-MT-7B –∏ Hunyuan-MT-Chimera-7B - —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏–µ —Å—É
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#ethics", "#training", "#data", "#healthcare", "#synthetic"], "emoji": "ü§ñ", "ru": {"title": "–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –¥
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training", "#reasoning", "#benchmark"], "emoji": "üß†", "ru": {"title": "–£–º–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π –ò–ò —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. –ú–µ—Ç–æ
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#agi", "#open_source", "#benchmark", "#multimodal", "#agents"], "emoji": "ü§ñ", "ru": {"title": "EnvX: –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –≤ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "EnvX - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–≥–µ–Ω—Ç–Ω—ã–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –¥–ª—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ –∏–Ω—Ç–µ–ª–ª–µ–∫
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#ethics", "#training", "#survey", "#data", "#benchmark"], "emoji": "üìä", "ru": {"title": "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–∂–µ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏, –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ
[12.09.2025 00:48] Using data from previous issue: {"categories": ["#ethics", "#alignment", "#benchmark", "#rlhf"], "emoji": "ü§ñ", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤ —ç–ø–æ—Ö—É –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ HumanAgencyBench (HAB) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤ –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à
[12.09.2025 00:48] Renaming data file.
[12.09.2025 00:48] Renaming previous data. hf_papers.json to ./d/2025-09-12.json
[12.09.2025 00:48] Saving new data file.
[12.09.2025 00:48] Generating page.
[12.09.2025 00:48] Renaming previous page.
[12.09.2025 00:48] Renaming previous data. index.html to ./d/2025-09-12.html
[12.09.2025 00:48] Writing result.
[12.09.2025 00:48] Renaming log file.
[12.09.2025 00:48] Renaming previous data. log.txt to ./logs/2025-09-12_last_log.txt
