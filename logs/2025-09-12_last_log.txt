[12.09.2025 06:17] Read previous papers.
[12.09.2025 06:17] Generating top page (month).
[12.09.2025 06:17] Writing top page (month).
[12.09.2025 07:11] Read previous papers.
[12.09.2025 07:11] Get feed.
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08519
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09674
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09174
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09265
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09595
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09680
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09666
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09676
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09286
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09118
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01964
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09614
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.09332
[12.09.2025 07:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07430
[12.09.2025 07:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[12.09.2025 07:11] No deleted papers detected.
[12.09.2025 07:11] Downloading and parsing papers (pdf, html). Total: 14.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.08519.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.08519.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.08519.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09674.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09674.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09674.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09174.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09174.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09174.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09265.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09265.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09265.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09595.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09595.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09595.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09680.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09680.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09680.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09666.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09666.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09666.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09676.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09676.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09676.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09286.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09286.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09286.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09118.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09118.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09118.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.01964.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.01964.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.01964.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09614.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09614.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09614.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.09332.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.09332.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.09332.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Downloading and parsing paper https://huggingface.co/papers/2509.07430.
[12.09.2025 07:11] Extra JSON file exists (./assets/json/2509.07430.json), skip PDF parsing.
[12.09.2025 07:11] Paper image links file exists (./assets/img_data/2509.07430.json), skip HTML parsing.
[12.09.2025 07:11] Success.
[12.09.2025 07:11] Enriching papers with extra data.
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 0. HuMo is a unified framework for human-centric video generation that addresses challenges in multimodal control through a two-stage training paradigm and novel strategies for subject preservation and audio-visual synchronization.  					AI-generated summary 				 Human-Centric Video Generation (HCVG) m...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 1. SimpleVLA-RL, an RL framework for VLA models, enhances long-horizon action planning, achieves state-of-the-art performance, and discovers novel patterns during training.  					AI-generated summary 				 Vision-Language-Action (VLA) models have recently emerged as a powerful paradigm for robotic manip...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 2. EchoX, a speech-to-speech large language model, addresses the acoustic-semantic gap by integrating semantic representations, preserving reasoning abilities, and achieving advanced performance on knowledge-based benchmarks.  					AI-generated summary 				 Speech-to-speech large language models (SLLMs...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 3. Entropy-Modulated Policy Gradients (EMPG) addresses learning dynamics issues in LLMs by recalibrating policy gradients based on uncertainty and task outcomes, leading to improved performance in long-horizon tasks.  					AI-generated summary 				 In long-horizon tasks, recent agents based on Large La...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 4. Kling-Avatar, a cascaded framework, enhances audio-driven avatar video generation by integrating multimodal instruction understanding with photorealistic portrait generation, resulting in high-fidelity, semantically grounded videos.  					AI-generated summary 				 Recent advances in audio-driven ava...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 5. FLUX-Reason-6M and PRISM-Bench address the lack of reasoning-focused datasets and benchmarks for text-to-image models, providing a large-scale dataset and evaluation standard to improve model performance.  					AI-generated summary 				 The advancement of open-source text-to-image (T2I) models has b...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 6. A novel framework UAE uses reinforcement learning to unify image-to-text and text-to-image processes, enhancing mutual understanding and generation fidelity.  					AI-generated summary 				 In this paper, we introduce an insightful paradigm through the Auto-Encoder lens-understanding as the encoder ...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 7. SpatialVID, a large-scale dataset with diverse videos and dense 3D annotations, enhances model generalization and performance in video and 3D vision research.  					AI-generated summary 				 Significant progress has been made in spatial intelligence, spanning both spatial reconstruction and world ex...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 8. VLMs are enhanced with an adaptive framework that selects between code-based and direct visual reasoning for chart understanding, improving performance and robustness.  					AI-generated summary 				 Chart understanding presents a critical test to the reasoning capabilities of Vision-Language Models...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 9. GA-DMS framework enhances CLIP for person representation learning by improving data quality and model architecture, achieving state-of-the-art performance.  					AI-generated summary 				 Although Contrastive Language-Image Pre-training (CLIP) exhibits strong performance across diverse vision tasks,...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 10. A novel image inpainting framework using 2D Gaussian Splatting achieves competitive performance by combining continuous field representation with pretrained DINO model features for global semantic consistency.  					AI-generated summary 				 Gaussian Splatting (GS), a recent technique for converting...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 11. LoCoBench evaluates long-context language models in complex software development scenarios, addressing the gap in understanding entire codebases and maintaining architectural consistency across large-scale systems.  					AI-generated summary 				 The emergence of long-context language models with co...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 12. OmniEVA addresses spatial and embodiment gaps in multimodal large language models for embodied intelligence through a task-adaptive 3D grounding mechanism and an embodiment-aware reasoning framework, achieving state-of-the-art performance across diverse tasks.  					AI-generated summary 				 Recent ...
[12.09.2025 07:11] ********************************************************************************
[12.09.2025 07:11] Abstract 13. A new framework, DPH-RL, uses mass-covering f-divergences to address Pass@k degradation and catastrophic forgetting in fine-tuning LLMs with RLVR, improving both Pass@1 and Pass@k.  					AI-generated summary 				 A central paradox in fine-tuning Large Language Models (LLMs) with Reinforcement Learni...
[12.09.2025 07:11] Read previous papers.
[12.09.2025 07:11] Generating reviews via LLM API.
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#dataset", "#video", "#multimodal", "#training"], "emoji": "üé≠", "ru": {"title": "HuMo: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –ª—é–¥—å–º–∏ —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "desc": "HuMo - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –ª—é–¥—å–º–∏, —É—á–∏—Ç—ã–≤–∞—é—â–∞—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#agents", "#optimization", "#rl", "#robotics", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤", "desc": "SimpleVLA-RL - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–ª—è –º–æ–¥–µ–ª–µ–π —Ç–∏–ø–∞ Vision-Language-Action (VL
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#science", "#reasoning", "#benchmark", "#audio", "#dataset"], "emoji": "üó£Ô∏è", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —Ä–∞–∑—Ä—ã–≤–∞ –º–µ–∂–¥—É –∑–≤—É–∫–æ–º –∏ —Å–º—ã—Å–ª–æ–º –≤ —Ä–µ—á–µ–≤—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö", "desc": "EchoX - —ç—Ç–æ —Ä–µ—á–µ–≤–∞—è –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∞–∫—É—Å—Ç–∏–∫–æ-—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–∞. –û–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#agents", "#optimization", "#rl", "#training", "#rlhf"], "emoji": "üß†", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —ç–Ω—Ç—Ä–æ–ø–∏–π–Ω—É—é –º–æ–¥—É–ª—è—Ü–∏—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤", "desc": "–ú–µ—Ç–æ–¥ EMPG (Entropy-Modulated Policy Gradients) —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –¥–∏–Ω–∞–º–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö 
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#story_generation", "#video", "#games"], "emoji": "üé≠", "ru": {"title": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä—ã —Å –≤—ã—Å–æ–∫–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π", "desc": "Kling-Avatar - —ç—Ç–æ –Ω–æ–≤–∞—è –∫–∞—Å–∫–∞–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —Å –∞–≤–∞—Ç–∞—Ä–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—É–¥–∏–æ. –û–Ω–∞ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–Ω
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#multilingual", "#benchmark", "#open_source", "#long_context", "#dataset", "#reasoning"], "emoji": "üß†", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –∏ –æ—Ü–µ–Ω–∫–µ –º–æ–¥–µ–ª–µ–π —Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "desc": "FLUX-Reason-6M –∏ PRISM-Bench —Ä–µ—à–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—É –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏ —ç—Ç–∞–ª–æ–Ω–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#multimodal", "#games", "#rl"], "emoji": "üîÑ", "ru": {"title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ UAE, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#3d", "#dataset", "#video"], "emoji": "üé•", "ru": {"title": "SpatialVID: –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ—Ä—ã–≤–∞ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ", "desc": "SpatialVID - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –≤–∏–¥–µ–æ —Å –ø–ª–æ—Ç–Ω—ã–º–∏ 3D-–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –±–æ–ª–µ–µ 21 000 —á–∞—Å–æ–≤ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#benchmark", "#multimodal", "#training", "#hallucinations"], "emoji": "üìä", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ VLM –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤–∏–∑—É–∞–ª—å–Ω–æ-—è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#data", "#optimization", "#benchmark", "#transfer_learning", "#dataset", "#architecture"], "emoji": "üë§", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ CLIP –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª—é–¥–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç GA-DMS —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è CLIP –≤ –∑–∞–¥–∞—á–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ª—é–¥–µ–π. –ê–≤—Ç–æ—Ä—ã —Ä
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#inference", "#cv", "#benchmark"], "emoji": "üñåÔ∏è", "ru": {"title": "–î–æ—Ä–∏—Å–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é 2D Gaussian Splatting –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", "desc": "–ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –¥–æ—Ä–∏—Å–æ–≤–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é 2D Gaussian Splatting, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ —Ç–æ—á–∫–∏ –≤ –Ω–µ–ø—Ä
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#long_context"], "emoji": "üß†", "ru": {"title": "LoCoBench: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –æ—Ü–µ–Ω–∫–µ –ò–ò –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ü–û", "desc": "LoCoBench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –≤ —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –û–Ω –≤–∫–ª—é—á
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#agents", "#reasoning", "#benchmark", "#multimodal", "#games", "#3d"], "emoji": "ü§ñ", "ru": {"title": "OmniEVA: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–≥–æ –ò–ò", "desc": "OmniEVA - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–≥–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∞–¥
[12.09.2025 07:11] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#rl"], "emoji": "üß†", "ru": {"title": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ DPH-RL –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. DP
[12.09.2025 07:11] Renaming data file.
[12.09.2025 07:11] Renaming previous data. hf_papers.json to ./d/2025-09-12.json
[12.09.2025 07:11] Saving new data file.
[12.09.2025 07:11] Generating page.
[12.09.2025 07:11] Renaming previous page.
[12.09.2025 07:11] Renaming previous data. index.html to ./d/2025-09-12.html
[12.09.2025 07:11] Writing result.
[12.09.2025 07:11] Renaming log file.
[12.09.2025 07:11] Renaming previous data. log.txt to ./logs/2025-09-12_last_log.txt
