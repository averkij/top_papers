[25.08.2025 15:12] Read previous papers.
[25.08.2025 15:12] Generating top page (month).
[25.08.2025 15:12] Writing top page (month).
[25.08.2025 16:14] Read previous papers.
[25.08.2025 16:14] Get feed.
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16153
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08240
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14029
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13013
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13650
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07877
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16402
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16292
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15746
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15881
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16279
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16359
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16072
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15868
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13797
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13562
[25.08.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10390
[25.08.2025 16:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[25.08.2025 16:14] No deleted papers detected.
[25.08.2025 16:14] Downloading and parsing papers (pdf, html). Total: 17.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.16153.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.16153.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.16153.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.08240.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.08240.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.08240.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.14029.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.14029.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.14029.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.13013.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.13013.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.13013.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.13650.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.13650.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.13650.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.07877.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.07877.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.07877.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.16402.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.16402.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.16402.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.16292.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.16292.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.16292.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.15746.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.15746.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.15746.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.15881.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.15881.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.15881.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.16279.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.16279.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.16279.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.16359.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.16359.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.16359.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.16072.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.16072.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.16072.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.15868.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.15868.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.15868.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.13797.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.13797.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.13797.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.13562.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.13562.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.13562.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2508.10390.
[25.08.2025 16:14] Extra JSON file exists (./assets/json/2508.10390.json), skip PDF parsing.
[25.08.2025 16:14] Paper image links file exists (./assets/img_data/2508.10390.json), skip HTML parsing.
[25.08.2025 16:14] Success.
[25.08.2025 16:14] Enriching papers with extra data.
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 0. A novel memory-augmented reinforcement learning paradigm enables adaptive LLM agents to continually learn without fine-tuning, using episodic memory and a neural case-selection policy.  					AI-generated summary 				 In this paper, we introduce a novel learning paradigm for adaptive Large Language M...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 1. ODYSSEY is a unified mobile manipulation framework for quadruped robots that integrates high-level task planning with low-level whole-body control, addressing challenges in egocentric perception, generalization, and coordination in unstructured environments.  					AI-generated summary 				 Language-...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 2. An online self-play strategy with variational problem synthesis for RLVR training maintains policy entropy and improves Pass@k performance on reasoning benchmarks.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a key paradigm for post-tr...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 3. EgoTwin, a diffusion transformer framework, addresses viewpoint alignment and causal interplay in joint egocentric video and human motion generation using a head-centric motion representation and cybernetics-inspired interaction mechanism.  					AI-generated summary 				 While exocentric video synth...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 4. CRISP is a parameter-efficient method using sparse autoencoders to permanently remove unwanted knowledge from large language models while preserving their utility.  					AI-generated summary 				 As large language models (LLMs) are increasingly deployed in real-world applications, the need to select...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 5. The method uses selective prototypical and pixel contrastive objectives to learn affordance-relevant cues from third-person demonstrations, improving upon traditional weakly supervised affordance grounding by focusing on both part and object levels.  					AI-generated summary 				 Facilitating an en...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 6. AetherCode is a new benchmark for evaluating Large Language Models in competitive programming, offering more challenging and expert-validated test cases than existing benchmarks.  					AI-generated summary 				 Competitive programming has emerged as a critical benchmark for evaluating the reasoning ...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 7. A unified framework, Instruct-Verify-and-Act (IVA), enhances Vision-Language-Action (VLA) models to detect and respond to false-premise instructions by leveraging contextually augmented datasets.  					AI-generated summary 				 Recently, Vision-Language-Action (VLA) models have demonstrated strong p...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 8. Deep-DxSearch, an agentic RAG system trained with reinforcement learning, enhances medical diagnosis accuracy by integrating a large-scale retrieval corpus and tailored rewards.  					AI-generated summary 				 Accurate diagnosis with medical large language models is hindered by knowledge gaps and ha...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 9. Tensor-Parallel Latent Attention (TPLA) enhances tensor parallelism efficiency by partitioning latent representations and input dimensions, preserving the benefits of compressed key-value caches while maintaining strong representational capacity.  					AI-generated summary 				 Multi-Head Latent Att...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 10. AgentScope enhances agentic applications by providing flexible tool-based interactions, unified interfaces, and advanced infrastructure based on the ReAct paradigm, supporting efficient and safe development and deployment.  					AI-generated summary 				 Driven by rapid advancements of Large Languag...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 11. RotaTouille is a deep learning framework that achieves rotation and cyclic shift equivariance for contour data using complex-valued circular convolution, enabling effective performance in shape classification, reconstruction, and contour regression.  					AI-generated summary 				 Contours or closed...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 12. InMind evaluates LLMs' ability to capture and apply personalized reasoning styles in social deduction games, highlighting limitations in current models' adaptive reasoning.  					AI-generated summary 				 LLMs have shown strong performance on human-centric reasoning tasks. While previous evaluations...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 13. A contrastive learning approach with annotated Chain-of-Thought enhances the reasoning performance of Large Language Models through stable fine-tuning and robust contrastive signals.  					AI-generated summary 				 Reasoning capability plays a significantly critical role in the the broad application...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 14. Sketch3DVE is a sketch-based 3D-aware video editing method that uses dense stereo estimation, point cloud editing, and a video diffusion model to handle sparse inputs and viewpoint changes in video editing.  					AI-generated summary 				 Recent video editing methods achieve attractive results in st...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 15. Learnable SMPLify replaces iterative optimization in SMPLify with a neural network for faster and more generalized 3D human pose and shape estimation.  					AI-generated summary 				 In 3D human pose and shape estimation, SMPLify remains a robust baseline that solves inverse kinematics (IK) through ...
[25.08.2025 16:14] ********************************************************************************
[25.08.2025 16:14] Abstract 16. A hybrid framework combining LLMs and human oversight is proposed to clean datasets and detect jailbreak attacks, with new strategies to enhance jailbreak success.  					AI-generated summary 				 Evaluating jailbreak attacks is challenging when prompts are not overtly harmful or fail to induce harmf...
[25.08.2025 16:14] Read previous papers.
[25.08.2025 16:14] Generating reviews via LLM API.
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#agi", "#optimization", "#rl", "#agents"], "emoji": "üß†", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ LLM-–∞–≥–µ–Ω—Ç–æ–≤ –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), –∫–æ—Ç–æ—Ä–∞—è —É—Å—Ç—Ä–∞–Ω—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#robotics", "#transfer_learning", "#optimization", "#reasoning", "#agents", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "–ú–æ–±–∏–ª—å–Ω–∞—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è —Ä–æ–±–æ—Ç–æ–≤: –æ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫ –¥–µ–π—Å—Ç–≤–∏—é", "desc": "ODYSSEY - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–±–∏–ª—å–Ω–æ–π –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ –¥–ª—è —á–µ—Ç–≤–µ—Ä–æ–Ω–æ–≥–∏—Ö —Ä–æ–±–æ—Ç–æ–≤, –æ–±—ä–µ–¥–∏
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#optimization", "#rlhf", "#reasoning", "#training"], "emoji": "üß†", "ru": {"title": "–°–∞–º–æ—É–ª—É—á—à–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Å–∏–Ω—Ç–µ–∑ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–º–∏ –Ω–∞–≥—Ä–∞–¥–∞–º–∏ (RLVR) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#diffusion", "#video", "#multimodal", "#dataset", "#architecture"], "emoji": "üëÄ", "ru": {"title": "EgoTwin: –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ –∏ –¥–≤–∏–∂–µ–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞", "desc": "EgoTwin - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ –∏ –¥–≤–∏–∂–µ–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#inference", "#ethics", "#training", "#security"], "emoji": "üß†", "ru": {"title": "–¢–æ—á–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –∏–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏", "desc": "CRISP - —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π –∏–∑ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#cv"], "emoji": "ü§ñ", "ru": {"title": "–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ø–æ–º–æ—â—å—é —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–ª–∞–±–æ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤–∑–∞–∏–º–æ–¥–µ
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#reasoning"], "emoji": "üèÜ", "ru": {"title": "AetherCode: –ù–æ–≤–∞—è –ø–ª–∞–Ω–∫–∞ –≤ –æ—Ü–µ–Ω–∫–µ –ò–ò-–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤", "desc": "AetherCode - –Ω–æ–≤—ã–π —ç—Ç–∞–ª–æ–Ω –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏. –û–Ω –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ –ø—Ä–æ–≤–µ—Ä
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#multimodal", "#interpretability", "#robotics", "#alignment", "#dataset"], "emoji": "ü§ñ", "ru": {"title": "–£–º–Ω—ã–µ —Ä–æ–±–æ—Ç—ã —É—á–∞—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –Ω–µ–≤—ã–ø–æ–ª–Ω–∏–º—ã–µ –∫–æ–º–∞–Ω–¥—ã", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –µ–¥–∏–Ω—É—é —Å–∏—Å—Ç–µ–º—É Instruct-Verify-and-Act (IVA) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π Vision-Language-Acti
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#optimization", "#interpretability", "#healthcare", "#rl", "#reasoning", "#rag", "#hallucinations"], "emoji": "ü©∫", "ru": {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–∂–µ –∑–¥–æ—Ä–æ–≤—å—è: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ", "desc": "Deep-DxSearch - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ 
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#training", "#benchmark", "#long_context"], "emoji": "‚ö°", "ru": {"title": "TPLA: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ç–µ–Ω–∑–æ—Ä–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π –º–∞—à
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#agents", "#architecture"], "emoji": "ü§ñ", "ru": {"title": "AgentScope: –≥–∏–±–∫–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "AgentScope 1.0 - —ç—Ç–æ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#optimization", "#games", "#architecture", "#cv"], "emoji": "üîÑ", "ru": {"title": "–í—Ä–∞—â–µ–Ω–∏–µ –∏ —Å–¥–≤–∏–≥ –Ω–µ –ø–æ–º–µ—Ö–∞: RotaTouille –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤", "desc": "RotaTouille - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–Ω—Ç—É—Ä–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –û–Ω –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —ç–∫–≤–∏–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –≤—Ä–∞—â–µ–Ω–∏—é –∏ —Ü–∏–∫–ª–∏—á
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#games", "#reasoning"], "emoji": "üß†", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Å—Ç–∏–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –ò–ò: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç InMind - —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —É–ª–∞–≤–ª–∏–≤–∞—Ç—å –∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#training", "#rl", "#reasoning", "#optimization"], "emoji": "üß†", "ru": {"title": "–ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å CoT: –Ω–æ–≤—ã–π —à–∞–≥ –≤ —É–ª—É—á—à–µ–Ω–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π LLM", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç—Ä–∞
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#video", "#games", "#diffusion", "#3d"], "emoji": "‚úèÔ∏è", "ru": {"title": "–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å —É—á–µ—Ç–æ–º 3D-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –ø–æ–º–æ—â—å—é —ç—Å–∫–∏–∑–æ–≤", "desc": "Sketch3DVE - —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Å–∫–∏–∑–æ–≤, —É—á–∏—Ç—ã–≤–∞—é—â–∏–π 3D-—Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ü–µ–Ω—ã. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–ª–æ—Ç–Ω—É—é —Å—Ç–µ—Ä–µ–æ–æ—Ü–µ–Ω–∫—É, —Ä–µ–¥–∞–∫—Ç–∏
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#3d", "#data", "#training", "#optimization"], "emoji": "üèÉ", "ru": {"title": "–ë—ã—Å—Ç—Ä–∞—è –∏ –æ–±–æ–±—â–∞–µ–º–∞—è –æ—Ü–µ–Ω–∫–∞ 3D –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Learnable SMPLify - –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ 3D –ø–æ–∑—ã –∏ —Ñ–æ—Ä–º—ã —á–µ–ª–æ–≤–µ–∫–∞. –û–Ω –∑–∞–º–µ–Ω—è–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏
[25.08.2025 16:14] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#data", "#security", "#dataset"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—é –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —É—Å–∏–ª–µ–Ω–∏—é jailbreak-–∞—Ç–∞–∫", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –≥–∏–±—Ä–∏–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Å–æ—á–µ—Ç–∞—é—â–∞—è –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å –¥–ª
[25.08.2025 16:14] Renaming data file.
[25.08.2025 16:14] Renaming previous data. hf_papers.json to ./d/2025-08-25.json
[25.08.2025 16:14] Saving new data file.
[25.08.2025 16:14] Generating page.
[25.08.2025 16:14] Renaming previous page.
[25.08.2025 16:14] Renaming previous data. index.html to ./d/2025-08-25.html
[25.08.2025 16:14] Writing result.
[25.08.2025 16:14] Renaming log file.
[25.08.2025 16:14] Renaming previous data. log.txt to ./logs/2025-08-25_last_log.txt
