[26.02.2025 17:09] Read previous papers.
[26.02.2025 17:09] Generating top page (month).
[26.02.2025 17:09] Writing top page (month).
[26.02.2025 18:14] Read previous papers.
[26.02.2025 18:14] Get feed.
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18411
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18137
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17363
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18449
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18364
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17262
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15499
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18461
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18356
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17425
[26.02.2025 18:14] Extract page data from URL. URL: https://huggingface.co/papers/2502.16069
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17535
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16794
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16825
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15612
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17092
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.14855
[26.02.2025 18:14] Extract page data from URL. URL: https://huggingface.co/papers/2502.17814
[26.02.2025 18:14] Get page data from previous paper. URL: https://huggingface.co/papers/2502.18316
[26.02.2025 18:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.02.2025 18:14] No deleted papers detected.
[26.02.2025 18:14] Downloading and parsing papers (pdf, html). Total: 19.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18411.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18411.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18411.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18137.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18137.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18137.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.17363.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.17363.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.17363.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18449.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18449.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18449.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18364.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18364.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18364.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.17262.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.17262.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.17262.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.15499.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.15499.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.15499.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18461.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18461.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18461.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18356.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18356.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18356.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.17425.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.17425.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.17425.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.16069.
[26.02.2025 18:14] Downloading paper 2502.16069 from http://arxiv.org/pdf/2502.16069v1...
[26.02.2025 18:14] Extracting affiliations from text.
[26.02.2025 18:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents Patrick Tser Jern Kon * 1 Jiachen Liu * 1 Qiuyi Ding 1 Yiming Qiu 1 Zhenning Yang 1 Yibo Huang 1 Jayanth Srinivasa 2 Myungjin Lee 2 Mosharaf Chowdhury 1 Ang Chen 1 5 2 0 2 2 2 ] . [ 1 9 6 0 6 1 . 2 0 5 2 : r a "
[26.02.2025 18:14] Response: ```python
[]
```
[26.02.2025 18:14] Extracting affiliations from text.
[26.02.2025 18:14] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents Patrick Tser Jern Kon * 1 Jiachen Liu * 1 Qiuyi Ding 1 Yiming Qiu 1 Zhenning Yang 1 Yibo Huang 1 Jayanth Srinivasa 2 Myungjin Lee 2 Mosharaf Chowdhury 1 Ang Chen 1 5 2 0 2 2 2 ] . [ 1 9 6 0 6 1 . 2 0 5 2 : r aScientific experimentation, cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve 3.4 improvement in correctly answering experimental questions. Curie is open-sourced at https: //github.com/Just-Curieous/Curie. 1. Introduction Scientific research drives human progress, advancing medicine, technology, and our understanding of the universe. At the heart of this endeavor lies experimentationa disciplined intellectual pursuit that transforms human curiosity, expressed through bold hypotheses, into verifiable knowledge. Experimentation thrives on creativity, as new ideas fuel discovery. Yet it also depends on rigorensuring that research is methodologically sound and its findings are trustworthy (Armour et al., 2009; Gill & Gill, 2020). If *Equal contribution 1Department of Computer Science and Engineering, University of Michigan 2Cisco Systems. Correspondence to: Patrick Tser Jern Kon <patkon@umich.edu>, Jiachen Liu <amberljc@umich.edu>. Figure 1. Curie overview. science isnt rigorous, its reckless (Hofseth, 2018). In recent years, numerous works (Zhang et al., 2024b; Kramer et al., 2023; Lu et al., 2024) leveraging large language models (LLMs) to automate scientific research have emerged (2.3). These solutions typically rely on ad-hoc prompt-based methods to mimic scientific workflows, which are prone to hallucination. While effective for creative tasks such as literature review and brainstorming, these approaches remain limited in their ability to support rigorous experimentation, largely unexplored capability. More specifically, rigorous experimentation (2.2) involves methodical procedure that includes formulating hypotheses, designing experiments, executing controlled trials, and analyzing results. Achieving reliability at every step is essential to ensure that the results are accurate, reproducible, and scientifically meaningful. Finally, all procedures and results must be documented in well-structured and interpretable manner, facilitating verification, reproducibility, and collaboration across the scientific community. To meet these requirements, we propose Curie, an AI agent framework representing the first step toward rigorous and automated experimentation (3). As shown in Fig. 1, Curie takes an experimental question and relevant context (e.g., domain-specific knowledge or starter code) as input. The Architect Agent generates high-level experimental plans, coordinates the process, and reflects on findings to guide subsequent steps. Working in unison, our Technician Agents focus on carefully implementing and executing 1 Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents Figure 2. Case Study. Curie can help researchers validate, expand, and critique existing research on the benefits of repeated sampling in LLM reasoning (Brown et al., 2024). The first panel (Original Finding) presents result from the original paper. The second panel (Reproduce) has Curie confirming this finding through rigorous experimentation. The third panel (Extend) has Curie exploring the impact of sampling temperature on repeated sampling. The final panel (Challenge) shows Curie identifying limitation in the original methodology, suggesting an avenue for future research. controlled experiments following these plans. At the core of Curie, the Experimental Rigor Engine preserves agent creativity while embedding rigor seamlessly throughout the experimentation process. This is achieved via three key modules: (1) The Intra-Agent Rigor Module safeguards reliability within individual agents by enforcing set of extensible rigor policies (e.g., validating that experiment plans align with objectives and setups are reproducible). (2) The Inter-Agent Rigor Module maintains methodical control over agent coordination, ensuring correct task transitions and efficient task scheduling. (3) Finally, the Experiment Knowledge Module enhances interpretability by maintaining well-structured documentation, enabling seamless collaboration in large-scale experiments. Though our architecture suggests applications across various disciplines, this paper focuses on addressing research problems in computer science by leveraging existing LLMfriendly interfaces for computer access (Anthropic, 2024; Yang et al., 2024). To evaluate Curie, we introduce an Experimentation Benchmark comprising 46 tasks of varying complexity across multiple domains within computer science (4). We derive these questions directly from influential research papers and widely adopted open-source projects, in order to reflect real-world challenges and practical significance. As shown in Fig. 2, Curie enables researchers to reproduce, extend, and challenge existing research through rigorous experimentation. We benchmarked Curie (5) against several state-ofthe-art agents: OpenHands (Wang et al., 2024c) (a topperforming coding agent on SWE-Bench (Jimenez et al., 2023)), and Microsoft Magentic (Fourney et al., 2024) (a state-of-the-art generalist multi-agent system). Our empirical findings show that Curie achieves 3.4 improvement in correctly answering experimental questions, compared to the strongest baseline tested, among other aspects. These results underscore Curies ability to automate complex and rigorous experimentation tasks, making it promising step toward accelerating scientific research. 2. Background 2.1. Science E"
[26.02.2025 18:14] Mistral response. {"id": "3ef0e8525240490d8b98770ac3d24f60", "object": "chat.completion", "created": 1740593674, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Department of Computer Science and Engineering, University of Michigan\", \"Cisco Systems\"]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1556, "total_tokens": 1580, "completion_tokens": 24}}
[26.02.2025 18:14] Response: ```python
["Department of Computer Science and Engineering, University of Michigan", "Cisco Systems"]
```
[26.02.2025 18:14] Deleting PDF ./assets/pdf/2502.16069.pdf.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.17535.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.17535.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.17535.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.16794.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.16794.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.16794.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.16825.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.16825.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.16825.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.15612.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.15612.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.15612.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.17092.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.17092.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.17092.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.14855.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.14855.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.14855.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.17814.
[26.02.2025 18:14] Downloading paper 2502.17814 from http://arxiv.org/pdf/2502.17814v1...
[26.02.2025 18:14] Extracting affiliations from text.
[26.02.2025 18:14] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Wenlong Ji1, Weizhe Yuan2,3, Emily Getzen4 Kyunghyun Cho2 Michael I. Jordan5,6 Weijie J. Su4, Jing Xu3, Song Mei Jason Weston2,3 Linjun Zhang7, 5 2 0 2 5 2 ] . s [ 1 4 1 8 7 1 . 2 0 5 2 : r 1Stanford University 2New York University 3Meta FAIR 4University of Pennsylvania 5UC Berkeley 6INRIA 7Rutgers University Abstract Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and deep learning architectures, emerging problemsin areas such as uncertainty quantification, decision-making, causal inference, and distribution shiftrequire deeper engagement with the field of statistics. This paper explores potential areas where statisticians can make important contributions to the development of LLMs, particularly those that aim to engender trustworthiness and transparency for human users. Thus, we focus on issues such as uncertainty quantification, interpretability, fairness, privacy, watermarking and model adaptation. We also consider possible roles for LLMs in statistical analysis. By bridging AI and statistics, we aim to foster deeper collaboration that advances both the theoretical foundations and practical applications of LLMs, ultimately shaping their role in addressing complex societal challenges. 1 Introduction 2 Background and Fundamentals of LLMs 2.1 Historical Development of LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1.1 Representation Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1.2 Language Modeling 2.2 Architectures of Pre-trained Language Models . . . . . . . . . . . . . . . . . . . . . . . . 2.3 LLM Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 4 4 4 5 5 3 Tr"
[26.02.2025 18:14] Response: ```python
[
    "Stanford University",
    "New York University",
    "Meta FAIR",
    "University of Pennsylvania",
    "UC Berkeley",
    "INRIA",
    "Rutgers University"
]
```
[26.02.2025 18:14] Deleting PDF ./assets/pdf/2502.17814.pdf.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Downloading and parsing paper https://huggingface.co/papers/2502.18316.
[26.02.2025 18:14] Extra JSON file exists (./assets/json/2502.18316.json), skip PDF parsing.
[26.02.2025 18:14] Paper image links file exists (./assets/img_data/2502.18316.json), skip HTML parsing.
[26.02.2025 18:14] Success.
[26.02.2025 18:14] Enriching papers with extra data.
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 0. Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities, leaving a significant gap in human preference alignment. This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples featur...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 1. An efficient attention implementation is essential for large models due to its quadratic time complexity. Fortunately, attention commonly exhibits sparsity, i.e., many values in the attention map are near zero, allowing for the omission of corresponding computations. Many studies have utilized the s...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 2. Background consistency remains a significant challenge in image editing tasks. Despite extensive developments, existing works still face a trade-off between maintaining similarity to the original image and generating content that aligns with the target. Here, we propose KV-Edit, a training-free appr...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 3. The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs). While DeepSeek-R1 and other follow-up work primarily focus on applying RL to competitive coding and math problems, thi...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 4. Multi-layer image generation is a fundamental task that enables users to isolate, select, and edit specific image layers, thereby revolutionizing interactions with generative models. In this paper, we introduce the Anonymous Region Transformer (ART), which facilitates the direct generation of variab...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 5. The rapid advancements in computing dramatically increase the scale and cost of training Large Language Models (LLMs). Accurately predicting downstream task performance prior to model training is crucial for efficient resource allocation, yet remains challenging due to two primary constraints: (1) t...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 6. Training stability is a persistent challenge in the pre-training of large language models (LLMs), particularly for architectures such as Post-Norm Transformers, which are prone to gradient explosion and dissipation. In this paper, we propose Scale-Distribution Decoupling (SDD), a novel approach that...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 7. Recent studies have explored combining different LoRAs to jointly generate learned style and content. However, existing methods either fail to effectively preserve both the original subject and style simultaneously or require additional training. In this paper, we argue that the intrinsic properties...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 8. We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 9. To utilize visual information, Multimodal Large Language Model (MLLM) relies on the perception process of its vision encoder. The completeness and accuracy of visual perception significantly influence the precision of spatial reasoning, fine-grained understanding, and other tasks. However, MLLM stil...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 10. Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigo...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 11. Motivated by reducing the computational and storage costs of LLMs, model compression and KV cache compression have attracted much attention from researchers. However, current methods predominantly emphasize maintaining the performance of compressed LLMs, as measured by perplexity or simple accuracy ...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 12. Auditory foundation models, including auditory large language models (LLMs), process all sound inputs equally, independent of listener perception. However, human auditory perception is inherently selective: listeners focus on specific speakers while ignoring others in complex auditory scenes. Existi...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 13. Iterative data generation and model retraining are widely used to align large language models (LLMs). It typically involves a policy model to generate on-policy responses and a reward model to guide training data selection. Direct Preference Optimization (DPO) further enhances this process by constr...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 14. State space models (SSMs), such as Mamba, have emerged as an efficient alternative to transformers for long-context sequence modeling. However, despite their growing adoption, SSMs lack the interpretability tools that have been crucial for understanding and improving attention-based architectures. W...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 15. We introduce Shakti VLM, a family of vision-language models in the capacity of 1B and 4B parameters designed to address data efficiency challenges in multimodal learning. While recent VLMs achieve strong performance through extensive training data, Shakti models leverage architectural innovations to...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 16. Large language model (LLM) evaluations typically rely on aggregated metrics like accuracy or human preference, averaging across users and prompts. This averaging obscures user- and prompt-specific variations in model performance. To address this, we propose Prompt-to-Leaderboard (P2L), a method that...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 17. Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and dee...
[26.02.2025 18:14] ********************************************************************************
[26.02.2025 18:14] Abstract 18. We introduce WiCkeD, a simple method to increase the complexity of existing multiple-choice benchmarks by randomly replacing a choice with "None of the above", a method often used in educational tests. We show that WiCkeD can be automatically applied to any existing benchmark, making it more challen...
[26.02.2025 18:14] Read previous papers.
[26.02.2025 18:14] Generating reviews via LLM API.
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#alignment", "#training", "#benchmark", "#multimodal", "#dataset", "#open_source"], "emoji": "🤖", "ru": {"title": "Приведение мультимодальных ИИ-моделей в соответствие с человеческими ценностями", "desc": "Статья представляет OmniAlign-V - набор данных для улучшения мультимодальных 
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#architecture", "#inference", "#video", "#optimization", "#cv"], "emoji": "🚀", "ru": {"title": "Универсальное разреженное внимание для ускорения нейросетей", "desc": "В статье представлен новый метод SpargeAttn для оптимизации внимания в нейронных сетях. Он использует двухэтапный он
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#training", "#cv"], "emoji": "🖼️", "ru": {"title": "KV-Edit: Революция в редактировании изображений с сохранением согласованности фона", "desc": "KV-Edit - это новый подход к редактированию изображений, основанный на использовании KV-кэша в DiT-моделях для сохранения согласованности
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#training", "#rl", "#reasoning", "#dataset", "#math", "#open_source"], "emoji": "🧠", "ru": {"title": "SWE-RL: Революция в обучении языковых моделей для задач разработки ПО", "desc": "Данная статья представляет SWE-RL - первый подход к масштабированию обучения с подкреплением (RL) дл
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#multimodal", "#cv"], "emoji": "🎭", "ru": {"title": "ART: революция в генерации многослойных изображений", "desc": "В статье представлен метод Anonymous Region Transformer (ART) для генерации многослойных прозрачных изображений на основе текстового запроса и анонимной разметки облас
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#optimization", "#small_models", "#training", "#benchmark"], "emoji": "🔮", "ru": {"title": "Предсказание будущего больших языковых моделей", "desc": "Статья представляет новый метод прогнозирования производительности больших языковых моделей (LLM) на различных задачах. Авторы предла
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training"], "emoji": "🚀", "ru": {"title": "Стабильное обучение языковых моделей через разделение масштаба и распределения", "desc": "Статья представляет новый метод Scale-Distribution Decoupling (SDD) для стабилизации обучения больших языковых моде
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#architecture", "#training"], "emoji": "🎨", "ru": {"title": "K-LoRA: Эффективное слияние стиля и содержания без дополнительного обучения", "desc": "Статья представляет новый метод K-LoRA для объединения различных LoRA (Low-Rank Adaptation) в генеративн
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#games", "#agents"], "emoji": "🌐", "ru": {"title": "WebGames: тестирование AI-агентов в реальных веб-сценариях", "desc": "WebGames - это комплексный набор тестов для оценки AI-агентов общего назначения, предназначенных для веб-браузинга. Он включает бол
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#architecture", "#cv"], "emoji": "👁️", "ru": {"title": "Токены визуального восприятия: новый шаг в развитии мультимодальных ИИ", "desc": "В этой статье представлена концепция Токенов Визуального Восприятия для мультимодальных больших языковых моделей (ML
[26.02.2025 18:14] Querying the API.
[26.02.2025 18:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4times improvement in correctly answering experimental questions.Curie is open-sourced at https://github.com/Just-Curieous/Curie.
[26.02.2025 18:14] Response: {
  "desc": "Статья представляет Curie - фреймворк ИИ-агента для автоматизации научных экспериментов. Curie состоит из трех ключевых компонентов: модуля внутриагентной строгости, межагентной строгости и модуля знаний об экспериментах. Фреймворк нацелен на повышение надежности, методического контроля и интерпретируемости автоматизированных экспериментов. Тестирование на новом эталонном наборе из 46 вопросов по информатике показало значительное улучшение по сравнению с базовыми методами.",
  "emoji": "🧪",
  "title": "Curie: ИИ-агент для строгих научных экспериментов"
}
[26.02.2025 18:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4times improvement in correctly answering experimental questions.Curie is open-sourced at https://github.com/Just-Curieous/Curie."

[26.02.2025 18:14] Response: ```python
['AGENTS', 'BENCHMARK', 'TRAINING']
```
[26.02.2025 18:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4times improvement in correctly answering experimental questions.Curie is open-sourced at https://github.com/Just-Curieous/Curie."

[26.02.2025 18:14] Response: ```python
['INTERPRETABILITY', 'OPEN_SOURCE', 'SCIENCE']
```
[26.02.2025 18:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Curie, an AI agent framework aimed at improving the rigor of scientific experimentation. Curie incorporates three main components: an intra-agent rigor module for enhancing reliability, an inter-agent rigor module for ensuring methodical control, and an experiment knowledge module for boosting interpretability. The framework was evaluated using a new benchmark consisting of 46 questions from various computer science domains, demonstrating a significant performance improvement over existing methods. The results indicate that Curie can effectively automate rigorous experimentation, making it a valuable tool for researchers.","title":"Curie: Enhancing Rigor in Scientific Experimentation with AI"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Curie, an AI agent framework aimed at improving the rigor of scientific experimentation. Curie incorporates three main components: an intra-agent rigor module for enhancing reliability, an inter-agent rigor module for ensuring methodical control, and an experiment knowledge module for boosting interpretability. The framework was evaluated using a new benchmark consisting of 46 questions from various computer science domains, demonstrating a significant performance improvement over existing methods. The results indicate that Curie can effectively automate rigorous experimentation, making it a valuable tool for researchers.', title='Curie: Enhancing Rigor in Scientific Experimentation with AI'))
[26.02.2025 18:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本论文提出了一种名为Curie的人工智能代理框架，旨在提高科学实验的严谨性。Curie通过三个关键模块实现这一目标：内部代理严谨模块增强可靠性，外部代理严谨模块保持方法控制，以及实验知识模块提升可解释性。我们设计了一个新的实验基准，包含46个问题，涵盖四个计算机科学领域，以评估Curie的性能。与最强基线相比，Curie在正确回答实验问题方面实现了3.4倍的提升。","title":"Curie：提升科学实验严谨性的AI框架"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本论文提出了一种名为Curie的人工智能代理框架，旨在提高科学实验的严谨性。Curie通过三个关键模块实现这一目标：内部代理严谨模块增强可靠性，外部代理严谨模块保持方法控制，以及实验知识模块提升可解释性。我们设计了一个新的实验基准，包含46个问题，涵盖四个计算机科学领域，以评估Curie的性能。与最强基线相比，Curie在正确回答实验问题方面实现了3.4倍的提升。', title='Curie：提升科学实验严谨性的AI框架'))
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#inference", "#optimization", "#reasoning", "#rag", "#training"], "emoji": "🎟️", "ru": {"title": "Лотерейные языковые модели: путь к эффективному сжатию без потери функциональности", "desc": "Статья рассматривает гипотезу лотерейной языковой модели (LLM) в контексте сжатия моделей и
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#multimodal", "#interpretability", "#alignment", "#audio"], "emoji": "👂", "ru": {"title": "Слушать как человек: ИИ с избирательным вниманием", "desc": "Статья представляет новый подход к обработке аудиоданных с использованием больших языковых моделей (LLM), учитывающий избирательное
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#training", "#alignment", "#rlhf"], "emoji": "📊", "ru": {"title": "Оптимизация выбора данных для выравнивания языковых моделей", "desc": "Статья посвящена улучшению процесса выравнивания больших языковых моделей (LLM) с помощью итеративной генерации данных и переобучения модели. Авт
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#interpretability", "#training", "#architecture", "#long_context", "#multimodal", "#machine_translation"], "emoji": "🔍", "ru": {"title": "Заглянуть внутрь Mamba: новый метод интерпретации SSM", "desc": "Статья представляет новый метод интерпретации моделей состояния (SSM), таких как
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#reasoning", "#architecture", "#training"], "emoji": "🧠", "ru": {"title": "Эффективные мультимодальные модели без избыточных данных", "desc": "Представлена линейка мультимодальных моделей Shakti VLM с 1B и 4B параметров, нацеленных на повышение эффект
[26.02.2025 18:14] Using data from previous issue: {"categories": ["#optimization", "#benchmark", "#open_source", "#interpretability", "#training"], "emoji": "🏆", "ru": {"title": "Точная оценка языковых моделей с учетом специфики запросов", "desc": "Статья представляет метод Prompt-to-Leaderboard (P2L) для оценки языковых моделей с учетом конкретных
[26.02.2025 18:14] Querying the API.
[26.02.2025 18:14] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and deep learning architectures, emerging problems -- in areas such as uncertainty quantification, decision-making, causal inference, and distribution shift -- require a deeper engagement with the field of statistics. This paper explores potential areas where statisticians can make important contributions to the development of LLMs, particularly those that aim to engender trustworthiness and transparency for human users. Thus, we focus on issues such as uncertainty quantification, interpretability, fairness, privacy, watermarking and model adaptation. We also consider possible roles for LLMs in statistical analysis. By bridging AI and statistics, we aim to foster a deeper collaboration that advances both the theoretical foundations and practical applications of LLMs, ultimately shaping their role in addressing complex societal challenges.
[26.02.2025 18:14] Response: {
  "desc": "Большие языковые модели (LLM) стали трансформационным инструментом в искусственном интеллекте, демонстрируя впечатляющие возможности в различных задачах. Статья исследует области, где статистики могут внести важный вклад в развитие LLM, особенно для повышения их надежности и прозрачности. Рассматриваются такие вопросы как количественная оценка неопределенности, интерпретируемость, справедливость, приватность и адаптация моделей. Авторы стремятся способствовать более глубокому сотрудничеству между ИИ и статистикой для развития как теоретических основ, так и практических приложений LLM.",
  "emoji": "🤖",
  "title": "Статистика на страже доверия к языковым моделям"
}
[26.02.2025 18:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and deep learning architectures, emerging problems -- in areas such as uncertainty quantification, decision-making, causal inference, and distribution shift -- require a deeper engagement with the field of statistics. This paper explores potential areas where statisticians can make important contributions to the development of LLMs, particularly those that aim to engender trustworthiness and transparency for human users. Thus, we focus on issues such as uncertainty quantification, interpretability, fairness, privacy, watermarking and model adaptation. We also consider possible roles for LLMs in statistical analysis. By bridging AI and statistics, we aim to foster a deeper collaboration that advances both the theoretical foundations and practical applications of LLMs, ultimately shaping their role in addressing complex societal challenges."

[26.02.2025 18:14] Response: ```python
["MATH", "ARCHITECTURE", "TRAINING"]
```
[26.02.2025 18:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have emerged as transformative tools in artificial intelligence (AI), exhibiting remarkable capabilities across diverse tasks such as text generation, reasoning, and decision-making. While their success has primarily been driven by advances in computational power and deep learning architectures, emerging problems -- in areas such as uncertainty quantification, decision-making, causal inference, and distribution shift -- require a deeper engagement with the field of statistics. This paper explores potential areas where statisticians can make important contributions to the development of LLMs, particularly those that aim to engender trustworthiness and transparency for human users. Thus, we focus on issues such as uncertainty quantification, interpretability, fairness, privacy, watermarking and model adaptation. We also consider possible roles for LLMs in statistical analysis. By bridging AI and statistics, we aim to foster a deeper collaboration that advances both the theoretical foundations and practical applications of LLMs, ultimately shaping their role in addressing complex societal challenges."

[26.02.2025 18:15] Response: ```python
['INTERPRETABILITY', 'ETHICS', 'REASONING']
```
[26.02.2025 18:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the intersection of Large Language Models (LLMs) and statistics, highlighting the need for statistical methods to enhance the reliability and transparency of LLMs. It identifies key areas where statisticians can contribute, such as uncertainty quantification, interpretability, and fairness, which are crucial for building trust in AI systems. The authors argue that addressing these statistical challenges can improve decision-making and causal inference in LLM applications. Ultimately, the paper advocates for a collaborative approach between AI and statistics to tackle complex societal issues effectively.","title":"Bridging AI and Statistics for Trustworthy LLMs"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the intersection of Large Language Models (LLMs) and statistics, highlighting the need for statistical methods to enhance the reliability and transparency of LLMs. It identifies key areas where statisticians can contribute, such as uncertainty quantification, interpretability, and fairness, which are crucial for building trust in AI systems. The authors argue that addressing these statistical challenges can improve decision-making and causal inference in LLM applications. Ultimately, the paper advocates for a collaborative approach between AI and statistics to tackle complex societal issues effectively.', title='Bridging AI and Statistics for Trustworthy LLMs'))
[26.02.2025 18:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型（LLMs）在人工智能领域展现了卓越的能力，能够进行文本生成、推理和决策等多种任务。尽管其成功主要依赖于计算能力和深度学习架构的进步，但在不确定性量化、决策制定、因果推断和分布变化等领域，仍需更深入的统计学参与。本文探讨了统计学家在LLMs发展中的重要贡献，特别是在提升模型的可信度和透明度方面。我们关注的不仅是不确定性量化、可解释性、公平性、隐私保护和模型适应性，还考虑了LLMs在统计分析中的潜在角色。","title":"统计学与大型语言模型的深度融合"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型（LLMs）在人工智能领域展现了卓越的能力，能够进行文本生成、推理和决策等多种任务。尽管其成功主要依赖于计算能力和深度学习架构的进步，但在不确定性量化、决策制定、因果推断和分布变化等领域，仍需更深入的统计学参与。本文探讨了统计学家在LLMs发展中的重要贡献，特别是在提升模型的可信度和透明度方面。我们关注的不仅是不确定性量化、可解释性、公平性、隐私保护和模型适应性，还考虑了LLMs在统计分析中的潜在角色。', title='统计学与大型语言模型的深度融合'))
[26.02.2025 18:15] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#benchmark"], "emoji": "🧠", "ru": {"title": "WiCkeD: Повышение сложности языковых тестов для более точной оценки ИИ", "desc": "Статья представляет метод WiCkeD, который повышает сложность существующих тестов с множественным выбором путем случайной замен
[26.02.2025 18:15] Loading Chinese text from previous data.
[26.02.2025 18:15] Renaming data file.
[26.02.2025 18:15] Renaming previous data. hf_papers.json to ./d/2025-02-26.json
[26.02.2025 18:15] Saving new data file.
[26.02.2025 18:15] Generating page.
[26.02.2025 18:15] Renaming previous page.
[26.02.2025 18:15] Renaming previous data. index.html to ./d/2025-02-26.html
[26.02.2025 18:15] [Experimental] Generating Chinese page for reading.
[26.02.2025 18:15] Chinese vocab [{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '基础能力', 'pinyin': 'jī chǔ néng lì', 'trans': 'basic capabilities'}, {'word': '对齐', 'pinyin': 'duì qí', 'trans': 'alignment'}, {'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high quality'}, {'word': '样本', 'pinyin': 'yàng běn', 'trans': 'sample'}, {'word': '涵盖', 'pinyin': 'hán gài', 'trans': 'cover'}, {'word': '多样化', 'pinyin': 'duō yàng huà', 'trans': 'diversified'}, {'word': '复杂', 'pinyin': 'fù zá', 'trans': 'complex'}, {'word': '格式', 'pinyin': 'gé shì', 'trans': 'format'}, {'word': '提升', 'pinyin': 'tí shēng', 'trans': 'improve'}, {'word': '人工标注', 'pinyin': 'rén gōng biāo zhù', 'trans': 'manual annotation'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '监督微调', 'pinyin': 'jiàn dū wēi tiáo', 'trans': 'supervised fine-tuning'}, {'word': '直接偏好优化', 'pinyin': 'zhí jiē piān hào yōu huà', 'trans': 'direct preference optimization'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '保持', 'pinyin': 'bǎo chí', 'trans': 'maintain'}, {'word': '标准', 'pinyin': 'biāo zhǔn', 'trans': 'standard'}, {'word': 'VQA', 'pinyin': 'VQA', 'trans': 'Visual Question Answering'}, {'word': '检查点', 'pinyin': 'jiǎn chá diǎn', 'trans': 'checkpoint'}]
[26.02.2025 18:15] Renaming previous Chinese page.
[26.02.2025 18:15] Renaming previous data. zh.html to ./d/2025-02-25_zh_reading_task.html
[26.02.2025 18:15] Writing Chinese reading task.
[26.02.2025 18:15] Writing result.
[26.02.2025 18:15] Renaming log file.
[26.02.2025 18:15] Renaming previous data. log.txt to ./logs/2025-02-26_last_log.txt
