[27.05.2025 05:13] Read previous papers.
[27.05.2025 05:13] Generating top page (month).
[27.05.2025 05:13] Writing top page (month).
[27.05.2025 06:16] Read previous papers.
[27.05.2025 06:16] Get feed.
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19147
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16348
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20258
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20259
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19914
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18675
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18545
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19815
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18536
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19209
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19457
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18601
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20256
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20152
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19752
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19602
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19590
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.16972
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.13426
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19427
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20254
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19949
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17652
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.10887
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20278
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19788
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19706
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19640
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19630
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19443
[27.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.19439
[27.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.18759
[27.05.2025 06:16] Extract page data from URL. URL: https://huggingface.co/papers/2505.18384
[27.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.15957
[27.05.2025 06:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.05.2025 06:16] No deleted papers detected.
[27.05.2025 06:16] Downloading and parsing papers (pdf, html). Total: 34.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19147.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19147.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19147.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16348.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16348.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16348.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20258.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20258.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20258.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20259.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20259.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20259.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19914.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19914.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19914.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.18675.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.18675.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.18675.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.18545.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.18545.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.18545.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19815.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19815.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19815.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.18536.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.18536.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.18536.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19209.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19209.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19209.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19457.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19457.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19457.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.18601.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.18601.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.18601.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20256.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20256.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20256.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20152.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20152.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20152.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19752.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19752.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19752.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19602.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19602.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19602.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19590.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19590.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19590.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.16972.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.16972.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.16972.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.13426.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.13426.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.13426.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19427.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19427.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19427.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20254.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20254.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20254.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19949.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19949.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19949.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.17652.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.17652.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.17652.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.10887.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.10887.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.10887.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.20278.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.20278.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.20278.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19788.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19788.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19788.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19706.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19706.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19706.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19640.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19640.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19640.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19630.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19630.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19630.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19443.
[27.05.2025 06:16] Extra JSON file exists (./assets/json/2505.19443.json), skip PDF parsing.
[27.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.19443.json), skip HTML parsing.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.19439.
[27.05.2025 06:16] Downloading paper 2505.19439 from http://arxiv.org/pdf/2505.19439v1...
[27.05.2025 06:16] Extracting affiliations from text.
[27.05.2025 06:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 9 3 4 9 1 . 5 0 5 2 : r Surrogate Signals from Format and Length: Reinforcement Learning for Solving Mathematical Problems without Ground Truth Answers Rihui Xin1, Han Liu1,2, Zecheng Wang1,3, Yupeng Zhang1, Dianbo Sui3, Xiaolin Hu*2, Bingning Wang*1 1Baichuan Inc. 2Tsinghua University 3Harbin Institute of Technology "
[27.05.2025 06:16] Response: ```python
["Baichuan Inc.", "Tsinghua University", "Harbin Institute of Technology"]
```
[27.05.2025 06:16] Deleting PDF ./assets/pdf/2505.19439.pdf.
[27.05.2025 06:16] Success.
[27.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.18759.
[27.05.2025 06:17] Downloading paper 2505.18759 from http://arxiv.org/pdf/2505.18759v1...
[27.05.2025 06:17] Extracting affiliations from text.
[27.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 2 ] . [ 1 9 5 7 8 1 . 5 0 5 2 : r The Quest for Efficient Reasoning: Data-Centric Benchmark to CoT Distillation Ruichen Zhang 1, Rana Muhammad Shahroz Khan1, Zhen Tan2, Dawei Li2, Song Wang3, Tianlong Chen1 1University of North Carolina at Chapel Hill,2Arizona State University, 3University of Virginia "
[27.05.2025 06:17] Response: ```python
["University of North Carolina at Chapel Hill", "Arizona State University", "University of Virginia"]
```
[27.05.2025 06:17] Deleting PDF ./assets/pdf/2505.18759.pdf.
[27.05.2025 06:17] Success.
[27.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.18384.
[27.05.2025 06:17] Downloading paper 2505.18384 from http://arxiv.org/pdf/2505.18384v1...
[27.05.2025 06:17] Extracting affiliations from text.
[27.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 2 ] . [ 1 4 8 3 8 1 . 5 0 5 2 : r a Boyi Wei1 Benedikt Stroebl1 Jiacen Xu2 Joie Zhang1 Zhou Li2 Peter Henderson1 1Princeton University 2University of California, Irvine "
[27.05.2025 06:17] Response: ```python
["Princeton University", "University of California, Irvine"]
```
[27.05.2025 06:17] Deleting PDF ./assets/pdf/2505.18384.pdf.
[27.05.2025 06:17] Success.
[27.05.2025 06:17] Downloading and parsing paper https://huggingface.co/papers/2505.15957.
[27.05.2025 06:17] Extra JSON file exists (./assets/json/2505.15957.json), skip PDF parsing.
[27.05.2025 06:17] Paper image links file exists (./assets/img_data/2505.15957.json), skip HTML parsing.
[27.05.2025 06:17] Success.
[27.05.2025 06:17] Enriching papers with extra data.
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 0. The rapid advancement of large language models (LLMs) and multi-modal LLMs (MLLMs) has historically relied on model-centric scaling through increasing parameter counts from millions to hundreds of billions to drive performance gains. However, as we approach hardware limits on model size, the dominan...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 1. MEMENTO evaluates personalized memory utilization in embodied agents, revealing limitations in understanding user semantics and routines.  					AI-generated summary 				 Embodied agents empowered by large language models (LLMs) have shown strong performance in household object rearrangement tasks. H...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 2. Adaptive Reasoning Model (ARM) uses Ada-GRPO to reduce token usage and improve efficiency across different reasoning modes.  					AI-generated summary 				 While large reasoning models demonstrate strong performance on complex tasks, they lack the ability to adjust reasoning token usage based on tas...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 3. A lifecycle safety alignment framework employs a Meta-Attacker and Defender to adapt LLMs to novel jailbreaking strategies, improving robustness in deployment.  					AI-generated summary 				 LLMs have made impressive progress, but their growing capabilities also expose them to highly flexible jailb...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 4. Enigmata is a comprehensive suite for improving LLMs in puzzle reasoning through scalable multi-task RL training, leading to better performance on benchmarks and advanced math tasks.  					AI-generated summary 				 Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at advance...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 5. Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic. However, their capacity for reasoning...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 6. Large language models (LLMs) often exhibit strong biases, e.g, against women or in favor of the number 7. We investigate whether LLMs would be able to output less biased answers when allowed to observe their prior answers to the same question in a multi-turn conversation. To understand which types o...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 7. LLM reasoning is understood through a meta-learning framework, treating reasoning as pseudo-gradient descent and questions as individual tasks, which enhances generalization and provides practical insights for improvement.  					AI-generated summary 				 We propose a novel framework for comprehendin...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 8. Standing in 2025, at a critical juncture in the pursuit of Artificial General Intelligence (AGI), reinforcement fine-tuning (RFT) has demonstrated significant potential in enhancing the reasoning capability of large language models (LLMs) and has led to the development of cutting-edge AI models such...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 9. A method is proposed to generate detailed scientific hypotheses using LLMs by defining and optimizing a latent reward landscape, outperforming baselines in benchmark evaluations.  					AI-generated summary 				 Large language models (LLMs) have shown promise in automating scientific hypothesis gener...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 10. BizFinBench is a benchmark for evaluating large language models in financial applications, revealing distinct performance patterns across various tasks.  					AI-generated summary 				 Large language models excel in general tasks, yet assessing their reliability in logic-heavy, precision-critical do...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 11. Flex-Judge uses minimal textual reasoning data to generalize across multiple modalities and evaluation formats, outperforming state-of-the-art models in multimodal evaluations.  					AI-generated summary 				 Human-generated reward signals are critical for aligning generative models with human prefe...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 12. An end-to-end reinforcement learning framework, Omni-R1, achieves superior performance in long-horizon video-audio reasoning and fine-grained pixel understanding tasks by combining global reasoning and detail understanding systems.  					AI-generated summary 				 Long-horizon video-audio reasoning a...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 13. A novel hard negative contrastive learning framework improves geometric reasoning in Large Multimodal Models, significantly enhancing their performance compared to existing models.  					AI-generated summary 				 Benefiting from contrastively trained visual encoders on large-scale natural scene imag...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 14. A novel framework, Discrete Markov Bridge, is introduced for discrete data modeling with Matrix Learning and Score Learning components, demonstrating superior performance compared to existing methods on Text8 and CIFAR-10 datasets.  					AI-generated summary 				 Discrete diffusion has recently emer...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 15. ScaleKV compresses the KV cache in Visual Autoregressive models by differentiating drafters and refiners across transformer layers, reducing memory consumption while maintaining high fidelity.  					AI-generated summary 				 Visual Autoregressive (VAR) modeling has garnered significant attention for...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 16. Intuitor, a Reinforcement Learning from Internal Feedback method, uses self-certainty as a reward signal to enable unsupervised learning of large language models, achieving performance comparable to GRPO on benchmarks and superior generalization.  					AI-generated summary 				 Training large langua...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 17. Recent advances in Automatic Speech Recognition (ASR) have been largely fueled by massive speech corpora. However, extending coverage to diverse languages with limited resources remains a formidable challenge. This paper introduces Speech Back-Translation, a scalable pipeline that improves multiling...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 18. VLM-Gym addresses the "knowing-doing" gap in Vision-Language Models by training them in a diverse RL environment, leading to enhanced perception and reasoning abilities that surpass existing models in interactive games.  					AI-generated summary 				 Vision-Language Models (VLMs) excel in many dire...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 19. WINA, a training-free sparse activation framework for large language models, improves inference accuracy by considering hidden state magnitudes and weight matrix norms, outperforming existing methods.  					AI-generated summary 				 The growing computational demands of large language models (LLMs) m...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 20. Prioritizing feature consistency in sparse autoencoders improves mechanistic interpretability of neural networks by ensuring reliable and interpretable features.  					AI-generated summary 				 Sparse Autoencoders (SAEs) are a prominent tool in mechanistic interpretability (MI) for decomposing neura...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 21. Influence functions are used to attribute LLMs' reasoning in math and coding to individual training elements, revealing cross-domain effects and enabling a reweighting strategy that improves model accuracy.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable rea...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 22. CDAS addresses low sample efficiency in reinforcement learning by aligning model competence with problem difficulty, improving both accuracy and efficiency in mathematical benchmarks.  					AI-generated summary 				 Reinforcement learning exhibits potential in enhancing the reasoning abilities of la...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 23. InfantAgent-Next is a multimodal agent that integrates tool-based and vision models in a modular architecture to solve various benchmarks, including OSWorld, GAIA, and SWE-Bench.  					AI-generated summary 				 This paper introduces InfantAgent-Next, a generalist agent capable of interacting with co...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 24. Large language models excel at pattern matching, yet often fall short in systematic compositional generalization. We propose the coverage principle: a data-centric framework showing that models relying primarily on pattern matching for compositional tasks cannot reliably generalize beyond substituti...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 25. Multi-Turn Decomposition improves efficiency in large reasoning models by breaking down chain-of-thought into manageable turns, reducing token usage and latency while maintaining performance.  					AI-generated summary 				 Large Reasoning Models (LRMs) are criticized for the excessively lengthy Cha...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 26. PathFinder-PRM, a hierarchical and error-aware Process Reward Model, improves mathematical problem-solving by fine-grained error classification and step correctness estimation, achieving state-of-the-art PRMScore with reduced data usage.  					AI-generated summary 				 Large Language Models (LLMs) a...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 27. A reinforcement learning-guided training paradigm enhances large language models' reasoning efficiency and performance for multi-hop questions by interleaving thinking and answering.  					AI-generated summary 				 Long chain-of-thought (CoT) significantly enhances large language models' (LLM) reaso...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 28. Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Existing systems rely on a one-way information transmission mode where patients must fully desc...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 29. A review contrasts vibe coding and agentic coding paradigms, highlighting their differences in interaction, autonomy, and application areas in AI-assisted software development.  					AI-generated summary 				 This review presents a comprehensive analysis of two emerging paradigms in AI-assisted soft...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 30. Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costl...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 31. Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the ef...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 32. Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.  					AI-generated summary 				 Foundation models are increasingly becoming better autonomous programmers, ...
[27.05.2025 06:17] ********************************************************************************
[27.05.2025 06:17] Abstract 33. A survey proposes a systematic taxonomy for evaluating large audio-language models across dimensions including auditory awareness, knowledge reasoning, dialogue ability, and fairness, to address fragmented benchmarks in the field.  					AI-generated summary 				 With advancements in large audio-lang...
[27.05.2025 06:17] Read previous papers.
[27.05.2025 06:17] Generating reviews via LLM API.
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#data", "#math", "#optimization", "#long_context", "#survey"], "emoji": "üóúÔ∏è", "ru": {"title": "–°–∂–∞—Ç–∏–µ —Ç–æ–∫–µ–Ω–æ–≤: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∫ —Å–∂–∞—Ç–∏—é –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ä–∞–∑–≤–∏—Ç–∏—è –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#agents", "#interpretability", "#multimodal", "#agi", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏ –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤: –ø—É—Ç—å –∫ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏", "desc": "MEMENTO - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø–ª–æ—â–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞–º—è
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#inference", "#optimization", "#training"], "emoji": "üß†", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ –ò–ò", "desc": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (ARM) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Ada-GRPO –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ 
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#inference", "#training", "#alignment", "#security"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –∑–∞—â–∏—Ç—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç –Ω–æ–≤—ã—Ö –∞—Ç–∞–∫", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º—É –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ —É—Å–ª–æ–≤–∏—è—Ö –Ω–æ–≤—ã—Ö –∞—Ç
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#math", "#training", "#rl", "#optimization", "#benchmark", "#dataset"], "emoji": "üß©", "ru": {"title": "Enigmata: –ø—Ä–æ–∫–∞—á–∫–∞ –ª–æ–≥–∏–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∏", "desc": "Enigmata - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤ —Ä–µ—à–µ–Ω–∏—è –≥–æ–ª–æ–≤–æ–ª–æ–º–æ–∫ —É –±–æ–ª—å
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark", "#cv", "#open_source"], "emoji": "üó∫Ô∏è", "ru": {"title": "ReasonMap: –Ω–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "ReasonMap - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –≤–∏–∑—É–∞–ª—å–Ω–æ–π
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#data", "#ethics", "#hallucinations", "#benchmark", "#rlhf"], "emoji": "ü§ñ", "ru": {"title": "–°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö —á–µ—Ä–µ–∑ –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –¥–∏–∞–ª–æ–≥", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∏–∑—É—á–µ–Ω–∏—é –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM) –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –µ–µ —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#math", "#training"], "emoji": "üß†", "ru": {"title": "–†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è LLM –∫–∞–∫ –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏–µ: –Ω–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —á–µ—Ä–µ–∑
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#training", "#reasoning", "#benchmark", "#rlhf", "#agi", "#rl"], "emoji": "üß†", "ru": {"title": "RFT: –∫–ª—é—á –∫ —É—Å–∏–ª–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é –º–µ—Ç–æ–¥–∞ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RFT) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#science", "#rlhf", "#benchmark", "#multimodal", "#optimization"], "emoji": "üß™", "ru": {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–∂–µ –Ω–∞—É—á–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: –æ—Ç –∏–¥–µ–∏ –∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –≥–∏–ø–æ—Ç–µ–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LL
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#benchmark", "#science", "#reasoning", "#dataset", "#open_source"], "emoji": "üíπ", "ru": {"title": "BizFinBench: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ü–µ–Ω–∫–∏ LLM –≤ —Ñ–∏–Ω–∞–Ω—Å–∞—Ö", "desc": "BizFinBench - —ç—Ç–æ –Ω–æ–≤—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö. –û–Ω —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 67
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#alignment", "#benchmark", "#multimodal", "#transfer_learning"], "emoji": "üß†", "ru": {"title": "–†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ - –∫–ª—é—á –∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ", "desc": "Flex-Judge - —ç—Ç–æ –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º–∏–Ω–∏–º–∞–ª—å–Ω—ã
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#video", "#hallucinations", "#benchmark", "#multimodal", "#optimization"], "emoji": "ü§ñ", "ru": {"title": "–£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä—É–¥–∞: –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏", "desc": "Omni-R1 - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –∑
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#training", "#reasoning", "#dataset", "#open_source"], "emoji": "üìê", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–º –º—ã—à–ª–µ–Ω–∏–∏ –ò–ò —á–µ—Ä–µ–∑ —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ª–æ
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#data", "#benchmark", "#diffusion", "#dataset", "#optimization", "#architecture"], "emoji": "üåâ", "ru": {"title": "–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–π –º–∞—Ä–∫–æ–≤—Å–∫–∏–π –º–æ—Å—Ç: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Discrete Markov Bridge –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#inference", "#optimization", "#architecture"], "emoji": "üóúÔ∏è", "ru": {"title": "ScaleKV: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –∫—ç—à–∞ –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª–µ–π", "desc": "ScaleKV - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–∂–∞—Ç–∏—è KV-–∫—ç—à–∞ –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω —Ä–∞–∑–¥–µ–ª—è–µ—Ç —Å–ª–æ–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –Ω–∞ –¥—Ä–∞—Ñ—Ç–µ—Ä—ã –∏ —Ä–µ—Ñ–∞–π
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#rlhf", "#optimization"], "emoji": "üß†", "ru": {"title": "–°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –ò–ò: –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∫–∞–∫ –¥–≤–∏–≥–∞—Ç–µ–ª—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Intuitor. –≠—Ç–æ—Ç –º
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#data", "#multilingual", "#low_resource", "#dataset", "#audio", "#synthetic"], "emoji": "üó£Ô∏è", "ru": {"title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ—á—å –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –¥–ª—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ ASR", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Speech Back-Translation –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∞–≤—Ç–æ–º–∞
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#multimodal", "#training", "#reasoning", "#open_source", "#agents", "#games", "#optimization", "#rl"], "emoji": "üéÆ", "ru": {"title": "–ü—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —Ä–∞–∑—Ä—ã–≤–∞ –º–µ–∂–¥—É –∑–Ω–∞–Ω–∏–µ–º –∏ –¥–µ–π—Å—Ç–≤–∏–µ–º –≤ Vision-Language Models —Å –ø–æ–º–æ—â—å—é RL", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç VLM-Gym - —Å—Ä–µ–¥—É –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#inference", "#training", "#open_source", "#optimization", "#architecture"], "emoji": "üöÄ", "ru": {"title": "WINA: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "WINA - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –Ω–µ —Ç—Ä–µ–±—É—é—â–∏–π –¥–æ–ø–æ–ª
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#interpretability", "#training", "#math", "#architecture"], "emoji": "üîç", "ru": {"title": "–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ - –∫–ª—é—á –∫ –Ω–∞–¥–µ–∂–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π", "desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–µ—Ö–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#reasoning", "#data", "#dataset", "#optimization", "#interpretability"], "emoji": "üß†", "ru": {"title": "–§—É–Ω–∫—Ü–∏–∏ –≤–ª–∏—è–Ω–∏—è —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç —Å–µ–∫—Ä–µ—Ç—ã –æ–±—É—á–µ–Ω–∏—è LLM –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–ª–∏—è–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∫–ª–∞–¥–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#math", "#optimization"], "emoji": "üéØ", "ru": {"title": "–¢–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: CDAS –ø–æ–≤—ã—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "CDAS (Competence-Difficulty Alignment Sampling) - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –Ω–∞–ø—Ä–∞
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#agi", "#open_source", "#benchmark", "#agents", "#multimodal", "#architecture"], "emoji": "ü§ñ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á", "desc": "InfantAgent-Next - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç, –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—â–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–æ
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#interpretability", "#training", "#reasoning", "#data", "#architecture"], "emoji": "üß†", "ru": {"title": "–ü—Ä–∏–Ω—Ü–∏–ø –ø–æ–∫—Ä—ã—Ç–∏—è: –Ω–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –≤ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –æ–±–ª–∞—Å—Ç–∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#rl", "#training", "#reasoning", "#benchmark", "#optimization"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ —à–∞–≥–∞–º: MinD –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É LRM", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Multi-Turn Decomposition (MinD) –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#training", "#math", "#hallucinations", "#dataset", "#optimization"], "emoji": "üßÆ", "ru": {"title": "–¢–æ—á–Ω–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è –≤ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö —Å PathFinder-PRM", "desc": "PathFinder-PRM - —ç—Ç–æ –Ω–æ–≤–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞, —É—á–∏—Ç—ã–≤–∞—é—â–∞—è –æ—à–∏–±–∫–∏, 
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#reasoning", "#math", "#rlhf", "#training", "#rl", "#optimization"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ò–ò: –º—ã—Å–ª—å –∏ –æ—Ç–≤–µ—Ç –≤ –æ–¥–Ω–æ–º –ø–æ—Ç–æ–∫–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã—Ö –∑–∞–¥–∞—á —Ä–∞—Å—Å—É–∂–¥–µ–Ω
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#training", "#reasoning", "#science", "#healthcare", "#dataset", "#games", "#optimization", "#rl"], "emoji": "ü©∫", "ru": {"title": "–£–º–Ω—ã–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –¥–æ–∫—Ç–æ—Ä: –ò–ò —É—á–∏—Ç—Å—è –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥ —Å –ø–∞—Ü–∏–µ–Ω—Ç–æ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç DoctorAgent-RL - —Å–∏—Å—Ç–µ–º—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º 
[27.05.2025 06:17] Using data from previous issue: {"categories": ["#survey", "#agents", "#architecture", "#interpretability"], "emoji": "ü§ñ", "ru": {"title": "–í–∞–π–± vs –ê–≥–µ–Ω—Ç: –ù–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –ò–ò-–∞—Å—Å–∏—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–≤—É—Ö –ø–∞—Ä–∞–¥–∏–≥–º –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –ò–ò: –≤–∞–π–±-–∫–æ–¥–∏
[27.05.2025 06:17] Querying the API.
[27.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costly, and sometimes unfeasible. This research delves into the utilization of format and length as surrogate signals to train LLMs for mathematical problem-solving, bypassing the need for traditional ground truth answers.Our study shows that a reward function centered on format correctness alone can yield performance improvements comparable to the standard GRPO algorithm in early phases. Recognizing the limitations of format-only rewards in the later phases, we incorporate length-based rewards. The resulting GRPO approach, leveraging format-length surrogate signals, not only matches but surpasses the performance of the standard GRPO algorithm relying on ground truth answers in certain scenarios, achieving 40.0\% accuracy on AIME2024 with a 7B base model. Through systematic exploration and experimentation, this research not only offers a practical solution for training LLMs to solve mathematical problems and reducing the dependence on extensive ground truth data collection, but also reveals the essence of why our label-free approach succeeds: base model is like an excellent student who has already mastered mathematical and logical reasoning skills, but performs poorly on the test paper, it simply needs to develop good answering habits to achieve outstanding results in exams , in other words, to unlock the capabilities it already possesses.
[27.05.2025 06:17] Response: {
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ñ–æ—Ä–º–∞—Ç–∞ –∏ –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–æ–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Ä–µ—à–µ–Ω–∏—é –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–∞—Ö. –ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è —Ç–æ–ª—å–∫–æ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º–∞—Ç–∞, –º–æ–∂–µ—Ç –¥–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Å—Ä–∞–≤–Ω–∏–º—ã–µ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º GRPO –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —ç—Ç–∞–ø–∞—Ö. –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ GRPO, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ñ–æ—Ä–º–∞—Ç–∞ –∏ –¥–ª–∏–Ω—ã, –Ω–µ —Ç–æ–ª—å–∫–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç, –Ω–æ –∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ GRPO –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç —Å—É—Ç—å —É—Å–ø–µ—Ö–∞ –ø–æ–¥—Ö–æ–¥–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫: –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –ø–æ–¥–æ–±–Ω–∞ –æ—Ç–ª–∏—á–Ω–æ–º—É —É—á–µ–Ω–∏–∫—É, –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ —Ä–∞–∑–≤–∏—Ç—å —Ö–æ—Ä–æ—à–∏–µ –ø—Ä–∏–≤—ã—á–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤—ã–¥–∞—é—â–∏—Ö—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ö.",
  "emoji": "üßÆ",
  "title": "–û–±—É—á–µ–Ω–∏–µ –ò–ò –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"
}
[27.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costly, and sometimes unfeasible. This research delves into the utilization of format and length as surrogate signals to train LLMs for mathematical problem-solving, bypassing the need for traditional ground truth answers.Our study shows that a reward function centered on format correctness alone can yield performance improvements comparable to the standard GRPO algorithm in early phases. Recognizing the limitations of format-only rewards in the later phases, we incorporate length-based rewards. The resulting GRPO approach, leveraging format-length surrogate signals, not only matches but surpasses the performance of the standard GRPO algorithm relying on ground truth answers in certain scenarios, achieving 40.0\% accuracy on AIME2024 with a 7B base model. Through systematic exploration and experimentation, this research not only offers a practical solution for training LLMs to solve mathematical problems and reducing the dependence on extensive ground truth data collection, but also reveals the essence of why our label-free approach succeeds: base model is like an excellent student who has already mastered mathematical and logical reasoning skills, but performs poorly on the test paper, it simply needs to develop good answering habits to achieve outstanding results in exams , in other words, to unlock the capabilities it already possesses."

[27.05.2025 06:17] Response: ```python
['RL', 'MATH', 'TRAINING']
```
[27.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costly, and sometimes unfeasible. This research delves into the utilization of format and length as surrogate signals to train LLMs for mathematical problem-solving, bypassing the need for traditional ground truth answers.Our study shows that a reward function centered on format correctness alone can yield performance improvements comparable to the standard GRPO algorithm in early phases. Recognizing the limitations of format-only rewards in the later phases, we incorporate length-based rewards. The resulting GRPO approach, leveraging format-length surrogate signals, not only matches but surpasses the performance of the standard GRPO algorithm relying on ground truth answers in certain scenarios, achieving 40.0\% accuracy on AIME2024 with a 7B base model. Through systematic exploration and experimentation, this research not only offers a practical solution for training LLMs to solve mathematical problems and reducing the dependence on extensive ground truth data collection, but also reveals the essence of why our label-free approach succeeds: base model is like an excellent student who has already mastered mathematical and logical reasoning skills, but performs poorly on the test paper, it simply needs to develop good answering habits to achieve outstanding results in exams , in other words, to unlock the capabilities it already possesses."

[27.05.2025 06:17] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[27.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores how to train Large Language Models (LLMs) for solving mathematical problems without relying on traditional ground truth answers. It introduces the idea of using format and length as surrogate signals to guide the training process. The research demonstrates that a reward function focused on format correctness can improve performance significantly, especially in the early training phases. By incorporating length-based rewards later on, the proposed GRPO approach not only matches but exceeds the performance of standard methods that depend on ground truth data, achieving notable accuracy on mathematical problem sets.","title":"Unlocking LLMs: Training with Format and Length Signals"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores how to train Large Language Models (LLMs) for solving mathematical problems without relying on traditional ground truth answers. It introduces the idea of using format and length as surrogate signals to guide the training process. The research demonstrates that a reward function focused on format correctness can improve performance significantly, especially in the early training phases. By incorporating length-based rewards later on, the proposed GRPO approach not only matches but exceeds the performance of standard methods that depend on ground truth data, achieving notable accuracy on mathematical problem sets.', title='Unlocking LLMs: Training with Format and Length Signals'))
[27.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Ê†ºÂºèÂíåÈïøÂ∫¶‰Ωú‰∏∫Êõø‰ª£‰ø°Âè∑ÔºåËÆ≠ÁªÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËß£ÂÜ≥Êï∞Â≠¶ÈóÆÈ¢òÔºåËÄåÊó†ÈúÄ‰º†ÁªüÁöÑÁúüÂÆûÁ≠îÊ°à„ÄÇÊàë‰ª¨ÂèëÁé∞Ôºå‰ªÖ‰æùÈù†Ê†ºÂºèÊ≠£Á°ÆÊÄßÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÂú®Êó©ÊúüÈò∂ÊÆµÂèØ‰ª•Ëé∑Âæó‰∏éÊ†áÂáÜGRPOÁÆóÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÈöèÁùÄËÆ≠ÁªÉÁöÑÊ∑±ÂÖ•ÔºåÊ†ºÂºèÂ•ñÂä±ÁöÑÂ±ÄÈôêÊÄßÊòæÁé∞ÔºåÂõ†Ê≠§Êàë‰ª¨ÂºïÂÖ•‰∫ÜÂü∫‰∫éÈïøÂ∫¶ÁöÑÂ•ñÂä±„ÄÇÊúÄÁªàÁöÑGRPOÊñπÊ≥ïÂà©Áî®Ê†ºÂºè-ÈïøÂ∫¶Êõø‰ª£‰ø°Âè∑ÔºåÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ã‰∏ç‰ªÖÂåπÈÖç‰∫ÜÊ†áÂáÜGRPOÁÆóÊ≥ïÁöÑË°®Áé∞ÔºåËøòË∂ÖË∂ä‰∫ÜÂÖ∂Âú®AIME2024‰∏äÁöÑË°®Áé∞ÔºåËææÂà∞‰∫Ü40.0%ÁöÑÂáÜÁ°ÆÁéá„ÄÇ","title":"Âà©Áî®Ê†ºÂºè‰∏éÈïøÂ∫¶ÊèêÂçáÊï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Ê†ºÂºèÂíåÈïøÂ∫¶‰Ωú‰∏∫Êõø‰ª£‰ø°Âè∑ÔºåËÆ≠ÁªÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËß£ÂÜ≥Êï∞Â≠¶ÈóÆÈ¢òÔºåËÄåÊó†ÈúÄ‰º†ÁªüÁöÑÁúüÂÆûÁ≠îÊ°à„ÄÇÊàë‰ª¨ÂèëÁé∞Ôºå‰ªÖ‰æùÈù†Ê†ºÂºèÊ≠£Á°ÆÊÄßÁöÑÂ•ñÂä±ÂáΩÊï∞ÔºåÂú®Êó©ÊúüÈò∂ÊÆµÂèØ‰ª•Ëé∑Âæó‰∏éÊ†áÂáÜGRPOÁÆóÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÈöèÁùÄËÆ≠ÁªÉÁöÑÊ∑±ÂÖ•ÔºåÊ†ºÂºèÂ•ñÂä±ÁöÑÂ±ÄÈôêÊÄßÊòæÁé∞ÔºåÂõ†Ê≠§Êàë‰ª¨ÂºïÂÖ•‰∫ÜÂü∫‰∫éÈïøÂ∫¶ÁöÑÂ•ñÂä±„ÄÇÊúÄÁªàÁöÑGRPOÊñπÊ≥ïÂà©Áî®Ê†ºÂºè-ÈïøÂ∫¶Êõø‰ª£‰ø°Âè∑ÔºåÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ã‰∏ç‰ªÖÂåπÈÖç‰∫ÜÊ†áÂáÜGRPOÁÆóÊ≥ïÁöÑË°®Áé∞ÔºåËøòË∂ÖË∂ä‰∫ÜÂÖ∂Âú®AIME2024‰∏äÁöÑË°®Áé∞ÔºåËææÂà∞‰∫Ü40.0%ÁöÑÂáÜÁ°ÆÁéá„ÄÇ', title='Âà©Áî®Ê†ºÂºè‰∏éÈïøÂ∫¶ÊèêÂçáÊï∞Â≠¶ÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõ'))
[27.05.2025 06:17] Querying the API.
[27.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the effect of each distillation approach. This paper introduces DC-CoT, the first data-centric benchmark that investigates data manipulation in chain-of-thought (CoT) distillation from method, model and data perspectives. Utilizing various teacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of these data manipulations on student model performance across multiple reasoning datasets, with a focus on in-distribution (IID) and out-of-distribution (OOD) generalization, and cross-domain transfer. Our findings aim to provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. The dataset can be found at https://huggingface.co/datasets/rana-shahroz/DC-COT, while our code is shared in https://anonymous.4open.science/r/DC-COT-FF4C/.
[27.05.2025 06:17] Response: {
  "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç DC-CoT - –ø–µ—Ä–≤—ã–π –¥–∞—Ç–∞-—Ü–µ–Ω—Ç—Ä–∏—á–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (Chain-of-Thought, CoT). –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–∑—É—á–∞—é—Ç –≤–ª–∏—è–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–Ω—ã–µ —É—á–∏—Ç–µ–ª—å—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã. –û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª—è–µ—Ç—Å—è –æ–±–æ–±—â–µ–Ω–∏—é –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∏ –≤–Ω–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –ø–µ—Ä–µ–Ω–æ—Å—É –∑–Ω–∞–Ω–∏–π –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø—Ä–æ—Ü–µ—Å—Å–∞ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ CoT –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª–µ–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —Å–∏–ª—å–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏ –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é.",
  "emoji": "üß†",
  "title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏"
}
[27.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the effect of each distillation approach. This paper introduces DC-CoT, the first data-centric benchmark that investigates data manipulation in chain-of-thought (CoT) distillation from method, model and data perspectives. Utilizing various teacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of these data manipulations on student model performance across multiple reasoning datasets, with a focus on in-distribution (IID) and out-of-distribution (OOD) generalization, and cross-domain transfer. Our findings aim to provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. The dataset can be found at https://huggingface.co/datasets/rana-shahroz/DC-COT, while our code is shared in https://anonymous.4open.science/r/DC-COT-FF4C/."

[27.05.2025 06:17] Response: ```python
['DATASET', 'BENCHMARK', 'TRAINING']
```
[27.05.2025 06:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the effect of each distillation approach. This paper introduces DC-CoT, the first data-centric benchmark that investigates data manipulation in chain-of-thought (CoT) distillation from method, model and data perspectives. Utilizing various teacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of these data manipulations on student model performance across multiple reasoning datasets, with a focus on in-distribution (IID) and out-of-distribution (OOD) generalization, and cross-domain transfer. Our findings aim to provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. The dataset can be found at https://huggingface.co/datasets/rana-shahroz/DC-COT, while our code is shared in https://anonymous.4open.science/r/DC-COT-FF4C/."

[27.05.2025 06:17] Response: ```python
['REASONING', 'OPTIMIZATION', 'TRANSFER_LEARNING']
```
[27.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents DC-CoT, a new benchmark for evaluating data-centric distillation methods in training smaller student Large Language Models (LLMs) while maintaining their reasoning capabilities. It explores various data manipulation techniques, such as augmentation, selection, and mixing, to understand their effects on model performance. The study uses different teacher and student model architectures to assess how these techniques influence both in-distribution and out-of-distribution generalization. The results aim to guide best practices for optimizing chain-of-thought distillation, making advanced reasoning models more efficient and accessible.","title":"Optimizing Reasoning in Smaller Models with Data-Centric Distillation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents DC-CoT, a new benchmark for evaluating data-centric distillation methods in training smaller student Large Language Models (LLMs) while maintaining their reasoning capabilities. It explores various data manipulation techniques, such as augmentation, selection, and mixing, to understand their effects on model performance. The study uses different teacher and student model architectures to assess how these techniques influence both in-distribution and out-of-distribution generalization. The results aim to guide best practices for optimizing chain-of-thought distillation, making advanced reasoning models more efficient and accessible.', title='Optimizing Reasoning in Smaller Models with Data-Centric Distillation'))
[27.05.2025 06:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫DC-CoTÁöÑÊï∞ÊçÆ‰∏≠ÂøÉÂü∫ÂáÜÔºåÊó®Âú®Á≥ªÁªüËØÑ‰º∞Êï∞ÊçÆÂ¢ûÂº∫„ÄÅÈÄâÊã©ÂíåÊ∑∑ÂêàÂØπÈìæÂºèÊé®ÁêÜÔºàCoTÔºâËí∏È¶èÁöÑÂΩ±Âìç„ÄÇÈÄöËøá‰ΩøÁî®Â§öÁßçÊïôÂ∏àÊ®°ÂûãÂíåÂ≠¶ÁîüÊû∂ÊûÑÔºåÊàë‰ª¨ÂØπÊï∞ÊçÆÊìç‰ΩúÂØπÂ≠¶ÁîüÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçËøõË°å‰∫Ü‰∏•Ê†ºËØÑ‰º∞ÔºåÈáçÁÇπÂÖ≥Ê≥®Âú®ÂàÜÂ∏ÉÂÜÖÂíåÂàÜÂ∏ÉÂ§ñÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁ†îÁ©∂ÁªìÊûú‰∏∫‰ºòÂåñCoTËí∏È¶èÊèê‰æõ‰∫ÜÂèØË°åÁöÑËßÅËß£ÂíåÊúÄ‰Ω≥ÂÆûË∑µÔºå‰øÉËøõ‰∫ÜÊõ¥È´òÊïàÁöÑÊé®ÁêÜÊ®°ÂûãÁöÑÂºÄÂèë„ÄÇËØ•Êï∞ÊçÆÈõÜÂíå‰ª£Á†ÅÂèØÂú®ÊåáÂÆöÈìæÊé•‰∏≠ÊâæÂà∞„ÄÇ","title":"Êï∞ÊçÆÈ©±Âä®ÁöÑËí∏È¶è‰ºòÂåñ‰πãË∑Ø"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫DC-CoTÁöÑÊï∞ÊçÆ‰∏≠ÂøÉÂü∫ÂáÜÔºåÊó®Âú®Á≥ªÁªüËØÑ‰º∞Êï∞ÊçÆÂ¢ûÂº∫„ÄÅÈÄâÊã©ÂíåÊ∑∑ÂêàÂØπÈìæÂºèÊé®ÁêÜÔºàCoTÔºâËí∏È¶èÁöÑÂΩ±Âìç„ÄÇÈÄöËøá‰ΩøÁî®Â§öÁßçÊïôÂ∏àÊ®°ÂûãÂíåÂ≠¶ÁîüÊû∂ÊûÑÔºåÊàë‰ª¨ÂØπÊï∞ÊçÆÊìç‰ΩúÂØπÂ≠¶ÁîüÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçËøõË°å‰∫Ü‰∏•Ê†ºËØÑ‰º∞ÔºåÈáçÁÇπÂÖ≥Ê≥®Âú®ÂàÜÂ∏ÉÂÜÖÂíåÂàÜÂ∏ÉÂ§ñÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁ†îÁ©∂ÁªìÊûú‰∏∫‰ºòÂåñCoTËí∏È¶èÊèê‰æõ‰∫ÜÂèØË°åÁöÑËßÅËß£ÂíåÊúÄ‰Ω≥ÂÆûË∑µÔºå‰øÉËøõ‰∫ÜÊõ¥È´òÊïàÁöÑÊé®ÁêÜÊ®°ÂûãÁöÑÂºÄÂèë„ÄÇËØ•Êï∞ÊçÆÈõÜÂíå‰ª£Á†ÅÂèØÂú®ÊåáÂÆöÈìæÊé•‰∏≠ÊâæÂà∞„ÄÇ', title='Êï∞ÊçÆÈ©±Âä®ÁöÑËí∏È¶è‰ºòÂåñ‰πãË∑Ø'))
[27.05.2025 06:17] Querying the API.
[27.05.2025 06:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.  					AI-generated summary 				 Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.
[27.05.2025 06:18] Response: {
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫–∏ –º–æ–≥—É—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –æ–±–ª–∞—Å—Ç–∏ –Ω–∞—Å—Ç—É–ø–∞—Ç–µ–ª—å–Ω–æ–π –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã. –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –¥–æ–ª–∂–Ω—ã —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —É–≥—Ä–æ–∑ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç, —á—Ç–æ –¥–∞–∂–µ —Å –Ω–µ–±–æ–ª—å—à–∏–º –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º –±—é–¥–∂–µ—Ç–æ–º –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞ –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 40% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–∞–∑–æ–≤—ã–º —É—Ä–æ–≤–Ω–µ–º. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.",

  "emoji": "üõ°Ô∏è",

  "title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —É–≥—Ä–æ–∑ –ò–ò –≤ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
}
[27.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.  					AI-generated summary 				 Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk."

[27.05.2025 06:18] Response: ```python
['AGENTS', 'CYBERSECURITY']
```
[27.05.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.  					AI-generated summary 				 Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk."

[27.05.2025 06:18] Response: ```python
['SECURITY']
```
[27.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses how adversaries can improve the capabilities of foundation models in offensive cybersecurity, even with limited computational resources. It highlights the importance of dynamic threat model assessments that consider the various options available to adversaries in real-world scenarios. The authors demonstrate that adversaries can enhance an agent\'s performance significantly, achieving over 40% improvement in cybersecurity tasks with minimal compute resources. This underscores the necessity for more comprehensive evaluations of cybersecurity risks associated with AI agents.","title":"Enhancing Cybersecurity: Adversaries Boost AI with Limited Resources"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper discusses how adversaries can improve the capabilities of foundation models in offensive cybersecurity, even with limited computational resources. It highlights the importance of dynamic threat model assessments that consider the various options available to adversaries in real-world scenarios. The authors demonstrate that adversaries can enhance an agent's performance significantly, achieving over 40% improvement in cybersecurity tasks with minimal compute resources. This underscores the necessity for more comprehensive evaluations of cybersecurity risks associated with AI agents.", title='Enhancing Cybersecurity: Adversaries Boost AI with Limited Resources'))
[27.05.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨ËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂØπÊäóËÄÖÂ¶Ç‰ΩïÂú®ÊúâÈôêÁöÑËÆ°ÁÆóËµÑÊ∫ê‰∏ãÊòæËëóÊèêÂçáÂü∫Á°ÄÊ®°ÂûãÂú®ËøõÊîªÊÄßÁΩëÁªúÂÆâÂÖ®‰∏≠ÁöÑËÉΩÂäõ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂü∫Á°ÄÊ®°ÂûãÂú®Ëá™Âä®ÂåñÁºñÁ®ãÊñπÈù¢ÁöÑËøõÊ≠•ÂèØËÉΩ‰ΩøÂÖ∂ËÉΩÂ§üËá™Âä®ÂåñÂç±Èô©ÁöÑÁΩëÁªúÊîªÂáªÊìç‰Ωú„ÄÇÂΩìÂâçÁöÑÊ®°ÂûãÂÆ°ËÆ°ÂæÄÂæÄÊú™ËÉΩËÄÉËôëÁé∞ÂÆû‰∏ñÁïå‰∏≠ÂØπÊäóËÄÖÁöÑËá™Áî±Â∫¶ÔºåÂØºËá¥ÂØπÁΩëÁªúÂÆâÂÖ®È£éÈô©ÁöÑËØÑ‰º∞‰∏çË∂≥„ÄÇÊàë‰ª¨Âª∫ËÆÆÂú®ÁΩëÁªúÂÆâÂÖ®ËØÑ‰º∞‰∏≠Â∫îËÄÉËôëÊâ©Â±ïÁöÑÂ®ÅËÉÅÊ®°ÂûãÔºå‰ª•Âä®ÊÄÅÊñπÂºèËØÑ‰º∞ÂØπÊäóËÄÖÂú®‰∏çÂêåÁéØÂ¢É‰∏ãÁöÑËÉΩÂäõ„ÄÇ","title":"Âä®ÊÄÅËØÑ‰º∞ÂØπÊäóËÄÖÂú®ÁΩëÁªúÂÆâÂÖ®‰∏≠ÁöÑÂ®ÅËÉÅ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨ËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂØπÊäóËÄÖÂ¶Ç‰ΩïÂú®ÊúâÈôêÁöÑËÆ°ÁÆóËµÑÊ∫ê‰∏ãÊòæËëóÊèêÂçáÂü∫Á°ÄÊ®°ÂûãÂú®ËøõÊîªÊÄßÁΩëÁªúÂÆâÂÖ®‰∏≠ÁöÑËÉΩÂäõ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂü∫Á°ÄÊ®°ÂûãÂú®Ëá™Âä®ÂåñÁºñÁ®ãÊñπÈù¢ÁöÑËøõÊ≠•ÂèØËÉΩ‰ΩøÂÖ∂ËÉΩÂ§üËá™Âä®ÂåñÂç±Èô©ÁöÑÁΩëÁªúÊîªÂáªÊìç‰Ωú„ÄÇÂΩìÂâçÁöÑÊ®°ÂûãÂÆ°ËÆ°ÂæÄÂæÄÊú™ËÉΩËÄÉËôëÁé∞ÂÆû‰∏ñÁïå‰∏≠ÂØπÊäóËÄÖÁöÑËá™Áî±Â∫¶ÔºåÂØºËá¥ÂØπÁΩëÁªúÂÆâÂÖ®È£éÈô©ÁöÑËØÑ‰º∞‰∏çË∂≥„ÄÇÊàë‰ª¨Âª∫ËÆÆÂú®ÁΩëÁªúÂÆâÂÖ®ËØÑ‰º∞‰∏≠Â∫îËÄÉËôëÊâ©Â±ïÁöÑÂ®ÅËÉÅÊ®°ÂûãÔºå‰ª•Âä®ÊÄÅÊñπÂºèËØÑ‰º∞ÂØπÊäóËÄÖÂú®‰∏çÂêåÁéØÂ¢É‰∏ãÁöÑËÉΩÂäõ„ÄÇ', title='Âä®ÊÄÅËØÑ‰º∞ÂØπÊäóËÄÖÂú®ÁΩëÁªúÂÆâÂÖ®‰∏≠ÁöÑÂ®ÅËÉÅ'))
[27.05.2025 06:18] Using data from previous issue: {"categories": ["#ethics", "#reasoning", "#audio", "#benchmark", "#multimodal", "#survey"], "emoji": "üéß", "ru": {"title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –∞—É–¥–∏–æ-—è–∑—ã–∫–æ–≤—ã—Ö –ò–ò-–º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Ç–∞–∫—Å–æ–Ω–æ–º–∏—é –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö –∞—É–¥–∏–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LALM). –ê–≤—Ç–æ—Ä—ã –≤—ã
[27.05.2025 06:18] Loading Chinese text from previous data.
[27.05.2025 06:18] Renaming data file.
[27.05.2025 06:18] Renaming previous data. hf_papers.json to ./d/2025-05-27.json
[27.05.2025 06:18] Saving new data file.
[27.05.2025 06:18] Generating page.
[27.05.2025 06:18] Renaming previous page.
[27.05.2025 06:18] Renaming previous data. index.html to ./d/2025-05-27.html
[27.05.2025 06:18] [Experimental] Generating Chinese page for reading.
[27.05.2025 06:18] Chinese vocab [{'word': 'ËøÅÁßªÂ≠¶‰π†', 'pinyin': 'qiƒÅn y√≠ xu√© x√≠', 'trans': 'transfer learning'}, {'word': 'ÂàÜÁ±ª‰ªªÂä°', 'pinyin': 'fƒìn l√®i r√®n w√π', 'trans': 'classification task'}, {'word': 'ÂèÇÊï∞', 'pinyin': 'cƒÅn sh«î', 'trans': 'parameter'}, {'word': 'È¢ÑËÆ≠ÁªÉ', 'pinyin': 'y√π x√πn li√†n', 'trans': 'pre-training'}, {'word': 'ÊñáÊú¨ÁºñÁ†ÅÂô®', 'pinyin': 'w√©n bƒõn biƒÅn m«é q√¨', 'trans': 'text encoder'}, {'word': 'ÁõÆÊ†á‰ª§Áâå', 'pinyin': 'm√π biƒÅo l√¨ng p√°i', 'trans': 'target token'}, {'word': 'ÂµåÂÖ•', 'pinyin': 'qi√†n r√π', 'trans': 'embedding'}, {'word': 'Ë°®Áé∞Âá∫Ëâ≤', 'pinyin': 'bi«éo xi√†n ch≈´ s√®', 'trans': 'perform excellently'}, {'word': 'Êâ©Â±ïËßÑÂæã', 'pinyin': 'ku√≤ zh«én guƒ´ l«ú', 'trans': 'expansion pattern'}]
[27.05.2025 06:18] Renaming previous Chinese page.
[27.05.2025 06:18] Renaming previous data. zh.html to ./d/2025-05-26_zh_reading_task.html
[27.05.2025 06:18] Writing Chinese reading task.
[27.05.2025 06:18] Writing result.
[27.05.2025 06:18] Renaming log file.
[27.05.2025 06:18] Renaming previous data. log.txt to ./logs/2025-05-27_last_log.txt
