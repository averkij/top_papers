[27.12.2024 08:13] Read previous papers.
[27.12.2024 08:13] Generating top page (month).
[27.12.2024 08:13] Writing top page (month).
[27.12.2024 09:10] Read previous papers.
[27.12.2024 09:10] Get feed.
[27.12.2024 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2412.17743
[27.12.2024 09:10] Get page data from previous paper. URL: https://huggingface.co/papers/2412.17483
[27.12.2024 09:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.12.2024 09:10] No deleted papers detected.
[27.12.2024 09:10] Downloading and parsing papers (pdf, html). Total: 2.
[27.12.2024 09:10] Downloading and parsing paper https://huggingface.co/papers/2412.17743.
[27.12.2024 09:10] Extra JSON file exists (./assets/json/2412.17743.json), skip PDF parsing.
[27.12.2024 09:10] Paper image links file exists (./assets/img_data/2412.17743.json), skip HTML parsing.
[27.12.2024 09:10] Success.
[27.12.2024 09:10] Downloading and parsing paper https://huggingface.co/papers/2412.17483.
[27.12.2024 09:10] Extra JSON file exists (./assets/json/2412.17483.json), skip PDF parsing.
[27.12.2024 09:10] Paper image links file exists (./assets/img_data/2412.17483.json), skip HTML parsing.
[27.12.2024 09:10] Success.
[27.12.2024 09:10] Enriching papers with extra data.
[27.12.2024 09:10] ********************************************************************************
[27.12.2024 09:10] Abstract 0. Effective pre-training of large language models (LLMs) has been challenging due to the immense resource demands and the complexity of the technical processes involved. This paper presents a detailed technical report on YuLan-Mini, a highly capable base model with 2.42B parameters that achieves top-t...
[27.12.2024 09:10] ********************************************************************************
[27.12.2024 09:10] Abstract 1. In this work, we provide a thorough investigation of gist-based context compression methods to improve long-context processing in large language models. We focus on two key questions: (1) How well can these methods replace full attention models? and (2) What potential failure patterns arise due to c...
[27.12.2024 09:10] Read previous papers.
[27.12.2024 09:10] Generating reviews via LLM API.
[27.12.2024 09:10] Using data from previous issue: {"categories": ["#long_context", "#open_source", "#optimization", "#small_models", "#data", "#training"], "emoji": "ğŸš€", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¼Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ YuLan-Mini - ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ 2.42 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ´
[27.12.2024 09:10] Using data from previous issue: {"categories": ["#training", "#rag", "#optimization", "#long_context", "#data"], "emoji": "ğŸ—œï¸", "ru": {"title": "Ğ¡Ğ¶Ğ°Ñ‚Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…", "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼ ÑĞ¶Ğ°Ñ‚Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ³Ğ¸ÑÑ‚-Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ 
[27.12.2024 09:10] Trying to get texts in Chinese.
[27.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Effective pre-training of large language models (LLMs) has been challenging due to the immense resource demands and the complexity of the technical processes involved. This paper presents a detailed technical report on YuLan-Mini, a highly capable base model with 2.42B parameters that achieves top-tier performance among models of similar parameter scale. Our pre-training approach focuses on enhancing training efficacy through three key technical contributions: an elaborate data pipeline combines data cleaning with data schedule strategies, a robust optimization method to mitigate training instability, and an effective annealing approach that incorporates targeted data selection and long context training. Remarkably, YuLan-Mini, trained on 1.08T tokens, achieves performance comparable to industry-leading models that require significantly more data. To facilitate reproduction, we release the full details of the data composition for each training phase. Project details can be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.
[27.12.2024 09:10] Mistral response. {"id": "3e84b562fe5046b4a6421e09ffc9935e", "object": "chat.completion", "created": 1735290610, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86YuLan-Mini\uff0c\u4e00\u4e2a\u5177\u670924.2\u4ebf\u53c2\u6570\u7684\u57fa\u7840\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u4e2d\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u6280\u672f\u8d21\u732e\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff1a\u6570\u636e\u7ba1\u9053\u3001\u4f18\u5316\u65b9\u6cd5\u548c\u9000\u706b\u65b9\u6cd5\u3002YuLan-Mini\u57281.08\u4e07\u4ebf\u4e2a\u8bb0\u53f7\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u5ab2\u7f8e\u9700\u8981\u66f4\u591a\u6570\u636e\u7684\u884c\u4e1a\u9886\u5148\u6a21\u578b\u3002\u8be6\u7ec6\u4fe1\u606f\u53ef\u5728GitHub\u4e0a\u627e\u5230\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 249, "total_tokens": 384, "completion_tokens": 135}}
[27.12.2024 09:10] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†YuLan-Miniï¼Œä¸€ä¸ªå…·æœ‰24.2äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­é€šè¿‡ä¸‰ä¸ªå…³é”®æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08ä¸‡äº¿ä¸ªè®°å·ä¸Šè®­ç»ƒï¼Œæ€§èƒ½åª²ç¾éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ã€‚è¯¦ç»†ä¿¡æ¯å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[27.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†YuLan-Miniï¼Œä¸€ä¸ªå…·æœ‰24.2äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­é€šè¿‡ä¸‰ä¸ªå…³é”®æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08ä¸‡äº¿ä¸ªè®°å·ä¸Šè®­ç»ƒï¼Œæ€§èƒ½åª²ç¾éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ã€‚è¯¦ç»†ä¿¡æ¯å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[27.12.2024 09:10] Mistral response. {"id": "c9831cbbc45f4e5e952a5f46870f85ea", "object": "chat.completion", "created": 1735290614, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86YuLan-Mini\uff0c\u4e00\u4e2a\u5177\u670924.2\u4ebf\u53c2\u6570\u7684\u57fa\u7840\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u4e2d\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u6280\u672f\u8d21\u732e\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff1a\u6570\u636e\u7ba1\u9053\u3001\u4f18\u5316\u65b9\u6cd5\u548c\u9000\u706b\u65b9\u6cd5\u3002YuLan-Mini\u57281.08\u4e07\u4ebf\u4e2a\u8bb0\u53f7\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u5ab2\u7f8e\u9700\u8981\u66f4\u591a\u6570\u636e\u7684\u884c\u4e1a\u9886\u5148\u6a21\u578b\u3002\u8be6\u7ec6\u4fe1\u606f\u53ef\u5728GitHub\u4e0a\u627e\u5230\u3002\n\nZh\u00e8 pi\u0101n w\u00e9nzh\u0101ng ji\u00e8sh\u00e0o le YuLan-Mini, y\u012bg\u00e8 j\u00f9y\u01d2u 24.2 y\u00ec c\u0101nsh\u00f9 de j\u012bch\u01d4 m\u00f3x\u00edng. G\u01cei m\u00f3x\u00edng z\u00e0i y\u00f9x\u00f9nli\u00e0n zh\u014dng t\u014dnggu\u00f2 s\u0101n g\u00e8 gu\u01cenji\u00e0n j\u00ecsh\u00f9 g\u00f2ngxi\u00e0n t\u00edg\u0101o le x\u00f9nli\u00e0n xi\u00e0ol\u01dc: sh\u00f9j\u00f9 gu\u01cend\u00e0o, y\u014duhu\u00e0 f\u0101ngf\u01ce h\u00e9 tu\u00echu\u01d2 f\u0101ngf\u01ce. YuLan-Mini z\u00e0i 1.08 w\u00e0n y\u00ec g\u00e8 j\u00ech\u00e0o sh\u00e0ng x\u00f9nli\u00e0n, x\u00ecngn\u00e9ng j\u012bm\u011bi x\u016by\u00e0o g\u00e8ng du\u014d sh\u00f9j\u00f9 de h\u00e1ngy\u00e8 l\u01d0ngxi\u0101n m\u00f3x\u00edng. Xi\u00e1ngx\u00ec x\u00ecnx\u012b k\u011b z\u00e0i GitHub sh\u00e0ng zh\u01ceo d\u00e0o."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 150, "total_tokens": 548, "completion_tokens": 398}}
[27.12.2024 09:10] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†YuLan-Miniï¼Œä¸€ä¸ªå…·æœ‰24.2äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­é€šè¿‡ä¸‰ä¸ªå…³é”®æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08ä¸‡äº¿ä¸ªè®°å·ä¸Šè®­ç»ƒï¼Œæ€§èƒ½åª²ç¾éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ã€‚è¯¦ç»†ä¿¡æ¯å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚

ZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le YuLan-Mini, yÄ«gÃ¨ jÃ¹yÇ’u 24.2 yÃ¬ cÄnshÃ¹ de jÄ«chÇ” mÃ³xÃ­ng. GÇi mÃ³xÃ­ng zÃ i yÃ¹xÃ¹nliÃ n zhÅng tÅngguÃ² sÄn gÃ¨ guÇnjiÃ n jÃ¬shÃ¹ gÃ²ngxiÃ n tÃ­gÄo le xÃ¹nliÃ n xiÃ olÇœ: shÃ¹jÃ¹ guÇndÃ o, yÅuhuÃ  fÄngfÇ hÃ© tuÃ¬huÇ’ fÄngfÇ. YuLan-Mini zÃ i 1.08 wÃ n yÃ¬ gÃ¨ jÃ¬hÃ o shÃ ng xÃ¹nliÃ n, xÃ¬ngnÃ©ng jÄ«mÄ›i xÅ«yÃ o gÃ¨ng duÅ shÃ¹jÃ¹ de hÃ¡ngyÃ¨ lÇngxiÄn mÃ³xÃ­ng. XiÃ¡ngxÃ¬ xÃ¬nxÄ« kÄ› zÃ i GitHub shÃ ng zhÇo dÃ o.
[27.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†YuLan-Miniï¼Œä¸€ä¸ªå…·æœ‰24.2äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­é€šè¿‡ä¸‰ä¸ªå…³é”®æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08ä¸‡äº¿ä¸ªè®°å·ä¸Šè®­ç»ƒï¼Œæ€§èƒ½åª²ç¾éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ã€‚è¯¦ç»†ä¿¡æ¯å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[27.12.2024 09:10] Mistral response. {"id": "8506dda50cc24d0b84fa8d1a81e73967", "object": "chat.completion", "created": 1735290626, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\n    {\"word\": \"\u7bc7\", \"pinyin\": \"pi\u0101n\", \"trans\": \"article, piece of writing\"},\n    {\"word\": \"\u4ecb\u7ecd\", \"pinyin\": \"ji\u00e8sh\u00e0o\", \"trans\": \"introduce, present\"},\n    {\"word\": \"\u5177\u6709\", \"pinyin\": \"j\u00f9y\u01d2u\", \"trans\": \"possess, have\"},\n    {\"word\": \"\u4ebf\", \"pinyin\": \"y\u00ec\", \"trans\": \"hundred million\"},\n    {\"word\": \"\u53c2\u6570\", \"pinyin\": \"c\u0101nsh\u00f9\", \"trans\": \"parameter\"},\n    {\"word\": \"\u57fa\u7840\", \"pinyin\": \"j\u012bch\u01d4\", \"trans\": \"basic, foundation\"},\n    {\"word\": \"\u6a21\u578b\", \"pinyin\": \"m\u00f3x\u00edng\", \"trans\": \"model\"},\n    {\"word\": \"\u9884\u8bad\u7ec3\", \"pinyin\": \"y\u00f9x\u00f9nli\u00e0n\", \"trans\": \"pre-training\"},\n    {\"word\": \"\u901a\u8fc7\", \"pinyin\": \"t\u014dnggu\u00f2\", \"trans\": \"through, by means of\"},\n    {\"word\": \"\u5173\u952e\", \"pinyin\": \"gu\u01cenji\u00e0n\", \"trans\": \"key, crucial\"},\n    {\"word\": \"\u6280\u672f\", \"pinyin\": \"j\u00ecsh\u00f9\", \"trans\": \"technology, skill\"},\n    {\"word\": \"\u8d21\u732e\", \"pinyin\": \"g\u00f2ngxi\u00e0n\", \"trans\": \"contribution\"},\n    {\"word\": \"\u63d0\u9ad8\", \"pinyin\": \"t\u00edg\u0101o\", \"trans\": \"improve, raise\"},\n    {\"word\": \"\u6548\u7387\", \"pinyin\": \"xi\u00e0ol\u01dc\", \"trans\": \"efficiency\"},\n    {\"word\": \"\u6570\u636e\", \"pinyin\": \"sh\u00f9j\u00f9\", \"trans\": \"data\"},\n    {\"word\": \"\u7ba1\u9053\", \"pinyin\": \"gu\u01cend\u00e0o\", \"trans\": \"pipeline\"},\n    {\"word\": \"\u4f18\u5316\", \"pinyin\": \"y\u014duhu\u00e0\", \"trans\": \"optimization\"},\n    {\"word\": \"\u65b9\u6cd5\", \"pinyin\": \"f\u0101ngf\u01ce\", \"trans\": \"method\"},\n    {\"word\": \"\u9000\u706b\", \"pinyin\": \"tu\u00echu\u01d2\", \"trans\": \"annealing\"},\n    {\"word\": \"\u8bb0\u53f7\", \"pinyin\": \"j\u00ech\u00e0o\", \"trans\": \"symbol, token\"},\n    {\"word\": \"\u6027\u80fd\", \"pinyin\": \"x\u00ecngn\u00e9ng\", \"trans\": \"performance\"},\n    {\"word\": \"\u5ab2\u7f8e\", \"pinyin\": \"p\u00ecm\u011bi\", \"trans\": \"rival, match\"},\n    {\"word\": \"\u884c\u4e1a\", \"pinyin\": \"h\u00e1ngy\u00e8\", \"trans\": \"industry\"},\n    {\"word\": \"\u9886\u5148\", \"pinyin\": \"l\u01d0ngxi\u0101n\", \"trans\": \"leading, ahead\"},\n    {\"word\": \"\u8be6\u7ec6\", \"pinyin\": \"xi\u00e1ngx\u00ec\", \"trans\": \"detailed\"},\n    {\"word\": \"\u4fe1\u606f\", \"pinyin\": \"x\u00ecnx\u012b\", \"trans\": \"information\"},\n    {\"word\": \"GitHub\", \"pinyin\": \"GitHub\", \"trans\": \"GitHub\"}\n]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 182, "total_tokens": 964, "completion_tokens": 782}}
[27.12.2024 09:10] Response: [
    {"word": "ç¯‡", "pinyin": "piÄn", "trans": "article, piece of writing"},
    {"word": "ä»‹ç»", "pinyin": "jiÃ¨shÃ o", "trans": "introduce, present"},
    {"word": "å…·æœ‰", "pinyin": "jÃ¹yÇ’u", "trans": "possess, have"},
    {"word": "äº¿", "pinyin": "yÃ¬", "trans": "hundred million"},
    {"word": "å‚æ•°", "pinyin": "cÄnshÃ¹", "trans": "parameter"},
    {"word": "åŸºç¡€", "pinyin": "jÄ«chÇ”", "trans": "basic, foundation"},
    {"word": "æ¨¡å‹", "pinyin": "mÃ³xÃ­ng", "trans": "model"},
    {"word": "é¢„è®­ç»ƒ", "pinyin": "yÃ¹xÃ¹nliÃ n", "trans": "pre-training"},
    {"word": "é€šè¿‡", "pinyin": "tÅngguÃ²", "trans": "through, by means of"},
    {"word": "å…³é”®", "pinyin": "guÇnjiÃ n", "trans": "key, crucial"},
    {"word": "æŠ€æœ¯", "pinyin": "jÃ¬shÃ¹", "trans": "technology, skill"},
    {"word": "è´¡çŒ®", "pinyin": "gÃ²ngxiÃ n", "trans": "contribution"},
    {"word": "æé«˜", "pinyin": "tÃ­gÄo", "trans": "improve, raise"},
    {"word": "æ•ˆç‡", "pinyin": "xiÃ olÇœ", "trans": "efficiency"},
    {"word": "æ•°æ®", "pinyin": "shÃ¹jÃ¹", "trans": "data"},
    {"word": "ç®¡é“", "pinyin": "guÇndÃ o", "trans": "pipeline"},
    {"word": "ä¼˜åŒ–", "pinyin": "yÅuhuÃ ", "trans": "optimization"},
    {"word": "æ–¹æ³•", "pinyin": "fÄngfÇ", "trans": "method"},
    {"word": "é€€ç«", "pinyin": "tuÃ¬huÇ’", "trans": "annealing"},
    {"word": "è®°å·", "pinyin": "jÃ¬hÃ o", "trans": "symbol, token"},
    {"word": "æ€§èƒ½", "pinyin": "xÃ¬ngnÃ©ng", "trans": "performance"},
    {"word": "åª²ç¾", "pinyin": "pÃ¬mÄ›i", "trans": "rival, match"},
    {"word": "è¡Œä¸š", "pinyin": "hÃ¡ngyÃ¨", "trans": "industry"},
    {"word": "é¢†å…ˆ", "pinyin": "lÇngxiÄn", "trans": "leading, ahead"},
    {"word": "è¯¦ç»†", "pinyin": "xiÃ¡ngxÃ¬", "trans": "detailed"},
    {"word": "ä¿¡æ¯", "pinyin": "xÃ¬nxÄ«", "trans": "information"},
    {"word": "GitHub", "pinyin": "GitHub", "trans": "GitHub"}
]
[27.12.2024 09:10] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†YuLan-Miniï¼Œä¸€ä¸ªå…·æœ‰24.2äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­é€šè¿‡ä¸‰ä¸ªå…³é”®æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08ä¸‡äº¿ä¸ªè®°å·ä¸Šè®­ç»ƒï¼Œæ€§èƒ½åª²ç¾éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ã€‚è¯¦ç»†ä¿¡æ¯å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[27.12.2024 09:10] Mistral response. {"id": "41a90de8e2a3459c812624693d486377", "object": "chat.completion", "created": 1735290643, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article introduces YuLan-Mini, a foundational model with 2.42 billion parameters. During pre-training, the model's training efficiency was enhanced through three key technological contributions: the data pipeline, optimization methods, and annealing techniques. YuLan-Mini was trained on 1.08 trillion tokens and performs comparably to industry-leading models that require more data. Detailed information can be found on GitHub."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 148, "total_tokens": 245, "completion_tokens": 97}}
[27.12.2024 09:10] Response: This article introduces YuLan-Mini, a foundational model with 2.42 billion parameters. During pre-training, the model's training efficiency was enhanced through three key technological contributions: the data pipeline, optimization methods, and annealing techniques. YuLan-Mini was trained on 1.08 trillion tokens and performs comparably to industry-leading models that require more data. Detailed information can be found on GitHub.
[27.12.2024 09:10] Renaming data file.
[27.12.2024 09:10] Renaming previous data. hf_papers.json to ./d/2024-12-27.json
[27.12.2024 09:10] Saving new data file.
[27.12.2024 09:10] Generating page.
[27.12.2024 09:10] Renaming previous page.
[27.12.2024 09:10] Renaming previous data. index.html to ./d/2024-12-27.html
[27.12.2024 09:10] [Experimental] Generating Chinese page for reading.
[27.12.2024 09:10] Chinese vocab [{'word': 'ç¯‡', 'pinyin': 'piÄn', 'trans': 'article, piece of writing'}, {'word': 'ä»‹ç»', 'pinyin': 'jiÃ¨shÃ o', 'trans': 'introduce, present'}, {'word': 'å…·æœ‰', 'pinyin': 'jÃ¹yÇ’u', 'trans': 'possess, have'}, {'word': 'äº¿', 'pinyin': 'yÃ¬', 'trans': 'hundred million'}, {'word': 'å‚æ•°', 'pinyin': 'cÄnshÃ¹', 'trans': 'parameter'}, {'word': 'åŸºç¡€', 'pinyin': 'jÄ«chÇ”', 'trans': 'basic, foundation'}, {'word': 'æ¨¡å‹', 'pinyin': 'mÃ³xÃ­ng', 'trans': 'model'}, {'word': 'é¢„è®­ç»ƒ', 'pinyin': 'yÃ¹xÃ¹nliÃ n', 'trans': 'pre-training'}, {'word': 'é€šè¿‡', 'pinyin': 'tÅngguÃ²', 'trans': 'through, by means of'}, {'word': 'å…³é”®', 'pinyin': 'guÇnjiÃ n', 'trans': 'key, crucial'}, {'word': 'æŠ€æœ¯', 'pinyin': 'jÃ¬shÃ¹', 'trans': 'technology, skill'}, {'word': 'è´¡çŒ®', 'pinyin': 'gÃ²ngxiÃ n', 'trans': 'contribution'}, {'word': 'æé«˜', 'pinyin': 'tÃ­gÄo', 'trans': 'improve, raise'}, {'word': 'æ•ˆç‡', 'pinyin': 'xiÃ olÇœ', 'trans': 'efficiency'}, {'word': 'æ•°æ®', 'pinyin': 'shÃ¹jÃ¹', 'trans': 'data'}, {'word': 'ç®¡é“', 'pinyin': 'guÇndÃ o', 'trans': 'pipeline'}, {'word': 'ä¼˜åŒ–', 'pinyin': 'yÅuhuÃ ', 'trans': 'optimization'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄngfÇ', 'trans': 'method'}, {'word': 'é€€ç«', 'pinyin': 'tuÃ¬huÇ’', 'trans': 'annealing'}, {'word': 'è®°å·', 'pinyin': 'jÃ¬hÃ o', 'trans': 'symbol, token'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ngnÃ©ng', 'trans': 'performance'}, {'word': 'åª²ç¾', 'pinyin': 'pÃ¬mÄ›i', 'trans': 'rival, match'}, {'word': 'è¡Œä¸š', 'pinyin': 'hÃ¡ngyÃ¨', 'trans': 'industry'}, {'word': 'é¢†å…ˆ', 'pinyin': 'lÇngxiÄn', 'trans': 'leading, ahead'}, {'word': 'è¯¦ç»†', 'pinyin': 'xiÃ¡ngxÃ¬', 'trans': 'detailed'}, {'word': 'ä¿¡æ¯', 'pinyin': 'xÃ¬nxÄ«', 'trans': 'information'}, {'word': 'GitHub', 'pinyin': 'GitHub', 'trans': 'GitHub'}]
[27.12.2024 09:10] Renaming previous Chinese page.
[27.12.2024 09:10] Renaming previous data. zh.html to ./d/2024-12-26_zh_reading_task.html
[27.12.2024 09:10] Writing Chinese reading task.
[27.12.2024 09:10] Writing result.
[27.12.2024 09:10] Renaming log file.
[27.12.2024 09:10] Renaming previous data. log.txt to ./logs/2024-12-27_last_log.txt
