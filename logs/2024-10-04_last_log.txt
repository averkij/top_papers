[05.10.2024 14:09] Get feed.
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02740
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02713
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02757
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02746
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02712
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02073
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02724
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.01679
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02678
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02416
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2409.19291
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02749
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02367
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02115
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02458
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02103
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02525
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02762
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02763
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02052
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.01946
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.01335
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02536
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02426
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.02056
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.00255
[05.10.2024 14:09] Get abstract from previous paper. URL: https://huggingface.co/papers/2410.01782
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 0. Recent advancements in multimodal models highlight the value of rewritten captions for improving performance, yet key challenges remain. For example, while synthetic captions often provide superior quality and image-text alignment, it is not clear whether they can fully replace AltTexts: the role of...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 1. The development of video large multimodal models (LMMs) has been hindered by the difficulty of curating large amounts of high-quality raw data from the web. To address this, we propose an alternative approach by creating a high-quality synthetic dataset specifically for video instruction-following, ...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 2. It is desirable but challenging to generate content-rich long videos in the scale of minutes. Autoregressive large language models (LLMs) have achieved great success in generating coherent and long sequences of tokens in the domain of natural language processing, while the exploration of autoregress...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 3. Contrastive Language-Image Pre-training (CLIP) has been a celebrated method for training vision encoders to generate image/text representations facilitating various applications. Recently, CLIP has been widely adopted as the vision backbone of multimodal large language models (MLLMs) to connect imag...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 4. We introduce LLaVA-Critic, the first open-source large multimodal model (LMM) designed as a generalist evaluator to assess performance across a wide range of multimodal tasks. LLaVA-Critic is trained using a high-quality critic instruction-following dataset that incorporates diverse evaluation crite...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 5. We present a foundation model for zero-shot metric monocular depth estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with unparalleled sharpness and high-frequency details. The predictions are metric, with absolute scale, without relying on the availability of metadata such as...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 6. Large language models (LLMs) have proven to be remarkably efficient, both across a wide range of natural language processing tasks and well beyond them. However, a comprehensive theoretical analysis of the origins of their impressive performance remains elusive. In this paper, we approach this chall...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 7. Large language models (LLMs) are increasingly applied to complex reasoning tasks that require executing several complex steps before receiving any reward. Properly assigning credit to these steps is essential for enhancing model performance. Proximal Policy Optimization (PPO), a state-of-the-art rei...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 8. Voice assistants, such as Siri and Google Assistant, typically model audio and text separately, resulting in lost speech information and increased complexity. Recent efforts to address this with end-to-end Speech Large Language Models (LLMs) trained with supervised finetuning (SFT)   have led to mod...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 9. Classifier-free guidance (CFG) is crucial for improving both generation quality and alignment between the input condition and final output in diffusion models. While a high guidance scale is generally required to enhance these aspects, it also causes oversaturation and unrealistic artifacts. In this...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 10. In recent years, Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in multimodal intelligence. However, recent studies have identified that the information loss in the CLIP encoding process is substantial, and CLIP tends to capture only coarse-grained features from the input. T...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 11. Software engineers mainly write code by editing existing programs. In contrast, large language models (LLMs) autoregressively synthesize programs in a single pass. One explanation for this is the scarcity of open-sourced edit data. While high-quality instruction data for code synthesis is already sc...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 12. The transformer architecture predominates across various models. As the heart of the transformer, attention has a computational complexity of O(N^2), compared to O(N) for linear transformations. When handling large sequence lengths, attention becomes the primary time-consuming component. Although qu...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 13. Long-context models (LCMs) have made remarkable strides in recent years, offering users great convenience for handling tasks that involve long context, such as document summarization. As the community increasingly prioritizes the faithfulness of generated results, merely ensuring the accuracy of LCM...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 14. Large Language Models (LLMs), known for their versatility in textual data, are increasingly being explored for their potential to enhance medical image segmentation, a crucial task for accurate diagnostic imaging. This study explores enhancing Vision Transformers (ViTs) for medical image segmentatio...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 15. Recent works in volume rendering, e.g. NeRF and 3D Gaussian Splatting (3DGS), significantly advance the rendering quality and efficiency with the help of the learned implicit neural radiance field or 3D Gaussians. Rendering on top of an explicit representation, the vanilla 3DGS and its variants deli...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 16. Dense document embeddings are central to neural retrieval. The dominant paradigm is to train and construct embeddings by running encoders directly on individual documents. In this work, we argue that these embeddings, while effective, are implicitly out-of-context for targeted use cases of retrieval...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 17. We investigate the internal representations of vision-language models (VLMs) to address hallucinations, a persistent challenge despite advances in model size and training. We project VLMs' internal image representations to their language vocabulary and observe more confident output probabilities on ...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 18. There has been growing sentiment recently that modern large multimodal models (LMMs) have addressed most of the key challenges related to short video comprehension. As a result, both academia and industry are gradually shifting their attention towards the more complex challenges posed by understandi...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 19. Autonomous agents have demonstrated significant potential in automating complex multistep decision-making tasks. However, even state-of-the-art vision-language models (VLMs), such as GPT-4o, still fall short of human-level performance, particularly in intricate web environments and long-horizon plan...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 20. Prompt-based fine-tuning has become an essential method for eliciting information encoded in pre-trained language models for a variety of tasks, including text classification. For multi-class classification tasks, prompt-based fine-tuning under low-resource scenarios has resulted in performance leve...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 21. Model merging, such as model souping, is the practice of combining different models with the same architecture together without further training. In this work, we present a model merging methodology that addresses the difficulty of fine-tuning Large Language Models (LLMs) for target tasks in non-Eng...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 22. We explore the emergence of intelligent behavior in artificial systems by investigating how the complexity of rule-based systems influences the capabilities of models trained to predict these rules. Our study focuses on elementary cellular automata (ECA), simple yet powerful one-dimensional systems ...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 23. We demonstrate that small pretrained foundational generative language models with millions of parameters can learn the latent rules of a process from data associated with the process. Inspired by Stefan Zweig's novella "Schachnovelle," also known as "The Royal Game" in English, we show that 28M and ...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 24. We present Synthio, a novel approach for augmenting small-scale audio classification datasets with synthetic data. Our goal is to improve audio classification accuracy with limited labeled data. Traditional data augmentation techniques, which apply artificial transformations (e.g., adding random noi...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 25. Recent advancements in 3D Large Language Models (3DLLMs) have highlighted their potential in building general-purpose agents in the 3D real world, yet challenges remain due to the lack of high-quality robust instruction-following data, leading to limited discriminative power and generalization of 3D...
[05.10.2024 14:09] ********************************************************************************
[05.10.2024 14:09] Abstract 26. Retrieval-Augmented Generation (RAG) has been shown to enhance the factual accuracy of Large Language Models (LLMs), but existing methods often suffer from limited reasoning capabilities in effectively using the retrieved evidence, particularly when using open-source LLMs. To mitigate this gap, we i...
[05.10.2024 14:09] Read previous papers.
[05.10.2024 14:09] Generating reviews via LLM API.
[05.10.2024 14:09] Using data from previous issue: {"desc": "В статье предлагается новый метод создания разнообразных форматов подписей к изображениям, адаптированных под различные мультимодальные модели. Исследуется влияние синтетических подписей разной длины и их взаимодействие с оригинальными AltText на производительность моделей CLIP, мультимода
[05.10.2024 14:09] Using data from previous issue: {"desc": "В статье представлен новый подход к созданию мультимодальных моделей для работы с видео. Авторы предлагают использовать синтетический датасет LLaVA-Video-178K для обучения модели выполнению инструкций по видео. На основе этого датасета разработана модель LLaVA-Video, показывающая высокие р
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет Loong - новую модель генерации видео на основе авторегрессивных больших языковых моделей (LLM), способную создавать минутные видео по текстовым запросам. Авторы анализируют проблемы, препятствующие генерации длинных видео, и предлагают решения, включая прогрессивное обу
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет новый метод предобучения под названием CLOC (Contrastive Localized Language-Image Pre-training), который улучшает возможности локализации модели CLIP. CLOC дополняет CLIP контрастивной потерей на уровне регионов и текста, а также вводит концепцию 'promptable embeddings'
[05.10.2024 14:09] Using data from previous issue: {"desc": "LLaVA-Critic - это первая мультимодальная модель с открытым исходным кодом, разработанная для оценки производительности в широком спектре мультимодальных задач. Модель обучена на высококачественном наборе данных, включающем разнообразные критерии и сценарии оценки. LLaVA-Critic эффективно 
[05.10.2024 14:09] Using data from previous issue: {"desc": "Представлена модель Depth Pro для оценки монокулярной глубины с нулевым обучением. Модель синтезирует высокоразрешающие карты глубины с непревзойденной четкостью и детализацией, обеспечивая метрические предсказания абсолютного масштаба без использования метаданных камеры. Depth Pro основан
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья исследует теоретические основы эффективности больших языковых моделей (LLM), проводя аналогию между ними и цепями Маркова. Авторы анализируют стационарное распределение и скорость сходимости этих цепей, что позволяет лучше понять механизмы работы LLM. Исследование также включает док
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья рассматривает проблему назначения кредита в задачах сложных рассуждений для больших языковых моделей (LLM). Авторы выявляют недостатки ценностных сетей в алгоритме Proximal Policy Optimization (PPO) для таких задач. Предлагается новый метод VinePPO, использующий несмещенные оценки М
[05.10.2024 14:09] Using data from previous issue: {"desc": "Эта статья представляет новый подход к обучению речевых больших языковых моделей (Speech LLMs) без использования размеченных данных. Авторы предлагают метод самообучения, используя ответы текстовой языковой модели на транскрипты речи в качестве целевых данных. Разработанная модель DiVA (Di
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет новый метод адаптивного проецируемого руководства (APG) для улучшения качества генерации в диффузионных моделях. Авторы предлагают модификацию правила обновления для бесклассификационного руководства (CFG), разделяя его на параллельные и ортогональные компоненты. APG по
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет новый подход к улучшению моделей CLIP, называемый Diversified Multiplet Upcycling (DMU). DMU позволяет обучить серию моделей CLIP, захватывающих различные пространства признаков, и объединить их в модель CLIP-MoE с большей емкостью. Этот метод значительно повышает произ
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет алгоритм LintSeq для генерации синтетических данных редактирования кода. Этот метод преобразует существующие пары инструкция-программа в последовательности изменений кода. Авторы демонстрируют, что модели, обученные на таких последовательностях, генерируют более разнооб
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет SageAttention - новый метод квантизации для механизма внимания в трансформерах. Авторы анализируют возможность квантизации внимания и предлагают эффективный подход, превосходящий существующие решения. SageAttention демонстрирует значительное ускорение по сравнению с Fla
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет L-CiteEval - комплексный многозадачный бенчмарк для оценки понимания длинного контекста с цитированием. Он охватывает 11 задач из различных областей с длиной контекста от 8K до 48K и предоставляет полностью автоматизированный набор для оценки. Тестирование 11 современны
[05.10.2024 14:09] Using data from previous issue: {"desc": "Исследование посвящено улучшению сегментации медицинских изображений с помощью интеграции предобученных блоков трансформеров из больших языковых моделей (LLM) в архитектуру Vision Transformer (ViT). Предложенный подход включает гибридный механизм внимания, сочетающий глобальное и локальное
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет новый метод оптимизации 3D Gaussian Splatting (3DGS) для улучшения качества рендеринга и синтеза новых ракурсов. Авторы предлагают многоракурсную стратегию обучения вместо традиционного подхода с одним ракурсом, что помогает избежать переобучения. Также вводится схема к
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет новый подход к созданию контекстуализированных векторных представлений документов для нейронного поиска. Авторы предлагают две complementary методики: новую контрастивную функцию потерь, учитывающую соседние документы, и архитектуру, кодирующую информацию о соседях в пр
[05.10.2024 14:09] Using data from previous issue: {"desc": "Исследование внутренних представлений визуально-языковых моделей (VLM) для решения проблемы галлюцинаций. Авторы проецируют внутренние представления изображений VLM на языковой словарь и наблюдают более уверенные вероятности для реальных объектов. Разработан алгоритм стирания знаний, котор
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет новый бенчмарк Vinoground для оценки способности крупных мультимодальных моделей к временному рассуждению на коротких видео. Исследование показывает, что существующие модели, включая GPT-4o, значительно уступают человеку в различении временных различий между действиями 
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет Reflective Monte Carlo Tree Search (R-MCTS) - новый алгоритм для улучшения способностей ИИ-агентов исследовать пространство решений. R-MCTS расширяет традиционный MCTS, включая контрастную рефлексию и мультиагентные дебаты для оценки состояний. Авторы также улучшают про
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет SciPrompt - фреймворк для автоматического извлечения терминов, связанных с научными темами, для задач классификации текста с малым количеством данных. Метод использует семантически связанные и специфичные для домена термины для расширения вербализатора в контексте научн
[05.10.2024 14:09] Using data from previous issue: {"desc": "Статья представляет методологию объединения моделей для решения проблемы тонкой настройки больших языковых моделей (LLM) для целевых задач на языках, отличных от английского. Авторы фокусируются на математических рассуждениях, комбинируя языковые и математические возможности моделей. Они о
[05.10.2024 14:09] Using data from previous issue: {"desc": "Исследование посвящено изучению влияния сложности систем на основе правил на способности моделей, обученных предсказывать эти правила. Авторы использовали элементарные клеточные автоматы (ECA) и обучали различные языковые модели на разных ECA. Результаты показали, что правила с более высок
[05.10.2024 14:09] Using data from previous issue: {"desc": "Исследование показывает, что небольшие предварительно обученные языковые модели с миллионами параметров способны изучать скрытые правила процесса на основе связанных с ним данных. Авторы демонстрируют, что модели размером 28M и 125M параметров могут быть дообучены на 1000-1000000 примерах 
[05.10.2024 14:09] Using data from previous issue: {"desc": "Synthio - это новый подход к аугментации небольших наборов данных для классификации аудио с использованием синтетических данных. Метод использует модели диффузии текст-в-аудио (T2A) для генерации дополнительных аудиозаписей. Для обеспечения акустической согласованности с исходным набором д
[05.10.2024 14:09] Using data from previous issue: {"desc": "Robin3D - это мощная 3D большая языковая модель, обученная на масштабных данных для выполнения инструкций. Модель использует новый метод генерации данных RIG, который создает разнообразные и состязательные инструкции для улучшения различительной способности и обобщения. Robin3D включает в 
[05.10.2024 14:09] Using data from previous issue: {"desc": "Open-RAG - это новая структура, улучшающая способности рассуждения в Retrieval-Augmented Generation с использованием открытых языковых моделей. Она преобразует плотную языковую модель в эффективную разреженную смесь экспертов, способную справляться со сложными задачами рассуждения. Open-RA
[05.10.2024 14:09] Renaming data file.
[05.10.2024 14:09] Renaming previous data. hf_papers.json to 2024-10-04_hf_papers.json
[05.10.2024 14:09] Saving new data file.
[05.10.2024 14:09] Generating page.
[05.10.2024 14:09] Renaming previous page.
[05.10.2024 14:09] Renaming previous data. index.html to 2024-10-04_hf_papers.html
[05.10.2024 14:09] Writing result.
[05.10.2024 14:09] Renaming log file.
[05.10.2024 14:09] Renaming previous data. log.txt to 2024-10-04_last_log.txt
