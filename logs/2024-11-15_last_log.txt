[15.11.2024 07:10] Read previous papers.
[15.11.2024 07:10] Generating top page (month).
[15.11.2024 07:10] Writing top page (month).
[15.11.2024 07:14] Read previous papers.
[15.11.2024 07:14] Get feed.
[15.11.2024 07:14] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09703
[15.11.2024 07:14] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09595
[15.11.2024 07:14] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06469
[15.11.2024 07:14] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09009
[15.11.2024 07:14] Downloading and parsing papers (pdf, html). Total: 4.
[15.11.2024 07:14] Downloading and parsing paper https://huggingface.co/papers/2411.09703.
[15.11.2024 07:14] Downloading paper 2411.09703 from http://arxiv.org/pdf/2411.09703v1...
[15.11.2024 07:14] Extracting affiliations from text.
[15.11.2024 07:14] Mistral request. Model: open-mistral-nemo. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. If there are no affiliations return empty list.

Text:"MagicQuill: An Intelligent Interactive Image Editing System Zichen Liu,1,2 Yue Yu,1,2 Hao Ouyang2 Qiuyu Wang2, Ka Leong Cheng1,2 Wen Wang3,2 Zhiheng Liu4 Qifeng Chen,1 Yujun Shen,2 1HKUST 2Ant Group 3ZJU 4HKU 4 2 0 2 4 1 ] . [ 1 3 0 7 9 0 . 1 1 4 2 : r Figure 1. MagicQuill is an intelligent and interactive image editing system built upon diffusion models. Users seamlessly edit images using three intuitive brushstrokes: add, subtract, and color (A). MLLM dynamically predicts user intentions from their brush strokes and suggests contextual prompts (B1-B4). The examples demonstrate diverse editing operations: to generate jacket from clothing contour (B1), add flower crown from head sketches (B2), remove background (B3), and apply color changes to the hair and flowers(B4). "
[15.11.2024 07:14] Mistral response. {"id": "8014b1125dc44b5f8ed7efba28d03db4", "object": "chat.completion", "created": 1731654845, "model": "open-mistral-nemo", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\"HKUST\", \"Ant Group\", \"ZJU\", \"HKU\"]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 284, "total_tokens": 301, "completion_tokens": 17}}
[15.11.2024 07:14] Response: ["HKUST", "Ant Group", "ZJU", "HKU"]
[15.11.2024 07:14] Deleting PDF ./assets/pdf/2411.09703.pdf.
[15.11.2024 07:14] Downloading and parsing paper https://huggingface.co/papers/2411.09595.
[15.11.2024 07:14] Downloading paper 2411.09595 from http://arxiv.org/pdf/2411.09595v1...
[15.11.2024 07:14] Extracting affiliations from text.
[15.11.2024 07:14] Mistral request. Model: open-mistral-nemo. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. If there are no affiliations return empty list.

Text:"4 2 0 2 4 1 ] . [ 1 5 9 5 9 0 . 1 1 4 2 : r LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models Zhengyi Wang1 * Jonathan Lorraine2 Yikai Wang1 Hang Su1 Jun Zhu1 Sanja Fidler Xiaohui Zeng2 https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh Tsinghua University1 NVIDIA2 Figure 1. An illustration of our method, LLAMA-MESH, which enables the generation of 3D meshes from human instructions via conversational interface. Users provide textual prompts, and the model responds with both text and 3D mesh outputs, facilitating interactive 3D content creation. LLAMA-MESH allows large language models to generate and interpret 3D meshes from text directly, seamlessly unifying language and 3D modalities within single model. "
[15.11.2024 07:14] Mistral response. {"id": "419cf034895945c1b0e3758048ffb635", "object": "chat.completion", "created": 1731654850, "model": "open-mistral-nemo", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\"Tsinghua University\", \"NVIDIA\"]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 263, "total_tokens": 275, "completion_tokens": 12}}
[15.11.2024 07:14] Response: ["Tsinghua University", "NVIDIA"]
[15.11.2024 07:14] Deleting PDF ./assets/pdf/2411.09595.pdf.
[15.11.2024 07:14] Downloading and parsing paper https://huggingface.co/papers/2411.06469.
[15.11.2024 07:14] Downloading paper 2411.06469 from http://arxiv.org/pdf/2411.06469v1...
[15.11.2024 07:14] Extracting affiliations from text.
[15.11.2024 07:14] Mistral request. Model: open-mistral-nemo. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. If there are no affiliations return empty list.

Text:"4 2 0 2 0 1 ] . [ 1 9 6 4 6 0 . 1 1 4 2 : r a ClinicalBench: CAN LLMS BEAT TRADITIONAL ML MODELS IN CLINICAL PREDICTION? Canyu Chen 1, Jian Yu, Shan Chen3, Che Liu5, Zhongwei Wan6, Danielle S. Bitterman3, Fei Wang4, Kai Shu2 1Illinois Institute of Technology 2Emory University 3Mass General Brigham & Boston Childrens Hospital, Harvard Medical School 4Weill Cornell Medicine, Cornell University 5Imperial College London 6Ohio State University cchen151@hawk.iit.edu,jian.yu0422@gmail.com,{schen73,dbitterman}@bwh.harvard.edu che.liu21@imperial.ac.uk,wan.512@osu.edu,few2001@med.cornell.edu,kai.shu@emory.edu Project website: https://clinicalbench.github.io "
[15.11.2024 07:14] Mistral response. {"id": "da813ecf783c43dbb88a411f7db96c07", "object": "chat.completion", "created": 1731654881, "model": "open-mistral-nemo", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\"Illinois Institute of Technology\", \"Emory University\", \"Mass General Brigham & Boston Children's Hospital, Harvard Medical School\", \"Weill Cornell Medicine, Cornell University\", \"Imperial College London\", \"Ohio State University\"]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 293, "total_tokens": 342, "completion_tokens": 49}}
[15.11.2024 07:14] Response: ["Illinois Institute of Technology", "Emory University", "Mass General Brigham & Boston Children's Hospital, Harvard Medical School", "Weill Cornell Medicine, Cornell University", "Imperial College London", "Ohio State University"]
[15.11.2024 07:14] Error. Failed to parse JSON from LLM. ["Illinois Institute of Technology", "Emory University", "Mass General Brigham & Boston Children"s Hospital, Harvard Medical School", "Weill Cornell Medicine, Cornell University", "Imperial College London", "Ohio State University"]
[15.11.2024 07:14] Deleting PDF ./assets/pdf/2411.06469.pdf.
[15.11.2024 07:14] Downloading and parsing paper https://huggingface.co/papers/2411.09009.
[15.11.2024 07:14] Downloading paper 2411.09009 from http://arxiv.org/pdf/2411.09009v1...
[15.11.2024 07:14] Extracting affiliations from text.
[15.11.2024 07:14] Mistral request. Model: open-mistral-nemo. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. If there are no affiliations return empty list.

Text:"4 2 0 2 3 1 ] . [ 1 9 0 0 9 0 . 1 1 4 2 : r a CUT YOUR LOSSES IN LARGE-VOCABULARY LANGUAGE MODELS Erik Wijmans Brody Huval Alexander Hertzberg Vladlen Koltun Philipp Krahenb uhl Apple "
[15.11.2024 07:14] Mistral response. {"id": "45ca6cd9c2f34410bf5e9243f209317e", "object": "chat.completion", "created": 1731654887, "model": "open-mistral-nemo", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\"Apple\"]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 135, "total_tokens": 138, "completion_tokens": 3}}
[15.11.2024 07:14] Response: ["Apple"]
[15.11.2024 07:14] Deleting PDF ./assets/pdf/2411.09009.pdf.
[15.11.2024 07:14] Enriching papers with extra data.
[15.11.2024 07:14] ********************************************************************************
[15.11.2024 07:14] Abstract 0. Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques. In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas. Our system features a streamlined yet functionally robust interfa...
[15.11.2024 07:14] ********************************************************************************
[15.11.2024 07:14] Abstract 1. This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling con...
[15.11.2024 07:14] ********************************************************************************
[15.11.2024 07:14] Abstract 2. Large Language Models (LLMs) hold great promise to revolutionize current clinical systems for their superior capacities on medical text processing tasks and medical licensing exams. Meanwhile, traditional ML models such as SVM and XGBoost have still been mainly adopted in clinical prediction tasks. ...
[15.11.2024 07:14] ********************************************************************************
[15.11.2024 07:14] Abstract 3. As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabu...
[15.11.2024 07:14] Read previous papers.
[15.11.2024 07:14] Generating reviews via LLM API.
[15.11.2024 07:14] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#cv"], "emoji": "üñåÔ∏è", "ru": {"title": "MagicQuill: –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "MagicQuill - —ç—Ç–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å (MLLM) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞
[15.11.2024 07:14] Using data from previous issue: {"categories": ["#optimization", "#games", "#3d", "#multimodal", "#training"], "emoji": "üß†", "ru": {"title": "–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —É—á–∞—Ç—Å—è —Å–æ–∑–¥–∞–≤–∞—Ç—å 3D-–º–∏—Ä—ã", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç LLaMA-Mesh
[15.11.2024 07:14] Using data from previous issue: {"categories": ["#science", "#benchmark", "#healthcare", "#reasoning"], "emoji": "üè•", "ru": {"title": "LLM vs —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–µ ML: –∫—Ç–æ –ø–æ–±–µ–¥–∏—Ç –≤ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏?", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ ClinicalBench –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–æ–¥
[15.11.2024 07:14] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üß†", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–∞–º—è—Ç–∏: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Cut Cross-Entropy (CCE) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –≤ –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. CCE –∑–Ω
[15.11.2024 07:14] Loading Chinese text from previous data.
[15.11.2024 07:14] Renaming data file.
[15.11.2024 07:14] Renaming previous data. hf_papers.json to ./d/2024-11-15.json
[15.11.2024 07:14] Saving new data file.
[15.11.2024 07:14] Generating page.
[15.11.2024 07:14] Renaming previous page.
[15.11.2024 07:14] Renaming previous data. index.html to ./d/2024-11-15.html
[15.11.2024 07:14] [Experimental] Generating Chinese page for reading.
[15.11.2024 07:14] Chinese vocab [{'word': 'ËÆ®ËÆ∫', 'pinyin': 't«éo l√πn', 'trans': 'discuss'}, {'word': 'ÊåëÊàò', 'pinyin': 'ti«éo zh√†n', 'trans': 'challenge'}, {'word': 'Áé∞Êúâ', 'pinyin': 'xi√†n y«íu', 'trans': 'existing'}, {'word': '‰æùËµñ', 'pinyin': 'yƒ´ l√†i', 'trans': 'rely on'}, {'word': '‰∏ìÂÆ∂', 'pinyin': 'zhuƒÅn jiƒÅ', 'trans': 'expert'}, {'word': 'Ê†áÊ≥®', 'pinyin': 'biƒÅo zh√π', 'trans': 'annotate'}, {'word': 'Êï∞ÊçÆ', 'pinyin': 'sh√π j√π', 'trans': 'data'}, {'word': 'ÈôêÂà∂', 'pinyin': 'xi√†n zh√¨', 'trans': 'limit'}, {'word': 'Ëøõ‰∏ÄÊ≠•', 'pinyin': 'j√¨n yƒ´ b√π', 'trans': 'further'}, {'word': 'ÂèëÂ±ï', 'pinyin': 'fƒÅ zh«én', 'trans': 'develop'}, {'word': 'ÊèêÂá∫', 'pinyin': 't√≠ ch≈´', 'trans': 'propose'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': 'Áß∞‰∏∫', 'pinyin': 'chƒìng w√©i', 'trans': 'called'}, {'word': 'Ëá™Êàë', 'pinyin': 'z√¨ w«í', 'trans': 'self'}, {'word': 'ÊèêÂçá', 'pinyin': 't√≠ shƒìng', 'trans': 'improve'}, {'word': 'ÈááÊ†∑', 'pinyin': 'c«éi y√†ng', 'trans': 'sample'}, {'word': 'ËæìÂá∫', 'pinyin': 'sh≈´ ch≈´', 'trans': 'output'}, {'word': 'Ë¥ùÂè∂ÊñØ', 'pinyin': 'b√®i y√® sƒ´', 'trans': 'Bayesian'}, {'word': 'È£éÈô©', 'pinyin': 'fƒìng xi«én', 'trans': 'risk'}, {'word': 'ËØÑÂàÜ', 'pinyin': 'p√≠ng fƒìn', 'trans': 'score'}, {'word': 'ÁõëÁù£', 'pinyin': 'jiƒÅn d≈´', 'trans': 'supervise'}, {'word': 'ÂæÆË∞É', 'pinyin': 'wƒìi ti√°o', 'trans': 'fine-tune'}, {'word': 'ÂÅèÂ•Ω', 'pinyin': 'piƒÅn h√†o', 'trans': 'preference'}, {'word': '‰ºòÂåñ', 'pinyin': 'y≈çu hu√†', 'trans': 'optimize'}, {'word': 'ËØÅÊòé', 'pinyin': 'zh√®ng m√≠ng', 'trans': 'prove'}, {'word': 'È¢ÜÂÖà', 'pinyin': 'l«êng xiƒÅn', 'trans': 'leading'}, {'word': 'Ë∂ÖË∂ä', 'pinyin': 'chƒÅo yu√®', 'trans': 'surpass'}]
[15.11.2024 07:14] Renaming previous Chinese page.
[15.11.2024 07:14] Renaming previous data. zh.html to ./d/2024-11-14_zh_reading_task.html
[15.11.2024 07:14] Writing Chinese reading task.
[15.11.2024 07:14] Writing result.
[15.11.2024 07:14] Renaming log file.
[15.11.2024 07:14] Renaming previous data. log.txt to ./logs/2024-11-15_last_log.txt
