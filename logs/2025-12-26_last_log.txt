[26.12.2025 03:27] Read previous papers.
[26.12.2025 03:27] Generating top page (month).
[26.12.2025 03:27] Writing top page (month).
[26.12.2025 04:36] Read previous papers.
[26.12.2025 04:36] Get feed.
[26.12.2025 04:36] Get page data from previous paper. URL: https://huggingface.co/papers/2512.21218
[26.12.2025 04:36] Get page data from previous paper. URL: https://huggingface.co/papers/2512.13043
[26.12.2025 04:36] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.12.2025 04:36] No deleted papers detected.
[26.12.2025 04:36] Downloading and parsing papers (pdf, html). Total: 2.
[26.12.2025 04:36] Downloading and parsing paper https://huggingface.co/papers/2512.21218.
[26.12.2025 04:36] Extra JSON file exists (./assets/json/2512.21218.json), skip PDF parsing.
[26.12.2025 04:36] Paper image links file exists (./assets/img_data/2512.21218.json), skip HTML parsing.
[26.12.2025 04:36] Success.
[26.12.2025 04:36] Downloading and parsing paper https://huggingface.co/papers/2512.13043.
[26.12.2025 04:36] Extra JSON file exists (./assets/json/2512.13043.json), skip PDF parsing.
[26.12.2025 04:36] Paper image links file exists (./assets/img_data/2512.13043.json), skip HTML parsing.
[26.12.2025 04:36] Success.
[26.12.2025 04:36] Enriching papers with extra data.
[26.12.2025 04:36] ********************************************************************************
[26.12.2025 04:36] Abstract 0. While Large Multimodal Models (LMMs) have made significant progress, they remain largely text-centric, relying on language as their core reasoning modality. As a result, they are limited in their ability to handle reasoning tasks that are predominantly visual. Recent approaches have sought to addres...
[26.12.2025 04:36] ********************************************************************************
[26.12.2025 04:36] Abstract 1. Multi-turn reinforcement learning (RL) for multi-modal agents built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR)...
[26.12.2025 04:36] Read previous papers.
[26.12.2025 04:36] Generating reviews via LLM API.
[26.12.2025 04:36] Using data from previous issue: {"categories": [], "emoji": "üëÅÔ∏è", "ru": {"title": "–°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ —Ç–µ–∫—Å—Ç–æ—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã –ø—Ä
[26.12.2025 04:36] Using data from previous issue: {"categories": ["#rl", "#multimodal", "#training", "#agents"], "emoji": "üöÄ", "ru": {"title": "–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π —É—á–∏—Ç–µ–ª—å –∏–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è GTR-Turbo ‚Äî —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∏–¥–µ–æ-—è–∑—ã–∫–æ–≤—ã—Ö
[26.12.2025 04:36] Renaming data file.
[26.12.2025 04:36] Renaming previous data. hf_papers.json to ./d/2025-12-26.json
[26.12.2025 04:36] Saving new data file.
[26.12.2025 04:36] Generating page.
[26.12.2025 04:36] Renaming previous page.
[26.12.2025 04:36] Renaming previous data. index.html to ./d/2025-12-26.html
[26.12.2025 04:36] Writing result.
[26.12.2025 04:36] Renaming log file.
[26.12.2025 04:36] Renaming previous data. log.txt to ./logs/2025-12-26_last_log.txt
