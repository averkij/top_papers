[17.07.2025 04:32] Read previous papers.
[17.07.2025 04:32] Generating top page (month).
[17.07.2025 04:32] Writing top page (month).
[17.07.2025 05:18] Read previous papers.
[17.07.2025 05:18] Get feed.
[17.07.2025 05:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12465
[17.07.2025 05:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.09477
[17.07.2025 05:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.11949
[17.07.2025 05:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.11527
[17.07.2025 05:18] Get page data from previous paper. URL: https://huggingface.co/papers/2507.09025
[17.07.2025 05:18] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[17.07.2025 05:18] No deleted papers detected.
[17.07.2025 05:18] Downloading and parsing papers (pdf, html). Total: 5.
[17.07.2025 05:18] Downloading and parsing paper https://huggingface.co/papers/2507.12465.
[17.07.2025 05:18] Extra JSON file exists (./assets/json/2507.12465.json), skip PDF parsing.
[17.07.2025 05:18] Paper image links file exists (./assets/img_data/2507.12465.json), skip HTML parsing.
[17.07.2025 05:18] Success.
[17.07.2025 05:18] Downloading and parsing paper https://huggingface.co/papers/2507.09477.
[17.07.2025 05:18] Extra JSON file exists (./assets/json/2507.09477.json), skip PDF parsing.
[17.07.2025 05:18] Paper image links file exists (./assets/img_data/2507.09477.json), skip HTML parsing.
[17.07.2025 05:18] Success.
[17.07.2025 05:18] Downloading and parsing paper https://huggingface.co/papers/2507.11949.
[17.07.2025 05:18] Extra JSON file exists (./assets/json/2507.11949.json), skip PDF parsing.
[17.07.2025 05:18] Paper image links file exists (./assets/img_data/2507.11949.json), skip HTML parsing.
[17.07.2025 05:18] Success.
[17.07.2025 05:18] Downloading and parsing paper https://huggingface.co/papers/2507.11527.
[17.07.2025 05:18] Extra JSON file exists (./assets/json/2507.11527.json), skip PDF parsing.
[17.07.2025 05:18] Paper image links file exists (./assets/img_data/2507.11527.json), skip HTML parsing.
[17.07.2025 05:18] Success.
[17.07.2025 05:18] Downloading and parsing paper https://huggingface.co/papers/2507.09025.
[17.07.2025 05:18] Extra JSON file exists (./assets/json/2507.09025.json), skip PDF parsing.
[17.07.2025 05:18] Paper image links file exists (./assets/img_data/2507.09025.json), skip HTML parsing.
[17.07.2025 05:18] Success.
[17.07.2025 05:18] Enriching papers with extra data.
[17.07.2025 05:18] ********************************************************************************
[17.07.2025 05:18] Abstract 0. PhysX addresses the lack of physical properties in 3D generative models by introducing PhysXNet, a physics-annotated dataset, and PhysXGen, a framework that integrates physical knowledge into 3D asset generation.  					AI-generated summary 				 3D modeling is moving from virtual to physical. Existin...
[17.07.2025 05:18] ********************************************************************************
[17.07.2025 05:18] Abstract 1. This survey integrates reasoning and retrieval in Large Language Models to improve factuality and multi-step inference, highlighting Synergized RAG-Reasoning frameworks and outlining future research directions.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) lifts the factuality...
[17.07.2025 05:18] ********************************************************************************
[17.07.2025 05:18] Abstract 2. A diffusion-based generative framework, MOSPA, is introduced to model human motion in response to spatial audio, achieving state-of-the-art performance using the newly created SAM dataset.  					AI-generated summary 				 Enabling virtual humans to dynamically and realistically respond to diverse aud...
[17.07.2025 05:18] ********************************************************************************
[17.07.2025 05:18] Abstract 3. DrafterBench is an open-source benchmark for evaluating LLM agents in technical drawing revision, assessing their capabilities in structured data comprehension, function execution, instruction following, and critical reasoning.  					AI-generated summary 				 Large Language Model (LLM) agents have s...
[17.07.2025 05:18] ********************************************************************************
[17.07.2025 05:18] Abstract 4. Lizard is a linearization framework that transforms Transformer-based LLMs into subquadratic architectures for efficient infinite-context generation, using a hybrid attention mechanism and hardware-aware training.  					AI-generated summary 				 We propose Lizard, a linearization framework that tran...
[17.07.2025 05:18] Read previous papers.
[17.07.2025 05:18] Generating reviews via LLM API.
[17.07.2025 05:18] Using data from previous issue: {"categories": ["#architecture", "#synthetic", "#games", "#3d", "#open_source", "#dataset"], "emoji": "üß±", "ru": {"title": "–§–∏–∑–∏—á–µ—Å–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 3D-–æ–±—ä–µ–∫—Ç–æ–≤", "desc": "PhysX –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –∏—Ö —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç Phys
[17.07.2025 05:18] Using data from previous issue: {"categories": ["#reasoning", "#multimodal", "#benchmark", "#survey", "#rag"], "emoji": "üß†", "ru": {"title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª–µ–µ –º–æ—â–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–æ –æ–±–∑–æ—Ä –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LL
[17.07.2025 05:18] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#benchmark", "#open_source", "#dataset"], "emoji": "üéß", "ru": {"title": "–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è –¥–≤–∏–∂–µ–Ω–∏–π –ø–æ–¥ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ MOSPA - –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞ –≤ –æ
[17.07.2025 05:18] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#open_source", "#long_context", "#agents"], "emoji": "üìê", "ru": {"title": "DrafterBench: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ LLM-–∞–≥–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏", "desc": "DrafterBench - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM)
[17.07.2025 05:18] Using data from previous issue: {"categories": ["#benchmark", "#architecture", "#optimization", "#training", "#long_context"], "emoji": "ü¶é", "ru": {"title": "Lizard: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Å –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º", "desc": "Lizard - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ª–∏–Ω–µ–∞—Ä–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤ —Å—É–±–∫–≤–∞–¥—Ä–∞—Ç–∏—á
[17.07.2025 05:18] Renaming data file.
[17.07.2025 05:18] Renaming previous data. hf_papers.json to ./d/2025-07-17.json
[17.07.2025 05:18] Saving new data file.
[17.07.2025 05:18] Generating page.
[17.07.2025 05:18] Renaming previous page.
[17.07.2025 05:18] Renaming previous data. index.html to ./d/2025-07-17.html
[17.07.2025 05:18] Writing result.
[17.07.2025 05:18] Renaming log file.
[17.07.2025 05:18] Renaming previous data. log.txt to ./logs/2025-07-17_last_log.txt
