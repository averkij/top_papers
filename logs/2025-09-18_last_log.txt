[17.09.2025 23:10] Read previous papers.
[17.09.2025 23:10] Generating top page (month).
[17.09.2025 23:10] Writing top page (month).
[18.09.2025 00:48] Read previous papers.
[18.09.2025 00:48] Get feed.
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13312
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13310
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13305
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13311
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13309
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13313
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13232
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12815
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13317
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12603
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12341
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06079
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12521
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.11526
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.11481
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.11177
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10687
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13177
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.12541
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10706
[18.09.2025 00:48] Get page data from previous paper. URL: https://huggingface.co/papers/2509.10696
[18.09.2025 00:48] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.09.2025 00:48] No deleted papers detected.
[18.09.2025 00:48] Downloading and parsing papers (pdf, html). Total: 21.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13312.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13312.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13312.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13310.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13310.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13310.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13305.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13305.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13305.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13311.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13311.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13311.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13309.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13309.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13309.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13313.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13313.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13313.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13232.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13232.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13232.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.12815.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.12815.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.12815.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13317.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13317.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13317.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.12603.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.12603.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.12603.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.12341.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.12341.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.12341.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.06079.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.06079.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.06079.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.12521.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.12521.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.12521.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.11526.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.11526.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.11526.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.11481.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.11481.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.11481.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.11177.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.11177.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.11177.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.10687.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.10687.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.10687.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.13177.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.13177.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.13177.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.12541.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.12541.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.12541.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.10706.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.10706.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.10706.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Downloading and parsing paper https://huggingface.co/papers/2509.10696.
[18.09.2025 00:48] Extra JSON file exists (./assets/json/2509.10696.json), skip PDF parsing.
[18.09.2025 00:48] Paper image links file exists (./assets/img_data/2509.10696.json), skip HTML parsing.
[18.09.2025 00:48] Success.
[18.09.2025 00:48] Enriching papers with extra data.
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 0. WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.  					AI-generated summary 				 This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents m...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 1. AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.  					AI-generated summary 				 Large language models (LLMs) have evolved into agentic systems capable of autonomo...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 2. WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.  					AI-generated summary 				 Transcending human cognitive limitations represents a critical frontier in LLM tra...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 3. A scalable framework and two-phase fine-tuning strategy enhance function-calling capabilities of agents in diverse environments, improving performance on agentic benchmarks.  					AI-generated summary 				 Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practic...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 4. WebResearcher, a deep-research framework, enhances AI agents' knowledge synthesis by reformulating research as a Markov Decision Process and using a scalable data synthesis engine, achieving superior performance across benchmarks.  					AI-generated summary 				 Recent advances in deep-research syst...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 5. ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.  					AI-generated summary 				 Large Language Model (LLM)-based web agents demonstrate ...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 6. Single-stream Policy Optimization (SPO) improves policy-gradient training for Large Language Models by eliminating group-based issues and providing a stable, low-variance learning signal, leading to better performance and efficiency.  					AI-generated summary 				 We revisit policy-gradient optimiz...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 7. Hunyuan3D Studio automates 3D asset creation using AI, integrating neural modules to transform concept images or text into high-quality, game-ready 3D models with optimized geometry and PBR textures.  					AI-generated summary 				 The creation of high-quality 3D assets, a cornerstone of modern game...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 8. A Spatial Region 3D (SR-3D) vision-language model unifies 2D and 3D representations by enriching 2D features with 3D positional embeddings, enabling flexible region prompting and accurate spatial reasoning across frames.  					AI-generated summary 				 We present Spatial Region 3D (SR-3D) aware visi...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 9. Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  					AI-generated summary 				 Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performanc...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 10. A replacement for the domain-extension step in a quantum lattice algorithm uses a pair-shift difference construction to correct periodicity issues and enforce modular linear relations efficiently.  					AI-generated summary 				 We give a simple, fully correct, and assumption-light replacement for t...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 11. A caption-assisted reasoning framework bridges visual and textual modalities, achieving top performance in multimodal reasoning tasks like SeePhys and MathVerse.  					AI-generated summary 				 Multimodal reasoning remains a fundamental challenge in artificial intelligence. Despite substantial advan...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 12. A novel method, Preference Hijacking (Phi), manipulates Multimodal Large Language Model (MLLM) response preferences using specially crafted images, demonstrating significant effectiveness across various tasks.  					AI-generated summary 				 Recently, Multimodal Large Language Models (MLLMs) have ga...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 13. A novel MIL framework, MHIM-MIL, uses masked hard instance mining with a Siamese structure and momentum teacher to improve cancer diagnosis and subtyping accuracy.  					AI-generated summary 				 Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has opened new avenues for Compu...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 14. A method called RAPTOR enables a single neural network policy to adapt zero-shot to various quadrotors using Meta-Imitation Learning and In-Context Learning with recurrence in the hidden layer.  					AI-generated summary 				 Humans are remarkably data-efficient when adapting to new unseen condition...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 15. A framework combining quantization and pruning in LLMs through error compensation achieves significant speedup and memory reduction.  					AI-generated summary 				 Recent advances in Large Language Model (LLM) compression, such as quantization and pruning, have achieved notable success. However, as...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 16. SP4D generates paired RGB and kinematic part videos from monocular inputs using a dual-branch diffusion model with spatial color encoding and BiDiFuse module, demonstrating strong generalization to diverse scenarios.  					AI-generated summary 				 We present Stable Part Diffusion 4D (SP4D), a frame...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 17. ROOM is a simulation framework that generates photorealistic bronchoscopy training data using patient CT scans, enabling the development and validation of autonomy algorithms in medical robotics.  					AI-generated summary 				 Continuum robots are advancing bronchoscopy procedures by accessing comp...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 18. A novel training methodology named zELO optimizes retrieval performance by treating ranking tasks as equivalent to a Thurstone model, resulting in state-of-the-art open-weight reranker models that outperform proprietary models across various domains.  					AI-generated summary 				 We introduce a no...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 19. A digital compressor is optimized using the Newton-Raphson method to emulate the behavior of an analogue levelling amplifier, demonstrating efficient training and approximation using parallel recursive filters.  					AI-generated summary 				 Automatic differentiation through digital signal processi...
[18.09.2025 00:48] ********************************************************************************
[18.09.2025 00:48] Abstract 20. Struct-Bench is a framework and benchmark for evaluating synthetic structured datasets with natural language components, addressing challenges in differentially private synthetic data generation.  					AI-generated summary 				 Differentially private (DP) synthetic data generation is a promising tec...
[18.09.2025 00:48] Read previous papers.
[18.09.2025 00:48] Generating reviews via LLM API.
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#hallucinations", "#long_context", "#multimodal", "#agents"], "emoji": "üï∏Ô∏è", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç WebWeaver - –¥–≤—É—Ö–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#agents", "#optimization", "#training", "#agi"], "emoji": "ü§ñ", "ru": {"title": "AgentFounder: –Ω–æ–≤—ã–π —à–∞–≥ –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ AgentFounder - –º–æ–¥–µ–ª—å –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â—É—é –ê–≥–µ–Ω—Ç
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#training", "#optimization", "#open_source", "#agents", "#agi"], "emoji": "üß≠", "ru": {"title": "WebSailor: –æ—Ç–∫—Ä—ã—Ç—ã–π –ø—É—Ç—å –∫ —Å–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–º—É –ø–æ–∏—Å–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "WebSailor - —ç—Ç–æ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agi", "#training", "#agents"], "emoji": "ü§ñ", "ru": {"title": "–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–π –≤ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—É—é —Å–∏—Å—Ç–µ–º—É –∏ –¥–≤—É—Ö—Ñ–∞–∑–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–æ–æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#science", "#dataset", "#training", "#agents", "#transfer_learning"], "emoji": "üï∏Ô∏è", "ru": {"title": "WebResearcher: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –ò–ò", "desc": "WebResearcher - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Å–ø–æ—Å–æ
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#training", "#optimization", "#long_context", "#agents"], "emoji": "üß†", "ru": {"title": "ReSum: —Ä–∞–∑–¥–≤–∏–≥–∞—è –≥—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ ReSum, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#reasoning"], "emoji": "üöÄ", "ru": {"title": "SPO: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Single-stream Policy Optimization (SPO). SPO 
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "üéÆ", "ru": {"title": "–ò–ò —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ 3D-–∞—Å—Å–µ—Ç–æ–≤ –¥–ª—è –∏–≥—Ä", "desc": "Hunyuan3D Studio - —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è 3D-–∞—Å—Å–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. –°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏ 
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#games", "#3d", "#cv", "#multimodal", "#reasoning"], "emoji": "üîç", "ru": {"title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ 2D –∏ 3D –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞", "desc": "SR-3D - —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è 2D –∏ 3D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∞ –æ–±–æ–≥–∞—â–∞–µ—Ç 2D –ø—Ä–∏–∑–Ω–∞–∫–∏ 
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#training", "#inference", "#optimization"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ —Ç–µ–æ—Ä–µ–º: –º–µ–Ω—å—à–µ –∑–∞—Ç—Ä–∞—Ç, —Ç–∞ –∂–µ –º–æ—â–Ω–æ—Å—Ç—å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–∞ –º–µ—Ç–æ–¥–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç –≤ –º–æ–¥–µ–ª—è—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫–∞
[18.09.2025 00:48] Using data from previous issue: {"categories": [], "emoji": "üî¨", "ru": {"title": "–£—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–≤–∞–Ω—Ç–æ–≤–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–µ—à–µ—Ç–∫–∏: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ä–µ—à–µ—Ç–∫–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∑–∞–º–µ–Ω—É –¥–ª—è —à–∞–≥–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–æ–º–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é —Ä–∞–∑–Ω–æ—Å—Ç–∏ –ø–∞—Ä–Ω—ã—Ö —Å–¥–≤–∏–≥–æ
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#reasoning", "#open_source", "#benchmark", "#multimodal"], "emoji": "üß†", "ru": {"title": "–ú–æ—Å—Ç –º–µ–∂–¥—É –∑—Ä–µ–Ω–∏–µ–º –∏ —è–∑—ã–∫–æ–º: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º—É –ò–ò", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏.
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#multimodal", "#inference", "#ethics", "#security"], "emoji": "üé≠", "ru": {"title": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ –ò–ò —á–µ—Ä–µ–∑ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏", "desc": "–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Preference Hijacking (Phi) –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#science", "#optimization", "#training", "#healthcare"], "emoji": "üî¨", "ru": {"title": "–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–∞–∫–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å —ç–∫–∑–µ–º–ø–ª—è—Ä–∞–º–∏ (MIL) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#agents", "#rl", "#transfer_learning", "#small_models", "#training", "#optimization", "#robotics"], "emoji": "üöÅ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–≤–∞–¥—Ä–æ–∫–æ–ø—Ç–µ—Ä–∞–º–∏ —Å –ø–æ–º–æ—â—å—é –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "desc": "–ú–µ—Ç–æ–¥ RAPTOR –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ–¥–∏–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ 
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üß†", "ru": {"title": "–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–∑–≥–∞: —Å–∂–∞—Ç–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), —Å–æ—á–µ—Ç–∞—é—â–∏–π –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä—É–Ω–∏–Ω–≥. –ê–≤
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#dataset", "#3d", "#cv", "#synthetic", "#diffusion"], "emoji": "ü§ñ", "ru": {"title": "SP4D: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∏–Ω–µ–º–∞—Ç–∏—á–µ—Å–∫–∏-–æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –∏–∑ –º–æ–Ω–æ–∫—É–ª—è—Ä–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "SP4D - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä–Ω—ã—Ö RGB –∏ –∫–∏–Ω–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤–∏–¥–µ–æ —á–∞—Å—Ç–µ–π –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –º–æ–Ω–æ–∫—É–ª—è—Ä–Ω—ã—Ö –≤—Ö–æ–¥–Ω
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#cv", "#synthetic", "#data", "#robotics", "#training", "#transfer_learning", "#dataset"], "emoji": "ü´Å", "ru": {"title": "–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è —Å–∏–º—É–ª—è—Ü–∏—è –±—Ä–æ–Ω—Ö–æ—Å–∫–æ–ø–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ", "desc": "ROOM - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#dataset", "#training"], "emoji": "üîç", "ru": {"title": "zELO: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—é –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º zELO, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—è –∑
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#data", "#training", "#optimization", "#architecture", "#open_source"], "emoji": "üéõÔ∏è", "ru": {"title": "–¶–∏—Ñ—Ä–æ–≤–∞—è —ç–º—É–ª—è—Ü–∏—è –∞–Ω–∞–ª–æ–≥–æ–≤–æ–≥–æ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–∞: –±—ã—Å—Ç—Ä–æ, —Ç–æ—á–Ω–æ, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ", "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç–æ–¥ —ç–º—É–ª—è—Ü–∏–∏ –∞–Ω–∞–ª–æ–≥–æ–≤—ã—Ö –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ
[18.09.2025 00:48] Using data from previous issue: {"categories": ["#benchmark", "#leakage", "#open_source", "#synthetic", "#dataset"], "emoji": "üîí", "ru": {"title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "Struct-Bench - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –∏ –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω
[18.09.2025 00:48] Renaming data file.
[18.09.2025 00:48] Renaming previous data. hf_papers.json to ./d/2025-09-18.json
[18.09.2025 00:48] Saving new data file.
[18.09.2025 00:48] Generating page.
[18.09.2025 00:48] Renaming previous page.
[18.09.2025 00:48] Renaming previous data. index.html to ./d/2025-09-18.html
[18.09.2025 00:48] Writing result.
[18.09.2025 00:48] Renaming log file.
[18.09.2025 00:48] Renaming previous data. log.txt to ./logs/2025-09-18_last_log.txt
