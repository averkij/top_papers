[01.09.2025 09:14] Read previous papers.
[01.09.2025 09:14] Generating top page (month).
[01.09.2025 09:14] Writing top page (month).
[01.09.2025 10:13] Read previous papers.
[01.09.2025 10:13] Get feed.
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21113
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21112
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18106
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20470
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.13618
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21365
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17677
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21290
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21767
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21456
[01.09.2025 10:13] Extract page data from URL. URL: https://huggingface.co/papers/2508.21148
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.21376
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.20085
[01.09.2025 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14197
[01.09.2025 10:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[01.09.2025 10:13] No deleted papers detected.
[01.09.2025 10:13] Downloading and parsing papers (pdf, html). Total: 14.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21113.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.21113.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.21113.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21112.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.21112.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.21112.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.18106.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.18106.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.18106.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.20470.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.20470.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.20470.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.13618.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.13618.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.13618.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21365.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.21365.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.21365.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.17677.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.17677.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.17677.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21290.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.21290.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.21290.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21767.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.21767.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.21767.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21456.
[01.09.2025 10:13] Extra JSON file exists (./assets/json/2508.21456.json), skip PDF parsing.
[01.09.2025 10:13] Paper image links file exists (./assets/img_data/2508.21456.json), skip HTML parsing.
[01.09.2025 10:13] Success.
[01.09.2025 10:13] Downloading and parsing paper https://huggingface.co/papers/2508.21148.
[01.09.2025 10:13] Downloading paper 2508.21148 from http://arxiv.org/pdf/2508.21148v1...
[01.09.2025 11:04] Extracting affiliations from text.
[01.09.2025 11:04] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 2 ] . [ 1 8 4 1 1 2 . 8 0 5 2 : r Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers Ming Hu1,2 Chenglong Ma1,3 Wei Li1,4 Wanghan Xu1,4 Guohang Zhuang Jiaqi Liu1,7 Yingzhou Lu8 Ying Chen1 Chaoyang Zhang1 Cheng Tan1 Jucheng Hu1,6 Tianbin Li1 Jie Ying1 Jiamin Wu1,5 Guocheng Wu1 Shujian Gao1 Pengcheng Chen1 Jiashi Lin1 Haitao Wu1 Lulu Chen9 Fengxiang Wang1 Yuanyuan Zhang10 Xiangyu Zhao1 Feilong Tang1,2 Encheng Su Junzhi Ning1 Xinyao Liu1 Ye Du1 Changkai Ji1 Cheng Tang1 Huihui Xu1 Ziyang Chen1 Ziyan Huang1 Yizhou Wang1 Chen Tang1 Shiyan Su2 Shangquan Sun1 Runkai Zhao1 Zhisheng Zhang12 Yu Liu13 Fudi Wang14 Yuanfeng Ji8 Jianyu Wu1 Yuchen Ren1 Siyuan Yan2 Zhonghua Wang2 Zhongxing Xu2 Jiyao Liu1,3 Pengfei Jiang1 Yanzhou Su15 Hongming Shan3 Chunmei Feng16 Jiahao Xu Jiangtao Yan1 Wenhao Tang1 Diping Song1 Lihao Liu1 Yanyan Huang11 Lequan Yu11 Bin Fu1 Shujun Wang17 Xiaomeng Li18 Xiaowei Hu19 Yun Gu4 Ben Fei5 Zhongying Deng20 Benyou Wang21 Yuewen Cao1 Minjie Shen9 Haodong Duan1 Jie Xu1 Yirong Chen1 Fang Yan1 Hongxia Hao1 Jielan Li1 Jiajun Du22 Yanbo Wang Imran Razzak24 Chi Zhang1 Lijun Wu1 Conghui He1 Zhaohui Lu4 Jinhai Huang3 Yihao Liu1 Fenghua Ling1 Yuqiang Li1 Aoran Wang1 Qihao Zheng1 Nanqing Dong1 Tianfan Fu25,1 Dongzhan Zhou1 Yan Lu1 Wenlong Zhang1 Jin Ye1,2 Zongyuan Ge2 Shixiang Tang1,5 Junjun He1 Jianfei Cai2 Wanli Ouyang1,5 Yu Qiao1 Lei Bai1 Bowen Zhou1 Chunfeng Song1 1Shanghai Artificial Intelligence Laboratory 2Monash University 3Fudan University 4Shanghai Jiao Tong University 5The Chinese University of Hong Kong 6University College London 7UNC-Chapel Hill 8Stanford University 9Virginia Tech 10Purdue University 11The University of Hong Kong 12China Pharmaceutical University 13Beijing Institute of Heart, Lung and Blood Vessel Diseases 14Chinese Academy of Sciences 15Fuzhou University 16University College Dublin 17The Hong Kong Polytechnic University 18The Hong Kong University of Science and Technology 19South China University"
[01.09.2025 11:04] Response: ```python
[
    "Shanghai Artificial Intelligence Laboratory",
    "Monash University",
    "Fudan University",
    "Shanghai Jiao Tong University",
    "The Chinese University of Hong Kong",
    "University College London",
    "UNC-Chapel Hill",
    "Stanford University",
    "Virginia Tech",
    "Purdue University",
    "The University of Hong Kong",
    "China Pharmaceutical University",
    "Beijing Institute of Heart, Lung and Blood Vessel Diseases",
    "Chinese Academy of Sciences",
    "Fuzhou University",
    "University College Dublin",
    "The Hong Kong Polytechnic University",
    "The Hong Kong University of Science and Technology",
    "South China University"
]
```
[01.09.2025 11:04] Deleting PDF ./assets/pdf/2508.21148.pdf.
[01.09.2025 11:04] Failed to download and parse paper https://huggingface.co/papers/2508.21148: Function execution timed out after 300 seconds.
[01.09.2025 11:04] Downloading and parsing paper https://huggingface.co/papers/2508.21376.
[01.09.2025 11:04] Extra JSON file exists (./assets/json/2508.21376.json), skip PDF parsing.
[01.09.2025 11:04] Paper image links file exists (./assets/img_data/2508.21376.json), skip HTML parsing.
[01.09.2025 11:04] Success.
[01.09.2025 11:04] Downloading and parsing paper https://huggingface.co/papers/2508.20085.
[01.09.2025 11:04] Extra JSON file exists (./assets/json/2508.20085.json), skip PDF parsing.
[01.09.2025 11:04] Paper image links file exists (./assets/img_data/2508.20085.json), skip HTML parsing.
[01.09.2025 11:04] Success.
[01.09.2025 11:04] Downloading and parsing paper https://huggingface.co/papers/2508.14197.
[01.09.2025 11:04] Downloading paper 2508.14197 from http://arxiv.org/pdf/2508.14197v1...
[01.09.2025 11:05] Failed to download and parse paper https://huggingface.co/papers/2508.14197: 'LTChar' object is not iterable
[01.09.2025 11:05] Enriching papers with extra data.
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 0. R-4B, an auto-thinking multimodal large language model, uses bi-mode annealing and Bi-mode Policy Optimization to adaptively decide on problem-solving strategies, achieving state-of-the-art performance with lower computational cost.  					AI-generated summary 				 Multimodal Large Language Models (M...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 1. EO-Robotics, comprising EO-1 model and EO-Data1.5M dataset, advances multimodal embodied reasoning and robot control through interleaved vision-text-action pre-training.  					AI-generated summary 				 The human ability to seamlessly perform multimodal reasoning and physical interaction in the open ...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 2. A.S.E is a benchmark for evaluating the security of code generated by large language models using real-world repositories and expert-defined rules, revealing insights into model performance and decoding strategies.  					AI-generated summary 				 The increasing adoption of large language models (LLM...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 3. Using video data to provide commonsense priors enhances 3D asset generation, enabling spatial consistency and semantic plausibility in 3D content creation.  					AI-generated summary 				 Scaling laws have validated the success and promise of large-data-trained models in creative generation across t...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 4. TalkVid, a large-scale, high-quality, and diverse dataset, improves audio-driven talking head synthesis by enhancing generalization across human diversity and revealing subgroup performance disparities.  					AI-generated summary 				 Audio-driven talking head synthesis has achieved remarkable photo...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 5. Think in Games (TiG) framework enables large language models to develop procedural knowledge through interactive game environments, achieving competitive performance with reduced data and computational demands while providing transparent explanations.  					AI-generated summary 				 Large language m...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 6. Dynamic adjustment of data mixture based on Group Influence metric improves language model performance by adapting to evolving learning preferences.  					AI-generated summary 				 The data mixture used in the pre-training of a language model is a cornerstone of its final performance. However, a sta...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 7. Jina-code-embeddings uses an autoregressive backbone pre-trained on text and code to generate embeddings for code retrieval, question-answering, and similarity identification.  					AI-generated summary 				 jina-code-embeddings is a novel code embedding model suite designed to retrieve code from na...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 8. UItron, an open-source foundational model for GUI agents, enhances visual understanding and task planning through advanced perception, grounding, and planning capabilities, achieving superior performance in Chinese app scenarios.  					AI-generated summary 				 GUI agent aims to enable automated ope...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 9. Morae, a UI agent, enhances accessibility for BLV users by involving them in decision-making processes during task execution, using large multimodal models to interpret user queries and UI elements.  					AI-generated summary 				 User interface (UI) agents promise to make inaccessible or complex UI...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 10. Sci-LLMs are evolving through a co-development with scientific data, addressing unique challenges like multimodal and domain-specific information, and are moving towards autonomous, closed-loop systems in scientific research.  					AI-generated summary 				 Scientific Large Language Models (Sci-LLMs...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 11. AHELM is a comprehensive benchmark for audio-language models that evaluates multiple aspects including fairness, safety, and reasoning across various datasets and models.  					AI-generated summary 				 Evaluations of audio-language models (ALMs) -- multimodal models that take interleaved audio and ...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 12. HERMES is a human-to-robot learning framework that translates human hand motions into robotic behaviors, using reinforcement learning and sim2real transfer for versatile manipulation in diverse environments.  					AI-generated summary 				 Leveraging human motion data to impart robots with versatile...
[01.09.2025 11:05] ********************************************************************************
[01.09.2025 11:05] Abstract 13. CLIPSym, a vision-language model using CLIP, enhances symmetry detection through a rotation-equivariant decoder and semantic-aware prompting, outperforming existing methods on standard datasets.  					AI-generated summary 				 Symmetry is one of the most fundamental geometric cues in computer vision...
[01.09.2025 11:05] Read previous papers.
[01.09.2025 11:05] Generating reviews via LLM API.
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#training", "#multimodal", "#reasoning", "#benchmark", "#dataset", "#optimization"], "emoji": "🧠", "ru": {"title": "R-4B: Адаптивное мышление для эффективного решения задач", "desc": "R-4B - это мультимодальная большая языковая модель с возможностью автоматического мышления. Она исп
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#architecture", "#training", "#agents", "#multimodal", "#agi", "#reasoning", "#dataset"], "emoji": "🤖", "ru": {"title": "Революция в мультимодальном ИИ для роботов: EO-Robotics объединяет зрение, текст и действие", "desc": "EO-Robotics представляет собой систему, состоящую из модели
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#open_source", "#security", "#benchmark", "#dataset"], "emoji": "🛡️", "ru": {"title": "A.S.E: Новый стандарт оценки безопасности ИИ-генерируемого кода", "desc": "A.S.E - это новый бенчмарк для оценки безопасности кода, генерируемого большими языковыми моделями (LLM). Он использует р
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#dataset", "#3d", "#multimodal", "#open_source", "#synthetic"], "emoji": "🎥", "ru": {"title": "Видео как источник здравого смысла для 3D-генерации", "desc": "Эта статья исследует применение видеоданных для улучшения генерации 3D-объектов. Авторы представляют датасет Droplet3D-4M с а
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#ethics", "#transfer_learning", "#dataset", "#cv", "#data"], "emoji": "🗣️", "ru": {"title": "TalkVid: большой и разнообразный датасет для улучшения синтеза говорящих голов", "desc": "Представлен новый набор данных TalkVid для улучшения синтеза говорящих
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#training", "#games", "#optimization", "#reasoning", "#interpretability", "#multimodal", "#rl", "#rlhf"], "emoji": "🎮", "ru": {"title": "Обучение ИИ через игры: от знаний к умениям", "desc": "Предложена новая система Think in Games (TiG), позволяющая большим языковым моделям развива
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#data", "#optimization", "#training"], "emoji": "🔄", "ru": {"title": "Динамическая оптимизация данных для эффективного обучения языковых моделей", "desc": "Статья представляет TiKMiX - метод динамической корректировки смеси данных для предобучения языковых моделей. Авторы вводят мет
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#multilingual", "#transfer_learning", "#data", "#dataset", "#games", "#plp", "#small_models", "#training"], "emoji": "🧠", "ru": {"title": "Умные эмбеддинги для эффективной работы с кодом", "desc": "Jina-code-embeddings - это новая модель встраивания кода, основанная на авторегрессио
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#benchmark", "#rl", "#open_source", "#training", "#optimization", "#reasoning", "#agi", "#dataset", "#data", "#agents"], "emoji": "🤖", "ru": {"title": "UItron: ИИ-агент для автоматизации графических интерфейсов", "desc": "UItron - это модель машинного обучения с открытым исходным ко
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#ethics", "#agi", "#multimodal", "#healthcare", "#agents"], "emoji": "👁️", "ru": {"title": "Morae: ИИ-ассистент, расширяющий возможности пользователей с нарушениями зрения", "desc": "Статья представляет Morae - агента пользовательского интерфейса, который улучшает доступность для по
[01.09.2025 11:05] Querying the API.
[01.09.2025 11:05] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Sci-LLMs are evolving through a co-development with scientific data, addressing unique challenges like multimodal and domain-specific information, and are moving towards autonomous, closed-loop systems in scientific research.  					AI-generated summary 				 Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery.
[01.09.2025 11:05] Response: {
  "desc": "Научные большие языковые модели (Sci-LLMs) развиваются в тесной связи с научными данными, решая уникальные задачи обработки мультимодальной и специализированной информации. В статье представлен комплексный обзор развития Sci-LLMs, включая анализ более 270 наборов данных для предобучения и дообучения моделей. Авторы рассматривают переход от статических тестов к оценке, ориентированной на процесс и открытия, с использованием продвинутых протоколов. Обсуждается парадигма автономных систем на основе Sci-LLMs, способных экспериментировать и вносить вклад в развивающуюся базу знаний.",
  "emoji": "🧬",
  "title": "Sci-LLMs: эволюция искусственного интеллекта в научном познании"
}
[01.09.2025 11:05] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Sci-LLMs are evolving through a co-development with scientific data, addressing unique challenges like multimodal and domain-specific information, and are moving towards autonomous, closed-loop systems in scientific research.  					AI-generated summary 				 Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery."

[01.09.2025 11:05] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'MULTIMODAL', 'AGENTS']
```
[01.09.2025 11:05] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Sci-LLMs are evolving through a co-development with scientific data, addressing unique challenges like multimodal and domain-specific information, and are moving towards autonomous, closed-loop systems in scientific research.  					AI-generated summary 				 Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery."

[01.09.2025 11:05] Response: ```python
['SURVEY', 'SCIENCE']
```
[01.09.2025 11:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the evolution of Scientific Large Language Models (Sci-LLMs) and their interaction with scientific data. It highlights the unique challenges posed by scientific datasets, which are often multimodal and domain-specific, requiring specialized approaches compared to general natural language processing. The authors propose a taxonomy of scientific data and review various Sci-LLMs, emphasizing the need for models that can handle heterogeneous and uncertain information. Ultimately, the paper advocates for the development of autonomous systems that can actively engage in scientific research, contributing to a dynamic knowledge base.","title":"Transforming Science with Autonomous Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the evolution of Scientific Large Language Models (Sci-LLMs) and their interaction with scientific data. It highlights the unique challenges posed by scientific datasets, which are often multimodal and domain-specific, requiring specialized approaches compared to general natural language processing. The authors propose a taxonomy of scientific data and review various Sci-LLMs, emphasizing the need for models that can handle heterogeneous and uncertain information. Ultimately, the paper advocates for the development of autonomous systems that can actively engage in scientific research, contributing to a dynamic knowledge base.', title='Transforming Science with Autonomous Language Models'))
[01.09.2025 11:05] Response: ParsedChatCompletionMessage[Article](content='{"desc":"科学大型语言模型（Sci-LLMs）正在通过与科学数据的共同发展而不断演变，解决多模态和特定领域信息等独特挑战。这项研究提出了一种以数据为中心的综合框架，将Sci-LLMs的发展视为模型与其基础数据之间的共同进化。我们建立了科学数据的统一分类法和科学知识的层次模型，强调了科学语料库与一般自然语言处理数据集之间的区别。最后，我们展望了向闭环系统的转变，强调基于Sci-LLMs的自主代理如何积极实验、验证并为不断发展的知识库做出贡献。","title":"科学研究中的智能合作伙伴"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='科学大型语言模型（Sci-LLMs）正在通过与科学数据的共同发展而不断演变，解决多模态和特定领域信息等独特挑战。这项研究提出了一种以数据为中心的综合框架，将Sci-LLMs的发展视为模型与其基础数据之间的共同进化。我们建立了科学数据的统一分类法和科学知识的层次模型，强调了科学语料库与一般自然语言处理数据集之间的区别。最后，我们展望了向闭环系统的转变，强调基于Sci-LLMs的自主代理如何积极实验、验证并为不断发展的知识库做出贡献。', title='科学研究中的智能合作伙伴'))
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#ethics", "#reasoning", "#multimodal", "#audio", "#dataset"], "emoji": "🎧", "ru": {"title": "AHELM: Всесторонняя оценка аудио-языковых моделей", "desc": "AHELM - это комплексный бенчмарк для оценки аудио-языковых моделей (ALM). Он измеряет 10 аспектов, 
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#rl", "#agents", "#optimization", "#transfer_learning", "#robotics"], "emoji": "🤖", "ru": {"title": "От движений человека к умелым рукам робота", "desc": "HERMES - это система обучения роботов на основе данных о движениях человеческих рук. Она использует обучение с подкреплением и п
[01.09.2025 11:05] Using data from previous issue: {"categories": ["#dataset", "#architecture", "#optimization", "#multimodal", "#cv", "#games"], "emoji": "🔍", "ru": {"title": "CLIPSym: Улучшенное обнаружение симметрии с помощью языковой модели", "desc": "CLIPSym - это новая модель для обнаружения симметрии, использующая предобученную модель CLIP. О
[01.09.2025 11:05] Renaming data file.
[01.09.2025 11:05] Renaming previous data. hf_papers.json to ./d/2025-09-01.json
[01.09.2025 11:05] Saving new data file.
[01.09.2025 11:05] Generating page.
[01.09.2025 11:05] Renaming previous page.
[01.09.2025 11:05] Renaming previous data. index.html to ./d/2025-09-01.html
[01.09.2025 11:05] Writing result.
[01.09.2025 11:05] Renaming log file.
[01.09.2025 11:05] Renaming previous data. log.txt to ./logs/2025-09-01_last_log.txt
