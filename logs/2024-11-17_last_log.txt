[17.11.2024 20:38] Read previous papers.
[17.11.2024 20:38] Generating top page (month).
[17.11.2024 20:38] Writing top page (month).
[17.11.2024 18:28] Read previous papers.
[17.11.2024 18:28] Get feed.
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09595
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09703
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09009
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06469
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.08768
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.08954
[17.11.2024 18:28] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06490
[17.11.2024 18:28] Downloading and parsing papers (pdf, html). Total: 7.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.09595.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.09595.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.09595.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.09703.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.09703.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.09703.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.09009.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.09009.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.09009.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.06469.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.06469.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.06469.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.08768.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.08768.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.08768.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.08954.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.08954.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.08954.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Downloading and parsing paper https://huggingface.co/papers/2411.06490.
[17.11.2024 18:28] Extra JSON file exists (./assets/json/2411.06490.json), skip PDF parsing.
[17.11.2024 18:28] Paper image links file exists (./assets/img_data/2411.06490.json), skip HTML parsing.
[17.11.2024 18:28] Success.
[17.11.2024 18:28] Enriching papers with extra data.
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 0. This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling con...
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 1. Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques. In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas. Our system features a streamlined yet functionally robust interfa...
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 2. As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabu...
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 3. Large Language Models (LLMs) hold great promise to revolutionize current clinical systems for their superior capacities on medical text processing tasks and medical licensing exams. Meanwhile, traditional ML models such as SVM and XGBoost have still been mainly adopted in clinical prediction tasks. ...
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 4. Video recordings of user activities, particularly desktop recordings, offer a rich source of data for understanding user behaviors and automating processes. However, despite advancements in Vision-Language Models (VLMs) and their increasing use in video analysis, extracting user actions from desktop...
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 5. Although diffusion models can generate remarkably high-quality samples, they are intrinsically bottlenecked by their expensive iterative sampling procedure. Consistency models (CMs) have recently emerged as a promising diffusion model distillation method, reducing the cost of sampling by generating ...
[17.11.2024 18:28] ********************************************************************************
[17.11.2024 18:28] Abstract 6. The drive toward automating cellular network operations has grown with the increasing complexity of these systems. Despite advancements, full autonomy currently remains out of reach due to reliance on human intervention for modeling network behaviors and defining policies to meet target requirements...
[17.11.2024 18:28] Read previous papers.
[17.11.2024 18:28] Generating reviews via LLM API.
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#optimization", "#games", "#3d", "#multimodal", "#training"], "emoji": "üß†", "ru": {"title": "–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —É—á–∞—Ç—Å—è —Å–æ–∑–¥–∞–≤–∞—Ç—å 3D-–º–∏—Ä—ã", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç LLaMA-Mesh
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#cv"], "emoji": "üñåÔ∏è", "ru": {"title": "MagicQuill: –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "MagicQuill - —ç—Ç–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å (MLLM) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üß†", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–∞–º—è—Ç–∏: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Cut Cross-Entropy (CCE) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –≤ –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. CCE –∑–Ω
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#science", "#benchmark", "#healthcare", "#reasoning"], "emoji": "üè•", "ru": {"title": "LLM vs —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–µ ML: –∫—Ç–æ –ø–æ–±–µ–¥–∏—Ç –≤ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏?", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ ClinicalBench –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–æ–¥
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#agents", "#training", "#optimization", "#video", "#cv", "#benchmark", "#games"], "emoji": "üñ•Ô∏è", "ru": {"title": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–µ–π —Å –ø–æ–º–æ—â—å—é Vision-Language Models", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–∞ –Ω–æ–≤—ã—Ö –º–µ—Ç–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Vision-Language Models –¥–ª—è –∏–∑
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#diffusion", "#training", "#optimization", "#cv"], "emoji": "üî¨", "ru": {"title": "–ü–∞—Ä–∞–¥–æ–∫—Å —Ç–æ—á–Ω–æ—Å—Ç–∏: –∫–æ–≥–¥–∞ –º–µ–Ω—å—à–∞—è –æ—à–∏–±–∫–∞ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –º–µ—Ç–æ–¥—ã —É–ª—É—á—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–æ–≤—ã–π 
[17.11.2024 18:28] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#agi", "#multimodal"], "emoji": "üß†", "ru": {"title": "Hermes: –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π '–º–æ–∑–≥' –¥–ª—è —Å–µ—Ç–µ–π —Å–≤—è–∑–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Hermes - —Å–∏—Å—Ç–µ–º—É –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –¥–≤–æ–π–Ω–∏–∫–æ–≤ —Å–µ—Ç–µ–π —Å–≤—è–∑
[17.11.2024 18:28] Loading Chinese text from previous data.
[17.11.2024 18:28] Renaming data file.
[17.11.2024 18:28] Renaming previous data. hf_papers.json to ./d/2024-11-15.json
[17.11.2024 18:28] Saving new data file.
[17.11.2024 18:28] Generating page.
[17.11.2024 18:28] Renaming previous page.
[17.11.2024 18:28] Renaming previous data. index.html to ./d/2024-11-15.html
[17.11.2024 18:28] [Experimental] Generating Chinese page for reading.
[17.11.2024 18:28] Chinese vocab [{'word': 'Êé¢ËÆ®', 'pinyin': 't√†n t«éo', 'trans': 'discuss'}, {'word': 'Êâ©Â±ï', 'pinyin': 'ku√≤ zh«én', 'trans': 'expand'}, {'word': 'Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'd√† x√≠ng y«î y√°n m√≥ x√≠ng', 'trans': 'large language models'}, {'word': 'Áªü‰∏Ä', 'pinyin': 't«íng yƒ´', 'trans': 'unified'}, {'word': '3DÁΩëÊ†º', 'pinyin': '3D w«éng g√©', 'trans': '3D mesh'}, {'word': '‰∏ªË¶Å', 'pinyin': 'zh«î y√†o', 'trans': 'main'}, {'word': '‰ºòÂäø', 'pinyin': 'y≈çu sh√¨', 'trans': 'advantage'}, {'word': 'Âà©Áî®', 'pinyin': 'l√¨ y√≤ng', 'trans': 'utilize'}, {'word': 'Á©∫Èó¥', 'pinyin': 'k≈çng jiƒÅn', 'trans': 'spatial'}, {'word': 'Áü•ËØÜ', 'pinyin': 'zhƒ´ sh√¨', 'trans': 'knowledge'}, {'word': 'ÂØπËØùÂºè', 'pinyin': 'du√¨ hu√† sh√¨', 'trans': 'conversational'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìng ch√©ng', 'trans': 'generate'}, {'word': 'ÁêÜËß£', 'pinyin': 'l«ê jiƒõ', 'trans': 'understand'}, {'word': 'ÊåëÊàò', 'pinyin': 'ti«éo zh√†n', 'trans': 'challenge'}, {'word': 'ËΩ¨Âåñ', 'pinyin': 'zhu«én hu√†', 'trans': 'convert'}, {'word': 'Á¶ªÊï£', 'pinyin': 'l√≠ s√†n', 'trans': 'discrete'}, {'word': 'Á¨¶Âè∑', 'pinyin': 'f√∫ h√†o', 'trans': 'symbol'}, {'word': 'ÂºïÂÖ•', 'pinyin': 'y«ên r√π', 'trans': 'introduce'}, {'word': 'LLaMA-Mesh', 'pinyin': 'LLaMA-Mesh', 'trans': 'LLaMA-Mesh'}, {'word': 'È°∂ÁÇπ', 'pinyin': 'd«êng di«én', 'trans': 'vertex'}, {'word': 'ÂùêÊ†á', 'pinyin': 'zu√≤ bi«éo', 'trans': 'coordinate'}, {'word': 'Èù¢', 'pinyin': 'mi√†n', 'trans': 'face'}, {'word': 'ÂÆö‰πâ', 'pinyin': 'd√¨ng y√¨', 'trans': 'definition'}, {'word': 'Á∫ØÊñáÊú¨', 'pinyin': 'ch√∫n w√©n bƒõn', 'trans': 'pure text'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': '‰∫§Êõø', 'pinyin': 'jiƒÅo t√¨', 'trans': 'alternate'}, {'word': 'ËæìÂá∫', 'pinyin': 'sh≈´ ch≈´', 'trans': 'output'}, {'word': 'Ëß£Èáä', 'pinyin': 'jiƒõ sh√¨', 'trans': 'explain'}, {'word': 'ÂæÆË∞É', 'pinyin': 'wƒìi ti√°o', 'trans': 'fine-tune'}, {'word': 'Â§çÊùÇ', 'pinyin': 'f√π z√°', 'trans': 'complex'}, {'word': 'Ê®°ÊÄÅ', 'pinyin': 'm√≥ t√†i', 'trans': 'modality'}, {'word': 'Â™≤Áæé', 'pinyin': 'p√¨ mƒõi', 'trans': 'rival'}, {'word': '‰ªéÂ§¥', 'pinyin': 'c√≥ng t√≥u', 'trans': 'from scratch'}, {'word': 'ËÆ≠ÁªÉ', 'pinyin': 'x√πn li√†n', 'trans': 'train'}, {'word': 'Ê®°Âûã', 'pinyin': 'm√≥ x√≠ng', 'trans': 'model'}, {'word': 'ÂêåÊó∂', 'pinyin': 't√≥ng sh√≠', 'trans': 'simultaneously'}, {'word': '‰øùÊåÅ', 'pinyin': 'b«éo ch√≠', 'trans': 'maintain'}, {'word': 'Âº∫Â§ß', 'pinyin': 'qi√°ng d√†', 'trans': 'powerful'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}]
[17.11.2024 18:28] Renaming previous Chinese page.
[17.11.2024 18:28] Renaming previous data. zh.html to ./d/2024-11-16_zh_reading_task.html
[17.11.2024 18:28] Writing Chinese reading task.
[17.11.2024 18:28] Writing result.
[17.11.2024 18:28] Renaming log file.
[17.11.2024 18:28] Renaming previous data. log.txt to ./logs/2024-11-17_last_log.txt
