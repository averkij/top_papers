[16.11.2024 18:27] Read previous papers.
[16.11.2024 18:27] Generating top page (month).
[16.11.2024 18:27] Writing top page (month).
[17.11.2024 01:51] Read previous papers.
[17.11.2024 01:51] Get feed.
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09595
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09703
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09009
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06469
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.08768
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.08954
[17.11.2024 01:51] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06490
[17.11.2024 01:51] Downloading and parsing papers (pdf, html). Total: 7.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.09595.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.09595.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.09595.json), skip HTML parsing.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.09703.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.09703.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.09703.json), skip HTML parsing.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.09009.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.09009.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.09009.json), skip HTML parsing.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.06469.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.06469.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.06469.json), skip HTML parsing.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.08768.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.08768.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.08768.json), skip HTML parsing.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.08954.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.08954.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.08954.json), skip HTML parsing.
[17.11.2024 01:51] Downloading and parsing paper https://huggingface.co/papers/2411.06490.
[17.11.2024 01:51] Extra JSON file exists (./assets/json/2411.06490.json), skip PDF parsing.
[17.11.2024 01:51] Paper image links file exists (./assets/img_data/2411.06490.json), skip HTML parsing.
[17.11.2024 01:51] Enriching papers with extra data.
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 0. This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling con...
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 1. Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques. In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas. Our system features a streamlined yet functionally robust interfa...
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 2. As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabu...
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 3. Large Language Models (LLMs) hold great promise to revolutionize current clinical systems for their superior capacities on medical text processing tasks and medical licensing exams. Meanwhile, traditional ML models such as SVM and XGBoost have still been mainly adopted in clinical prediction tasks. ...
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 4. ...
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 5. ...
[17.11.2024 01:51] ********************************************************************************
[17.11.2024 01:51] Abstract 6. ...
[17.11.2024 01:51] Read previous papers.
[17.11.2024 01:51] Generating reviews via LLM API.
[17.11.2024 01:51] Using data from previous issue: {"categories": ["#optimization", "#games", "#3d", "#multimodal", "#training"], "emoji": "üß†", "ru": {"title": "–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —É—á–∞—Ç—Å—è —Å–æ–∑–¥–∞–≤–∞—Ç—å 3D-–º–∏—Ä—ã", "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç LLaMA-Mesh
[17.11.2024 01:51] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#cv"], "emoji": "üñåÔ∏è", "ru": {"title": "MagicQuill: –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "MagicQuill - —ç—Ç–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å (MLLM) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞
[17.11.2024 01:51] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "üß†", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–∞–º—è—Ç–∏: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Cut Cross-Entropy (CCE) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –≤ –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. CCE –∑–Ω
[17.11.2024 01:51] Using data from previous issue: {"categories": ["#science", "#benchmark", "#healthcare", "#reasoning"], "emoji": "üè•", "ru": {"title": "LLM vs —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–µ ML: –∫—Ç–æ –ø–æ–±–µ–¥–∏—Ç –≤ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏?", "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ ClinicalBench –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–æ–¥
[17.11.2024 01:51] Using data from previous issue: {"categories": [], "emoji": "üöÄ", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è LLM –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é LLM, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–∏–±—Ä–∏–¥–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, —Å–æ—á–µ—Ç–∞—é—â—É
[17.11.2024 01:51] Using data from previous issue: {"categories": [], "emoji": "üöÄ", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è LLM —Å –ø–æ–º–æ—â—å—é AI", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é LLM, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ
[17.11.2024 01:51] Using data from previous issue: {"categories": [], "emoji": "üöÄ", "ru": {"title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è LLM –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é LLM, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–∏–±—Ä–∏–¥–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, —Å–æ—á–µ—Ç–∞—é—â—É
[17.11.2024 01:51] Loading Chinese text from previous data.
[17.11.2024 01:51] Renaming data file.
[17.11.2024 01:51] Renaming previous data. hf_papers.json to ./d/2024-11-15.json
[17.11.2024 01:51] Saving new data file.
[17.11.2024 01:51] Generating page.
[17.11.2024 01:51] Renaming previous page.
[17.11.2024 01:51] Renaming previous data. index.html to ./d/2024-11-15.html
[17.11.2024 01:51] [Experimental] Generating Chinese page for reading.
[17.11.2024 01:51] Chinese vocab [{'word': 'Êâ©Â±ï', 'pinyin': 'ku√≤zh«én', 'trans': 'extend'}, {'word': 'Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'd√†x√≠ng y«îy√°n m√≥x√≠ng', 'trans': 'large language models'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìngch√©ng', 'trans': 'generate'}, {'word': '3DÁΩëÊ†º', 'pinyin': '3D w«éngg√©', 'trans': '3D mesh'}, {'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ngl√¨', 'trans': 'ability'}, {'word': 'Âà©Áî®', 'pinyin': 'l√¨y√≤ng', 'trans': 'utilize'}, {'word': 'Á©∫Èó¥Áü•ËØÜ', 'pinyin': 'k≈çngjiƒÅn zhƒ´shi', 'trans': 'spatial knowledge'}, {'word': 'ÊñáÊú¨Êù•Ê∫ê', 'pinyin': 'w√©nbƒõn l√°iyu√°n', 'trans': 'textual sources'}, {'word': 'ÂÆûÁé∞', 'pinyin': 'sh√≠xi√†n', 'trans': 'achieve'}, {'word': 'ÂØπËØùÂºè', 'pinyin': 'du√¨hu√†sh√¨', 'trans': 'conversational'}, {'word': 'ÁêÜËß£', 'pinyin': 'l«êjiƒõ', 'trans': 'understand'}, {'word': '‰ªãÁªç', 'pinyin': 'ji√®sh√†o', 'trans': 'introduce'}, {'word': 'LLaMA-Mesh', 'pinyin': 'LLaMA-Mesh', 'trans': 'LLaMA-Mesh'}, {'word': 'Ë°®Á§∫', 'pinyin': 'bi«éosh√¨', 'trans': 'represent'}, {'word': 'Á∫ØÊñáÊú¨', 'pinyin': 'ch√∫n w√©nbƒõn', 'trans': 'pure text'}, {'word': 'Áõ¥Êé•Â§ÑÁêÜ', 'pinyin': 'zh√≠jiƒì ch«îl«ê', 'trans': 'directly process'}, {'word': 'ÁõëÁù£ÂæÆË∞É', 'pinyin': 'jiƒÅnd≈´ wƒìiti√°o', 'trans': 'supervised fine-tuning'}, {'word': 'Êï∞ÊçÆÈõÜ', 'pinyin': 'sh√πj√πj√≠', 'trans': 'dataset'}, {'word': '‰∫ßÁîü', 'pinyin': 'ch«énshƒìng', 'trans': 'produce'}, {'word': '‰∫§Êõø', 'pinyin': 'jiƒÅot√¨', 'trans': 'alternate'}, {'word': 'ËæìÂá∫', 'pinyin': 'sh≈´ch≈´', 'trans': 'output'}, {'word': 'Ëß£Èáä', 'pinyin': 'jiƒõsh√¨', 'trans': 'explain'}, {'word': 'È¶ñÊ¨°', 'pinyin': 'sh«íuc√¨', 'trans': 'for the first time'}, {'word': 'Â±ïÁ§∫', 'pinyin': 'zh«énsh√¨', 'trans': 'demonstrate'}, {'word': 'ÂæÆË∞É', 'pinyin': 'wƒìiti√°o', 'trans': 'fine-tuning'}, {'word': 'Â§çÊùÇ', 'pinyin': 'f√πz√°', 'trans': 'complex'}, {'word': 'È´òË¥®Èáè', 'pinyin': 'gƒÅo zh√¨li√†ng', 'trans': 'high quality'}]
[17.11.2024 01:51] Renaming previous Chinese page.
[17.11.2024 01:51] Renaming previous data. zh.html to ./d/2024-11-16_zh_reading_task.html
[17.11.2024 01:51] Writing Chinese reading task.
[17.11.2024 01:51] Writing result.
[17.11.2024 01:51] Renaming log file.
[17.11.2024 01:51] Renaming previous data. log.txt to ./logs/2024-11-17_last_log.txt
