[18.07.2025 06:19] Read previous papers.
[18.07.2025 06:19] Generating top page (month).
[18.07.2025 06:19] Writing top page (month).
[18.07.2025 07:16] Read previous papers.
[18.07.2025 07:16] Get feed.
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13334
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13332
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13347
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12841
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13348
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12508
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.13300
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12720
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.12956
[18.07.2025 07:16] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04984
[18.07.2025 07:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[18.07.2025 07:16] No deleted papers detected.
[18.07.2025 07:16] Downloading and parsing papers (pdf, html). Total: 10.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.13334.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.13334.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.13334.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.13332.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.13332.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.13332.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.13347.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.13347.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.13347.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.12841.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.12841.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.12841.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.13348.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.13348.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.13348.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.12508.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.12508.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.12508.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.13300.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.13300.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.13300.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.12720.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.12720.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.12720.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.12956.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.12956.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.12956.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Downloading and parsing paper https://huggingface.co/papers/2507.04984.
[18.07.2025 07:16] Extra JSON file exists (./assets/json/2507.04984.json), skip PDF parsing.
[18.07.2025 07:16] Paper image links file exists (./assets/img_data/2507.04984.json), skip HTML parsing.
[18.07.2025 07:16] Success.
[18.07.2025 07:16] Enriching papers with extra data.
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 0. Context Engineering systematically optimizes information payloads for Large Language Models, addressing gaps in generating sophisticated, long-form outputs.  					AI-generated summary 				 The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provi...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 1. TAIL, a method that imitates Turing Machine execution processes, enhances the length generalization and performance of LLMs by synthesizing chain-of-thought data and reducing shortcut learning.  					AI-generated summary 				 Length generalization, the ability to solve problems of longer sequences t...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 2. A permutation-equivariant neural network, $\pi^3$, reconstructs visual geometry without a fixed reference view, achieving state-of-the-art performance in camera pose estimation, depth estimation, and point map reconstruction.  					AI-generated summary 				 We introduce pi^3, a feed-forward neural n...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 3. The AnyCap Project introduces a framework, dataset, and evaluation protocol to enhance controllability and reliability in multimodal captioning.  					AI-generated summary 				 Controllable captioning is essential for precise multimodal alignment and instruction following, yet existing models often ...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 4. VisionThink dynamically adjusts image resolution and visual token processing for efficient and effective vision-language tasks, improving performance on OCR tasks while reducing token usage in simpler tasks.  					AI-generated summary 				 Recent advancements in vision-language models (VLMs) have im...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 5. MindJourney enhances vision-language models with 3D reasoning by coupling them with a video diffusion-based world model, achieving improved performance on spatial reasoning tasks without fine-tuning.  					AI-generated summary 				 Spatial reasoning in 3D space is central to human cognition and indi...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 6. AbGen evaluates LLMs in designing ablation studies for scientific research, revealing performance gaps compared to human experts and highlighting the unreliability of current automated evaluation methods.  					AI-generated summary 				 We introduce AbGen, the first benchmark designed to evaluate th...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 7. FLEXITOKENS, a byte-level language model with a learnable tokenizer, reduces token over-fragmentation and improves performance across multilingual and morphologically diverse tasks.  					AI-generated summary 				 Language models (LMs) are challenging to adapt to new data distributions by simple fin...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 8. FantasyPortrait, a diffusion transformer framework, generates high-fidelity and emotion-rich facial animations for single and multi-character scenarios using implicit representations and a masked cross-attention mechanism.  					AI-generated summary 				 Producing expressive facial animations from s...
[18.07.2025 07:16] ********************************************************************************
[18.07.2025 07:16] Abstract 9. Temporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation (TLB-VFI) improves video frame interpolation by efficiently extracting temporal information, reducing parameters, and requiring less training data compared to existing methods.  					AI-generated summary 				 Video Frame I...
[18.07.2025 07:16] Read previous papers.
[18.07.2025 07:16] Generating reviews via LLM API.
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#data", "#survey", "#multimodal", "#long_context", "#architecture", "#rag"], "emoji": "üß†", "ru": {"title": "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∏–Ω–∂–µ–Ω–µ—Ä–∏—è: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ LLM", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±–∑–æ—Ä –æ–±–ª–∞—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#data", "#synthetic", "#training", "#architecture", "#dataset", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ò–º–∏—Ç–∞—Ü–∏—è –º–∞—à–∏–Ω—ã –¢—å—é—Ä–∏–Ω–≥–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ú–µ—Ç–æ–¥ TAIL –∏–º–∏—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–∞—à–∏–Ω—ã –¢—å—é—Ä–∏–Ω–≥–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ 
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#open_source", "#cv", "#optimization", "#architecture"], "emoji": "üî¨", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ 3D —Å—Ü–µ–Ω –±–µ–∑ –æ–ø–æ—Ä–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å œÄ^3 –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –±–µ–∑ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–ø–æ—Ä–Ω–æ–≥–æ –≤–∏–¥–∞. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç 
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#benchmark", "#games", "#dataset"], "emoji": "üéõÔ∏è", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏", "desc": "–ü—Ä–æ–µ–∫—Ç AnyCap –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ—Å—Ç–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –ø
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#cv", "#optimization", "#training", "#rl", "#games"], "emoji": "üîç", "ru": {"title": "–£–º–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ", "desc": "VisionThink - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–¥–∞—á–∞—Ö –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞. –û–Ω –¥–∏
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#cv", "#3d", "#benchmark", "#diffusion", "#rl", "#reasoning", "#video"], "emoji": "üß†", "ru": {"title": "MindJourney: 3D-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è", "desc": "MindJourney - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#science", "#interpretability"], "emoji": "üß™", "ru": {"title": "AbGen: –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è—Ö –ò–ò –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—É—á–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã", "desc": "AbGen - —ç—Ç–æ –ø–µ—Ä–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞–±–ª–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#low_resource", "#training", "#architecture", "#dataset", "#optimization", "#multilingual"], "emoji": "üß©", "ru": {"title": "–ì–∏–±–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "FLEXITOKENS - —ç—Ç–æ –±–∞–π—Ç–æ–≤–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –æ–±—É—á–∞–µ–º—ã–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º, –∫–æ—Ç–æ—Ä–∞—è —Å–Ω–∏–∂–∞–µ—Ç —á—Ä–µ–∑–º–µ—Ä–Ω—É—é —Ñ
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#dataset", "#games", "#diffusion", "#benchmark", "#cv"], "emoji": "üé≠", "ru": {"title": "–û–∂–∏–≤–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: –æ—Ç —Å—Ç–∞—Ç–∏–∫–∏ –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–µ", "desc": "FantasyPortrait - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –±–æ–≥–∞—Ç—ã—Ö –∞–Ω
[18.07.2025 07:16] Using data from previous issue: {"categories": ["#video", "#training", "#data", "#diffusion"], "emoji": "üéûÔ∏è", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –≤–∏–¥–µ–æ–∫–∞–¥—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –≤—Ä–µ–º–µ–Ω–Ω–æ-–æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –≤–∏–¥–µ–æ–∫–∞–¥—Ä–æ–≤ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º TLB-VFI, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω
[18.07.2025 07:16] Renaming data file.
[18.07.2025 07:16] Renaming previous data. hf_papers.json to ./d/2025-07-18.json
[18.07.2025 07:16] Saving new data file.
[18.07.2025 07:16] Generating page.
[18.07.2025 07:16] Renaming previous page.
[18.07.2025 07:16] Renaming previous data. index.html to ./d/2025-07-18.html
[18.07.2025 07:16] Writing result.
[18.07.2025 07:16] Renaming log file.
[18.07.2025 07:16] Renaming previous data. log.txt to ./logs/2025-07-18_last_log.txt
