[30.10.2024 12:23] [Experimental] Generating an image for paper CLEAR: Character Unlearning in Textual and Visual Modalities.
[30.10.2024 12:23] [Experimental] Image for paper CLEAR: Character Unlearning in Textual and Visual Modalities already exists.
[30.10.2024 12:23] [Experimental] Generating an image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions.
[30.10.2024 12:23] [Experimental] Image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions already exists.
[30.10.2024 12:23] [Experimental] Generating an image for paper SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.
[30.10.2024 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization' Text: 'Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To address these issues, we first present a simple yet well-crafted framework named {\name}, which combines the perception capability of Vision Foundation Models (VFMs) and the reasoning capability of Large Language Models (LLMs) within a modular framework, providing a strong baseline for social relation recognition. Specifically, we instruct VFMs to translate image content into a textual social story, and then utilize LLMs for text-based reasoning. {\name} introduces systematic design principles to adapt VFMs and LLMs separately and bridge their gaps. Without additional model training, it achieves competitive zero-shot results on two databases while offering interpretable answers, as LLMs can generate language-based explanations for the decisions. The manual prompt design process for LLMs at the reasoning phase is tedious and an automated prompt optimization method is desired. As we essentially convert a visual classification task into a generative task of LLMs, automatic prompt optimization encounters a unique long prompt optimization issue. To address this issue, we further propose the Greedy Segment Prompt Optimization (GSPO), which performs a greedy search by utilizing gradient information at the segment level. Experimental results show that GSPO significantly improves performance, and our method also generalizes to different image styles. The code is available at https://github.com/Mengzibin/SocialGPT.'
[30.10.2024 12:23] Response: **Prompt:** Create a linear art piece on a white background that depicts a surreal scene blending the worlds of visual perception and textual reasoning. Visualize a giant eye made of interwoven threads representing Vision Foundation Models, looking at a cluster of abstract human figures symbolizing social relations (friends, spouses, colleagues). Each figure is connected by colorful, flowing lines to a central book that represents Large Language Models, from which whimsical text bubbles emanate, giving language-based explanations. Place a label beneath the central book that reads: "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization."
[30.10.2024 12:23] Generating image by prompt: **Prompt:** Create a linear art piece on a white background that depicts a surreal scene blending the worlds of visual perception and textual reasoning. Visualize a giant eye made of interwoven threads representing Vision Foundation Models, looking at a cluster of abstract human figures symbolizing social relations (friends, spouses, colleagues). Each figure is connected by colorful, flowing lines to a central book that represents Large Language Models, from which whimsical text bubbles emanate, giving language-based explanations. Place a label beneath the central book that reads: "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.".
[30.10.2024 12:23] Saving generated image from https://fal.media/files/elephant/GbnJ5wEUskVTzo_yYIOLi.png to ad99b3e3b4ef165c.jpg.
[30.10.2024 12:23] [Experimental] Generating an image for paper OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization.
[30.10.2024 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization' Text: 'The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with the ability to explore environments and continuously improve over time, they are building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents struggle to generalize to realistic settings that require multimodal perception abilities and lack ground-truth signals. In this paper, we introduce an open-source framework designed to facilitate the development of multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets.'
[30.10.2024 12:23] Response: **Prompt:** Create a piece of linear art on a white background depicting a surreal landscape where a large, abstract figure represents a web agent. This figure is intertwined with various digital elements symbolizing multimodal perceptionâ€”like distorted screens displaying text, images, and audio waves. In the background, a labyrinth of pathways represents the open web, with feedback loops illustrated as swirling arrows guiding the agent's exploration. Above the figure, inscribe the title: "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization" in a modern, minimalist font, as if it were a label on an art piece.
[30.10.2024 12:23] Generating image by prompt: **Prompt:** Create a piece of linear art on a white background depicting a surreal landscape where a large, abstract figure represents a web agent. This figure is intertwined with various digital elements symbolizing multimodal perceptionâ€”like distorted screens displaying text, images, and audio waves. In the background, a labyrinth of pathways represents the open web, with feedback loops illustrated as swirling arrows guiding the agent's exploration. Above the figure, inscribe the title: "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization" in a modern, minimalist font, as if it were a label on an art piece..
[30.10.2024 12:23] Saving generated image from https://fal.media/files/elephant/x1htojugc1YaDe9myJ7Jr.png to c9775abc4b4ddd0d.jpg.
[30.10.2024 14:11] Read previous papers.
[30.10.2024 14:11] Get feed.
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18057
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.20424
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21411
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.19609
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22304
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22325
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21465
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21845
[30.10.2024 14:11] Extract page data from URL. URL: https://huggingface.co/papers/2410.21333
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 0. Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearn...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 1. Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKag...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 2. Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To ad...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 3. The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with t...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 4. Mathematical reasoning is a crucial capability for Large Language Models (LLMs), yet generating detailed and accurate reasoning traces remains a significant challenge. This paper introduces a novel approach to produce high-quality reasoning traces for LLM fine-tuning using online learning Flows. Our...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 5. The pre-training of visual representations has enhanced the efficiency of robot learning. Due to the lack of large-scale in-domain robotic datasets, prior works utilize in-the-wild human videos to pre-train robotic visual representation. Despite their promising results, representations from human vi...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 6. With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each t...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 7. Reinforcement learning (RL) holds great promise for enabling autonomous acquisition of complex robotic manipulation skills, but realizing this potential in real-world settings has been challenging. We present a human-in-the-loop vision-based RL system that demonstrates impressive performance on a di...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 8. Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open...
[30.10.2024 14:11] Read previous papers.
[30.10.2024 14:11] Generating reviews via LLM API.
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#multimodal"], "emoji": "ğŸ§ ", "ru": {"title": "CLEAR: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² Ğ˜Ğ˜", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº CLEAR Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (MMU) Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (M
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#dataset", "#data", "#agents"], "emoji": "ğŸ¤–", "ru": {"title": "AutoKaggle: Ğ˜Ğ˜-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸", "desc": "AutoKaggle - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸, Ğ²
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#interpretability", "#long_context"], "emoji": "ğŸ‘¥", "ru": {"title": "SocialGPT: Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ·Ñ‹ĞºĞ° Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#rl"], "emoji": "ğŸ•¸ï¸", "ru": {"title": "Ğ¡Ğ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸ĞµÑÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµĞ±-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ°", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ÑƒÑ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñƒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ²ĞµĞ±-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… Ğº Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¼Ñƒ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ° Ğ¸ ÑĞ°Ğ¼Ğ¾
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#math", "#rlhf", "#reasoning"], "emoji": "ğŸ§®", "ru": {"title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ LLM Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#agents", "#robotics", "#dataset"], "emoji": "ğŸ¦¾", "ru": {"title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Manipulation Centric
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#inference", "#long_context", "#benchmark"], "emoji": "ğŸš€", "ru": {"title": "ShadowKV: Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… LLM Ğ±ĞµĞ· ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑĞ¾Ğ²", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ShadowKV - ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Shadow
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#robotics"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸ Ğ˜Ğ˜: ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğ¼ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸ÑĞ¼", "desc": "Ğ’ ÑÑ‚Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸ĞµĞ¼ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ»Ñ
[30.10.2024 14:11] Querying the API.
[30.10.2024 14:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning.
[30.10.2024 14:12] Response: {
  "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¸Ğ½Ğ³Ğ° Ñ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¾Ğ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (CoT) Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ»ÑÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ³Ğ´Ğµ CoT ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ¾Ğ¿Ğ¸Ñ€Ğ°ÑÑÑŒ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ· ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿ÑĞ¸Ñ…Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ CoT Ğ² Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ¾Ğ¹ Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ… Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹ CoT Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.",
  "emoji": "ğŸ§ ",
  "title": "ĞšĞ¾Ğ³Ğ´Ğ° Ñ€Ğ°Ğ·Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ´ÑÑ‚: Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ CoT Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…"
}
[30.10.2024 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: You are an expert classifier of machine learning research papers. Analyze the following research paper text and classify it into one or more relevant categories from the list below. Consider the paper's main contributions, methodologies, and applications.

Categories:
1. DATASET: Papers that introduce new datasets or make significant modifications to existing ones
2. DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
3. BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
4. AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
5. CV: Papers developing computer vision methods or visual processing systems
6. RL: Papers investigating reinforcement learning theory or applications
7. RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
8. RAG: Papers advancing retrieval-augmented generation techniques
9. PLP: Papers about Programming Language Processing models or programming benchmarks
10. INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
11. 3D: Papers on 3D content generation, processing, or understanding
12. AUDIO: Papers advancing speech/audio processing or generation
13. VIDEO: Papers on video analysis, generation, or understanding
14. MULTIMODAL: Papers combining multiple input/output modalities
15. MATH: Papers focused on mathematical theory and algorithms
16. MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities
17. ARCHITECTURE: Papers proposing novel neural architectures or components
18. MEDICINE: Papers applying ML to medical/healthcare domains
19. TRAINING: Papers improving model training or fine-tuning methods
20. ROBOTICS: Papers on robotic systems and embodied AI
21. AGI: Papers discussing artificial general intelligence concepts
22. GAMES: Papers applying ML to games or game development
23. INTERPRETABILITY: Papers analyzing model behavior and explanations
24. REASONING: Papers enhancing logical reasoning capabilities
25. TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
26. GRAPHS: Papers advancing graph neural networks and applications
27. ETHICS: Papers addressing AI ethics, fairness, and bias
28. SECURITY: Papers on model security and adversarial robustness
29. EDGE_COMPUTING: Papers on ML deployment for resource-constrained devices
30. OPTIMIZATION: Papers advancing training optimization methods
31. SURVEY: Papers comprehensively reviewing research areas
32. DIFFUSION: Papers on diffusion-based generative models
33. ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
34. STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
35. HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
36. LONG_CONTEXT: Papers about long context handling, including techniques to extend context length and process long sequences.

Return only JSON with flat array of categories that match the given text.

Paper text to classify:

"Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning."

[30.10.2024 14:12] Response: ```json
["INTERPRETABILITY", "REASONING", "MULTIMODAL"]
```
[30.10.2024 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the effectiveness of Chain-of-Thought (CoT) prompting in large language and multimodal models, particularly focusing on when it may hinder performance. By drawing parallels from cognitive psychology, the authors explore scenarios where verbal reasoning negatively impacts human performance and whether these scenarios apply to language models. Through extensive experiments, they demonstrate that certain tasks, such as implicit statistical learning and visual recognition, can lead to significant performance drops in models when using CoT prompting. The findings suggest that understanding human cognitive limitations can provide insights into optimizing model performance and prompt design.","title":"Understanding When Chain-of-Thought Prompting Fails in AI Models"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper investigates the effectiveness of Chain-of-Thought (CoT) prompting in large language and multimodal models, particularly focusing on when it may hinder performance. By drawing parallels from cognitive psychology, the authors explore scenarios where verbal reasoning negatively impacts human performance and whether these scenarios apply to language models. Through extensive experiments, they demonstrate that certain tasks, such as implicit statistical learning and visual recognition, can lead to significant performance drops in models when using CoT prompting. The findings suggest that understanding human cognitive limitations can provide insights into optimizing model performance and prompt design.', title='Understanding When Chain-of-Thought Prompting Fails in AI Models'))
[30.10.2024 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºæ˜¯ä¸€ç§åœ¨å¤§å‹è¯­è¨€å’Œå¤šæ¨¡æ€æ¨¡å‹ä¸­å¹¿æ³›ä½¿ç”¨çš„ç­–ç•¥ã€‚æœ¬æ–‡æ¢è®¨äº†åœ¨ä½•ç§æƒ…å†µä¸‹é“¾å¼æ€ç»´ä¼šé™ä½æ¨¡å‹æ€§èƒ½ï¼Œå€Ÿé‰´äº†è®¤çŸ¥å¿ƒç†å­¦çš„ç ”ç©¶ã€‚é€šè¿‡å¯¹éšæ€§ç»Ÿè®¡å­¦ä¹ ã€è§†è§‰è¯†åˆ«å’ŒåŒ…å«ä¾‹å¤–çš„æ¨¡å¼åˆ†ç±»ç­‰ä»»åŠ¡çš„å®éªŒï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨æ¨ç†æ—¶çš„é“¾å¼æ€ç»´ä¼šå¯¼è‡´æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œç†è§£äººç±»æ€ç»´å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°é€‰æ‹©æç¤ºå’Œæ¨ç†ç­–ç•¥ã€‚","title":"é“¾å¼æ€ç»´çš„å½±å“ï¼šä½•æ—¶æœ‰ç›Šï¼Œä½•æ—¶æœ‰å®³"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºæ˜¯ä¸€ç§åœ¨å¤§å‹è¯­è¨€å’Œå¤šæ¨¡æ€æ¨¡å‹ä¸­å¹¿æ³›ä½¿ç”¨çš„ç­–ç•¥ã€‚æœ¬æ–‡æ¢è®¨äº†åœ¨ä½•ç§æƒ…å†µä¸‹é“¾å¼æ€ç»´ä¼šé™ä½æ¨¡å‹æ€§èƒ½ï¼Œå€Ÿé‰´äº†è®¤çŸ¥å¿ƒç†å­¦çš„ç ”ç©¶ã€‚é€šè¿‡å¯¹éšæ€§ç»Ÿè®¡å­¦ä¹ ã€è§†è§‰è¯†åˆ«å’ŒåŒ…å«ä¾‹å¤–çš„æ¨¡å¼åˆ†ç±»ç­‰ä»»åŠ¡çš„å®éªŒï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨æ¨ç†æ—¶çš„é“¾å¼æ€ç»´ä¼šå¯¼è‡´æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œç†è§£äººç±»æ€ç»´å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°é€‰æ‹©æç¤ºå’Œæ¨ç†ç­–ç•¥ã€‚', title='é“¾å¼æ€ç»´çš„å½±å“ï¼šä½•æ—¶æœ‰ç›Šï¼Œä½•æ—¶æœ‰å®³'))
[30.10.2024 14:12] Loading Chinese text from previous data.
[30.10.2024 14:12] Renaming data file.
[30.10.2024 14:12] Renaming previous data. hf_papers.json to ./d/2024-10-30.json
[30.10.2024 14:12] Saving new data file.
[30.10.2024 14:12] Generating page.
[30.10.2024 14:12] Renaming previous page.
[30.10.2024 14:12] Renaming previous data. index.html to ./d/2024-10-30.html
[30.10.2024 14:12] [Experimental] Generating Chinese page for reading.
[30.10.2024 14:12] Chinese vocab [{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'}, {'word': 'æœºå™¨å–æ¶ˆå­¦ä¹ ', 'pinyin': 'jÄ« qÃ¬ qÇ” xiÄo xuÃ© xÃ­', 'trans': 'machine unlearning'}, {'word': 'å¢å¼º', 'pinyin': 'zÄ“ng qiÃ¡ng', 'trans': 'enhance'}, {'word': 'éšç§', 'pinyin': 'yÇn sÄ«', 'trans': 'privacy'}, {'word': 'å®‰å…¨', 'pinyin': 'Än quÃ¡n', 'trans': 'security'}, {'word': 'æ·±åº¦å­¦ä¹ æ¨¡å‹', 'pinyin': 'shÄ“n dÃ¹ xuÃ© xÃ­ mÃ³ xÃ­ng', 'trans': 'deep learning model'}, {'word': 'å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹', 'pinyin': 'duÅ mÃ³ shuÃ i yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'multimodal language model'}, {'word': 'æ˜¾è‘—', 'pinyin': 'xiÇn zhÃ¹', 'trans': 'significant'}, {'word': 'è¿›å±•', 'pinyin': 'jÃ¬n zhÇn', 'trans': 'progress'}, {'word': 'å¤šæ¨¡æ€å–æ¶ˆå­¦ä¹ ', 'pinyin': 'duÅ mÃ³ shuÃ i qÇ” xiÄo xuÃ© xÃ­', 'trans': 'multimodal unlearning'}, {'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡n jiÅ«', 'trans': 'research'}, {'word': 'åˆé€‚', 'pinyin': 'hÃ© shÃ¬', 'trans': 'suitable'}, {'word': 'å¼€æº', 'pinyin': 'kÄi yuÃ¡n', 'trans': 'open-source'}, {'word': 'åŸºå‡†', 'pinyin': 'jÄ« zhÇ”n', 'trans': 'benchmark'}, {'word': 'å¼•å…¥', 'pinyin': 'yÇn rÃ¹', 'trans': 'introduce'}, {'word': 'è¯„ä¼°', 'pinyin': 'pÃ­ng gÅ«', 'trans': 'evaluate'}, {'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'}, {'word': 'è™šæ„', 'pinyin': 'xÅ« gÃ²u', 'trans': 'fictional'}, {'word': 'ä¸ªä½“', 'pinyin': 'gÃ¨ tÇ', 'trans': 'individual'}, {'word': 'å›¾ç‰‡', 'pinyin': 'tÃº piÃ n', 'trans': 'image'}, {'word': 'é—®ç­”å¯¹', 'pinyin': 'wÃ¨n dÃ¡ duÃ¬', 'trans': 'question-answer pair'}, {'word': 'è·¨æ¨¡æ€', 'pinyin': 'kuÃ  mÃ³ shuÃ i', 'trans': 'cross-modal'}, {'word': 'å…¨é¢', 'pinyin': 'quÃ¡n miÃ n', 'trans': 'comprehensive'}, {'word': 'é—å¿˜', 'pinyin': 'yÃ­ wÃ ng', 'trans': 'forgetting'}, {'word': 'æŒ‘æˆ˜', 'pinyin': 'tiÇo zhÃ n', 'trans': 'challenge'}, {'word': 'æ­£åˆ™åŒ–', 'pinyin': 'zhÃ¨ng zÃ© huÃ ', 'trans': 'regularization'}, {'word': 'å‡è½»', 'pinyin': 'jiÇn qÄ«ng', 'trans': 'alleviate'}, {'word': 'ç¾éš¾æ€§', 'pinyin': 'zÄi nÃ n xÃ¬ng', 'trans': 'catastrophic'}, {'word': 'ä¿æŒ', 'pinyin': 'bÇo chÃ­', 'trans': 'maintain'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'æ•°æ®é›†', 'pinyin': 'shÃ¹ jÃ¹ jÃ­', 'trans': 'dataset'}]
[30.10.2024 14:12] Renaming previous Chinese page.
[30.10.2024 14:12] Renaming previous data. zh.html to ./d/2024-10-29_zh_reading_task.html
[30.10.2024 14:12] Writing result.
[30.10.2024 14:12] Writing Chinese reading task.
[30.10.2024 14:12] Renaming log file.
[30.10.2024 14:12] Renaming previous data. log.txt to ./logs/2024-10-30_last_log.txt
