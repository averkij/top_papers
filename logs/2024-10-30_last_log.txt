[30.10.2024 10:15] [Experimental] Generating an image for paper CLEAR: Character Unlearning in Textual and Visual Modalities.
[30.10.2024 10:15] [Experimental] Image for paper CLEAR: Character Unlearning in Textual and Visual Modalities already exists.
[30.10.2024 10:15] [Experimental] Generating an image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions.
[30.10.2024 10:15] [Experimental] Image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions already exists.
[30.10.2024 12:23] Read previous papers.
[30.10.2024 12:23] Get feed.
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18057
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.20424
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21411
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.19609
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22304
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21465
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22325
[30.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21845
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 0. Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearn...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 1. Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKag...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 2. Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To ad...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 3. The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with t...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 4. Mathematical reasoning is a crucial capability for Large Language Models (LLMs), yet generating detailed and accurate reasoning traces remains a significant challenge. This paper introduces a novel approach to produce high-quality reasoning traces for LLM fine-tuning using online learning Flows. Our...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 5. With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each t...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 6. The pre-training of visual representations has enhanced the efficiency of robot learning. Due to the lack of large-scale in-domain robotic datasets, prior works utilize in-the-wild human videos to pre-train robotic visual representation. Despite their promising results, representations from human vi...
[30.10.2024 12:23] ********************************************************************************
[30.10.2024 12:23] Abstract 7. Reinforcement learning (RL) holds great promise for enabling autonomous acquisition of complex robotic manipulation skills, but realizing this potential in real-world settings has been challenging. We present a human-in-the-loop vision-based RL system that demonstrates impressive performance on a di...
[30.10.2024 12:23] Read previous papers.
[30.10.2024 12:23] Generating reviews via LLM API.
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#multimodal"], "emoji": "üß†", "ru": {"title": "CLEAR: –ù–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏—è –≤ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ CLEAR –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏—è (MMU) –≤ –±–æ–ª—å—à–∏—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (M
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#dataset", "#data", "#agents"], "emoji": "ü§ñ", "ru": {"title": "AutoKaggle: –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏", "desc": "AutoKaggle - —ç—Ç–æ –º–æ—â–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á —Å —Ç–∞–±–ª–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, –≤
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#interpretability", "#long_context"], "emoji": "üë•", "ru": {"title": "SocialGPT: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑—Ä–µ–Ω–∏—è –∏ —è–∑—ã–∫–∞ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#rl"], "emoji": "üï∏Ô∏è", "ru": {"title": "–°–∞–º–æ–æ–±—É—á–∞—é—â–∏–µ—Å—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –≤–µ–±-–∞–≥–µ–Ω—Ç—ã –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –º–∏—Ä–∞", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç–∫—Ä—ã—Ç—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é —Ä–µ–∞–ª—å–Ω–æ–≥–æ –º–∏—Ä–∞ –∏ —Å–∞–º–æ
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#math", "#rlhf", "#reasoning"], "emoji": "üßÆ", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π LLM —á–µ—Ä–µ–∑ –æ–Ω–ª–∞–π–Ω-–æ–±—É—á–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∑–∞–¥–∞—á–∞—Ö –º
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#inference", "#long_context", "#benchmark"], "emoji": "üöÄ", "ru": {"title": "ShadowKV: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –≤—ã–≤–æ–¥–∞ –¥–ª–∏–Ω–Ω–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö LLM –±–µ–∑ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç ShadowKV - —Å–∏—Å—Ç–µ–º—É –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –¥–ª–∏–Ω–Ω–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). Shadow
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#agents", "#robotics", "#dataset"], "emoji": "ü¶æ", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π —á–µ—Ä–µ–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏–∫–∏", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—é –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–ª—è —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Manipulation Centric
[30.10.2024 12:23] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–ß–µ–ª–æ–≤–µ–∫ –∏ –ò–ò: —Å–æ–≤–º–µ—Å—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–æ–≤ —Å–ª–æ–∂–Ω—ã–º –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è–º", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –¥–ª—è —Ä–æ–±–æ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ —Å —É—á–∞—Å—Ç–∏–µ–º —á–µ–ª–æ–≤–µ–∫–∞. –°–∏—Å—Ç–µ–º–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–ø–µ—á–∞—Ç–ª—è
[30.10.2024 12:23] Loading Chinese text from previous data.
[30.10.2024 12:23] Renaming data file.
[30.10.2024 12:23] Renaming previous data. hf_papers.json to ./d/2024-10-30.json
[30.10.2024 12:23] Saving new data file.
[30.10.2024 12:23] Generating page.
[30.10.2024 12:23] Renaming previous page.
[30.10.2024 12:23] Renaming previous data. index.html to ./d/2024-10-30.html
[30.10.2024 12:23] [Experimental] Generating Chinese page for reading.
[30.10.2024 12:23] Chinese vocab [{'word': 'ËÆ®ËÆ∫', 'pinyin': 't«éo l√πn', 'trans': 'discuss'}, {'word': 'Êú∫Âô®ÂèñÊ∂àÂ≠¶‰π†', 'pinyin': 'jƒ´ q√¨ q«î xiƒÅo xu√© x√≠', 'trans': 'machine unlearning'}, {'word': 'Â¢ûÂº∫', 'pinyin': 'zƒìng qi√°ng', 'trans': 'enhance'}, {'word': 'ÈöêÁßÅ', 'pinyin': 'y«ên sƒ´', 'trans': 'privacy'}, {'word': 'ÂÆâÂÖ®', 'pinyin': 'ƒÅn qu√°n', 'trans': 'security'}, {'word': 'Ê∑±Â∫¶Â≠¶‰π†Ê®°Âûã', 'pinyin': 'shƒìn d√π xu√© x√≠ m√≥ x√≠ng', 'trans': 'deep learning model'}, {'word': 'Â§öÊ®°ÊÄÅËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'du≈ç m√≥ shu√†i y«î y√°n m√≥ x√≠ng', 'trans': 'multimodal language model'}, {'word': 'ÊòæËëó', 'pinyin': 'xi«én zh√π', 'trans': 'significant'}, {'word': 'ËøõÂ±ï', 'pinyin': 'j√¨n zh«én', 'trans': 'progress'}, {'word': 'Â§öÊ®°ÊÄÅÂèñÊ∂àÂ≠¶‰π†', 'pinyin': 'du≈ç m√≥ shu√†i q«î xiƒÅo xu√© x√≠', 'trans': 'multimodal unlearning'}, {'word': 'Á†îÁ©∂', 'pinyin': 'y√°n ji≈´', 'trans': 'research'}, {'word': 'ÂêàÈÄÇ', 'pinyin': 'h√© sh√¨', 'trans': 'suitable'}, {'word': 'ÂºÄÊ∫ê', 'pinyin': 'kƒÅi yu√°n', 'trans': 'open-source'}, {'word': 'Âü∫ÂáÜ', 'pinyin': 'jƒ´ zh«în', 'trans': 'benchmark'}, {'word': 'ÂºïÂÖ•', 'pinyin': 'y«ên r√π', 'trans': 'introduce'}, {'word': 'ËØÑ‰º∞', 'pinyin': 'p√≠ng g≈´', 'trans': 'evaluate'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': 'ËôöÊûÑ', 'pinyin': 'x≈´ g√≤u', 'trans': 'fictional'}, {'word': '‰∏™‰Ωì', 'pinyin': 'g√® t«ê', 'trans': 'individual'}, {'word': 'ÂõæÁâá', 'pinyin': 't√∫ pi√†n', 'trans': 'image'}, {'word': 'ÈóÆÁ≠îÂØπ', 'pinyin': 'w√®n d√° du√¨', 'trans': 'question-answer pair'}, {'word': 'Ë∑®Ê®°ÊÄÅ', 'pinyin': 'ku√† m√≥ shu√†i', 'trans': 'cross-modal'}, {'word': 'ÂÖ®Èù¢', 'pinyin': 'qu√°n mi√†n', 'trans': 'comprehensive'}, {'word': 'ÈÅóÂøò', 'pinyin': 'y√≠ w√†ng', 'trans': 'forgetting'}, {'word': 'ÊåëÊàò', 'pinyin': 'ti«éo zh√†n', 'trans': 'challenge'}, {'word': 'Ê≠£ÂàôÂåñ', 'pinyin': 'zh√®ng z√© hu√†', 'trans': 'regularization'}, {'word': 'ÂáèËΩª', 'pinyin': 'ji«én qƒ´ng', 'trans': 'alleviate'}, {'word': 'ÁÅæÈöæÊÄß', 'pinyin': 'zƒÅi n√†n x√¨ng', 'trans': 'catastrophic'}, {'word': '‰øùÊåÅ', 'pinyin': 'b«éo ch√≠', 'trans': 'maintain'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'Êï∞ÊçÆÈõÜ', 'pinyin': 'sh√π j√π j√≠', 'trans': 'dataset'}]
[30.10.2024 12:23] Renaming previous Chinese page.
[30.10.2024 12:23] Renaming previous data. zh.html to ./d/2024-10-29_zh_reading_task.html
[30.10.2024 12:23] Writing result.
[30.10.2024 12:23] Writing Chinese reading task.
[30.10.2024 12:23] Renaming log file.
[30.10.2024 12:23] Renaming previous data. log.txt to ./logs/2024-10-30_last_log.txt
