[30.10.2024 06:34] [Experimental] Generating an image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions.
[30.10.2024 06:34] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions' Text: 'Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKaggle implements an iterative development process that combines code execution, debugging, and comprehensive unit testing to ensure code correctness and logic consistency. The framework offers highly customizable workflows, allowing users to intervene at each phase, thus integrating automated intelligence with human expertise. Our universal data science toolkit, comprising validated functions for data cleaning, feature engineering, and modeling, forms the foundation of this solution, enhancing productivity by streamlining common tasks. We selected 8 Kaggle competitions to simulate data processing workflows in real-world application scenarios. Evaluation results demonstrate that AutoKaggle achieves a validation submission rate of 0.85 and a comprehensive score of 0.82 in typical data science pipelines, fully proving its effectiveness and practicality in handling complex data science tasks.'
[30.10.2024 06:34] Response: **Prompt:** Create a linear art scene on a white background featuring a surreal landscape where abstract representations of data pipelines intertwine with multi-agent figures collaborating around a giant, whimsical data wand. The figures should embody human expertise and automated intelligence, with exaggerated features and expressions of contemplation and creativity. Include elements like floating tables with chaotic datasets, colorful feature engineering tools, and ethereal clouds of code snippets hovering above. The text label for the central object, resembling a whimsical trophy, reads: "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions".
[30.10.2024 06:34] Generating image by prompt: **Prompt:** Create a linear art scene on a white background featuring a surreal landscape where abstract representations of data pipelines intertwine with multi-agent figures collaborating around a giant, whimsical data wand. The figures should embody human expertise and automated intelligence, with exaggerated features and expressions of contemplation and creativity. Include elements like floating tables with chaotic datasets, colorful feature engineering tools, and ethereal clouds of code snippets hovering above. The text label for the central object, resembling a whimsical trophy, reads: "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions"..
[30.10.2024 06:34] Saving generated image from https://fal.media/files/lion/bKF6R1JNfjz7-dZjQJ4An.png to d86977fc81e85089.jpg.
[30.10.2024 07:28] Read previous papers.
[30.10.2024 07:28] Get feed.
[30.10.2024 07:28] Extract page data from URL. URL: https://huggingface.co/papers/2410.18057
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.20424
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21411
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.19609
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22304
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22325
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21465
[30.10.2024 07:28] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21845
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 0. Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearn...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 1. Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKag...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 2. Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To ad...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 3. The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with t...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 4. Mathematical reasoning is a crucial capability for Large Language Models (LLMs), yet generating detailed and accurate reasoning traces remains a significant challenge. This paper introduces a novel approach to produce high-quality reasoning traces for LLM fine-tuning using online learning Flows. Our...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 5. The pre-training of visual representations has enhanced the efficiency of robot learning. Due to the lack of large-scale in-domain robotic datasets, prior works utilize in-the-wild human videos to pre-train robotic visual representation. Despite their promising results, representations from human vi...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 6. With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each t...
[30.10.2024 07:28] ********************************************************************************
[30.10.2024 07:28] Abstract 7. Reinforcement learning (RL) holds great promise for enabling autonomous acquisition of complex robotic manipulation skills, but realizing this potential in real-world settings has been challenging. We present a human-in-the-loop vision-based RL system that demonstrates impressive performance on a di...
[30.10.2024 07:28] Read previous papers.
[30.10.2024 07:28] Generating reviews via LLM API.
[30.10.2024 07:28] Querying the API.
[30.10.2024 07:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearning (MMU) remains significantly underexplored, partially due to the absence of a suitable open-source benchmark. To address this, we introduce CLEAR, a new benchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious individuals and 3,700 images linked with corresponding question-answer pairs, enabling a thorough evaluation across modalities. We assess 10 MU methods, adapting them for MMU, and highlight new challenges specific to multimodal forgetting. We also demonstrate that simple ell_1 regularization on LoRA weights significantly mitigates catastrophic forgetting, preserving model performance on retained data. The dataset is available at https://huggingface.co/datasets/therem/CLEAR
[30.10.2024 07:28] Response: {
  "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº CLEAR Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (MMU) Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (MLLM). CLEAR ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾ 200 Ğ²Ñ‹Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ»Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑÑ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ 3700 Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ-Ğ¾Ñ‚Ğ²ĞµÑ‚. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ»Ğ¸ 10 Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (MU) Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ L1-Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ² LoRA Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ ĞºĞ°Ñ‚Ğ°ÑÑ‚Ñ€Ğ¾Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ·Ğ°Ğ±Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ²ÑˆĞ¸Ñ…ÑÑ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….",
  "emoji": "ğŸ§ ",
  "title": "CLEAR: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² Ğ˜Ğ˜"
}
[30.10.2024 07:28] OpenAI request. Model: gpt-4o-mini. Prompt: You are an expert classifier of machine learning research papers. Analyze the following research paper text and classify it into one or more relevant categories from the list below. Consider the paper's main contributions, methodologies, and applications.

Categories:
1. DATASET: Papers that introduce new datasets or make significant modifications to existing ones
2. DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
3. BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
4. AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
5. CV: Papers developing computer vision methods or visual processing systems
6. RL: Papers investigating reinforcement learning theory or applications
7. RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
8. RAG: Papers advancing retrieval-augmented generation techniques
9. PLP: Papers about Programming Language Processing models or programming benchmarks
10. INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
11. 3D: Papers on 3D content generation, processing, or understanding
12. AUDIO: Papers advancing speech/audio processing or generation
13. VIDEO: Papers on video analysis, generation, or understanding
14. MULTIMODAL: Papers combining multiple input/output modalities
15. MATH: Papers focused on mathematical theory and algorithms
16. MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities
17. ARCHITECTURE: Papers proposing novel neural architectures or components
18. MEDICINE: Papers applying ML to medical/healthcare domains
19. TRAINING: Papers improving model training or fine-tuning methods
20. ROBOTICS: Papers on robotic systems and embodied AI
21. AGI: Papers discussing artificial general intelligence concepts
22. GAMES: Papers applying ML to games or game development
23. INTERPRETABILITY: Papers analyzing model behavior and explanations
24. REASONING: Papers enhancing logical reasoning capabilities
25. TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
26. GRAPHS: Papers advancing graph neural networks and applications
27. ETHICS: Papers addressing AI ethics, fairness, and bias
28. SECURITY: Papers on model security and adversarial robustness
29. EDGE_COMPUTING: Papers on ML deployment for resource-constrained devices
30. OPTIMIZATION: Papers advancing training optimization methods
31. SURVEY: Papers comprehensively reviewing research areas
32. DIFFUSION: Papers on diffusion-based generative models
33. ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
34. STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
35. HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
36. LONG_CONTEXT: Papers about long context handling, including techniques to extend context length and process long sequences.

Return only JSON with flat array of categories that match the given text.

Paper text to classify:

"Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearning (MMU) remains significantly underexplored, partially due to the absence of a suitable open-source benchmark. To address this, we introduce CLEAR, a new benchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious individuals and 3,700 images linked with corresponding question-answer pairs, enabling a thorough evaluation across modalities. We assess 10 MU methods, adapting them for MMU, and highlight new challenges specific to multimodal forgetting. We also demonstrate that simple ell_1 regularization on LoRA weights significantly mitigates catastrophic forgetting, preserving model performance on retained data. The dataset is available at https://huggingface.co/datasets/therem/CLEAR"

[30.10.2024 07:28] Response: ```json
["DATASET", "BENCHMARK", "MULTIMODAL", "TRAINING"]
```
[30.10.2024 07:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper focuses on Machine Unlearning (MU), which is important for protecting privacy in deep learning models, especially in large multimodal language models (MLLMs). The authors identify a gap in multimodal unlearning (MMU) research and introduce CLEAR, a new benchmark that includes 200 fictitious individuals and 3,700 images with question-answer pairs for evaluating MMU methods. They assess 10 existing MU methods adapted for MMU and reveal unique challenges related to forgetting in multimodal contexts. Additionally, they find that applying simple ell_1 regularization on LoRA weights can help reduce catastrophic forgetting, thus maintaining the model\'s performance on the data that remains.","title":"Enhancing Privacy with Multimodal Unlearning: Introducing CLEAR"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc="This paper focuses on Machine Unlearning (MU), which is important for protecting privacy in deep learning models, especially in large multimodal language models (MLLMs). The authors identify a gap in multimodal unlearning (MMU) research and introduce CLEAR, a new benchmark that includes 200 fictitious individuals and 3,700 images with question-answer pairs for evaluating MMU methods. They assess 10 existing MU methods adapted for MMU and reveal unique challenges related to forgetting in multimodal contexts. Additionally, they find that applying simple ell_1 regularization on LoRA weights can help reduce catastrophic forgetting, thus maintaining the model's performance on the data that remains.", title='Enhancing Privacy with Multimodal Unlearning: Introducing CLEAR'))
[30.10.2024 07:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"æœºå™¨é—å¿˜ï¼ˆMUï¼‰åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­å¯¹äºå¢å¼ºéšç§å’Œå®‰å…¨æ€§è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ã€‚å°½ç®¡åœ¨æ–‡æœ¬å’Œè§†è§‰æ¨¡æ€ä¸Šï¼ŒMUå·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤šæ¨¡æ€é—å¿˜ï¼ˆMMUï¼‰ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ï¼Œéƒ¨åˆ†åŸå› æ˜¯ç¼ºä¹åˆé€‚çš„å¼€æºåŸºå‡†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CLEARï¼Œä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°MMUæ–¹æ³•ã€‚CLEARåŒ…å«200ä¸ªè™šæ„ä¸ªä½“å’Œ3700å¼ ä¸ç›¸åº”é—®ç­”å¯¹ç›¸å…³çš„å›¾åƒï¼Œèƒ½å¤Ÿå…¨é¢è¯„ä¼°ä¸åŒæ¨¡æ€çš„é—å¿˜æ•ˆæœã€‚","title":"CLEARï¼šå¤šæ¨¡æ€é—å¿˜çš„æ–°åŸºå‡†"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='æœºå™¨é—å¿˜ï¼ˆMUï¼‰åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­å¯¹äºå¢å¼ºéšç§å’Œå®‰å…¨æ€§è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ã€‚å°½ç®¡åœ¨æ–‡æœ¬å’Œè§†è§‰æ¨¡æ€ä¸Šï¼ŒMUå·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤šæ¨¡æ€é—å¿˜ï¼ˆMMUï¼‰ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ï¼Œéƒ¨åˆ†åŸå› æ˜¯ç¼ºä¹åˆé€‚çš„å¼€æºåŸºå‡†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CLEARï¼Œä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°MMUæ–¹æ³•ã€‚CLEARåŒ…å«200ä¸ªè™šæ„ä¸ªä½“å’Œ3700å¼ ä¸ç›¸åº”é—®ç­”å¯¹ç›¸å…³çš„å›¾åƒï¼Œèƒ½å¤Ÿå…¨é¢è¯„ä¼°ä¸åŒæ¨¡æ€çš„é—å¿˜æ•ˆæœã€‚', title='CLEARï¼šå¤šæ¨¡æ€é—å¿˜çš„æ–°åŸºå‡†'))
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#dataset", "#data", "#agents"], "emoji": "ğŸ¤–", "ru": {"title": "AutoKaggle: Ğ˜Ğ˜-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸", "desc": "AutoKaggle - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸, Ğ²
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#interpretability", "#long_context"], "emoji": "ğŸ‘¥", "ru": {"title": "SocialGPT: Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ·Ñ‹ĞºĞ° Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#rl", "#training"], "emoji": "ğŸ•¸ï¸", "ru": {"title": "Ğ¡Ğ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸ĞµÑÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµĞ±-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ°", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ÑƒÑ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñƒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ²ĞµĞ±-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… Ğº Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¼Ñƒ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#math", "#rlhf", "#reasoning"], "emoji": "ğŸ§®", "ru": {"title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ LLM Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#agents", "#robotics", "#dataset"], "emoji": "ğŸ¦¾", "ru": {"title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Manipulation Centric
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#inference", "#long_context", "#benchmark"], "emoji": "ğŸš€", "ru": {"title": "ShadowKV: Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… LLM Ğ±ĞµĞ· ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑĞ¾Ğ²", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ShadowKV - ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Shadow
[30.10.2024 07:28] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#robotics"], "emoji": "ğŸ¤–", "ru": {"title": "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸ Ğ˜Ğ˜: ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğ¼ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸ÑĞ¼", "desc": "Ğ’ ÑÑ‚Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸ĞµĞ¼ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ»Ñ
[30.10.2024 07:28] Loading Chinese text from previous data.
[30.10.2024 07:28] Renaming data file.
[30.10.2024 07:28] Renaming previous data. hf_papers.json to ./d/2024-10-30.json
[30.10.2024 07:28] Saving new data file.
[30.10.2024 07:28] Generating page.
[30.10.2024 07:28] Renaming previous page.
[30.10.2024 07:28] Renaming previous data. index.html to ./d/2024-10-30.html
[30.10.2024 07:28] [Experimental] Generating Chinese page for reading.
[30.10.2024 07:28] Chinese vocab [{'word': 'ä»‹ç»', 'pinyin': 'jiÃ¨shÃ o', 'trans': 'introduce'}, {'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generate'}, {'word': 'æ¨¡å‹', 'pinyin': 'mÃ³xÃ­ng', 'trans': 'model'}, {'word': 'åˆ›æ–°', 'pinyin': 'chuÃ ngxÄ«n', 'trans': 'innovative'}, {'word': 'æŠ€æœ¯', 'pinyin': 'jÃ¬shÃ¹', 'trans': 'technology'}, {'word': 'è®­ç»ƒ', 'pinyin': 'xÃ¹nliÃ n', 'trans': 'train'}, {'word': 'æƒé‡', 'pinyin': 'quÃ¡nzhÃ²ng', 'trans': 'weight'}, {'word': 'æŒ‡ä»¤', 'pinyin': 'zhÇlÃ¬ng', 'trans': 'instruction'}, {'word': 'äº¤å‰ç†µ', 'pinyin': 'jiÄochÄ shÄng', 'trans': 'cross-entropy'}, {'word': 'æŸå¤±', 'pinyin': 'sÇ”nshÄ«', 'trans': 'loss'}, {'word': 'è‡ªé€‚åº”', 'pinyin': 'zÃ¬shÃ¬yÃ¬ng', 'trans': 'adaptive'}, {'word': 'å­¦ä¹ ç‡', 'pinyin': 'xuÃ©xÃ­lÇœ', 'trans': 'learning rate'}, {'word': 'è¯„ä¼°', 'pinyin': 'pÃ­nggÅ«', 'trans': 'evaluate'}, {'word': 'æ¡†æ¶', 'pinyin': 'kuÃ ngjiÃ ', 'trans': 'framework'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ­ngnÃ©ng', 'trans': 'performance'}, {'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨nwÃ¹', 'trans': 'task'}, {'word': 'æ˜¾è‘—', 'pinyin': 'xiÇnzhÃ¹', 'trans': 'significant'}, {'word': 'æ”¹è¿›', 'pinyin': 'gÇijÃ¬n', 'trans': 'improvement'}, {'word': 'æ¨ç†', 'pinyin': 'tuÄ«lÇ', 'trans': 'reasoning'}, {'word': 'è§’è‰²', 'pinyin': 'juÃ©sÃ¨', 'trans': 'role'}, {'word': 'æ‰®æ¼”', 'pinyin': 'bÃ nyÇn', 'trans': 'play'}, {'word': 'é¢†åŸŸ', 'pinyin': 'lÇngyÃ¹', 'trans': 'field'}, {'word': 'é‡å¤§', 'pinyin': 'zhÃ²ngdÃ ', 'trans': 'major'}, {'word': 'è¿›å±•', 'pinyin': 'jÃ¬nzhÇn', 'trans': 'progress'}]
[30.10.2024 07:28] Renaming previous Chinese page.
[30.10.2024 07:28] Renaming previous data. zh.html to ./d/2024-10-29_zh_reading_task.html
[30.10.2024 07:28] Writing result.
[30.10.2024 07:28] Writing Chinese reading task.
[30.10.2024 07:28] Renaming log file.
[30.10.2024 07:28] Renaming previous data. log.txt to ./logs/2024-10-30_last_log.txt
