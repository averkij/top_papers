[30.10.2024 12:23] [Experimental] Generating an image for paper CLEAR: Character Unlearning in Textual and Visual Modalities.
[30.10.2024 12:23] [Experimental] Image for paper CLEAR: Character Unlearning in Textual and Visual Modalities already exists.
[30.10.2024 12:23] [Experimental] Generating an image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions.
[30.10.2024 12:23] [Experimental] Image for paper AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions already exists.
[30.10.2024 12:23] [Experimental] Generating an image for paper SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.
[30.10.2024 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization' Text: 'Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To address these issues, we first present a simple yet well-crafted framework named {\name}, which combines the perception capability of Vision Foundation Models (VFMs) and the reasoning capability of Large Language Models (LLMs) within a modular framework, providing a strong baseline for social relation recognition. Specifically, we instruct VFMs to translate image content into a textual social story, and then utilize LLMs for text-based reasoning. {\name} introduces systematic design principles to adapt VFMs and LLMs separately and bridge their gaps. Without additional model training, it achieves competitive zero-shot results on two databases while offering interpretable answers, as LLMs can generate language-based explanations for the decisions. The manual prompt design process for LLMs at the reasoning phase is tedious and an automated prompt optimization method is desired. As we essentially convert a visual classification task into a generative task of LLMs, automatic prompt optimization encounters a unique long prompt optimization issue. To address this issue, we further propose the Greedy Segment Prompt Optimization (GSPO), which performs a greedy search by utilizing gradient information at the segment level. Experimental results show that GSPO significantly improves performance, and our method also generalizes to different image styles. The code is available at https://github.com/Mengzibin/SocialGPT.'
[30.10.2024 12:23] Response: **Prompt:** Create a linear art piece on a white background that depicts a surreal scene blending the worlds of visual perception and textual reasoning. Visualize a giant eye made of interwoven threads representing Vision Foundation Models, looking at a cluster of abstract human figures symbolizing social relations (friends, spouses, colleagues). Each figure is connected by colorful, flowing lines to a central book that represents Large Language Models, from which whimsical text bubbles emanate, giving language-based explanations. Place a label beneath the central book that reads: "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization."
[30.10.2024 12:23] Generating image by prompt: **Prompt:** Create a linear art piece on a white background that depicts a surreal scene blending the worlds of visual perception and textual reasoning. Visualize a giant eye made of interwoven threads representing Vision Foundation Models, looking at a cluster of abstract human figures symbolizing social relations (friends, spouses, colleagues). Each figure is connected by colorful, flowing lines to a central book that represents Large Language Models, from which whimsical text bubbles emanate, giving language-based explanations. Place a label beneath the central book that reads: "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.".
[30.10.2024 12:23] Saving generated image from https://fal.media/files/elephant/GbnJ5wEUskVTzo_yYIOLi.png to ad99b3e3b4ef165c.jpg.
[30.10.2024 12:23] [Experimental] Generating an image for paper OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization.
[30.10.2024 12:23] OpenAI request. Model: gpt-4o-mini. Prompt: Write a text with image prompt in style of surrealism and modern art based on the following paper. Use key themes and elements from it. Add instruction to write a text that reads as brief paper title as a label on some object on an image. Style: linear art on white background. Return only prompt and nothing else. Title: 'OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization' Text: 'The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with the ability to explore environments and continuously improve over time, they are building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents struggle to generalize to realistic settings that require multimodal perception abilities and lack ground-truth signals. In this paper, we introduce an open-source framework designed to facilitate the development of multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets.'
[30.10.2024 12:23] Response: **Prompt:** Create a piece of linear art on a white background depicting a surreal landscape where a large, abstract figure represents a web agent. This figure is intertwined with various digital elements symbolizing multimodal perception—like distorted screens displaying text, images, and audio waves. In the background, a labyrinth of pathways represents the open web, with feedback loops illustrated as swirling arrows guiding the agent's exploration. Above the figure, inscribe the title: "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization" in a modern, minimalist font, as if it were a label on an art piece.
[30.10.2024 12:23] Generating image by prompt: **Prompt:** Create a piece of linear art on a white background depicting a surreal landscape where a large, abstract figure represents a web agent. This figure is intertwined with various digital elements symbolizing multimodal perception—like distorted screens displaying text, images, and audio waves. In the background, a labyrinth of pathways represents the open web, with feedback loops illustrated as swirling arrows guiding the agent's exploration. Above the figure, inscribe the title: "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization" in a modern, minimalist font, as if it were a label on an art piece..
[30.10.2024 12:23] Saving generated image from https://fal.media/files/elephant/x1htojugc1YaDe9myJ7Jr.png to c9775abc4b4ddd0d.jpg.
[30.10.2024 14:11] Read previous papers.
[30.10.2024 14:11] Get feed.
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.18057
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.20424
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21411
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.19609
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22304
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.22325
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21465
[30.10.2024 14:11] Get page data from previous paper. URL: https://huggingface.co/papers/2410.21845
[30.10.2024 14:11] Extract page data from URL. URL: https://huggingface.co/papers/2410.21333
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 0. Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearn...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 1. Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKag...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 2. Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To ad...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 3. The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with t...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 4. Mathematical reasoning is a crucial capability for Large Language Models (LLMs), yet generating detailed and accurate reasoning traces remains a significant challenge. This paper introduces a novel approach to produce high-quality reasoning traces for LLM fine-tuning using online learning Flows. Our...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 5. The pre-training of visual representations has enhanced the efficiency of robot learning. Due to the lack of large-scale in-domain robotic datasets, prior works utilize in-the-wild human videos to pre-train robotic visual representation. Despite their promising results, representations from human vi...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 6. With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each t...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 7. Reinforcement learning (RL) holds great promise for enabling autonomous acquisition of complex robotic manipulation skills, but realizing this potential in real-world settings has been challenging. We present a human-in-the-loop vision-based RL system that demonstrates impressive performance on a di...
[30.10.2024 14:11] ********************************************************************************
[30.10.2024 14:11] Abstract 8. Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open...
[30.10.2024 14:11] Read previous papers.
[30.10.2024 14:11] Generating reviews via LLM API.
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#multimodal"], "emoji": "🧠", "ru": {"title": "CLEAR: Новый стандарт для мультимодального разобучения в ИИ", "desc": "Статья представляет новый бенчмарк CLEAR для оценки методов мультимодального разобучения (MMU) в больших мультимодальных языковых моделях (M
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#dataset", "#data", "#agents"], "emoji": "🤖", "ru": {"title": "AutoKaggle: ИИ-помощник для ускорения работы с данными", "desc": "AutoKaggle - это мощный фреймворк для решения задач с табличными данными с помощью мультиагентной системы. Он использует итеративный процесс разработки, в
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#interpretability", "#long_context"], "emoji": "👥", "ru": {"title": "SocialGPT: объединение зрения и языка для интерпретируемого распознавания социальных отношений", "desc": "Эта статья представляет новый подход к распознаванию социальных отношений на изображен
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#agents", "#multimodal", "#rl"], "emoji": "🕸️", "ru": {"title": "Самообучающиеся мультимодальные веб-агенты для реального мира", "desc": "Эта статья представляет открытую платформу для разработки мультимодальных веб-агентов, способных к автономному исследованию реального мира и само
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#math", "#rlhf", "#reasoning"], "emoji": "🧮", "ru": {"title": "Улучшение математических рассуждений LLM через онлайн-обучение потоков", "desc": "Эта статья представляет новый подход к созданию качественных цепочек рассуждений для дообучения больших языковых моделей (LLM) в задачах м
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#agents", "#robotics", "#dataset"], "emoji": "🦾", "ru": {"title": "Улучшение роботизированных манипуляций через предобучение с учетом динамики", "desc": "Эта статья представляет новый подход к предобучению визуальных представлений для робототехники под названием Manipulation Centric
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#inference", "#long_context", "#benchmark"], "emoji": "🚀", "ru": {"title": "ShadowKV: Ускорение вывода длинноконтекстных LLM без компромиссов", "desc": "Статья представляет ShadowKV - систему для высокопроизводительного вывода длинноконтекстных больших языковых моделей (LLM). Shadow
[30.10.2024 14:11] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#robotics"], "emoji": "🤖", "ru": {"title": "Человек и ИИ: совместное обучение роботов сложным манипуляциям", "desc": "В этой статье представлена система обучения с подкреплением (RL) для роботизированной манипуляции с участием человека. Система демонстрирует впечатля
[30.10.2024 14:11] Querying the API.
[30.10.2024 14:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning.
[30.10.2024 14:12] Response: {
  "desc": "Статья исследует влияние промптинга с цепочкой рассуждений (CoT) на производительность языковых моделей. Авторы выявляют задачи, где CoT снижает эффективность, опираясь на примеры из когнитивной психологии. Эксперименты показывают значительное падение точности современных моделей при использовании CoT в определенных сценариях. Исследование устанавливает связь между литературой о человеческих рассуждениях и оценкой CoT в контексте языковых моделей.",
  "emoji": "🧠",
  "title": "Когда размышления вредят: ограничения CoT в языковых моделях"
}
[30.10.2024 14:12] OpenAI request. Model: gpt-4o-mini. Prompt: You are an expert classifier of machine learning research papers. Analyze the following research paper text and classify it into one or more relevant categories from the list below. Consider the paper's main contributions, methodologies, and applications.

Categories:
1. DATASET: Papers that introduce new datasets or make significant modifications to existing ones
2. DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
3. BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
4. AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
5. CV: Papers developing computer vision methods or visual processing systems
6. RL: Papers investigating reinforcement learning theory or applications
7. RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
8. RAG: Papers advancing retrieval-augmented generation techniques
9. PLP: Papers about Programming Language Processing models or programming benchmarks
10. INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
11. 3D: Papers on 3D content generation, processing, or understanding
12. AUDIO: Papers advancing speech/audio processing or generation
13. VIDEO: Papers on video analysis, generation, or understanding
14. MULTIMODAL: Papers combining multiple input/output modalities
15. MATH: Papers focused on mathematical theory and algorithms
16. MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities
17. ARCHITECTURE: Papers proposing novel neural architectures or components
18. MEDICINE: Papers applying ML to medical/healthcare domains
19. TRAINING: Papers improving model training or fine-tuning methods
20. ROBOTICS: Papers on robotic systems and embodied AI
21. AGI: Papers discussing artificial general intelligence concepts
22. GAMES: Papers applying ML to games or game development
23. INTERPRETABILITY: Papers analyzing model behavior and explanations
24. REASONING: Papers enhancing logical reasoning capabilities
25. TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
26. GRAPHS: Papers advancing graph neural networks and applications
27. ETHICS: Papers addressing AI ethics, fairness, and bias
28. SECURITY: Papers on model security and adversarial robustness
29. EDGE_COMPUTING: Papers on ML deployment for resource-constrained devices
30. OPTIMIZATION: Papers advancing training optimization methods
31. SURVEY: Papers comprehensively reviewing research areas
32. DIFFUSION: Papers on diffusion-based generative models
33. ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
34. STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
35. HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
36. LONG_CONTEXT: Papers about long context handling, including techniques to extend context length and process long sequences.

Return only JSON with flat array of categories that match the given text.

Paper text to classify:

"Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning."

[30.10.2024 14:12] Response: ```json
["INTERPRETABILITY", "REASONING", "MULTIMODAL"]
```
[30.10.2024 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the effectiveness of Chain-of-Thought (CoT) prompting in large language and multimodal models, particularly focusing on when it may hinder performance. By drawing parallels from cognitive psychology, the authors explore scenarios where verbal reasoning negatively impacts human performance and whether these scenarios apply to language models. Through extensive experiments, they demonstrate that certain tasks, such as implicit statistical learning and visual recognition, can lead to significant performance drops in models when using CoT prompting. The findings suggest that understanding human cognitive limitations can provide insights into optimizing model performance and prompt design.","title":"Understanding When Chain-of-Thought Prompting Fails in AI Models"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='This paper investigates the effectiveness of Chain-of-Thought (CoT) prompting in large language and multimodal models, particularly focusing on when it may hinder performance. By drawing parallels from cognitive psychology, the authors explore scenarios where verbal reasoning negatively impacts human performance and whether these scenarios apply to language models. Through extensive experiments, they demonstrate that certain tasks, such as implicit statistical learning and visual recognition, can lead to significant performance drops in models when using CoT prompting. The findings suggest that understanding human cognitive limitations can provide insights into optimizing model performance and prompt design.', title='Understanding When Chain-of-Thought Prompting Fails in AI Models'))
[30.10.2024 14:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"链式思维（CoT）提示是一种在大型语言和多模态模型中广泛使用的策略。本文探讨了在何种情况下链式思维会降低模型性能，借鉴了认知心理学的研究。通过对隐性统计学习、视觉识别和包含例外的模式分类等任务的实验，我们发现使用推理时的链式思维会导致模型性能显著下降。我们的研究表明，理解人类思维对模型性能的影响，可以帮助我们更好地选择提示和推理策略。","title":"链式思维的影响：何时有益，何时有害"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], parsed=Article(desc='链式思维（CoT）提示是一种在大型语言和多模态模型中广泛使用的策略。本文探讨了在何种情况下链式思维会降低模型性能，借鉴了认知心理学的研究。通过对隐性统计学习、视觉识别和包含例外的模式分类等任务的实验，我们发现使用推理时的链式思维会导致模型性能显著下降。我们的研究表明，理解人类思维对模型性能的影响，可以帮助我们更好地选择提示和推理策略。', title='链式思维的影响：何时有益，何时有害'))
[30.10.2024 14:12] Loading Chinese text from previous data.
[30.10.2024 14:12] Renaming data file.
[30.10.2024 14:12] Renaming previous data. hf_papers.json to ./d/2024-10-30.json
[30.10.2024 14:12] Saving new data file.
[30.10.2024 14:12] Generating page.
[30.10.2024 14:12] Renaming previous page.
[30.10.2024 14:12] Renaming previous data. index.html to ./d/2024-10-30.html
[30.10.2024 14:12] [Experimental] Generating Chinese page for reading.
[30.10.2024 14:12] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '机器取消学习', 'pinyin': 'jī qì qǔ xiāo xué xí', 'trans': 'machine unlearning'}, {'word': '增强', 'pinyin': 'zēng qiáng', 'trans': 'enhance'}, {'word': '隐私', 'pinyin': 'yǐn sī', 'trans': 'privacy'}, {'word': '安全', 'pinyin': 'ān quán', 'trans': 'security'}, {'word': '深度学习模型', 'pinyin': 'shēn dù xué xí mó xíng', 'trans': 'deep learning model'}, {'word': '多模态语言模型', 'pinyin': 'duō mó shuài yǔ yán mó xíng', 'trans': 'multimodal language model'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'}, {'word': '多模态取消学习', 'pinyin': 'duō mó shuài qǔ xiāo xué xí', 'trans': 'multimodal unlearning'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '合适', 'pinyin': 'hé shì', 'trans': 'suitable'}, {'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'}, {'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'}, {'word': '引入', 'pinyin': 'yǐn rù', 'trans': 'introduce'}, {'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluate'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '虚构', 'pinyin': 'xū gòu', 'trans': 'fictional'}, {'word': '个体', 'pinyin': 'gè tǐ', 'trans': 'individual'}, {'word': '图片', 'pinyin': 'tú piàn', 'trans': 'image'}, {'word': '问答对', 'pinyin': 'wèn dá duì', 'trans': 'question-answer pair'}, {'word': '跨模态', 'pinyin': 'kuà mó shuài', 'trans': 'cross-modal'}, {'word': '全面', 'pinyin': 'quán miàn', 'trans': 'comprehensive'}, {'word': '遗忘', 'pinyin': 'yí wàng', 'trans': 'forgetting'}, {'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'}, {'word': '正则化', 'pinyin': 'zhèng zé huà', 'trans': 'regularization'}, {'word': '减轻', 'pinyin': 'jiǎn qīng', 'trans': 'alleviate'}, {'word': '灾难性', 'pinyin': 'zāi nàn xìng', 'trans': 'catastrophic'}, {'word': '保持', 'pinyin': 'bǎo chí', 'trans': 'maintain'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'}]
[30.10.2024 14:12] Renaming previous Chinese page.
[30.10.2024 14:12] Renaming previous data. zh.html to ./d/2024-10-29_zh_reading_task.html
[30.10.2024 14:12] Writing result.
[30.10.2024 14:12] Writing Chinese reading task.
[30.10.2024 14:12] Renaming log file.
[30.10.2024 14:12] Renaming previous data. log.txt to ./logs/2024-10-30_last_log.txt
