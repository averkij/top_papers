[24.10.2024 00:58] [Experimental] Generating an image for paper PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction.
[24.10.2024 00:58] [Experimental] Image for paper PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction already exists.
[24.10.2024 00:58] [Experimental] Generating an image for paper SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes.
[24.10.2024 00:58] [Experimental] Image for paper SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes already exists.
[24.10.2024 02:44] Read previous papers.
[24.10.2024 02:44] Get feed.
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17247
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17249
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17131
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17215
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.16267
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.16198
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17250
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.16392
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.15926
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.14649
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.16930
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.17241
[24.10.2024 02:44] Get page data from previous paper. URL: https://huggingface.co/papers/2410.16266
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 0. In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information. As the idiom "A picture is worth a thousand words" implies, representing a single image in current LVLMs can require hundreds or even thousands of tokens. This results in significant computational cos...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 1. We present SpectroMotion, a novel approach that combines 3D Gaussian Splatting (3DGS) with physically-based rendering (PBR) and deformation fields to reconstruct dynamic specular scenes. Previous methods extending 3DGS to model dynamic scenes have struggled to accurately represent specular surfaces....
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 2. Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce Self-Steering Optimization (SSO), an algorithm that...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 3. Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness. Existing methods either incur high computational co...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 4. We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for videos, particularly designed to efficiently capture temporal information over multiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in addition to the conventional visual tokenizer, which maps a sequence of tok...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 5. Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial for improving interpretability and trustworthiness. However, current training recipes lack robust CoT reasoning data, relying on datasets dominated by short annotations with minimal rationales. In this work, we show that tr...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 6. Accelerating research on Large Multimodal Models (LMMs) in non-English languages is crucial for enhancing user experiences across broader populations. In this paper, we introduce JMMMU (Japanese MMMU), the first large-scale Japanese benchmark designed to evaluate LMMs on expert-level tasks based on ...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 7. In a compound AI system, components such as an LLM call, a retriever, a code interpreter, or tools are interconnected. The system's behavior is primarily driven by parameters such as instructions or tool definitions. Recent advancements enable end-to-end optimization of these parameters using an LLM...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 8. Recent Large Vision Language Models (LVLMs) present remarkable zero-shot conversational and reasoning capabilities given multimodal queries. Nevertheless, they suffer from object hallucination, a phenomenon where LVLMs are prone to generate textual responses not factually aligned with image inputs. ...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 9. The high computational costs of large language models (LLMs) have led to a flurry of research on LLM compression, via methods such as quantization, sparsification, or structured pruning. A new frontier in this area is given by dynamic, non-uniform compression methods, which adjust the compression le...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 10. Math reasoning is a highly active area of Large Language Model (LLM) research because it is a hallmark of artificial intelligence. However, few works have explored how math reasoning is encoded within LLM parameters and if it is a skill that can be isolated within a model. Doing so could allow targe...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 11. Colonoscopy is currently one of the most sensitive screening methods for colorectal cancer. This study investigates the frontiers of intelligent colonoscopy techniques and their prospective implications for multimodal medical applications. With this goal, we begin by assessing the current data-centr...
[24.10.2024 02:44] ********************************************************************************
[24.10.2024 02:44] Abstract 12. Novel-view synthesis aims to generate novel views of a scene from multiple input images or videos, and recent advancements like 3D Gaussian splatting (3DGS) have achieved notable success in producing photorealistic renderings with efficient pipelines. However, generating high-quality novel views und...
[24.10.2024 02:44] Read previous papers.
[24.10.2024 02:44] Generating reviews via LLM API.
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет новый метод PyramidDrop для повышения эффективности крупных визуально-языковых моделей (LVLM). Авторы обнаружили, что токены изображений становятся избыточными в глубоких слоях модели. PyramidDrop постепенно уменьшает количество токенов изображения на разных этапах обра
[24.10.2024 02:44] Using data from previous issue: {"desc": "SpectroMotion - это новый подход, объединяющий 3D гауссово сплаттинг (3DGS) с физически корректным рендерингом (PBR) и полями деформации для реконструкции динамических зеркальных сцен. Метод вводит технику остаточной коррекции для точного вычисления нормалей поверхности при деформации, а т
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет алгоритм Self-Steering Optimization (SSO) для автоматизированного выравнивания языковых моделей. SSO генерирует качественные сигналы предпочтений без ручной разметки, поддерживая постоянный разрыв между выбранными и отвергнутыми ответами. Алгоритм улучшает онлайн и офла
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет MiniPLM - новый фреймворк для дистилляции знаний при предварительном обучении языковых моделей. MiniPLM решает проблемы эффективности, гибкости и эффективности существующих методов, выполняя офлайн-вывод учительской модели и работая только с обучающим корпусом. Этот под
[24.10.2024 02:44] Using data from previous issue: {"desc": "В статье представлена мультимодальная языковая модель xGen-MM-Vid (BLIP-3-Video) для обработки видео. Модель использует 'временной кодировщик' в дополнение к обычному визуальному токенизатору, что позволяет эффективно захватывать временную информацию из нескольких кадров. BLIP-3-Video треб
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет новый подход к улучшению рассуждений в визуально-языковых моделях (VLM). Авторы предлагают обогащать обучающие данные подробными объяснениями, полученными от GPT-4, и применять обучение с подкреплением для калибровки качества рассуждений. Эксперименты показывают значите
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет JMMMU - первый масштабный японский бенчмарк для оценки больших мультимодальных моделей (LMM) на экспертных задачах в японском культурном контексте. Бенчмарк состоит из двух подмножеств: культурно-агностического (CA) и культурно-специфического (CS). Исследование выявило 
[24.10.2024 02:44] Using data from previous issue: {"desc": "Эта статья представляет обзор принципов и новых тенденций в оптимизации сложных систем искусственного интеллекта с использованием больших языковых моделей (LLM). Авторы рассматривают архетипы сложных AI-систем и подходы к их сквозной оптимизации с помощью LLM. В работе используются концепц
[24.10.2024 02:44] Using data from previous issue: {"desc": "Исследователи обнаружили, что большие мультимодальные языковые модели (LVLMs) склонны к галлюцинациям объектов из-за особенностей позиционного кодирования RoPE. Эта проблема усугубляется, когда визуальные подсказки находятся далеко от текстовых инструкций во входной последовательности. Авт
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет новый подход к динамической компрессии больших языковых моделей (LLM) под названием EvoPress. Авторы опровергают предположение о монотонности ошибок в LLM и предлагают эволюционный фреймворк с доказуемой сходимостью и низкой вычислительной сложностью. EvoPress показывае
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет метод MathNeuro для выделения параметров, отвечающих за математические рассуждения в больших языковых моделях (LLM). Этот метод позволяет целенаправленно улучшать математические способности модели, не затрагивая другие языковые навыки. Исследователи показали, что удален
[24.10.2024 02:44] Using data from previous issue: {"desc": "Это исследование посвящено интеллектуальным методам колоноскопии и их потенциальному применению в мультимодальной медицине. Авторы оценивают текущее состояние подходов, основанных на данных и моделях, для четырех задач восприятия колоноскопических сцен. Они выявляют специфические для домен
[24.10.2024 02:44] Using data from previous issue: {"desc": "Статья представляет 3DGS-Enhancer - новый метод улучшения качества представления сцен в задаче синтеза новых ракурсов. Авторы используют 2D видео-диффузионные приоры для решения проблемы согласованности ракурсов в 3D, переформулируя ее как достижение временной согласованности в процессе ге
[24.10.2024 02:44] Loading Chinese text from previous data.
[24.10.2024 02:44] Renaming data file.
[24.10.2024 02:44] Renaming previous data. hf_papers.json to ./d/2024-10-24.json
[24.10.2024 02:44] Saving new data file.
[24.10.2024 02:44] Generating page.
[24.10.2024 02:44] Renaming previous page.
[24.10.2024 02:44] Renaming previous data. index.html to ./d/2024-10-24.html
[24.10.2024 02:44] [Experimental] Generating Chinese page for reading.
[24.10.2024 02:44] Chinese vocab [{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大规模', 'pinyin': 'dà guī mó', 'trans': 'large-scale'}, {'word': '视觉-语言模型', 'pinyin': 'shì jué yǔ yán mó xìng', 'trans': 'vision-language model'}, {'word': '计算成本', 'pinyin': 'jì suàn chéng běn', 'trans': 'computational cost'}, {'word': '表示', 'pinyin': 'biǎo shì', 'trans': 'representation'}, {'word': '标记', 'pinyin': 'biāo jì', 'trans': 'token'}, {'word': '分辨率', 'pinyin': 'fēn biàn lǜ', 'trans': 'resolution'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '逐步', 'pinyin': 'zhú bù', 'trans': 'gradually'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'training'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '损失', 'pinyin': 'sǔn shī', 'trans': 'loss'}, {'word': '可忽略', 'pinyin': 'kě hū lüè', 'trans': 'negligible'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '加快', 'pinyin': 'jiā kuài', 'trans': 'accelerate'}, {'word': '速度', 'pinyin': 'sù dù', 'trans': 'speed'}, {'word': '即插即用', 'pinyin': 'jí chā jí yòng', 'trans': 'plug-and-play'}, {'word': '进一步', 'pinyin': 'jìn yī bù', 'trans': 'further'}]
[24.10.2024 02:44] Renaming previous Chinese page.
[24.10.2024 02:44] Renaming previous data. zh.html to ./d/2024-10-23_zh_reading_task.html
[24.10.2024 02:44] Writing result.
[24.10.2024 02:44] Writing Chinese reading task.
[24.10.2024 02:44] Renaming log file.
[24.10.2024 02:44] Renaming previous data. log.txt to ./logs/2024-10-24_last_log.txt
