[09.06.2025 06:19] Read previous papers.
[09.06.2025 06:19] Generating top page (month).
[09.06.2025 06:19] Writing top page (month).
[09.06.2025 07:13] Read previous papers.
[09.06.2025 07:13] Get feed.
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.01111
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05984
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05629
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.05523
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06276
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.06199
[09.06.2025 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2506.04255
[09.06.2025 07:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[09.06.2025 07:13] No deleted papers detected.
[09.06.2025 07:13] Downloading and parsing papers (pdf, html). Total: 7.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.01111.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.01111.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.01111.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.05984.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.05984.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.05984.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.05629.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.05629.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.05629.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.05523.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.05523.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.05523.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.06276.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.06276.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.06276.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.06199.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.06199.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.06199.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Downloading and parsing paper https://huggingface.co/papers/2506.04255.
[09.06.2025 07:13] Extra JSON file exists (./assets/json/2506.04255.json), skip PDF parsing.
[09.06.2025 07:13] Paper image links file exists (./assets/img_data/2506.04255.json), skip HTML parsing.
[09.06.2025 07:13] Success.
[09.06.2025 07:13] Enriching papers with extra data.
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 0. A novel two-stage pipeline using specialized pretrained models and a large language model enhances audio caption quality by integrating diverse multimodal cues and contextual information.  					AI-generated summary 				 High-quality, large-scale audio captioning is crucial for advancing audio unders...
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 1. Audio-aware large language models can assess speaking styles in audio inputs, demonstrating performance comparable to human judges in evaluating synthesized speech along dimensions like emotion, volume, and pitch.  					AI-generated summary 				 Audio-aware large language models (ALLMs) can understa...
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 2. A new method using input-dependent soft prompting with a self-attention mechanism improves parameter-efficient fine-tuning for large language models, enhancing zero-shot domain transfer.  					AI-generated summary 				 The performance of large language models in domain-specific tasks necessitates fi...
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 3. MORSE-500, a video benchmark with 500 scripted clips, evaluates multimodal reasoning across six categories, highlighting performance gaps in abstract and planning tasks.  					AI-generated summary 				 Despite rapid advances in vision-language models (VLMs), current benchmarks for multimodal reasoni...
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 4. STARFlow, a generative model combining normalizing flows with autoregressive Transformers, achieves competitive image synthesis performance with innovations in architecture and latent space modeling.  					AI-generated summary 				 We present STARFlow, a scalable generative model based on normalizin...
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 5. A 3D flow world model learned from human and robot manipulation data, using video diffusion and GPT-4o, enables robots to perform diverse manipulation tasks with strong generalization and cross-embodiment adaptation.  					AI-generated summary 				 Manipulation has long been a challenging task for r...
[09.06.2025 07:13] ********************************************************************************
[09.06.2025 07:13] Abstract 6. HASHIRU, a novel MAS framework, enhances flexibility, resource efficiency, and adaptability by dynamically managing specialized agents and using a hybrid intelligence approach with smaller, local LLMs and external APIs.  					AI-generated summary 				 Rapid Large Language Model (LLM) advancements ar...
[09.06.2025 07:13] Read previous papers.
[09.06.2025 07:13] Generating reviews via LLM API.
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#audio", "#multimodal", "#optimization", "#data", "#games"], "emoji": "üéß", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞—É–¥–∏–æ-–ø–æ–¥–ø–∏—Å—è—Ö: –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ò–ò –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∑–≤—É–∫–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ-–ø
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#multimodal", "#audio", "#interpretability", "#games"], "emoji": "üéôÔ∏è", "ru": {"title": "–ê–û–ë–õ–ú –∫–∞–∫ –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ —Å—É–¥—å–∏ —Å—Ç–∏–ª—è —Ä–µ—á–∏", "desc": "–ê—É–¥–∏–æ-–æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω—ã–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–ê–û–ë–õ–ú) —Å–ø–æ—Å–æ–±–Ω—ã –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —Å—Ç–∏–ª–∏ —Ä–µ—á–∏ –≤ –∞—É–¥–∏–æ–≤—Ö–æ–¥–∞—Ö, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Å—Ä–∞–≤–Ω–∏–º—É—é —Å –æ—Ü–µ
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#transfer_learning", "#small_models"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –¥–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏-—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –¥–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ü—Ä
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#survey", "#video", "#open_source", "#dataset", "#reasoning"], "emoji": "üé¨", "ru": {"title": "MORSE-500: –ù–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –æ—Ü–µ–Ω–∫–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ò–ò", "desc": "MORSE-500 - —ç—Ç–æ –Ω–æ–≤—ã–π –≤–∏–¥–µ–æ–±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#architecture", "#cv", "#diffusion"], "emoji": "üåä", "ru": {"title": "–ù–æ—Ä–º–∞–ª–∏–∑—É—é—â–∏–µ –ø–æ—Ç–æ–∫–∏ –ø–æ–∫–æ—Ä—è—é—Ç –≤—ã—Å–æ—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "STARFlow - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—â–∏–µ –ø–æ—Ç–æ–∫–∏ –∏ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#robotics", "#optimization", "#3d", "#games"], "emoji": "ü§ñ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å 3D-–ø–æ—Ç–æ–∫–∞ –¥–ª—è —Ä–æ–±–æ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å 3D-–ø–æ—Ç–æ–∫–∞ –¥–ª—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π —Ä–æ–±–æ—Ç–æ–≤, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –∏ —Ä–æ–±–æ—Ç–∏–∑
[09.06.2025 07:13] Using data from previous issue: {"categories": ["#architecture", "#agi", "#optimization", "#benchmark", "#agents", "#open_source"], "emoji": "ü§ñ", "ru": {"title": "–ì–∏–±–∫–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "HASHIRU - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–≤—ã—à–∞–µ—Ç –≥–∏–±–∫–æ—Å—Ç—å, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
[09.06.2025 07:13] Loading Chinese text from previous data.
[09.06.2025 07:13] Renaming data file.
[09.06.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-06-09.json
[09.06.2025 07:13] Saving new data file.
[09.06.2025 07:13] Generating page.
[09.06.2025 07:13] Renaming previous page.
[09.06.2025 07:13] Renaming previous data. index.html to ./d/2025-06-09.html
[09.06.2025 07:13] [Experimental] Generating Chinese page for reading.
[09.06.2025 07:13] Chinese vocab [{'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'}, {'word': 'Êèí‰ª∂', 'pinyin': 'chƒÅ ji√†n', 'trans': 'plugin'}, {'word': 'Êó®Âú®', 'pinyin': 'zh«ê z√†i', 'trans': 'aim to'}, {'word': 'ÊèêÈ´ò', 'pinyin': 't√≠ gƒÅo', 'trans': 'improve'}, {'word': 'ÊòìÁî®ÊÄß', 'pinyin': 'y√¨ y√≤ng x√¨ng', 'trans': 'usability'}, {'word': 'ÊïàÁéá', 'pinyin': 'xi√†o l«ú', 'trans': 'efficiency'}, {'word': 'ÁÅµÊ¥ª', 'pinyin': 'l√≠ng hu√≥', 'trans': 'flexible'}, {'word': 'Êñ∞Êâã', 'pinyin': 'xƒ´n sh«íu', 'trans': 'beginner'}, {'word': 'ÈöæÂ∫¶', 'pinyin': 'n√°n d√π', 'trans': 'difficulty'}, {'word': 'Êô∫ËÉΩ', 'pinyin': 'zh√¨ n√©ng', 'trans': 'intelligent'}, {'word': 'Êé®Ëçê', 'pinyin': 'tuƒ´ ji√†n', 'trans': 'recommend'}, {'word': 'Ëá™Âä®Âåñ', 'pinyin': 'z√¨ d√≤ng hu√†', 'trans': 'automation'}, {'word': 'Â∑•‰ΩúÊµÅ', 'pinyin': 'g≈çng zu√≤ li√∫', 'trans': 'workflow'}, {'word': 'ÊûÑÂª∫', 'pinyin': 'g√≤u ji√†n', 'trans': 'build'}, {'word': 'Ëß£ÂÜ≥', 'pinyin': 'jiƒõ ju√©', 'trans': 'solve'}, {'word': 'ÂáÜÁ°Æ', 'pinyin': 'zh«în qu√®', 'trans': 'accurate'}, {'word': 'ËäÇÁÇπ', 'pinyin': 'ji√© di«én', 'trans': 'node'}, {'word': 'Âä†ÈÄü', 'pinyin': 'jiƒÅ s√π', 'trans': 'accelerate'}, {'word': 'ÂºÄÂèë', 'pinyin': 'kƒÅi fƒÅ', 'trans': 'develop'}, {'word': 'ÂèçÈ¶à', 'pinyin': 'f«én ku√¨', 'trans': 'feedback'}]
[09.06.2025 07:13] Renaming previous Chinese page.
[09.06.2025 07:13] Renaming previous data. zh.html to ./d/2025-06-08_zh_reading_task.html
[09.06.2025 07:13] Writing Chinese reading task.
[09.06.2025 07:13] Writing result.
[09.06.2025 07:13] Renaming log file.
[09.06.2025 07:13] Renaming previous data. log.txt to ./logs/2025-06-09_last_log.txt
