[07.03.2025 09:12] Read previous papers.
[07.03.2025 09:12] Generating top page (month).
[07.03.2025 09:12] Writing top page (month).
[07.03.2025 10:11] Read previous papers.
[07.03.2025 10:11] Get feed.
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04625
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.03803
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04598
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.20258
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04094
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04222
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04130
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04725
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.03983
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04606
[07.03.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.02972
[07.03.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.01901
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.01375
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.02191
[07.03.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.04378
[07.03.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.04644
[07.03.2025 10:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[07.03.2025 10:11] No deleted papers detected.
[07.03.2025 10:11] Downloading and parsing papers (pdf, html). Total: 16.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04625.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04625.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04625.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.03803.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.03803.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.03803.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04598.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04598.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04598.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2502.20258.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2502.20258.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2502.20258.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04094.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04094.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04094.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04222.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04222.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04222.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04130.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04130.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04130.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04725.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04725.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04725.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.03983.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.03983.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.03983.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04606.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04606.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04606.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.02972.
[07.03.2025 10:11] Downloading paper 2503.02972 from http://arxiv.org/pdf/2503.02972v2...
[07.03.2025 10:11] Extracting affiliations from text.
[07.03.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation Jude Khouja * 1 Karolina Korgul * 1 Simi Hellsten * 2 3 Lingyi Yang 1 Vlad Neacs, 4 5 6 Harry Mayne 1 Ryan Kearns 1 Andrew Bean 1 Adam Mahdi 1 Abstract Assessing the reasoning capabilities of Large Language Models (LLMs) is susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates and apply this framework to develop LINGOLY-TOO, challenging benchmark for linguistic reasoning. By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerous question variations. These variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data. Our experiments demonstrate that frontier models, including Claud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning. Our analysis also shows that LLMs exhibit noticeable variance in accuracy across permutations of the same problem, and on average perform better on questions appearing in their original orthography. Our findings highlight the opaque nature of response generation in LLMs and provide evidence that prior data exposure contributes to overestimating the reasoning capabilities of frontier models. 1 5 2 0 2 ] . [ 2 2 7 9 2 0 . 3 0 5 2 : r 1. Introduction Recent advancements in Large Language Models (LLMs) have resulted in impressive performance on reasoning bench- *Equal contribution 1University of Oxford, Oxford, United Kingdom 2United Kingdom Linguistics Olympiad 3University of Glasgow, Glasgow, United Kingdom 4National University of Science and Technology POLITEHNICA Bucharest, Romania 5Hong Kong Linguistics Olympiad 6Asia-Pacific Linguistics Olympiad. Correspondence to: Jude Khouja <jude.k"
[07.03.2025 10:11] Response: ```python
[
    "University of Oxford, Oxford, United Kingdom",
    "United Kingdom Linguistics Olympiad",
    "University of Glasgow, Glasgow, United Kingdom",
    "National University of Science and Technology POLITEHNICA Bucharest, Romania",
    "Hong Kong Linguistics Olympiad",
    "Asia-Pacific Linguistics Olympiad"
]
```
[07.03.2025 10:11] Deleting PDF ./assets/pdf/2503.02972.pdf.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.01901.
[07.03.2025 10:11] Downloading paper 2503.01901 from http://arxiv.org/pdf/2503.01901v1...
[07.03.2025 10:11] Extracting affiliations from text.
[07.03.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Identifying Sensitive Weights via Post-quantization Integral Yuezhou Hu 1 Weiyu Huang 1 Zichen Liang 1 Chang Chen 1 Jintao Zhang 1 Jun Zhu 1 Jianfei Chen "
[07.03.2025 10:11] Response: []
[07.03.2025 10:11] Extracting affiliations from text.
[07.03.2025 10:11] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Identifying Sensitive Weights via Post-quantization Integral Yuezhou Hu 1 Weiyu Huang 1 Zichen Liang 1 Chang Chen 1 Jintao Zhang 1 Jun Zhu 1 Jianfei ChenServing Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on sensitivity metric, which indicates the element-wise influence of weights on loss function and is used to preprocess original weights for better quantization. In this work, we conduct an empirical study on the accuracy of the sensitivity metric, and find that existing gradient and Hessian based metrics are very inaccurate: they underestimate quantizations impact on the loss function by orders of magnitude, mainly due to the small convergence radius of local 2nd order approximation, i.e., gradient and Hessian term in Taylors formula. To tackle this problem, we propose Post-quantization Integral (PQI), an accurate metric to estimate posterior sensitivity in fine-grained manner. To leverage this accurate metric, we further propose ReQuant, simple yet powerful framework that mainly consists of two Dense-and-Sparse detach components: selfadaptive outlier selection and step-wise significant weights detach. Results show that ReQuant boosts state-of-the-art post-training quantization methods, with pronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP. 5 2 0 2 8 2 ] . [ 1 1 0 9 1 0 . 3 0 5 2 : r 1. Introduction The past decade has witnessed the thriving of Large Language Models, which have exhibited their great potential in various domains, such as reasoning (Wei et al., 2022), code generation (Hui et al., 2024) and instruction following (Ouyang et al., 2022). However, as LLMs are becoming *Equal contribution 1Dept. of Comp. Sci. & Tech., Institute for AI, BNRist Center, Tsinghua-Bosch Joint ML Center, THBI Lab, Tsinghua University. Correspondence to: Jianfei Chen <jianfeic@tsinghua.edu.cn>. 1 larger, efficiently serving or even simply launching them becomes challenge, especially for those edge devices with limited memory. One possible solution to this is weight quantization, which converts high-precision LLM into low-precision counterpart. As the main bottleneck of LLM decoding is loading weights from memory to chip, weight quantization also proportionally accelerate decoding. Many previous methods have demonstrated the possibility to compress LLM into lower precision. Specifically, posttraining quantization (PTQ) methods (Frantar et al., 2023; Lin et al., 2024b; Xiao et al., 2023; Chee et al., 2023; Kim et al., 2024; Lin et al., 2024a; Tseng et al., 2024b; Zhang et al., 2025; 2024) are popular since they do not require the expensive training procedure. Although most PTQ methods are feasible with models such as OPT (Zhang et al., 2022) and Llama 2 (Touvron et al., 2023), the effectiveness of these methods on state-of-the-art models in preserving accuracy remains an open question. Empirical study (Kumar et al., 2024) reveals that the quantization difficulty depends on the ratio of dataset size and model size. As recent LLMs, such as Phi-4 (Abdin et al., 2024), are typically trained with more than ten trillion tokens, it is even challenging to compress them to 4-bit without accuracy degradation. Existing low-bit quantization methods for LLMs exploit the unequal importance of weight dimensions, necessitating the use of sensitivity metric to quantify their impact. Extensive experiments have demonstrated that certain dimensions are more critical than others, where even slight modifications to these weights can cause significant distortions in the models output (Lin et al., 2024b). Therefore, an accurate sensitivity metric for weight dimensions is essential for the effectiveness of quantization algorithm. Consider quantizing model with weights RD using calibration set D. PTQ method typically consists of two stages. In the first stage, sensitivity metric is calculated on the calibration set, which is typically vector indicating the element-wise1 importance: = S(M, D) RD. In the second stage, the sensitivity vector is used to quantize w: = Q(w, v), where is the quantization process, and RD is the low-precision weight vector. For example, 1For channel-wise sensitivity metrics such as AWQ (Lin et al., 2024b), the definition of sensitivity can also be extended to be element-wise by simple broadcasting along the other dimension. Identifying Sensitive Weights via Post-quantization Integral the simplest technique is to store the most sensitive elements in full precision to preserve accuracy. For another, scale can be applied to salient weights to diminish the relative quantization error. In this work, we empirically evaluate the accuracy of sensitivity metrics in predicting the change in the loss function caused by weight quantization. Unfortunately, none of the existing sensitivity metrics is sufficiently accurate, in the sense that they cannot predict the change of loss function caused by weight quantization. We identify two key reasons why previous methods fail to accurately estimate sensitivity: 1) Small convergence radius: The complicated loss landscape of LLM makes the local gradient and Hessian based approximation only valid in very small region near w. Specifically, the quantized weight falls outside the convergence radius. 2) Misalignment of Sensitivity between and w: While previous methods only calculate the sensitivity based on w, sensitivity results might change: previously sensitive weights may lose importance after quantization, and other non-sensitive weights may emerge as sensitive. To overcome these difficulties, we introduce PQI, novel sensitivity metric to estimate the influence of each quantized weight. First, PQI only leverages the local continuity of the model, which can be easily achieved. Additionally, both and are considered to calculate v, making it more accurate. Our contributions are summarized as follows: We propose Post-quantization Integral (PQI), an accurate sensitivity metric designed to compute the element-wise importance of quantized model. We introduce ReQuant, pipeline that utilizes PQI to enhance the quality of quantized model by Dense-andSparse (Li et al., 2023b; Kim et al., 2024) decomposition. When applied to Llama 3.2 1B model, ReQuant can reduce the perplexity up to 2.6 and enhance MATH (Hendrycks et al."
[07.03.2025 10:11] Mistral response. {"id": "fbb41818a100437fbc1e6eb999ba8d64", "object": "chat.completion", "created": 1741342302, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Dept. of Comp. Sci. & Tech., Institute for AI, BNRist Center, Tsinghua-Bosch Joint ML Center, THBI Lab, Tsinghua University\"]\n```"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 1642, "total_tokens": 1692, "completion_tokens": 50}}
[07.03.2025 10:11] Response: ```python
["Dept. of Comp. Sci. & Tech., Institute for AI, BNRist Center, Tsinghua-Bosch Joint ML Center, THBI Lab, Tsinghua University"]
```
[07.03.2025 10:11] Deleting PDF ./assets/pdf/2503.01901.pdf.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.01375.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.01375.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.01375.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.02191.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.02191.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.02191.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04378.
[07.03.2025 10:11] Extra JSON file exists (./assets/json/2503.04378.json), skip PDF parsing.
[07.03.2025 10:11] Paper image links file exists (./assets/img_data/2503.04378.json), skip HTML parsing.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2503.04644.
[07.03.2025 10:11] Downloading paper 2503.04644 from http://arxiv.org/pdf/2503.04644v1...
[07.03.2025 10:11] Extracting affiliations from text.
[07.03.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"IFIR: Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval Tingyu Song Guo Gan Mingsheng Shang Yilun Zhao School of Advanced Interdisciplinary Sciences, University of Chinese Academy of Sciences Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences Zhejiang University Yale University https://github.com/SighingSnow/IFIR 5 2 0 M 6 ] . [ 1 4 4 6 4 0 . 3 0 5 2 : r a "
[07.03.2025 10:11] Response: ```python
[
    "School of Advanced Interdisciplinary Sciences, University of Chinese Academy of Sciences",
    "Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences",
    "Zhejiang University",
    "Yale University"
]
```
[07.03.2025 10:11] Deleting PDF ./assets/pdf/2503.04644.pdf.
[07.03.2025 10:11] Success.
[07.03.2025 10:11] Enriching papers with extra data.
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 0. Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have demonstrated remarkable capabilities in complex reasoning tasks through the utilization of long Chain-of-thought (CoT). However, these models often suffer from hallucinations and inefficiencies due to their reliance solely on internal...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 1. We introduce EgoLife, a project to develop an egocentric life assistant that accompanies and enhances personal efficiency through AI-powered wearable glasses. To lay the foundation for this assistant, we conducted a comprehensive data collection study where six participants lived together for one we...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 2. Transformers have become the de facto architecture for a wide range of machine learning tasks, particularly in large language models (LLMs). Despite their remarkable performance, challenges remain in training deep transformer networks, especially regarding the location of layer normalization. While ...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 3. As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs. Inspired by the "broken telephone" effect in chained human communication, this study investigates whether LLMs similarly distort information through i...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 4. We introduce Pok\'eChamp, a minimax agent powered by Large Language Models (LLMs) for Pok\'emon battles. Built on a general framework for two-player competitive games, Pok\'eChamp leverages the generalist capabilities of LLMs to enhance minimax tree search. Specifically, LLMs replace three key modul...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 5. We introduce FuseChat-3.0, a suite of large language models (LLMs) developed by integrating the strengths of heterogeneous source LLMs into more compact target LLMs. Our source models include the powerful Gemma-2-27B-it, Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct....
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 6. Recent advances in video-based multimodal large language models (Video-LLMs) have significantly improved video understanding by processing videos as sequences of image frames. However, many existing methods treat frames independently in the vision backbone, lacking explicit temporal modeling, which ...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 7. We rigorously establish a bipartite mutual information scaling law in natural language that governs long-range dependencies. This scaling law, which we show is distinct from and scales independently of the conventional two-point mutual information, is the key to understanding long-context language m...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 8. Understanding and reasoning over non-speech sounds and music are crucial for both humans and AI agents to interact effectively with their environments. In this paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM) with advanced audio understanding and reasoning capabilities. AF2 ...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 9. Recent advancements in text-to-video (T2V) generation have been driven by two competing paradigms: autoregressive language models and diffusion models. However, each paradigm has intrinsic limitations: language models struggle with visual quality and error accumulation, while diffusion models lack s...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 10. Effective evaluation of the reasoning capabilities of large language models (LLMs) are susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce a framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estima...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 11. Serving Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on a sensitiv...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 12. Solving Bayesian inverse problems efficiently remains a significant challenge due to the complexity of posterior distributions and the computational cost of traditional sampling methods. Given a series of observations and the forward model, we want to recover the distribution of the parameters, cond...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 13. Software projects thrive on the involvement and contributions of individuals from different backgrounds. However, toxic language and negative interactions can hinder the participation and retention of contributors and alienate newcomers. Proactive moderation strategies aim to prevent toxicity from o...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 14. Inference-Time Scaling has been critical to the success of recent models such as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for inference-time scaling require tasks to have answers that can be verified, limiting their application to domains such as math, coding and logi...
[07.03.2025 10:11] ********************************************************************************
[07.03.2025 10:11] Abstract 15. We introduce IFIR, the first comprehensive benchmark designed to evaluate instruction-following information retrieval (IR) in expert domains. IFIR includes 2,426 high-quality examples and covers eight subsets across four specialized domains: finance, law, healthcare, and science literature. Each sub...
[07.03.2025 10:11] Read previous papers.
[07.03.2025 10:11] Generating reviews via LLM API.
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#long_context", "#rl", "#training", "#architecture", "#hallucinations", "#reasoning"], "emoji": "🧠", "ru": {"title": "START: Самообучающаяся модель рассуждений с инструментами", "desc": "Статья представляет START - новую модель для рассуждений с длинной цепочкой мыслей, интегрирующу
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#video", "#long_context", "#dataset", "#open_source", "#agents", "#multimodal", "#data", "#benchmark"], "emoji": "👓", "ru": {"title": "EgoLife: ИИ-ассистент для повседневной жизни на базе умных очков", "desc": "Проект EgoLife представляет собой разработку эгоцентричного ассистента н
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#training", "#architecture", "#open_source"], "emoji": "🔀", "ru": {"title": "HybridNorm: Гибридная нормализация для улучшения обучения и производительности трансформеров", "desc": "Статья представляет новый метод нормализации для трансформеров под назв
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#hallucinations", "#data", "#long_context", "#alignment", "#multimodal", "#training"], "emoji": "📞", "ru": {"title": "Эффект 'испорченного телефона' в языковых моделях", "desc": "Исследование посвящено изучению эффекта искажения информации при многократной обработке собственных выхо
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#dataset", "#agents", "#games"], "emoji": "🎮", "ru": {"title": "PokeChamp: Революция в ИИ для игровых стратегий с использованием языковых моделей", "desc": "Статья представляет PokeChamp - агента на основе минимакса, использующего большие языковые модел
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#training", "#dataset", "#benchmark", "#small_models", "#rlhf", "#transfer_learning", "#open_source", "#optimization"], "emoji": "🔀", "ru": {"title": "Слияние мощи больших языковых моделей в компактном формате", "desc": "FuseChat-3.0 представляет собой набор больших языковых моделей
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#optimization", "#long_context", "#architecture", "#video", "#inference", "#multimodal"], "emoji": "🌪️", "ru": {"title": "STORM: Эффективное понимание длинных видео с помощью темпорального кодирования", "desc": "STORM - это новая архитектура для видео-LLM
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#training", "#architecture", "#math", "#long_context"], "emoji": "📏", "ru": {"title": "Масштабирование взаимной информации - ключ к моделированию длинного контекста", "desc": "Статья представляет собой исследование в области обработки естественного языка, фокусирующееся на закономер
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#audio", "#long_context", "#dataset", "#small_models", "#reasoning", "#synthetic", "#open_source", "#benchmark"], "emoji": "🎵", "ru": {"title": "AF2: Революция в понимании аудио искусственным интеллектом", "desc": "Audio Flamingo 2 (AF2) - это усовершенствованная аудио-языковая моде
[07.03.2025 10:11] Using data from previous issue: {"categories": ["#diffusion", "#open_source", "#benchmark", "#long_context", "#architecture", "#video"], "emoji": "🎬", "ru": {"title": "LanDiff: гибридный подход к генерации видео из текста", "desc": "Статья представляет LanDiff - гибридную архитектуру для генерации видео из текста, сочетающую преим
[07.03.2025 10:11] Querying the API.
[07.03.2025 10:11] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Effective evaluation of the reasoning capabilities of large language models (LLMs) are susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce a framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates and apply this framework to develop LINGOLY-TOO, a challenging evaluation benchmark for linguistic reasoning. By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerous question variations. These variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data. Our experiments demonstrate that frontier models, including OpenAI o1-preview and DeepSeem R1, struggle with advanced reasoning. Our analysis also shows that LLMs exhibit noticeable variance in accuracy across permutations of the same problem, and on average perform better on questions appearing in their original orthography. Our findings highlight the opaque nature of response generation in LLMs and provide evidence that prior data exposure contributes to overestimating the reasoning capabilities of frontier models.
[07.03.2025 10:11] Response: {
  "desc": "Статья представляет новый подход к оценке способностей больших языковых моделей (LLM) к рассуждению. Авторы разработали фреймворк LINGOLY-TOO, который генерирует лингвистические задачи с обфускацией систем письма реальных языков. Эксперименты показали, что современные модели, включая OpenAI и DeepSeem, испытывают трудности с продвинутыми рассуждениями. Исследование выявило, что предварительное знакомство с данными может приводить к переоценке возможностей LLM в области рассуждений.",
  "emoji": "🧠",
  "title": "Новый метод оценки рассуждений LLM без влияния предварительных знаний"
}
[07.03.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Effective evaluation of the reasoning capabilities of large language models (LLMs) are susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce a framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates and apply this framework to develop LINGOLY-TOO, a challenging evaluation benchmark for linguistic reasoning. By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerous question variations. These variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data. Our experiments demonstrate that frontier models, including OpenAI o1-preview and DeepSeem R1, struggle with advanced reasoning. Our analysis also shows that LLMs exhibit noticeable variance in accuracy across permutations of the same problem, and on average perform better on questions appearing in their original orthography. Our findings highlight the opaque nature of response generation in LLMs and provide evidence that prior data exposure contributes to overestimating the reasoning capabilities of frontier models."

[07.03.2025 10:11] Response: ```python
["BENCHMARK", "DATASET"]
```
[07.03.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Effective evaluation of the reasoning capabilities of large language models (LLMs) are susceptible to overestimation due to data exposure of evaluation benchmarks. We introduce a framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates and apply this framework to develop LINGOLY-TOO, a challenging evaluation benchmark for linguistic reasoning. By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerous question variations. These variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data. Our experiments demonstrate that frontier models, including OpenAI o1-preview and DeepSeem R1, struggle with advanced reasoning. Our analysis also shows that LLMs exhibit noticeable variance in accuracy across permutations of the same problem, and on average perform better on questions appearing in their original orthography. Our findings highlight the opaque nature of response generation in LLMs and provide evidence that prior data exposure contributes to overestimating the reasoning capabilities of frontier models."

[07.03.2025 10:11] Response: ```python
['REASONING', 'HALLUCINATIONS']
```
[07.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the challenge of accurately evaluating the reasoning abilities of large language models (LLMs) by introducing a new framework that minimizes the impact of memorization on performance assessments. The authors present LINGOLY-TOO, a benchmark designed to test linguistic reasoning through dynamically generated questions that obfuscate the original writing systems of languages. By using orthographic templates, they create multiple variations of questions that maintain the necessary reasoning steps while reducing the chance of models having seen specific instances during training. The results indicate that leading models struggle with complex reasoning tasks and show significant performance differences based on the question format, revealing the influence of prior data exposure on their evaluation.","title":"Unmasking Reasoning: Evaluating LLMs Beyond Memorization"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the challenge of accurately evaluating the reasoning abilities of large language models (LLMs) by introducing a new framework that minimizes the impact of memorization on performance assessments. The authors present LINGOLY-TOO, a benchmark designed to test linguistic reasoning through dynamically generated questions that obfuscate the original writing systems of languages. By using orthographic templates, they create multiple variations of questions that maintain the necessary reasoning steps while reducing the chance of models having seen specific instances during training. The results indicate that leading models struggle with complex reasoning tasks and show significant performance differences based on the question format, revealing the influence of prior data exposure on their evaluation.', title='Unmasking Reasoning: Evaluating LLMs Beyond Memorization'))
[07.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种评估大型语言模型（LLMs）推理能力的新框架，旨在减少由于数据暴露导致的评估过高的问题。我们开发了LINGOLY-TOO，这是一个具有挑战性的语言推理评估基准，通过使用正字法模板动态模糊真实语言的书写系统，生成多种问题变体。实验结果表明，前沿模型在高级推理任务中表现不佳，并且在相同问题的不同排列中，LLMs的准确性存在显著差异。我们的研究揭示了LLMs响应生成的复杂性，并提供了证据表明，先前的数据暴露会导致对前沿模型推理能力的高估。","title":"揭示大型语言模型推理能力的真实面貌"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种评估大型语言模型（LLMs）推理能力的新框架，旨在减少由于数据暴露导致的评估过高的问题。我们开发了LINGOLY-TOO，这是一个具有挑战性的语言推理评估基准，通过使用正字法模板动态模糊真实语言的书写系统，生成多种问题变体。实验结果表明，前沿模型在高级推理任务中表现不佳，并且在相同问题的不同排列中，LLMs的准确性存在显著差异。我们的研究揭示了LLMs响应生成的复杂性，并提供了证据表明，先前的数据暴露会导致对前沿模型推理能力的高估。', title='揭示大型语言模型推理能力的真实面貌'))
[07.03.2025 10:12] Querying the API.
[07.03.2025 10:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Serving Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on a sensitivity metric, which indicates the element-wise influence of weights on loss function and is used to preprocess original weights for better quantization. In this work, we conduct an empirical study on the accuracy of the sensitivity metric, and find that existing gradient and Hessian based metrics are very inaccurate: they underestimate quantization's impact on the loss function by orders of magnitude, mainly due to the small convergence radius of local 2nd order approximation, \ie, gradient and Hessian term in Taylor's formula. To tackle this problem, we propose Post-quantization Integral (PQI), an accurate metric to estimate posterior sensitivity in a fine-grained manner. To leverage this accurate metric, we further propose ReQuant, a simple yet powerful framework that mainly consists of two Dense-and-Sparse detach components: self-adaptive outlier selection and step-wise significant weights detach. Results show that ReQuant boosts state-of-the-art post-training quantization methods, with a pronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP.
[07.03.2025 10:12] Response: {
  "desc": "Эта статья представляет новый метод квантизации весов для крупных языковых моделей (LLM), называемый ReQuant. Авторы обнаружили, что существующие метрики чувствительности весов неточны и предложили более точную метрику - Post-quantization Integral (PQI). ReQuant использует PQI вместе с адаптивным выбором выбросов и пошаговым отделением значимых весов. Результаты показывают, что ReQuant улучшает современные методы пост-тренировочной квантизации, значительно повышая производительность модели Llama 3.2 1B.",
  "emoji": "⚖️",
  "title": "Точная квантизация для эффективных языковых моделей"
}
[07.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Serving Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on a sensitivity metric, which indicates the element-wise influence of weights on loss function and is used to preprocess original weights for better quantization. In this work, we conduct an empirical study on the accuracy of the sensitivity metric, and find that existing gradient and Hessian based metrics are very inaccurate: they underestimate quantization's impact on the loss function by orders of magnitude, mainly due to the small convergence radius of local 2nd order approximation, \ie, gradient and Hessian term in Taylor's formula. To tackle this problem, we propose Post-quantization Integral (PQI), an accurate metric to estimate posterior sensitivity in a fine-grained manner. To leverage this accurate metric, we further propose ReQuant, a simple yet powerful framework that mainly consists of two Dense-and-Sparse detach components: self-adaptive outlier selection and step-wise significant weights detach. Results show that ReQuant boosts state-of-the-art post-training quantization methods, with a pronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP."

[07.03.2025 10:12] Response: ```python
["INFERENCE", "TRAINING"]
```
[07.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Serving Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on a sensitivity metric, which indicates the element-wise influence of weights on loss function and is used to preprocess original weights for better quantization. In this work, we conduct an empirical study on the accuracy of the sensitivity metric, and find that existing gradient and Hessian based metrics are very inaccurate: they underestimate quantization's impact on the loss function by orders of magnitude, mainly due to the small convergence radius of local 2nd order approximation, \ie, gradient and Hessian term in Taylor's formula. To tackle this problem, we propose Post-quantization Integral (PQI), an accurate metric to estimate posterior sensitivity in a fine-grained manner. To leverage this accurate metric, we further propose ReQuant, a simple yet powerful framework that mainly consists of two Dense-and-Sparse detach components: self-adaptive outlier selection and step-wise significant weights detach. Results show that ReQuant boosts state-of-the-art post-training quantization methods, with a pronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP."

[07.03.2025 10:12] Response: ```python
["OPTIMIZATION"]
```
[07.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the high costs associated with serving large language models (LLMs) by introducing post-training weight quantization techniques. It highlights the inadequacy of existing sensitivity metrics, which fail to accurately predict the impact of quantization on model performance. The authors propose a new metric called Post-quantization Integral (PQI) that provides a more precise estimation of weight sensitivity. Additionally, they introduce ReQuant, a framework that enhances quantization methods by effectively selecting significant weights and improving overall model accuracy.","title":"Enhancing LLM Efficiency with Accurate Quantization Metrics"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper addresses the high costs associated with serving large language models (LLMs) by introducing post-training weight quantization techniques. It highlights the inadequacy of existing sensitivity metrics, which fail to accurately predict the impact of quantization on model performance. The authors propose a new metric called Post-quantization Integral (PQI) that provides a more precise estimation of weight sensitivity. Additionally, they introduce ReQuant, a framework that enhances quantization methods by effectively selecting significant weights and improving overall model accuracy.', title='Enhancing LLM Efficiency with Accurate Quantization Metrics'))
[07.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文讨论了大型语言模型（LLMs）在服务时的高成本问题。通过后训练权重量化，可以压缩模型大小，节省内存和带宽。研究发现，现有的基于梯度和海森矩阵的敏感度度量不够准确，低估了量化对损失函数的影响。为了解决这个问题，提出了后量化积分（PQI）作为一种更精确的敏感度度量，并进一步提出了ReQuant框架，以提高后训练量化方法的效果。","title":"提升量化精度，降低模型成本"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文讨论了大型语言模型（LLMs）在服务时的高成本问题。通过后训练权重量化，可以压缩模型大小，节省内存和带宽。研究发现，现有的基于梯度和海森矩阵的敏感度度量不够准确，低估了量化对损失函数的影响。为了解决这个问题，提出了后量化积分（PQI）作为一种更精确的敏感度度量，并进一步提出了ReQuant框架，以提高后训练量化方法的效果。', title='提升量化精度，降低模型成本'))
[07.03.2025 10:12] Using data from previous issue: {"categories": ["#architecture", "#math"], "emoji": "🔄", "ru": {"title": "Эффективная выборка из сложных апостериорных распределений с помощью CFM и трансформеров", "desc": "Статья представляет новый подход к решению байесовских обратных задач. Авторы предлагают комбинацию метода Conditional Flow Ma
[07.03.2025 10:12] Using data from previous issue: {"categories": ["#ethics", "#dataset", "#multimodal", "#data"], "emoji": "🛡️", "ru": {"title": "ИИ на страже здоровой атмосферы в open-source сообществах", "desc": "Исследование посвящено анализу и предотвращению токсичных взаимодействий в проектах на GitHub. Авторы создали датасет из 202 токсичных 
[07.03.2025 10:12] Using data from previous issue: {"categories": ["#training", "#benchmark", "#inference", "#reasoning", "#rlhf", "#optimization"], "emoji": "🔄", "ru": {"title": "Масштабирование при выводе для открытых задач: от черновика к улучшенному ответу", "desc": "Статья описывает новый метод масштабирования во время вывода для открытых задач
[07.03.2025 10:12] Querying the API.
[07.03.2025 10:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

We introduce IFIR, the first comprehensive benchmark designed to evaluate instruction-following information retrieval (IR) in expert domains. IFIR includes 2,426 high-quality examples and covers eight subsets across four specialized domains: finance, law, healthcare, and science literature. Each subset addresses one or more domain-specific retrieval tasks, replicating real-world scenarios where customized instructions are critical. IFIR enables a detailed analysis of instruction-following retrieval capabilities by incorporating instructions at different levels of complexity. We also propose a novel LLM-based evaluation method to provide a more precise and reliable assessment of model performance in following instructions. Through extensive experiments on 15 frontier retrieval models, including those based on LLMs, our results reveal that current models face significant challenges in effectively following complex, domain-specific instructions. We further provide in-depth analyses to highlight these limitations, offering valuable insights to guide future advancements in retriever development.
[07.03.2025 10:12] Response: {
  "desc": "IFIR - это новый комплексный бенчмарк для оценки информационного поиска с выполнением инструкций в экспертных областях. Он включает 2426 примеров высокого качества в 8 подмножествах из 4 специализированных доменов: финансы, право, здравоохранение и научная литература. IFIR позволяет проводить детальный анализ возможностей поиска с выполнением инструкций разной сложности. Эксперименты на 15 передовых моделях поиска показали значительные трудности в эффективном выполнении сложных доменно-специфичных инструкций.",
  "emoji": "🔍",
  "title": "IFIR: Новый стандарт оценки интеллектуального поиска информации"
}
[07.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce IFIR, the first comprehensive benchmark designed to evaluate instruction-following information retrieval (IR) in expert domains. IFIR includes 2,426 high-quality examples and covers eight subsets across four specialized domains: finance, law, healthcare, and science literature. Each subset addresses one or more domain-specific retrieval tasks, replicating real-world scenarios where customized instructions are critical. IFIR enables a detailed analysis of instruction-following retrieval capabilities by incorporating instructions at different levels of complexity. We also propose a novel LLM-based evaluation method to provide a more precise and reliable assessment of model performance in following instructions. Through extensive experiments on 15 frontier retrieval models, including those based on LLMs, our results reveal that current models face significant challenges in effectively following complex, domain-specific instructions. We further provide in-depth analyses to highlight these limitations, offering valuable insights to guide future advancements in retriever development."

[07.03.2025 10:12] Response: ```python
['BENCHMARK', 'DATASET', 'HEALTHCARE']
```
[07.03.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"We introduce IFIR, the first comprehensive benchmark designed to evaluate instruction-following information retrieval (IR) in expert domains. IFIR includes 2,426 high-quality examples and covers eight subsets across four specialized domains: finance, law, healthcare, and science literature. Each subset addresses one or more domain-specific retrieval tasks, replicating real-world scenarios where customized instructions are critical. IFIR enables a detailed analysis of instruction-following retrieval capabilities by incorporating instructions at different levels of complexity. We also propose a novel LLM-based evaluation method to provide a more precise and reliable assessment of model performance in following instructions. Through extensive experiments on 15 frontier retrieval models, including those based on LLMs, our results reveal that current models face significant challenges in effectively following complex, domain-specific instructions. We further provide in-depth analyses to highlight these limitations, offering valuable insights to guide future advancements in retriever development."

[07.03.2025 10:12] Response: ```python
["SCIENCE"]
```
[07.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper presents IFIR, a new benchmark for assessing how well information retrieval systems can follow instructions in specialized fields like finance, law, healthcare, and science. It consists of 2,426 examples that simulate real-world retrieval tasks requiring tailored instructions. The benchmark allows for a nuanced evaluation of retrieval models, particularly focusing on their ability to handle varying complexities of instructions. The authors also introduce a new evaluation method using large language models (LLMs) to measure performance, revealing that existing models struggle with complex, domain-specific tasks and providing insights for future improvements.","title":"IFIR: Benchmarking Instruction-Following in Expert Domains"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper presents IFIR, a new benchmark for assessing how well information retrieval systems can follow instructions in specialized fields like finance, law, healthcare, and science. It consists of 2,426 examples that simulate real-world retrieval tasks requiring tailored instructions. The benchmark allows for a nuanced evaluation of retrieval models, particularly focusing on their ability to handle varying complexities of instructions. The authors also introduce a new evaluation method using large language models (LLMs) to measure performance, revealing that existing models struggle with complex, domain-specific tasks and providing insights for future improvements.', title='IFIR: Benchmarking Instruction-Following in Expert Domains'))
[07.03.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"我们介绍了IFIR，这是第一个全面的基准，用于评估专家领域中的指令跟随信息检索（IR）。IFIR包含2426个高质量示例，涵盖金融、法律、医疗和科学文献等四个专业领域的八个子集。每个子集针对一个或多个特定领域的检索任务，模拟了需要定制指令的真实场景。通过对15个前沿检索模型的广泛实验，我们的结果显示，当前模型在有效跟随复杂的领域特定指令方面面临重大挑战。","title":"IFIR：专家领域指令跟随检索的首个基准"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='我们介绍了IFIR，这是第一个全面的基准，用于评估专家领域中的指令跟随信息检索（IR）。IFIR包含2426个高质量示例，涵盖金融、法律、医疗和科学文献等四个专业领域的八个子集。每个子集针对一个或多个特定领域的检索任务，模拟了需要定制指令的真实场景。通过对15个前沿检索模型的广泛实验，我们的结果显示，当前模型在有效跟随复杂的领域特定指令方面面临重大挑战。', title='IFIR：专家领域指令跟随检索的首个基准'))
[07.03.2025 10:12] Loading Chinese text from previous data.
[07.03.2025 10:12] Renaming data file.
[07.03.2025 10:12] Renaming previous data. hf_papers.json to ./d/2025-03-07.json
[07.03.2025 10:12] Saving new data file.
[07.03.2025 10:12] Generating page.
[07.03.2025 10:12] Renaming previous page.
[07.03.2025 10:12] Renaming previous data. index.html to ./d/2025-03-07.html
[07.03.2025 10:12] [Experimental] Generating Chinese page for reading.
[07.03.2025 10:12] Chinese vocab [{'word': '大型', 'pinyin': 'dàxíng', 'trans': 'large-scale'}, {'word': '语言模型', 'pinyin': 'yǔyán móxíng', 'trans': 'language model'}, {'word': '结合', 'pinyin': 'jiéhé', 'trans': 'combine'}, {'word': '外部', 'pinyin': 'wàibù', 'trans': 'external'}, {'word': '工具', 'pinyin': 'gōngjù', 'trans': 'tool'}, {'word': '提升', 'pinyin': 'tíshēng', 'trans': 'enhance'}, {'word': '复杂', 'pinyin': 'fùzá', 'trans': 'complex'}, {'word': '推理', 'pinyin': 'tuīlǐ', 'trans': 'reasoning'}, {'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'}, {'word': '能力', 'pinyin': 'nénglì', 'trans': 'ability'}, {'word': '传统', 'pinyin': 'chuántǒng', 'trans': 'traditional'}, {'word': '依赖', 'pinyin': 'yīlài', 'trans': 'rely'}, {'word': '内部', 'pinyin': 'nèibù', 'trans': 'internal'}, {'word': '产生', 'pinyin': 'chǎnshēng', 'trans': 'generate'}, {'word': '幻觉', 'pinyin': 'huànjué', 'trans': 'hallucination'}, {'word': '低效', 'pinyin': 'dīxiào', 'trans': 'inefficient'}, {'word': '执行', 'pinyin': 'zhíxíng', 'trans': 'execute'}, {'word': '计算', 'pinyin': 'jìsuàn', 'trans': 'calculation'}, {'word': '自我检查', 'pinyin': 'zìwǒ jiǎnchá', 'trans': 'self-check'}, {'word': '探索', 'pinyin': 'tànsuǒ', 'trans': 'explore'}, {'word': '方法', 'pinyin': 'fāngfǎ', 'trans': 'method'}, {'word': '自我调试', 'pinyin': 'zìwǒ tiáoshì', 'trans': 'self-debug'}, {'word': '解决', 'pinyin': 'jiějué', 'trans': 'solve'}, {'word': '核心', 'pinyin': 'héxīn', 'trans': 'core'}, {'word': '创新', 'pinyin': 'chuàngxīn', 'trans': 'innovation'}, {'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'}, {'word': '技术', 'pinyin': 'jìshù', 'trans': 'technology'}, {'word': '高难度', 'pinyin': 'gāo nándù', 'trans': 'high difficulty'}, {'word': '科学问答', 'pinyin': 'kēxué wèndá', 'trans': 'scientific Q&A'}, {'word': '数学竞赛', 'pinyin': 'shùxué jìngsài', 'trans': 'math competition'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '优异', 'pinyin': 'yōuyì', 'trans': 'excellent'}, {'word': '显著', 'pinyin': 'xiǎnzhù', 'trans': 'significant'}, {'word': '超越', 'pinyin': 'chāoyuè', 'trans': 'surpass'}, {'word': '基础模型', 'pinyin': 'jīchǔ móxíng', 'trans': 'base model'}]
[07.03.2025 10:12] Renaming previous Chinese page.
[07.03.2025 10:12] Renaming previous data. zh.html to ./d/2025-03-06_zh_reading_task.html
[07.03.2025 10:12] Writing Chinese reading task.
[07.03.2025 10:12] Writing result.
[07.03.2025 10:12] Renaming log file.
[07.03.2025 10:12] Renaming previous data. log.txt to ./logs/2025-03-07_last_log.txt
