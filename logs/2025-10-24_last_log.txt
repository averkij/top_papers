[24.10.2025 07:13] Read previous papers.
[24.10.2025 07:13] Generating top page (month).
[24.10.2025 07:13] Writing top page (month).
[24.10.2025 08:16] Read previous papers.
[24.10.2025 08:16] Get feed.
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19779
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20579
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19600
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20822
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19304
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20187
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19365
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20766
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20470
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18821
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20820
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20803
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19944
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20771
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20668
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20270
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20733
[24.10.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15804
[24.10.2025 08:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.10.2025 08:16] No deleted papers detected.
[24.10.2025 08:16] Downloading and parsing papers (pdf, html). Total: 18.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.19779.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.19779.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.19779.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20579.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20579.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20579.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.19600.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.19600.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.19600.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20822.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20822.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20822.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.19304.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.19304.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.19304.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20187.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20187.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20187.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.19365.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.19365.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.19365.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20766.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20766.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20766.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20470.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20470.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20470.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.18821.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.18821.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.18821.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20820.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20820.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20820.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20803.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20803.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20803.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.19944.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.19944.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.19944.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20771.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20771.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20771.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20668.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20668.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20668.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20270.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20270.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20270.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.20733.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.20733.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.20733.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2510.15804.
[24.10.2025 08:16] Extra JSON file exists (./assets/json/2510.15804.json), skip PDF parsing.
[24.10.2025 08:16] Paper image links file exists (./assets/img_data/2510.15804.json), skip HTML parsing.
[24.10.2025 08:16] Success.
[24.10.2025 08:16] Enriching papers with extra data.
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 0. AdaSPEC enhances speculative decoding by selectively filtering tokens during knowledge distillation, improving token acceptance rates without sacrificing generation quality.  					AI-generated summary 				 Speculative Decoding (SD) accelerates large language model inference by employing a small draf...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 1. Open-o3 Video integrates spatio-temporal evidence into video reasoning, achieving state-of-the-art performance on multiple benchmarks and providing valuable reasoning traces for test-time scaling.  					AI-generated summary 				 Most video reasoning models only generate textual reasoning traces with...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 2. AutoPage, a multi-agent system, automates the creation of interactive research webpages through a hierarchical process, ensuring high-quality and efficient results.  					AI-generated summary 				 In the quest for scientific progress, communicating research is as vital as the discovery itself. Yet, ...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 3. HoloCine generates coherent multi-shot narratives using a Window Cross-Attention mechanism and Sparse Inter-Shot Self-Attention, enabling end-to-end cinematic creation.  					AI-generated summary 				 State-of-the-art text-to-video models excel at generating isolated clips but fall short of creating...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 4. Loopholing Discrete Diffusion Models (LDDMs) enhance text generation by preserving distributional information through a deterministic latent pathway, reducing perplexity and improving coherence and performance on reasoning tasks.  					AI-generated summary 				 Discrete diffusion models offer a prom...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 5. RLEV, a reinforcement learning method, aligns LLM optimization with human value signals, improving value-weighted accuracy and learning value-sensitive termination policies.  					AI-generated summary 				 We propose Reinforcement Learning with Explicit Human Values (RLEV), a method that aligns Larg...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 6. MLEB is the largest open-source benchmark for legal information retrieval, encompassing multiple jurisdictions, document types, and task types.  					AI-generated summary 				 We present the Massive Legal Embedding Benchmark (MLEB), the largest, most diverse, and most comprehensive open-source bench...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 7. Dynamic Position Extrapolation (DyPE) enhances ultra-high-resolution image generation by dynamically adjusting positional encodings in pre-trained diffusion transformers, achieving state-of-the-art fidelity without additional sampling cost.  					AI-generated summary 				 Diffusion Transformer model...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 8. Conan, a framework for evidence-grounded multi-step video reasoning, enhances visual grounding and reasoning accuracy through a multi-stage training strategy and outperforms existing models on various benchmarks.  					AI-generated summary 				 Video reasoning, which requires multi-step deduction ac...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 9. Self-play training for deep search agents improves performance through co-evolution of task generation and problem solving without supervision.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has become the mainstream technique for training LLM agents. However, ...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 10. LayerComposer provides interactive control over spatial composition and scalability in multi-subject text-to-image generation through a layered canvas and locking mechanism.  					AI-generated summary 				 Despite their impressive visual fidelity, existing personalized generative models lack interac...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 11. A novel AutoRegressive Generation-based paradigm for image segmentation leverages multimodal large language models and VQ-VAE for dense mask generation, achieving high performance and fast inference.  					AI-generated summary 				 We propose a novel AutoRegressive Generation-based paradigm for imag...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 12. Seed3D 1.0 generates scalable, physics-accurate 3D assets from images for use in simulation environments, enhancing both content diversity and real-time physics feedback.  					AI-generated summary 				 Developing embodied AI agents requires scalable training environments that balance content divers...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 13. The $\alpha$-Flow framework improves few-step generative modeling by unifying and disentangling conflicting objectives, leading to better convergence and state-of-the-art performance on ImageNet-1K.  					AI-generated summary 				 MeanFlow has recently emerged as a powerful framework for few-step ge...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 14. The guide outlines a progression from early masked models to memory-augmented systems, emphasizing generative capabilities, interactive loops, and memory for building world models.  					AI-generated summary 				 This is not a typical survey of world models; it is a guide for those who want to build...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 15. ImpossibleBench is a benchmark framework that measures and mitigates LLMs' tendency to exploit test cases by introducing impossible task variants, thereby enhancing model reliability.  					AI-generated summary 				 The tendency to find and exploit "shortcuts" to complete tasks poses significant ris...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 16. Thought communication enables direct mind-to-mind interaction between agents, uncovering latent thoughts and improving collaborative intelligence beyond natural language.  					AI-generated summary 				 Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect natur...
[24.10.2025 08:16] ********************************************************************************
[24.10.2025 08:16] Abstract 17. A one-layer transformer model demonstrates how linear subspaces separating true from false statements can emerge in language models through memorization and subsequent linear separation.  					AI-generated summary 				 Recent probing studies reveal that large language models exhibit linear subspaces...
[24.10.2025 08:16] Read previous papers.
[24.10.2025 08:16] Generating reviews via LLM API.
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#alignment", "#inference", "#training"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞", "desc": "Speculative Decoding —É—Å–∫–æ—Ä—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö, –∏—Å–ø–æ–ª—å–∑—É—è –º–∞–ª–µ–Ω—å–∫—É—é draft-–º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#video", "#training", "#benchmark", "#reasoning", "#games"], "emoji": "üé¨", "ru": {"title": "–í–∏–¥–µ–æ-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è —Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º–∏", "desc": "Open-o3 Video ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –æ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#hallucinations", "#open_source", "#science", "#agents"], "emoji": "üåê", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã", "desc": "AutoPage ‚Äî —ç—Ç–æ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç —Å
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#architecture", "#story_generation", "#video", "#cv"], "emoji": "üé¨", "ru": {"title": "–û—Ç –∫–ª–∏–ø–æ–≤ –∫ –∫–∏–Ω–æ: —Ü–µ–ª–æ—Å—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ-–Ω–∞—Ä—Ä–∞—Ç–∏–≤–æ–≤", "desc": "HoloCine ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤—è–∑–Ω—ã—Ö –≤–∏–¥–µ–æ-–Ω–∞—Ä—Ä–∞—Ç–∏–≤–æ–≤, —Å–æ—Å—Ç–æ—è—â–∏—Ö –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∫–∞–¥—Ä–æ–≤, —á—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö text-t
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#data", "#multimodal", "#training", "#reasoning", "#diffusion"], "emoji": "üîÑ", "ru": {"title": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö —á–µ—Ä–µ–∑ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Loopholing Discrete Diffusion Models (LDDMs) ‚Äî —É–ª—É—á—à–µ–Ω–Ω—ã–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#rl", "#alignment", "#rlhf"], "emoji": "üéØ", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ AI —Å —É—á—ë—Ç–æ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –º–µ—Ç–æ–¥ RLEV, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —É—á—ë—Ç–æ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π –∏ –ø—Ä
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#data"], "emoji": "‚öñÔ∏è", "ru": {"title": "–≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤–æ –≤—Å–µ—Ö –ø—Ä–∞–≤–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω MLEB ‚Äî –∫—Ä—É–ø–Ω–µ–π—à–∏–π –æ—Ç–∫—Ä—ã—Ç—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä–µ. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –¥–µ—Å—è—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#cv", "#benchmark", "#architecture"], "emoji": "üî≠", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–µ—Ä—Ö–≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —á–µ—Ä–µ–∑ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é —ç–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—é –ø–æ–∑–∏—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Dynamic Position Extrapolation (DyPE) - –º–µ—Ç–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–≤–µ—Ä
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#reasoning", "#long_context", "#dataset", "#rl", "#video"], "emoji": "üîç", "ru": {"title": "Conan: –ü–æ—à–∞–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Conan ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –Ω–∞–¥ –≤–∏–¥–µ–æ —Å –æ–ø–æ—Ä–æ–π 
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agents", "#rag", "#games", "#rl"], "emoji": "üîÑ", "ru": {"title": "Self-play –¥–ª—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤: —É—á–∏–º—Å—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–µ—Ç–æ–¥ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ self-play, –≥–¥–µ LLM –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#games", "#cv"], "emoji": "üé®", "ru": {"title": "–ü–æ—Å–ª–æ–π–Ω–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏—è: –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "LayerComposer ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏, –∫–æ—Ç–æ
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#inference", "#games", "#cv"], "emoji": "üé≠", "ru": {"title": "–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –º–∞—Å–æ–∫", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ARGenSeg, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –±–æ–ª—å—à–∏
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#agents", "#games", "#3d", "#robotics", "#synthetic"], "emoji": "üé≤", "ru": {"title": "–û—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∫ —Å–∏–º—É–ª—è—Ü–∏–∏: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–∑–∏—á–µ—Å–∫–∏ —Ç–æ—á–Ω—ã—Ö 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è AI-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "Seed3D 1.0 ‚Äî —ç—Ç–æ foundation –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç—ã –∏–∑ –æ–¥–Ω–æ–≥–æ 
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#data", "#optimization", "#training", "#cv", "#diffusion"], "emoji": "üåä", "ru": {"title": "Œ±-Flow: —Ä–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π –≤ –±—ã—Å—Ç—Ä–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Œ±-Flow ‚Äî —É–ª—É—á—à–µ–Ω–Ω—ã–π framework –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —Ç—Ä–µ–±—É–µ—Ç –≤—Å–µ–≥–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ 
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#architecture", "#multimodal", "#games", "#diffusion"], "emoji": "üåç", "ru": {"title": "–ü—É—Ç–µ–≤–æ–¥–∏—Ç–µ–ª—å –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤—É –º–∏—Ä–æ–≤: –æ—Ç –º–∞—Å–æ–∫ –∫ –ø–∞–º—è—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—é world models, –∞ –Ω–µ –æ–±—ã—á–Ω—ã–π –æ–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ—Å–ª–µ–∂–∏–≤–∞—é—Ç 
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#security"], "emoji": "üö´", "ru": {"title": "–õ–æ–≤—É—à–∫–∞ –¥–ª—è —á–∏—Ç–µ—Ä–æ–≤: –∫–∞–∫ –ø–æ–π–º–∞—Ç—å LLM –Ω–∞ –Ω–µ—á–µ—Å—Ç–Ω–æ–º —Ä–µ—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á", "desc": "ImpossibleBench ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è LLM, –∫–æ—Ç–æ—Ä—ã–π –∏–∑–º–µ—Ä—è–µ—Ç —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –Ω–µ—á–µ—Å—Ç–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ —Ä–µ—à–µ
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#benchmark", "#reasoning", "#interpretability", "#synthetic"], "emoji": "üß†", "ru": {"title": "–¢–µ–ª–µ–ø–∞—Ç–∏—è –¥–ª—è –ò–ò: –æ–±—â–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ —Å–∫—Ä—ã—Ç—ã–µ –º—ã—Å–ª–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –º–µ–∂–¥—É AI-–∞–≥–µ–Ω—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–º –æ–±–º
[24.10.2025 08:16] Using data from previous issue: {"categories": ["#architecture", "#training", "#reasoning", "#interpretability"], "emoji": "üéØ", "ru": {"title": "–ö–∞–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã —É—á–∞—Ç—Å—è –æ—Ç–ª–∏—á–∞—Ç—å –ø—Ä–∞–≤–¥—É –æ—Ç –ª–∂–∏ —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Å–æ–∑–¥–∞–ª–∏ –ø—Ä–æ—Å—Ç—É—é –æ–¥–Ω–æ—Å–ª–æ–π–Ω—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä-–º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, –∫–∞–∫ –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥
[24.10.2025 08:16] Renaming data file.
[24.10.2025 08:16] Renaming previous data. hf_papers.json to ./d/2025-10-24.json
[24.10.2025 08:16] Saving new data file.
[24.10.2025 08:16] Generating page.
[24.10.2025 08:16] Renaming previous page.
[24.10.2025 08:16] Renaming previous data. index.html to ./d/2025-10-24.html
[24.10.2025 08:16] Writing result.
[24.10.2025 08:16] Renaming log file.
[24.10.2025 08:16] Renaming previous data. log.txt to ./logs/2025-10-24_last_log.txt
