[24.10.2025 15:12] Read previous papers.
[24.10.2025 15:12] Generating top page (month).
[24.10.2025 15:12] Writing top page (month).
[24.10.2025 16:14] Read previous papers.
[24.10.2025 16:14] Get feed.
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19600
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19779
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20579
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20822
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19304
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20766
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20187
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19365
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16917
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16893
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18821
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20470
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20820
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19944
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12487
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20803
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20270
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20771
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20733
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20668
[24.10.2025 16:14] Extract page data from URL. URL: https://huggingface.co/papers/2510.17853
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20362
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19995
[24.10.2025 16:14] Extract page data from URL. URL: https://huggingface.co/papers/2510.18413
[24.10.2025 16:14] Extract page data from URL. URL: https://huggingface.co/papers/2510.17896
[24.10.2025 16:14] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15804
[24.10.2025 16:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.10.2025 16:14] No deleted papers detected.
[24.10.2025 16:14] Downloading and parsing papers (pdf, html). Total: 26.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.19600.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.19600.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.19600.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.19779.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.19779.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.19779.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20579.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20579.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20579.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20822.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20822.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20822.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.19304.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.19304.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.19304.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20766.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20766.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20766.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20187.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20187.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20187.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.19365.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.19365.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.19365.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.16917.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.16917.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.16917.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.16893.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.16893.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.16893.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.18821.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.18821.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.18821.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20470.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20470.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20470.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20820.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20820.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20820.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.19944.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.19944.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.19944.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.12487.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.12487.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.12487.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20803.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20803.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20803.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20270.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20270.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20270.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20771.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20771.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20771.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20733.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20733.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20733.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.20668.
[24.10.2025 16:14] Extra JSON file exists (./assets/json/2510.20668.json), skip PDF parsing.
[24.10.2025 16:14] Paper image links file exists (./assets/img_data/2510.20668.json), skip HTML parsing.
[24.10.2025 16:14] Success.
[24.10.2025 16:14] Downloading and parsing paper https://huggingface.co/papers/2510.17853.
[24.10.2025 16:14] Downloading paper 2510.17853 from http://arxiv.org/pdf/2510.17853v1...
[24.10.2025 16:15] Extracting affiliations from text.
[24.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"CiteGuard: Faithful Citation Attribution for LLMs via Retrieval-Augmented Validation Yee Man Choi1, Xuehang Guo2, Yi R. (May) Fung3, Qingyun Wang4, 1University of Waterloo, 2University of Illinois at Urbana-Champaign, 3Hong Kong University of Science and Technology, 4College of William and Mary ymchoi@uwaterloo.ca xuehangg@illinois.edu yrfung@ust.hk qwang16@wm.edu 5 2 0 2 5 1 ] . [ 1 3 5 8 7 1 . 0 1 5 2 : r a "
[24.10.2025 16:15] Response: ```python
[
    "University of Waterloo",
    "University of Illinois at Urbana-Champaign",
    "Hong Kong University of Science and Technology",
    "College of William and Mary"
]
```
[24.10.2025 16:15] Deleting PDF ./assets/pdf/2510.17853.pdf.
[24.10.2025 16:15] Success.
[24.10.2025 16:15] Downloading and parsing paper https://huggingface.co/papers/2510.20362.
[24.10.2025 16:15] Extra JSON file exists (./assets/json/2510.20362.json), skip PDF parsing.
[24.10.2025 16:15] Paper image links file exists (./assets/img_data/2510.20362.json), skip HTML parsing.
[24.10.2025 16:15] Success.
[24.10.2025 16:15] Downloading and parsing paper https://huggingface.co/papers/2510.19995.
[24.10.2025 16:15] Extra JSON file exists (./assets/json/2510.19995.json), skip PDF parsing.
[24.10.2025 16:15] Paper image links file exists (./assets/img_data/2510.19995.json), skip HTML parsing.
[24.10.2025 16:15] Success.
[24.10.2025 16:15] Downloading and parsing paper https://huggingface.co/papers/2510.18413.
[24.10.2025 16:15] Downloading paper 2510.18413 from http://arxiv.org/pdf/2510.18413v1...
[24.10.2025 16:15] Extracting affiliations from text.
[24.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 2 ] . [ 1 3 1 4 8 1 . 0 1 5 2 : r ADAMAS: HADAMARD SPARSE ATTENTION FOR EFFICIENT LONG-CONTEXT INFERENCE Siyuan Yan1,2 Guo-qing Jiang2, Yucheng Zhang1 Xiaoxing Ma1 Ran Zhu2 Chun Cao1 1State Key Laboratory for Novel Software Technology, Nanjing University, China 2rednote hilab, China siyuanyan@smail.nju.edu.cn, jingweix@nju.edu.cn Jingwei Xu "
[24.10.2025 16:15] Response: ```python
[
    "State Key Laboratory for Novel Software Technology, Nanjing University, China",
    "rednote hilab, China"
]
```
[24.10.2025 16:15] Deleting PDF ./assets/pdf/2510.18413.pdf.
[24.10.2025 16:15] Success.
[24.10.2025 16:15] Downloading and parsing paper https://huggingface.co/papers/2510.17896.
[24.10.2025 16:15] Downloading paper 2510.17896 from http://arxiv.org/pdf/2510.17896v1...
[24.10.2025 16:15] Extracting affiliations from text.
[24.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 9 1 ] . [ 1 6 9 8 7 1 . 0 1 5 2 : r LONG-CONTEXT ATTENTION BENCHMARK: FROM KERNEL EFFICIENCY TO DISTRIBUTED CONTEXT PARALLELISM Tao Bu 1 Qiangang Wang 1 Bowen Zeng2 Hanwen Sun3 Yunpeng Huang1 Chun Cao1 Jingwei Xu 1 1State Key Laboratory for Novel Software Technology, Nanjing University, China 2Zhejiang University, China 3Peking University, China {butao,qgwang}@smail.nju.edu.cn, jingweix@nju.edu.cn "
[24.10.2025 16:15] Response: ```python
[
    "State Key Laboratory for Novel Software Technology, Nanjing University, China",
    "Zhejiang University, China",
    "Peking University, China"
]
```
[24.10.2025 16:15] Deleting PDF ./assets/pdf/2510.17896.pdf.
[24.10.2025 16:15] Success.
[24.10.2025 16:15] Downloading and parsing paper https://huggingface.co/papers/2510.15804.
[24.10.2025 16:15] Extra JSON file exists (./assets/json/2510.15804.json), skip PDF parsing.
[24.10.2025 16:15] Paper image links file exists (./assets/img_data/2510.15804.json), skip HTML parsing.
[24.10.2025 16:15] Success.
[24.10.2025 16:15] Enriching papers with extra data.
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 0. AutoPage, a multi-agent system, automates the creation of interactive research webpages through a hierarchical process, ensuring high-quality and efficient results.  					AI-generated summary 				 In the quest for scientific progress, communicating research is as vital as the discovery itself. Yet, ...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 1. AdaSPEC enhances speculative decoding by selectively filtering tokens during knowledge distillation, improving token acceptance rates without sacrificing generation quality.  					AI-generated summary 				 Speculative Decoding (SD) accelerates large language model inference by employing a small draf...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 2. Open-o3 Video integrates spatio-temporal evidence into video reasoning, achieving state-of-the-art performance on multiple benchmarks and providing valuable reasoning traces for test-time scaling.  					AI-generated summary 				 Most video reasoning models only generate textual reasoning traces with...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 3. HoloCine generates coherent multi-shot narratives using a Window Cross-Attention mechanism and Sparse Inter-Shot Self-Attention, enabling end-to-end cinematic creation.  					AI-generated summary 				 State-of-the-art text-to-video models excel at generating isolated clips but fall short of creating...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 4. Loopholing Discrete Diffusion Models (LDDMs) enhance text generation by preserving distributional information through a deterministic latent pathway, reducing perplexity and improving coherence and performance on reasoning tasks.  					AI-generated summary 				 Discrete diffusion models offer a prom...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 5. Dynamic Position Extrapolation (DyPE) enhances ultra-high-resolution image generation by dynamically adjusting positional encodings in pre-trained diffusion transformers, achieving state-of-the-art fidelity without additional sampling cost.  					AI-generated summary 				 Diffusion Transformer model...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 6. RLEV, a reinforcement learning method, aligns LLM optimization with human value signals, improving value-weighted accuracy and learning value-sensitive termination policies.  					AI-generated summary 				 We propose Reinforcement Learning with Explicit Human Values (RLEV), a method that aligns Larg...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 7. MLEB is the largest open-source benchmark for legal information retrieval, encompassing multiple jurisdictions, document types, and task types.  					AI-generated summary 				 We present the Massive Legal Embedding Benchmark (MLEB), the largest, most diverse, and most comprehensive open-source bench...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 8. SAKE is a benchmark for editing auditory attribute knowledge in Large Audio-Language Models, addressing challenges in reliability, generality, locality, and portability.  					AI-generated summary 				 Knowledge editing offers an efficient way to update model knowledge without full retraining, but p...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 9. Research investigates the impact of speaker emotion on the safety of large audio-language models, revealing inconsistencies and vulnerabilities that require targeted alignment strategies.  					AI-generated summary 				 Large audio-language models (LALMs) extend text-based LLMs with auditory underst...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 10. Self-play training for deep search agents improves performance through co-evolution of task generation and problem solving without supervision.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has become the mainstream technique for training LLM agents. However, ...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 11. Conan, a framework for evidence-grounded multi-step video reasoning, enhances visual grounding and reasoning accuracy through a multi-stage training strategy and outperforms existing models on various benchmarks.  					AI-generated summary 				 Video reasoning, which requires multi-step deduction ac...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 12. LayerComposer provides interactive control over spatial composition and scalability in multi-subject text-to-image generation through a layered canvas and locking mechanism.  					AI-generated summary 				 Despite their impressive visual fidelity, existing personalized generative models lack interac...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 13. Seed3D 1.0 generates scalable, physics-accurate 3D assets from images for use in simulation environments, enhancing both content diversity and real-time physics feedback.  					AI-generated summary 				 Developing embodied AI agents requires scalable training environments that balance content divers...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 14. A benchmark for code-diff understanding with tasks including apply, anti-apply, and diff generation, revealing optimal diff formats based on model size and use case.  					AI-generated summary 				 Reliable handling of code diffs is central to agents that edit and refactor repositories at scale. We ...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 15. A novel AutoRegressive Generation-based paradigm for image segmentation leverages multimodal large language models and VQ-VAE for dense mask generation, achieving high performance and fast inference.  					AI-generated summary 				 We propose a novel AutoRegressive Generation-based paradigm for imag...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 16. ImpossibleBench is a benchmark framework that measures and mitigates LLMs' tendency to exploit test cases by introducing impossible task variants, thereby enhancing model reliability.  					AI-generated summary 				 The tendency to find and exploit "shortcuts" to complete tasks poses significant ris...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 17. The $\alpha$-Flow framework improves few-step generative modeling by unifying and disentangling conflicting objectives, leading to better convergence and state-of-the-art performance on ImageNet-1K.  					AI-generated summary 				 MeanFlow has recently emerged as a powerful framework for few-step ge...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 18. Thought communication enables direct mind-to-mind interaction between agents, uncovering latent thoughts and improving collaborative intelligence beyond natural language.  					AI-generated summary 				 Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect natur...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 19. The guide outlines a progression from early masked models to memory-augmented systems, emphasizing generative capabilities, interactive loops, and memory for building world models.  					AI-generated summary 				 This is not a typical survey of world models; it is a guide for those who want to build...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 20. CiteGuard, a retrieval-aware agent framework, enhances citation accuracy in LLM-generated text by aligning citations with human choices, achieving near-human performance.  					AI-generated summary 				 Large Language Models (LLMs) have emerged as promising assistants for scientific writing. However...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 21. ComProScanner, an autonomous multi-agent platform, extracts, validates, classifies, and visualizes chemical compositions and properties from scientific literature, outperforming various LLMs in accuracy.  					AI-generated summary 				 Since the advent of various pre-trained large language models, e...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 22. C2C, a scalable framework for multi-agent LLM systems, improves task completion time through the Alignment Factor and Sequential Action Framework, enabling cost-aware communication and dynamic task understanding.  					AI-generated summary 				 Teamwork in workspace for complex tasks requires divers...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 23. Adamas, a sparse attention mechanism, achieves high accuracy and speed in long-context inference by using Hadamard transform, bucketization, 2-bit compression, and Manhattan-distance estimation.  					AI-generated summary 				 Large language models (LLMs) now support context windows of hundreds of t...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 24. A unified benchmark evaluates attention mechanisms in transformer-based LLMs, focusing on efficiency, scalability, and performance across different attention mask patterns and sequence lengths.  					AI-generated summary 				 Transformer-based large language models (LLMs) have achieved remarkable su...
[24.10.2025 16:15] ********************************************************************************
[24.10.2025 16:15] Abstract 25. A one-layer transformer model demonstrates how linear subspaces separating true from false statements can emerge in language models through memorization and subsequent linear separation.  					AI-generated summary 				 Recent probing studies reveal that large language models exhibit linear subspaces...
[24.10.2025 16:15] Read previous papers.
[24.10.2025 16:15] Generating reviews via LLM API.
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#hallucinations", "#open_source", "#science", "#agents"], "emoji": "🌐", "ru": {"title": "Автоматическое создание интерактивных научных веб-страниц с помощью мультиагентной системы", "desc": "AutoPage — это мультиагентная система, которая автоматизирует с
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#reasoning", "#optimization", "#alignment", "#inference", "#training"], "emoji": "🎯", "ru": {"title": "Умная фильтрация токенов для быстрой генерации текста", "desc": "Speculative Decoding ускоряет генерацию текста в больших языковых моделях, используя маленькую draft-модель для пре
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#dataset", "#video", "#training", "#benchmark", "#reasoning", "#games"], "emoji": "🎬", "ru": {"title": "Видео-рассуждения с пространственно-временными доказательствами", "desc": "Open-o3 Video — это фреймворк для рассуждений о видео, который не просто генерирует текстовые объяснения
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#architecture", "#story_generation", "#video", "#cv"], "emoji": "🎬", "ru": {"title": "От клипов к кино: целостная генерация видео-нарративов", "desc": "HoloCine — это модель для генерации связных видео-нарративов, состоящих из множества кадров, что решает проблему современных text-t
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#data", "#multimodal", "#training", "#reasoning", "#diffusion"], "emoji": "🔄", "ru": {"title": "Сохранение информации в диффузионных моделях через детерминированный обходной путь", "desc": "Статья представляет Loopholing Discrete Diffusion Models (LDDMs) — улучшенные дискретные дифф
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#cv", "#benchmark", "#architecture"], "emoji": "🔭", "ru": {"title": "Генерация сверхвысокого разрешения через динамическую экстраполяцию позиций", "desc": "Статья представляет Dynamic Position Extrapolation (DyPE) - метод для генерации изображений свер
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#optimization", "#rl", "#alignment", "#rlhf"], "emoji": "🎯", "ru": {"title": "Обучение AI с учётом человеческих ценностей", "desc": "В статье предлагается метод RLEV, который использует reinforcement learning для обучения больших языковых моделей с учётом человеческих ценностей и пр
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#open_source", "#data"], "emoji": "⚖️", "ru": {"title": "Эталонный тест для юридического поиска во всех правовых системах", "desc": "Представлен MLEB — крупнейший открытый бенчмарк для информационного поиска в юридической сфере. Он включает десять экспертно
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#audio", "#benchmark", "#multimodal"], "emoji": "🔊", "ru": {"title": "Редактирование звуковых знаний в AI-моделях без полного переобучения", "desc": "В статье представлен SAKE — первый бенчмарк для редактирования знаний об аудиальных атрибутах в больших аудио-языковых моделях (LALM)
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#audio", "#dataset", "#security", "#alignment", "#multimodal"], "emoji": "😠", "ru": {"title": "Эмоции как уязвимость: безопасность аудио-LLM под угрозой", "desc": "Исследование изучает, как эмоции говорящего влияют на безопасность больших аудио-языковых моделей (LALMs). Учёные созда
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#agents", "#rag", "#games", "#rl"], "emoji": "🔄", "ru": {"title": "Self-play для поисковых агентов: учимся без учителя", "desc": "Статья предлагает метод самообучения для агентов глубокого поиска через self-play, где LLM одновременно генерирует поисков
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#reasoning", "#long_context", "#dataset", "#rl", "#video"], "emoji": "🔍", "ru": {"title": "Conan: Пошаговое видеорассуждение с визуальными доказательствами", "desc": "Статья представляет Conan — фреймворк для многошагового рассуждения над видео с опорой 
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#synthetic", "#multimodal", "#games", "#cv"], "emoji": "🎨", "ru": {"title": "Послойная композиция: интерактивное управление персонализированной генерацией изображений", "desc": "LayerComposer — это фреймворк для персонализированной генерации изображений с несколькими объектами, кото
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#agents", "#games", "#3d", "#robotics", "#synthetic"], "emoji": "🎲", "ru": {"title": "От картинки к симуляции: генерация физически точных 3D-объектов для обучения AI-агентов", "desc": "Seed3D 1.0 — это foundation модель, которая генерирует готовые для симуляции 3D-объекты из одного 
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#optimization", "#open_source"], "emoji": "🔄", "ru": {"title": "Оптимальные форматы diff для разных моделей и задач", "desc": "Исследователи представили Diff-XYZ — бенчмарк для оценки понимания code diff моделями с тремя задачами: применение патча, обратное
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#inference", "#games", "#cv"], "emoji": "🎭", "ru": {"title": "Сегментация изображений через авторегрессивную генерацию масок", "desc": "Исследователи предложили новый подход к сегментации изображений ARGenSeg, который объединяет мультимодальные больши
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#interpretability", "#benchmark", "#security"], "emoji": "🚫", "ru": {"title": "Ловушка для читеров: как поймать LLM на нечестном решении задач", "desc": "ImpossibleBench — это фреймворк для тестирования LLM, который измеряет склонность моделей к использованию нечестных способов реше
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#data", "#optimization", "#training", "#cv", "#diffusion"], "emoji": "🌊", "ru": {"title": "α-Flow: разделяй и властвуй в быстрой генерации изображений", "desc": "Статья представляет α-Flow — улучшенный framework для генеративного моделирования, который требует всего несколько шагов 
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#benchmark", "#reasoning", "#interpretability", "#synthetic"], "emoji": "🧠", "ru": {"title": "Телепатия для ИИ: общение напрямую через скрытые мысли", "desc": "Исследователи предложили новую парадигму коммуникации между AI-агентами, которая позволяет им обм
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#architecture", "#multimodal", "#games", "#diffusion"], "emoji": "🌍", "ru": {"title": "Путеводитель по строительству миров: от масок к памяти", "desc": "Статья представляет собой практическое руководство по построению world models, а не обычный обзор литературы. Авторы прослеживают 
[24.10.2025 16:15] Querying the API.
[24.10.2025 16:15] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

CiteGuard, a retrieval-aware agent framework, enhances citation accuracy in LLM-generated text by aligning citations with human choices, achieving near-human performance.  					AI-generated summary 				 Large Language Models (LLMs) have emerged as promising assistants for scientific writing. However, there have been concerns regarding the quality and reliability of the generated text, one of which is the citation accuracy and faithfulness. While most recent work relies on methods such as LLM-as-a-Judge, the reliability of LLM-as-a-Judge alone is also in doubt. In this work, we reframe citation evaluation as a problem of citation attribution alignment, which is assessing whether LLM-generated citations match those a human author would include for the same text. We propose CiteGuard, a retrieval-aware agent framework designed to provide more faithful grounding for citation validation. CiteGuard improves the prior baseline by 12.3%, and achieves up to 65.4% accuracy on the CiteME benchmark, on par with human-level performance (69.7%). It also enables the identification of alternative but valid citations.
[24.10.2025 16:15] Response: ```json
{
  "desc": "Статья представляет CiteGuard — агентский фреймворк для улучшения точности цитирования в текстах, генерируемых LLM. Авторы переформулируют проблему валидации цитат как задачу выравнивания атрибуции: проверяют, совпадают ли цитаты от LLM с теми, что выбрал бы человек. CiteGuard использует retrieval-подход и достигает 65.4% точности на бенчмарке CiteME, что близко к человеческому уровню в 69.7%. Система улучшает предыдущий baseline на 12.3% и может находить альтернативные, но валидные цитаты.",
  "emoji": "📚",
  "title": "CiteGuard: цитирование на уровне человека для AI-ассистентов в научном письме"
}
```
[24.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CiteGuard, a retrieval-aware agent framework, enhances citation accuracy in LLM-generated text by aligning citations with human choices, achieving near-human performance.  					AI-generated summary 				 Large Language Models (LLMs) have emerged as promising assistants for scientific writing. However, there have been concerns regarding the quality and reliability of the generated text, one of which is the citation accuracy and faithfulness. While most recent work relies on methods such as LLM-as-a-Judge, the reliability of LLM-as-a-Judge alone is also in doubt. In this work, we reframe citation evaluation as a problem of citation attribution alignment, which is assessing whether LLM-generated citations match those a human author would include for the same text. We propose CiteGuard, a retrieval-aware agent framework designed to provide more faithful grounding for citation validation. CiteGuard improves the prior baseline by 12.3%, and achieves up to 65.4% accuracy on the CiteME benchmark, on par with human-level performance (69.7%). It also enables the identification of alternative but valid citations."

[24.10.2025 16:15] Response: ```python
["AGENTS", "RAG", "BENCHMARK"]
```
[24.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"CiteGuard, a retrieval-aware agent framework, enhances citation accuracy in LLM-generated text by aligning citations with human choices, achieving near-human performance.  					AI-generated summary 				 Large Language Models (LLMs) have emerged as promising assistants for scientific writing. However, there have been concerns regarding the quality and reliability of the generated text, one of which is the citation accuracy and faithfulness. While most recent work relies on methods such as LLM-as-a-Judge, the reliability of LLM-as-a-Judge alone is also in doubt. In this work, we reframe citation evaluation as a problem of citation attribution alignment, which is assessing whether LLM-generated citations match those a human author would include for the same text. We propose CiteGuard, a retrieval-aware agent framework designed to provide more faithful grounding for citation validation. CiteGuard improves the prior baseline by 12.3%, and achieves up to 65.4% accuracy on the CiteME benchmark, on par with human-level performance (69.7%). It also enables the identification of alternative but valid citations."

[24.10.2025 16:15] Response: ```python
['ALIGNMENT', 'SCIENCE']
```
[24.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CiteGuard is a framework designed to improve the accuracy of citations in text generated by Large Language Models (LLMs). It focuses on aligning the citations produced by LLMs with those that a human author would choose, addressing concerns about citation reliability. By reframing citation evaluation as citation attribution alignment, CiteGuard enhances the grounding for citation validation. The framework shows significant improvement over previous methods, achieving near-human performance in citation accuracy.","title":"CiteGuard: Aligning AI Citations with Human Choices"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CiteGuard is a framework designed to improve the accuracy of citations in text generated by Large Language Models (LLMs). It focuses on aligning the citations produced by LLMs with those that a human author would choose, addressing concerns about citation reliability. By reframing citation evaluation as citation attribution alignment, CiteGuard enhances the grounding for citation validation. The framework shows significant improvement over previous methods, achieving near-human performance in citation accuracy.', title='CiteGuard: Aligning AI Citations with Human Choices'))
[24.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"CiteGuard是一个检索感知的代理框架，旨在提高大型语言模型（LLM）生成文本中的引用准确性。它通过将引用与人类选择对齐，来评估LLM生成的引用是否符合人类作者的标准。该框架在CiteME基准测试中达到了65.4%的准确率，接近人类水平的69.7%。CiteGuard还能够识别替代但有效的引用，从而增强了引用验证的可靠性。","title":"CiteGuard：提升引用准确性的智能框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='CiteGuard是一个检索感知的代理框架，旨在提高大型语言模型（LLM）生成文本中的引用准确性。它通过将引用与人类选择对齐，来评估LLM生成的引用是否符合人类作者的标准。该框架在CiteME基准测试中达到了65.4%的准确率，接近人类水平的69.7%。CiteGuard还能够识别替代但有效的引用，从而增强了引用验证的可靠性。', title='CiteGuard：提升引用准确性的智能框架'))
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#data", "#dataset", "#agents", "#benchmark", "#open_source", "#science"], "emoji": "🔬", "ru": {"title": "Автономная платформа для извлечения химических данных из научных статей", "desc": "ComProScanner — это мультиагентная платформа, которая автоматически извлекает, проверяет, класс
[24.10.2025 16:15] Using data from previous issue: {"categories": ["#alignment", "#agents", "#multimodal"], "emoji": "🤝", "ru": {"title": "Умная коммуникация агентов для ускорения командной работы", "desc": "Исследователи представили C2C — фреймворк для координации множества LLM-агентов при решении сложных задач. Ключевая идея — метрика Alignment Fa
[24.10.2025 16:15] Querying the API.
[24.10.2025 16:15] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Adamas, a sparse attention mechanism, achieves high accuracy and speed in long-context inference by using Hadamard transform, bucketization, 2-bit compression, and Manhattan-distance estimation.  					AI-generated summary 				 Large language models (LLMs) now support context windows of hundreds of thousands to millions of tokens, enabling applications such as long-document summarization, large-scale code synthesis, multi-document question answering and persistent multi-turn dialogue. However, such extended contexts exacerbate the quadratic cost of self-attention, leading to severe latency in autoregressive decoding. Existing sparse attention methods alleviate these costs but rely on heuristic patterns that struggle to recall critical key-value (KV) pairs for each query, resulting in accuracy degradation. We introduce Adamas, a lightweight yet highly accurate sparse attention mechanism designed for long-context inference. Adamas applies the Hadamard transform, bucketization and 2-bit compression to produce compact representations, and leverages Manhattan-distance estimation for efficient top-k selections. Experiments show that Adamas matches the accuracy of full attention with only a 64-token budget, achieves near-lossless performance at 128, and supports up to 8x higher sparsity than prior state-of-the-art (SOTA) methods while delivering up to 4.4x self-attention and 1.5x end-to-end speedups on 32K-length sequences. Remarkably, Adamas attains comparable or even lower perplexity than full attention, underscoring its effectiveness in maintaining accuracy under aggressive sparsity.
[24.10.2025 16:16] Response: ```json
{
  "desc": "Adamas — это новый механизм разреженного внимания для LLM, который решает проблему квадратичной сложности self-attention при работе с длинными контекстами (сотни тысяч токенов). Метод использует преобразование Адамара, квантизацию до 2 бит и манхэттенское расстояние для эффективного отбора наиболее важных key-value пар. В отличие от существующих эвристических подходов, Adamas достигает точности полного внимания при бюджете всего 64 токена и обеспечивает ускорение до 4.4x для self-attention на последовательностях длиной 32K токенов. Метод поддерживает в 8 раз большую разреженность по сравнению с современными решениями без потери качества модели.",
  "emoji": "💎",
  "title": "Adamas: сверхбыстрое разреженное внимание для длинных контекстов без потери точности"
}
```
[24.10.2025 16:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adamas, a sparse attention mechanism, achieves high accuracy and speed in long-context inference by using Hadamard transform, bucketization, 2-bit compression, and Manhattan-distance estimation.  					AI-generated summary 				 Large language models (LLMs) now support context windows of hundreds of thousands to millions of tokens, enabling applications such as long-document summarization, large-scale code synthesis, multi-document question answering and persistent multi-turn dialogue. However, such extended contexts exacerbate the quadratic cost of self-attention, leading to severe latency in autoregressive decoding. Existing sparse attention methods alleviate these costs but rely on heuristic patterns that struggle to recall critical key-value (KV) pairs for each query, resulting in accuracy degradation. We introduce Adamas, a lightweight yet highly accurate sparse attention mechanism designed for long-context inference. Adamas applies the Hadamard transform, bucketization and 2-bit compression to produce compact representations, and leverages Manhattan-distance estimation for efficient top-k selections. Experiments show that Adamas matches the accuracy of full attention with only a 64-token budget, achieves near-lossless performance at 128, and supports up to 8x higher sparsity than prior state-of-the-art (SOTA) methods while delivering up to 4.4x self-attention and 1.5x end-to-end speedups on 32K-length sequences. Remarkably, Adamas attains comparable or even lower perplexity than full attention, underscoring its effectiveness in maintaining accuracy under aggressive sparsity."

[24.10.2025 16:16] Response: ```python
["ARCHITECTURE", "INFERENCE", "TRAINING"]
```
[24.10.2025 16:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adamas, a sparse attention mechanism, achieves high accuracy and speed in long-context inference by using Hadamard transform, bucketization, 2-bit compression, and Manhattan-distance estimation.  					AI-generated summary 				 Large language models (LLMs) now support context windows of hundreds of thousands to millions of tokens, enabling applications such as long-document summarization, large-scale code synthesis, multi-document question answering and persistent multi-turn dialogue. However, such extended contexts exacerbate the quadratic cost of self-attention, leading to severe latency in autoregressive decoding. Existing sparse attention methods alleviate these costs but rely on heuristic patterns that struggle to recall critical key-value (KV) pairs for each query, resulting in accuracy degradation. We introduce Adamas, a lightweight yet highly accurate sparse attention mechanism designed for long-context inference. Adamas applies the Hadamard transform, bucketization and 2-bit compression to produce compact representations, and leverages Manhattan-distance estimation for efficient top-k selections. Experiments show that Adamas matches the accuracy of full attention with only a 64-token budget, achieves near-lossless performance at 128, and supports up to 8x higher sparsity than prior state-of-the-art (SOTA) methods while delivering up to 4.4x self-attention and 1.5x end-to-end speedups on 32K-length sequences. Remarkably, Adamas attains comparable or even lower perplexity than full attention, underscoring its effectiveness in maintaining accuracy under aggressive sparsity."

[24.10.2025 16:16] Response: ```python
["LONG_CONTEXT", "OPTIMIZATION"]
```
[24.10.2025 16:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Adamas is a novel sparse attention mechanism that enhances the efficiency of long-context inference in large language models. It utilizes techniques like Hadamard transform, bucketization, and 2-bit compression to create compact representations of data, which helps in reducing computational costs. By employing Manhattan-distance estimation, Adamas efficiently selects the most relevant key-value pairs, improving accuracy while maintaining high speed. The results demonstrate that Adamas can achieve similar or better performance than traditional full attention methods, even with significantly reduced resource usage.","title":"Adamas: Efficient Sparse Attention for Long-Context Inference"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Adamas is a novel sparse attention mechanism that enhances the efficiency of long-context inference in large language models. It utilizes techniques like Hadamard transform, bucketization, and 2-bit compression to create compact representations of data, which helps in reducing computational costs. By employing Manhattan-distance estimation, Adamas efficiently selects the most relevant key-value pairs, improving accuracy while maintaining high speed. The results demonstrate that Adamas can achieve similar or better performance than traditional full attention methods, even with significantly reduced resource usage.', title='Adamas: Efficient Sparse Attention for Long-Context Inference'))
[24.10.2025 16:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Adamas是一种稀疏注意力机制，旨在提高长上下文推理的准确性和速度。它通过使用Hadamard变换、桶化、2位压缩和曼哈顿距离估计来生成紧凑的表示。实验表明，Adamas在仅使用64个标记的情况下，准确性与全注意力相当，并在128个标记时实现近乎无损的性能。与之前的最先进方法相比，Adamas支持高达8倍的稀疏性，同时在32K长度序列上实现了高达4.4倍的自注意力加速和1.5倍的端到端加速。","title":"Adamas：高效稀疏注意力机制的创新"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Adamas是一种稀疏注意力机制，旨在提高长上下文推理的准确性和速度。它通过使用Hadamard变换、桶化、2位压缩和曼哈顿距离估计来生成紧凑的表示。实验表明，Adamas在仅使用64个标记的情况下，准确性与全注意力相当，并在128个标记时实现近乎无损的性能。与之前的最先进方法相比，Adamas支持高达8倍的稀疏性，同时在32K长度序列上实现了高达4.4倍的自注意力加速和1.5倍的端到端加速。', title='Adamas：高效稀疏注意力机制的创新'))
[24.10.2025 16:16] Querying the API.
[24.10.2025 16:16] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A unified benchmark evaluates attention mechanisms in transformer-based LLMs, focusing on efficiency, scalability, and performance across different attention mask patterns and sequence lengths.  					AI-generated summary 				 Transformer-based large language models (LLMs) have achieved remarkable success, yet their standard attention mechanism incurs quadratic computation and memory costs with respect to sequence length, posing a major bottleneck for long-context training. Prior work tackles this challenge along two directions: (1) kernel-level optimizations, which accelerate dense and sparse attention operators; and (2) module-level strategies, often referred to as distributed attention or context parallel training, which scale attention across multiple devices. However, systematic evaluation still remains limited: operator-level comparisons are often incomplete, while context parallel strategies are typically framework-specific, with unclear performance analysis across contexts. To address these gaps, we propose a unified benchmark that integrates representative attention kernels and context parallel mechanisms with a modular and extensible interface for evaluation. The benchmark evaluates methods along two critical dimensions: (1) attention mask patterns, which strongly affect efficiency, scalability, and usability, and (2) sequence length and distributed scale, which determine performance under extreme long-context training. Through comprehensive experiments on the cluster of up to 96 GPUs, our benchmark enables reproducible comparisons, highlights method-specific trade-offs, and provides practical guidance for designing and deploying attention mechanisms in long-context LLM training.
[24.10.2025 16:16] Response: ```json
{
  "title": "Универсальный бенчмарк для механизмов внимания в длинных контекстах",
  "desc": "Исследователи создали единый бенчмарк для оценки механизмов внимания в трансформерных LLM, которые страдают от квадратичной сложности при обработке длинных последовательностей. Бенчмарк объединяет оптимизации на уровне ядер (kernel-level) и распределённые стратегии обучения (context parallel training) в модульном интерфейсе. Оценка проводится по двум измерениям: паттернам масок внимания и масштабу последовательностей при распределённом обучении. Эксперименты на кластере до 96 GPU позволяют воспроизводимо сравнивать методы и выявлять компромиссы для практического применения в обучении LLM на длинных контекстах.",
  "emoji": "🔍"
}
```
[24.10.2025 16:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A unified benchmark evaluates attention mechanisms in transformer-based LLMs, focusing on efficiency, scalability, and performance across different attention mask patterns and sequence lengths.  					AI-generated summary 				 Transformer-based large language models (LLMs) have achieved remarkable success, yet their standard attention mechanism incurs quadratic computation and memory costs with respect to sequence length, posing a major bottleneck for long-context training. Prior work tackles this challenge along two directions: (1) kernel-level optimizations, which accelerate dense and sparse attention operators; and (2) module-level strategies, often referred to as distributed attention or context parallel training, which scale attention across multiple devices. However, systematic evaluation still remains limited: operator-level comparisons are often incomplete, while context parallel strategies are typically framework-specific, with unclear performance analysis across contexts. To address these gaps, we propose a unified benchmark that integrates representative attention kernels and context parallel mechanisms with a modular and extensible interface for evaluation. The benchmark evaluates methods along two critical dimensions: (1) attention mask patterns, which strongly affect efficiency, scalability, and usability, and (2) sequence length and distributed scale, which determine performance under extreme long-context training. Through comprehensive experiments on the cluster of up to 96 GPUs, our benchmark enables reproducible comparisons, highlights method-specific trade-offs, and provides practical guidance for designing and deploying attention mechanisms in long-context LLM training."

[24.10.2025 16:16] Response: ```python
['BENCHMARK', 'ARCHITECTURE']
```
[24.10.2025 16:16] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A unified benchmark evaluates attention mechanisms in transformer-based LLMs, focusing on efficiency, scalability, and performance across different attention mask patterns and sequence lengths.  					AI-generated summary 				 Transformer-based large language models (LLMs) have achieved remarkable success, yet their standard attention mechanism incurs quadratic computation and memory costs with respect to sequence length, posing a major bottleneck for long-context training. Prior work tackles this challenge along two directions: (1) kernel-level optimizations, which accelerate dense and sparse attention operators; and (2) module-level strategies, often referred to as distributed attention or context parallel training, which scale attention across multiple devices. However, systematic evaluation still remains limited: operator-level comparisons are often incomplete, while context parallel strategies are typically framework-specific, with unclear performance analysis across contexts. To address these gaps, we propose a unified benchmark that integrates representative attention kernels and context parallel mechanisms with a modular and extensible interface for evaluation. The benchmark evaluates methods along two critical dimensions: (1) attention mask patterns, which strongly affect efficiency, scalability, and usability, and (2) sequence length and distributed scale, which determine performance under extreme long-context training. Through comprehensive experiments on the cluster of up to 96 GPUs, our benchmark enables reproducible comparisons, highlights method-specific trade-offs, and provides practical guidance for designing and deploying attention mechanisms in long-context LLM training."

[24.10.2025 16:16] Response: ```python
["LONG_CONTEXT", "OPTIMIZATION"]
```
[24.10.2025 16:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a unified benchmark for evaluating attention mechanisms in transformer-based large language models (LLMs). It addresses the computational and memory challenges posed by the standard attention mechanism, particularly for long sequences. The benchmark integrates various attention kernels and context parallel strategies, allowing for systematic comparisons across different attention mask patterns and sequence lengths. By conducting extensive experiments on a large GPU cluster, the study aims to provide insights into the efficiency and scalability of these methods, facilitating better design choices for long-context training.","title":"Benchmarking Attention: Enhancing Efficiency in Long-Context LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a unified benchmark for evaluating attention mechanisms in transformer-based large language models (LLMs). It addresses the computational and memory challenges posed by the standard attention mechanism, particularly for long sequences. The benchmark integrates various attention kernels and context parallel strategies, allowing for systematic comparisons across different attention mask patterns and sequence lengths. By conducting extensive experiments on a large GPU cluster, the study aims to provide insights into the efficiency and scalability of these methods, facilitating better design choices for long-context training.', title='Benchmarking Attention: Enhancing Efficiency in Long-Context LLMs'))
[24.10.2025 16:16] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一个统一的基准测试，用于评估基于变换器的大型语言模型中的注意力机制，重点关注效率、可扩展性和在不同注意力掩码模式及序列长度下的性能。传统的注意力机制在处理长序列时会导致计算和内存成本呈平方级增长，成为长上下文训练的瓶颈。我们通过整合代表性的注意力内核和上下文并行机制，提供了一个模块化和可扩展的评估接口，填补了现有评估的空白。通过在多达96个GPU的集群上进行全面实验，我们的基准测试能够实现可重复的比较，突出方法特定的权衡，并为长上下文LLM训练中的注意力机制设计和部署提供实用指导。","title":"统一基准测试：提升长上下文训练的注意力机制"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一个统一的基准测试，用于评估基于变换器的大型语言模型中的注意力机制，重点关注效率、可扩展性和在不同注意力掩码模式及序列长度下的性能。传统的注意力机制在处理长序列时会导致计算和内存成本呈平方级增长，成为长上下文训练的瓶颈。我们通过整合代表性的注意力内核和上下文并行机制，提供了一个模块化和可扩展的评估接口，填补了现有评估的空白。通过在多达96个GPU的集群上进行全面实验，我们的基准测试能够实现可重复的比较，突出方法特定的权衡，并为长上下文LLM训练中的注意力机制设计和部署提供实用指导。', title='统一基准测试：提升长上下文训练的注意力机制'))
[24.10.2025 16:16] Using data from previous issue: {"categories": ["#architecture", "#training", "#reasoning", "#interpretability"], "emoji": "🎯", "ru": {"title": "Как трансформеры учатся отличать правду от лжи через линейное разделение", "desc": "Исследователи создали простую однослойную трансформер-модель, которая демонстрирует, как в языковых мод
[24.10.2025 16:16] Renaming data file.
[24.10.2025 16:16] Renaming previous data. hf_papers.json to ./d/2025-10-24.json
[24.10.2025 16:16] Saving new data file.
[24.10.2025 16:16] Generating page.
[24.10.2025 16:16] Renaming previous page.
[24.10.2025 16:16] Renaming previous data. index.html to ./d/2025-10-24.html
[24.10.2025 16:16] Writing result.
[24.10.2025 16:16] Renaming log file.
[24.10.2025 16:16] Renaming previous data. log.txt to ./logs/2025-10-24_last_log.txt
