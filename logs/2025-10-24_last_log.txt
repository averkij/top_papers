[23.10.2025 23:11] Read previous papers.
[23.10.2025 23:11] Generating top page (month).
[23.10.2025 23:11] Writing top page (month).
[24.10.2025 00:49] Read previous papers.
[24.10.2025 00:49] Get feed.
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19338
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18927
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19363
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15511
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15731
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19430
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19307
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19488
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19336
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19808
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19817
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19592
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16844
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15050
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19386
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19316
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19028
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18313
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19286
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19127
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18941
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18940
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17932
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19457
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18917
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18428
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18909
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18091
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19753
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18840
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18279
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.16435
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.15015
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19492
[24.10.2025 00:49] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18034
[24.10.2025 00:49] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.10.2025 00:49] No deleted papers detected.
[24.10.2025 00:49] Downloading and parsing papers (pdf, html). Total: 35.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19338.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19338.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19338.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18927.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18927.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18927.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19363.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19363.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19363.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.15511.
[24.10.2025 00:49] Downloading paper 2510.15511 from http://arxiv.org/pdf/2510.15511v3...
[24.10.2025 00:49] Failed to download and parse paper https://huggingface.co/papers/2510.15511: 'LTChar' object is not iterable
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.15731.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.15731.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.15731.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19430.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19430.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19430.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19307.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19307.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19307.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19488.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19488.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19488.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19336.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19336.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19336.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19808.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19808.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19808.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19817.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19817.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19817.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19592.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19592.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19592.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.16844.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.16844.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.16844.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.15050.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.15050.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.15050.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19386.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19386.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19386.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19316.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19316.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19316.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19028.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19028.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19028.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18313.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18313.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18313.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19286.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19286.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19286.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19127.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19127.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19127.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18941.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18941.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18941.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18940.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18940.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18940.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.17932.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.17932.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.17932.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19457.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19457.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19457.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18917.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18917.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18917.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18428.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18428.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18428.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18909.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18909.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18909.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18091.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18091.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18091.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19753.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19753.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19753.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18840.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18840.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18840.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18279.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18279.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18279.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.16435.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.16435.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.16435.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.15015.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.15015.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.15015.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.19492.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.19492.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.19492.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Downloading and parsing paper https://huggingface.co/papers/2510.18034.
[24.10.2025 00:49] Extra JSON file exists (./assets/json/2510.18034.json), skip PDF parsing.
[24.10.2025 00:49] Paper image links file exists (./assets/img_data/2510.18034.json), skip HTML parsing.
[24.10.2025 00:49] Success.
[24.10.2025 00:49] Enriching papers with extra data.
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 0. The Ring-linear model series, including Ring-mini-linear-2.0 and Ring-flash-linear-2.0, uses a hybrid architecture combining linear and softmax attention to reduce inference costs and improve training efficiency.  					AI-generated summary 				 In this technical report, we present the Ring-linear mo...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 1. BAlanced Policy Optimization with Adaptive Clipping (BAPO) addresses challenges in off-policy reinforcement learning by dynamically adjusting clipping bounds to improve sample efficiency, stability, and performance in large language models.  					AI-generated summary 				 Reinforcement learning (RL)...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 2. LoongRL, a data-driven reinforcement learning method, enhances long-context reasoning by transforming short multi-hop QA into high-difficulty tasks, improving accuracy and generalization in large language models.  					AI-generated summary 				 Reasoning over long contexts is essential for large lan...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 3. Transformer language models are proven to be injective, allowing exact input reconstruction from hidden activations, which has implications for transparency and safety.  					AI-generated summary 				 Transformer components such as non-linear activations and normalization are inherently non-injectiv...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 4. Empirical analysis of Masked Diffusion Language Models (DLMs) reveals distinct attention sinking phenomena and robustness compared to Autoregressive Models (ARMs).  					AI-generated summary 				 Masked Diffusion Language Models (DLMs) have recently emerged as a promising alternative to traditional ...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 5. GigaBrain-0, a VLA foundation model, uses world model-generated data to enhance cross-task generalization and policy robustness, improving real-world performance on complex manipulation tasks.  					AI-generated summary 				 Training Vision-Language-Action (VLA) models for generalist robots typicall...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 6. A unified reinforcement and imitation learning algorithm creates efficient, lightweight vision-language models that match or exceed leading VLMs in performance.  					AI-generated summary 				 Vision-Language Models (VLMs) have achieved remarkable progress, yet their large scale often renders them i...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 7. VideoAgentTrek automatically extracts GUI interaction data from YouTube videos using Video2Action, an inverse dynamics module, improving task success rates and step accuracy for computer-use agents.  					AI-generated summary 				 Training computer-use agents requires massive amounts of GUI interact...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 8. DaMo, a trainable network optimizing data mixtures for Multimodal Large Language Models, enhances performance across various mobile phone tasks and benchmarks.  					AI-generated summary 				 Mobile Phone Agents (MPAs) have emerged as a promising research direction due to their broad applicability a...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 9. Pico-Banana-400K is a large-scale, high-quality dataset for instruction-based image editing, featuring diverse edit pairs, multi-turn editing, preference subsets, and long-short instruction pairs, enabling comprehensive research and benchmarking.  					AI-generated summary 				 Recent advances in mu...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 10. olmOCR 2, a vision language model trained with reinforcement learning and verifiable rewards, achieves state-of-the-art performance in OCR tasks, particularly in math formula conversion, table parsing, and multi-column layouts.  					AI-generated summary 				 We present olmOCR 2, the latest in our f...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 11. Decomposed Attention Fusion (DecAF) enhances video object segmentation by refining attention maps from multimodal large language models without retraining.  					AI-generated summary 				 Multimodal large language models (MLLMs) demonstrate strong video understanding by attending to visual tokens re...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 12. FinSight, a multi-agent framework using CAVM architecture and iterative vision-enhanced mechanism, generates high-quality, multimodal financial reports with superior accuracy and presentation quality compared to existing systems.  					AI-generated summary 				 Generating professional financial repo...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 13. DRIFT, a lightweight method, enhances multimodal large language models' reasoning ability by transferring knowledge in gradient space, outperforming naive merging and supervised fine-tuning with reduced computational cost.  					AI-generated summary 				 Multimodal large language models (MLLMs) are ...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 14. ColorAgent, an OS agent using step-wise reinforcement learning and a multi-agent framework, achieves high success rates in long-horizon interactions and personalized user engagement on Android benchmarks.  					AI-generated summary 				 With the advancements in hardware, software, and large language...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 15. KORE is a method for injecting new knowledge into large multimodal models while preserving old knowledge, using structured augmentations and covariance matrix constraints to minimize catastrophic forgetting.  					AI-generated summary 				 Large Multimodal Models encode extensive factual knowledge i...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 16. Current large language models exhibit significant limitations in social reasoning, particularly in inferring interpersonal relationships across different languages, and thinking models or chain-of-thought prompting offer minimal improvement.  					AI-generated summary 				 As large language models (...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 17. OmniNWM is a unified world model for autonomous driving that generates panoramic videos, encodes actions using Plucker ray-maps, and defines dense rewards based on 3D occupancy, achieving top performance in video generation, control, and stability.  					AI-generated summary 				 Autonomous driving ...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 18. TheMCPCompany evaluates tool-calling agents using REST APIs for interacting with real-world services, showing that advanced models perform well in simpler environments but struggle with complex enterprise environments.  					AI-generated summary 				 Since the introduction of the Model Context Proto...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 19. MusicRFM uses Recursive Feature Machines to enable real-time, fine-grained control over pre-trained music models by steering their internal activations, improving musical note accuracy with minimal impact on prompt fidelity.  					AI-generated summary 				 Controllable music generation remains a sig...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 20. ProfBench evaluates large language models in professional domains using human-expert criteria, revealing challenges and performance disparities between proprietary and open-weight models.  					AI-generated summary 				 Evaluating progress in large language models (LLMs) is often constrained by the ...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 21. NeuroAda is a parameter-efficient fine-tuning method that combines selective adaptation with bypass connections to achieve high performance with minimal trainable parameters and reduced memory usage.  					AI-generated summary 				 Existing parameter-efficient fine-tuning (PEFT) methods primarily fa...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 22. Chart2Code is a hierarchical benchmark for evaluating the chart understanding and code generation capabilities of large multimodal models, featuring three levels of increasing complexity and diverse real-world scenarios.  					AI-generated summary 				 We introduce Chart2Code, a new benchmark for ev...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 23. Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal pre-training, yet their static representations struggle to maintain an accurate understanding of time-sensitive factual knowledge. Existing benchmarks remain constrained by static designs, inadequately evaluating LMMs' abil...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 24. RIR-Mega is a large dataset of simulated room impulse responses with tools for validation and a baseline model for predicting RT60 from waveforms.  					AI-generated summary 				 Room impulse responses are a core resource for dereverberation, robust speech recognition, source localization, and room ...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 25. AlphaOPT is a self-improving library that enables an LLM to learn from limited demonstrations and solver feedback, improving optimization modeling across industries without costly retraining.  					AI-generated summary 				 Optimization modeling enables critical decisions across industries but remai...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 26. The Orthogonal Diversity-Aware Selection (ODiS) algorithm enhances large language model performance by ensuring both quality and diversity in training data through orthogonal decomposition of evaluation dimensions.  					AI-generated summary 				 High-quality pre-training data is crutial for large l...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 27. Adaptive Patch Transformers (APT) improve Vision Transformer (ViT) efficiency by using variable patch sizes, enhancing speed without compromising performance.  					AI-generated summary 				 Vision Transformers (ViTs) partition input images into uniformly sized patches regardless of their content, r...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 28. Transformers struggle with generalizable algorithms, preferring heuristics; a disentangled Transformer can learn graph algorithms within its capacity but resorts to heuristics otherwise.  					AI-generated summary 				 Transformers often fail to learn generalizable algorithms, instead relying on bri...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 29. SeeTok, a vision-centric method, renders text as images and uses pretrained multimodal LLMs to interpret them, offering efficiency and robustness improvements over traditional subword tokenization.  					AI-generated summary 				 People see text. Humans read by recognizing words as visual objects, i...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 30. Rendering text as images reduces token usage for decoder LLMs without compromising performance on tasks like long-context retrieval and document summarization.  					AI-generated summary 				 Large language models (LLMs) and their multimodal variants can now process visual inputs, including images o...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 31. A dataset of user questions for household robots is introduced, providing insights into the types of questions users ask and the information robots need to answer, supporting the development of conversational interfaces and explanation strategies.  					AI-generated summary 				 With the growing use...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 32. DeLeaker mitigates semantic leakage in text-to-image models by dynamically reweighting attention maps during the diffusion process, outperforming existing methods without compromising quality.  					AI-generated summary 				 Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerabl...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 33. Theoretical and empirical investigation shows strong transferability between membership inference attacks and machine-generated text detection, highlighting the need for cross-task collaboration and introducing MINT for unified evaluation.  					AI-generated summary 				 Although membership inferenc...
[24.10.2025 00:49] ********************************************************************************
[24.10.2025 00:49] Abstract 34. SAVANT, a structured reasoning framework using VLMs, achieves high accuracy and recall in detecting anomalous driving scenarios through layered scene analysis and multi-modal evaluation.  					AI-generated summary 				 Autonomous driving systems remain critically vulnerable to the long-tail of rare,...
[24.10.2025 00:49] Read previous papers.
[24.10.2025 00:49] Generating reviews via LLM API.
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#architecture", "#training", "#long_context", "#benchmark", "#inference", "#optimization"], "emoji": "💍", "ru": {"title": "Гибридное внимание для эффективного вывода на длинных контекстах", "desc": "Серия моделей Ring-linear использует гибридную архитектуру, комбинирующую линейное и
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#rl", "#optimization", "#training", "#rlhf"], "emoji": "⚖️", "ru": {"title": "Балансировка градиентов для стабильного обучения LLM через RL", "desc": "Статья представляет метод BAPO для обучения больших языковых моделей с помощью reinforcement learning в off-policy режиме. Авторы вы
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#training", "#rl", "#long_context", "#reasoning"], "emoji": "🔗", "ru": {"title": "Обучение LLM длинному рассуждению через цепочки UUID", "desc": "LoongRL — это метод reinforcement learning для улучшения рассуждений над длинными контекстами в больших языковых моделях. Ключевая идея —
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#interpretability", "#math", "#architecture", "#training", "#security"], "emoji": "🔄", "ru": {"title": "Трансформеры обратимы: восстановление входных данных из скрытых состояний", "desc": "Исследователи доказали, что transformer language models являются инъективными функциями, то ес
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#architecture", "#diffusion", "#interpretability"], "emoji": "🌊", "ru": {"title": "Динамические паттерны внимания в диффузионных языковых моделях", "desc": "Исследователи изучили механизмы внимания в Masked Diffusion Language Models (DLM) — новом классе языковых моделей, которые ген
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#small_models", "#agi", "#transfer_learning", "#agents", "#optimization", "#3d", "#training", "#reasoning"], "emoji": "🤖", "ru": {"title": "Обучение роботов на синтетических данных из world model", "desc": "GigaBrain-0 - это VLA-модель (Vision-Language-Action) для обучения роботов, 
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#games", "#optimization", "#rlhf", "#cv", "#training", "#rl"], "emoji": "🎓", "ru": {"title": "Компактные VLM учатся у гигантов через reinforcement и imitation learning", "desc": "Статья представляет алгоритм Unified Reinforcement and Imitation Learning (RIL) для создания эффективных
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#training", "#dataset", "#video", "#data", "#agents", "#optimization", "#transfer_learning"], "emoji": "🎥", "ru": {"title": "Обучение AI-агентов на YouTube видео вместо ручной разметки", "desc": "Исследователи создали VideoAgentTrek — систему, которая автоматически извлекает данные 
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#survey", "#training", "#architecture", "#dataset", "#data", "#benchmark", "#multimodal", "#optimization"], "emoji": "📱", "ru": {"title": "DaMo: умная оптимизация данных для AI-агентов на смартфонах", "desc": "DaMo - это обучаемая нейросеть, которая оптимизирует состав обучающих дан
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#multimodal", "#synthetic", "#alignment", "#reasoning"], "emoji": "🍌", "ru": {"title": "Pico-Banana-400K: масштабный датасет для обучения редактированию изображений по текстовым инструкциям", "desc": "Статья представляет Pico-Banana-400K — датасет из 400 ты
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#rl", "#dataset", "#benchmark", "#open_source", "#synthetic", "#optimization", "#cv"], "emoji": "📄", "ru": {"title": "OCR нового поколения через обучение с подкреплением на unit-тестах", "desc": "Представлена модель olmOCR 2 на базе vision language model с 7 миллиардами параметров д
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#video", "#games", "#reasoning", "#benchmark"], "emoji": "🎯", "ru": {"title": "Сегментация видео через внимание без переобучения", "desc": "Исследователи предложили метод DecAF для видео сегментации объектов, который использует карты внимания из мульт
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#architecture"], "emoji": "📊", "ru": {"title": "AI-аналитик создаёт финансовые отчёты профессионального уровня", "desc": "FinSight — это мультиагентный фреймворк для автоматической генерации профессиональных финансовых отчётов с графиками и аналитикой. Сист
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#optimization", "#training", "#benchmark", "#reasoning", "#multimodal", "#transfer_learning"], "emoji": "🧭", "ru": {"title": "Перенос знаний в пространстве градиентов для улучшения рассуждений", "desc": "DRIFT — это легковесный метод для улучшения способности к рассуждениям у мульти
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#rl", "#games", "#benchmark", "#security", "#agents", "#open_source", "#optimization"], "emoji": "🤖", "ru": {"title": "ColorAgent: умный OS-агент с обучением через взаимодействие", "desc": "ColorAgent — это AI-агент для операционной системы Android, способный выполнять сложные много
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "KORE: инъекция знаний без забывания старого", "desc": "KORE — это метод для внедрения новых знаний в большие мультимодальные модели с сохранением ранее изученной информации. Метод испол
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#low_resource", "#alignment", "#dataset", "#multilingual", "#reasoning"], "emoji": "👥", "ru": {"title": "LLM не понимают человеческие отношения так хорошо, как мы думали", "desc": "Исследователи представили датасет SCRIPTS для оценки способности языковых моделей определять межличнос
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#training", "#video", "#games", "#agents", "#3d", "#optimization"], "emoji": "🚗", "ru": {"title": "Всевидящая world model для автономного вождения с панорамным видео и 3D-наградами", "desc": "OmniNWM — это универсальная world model для автономного вождения, которая одновременно гене
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#reasoning"], "emoji": "🔧", "ru": {"title": "Тысячи инструментов — испытание для AI-агентов", "desc": "Исследователи представили TheMCPCompany — бенчмарк для оценки AI-агентов, использующих инструменты через REST API для взаимодействия с реальными сервисами.
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#audio", "#interpretability", "#open_source", "#data", "#optimization", "#inference"], "emoji": "🎹", "ru": {"title": "Точное управление музыкальными моделями через внутренние активации", "desc": "MusicRFM использует Recursive Feature Machines для управления предобученными музыкальны
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#data", "#science", "#open_source", "#dataset", "#benchmark"], "emoji": "🎓", "ru": {"title": "ProfBench: даже лучшие LLM справляются только на 66% с профессиональными задачами", "desc": "Исследователи представили ProfBench - бенчмарк для оценки больших языковых моделей в профессиона
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#open_source", "#small_models", "#training", "#optimization"], "emoji": "🔀", "ru": {"title": "NeuroAda: тонкая настройка нейросетей через обходные пути для важных параметров", "desc": "NeuroAda — это метод эффективной тонкой настройки (PEFT), который объединяет селективную адаптацию
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#open_source", "#reasoning", "#multimodal", "#interpretability", "#optimization", "#benchmark", "#games"], "emoji": "📊", "ru": {"title": "Научить AI создавать графики — сложнее, чем кажется", "desc": "Chart2Code — это иерархический бенчмарк для оценки способностей больших мультимода
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#open_source", "#reasoning"], "emoji": "⏰", "ru": {"title": "MINED: учим мультимодальные модели понимать время", "desc": "Статья представляет MINED — новый бенчмарк для оценки способности больших мультимодальных моделей (LMM) понимать знания, чувствитель
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#dataset", "#data", "#open_source", "#science"], "emoji": "🔊", "ru": {"title": "Мега-датасет импульсных откликов помещений для акустических исследований", "desc": "Представлен RIR-Mega — крупный датасет симулированных импульсных откликов помещений (room impulse responses), который и
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#interpretability", "#dataset", "#transfer_learning", "#optimization", "#rlhf", "#training"], "emoji": "📚", "ru": {"title": "Библиотека опыта для самообучения LLM в оптимизационном моделировании", "desc": "AlphaOPT — это самообучающаяся библиотека опыта, которая позволяет LLM автома
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#benchmark", "#transfer_learning", "#optimization", "#dataset", "#data", "#training"], "emoji": "⊥", "ru": {"title": "Ортогональность измерений для разнообразия обучающих данных LLM", "desc": "Алгоритм ODiS улучшает качество обучающих данных для больших языковых моделей путём одновр
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#cv", "#inference", "#training"], "emoji": "🧩", "ru": {"title": "Умные патчи: больше скорости, меньше токенов", "desc": "Adaptive Patch Transformers (APT) улучшают эффективность Vision Transformer за счёт использования патчей разного размера в одном
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#architecture", "#graphs", "#optimization", "#training"], "emoji": "🔗", "ru": {"title": "Трансформеры учат алгоритмы только в пределах своих возможностей", "desc": "Исследование показывает, что Transformer-модели часто не могут выучить обобщаемые алгоритмы и вместо этого полагаются 
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#multimodal", "#cv", "#optimization", "#low_resource", "#data"], "emoji": "👁️", "ru": {"title": "Чтение текста глазами: когда LLM видит слова как картинки", "desc": "SeeTok представляет новый подход к обработке текста в языковых моделях, преобразуя текст в изображения вместо традици
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#optimization", "#data", "#multimodal"], "emoji": "🖼️", "ru": {"title": "Текст как картинка: новый способ сжатия входных данных для LLM", "desc": "Исследователи предложили необычный метод сжатия текстовых входных данных для декодерных LLM: преобразовыв
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#alignment", "#agents", "#multimodal", "#interpretability", "#dataset", "#benchmark"], "emoji": "🤖", "ru": {"title": "Что люди хотят спросить у домашних роботов", "desc": "Исследователи создали датасет из 1893 вопросов, которые люди задают домашним роботам, собранных от 100 участник
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#optimization", "#cv", "#inference", "#leakage", "#benchmark", "#dataset"], "emoji": "🔒", "ru": {"title": "DeLeaker: устранение семантической утечки в генерации изображений через управление вниманием", "desc": "Исследователи представили DeLeaker — метод борьбы с семантической утечко
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#data", "#transfer_learning", "#benchmark", "#multimodal"], "emoji": "🔄", "ru": {"title": "Два в одном: атаки на приватность и детекция AI-текста используют одни методы", "desc": "Исследование показывает сильную взаимосвязь между атаками на определение членства в обучающей выборке (
[24.10.2025 00:49] Using data from previous issue: {"categories": ["#open_source", "#cv", "#dataset", "#reasoning", "#training", "#multimodal"], "emoji": "🚗", "ru": {"title": "SAVANT: Структурированный анализ аномалий для автономного вождения", "desc": "SAVANT — это фреймворк для обнаружения редких и аномальных дорожных ситуаций с использованием Vis
[24.10.2025 00:49] Renaming data file.
[24.10.2025 00:49] Renaming previous data. hf_papers.json to ./d/2025-10-24.json
[24.10.2025 00:49] Saving new data file.
[24.10.2025 00:49] Generating page.
[24.10.2025 00:49] Renaming previous page.
[24.10.2025 00:49] Renaming previous data. index.html to ./d/2025-10-24.html
[24.10.2025 00:49] Writing result.
[24.10.2025 00:49] Renaming log file.
[24.10.2025 00:49] Renaming previous data. log.txt to ./logs/2025-10-24_last_log.txt
