[10.02.2026 18:58] Read previous papers.
[10.02.2026 18:58] Generating top page (month).
[10.02.2026 18:58] Writing top page (month).
[10.02.2026 19:58] Read previous papers.
[10.02.2026 19:58] Get feed.
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07085
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08794
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07026
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08222
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06855
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07845
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08676
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06422
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09007
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08439
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06025
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07962
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08543
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09022
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08990
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07055
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07075
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.03784
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08658
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06540
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06454
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08808
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08236
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07775
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06694
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.00169
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07796
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08145
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2601.21363
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.09003
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08961
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06445
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08829
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07803
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06942
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.06600
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08818
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07970
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07491
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07150
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07120
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07090
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07080
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05929
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05708
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07054
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07040
[10.02.2026 19:58] Extract page data from URL. URL: https://huggingface.co/papers/2602.02827
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08629
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08004
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07948
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.05946
[10.02.2026 19:58] Get page data from previous paper. URL: https://huggingface.co/papers/2602.02285
[10.02.2026 19:58] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[10.02.2026 19:58] No deleted papers detected.
[10.02.2026 19:58] Downloading and parsing papers (pdf, html). Total: 53.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07085.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07085.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07085.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08794.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08794.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08794.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07026.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07026.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07026.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08222.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08222.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08222.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06855.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06855.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06855.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07845.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07845.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07845.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08676.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08676.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08676.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06422.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06422.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06422.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.09007.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.09007.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.09007.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08439.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08439.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08439.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06025.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06025.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06025.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07962.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07962.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07962.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08543.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08543.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08543.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.09022.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.09022.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.09022.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08990.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08990.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08990.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07055.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07055.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07055.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07075.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07075.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07075.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.03784.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.03784.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.03784.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08658.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08658.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08658.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06540.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06540.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06540.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06454.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06454.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06454.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08808.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08808.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08808.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08236.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08236.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08236.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07775.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07775.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07775.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06694.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06694.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06694.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.00169.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.00169.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.00169.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07796.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07796.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07796.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08145.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08145.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08145.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2601.21363.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2601.21363.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2601.21363.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.09003.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.09003.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.09003.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08961.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08961.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08961.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06445.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06445.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06445.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08829.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08829.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08829.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07803.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07803.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07803.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06942.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06942.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06942.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.06600.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.06600.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.06600.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08818.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08818.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08818.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07970.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07970.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07970.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07491.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07491.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07491.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07150.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07150.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07150.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07120.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07120.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07120.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07090.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07090.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07090.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07080.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07080.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07080.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.05929.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.05929.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.05929.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.05708.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.05708.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.05708.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07054.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07054.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07054.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07040.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07040.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07040.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.02827.
[10.02.2026 19:58] Downloading paper 2602.02827 from https://arxiv.org/pdf/2602.02827v1...
[10.02.2026 19:58] Extracting affiliations from text.
[10.02.2026 19:58] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval Roi Pony 1 Adi Raz 1 Oshri Naparstek 1 Idan Friedman 1 Udi Barzelay "
[10.02.2026 19:58] Response: ```python
[]
```
[10.02.2026 19:58] Extracting affiliations from text.
[10.02.2026 19:58] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval Roi Pony 1 Adi Raz 1 Oshri Naparstek 1 Idan Friedman 1 Udi BarzelayMulti-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, query-time pruning algorithm that reduces this computational burden by casting reranking as finite-population Top-K identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time. 6 2 0 2 2 ] . [ 1 7 2 8 2 0 . 2 0 6 2 : r 1. Introduction Multi-vector such as Collate-interaction retrievers, BERT (Khattab & Zaharia, 2020), have emerged as powerful alternative to single-vector dense retrieval. By representing each query and document as set of token embeddings, these models capture fine-grained semantic matches that single-vector representations miss (Wang et al., 2023; Formal et al., 2021). This paradigm has been widely adopted 1IBM Research Israel. Correspondence to: Roi Pony <roi.pony@ibm.com>. Preprint. February 4, 2026. 1 in recent text and multimodal systems (Faysse et al., 2024; Team, 2025a; Warner et al., 2025; Team, 2025b; Xu et al., 2025; Gunther et al., 2025), becoming standard foundation for high-accuracy neural retrieval. However, this granularity comes with cost. Unlike single-vector retrieval, where scoring is cheap dot product, exact late interaction requires evaluating grid of token-level operations (MaxSim) for every document. Consequently, this computation often becomes the bottleneck in modern pipelines, motivating methods that reduce these operations without sacrificing ranking fidelity (Santhanam et al., 2022a; Engels et al., 2023). The Hiring Analogy. To build intuition for the inefficiency of standard late interaction, consider manager hiring the top-K candidates from applicants. Each applicant takes short tests, and their final score is the sum of the results. Administering all tests to every applicant guarantees the correct shortlist, but it is wasteful. resource-efficient manager would allocate tests adaptively, giving few to everyone and focusing the remaining budget on the candidates whose ranking is unclear, stopping once the top-K is statistically certain. Standard late-interaction retrieval mirrors this wasteful strategy. It sums tokenwise interactions for every document, even though partial evaluation often suffices to rule documents out (or in). The Opportunity: Removing Redundancy. In the vectorset setting, the total score is sum of independent components. NaÄ±vely, systems evaluate the full sum for every candidate in the pool D. However, for any specific query, we do not need to know the exact score of document that is clearly irrelevant, nor do we need perfect precision for clear winner. We only need enough information to distinguish the true Top-K documents from the rest. This implies that the computational budget should be spent asymmetrically, heavily on the borderline cases and sparsely on everything else. Our Approach: Col-Bandit. We propose viewing this resource allocation problem as progressive matrix completion. We treat the token-level scores as values in table that can be revealed on-demand. Our objective is to reveal just enough cells to confidently identify the Top-K set, minimizing computation while maintaining user-defined level of statistical reliability (Figure 1). To this end, we introduce Col-Bandit, purely query-time Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval Figure 1. Schematic of Col-Bandit. Given query (e.g., human mobility...) and set of candidate documents (e.g., Nature, Auto), the goal is to identify the Top-2 relevant documents. (A) Full ColBERT determines the exact score for every document by summing all interaction cells (MaxSims), requiring 100% of the compute budget. (B) Col-Bandit approximates these sums using partial cell observations. By adaptively revealing informative cells (green) and skipping others (hatched), it maintains confidence intervals for the total score. The algorithm terminates as soon as positive separation gap emerges: the Lower Bound of the weakest winner (Sports) is strictly higher than the Upper Bound of the strongest loser (Auto). This enables the identification of the correct Top-K ranking while saving 60% of the query-time computations. algorithm that operates directly on vanilla ColBERT. Unlike prior acceleration methods that require quantization or distilling document representations, Col-Bandit works on top of standard indices and model weights, requiring no index-time changes and no retraining. We formulate the task as finite-population Top-K identification problem. By exploiting the fact that document token sequences are finite, we utilize Serfling-type concentration inequalities (Bardenet & Maillard, 2015) to construct tighter confidence intervals than standard bandit approaches. We further introduce calibration parameter to optimize the trade-off between theoretical certification and practical FLOP reduction. Contributions. Formulation: We cast late-interaction reranking as finite-population Top-K identification problem using progressive scoring framework. Algorithm: We introduce Col-Bandit, Lower-Upper Confidence Bound (LUCB) (Kalyanakrishnan et al., 2012) style algorithm that leverages variance-adaptive Serfling bounds for tighter estimation and tunable relaxation parameter for efficiency. Drop-in Acceleration: We demonstrate substantial FLOP reductions on s"
[10.02.2026 19:58] Mistral response. {"id": "82ceed33730a49b48ccc8819feeaa3cc", "created": 1770753517, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1449, "total_tokens": 1459, "completion_tokens": 10, "num_cached_tokens": 1448}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"IBM Research Israel\"]\n```"}}]}
[10.02.2026 19:58] Response: ```python
["IBM Research Israel"]
```
[10.02.2026 19:58] Deleting PDF ./assets/pdf/2602.02827.pdf.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08629.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08629.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08629.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.08004.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.08004.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.08004.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.07948.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.07948.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.07948.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.05946.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.05946.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.05946.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Downloading and parsing paper https://huggingface.co/papers/2602.02285.
[10.02.2026 19:58] Extra JSON file exists (./assets/json/2602.02285.json), skip PDF parsing.
[10.02.2026 19:58] Paper image links file exists (./assets/img_data/2602.02285.json), skip HTML parsing.
[10.02.2026 19:58] Success.
[10.02.2026 19:58] Enriching papers with extra data.
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 0. Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated exper...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 1. MOVA is an open-source model that generates synchronized audio-visual content using a Mixture-of-Experts architecture with 32 billion parameters, supporting image-text to video-audio generation tasks.  					AI-generated summary 				 Audio is indispensable for real-world video, yet generation models ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 2. Researchers address the modality gap in multimodal learning by proposing a fixed-frame theory and a training-free alignment method that enables efficient scaling of multimodal models using unpaired data.  					AI-generated summary 				 Despite the success of multimodal contrastive learning in aligni...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 3. WMSS is a post-training paradigm that uses weak model checkpoints to identify and fill learning gaps, enabling continued improvement beyond conventional saturation points in large language models.  					AI-generated summary 				 As post-training optimization becomes central to improving large langua...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 4. AIRS-Bench presents a comprehensive benchmark suite for evaluating LLM agents across diverse scientific domains, demonstrating current limitations while providing open-source resources for advancing autonomous scientific research.  					AI-generated summary 				 LLM agents hold significant promise f...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 5. RD-VLA introduces a recurrent architecture for vision-language-action models that adapts computational depth through latent iterative refinement, achieving constant memory usage and improved task success rates.  					AI-generated summary 				 Current Vision-Language-Action (VLA) models rely on fixed...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 6. LLaDA2.1 introduces a novel token-to-token editing approach with speed and quality modes, enhanced through reinforcement learning for improved reasoning and instruction following in large language diffusion models.  					AI-generated summary 				 While LLaDA2.0 showcased the scaling potential of 100...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 7. TP-GRPO addresses reward sparsity in flow matching models by introducing step-level incremental rewards and identifying turning points to capture long-term effects in denoising trajectories.  					AI-generated summary 				 Deploying GRPO on Flow Matching models has proven effective for text-to-image...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 8. A new benchmark and evaluation metric are introduced for assessing temporal coherence and dynamic interaction in GUI generation models, revealing significant challenges in maintaining consistency over extended interaction sequences.  					AI-generated summary 				 Recent advancements in image genera...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 9. Researchers introduce a new video understanding task and benchmark that evaluates models' ability to learn from few-shot demonstrations, along with a specialized MLLM architecture trained using a two-stage approach combining video supervision and preference optimization.  					AI-generated summary 	...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 10. BudgetMem is a runtime memory framework for LLM agents that uses modular components with three budget tiers and a neural policy router to optimize performance-cost trade-offs in memory usage.  					AI-generated summary 				 Memory is increasingly central to Large Language Model (LLM) agents operatin...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 11. LOCA-bench is introduced as a benchmark for evaluating language agents in long-context, agentic scenarios with controlled environment state management.  					AI-generated summary 				 Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as th...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 12. A new benchmark called GISA is introduced for evaluating information-seeking assistants, featuring human-crafted queries with structured answer formats and live updates to prevent memorization.  					AI-generated summary 				 The advancement of large language models (LLMs) has significantly accelera...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 13. WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms.  					AI-generated summary 				 This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training fr...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 14. InternAgent-1.5 is a unified system for autonomous scientific discovery that integrates computational modeling and experimental research through coordinated subsystems for generation, verification, and evolution.  					AI-generated summary 				 We introduce InternAgent-1.5, a unified system designed...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 15. Current multimodal foundation models show limitations in maintaining coherent spatial beliefs during active exploration, exhibiting gaps between active and passive performance, inefficient exploration strategies, and difficulties in updating outdated spatial knowledge.  					AI-generated summary 			...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 16. LatentChem enables chemical reasoning through continuous latent space computations instead of discrete textual tokens, achieving superior performance and efficiency compared to traditional chain-of-thought approaches.  					AI-generated summary 				 Chemical large language models (LLMs) predominantl...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 17. ComprExIT introduces a novel approach to long-context inference in LLMs by using explicit information transmission over frozen hidden states, improving compression efficiency through depth-wise and width-wise transmission mechanisms.  					AI-generated summary 				 Long-context inference with Large ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 18. Research investigates how fundamental reasoning paradigms influence large language model generalization through targeted training approaches and evaluation on real-world tasks.  					AI-generated summary 				 Deduction, induction, and abduction are fundamental reasoning paradigms, core for human log...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 19. AgentCPM-Report presents a lightweight local solution for deep research report generation using a Writing As Reasoning Policy framework and multi-stage agentic training to enhance small models' reasoning and outline evolution capabilities.  					AI-generated summary 				 Generating deep research rep...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 20. RelayGen is a training-free framework that dynamically switches between large and small models during reasoning by identifying difficulty transitions at the segment level, achieving faster inference with minimal accuracy loss.  					AI-generated summary 				 Large reasoning models (LRMs) achieve str...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 21. A scalable framework for evaluating and improving goal-conditioned procedure generation using large-scale web mining, automated scoring, and reinforcement learning to enhance step-by-step instruction quality.  					AI-generated summary 				 Generating step-by-step "how-to" procedures is a key LLM ca...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 22. Adaptive test-time framework with world models enables selective visual imagination for spatial reasoning, improving efficiency and reliability by determining when imagination is necessary.  					AI-generated summary 				 Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spa...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 23. Autoregressive video diffusion models suffer from train-test gaps when generating long videos, but a training-free approach called Rolling Sink addresses this by maintaining AR cache and enabling ultra-long video synthesis.  					AI-generated summary 				 Recently, autoregressive (AR) video diffusio...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 24. NanoQuant enables efficient post-training quantization of large language models to binary and sub-1-bit levels using low-rank binary factorization and ADMM optimization, achieving state-of-the-art accuracy while reducing memory requirements for consumer hardware deployment.  					AI-generated summar...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 25. AI-driven materials science integrates large language models across discovery pipelines from data curation to agent-based experimentation, emphasizing system-level optimization and autonomous goal pursuit.  					AI-generated summary 				 The convergence of artificial intelligence and materials scien...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 26. Explicit reasoning in LLM agents can degrade performance in user-engaged scenarios by reducing information disclosure and weakening agent-user communication, with transparency-aware prompting showing better results.  					AI-generated summary 				 Eliciting reasoning has emerged as a powerful techni...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 27. Foundation models including LLMs, MLLMs, and generative models require reliable and responsible development addressing bias, security, explainability, and other critical issues for trustworthy deployment across multiple domains.  					AI-generated summary 				 Foundation models, including Large Lang...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 28. Off-policy Soft Actor-Critic with large-batch updates enables efficient humanoid locomotion policy pretraining, while model-based methods facilitate safe adaptation through deterministic data collection and stochastic exploration within physics-informed world models.  					AI-generated summary 				 ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 29. Large language models are increasingly guiding data management processes through a tiered framework that optimizes data quality, cost, and training efficiency across different stages of model development.  					AI-generated summary 				 The development of artificial intelligence can be viewed as an ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 30. MotionCrafter is a video diffusion framework that jointly reconstructs 4D geometry and estimates dense motion using a novel joint representation and 4D VAE architecture.  					AI-generated summary 				 We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometr...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 31. Energy-constrained optimization framework separates energy metrics from rewards using Lagrangian method to achieve stable, energy-efficient humanoid robot locomotion with reduced hyperparameter tuning.  					AI-generated summary 				 Achieving stable and energy-efficient locomotion is essential for ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 32. WildReward demonstrates that reward models can be effectively trained from in-the-wild user interactions using ordinal regression, achieving performance comparable to traditional methods while benefiting from user diversity.  					AI-generated summary 				 Reward models (RMs) are crucial for the tra...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 33. A high-quality open-source singing voice synthesis system is presented with support for multiple languages and controllable generation, along with a dedicated benchmark for evaluating zero-shot performance.  					AI-generated summary 				 While recent years have witnessed rapid progress in speech sy...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 34. A comprehensive study of Turkish subword tokenization systematically investigates the relationship between vocabulary size, training corpus, and tokenizer performance across multiple linguistic tasks and diagnostics.  					AI-generated summary 				 Tokenization is a pivotal design choice for neural ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 35. Large reasoning models exhibit spontaneous question repetition patterns that can be formalized and leveraged to improve computational efficiency and accuracy through echo-aware training and prompting techniques.  					AI-generated summary 				 Test-time compute allocation in large reasoning models (...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 36. FlexMoRE demonstrates that low-rank adapters can replace full-sized experts in mixture-of-experts architectures, achieving better performance with significantly fewer parameters.  					AI-generated summary 				 Recent advances in mixture-of-experts architectures have shown that individual experts mo...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 37. Research explores PDE solvers including neural frameworks for scientific simulations, examining forward solutions, inverse problems, and equation discovery across multi-variable and non-linear systems.  					AI-generated summary 				 Partial Differential Equations are precise in modelling the physic...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 38. A multi-agent framework guided by knowledge graphs addresses materials science challenges by integrating specialized agents for problem decomposition, evidence retrieval, and graph traversal to discover sustainable PFAS alternatives.  					AI-generated summary 				 Large Language Models (LLMs) promi...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 39. Analysis of agentic system evaluation reveals significant variance in single-run performance estimates, necessitating multiple runs and advanced metrics for reliable assessment.  					AI-generated summary 				 Agentic systems are evaluated on benchmarks where agents interact with environments to sol...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 40. Anchor decoding suppresses verbatim copying in language models while maintaining fluency and factual accuracy through constrained generation that balances risk and utility.  					AI-generated summary 				 Modern language models (LMs) tend to memorize portions of their training data and emit verbatim...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 41. SPARSE is a user-centric framework that protects text embeddings from privacy leaks by selectively perturbing sensitive dimensions using differentiable masking and Mahalanobis noise calibration.  					AI-generated summary 				 Text embeddings enable numerous NLP applications but face severe privacy ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 42. LLM code verification can be achieved through internal neural dynamics analysis, identifying structural signatures that distinguish correct reasoning from logical failures in computational circuits.  					AI-generated summary 				 Current paradigms for code verification rely heavily on external mech...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 43. KV-CoRE method evaluates kv-cache compressibility through SVD-based low-rank approximation, revealing patterns linking compressibility to model architecture and training data across multiple languages and domains.  					AI-generated summary 				 Large language models rely on kv-caches to avoid redun...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 44. CE-RAG4EM reduces computational overhead in large-scale entity matching by implementing blocking-based batch retrieval and generation while maintaining competitive matching quality.  					AI-generated summary 				 Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tas...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 45. A benchmark and optimization technique are presented to improve multimodal large language models' emotion understanding by addressing spurious associations and hallucinations in audiovisual cues.  					AI-generated summary 				 Emotion understanding is essential for building socially intelligent age...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 46. Aster is an AI agent that accelerates scientific discovery by iteratively improving programs, achieving state-of-the-art results across multiple domains including mathematics, biology, and machine learning with significantly reduced computational requirements.  					AI-generated summary 				 We intr...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 47. Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy.  					AI-generated summary 				 Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-a...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 48. CauScale is a neural architecture that enables efficient causal discovery on large graphs through compressed embeddings and tied attention weights, achieving high accuracy and significant speedups over previous methods.  					AI-generated summary 				 Causal discovery is essential for advancing data...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 49. Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they ...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 50. Collective motion in fish schools exemplifies emergent self-organization in active matter systems, yet computational tools for simulating and analyzing these dynamics remain fragmented across research groups. We present dewi-kadita, an open-source Python library implementing the three-dimensional Co...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 51. Preference alignment objectives are extended to general alignment settings using f-divergence variational representations, introducing novel on-policy and hybrid policy optimization methods for LLM alignment with theoretical and empirical validation.  					AI-generated summary 				 Recent research s...
[10.02.2026 19:58] ********************************************************************************
[10.02.2026 19:58] Abstract 52. A comprehensive formalization of statistical learning theory in Lean 4 addresses gaps in mathematical libraries and demonstrates human-AI collaboration for verified machine learning theory foundations.  					AI-generated summary 				 We present the first comprehensive Lean 4 formalization of statist...
[10.02.2026 19:58] Read previous papers.
[10.02.2026 19:58] Generating reviews via LLM API.
[10.02.2026 19:58] Using data from previous issue: {"categories": [], "emoji": "ð¹", "ru": {"title": "Ð­Ð²Ð¾Ð»ÑÑÐ¸Ð¾Ð½Ð½ÑÐ¹ Ð¿Ð¾Ð¸ÑÐº ÑÐ¾ÑÐ³Ð¾Ð²ÑÑ ÑÐ°ÐºÑÐ¾ÑÐ¾Ð² ÑÐµÑÐµÐ· Ð¾Ð¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ñ ÑÑÐ°ÐµÐºÑÐ¾ÑÐ¸Ð¹", "desc": "QuantaAlpha Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ ÑÐ²Ð¾Ð»ÑÑÐ¸Ð¾Ð½Ð½ÑÐ¹ ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº Ð´Ð»Ñ Ð°Ð²ÑÐ¾Ð¼Ð°ÑÐ¸Ð·Ð¸ÑÐ¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð°Ð»ÑÑÐ°-ÑÐ°ÐºÑÐ¾ÑÐ¾Ð² Ð½Ð° ÑÐ¸Ð½Ð°Ð½ÑÐ¾Ð²ÑÑ ÑÑÐ½ÐºÐ°Ñ, ÐºÐ¾ÑÐ¾ÑÑÐ¹ ÑÐ°ÑÑÐ¼Ð°ÑÑÐ¸Ð²Ð°ÐµÑ ÐºÐ°Ð¶Ð´ÑÐ¹ ÑÐ¸ÐºÐ» Ð¼Ð°Ð¹Ð½Ð¸Ð½Ð³Ð° ÐºÐ°Ðº ÑÑÐ°ÐµÐºÑÐ¾ÑÐ¸Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#inference", "#video", "#audio", "#dataset", "#architecture", "#open_source", "#multimodal"], "emoji": "ð¬", "ru": {"title": "Ð¡Ð¾Ð²Ð¼ÐµÑÑÐ½Ð°Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð°ÑÐ´Ð¸Ð¾ Ñ Ð¾Ð´Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»ÑÑ", "desc": "MOVA â ÑÑÐ¾ Ð¾ÑÐºÑÑÑÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ Ð´Ð»Ñ ÑÐ¸Ð½ÑÐµÐ·Ð° Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð°ÑÐ´Ð¸Ð¾ Ñ Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÐ¾Ð¹ Mixture-of-Experts, ÑÐ¾Ð´ÐµÑÐ¶Ð°Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#training", "#multimodal", "#architecture"], "emoji": "ð", "ru": {"title": "ÐÑÑÐ°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´Ð°Ð»ÑÐ½Ð¾ÑÑÐµÐ¹ Ð±ÐµÐ· Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ Ð¼Ð°ÑÑÑÐ°Ð±Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ Ð¼ÑÐ»ÑÑÐ¸Ð¼Ð¾Ð´Ð°Ð»ÑÐ½ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "ÐÑÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»Ð¸ ÑÐµÑÐ¸Ð»Ð¸ Ð¿ÑÐ¾Ð±Ð»ÐµÐ¼Ñ Ð½ÐµÑÐ¾Ð¾ÑÐ²ÐµÑÑÑÐ²Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñ Ð¼Ð¾Ð´Ð°Ð»ÑÐ½Ð¾ÑÑÑÐ¼Ð¸ Ð² Ð¼ÑÐ»ÑÑÐ¸Ð¼Ð¾Ð´Ð°Ð»ÑÐ½Ð¾Ð¼ Ð¾Ð±ÑÑÐµÐ½Ð¸Ð¸, Ð¿ÑÐµÐ´Ð»Ð¾Ð¶
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#reasoning", "#optimization"], "emoji": "ð", "ru": {"title": "Ð¡Ð»Ð°Ð±ÑÐµ ÐºÐ¾Ð½ÑÑÐ¾Ð»ÑÐ½ÑÐµ ÑÐ¾ÑÐºÐ¸ ÐºÐ°Ðº Ð¿ÑÑÑ Ðº ÑÐ¸Ð»ÑÐ½ÑÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑÑÑ WMSS â Ð½Ð¾Ð²Ð°Ñ Ð¿Ð°ÑÐ°Ð´Ð¸Ð³Ð¼Ð° Ð¿Ð¾ÑÑÐ¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, ÐºÐ¾ÑÐ¾ÑÐ°Ñ Ð¿ÑÐµÐ¾Ð´Ð¾Ð»ÐµÐ²Ð°ÐµÑ Ð¿ÑÐ¾Ð±Ð»ÐµÐ¼Ñ Ð½Ð°ÑÑÑÐµÐ½Ð¸Ñ, Ð²Ð¾Ð·Ð½Ð¸ÐºÐ°ÑÑÑÑ Ð¿ÑÐ¸ ÑÑÐ°Ð½Ð´Ð°ÑÑÐ½Ð¾Ð¼ Ð¾
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#agents", "#open_source", "#survey", "#science", "#benchmark", "#dataset"], "emoji": "ð§ª", "ru": {"title": "ÐÐµÑÐ¸Ð»Ð¾ Ð´Ð»Ñ Ð°Ð²ÑÐ¾Ð½Ð¾Ð¼Ð½ÑÑ Ð½Ð°ÑÑÐ½ÑÑ Ð°Ð³ÐµÐ½ÑÐ¾Ð²", "desc": "ÐÐ²ÑÐ¾ÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÑÑ AIRS-Bench â ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½ÑÐ¹ Ð½Ð°Ð±Ð¾Ñ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐºÐ¾Ð² Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑÐµÐ¹ LLM Ð°Ð³ÐµÐ½ÑÐ¾Ð² Ð² Ð½Ð°ÑÑÐ½ÑÑ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸ÑÑ. ÐÐµÐ½Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#inference", "#training", "#robotics", "#architecture", "#multimodal"], "emoji": "ð¤", "ru": {"title": "ÐÐ´Ð°Ð¿ÑÐ¸Ð²Ð½ÑÐµ Ð²ÑÑÐ¸ÑÐ»ÐµÐ½Ð¸Ñ Ð²Ð¼ÐµÑÑÐ¾ ÑÐ¸ÐºÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð³Ð»ÑÐ±Ð¸Ð½Ñ: ÑÐºÑÑÑÐ¾Ðµ ÑÑÐ¾ÑÐ½ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ robotics", "desc": "RD-VLA Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ ÑÐµÐºÑÑÑÐµÐ½ÑÐ½ÑÑ Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÑ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ vision-language-action, ÐºÐ¾ÑÐ¾Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#alignment", "#benchmark", "#architecture", "#open_source", "#reasoning", "#diffusion", "#plp"], "emoji": "â¡", "ru": {"title": "ÐÐ°Ð»Ð°Ð½ÑÐ¸ÑÐ¾Ð²ÐºÐ° ÑÐºÐ¾ÑÐ¾ÑÑÐ¸ Ð¸ ÐºÐ°ÑÐµÑÑÐ²Ð° Ð² Ð´Ð¸ÑÑÑÐ·Ð¸Ð¾Ð½Ð½ÑÑ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑÑ ÑÐµÑÐµÐ· T2T ÑÐµÐ´Ð°ÐºÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð¾Ð±ÑÑÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼",
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization"], "emoji": "ð¯", "ru": {"title": "Ð¢Ð¾ÑÐ½ÑÐµ Ð²Ð¾Ð·Ð½Ð°Ð³ÑÐ°Ð¶Ð´ÐµÐ½Ð¸Ñ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑÐ°Ð³Ðµ Ð´Ð»Ñ Ð»ÑÑÑÐµÐ³Ð¾ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸", "desc": "TP-GRPO ÑÐµÑÐ°ÐµÑ Ð¿ÑÐ¾Ð±Ð»ÐµÐ¼Ñ ÑÐ°Ð·ÑÐµÐ¶ÐµÐ½Ð½Ð¾ÑÑÐ¸ Ð²Ð¾Ð·Ð½Ð°Ð³ÑÐ°Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð² Ð¼Ð¾Ð´ÐµÐ»ÑÑ flow matching Ð¿ÑÑÑÐ¼ Ð²Ð²ÐµÐ´ÐµÐ½Ð¸Ñ Ð¿Ð¾ÑÐ°Ð³Ð¾Ð²ÑÑ Ð¸Ð½ÐºÑÐµÐ¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÑ Ð²Ð¾Ð·Ð½Ð°Ð³ÑÐ°Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð²Ð¼ÐµÑÑÐ¾ Ð¸ÑÐ¾Ð³Ð¾Ð²Ð¾Ð³
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#benchmark", "#cv", "#dataset"], "emoji": "ð¥ï¸", "ru": {"title": "ÐÑÐµÐ½ÐºÐ° Ð²ÑÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ ÐºÐ¾Ð³ÐµÑÐµÐ½ÑÐ½Ð¾ÑÑÐ¸ Ð² Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð²Ð½ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑÑ Ð¸Ð½ÑÐµÑÑÐµÐ¹ÑÐ¾Ð²", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½ Ð½Ð¾Ð²ÑÐ¹ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº GEBench Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ Ð³ÑÐ°ÑÐ¸ÑÐµÑÐºÐ¸Ñ Ð¸Ð½ÑÐµÑÑÐµÐ¹ÑÐ¾Ð², ÑÐ¾Ð´ÐµÑÐ¶Ð°ÑÐ¸Ð¹ 700 ÑÑÐ°ÑÐµÐ»ÑÐ½Ð¾ Ð¾ÑÐ¾Ð±ÑÐ°Ð½Ð½ÑÑ Ð¿ÑÐ¸Ð¼ÐµÑÐ¾
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#training", "#video", "#benchmark", "#dataset", "#multimodal", "#rlhf"], "emoji": "ð¥", "ru": {"title": "ÐÐ±ÑÑÐµÐ½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð½Ð° Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¸Ñ Ð¿ÑÐ¸Ð¼ÐµÑÐ°Ñ ÑÐµÑÐµÐ· ÐºÐ¾Ð½ÑÐµÐºÑÑÐ½ÑÐµ Ð´ÐµÐ¼Ð¾Ð½ÑÑÑÐ°ÑÐ¸Ð¸", "desc": "ÐÑÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»Ð¸ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÑÑ Ð½Ð¾Ð²ÑÑ Ð·Ð°Ð´Ð°ÑÑ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑÐ¸ Ð¼Ð¾
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization", "#rl", "#agents", "#long_context", "#training"], "emoji": "âï¸", "ru": {"title": "ÐÐ½ÑÐµÐ»Ð»ÐµÐºÑÑÐ°Ð»ÑÐ½Ð¾Ðµ ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐµÑÑÑÑÐ¾Ð² Ð¿Ð°Ð¼ÑÑÐ¸ Ð´Ð»Ñ Ð°Ð³ÐµÐ½ÑÐ¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "desc": "BudgetMem â ÑÑÐ¾ ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº Ð´Ð»Ñ ÑÐ¿ÑÐ°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð°Ð¼ÑÑÑÑ LLM-Ð°Ð³ÐµÐ½ÑÐ¾Ð² Ð²Ð¾ Ð²ÑÐµÐ¼Ñ Ð²ÑÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ,
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#agents", "#long_context", "#open_source", "#benchmark"], "emoji": "ð", "ru": {"title": "Ð£Ð¿ÑÐ°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð»Ð¸Ð½Ð½ÑÐ¼ ÐºÐ¾Ð½ÑÐµÐºÑÑÐ¾Ð¼ Ð² ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð°Ð³ÐµÐ½ÑÐ°Ñ ÑÐµÑÐµÐ· ÐºÐ¾Ð½ÑÑÐ¾Ð»Ð¸ÑÑÐµÐ¼Ð¾Ðµ ÑÐ¾ÑÑÐ¾ÑÐ½Ð¸Ðµ Ð¾ÐºÑÑÐ¶ÐµÐ½Ð¸Ñ", "desc": "ÐÐ²ÐµÐ´ÐµÐ½Ð° Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº LOCA-bench Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð°Ð³ÐµÐ½ÑÐ¾Ð² Ð² ÑÑÐµÐ½Ð°ÑÐ¸ÑÑ Ñ Ð´Ð»Ð¸Ð½Ð½ÑÐ¼ ÐºÐ¾Ð½ÑÐµÐºÑÑÐ¾Ð¼ Ð¸ ÑÐ¿
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#dataset", "#survey", "#agents"], "emoji": "ð", "ru": {"title": "GISA: Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²ÑÑ Ð°Ð³ÐµÐ½ÑÐ¾Ð² Ñ ÐµÑÑÐµÑÑÐ²ÐµÐ½Ð½ÑÐ¼Ð¸ Ð·Ð°Ð´Ð°ÑÐ°Ð¼Ð¸ Ð¸ Ð¶Ð¸Ð²ÑÐ¼Ð¸ Ð´Ð°Ð½Ð½ÑÐ¼Ð¸", "desc": "ÐÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½ Ð½Ð¾Ð²ÑÐ¹ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº GISA Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ Ð¸Ð½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¾Ð½Ð½Ð¾-Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²ÑÑ Ð°ÑÑÐ¸ÑÑÐµÐ½ÑÐ¾Ð², ÑÐ¾Ð´ÐµÑÐ¶Ð°ÑÐ¸Ð¹ 37
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#training", "#video", "#rl"], "emoji": "ð§­", "ru": {"title": "ÐÐ°Ð¿ÑÐ°Ð²Ð»ÑÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾-Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¼Ð¸ÑÐ°: Ð¾Ð±ÑÑÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ ÑÐ¾ÑÐ½Ð¾Ð³Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ", "desc": "WorldCompass Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ ÑÐ¾Ð±Ð¾Ð¹ ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº Ð´Ð»Ñ Ð¿Ð¾ÑÑ-Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾-Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¼Ð¸ÑÐ° Ñ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼. ÐÐ²ÑÐ¾ÑÑ Ð²Ð²
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#science", "#reasoning", "#benchmark", "#open_source", "#agents"], "emoji": "ð§¬", "ru": {"title": "ÐÐ²ÑÐ¾Ð½Ð¾Ð¼Ð½Ð°Ñ Ð½Ð°ÑÑÐ½Ð°Ñ ÑÐ¸ÑÑÐµÐ¼Ð° Ð´Ð»Ñ Ð¾ÑÐºÑÑÑÐ¸Ð¹ ÑÐµÑÐµÐ· ÐºÐ¾Ð¾ÑÐ´Ð¸Ð½Ð°ÑÐ¸Ñ Ð²ÑÑÐ¸ÑÐ»ÐµÐ½Ð¸Ð¹ Ð¸ ÑÐºÑÐ¿ÐµÑÐ¸Ð¼ÐµÐ½ÑÐ¾Ð²", "desc": "InternAgent-1.5 â ÑÑÐ¾ ÐµÐ´Ð¸Ð½Ð°Ñ ÑÐ¸ÑÑÐµÐ¼Ð° Ð´Ð»Ñ Ð°Ð²ÑÐ¾Ð½Ð¾Ð¼Ð½Ð¾Ð³Ð¾ Ð½Ð°ÑÑÐ½Ð¾Ð³Ð¾ Ð¾ÑÐºÑÑÑÐ¸Ñ, ÐºÐ¾ÑÐ¾ÑÐ°Ñ Ð¾Ð±ÑÐµÐ´Ð¸Ð½ÑÐµ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#multimodal", "#robotics"], "emoji": "ðºï¸", "ru": {"title": "ÐÐ³ÐµÐ½ÑÑ Ð½Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÑÑ Ð¿ÑÐ¾ÑÑÑÐ°Ð½ÑÑÐ²Ð¾: Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑÐ¸ÐºÐ° ÑÐ»Ð°Ð±Ð¾ÑÑÐµÐ¹ Ð°ÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² foundation models", "desc": "ÐÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÐºÐ°Ð·ÑÐ²Ð°ÐµÑ, ÑÑÐ¾ ÑÐ¾Ð²ÑÐµÐ¼ÐµÐ½Ð½ÑÐµ Ð¼ÑÐ»ÑÑÐ¸Ð¼Ð¾Ð´Ð°Ð»ÑÐ½ÑÐµ foundation models Ð¿Ð»Ð¾ÑÐ¾ ÑÐ¿ÑÐ°Ð²Ð»ÑÑ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#science", "#reasoning"], "emoji": "âï¸", "ru": {"title": "Ð¥Ð¸Ð¼Ð¸ÑÐµÑÐºÐ¸Ðµ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² ÑÐºÑÑÑÐ¾Ð¼ Ð¿ÑÐ¾ÑÑÑÐ°Ð½ÑÑÐ²Ðµ Ð²Ð¼ÐµÑÑÐ¾ ÑÐµÐºÑÑÐ¾Ð²ÑÑ ÑÐµÐ¿Ð¾ÑÐµÐº Ð¼ÑÑÐ»Ð¸", "desc": "LatentChem Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ Ð½Ð¾Ð²ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº ÑÐ¸Ð¼Ð¸ÑÐµÑÐºÐ¾Ð¼Ñ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ, Ð¸ÑÐ¿Ð¾Ð»ÑÐ·ÑÑ Ð½ÐµÐ¿ÑÐµÑÑÐ²Ð½ÑÐµ Ð²ÑÑÐ¸ÑÐ»ÐµÐ½Ð¸Ñ Ð² ÑÐºÑÑÑÐ¾Ð¼ Ð¿ÑÐ¾ÑÑÑÐ°Ð½ÑÑÐ²Ðµ Ð²Ð¼ÐµÑÑÐ¾ Ð´Ð¸ÑÐºÑÐµÑÐ½ÑÑ Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#inference", "#benchmark"], "emoji": "ð¦", "ru": {"title": "Ð¯Ð²Ð½Ð°Ñ Ð¿ÐµÑÐµÐ´Ð°ÑÐ° Ð¸Ð½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¸ Ð´Ð»Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ ÑÐ¶Ð°ÑÐ¸Ñ ÐºÐ¾Ð½ÑÐµÐºÑÑÐ°", "desc": "ComprExIT Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ Ð½Ð¾Ð²ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº ÑÐ¶Ð°ÑÐ¸Ñ ÐºÐ¾Ð½ÑÐµÐºÑÑÐ° Ð² Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑÑ, Ð¸ÑÐ¿Ð¾Ð»ÑÐ·ÑÑÑÐ¸Ð¹ ÑÐ²Ð½ÑÑ Ð¿ÐµÑÐµÐ´Ð°ÑÑ Ð¸Ð½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¸
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#benchmark", "#training", "#reasoning", "#synthetic", "#dataset"], "emoji": "ð§ ", "ru": {"title": "Ð¢ÑÐ¸ ÑÐ¸Ð¿Ð° Ð»Ð¾Ð³Ð¸ÐºÐ¸ â Ð¾Ð´Ð¸Ð½ ÐºÐ»ÑÑ Ðº Ð¾Ð±Ð¾Ð±ÑÐµÐ½Ð¸Ñ LLM", "desc": "Ð ÑÑÐ¾Ð¼ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð°Ð²ÑÐ¾ÑÑ Ð¸Ð·ÑÑÐ°ÑÑ, ÐºÐ°Ðº ÑÑÐ¸ ÑÑÐ½Ð´Ð°Ð¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÑ ÑÐ¸Ð¿Ð° Ð»Ð¾Ð³Ð¸ÑÐµÑÐºÐ¾Ð³Ð¾ Ð¼ÑÑÐ»ÐµÐ½Ð¸Ñ â Ð´ÐµÐ´ÑÐºÑÐ¸Ñ, Ð¸Ð½Ð´ÑÐºÑÐ¸Ñ Ð¸ Ð°Ð±Ð´ÑÐºÑÐ¸Ñ â Ð²Ð»Ð¸ÑÑÑ Ð½Ð° 
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#training", "#small_models", "#open_source", "#rl", "#agents", "#reasoning", "#benchmark"], "emoji": "ð", "ru": {"title": "Ð Ð°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð²Ð¾ Ð²ÑÐµÐ¼Ñ Ð¿Ð¸ÑÑÐ¼Ð°: Ð¼Ð°Ð»ÑÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÐºÐ°ÑÐµÑÑÐ²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»ÑÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°", "desc": "AgentCPM-Report Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð»ÑÐ³ÐºÐ¾Ðµ Ð»Ð¾ÐºÐ°Ð»ÑÐ½Ð¾Ðµ ÑÐµÑÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð³ÐµÐ½Ðµ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#inference", "#training", "#small_models", "#optimization", "#reasoning"], "emoji": "â¡", "ru": {"title": "ÐÐ¸Ð½Ð°Ð¼Ð¸ÑÐµÑÐºÐ¾Ðµ Ð¿ÐµÑÐµÐºÐ»ÑÑÐµÐ½Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ð´Ð»Ñ ÑÑÐºÐ¾ÑÐµÐ½Ð¸Ñ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ð¹", "desc": "RelayGen â ÑÑÐ¾ ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº Ð´Ð»Ñ Ð¾Ð¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð¸Ð½ÑÐµÑÐµÐ½ÑÐ° Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, ÐºÐ¾ÑÐ¾ÑÑÐ¹ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÑÐµÑÐºÐ¸ Ð¿Ðµ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#synthetic", "#dataset", "#benchmark", "#open_source", "#reasoning"], "emoji": "ð", "ru": {"title": "ÐÐ°ÐºÑÑÑÑÐ¹ ÑÐ¸ÐºÐ» Ð¾ÑÐµÐ½ÐºÐ¸ Ð¸ ÑÐ»ÑÑÑÐµÐ½Ð¸Ñ Ð¸Ð½ÑÑÑÑÐºÑÐ¸Ð¹ ÑÐµÑÐµÐ· Ð¾Ð±ÑÑÐµÐ½Ð¸Ðµ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ð° How2Everything - Ð¼Ð°ÑÑÑÐ°Ð±Ð¸ÑÑÐµÐ¼Ð°Ñ ÑÐ¸ÑÑÐµ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#inference", "#multimodal", "#cv", "#benchmark"], "emoji": "ð¯", "ru": {"title": "ÐÐ·Ð±Ð¸ÑÐ°ÑÐµÐ»ÑÐ½Ð¾Ðµ Ð²Ð¾Ð¾Ð±ÑÐ°Ð¶ÐµÐ½Ð¸Ðµ: ÐºÐ¾Ð³Ð´Ð° Ð²Ð¸Ð´ÐµÑÑ Ð½ÑÐ¶Ð½Ð¾, Ð° ÐºÐ¾Ð³Ð´Ð° Ð½ÐµÑ", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¸ÑÑÐ»ÐµÐ´ÑÐµÑÑÑ Ð¿ÑÐ¾Ð±Ð»ÐµÐ¼Ð° Ð¿ÑÐ¾ÑÑÑÐ°Ð½ÑÑÐ²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð¼Ð½Ð¾Ð³Ð¾Ð¼Ð¾Ð´Ð°Ð»ÑÐ½ÑÑ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑÑ, ÐºÐ¾ÑÐ¾ÑÑÐµ ÑÐ°ÑÑÐ¾ Ð¾ÑÐ¸Ð±Ð°ÑÑÑÑ Ð¿ÑÐ¸ Ð½
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#inference", "#training", "#video", "#long_context", "#diffusion"], "emoji": "ð¬", "ru": {"title": "ÐÐµÑÐ¿ÑÐ¾Ð±Ð»ÐµÐ¼Ð½Ð¾Ðµ ÑÐ°ÑÑÐ¸ÑÐµÐ½Ð¸Ðµ Ð°Ð²ÑÑÐµÐ³ÑÐµÑÑÐ¸Ð²Ð½ÑÑ Ð²Ð¸Ð´ÐµÐ¾Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð¾ ÑÐ²ÐµÑÑÐ´Ð»Ð¸Ð½Ð½ÑÑ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»ÑÐ½Ð¾ÑÑÐµÐ¹ Ð±ÐµÐ· Ð¿ÐµÑÐµÐ¾Ð±ÑÑÐµÐ½Ð¸Ñ", "desc": "Ð ÑÑÐ°ÑÑÐµ ÑÐ°ÑÑÐ¼Ð°ÑÑÐ¸Ð²Ð°ÐµÑÑÑ Ð¿ÑÐ¾Ð±Ð»ÐµÐ¼Ð° Ð½ÐµÑÐ¾Ð¾ÑÐ²ÐµÑÑÑÐ²Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñ Ð¾Ð±ÑÑÐµÐ½Ð¸ÐµÐ¼ Ð¸
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization"], "emoji": "âï¸", "ru": {"title": "Ð­ÐºÑÑÑÐµÐ¼Ð°Ð»ÑÐ½Ð¾Ðµ ÑÐ¶Ð°ÑÐ¸Ðµ Ð±Ð¾Ð»ÑÑÐ¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: Ð¿ÑÑÑ Ðº ÑÐ°Ð·Ð²ÐµÑÑÑÐ²Ð°Ð½Ð¸Ñ Ð½Ð° Ð¿Ð¾ÑÑÐµÐ±Ð¸ÑÐµÐ»ÑÑÐºÐ¸Ñ ÑÑÑÑÐ¾Ð¹ÑÑÐ²Ð°Ñ", "desc": "NanoQuant â ÑÑÐ¾ Ð½Ð¾Ð²ÑÐ¹ Ð¼ÐµÑÐ¾Ð´ Ð¿Ð¾ÑÑÐ¾Ð±ÑÑÐ°ÑÑÐµÐ³Ð¾ ÐºÐ²Ð°Ð½ÑÐ¾Ð²Ð°Ð½Ð¸Ñ, ÐºÐ¾ÑÐ¾ÑÑÐ¹ ÑÐ¶Ð¸Ð¼Ð°ÐµÑ Ð±Ð¾Ð»ÑÑÐ¸Ðµ ÑÐ·ÑÐºÐ¾Ð²ÑÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð¾ Ð±Ð¸Ð½Ð°ÑÐ½Ð¾Ð³Ð¾ (1-Ð±Ð¸Ñ) Ð¸ ÑÑÐ±Ð±Ð¸Ð½Ð°ÑÐ½Ð¾Ð³Ð¾ Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#benchmark", "#training", "#survey", "#science", "#optimization", "#agents", "#data"], "emoji": "ð§ª", "ru": {"title": "ÐÑ Ð¸Ð·Ð¾Ð»Ð¸ÑÐ¾Ð²Ð°Ð½Ð½ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ðº Ð°Ð²ÑÐ¾Ð½Ð¾Ð¼Ð½ÑÐ¼ Ð°Ð³ÐµÐ½ÑÐ°Ð¼: LLM Ð´Ð»Ñ ÑÑÐºÐ¾ÑÐµÐ½Ð¸Ñ Ð¾ÑÐºÑÑÑÐ¸Ñ Ð½Ð¾Ð²ÑÑ Ð¼Ð°ÑÐµÑÐ¸Ð°Ð»Ð¾Ð²", "desc": "Ð ÑÑÐ°ÑÑÐµ ÑÐ°ÑÑÐ¼Ð°ÑÑÐ¸Ð²Ð°ÐµÑÑÑ Ð¸Ð½ÑÐµÐ³ÑÐ°ÑÐ¸Ñ Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (L
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#alignment", "#agents", "#reasoning", "#benchmark", "#open_source", "#training"], "emoji": "ð¤", "ru": {"title": "ÐÐ¾Ð»ÑÐ°Ð½Ð¸Ðµ Ð·Ð¾Ð»Ð¾ÑÐ¾? ÐÐ¾ÑÐµÐ¼Ñ ÑÐ²Ð½Ð¾Ðµ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð¾ÑÐ»Ð°Ð±Ð»ÑÐµÑ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸Ðµ Ð°Ð³ÐµÐ½ÑÐ° Ñ Ð¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°ÑÐµÐ»ÐµÐ¼", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¸ÑÑÐ»ÐµÐ´ÑÐµÑÑÑ Ð²Ð»Ð¸ÑÐ½Ð¸Ðµ ÑÐ²Ð½Ð¾Ð³Ð¾ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² LLM Ð°Ð³ÐµÐ½ÑÐ°Ñ, Ð²Ð·Ð°Ð¸Ð¼Ð¾
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#security", "#alignment", "#ethics", "#hallucinations", "#survey", "#interpretability"], "emoji": "ð¡ï¸", "ru": {"title": "ÐÑÑÑ Ðº Ð½Ð°Ð´ÐµÐ¶Ð½ÑÐ¼ Ð¸ Ð¾ÑÐ²ÐµÑÑÑÐ²ÐµÐ½Ð½ÑÐ¼ ÑÑÐ½Ð´Ð°Ð¼ÐµÐ½ÑÐ°Ð»ÑÐ½ÑÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼", "desc": "Ð ÑÑÐ¾Ð¼ Ð¾Ð±Ð·Ð¾ÑÐµ ÑÐ°ÑÑÐ¼Ð°ÑÑÐ¸Ð²Ð°ÑÑÑÑ ÐºÑÐ¸ÑÐ¸ÑÐµÑÐºÐ¸Ðµ Ð°ÑÐ¿ÐµÐºÑÑ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾Ð¹ Ð¸ Ð¾ÑÐ²ÐµÑÑÑÐ²ÐµÐ½Ð½Ð¾Ð¹ ÑÐ°Ð·ÑÐ°Ð±Ð¾ÑÐºÐ¸ ÑÑÐ½Ð´Ð°Ð¼ÐµÐ½Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#training", "#robotics", "#rl"], "emoji": "ð¤", "ru": {"title": "Ð­ÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ðµ Ð¿ÑÐµÐ´Ð²Ð°ÑÐ¸ÑÐµÐ»ÑÐ½Ð¾Ðµ Ð¾Ð±ÑÑÐµÐ½Ð¸Ðµ Ð¸ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð°Ð´Ð°Ð¿ÑÐ°ÑÐ¸Ñ Ð³ÑÐ¼Ð°Ð½Ð¾Ð¸Ð´Ð¾Ð² ÑÐµÑÐµÐ· off-policy Ð¾Ð±ÑÑÐµÐ½Ð¸Ðµ Ñ ÑÑÐ¸Ð»ÐµÐ½Ð¸ÐµÐ¼", "desc": "ÐÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÐºÐ°Ð·ÑÐ²Ð°ÐµÑ, ÑÑÐ¾ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼ Soft Actor-Critic Ñ Ð±Ð¾Ð»ÑÑÐ¸Ð¼ ÑÐ°Ð·Ð¼ÐµÑÐ¾Ð¼ Ð±Ð°ÑÑÐ° Ð¸ Ð²ÑÑÐ¾ÐºÐ¸Ð¼ ÐºÐ¾ÑÑÑÐ¸ÑÐ¸
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#training", "#open_source", "#alignment", "#agi", "#optimization", "#data"], "emoji": "ð", "ru": {"title": "ÐÐ°Ð½Ð½ÑÐµ Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ°ÑÑÑÑ Ð²Ð¼ÐµÑÑÐµ: Ð¼Ð½Ð¾Ð³Ð¾ÑÑÐ¾Ð²Ð½ÐµÐ²Ð¾Ðµ ÑÐ¿ÑÐ°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ AGI", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¿ÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ Ð½Ð¾Ð²ÑÑ Ð¿Ð°ÑÐ°Ð´Ð¸Ð³Ð¼Ñ ÑÐ¾Ð²Ð¼ÐµÑÑÐ½Ð¾Ð¹ ÑÐ²Ð¾Ð»ÑÑÐ¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¸ Ð´Ð°Ð½Ð½ÑÑ, Ð³Ð´Ðµ ÑÐ·ÑÐºÐ¾Ð²ÑÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð°ÐºÑÐ¸Ð²Ð½Ð¾
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#diffusion", "#video", "#architecture", "#3d", "#training"], "emoji": "ð¬", "ru": {"title": "Ð¡Ð¾Ð²Ð¼ÐµÑÑÐ½Ð°Ñ ÑÐµÐºÐ¾Ð½ÑÑÑÑÐºÑÐ¸Ñ Ð³ÐµÐ¾Ð¼ÐµÑÑÐ¸Ð¸ Ð¸ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ ÑÐµÑÐµÐ· 4D Ð´Ð¸ÑÑÑÐ·Ð¸Ñ", "desc": "MotionCrafter â ÑÑÐ¾ ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð´Ð¸ÑÑÑÐ·Ð¸Ð¾Ð½Ð½ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, ÐºÐ¾ÑÐ¾ÑÑÐ¹ Ð¾Ð´Ð½Ð¾Ð²ÑÐµÐ¼ÐµÐ½Ð½Ð¾ ÑÐµÐºÐ¾Ð½ÑÑÑÑÐ¸ÑÑÐµÑ 4D Ð³ÐµÐ¾Ð¼ÐµÑÑÐ¸Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization", "#robotics", "#rl"], "emoji": "ð¤", "ru": {"title": "ÐÐ¿ÑÐ¸Ð¼Ð¸Ð·Ð°ÑÐ¸Ñ ÑÐ½ÐµÑÐ³Ð¾Ð¿Ð¾ÑÑÐµÐ±Ð»ÐµÐ½Ð¸Ñ ÑÐµÑÐµÐ· ÑÐ²Ð½ÑÐµ Ð¾Ð³ÑÐ°Ð½Ð¸ÑÐµÐ½Ð¸Ñ Ð²Ð¼ÐµÑÑÐ¾ ÑÑÑÐ°ÑÐ¾Ð² Ð² Ð½Ð°Ð³ÑÐ°Ð´Ðµ", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð° ECO (Energy-Constrained Optimization) â ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð´ÐºÑÐµÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼, ÐºÐ¾ÑÐ¾ÑÑÐ¹ Ð¾ÑÐ´ÐµÐ»ÑÐµÑ ÑÐ½ÐµÑÐ³ÐµÑÐ¸ÑÐµÑÐº
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#dataset", "#training", "#rlhf", "#data"], "emoji": "ð", "ru": {"title": "ÐÐ±ÑÑÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð²Ð¾Ð·Ð½Ð°Ð³ÑÐ°Ð¶Ð´ÐµÐ½Ð¸Ñ Ð½Ð° ÑÐµÐ°Ð»ÑÐ½ÑÑ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸ÑÑ Ð¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°ÑÐµÐ»ÐµÐ¹", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½ WildReward â Ð¼Ð¾Ð´ÐµÐ»Ñ Ð²Ð¾Ð·Ð½Ð°Ð³ÑÐ°Ð¶Ð´ÐµÐ½Ð¸Ñ, ÐºÐ¾ÑÐ¾ÑÐ°Ñ Ð¾Ð±ÑÑÐ°ÐµÑÑÑ Ð½Ð° ÑÐµÐ°Ð»ÑÐ½ÑÑ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸ÑÑ Ð¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°ÑÐµÐ»ÐµÐ¹ Ñ ÑÐ·ÑÐºÐ¾
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#low_resource", "#audio", "#dataset", "#benchmark", "#open_source", "#multilingual"], "emoji": "ð¤", "ru": {"title": "ÐÑÐºÑÑÑÐ°Ñ ÑÐ¸ÑÑÐµÐ¼Ð° ÑÐ¸Ð½ÑÐµÐ·Ð° Ð¿ÐµÐ²ÑÐµÑÐºÐ¾Ð³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ° Ñ ÑÐ½Ð¸Ð²ÐµÑÑÐ°Ð»ÑÐ½Ð¾Ð¹ Ð¿Ð¾Ð´Ð´ÐµÑÐ¶ÐºÐ¾Ð¹ ÑÐ·ÑÐºÐ¾Ð² Ð¸ Ð½Ð°Ð´ÑÐ¶Ð½Ð¾Ð¹ Ð¾ÑÐµÐ½ÐºÐ¾Ð¹ Ð¿ÑÐ¾Ð¸Ð·Ð²Ð¾Ð´Ð¸ÑÐµÐ»ÑÐ½Ð¾ÑÑÐ¸", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ð° SoulX-Singer â Ð²ÑÑ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#open_source", "#interpretability", "#multilingual", "#low_resource", "#data", "#benchmark"], "emoji": "ð¤", "ru": {"title": "Ð¡Ð¸ÑÑÐµÐ¼Ð°ÑÐ¸ÑÐµÑÐºÐ¾Ðµ Ð¸Ð·ÑÑÐµÐ½Ð¸Ðµ ÑÑÐ±ÑÐ»Ð¾Ð²Ð½Ð¾Ð¹ ÑÐ¾ÐºÐµÐ½Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð´Ð»Ñ Ð¼Ð¾ÑÑÐ¾Ð»Ð¾Ð³Ð¸ÑÐµÑÐºÐ¸ Ð±Ð¾Ð³Ð°ÑÑÑ ÑÐ·ÑÐºÐ¾Ð²", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐ¾Ð²ÐµÐ´ÐµÐ½Ð¾ ÑÐ¸ÑÑÐµÐ¼Ð°ÑÐ¸ÑÐµÑÐºÐ¾Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑÐ±ÑÐ»Ð¾Ð²Ð½Ð¾Ð¹ ÑÐ¾ÐºÐµÐ½Ð¸
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#math", "#training", "#reasoning", "#open_source", "#inference", "#interpretability", "#optimization"], "emoji": "ð", "ru": {"title": "ÐÑÐµÐ²ÑÐ°ÑÐ°ÐµÐ¼ Ð¸Ð½ÑÑÐ¸ÑÐ¸Ð²Ð½Ð¾Ðµ Ð¿Ð¾Ð²ÑÐ¾ÑÐµÐ½Ð¸Ðµ Ð² ÑÐºÐ¾ÑÑ Ð´Ð»Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¸ÑÑÐ»ÐµÐ´ÑÐµÑÑÑ ÑÐ²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¾Ð½ÑÐ°Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð²ÑÐ¾ÑÐµÐ½Ð¸Ñ Ð²Ð¾Ð¿ÑÐ¾ÑÐ° Ð² Ð±Ð¾Ð»Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#reasoning"], "emoji": "ðï¸", "ru": {"title": "ÐÐ¸Ð·ÐºÐ¾ÑÐ°Ð½Ð³Ð¾Ð²ÑÐµ Ð°Ð´Ð°Ð¿ÑÐµÑÑ Ð²Ð¼ÐµÑÑÐ¾ Ð¿Ð¾Ð»Ð½ÑÑ ÑÐºÑÐ¿ÐµÑÑÐ¾Ð² Ð² ÑÐ¼ÐµÑÐ°Ð½Ð½Ð¾Ð¹ Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÐµ", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð° Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÐ° FlexMoRE, ÐºÐ¾ÑÐ¾ÑÐ°Ñ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·ÑÐµÑ Ð½Ð¸Ð·ÐºÐ¾ÑÐ°Ð½Ð³Ð¾Ð²ÑÐµ Ð°Ð´Ð°Ð¿ÑÐµÑÑ Ð²Ð¼ÐµÑÑÐ¾ Ð¿Ð¾Ð»Ð½Ð¾ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÑÐ½Ð½ÑÑ ÑÐºÑÐ¿ÐµÑÑÐ¾Ð² Ð²
[10.02.2026 19:58] Using data from previous issue: {"categories": [], "emoji": "ð§®", "ru": {"title": "ÐÐµÐ¹ÑÐ¾ÑÐµÑÐµÐ²ÑÐµ ÑÐµÑÐ°ÑÐµÐ»Ð¸ ÑÑÐ°Ð²Ð½ÐµÐ½Ð¸Ð¹ Ð² ÑÐ°ÑÑÐ½ÑÑ Ð¿ÑÐ¾Ð¸Ð·Ð²Ð¾Ð´Ð½ÑÑ Ð´Ð»Ñ Ð½Ð°ÑÑÐ½ÑÑ Ð²ÑÑÐ¸ÑÐ»ÐµÐ½Ð¸Ð¹", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¸ÑÑÐ»ÐµÐ´ÑÐµÑ ÑÐ°Ð·Ð»Ð¸ÑÐ½ÑÐµ Ð¼ÐµÑÐ¾Ð´Ñ ÑÐµÑÐµÐ½Ð¸Ñ ÑÑÐ°Ð²Ð½ÐµÐ½Ð¸Ð¹ Ð² ÑÐ°ÑÑÐ½ÑÑ Ð¿ÑÐ¾Ð¸Ð·Ð²Ð¾Ð´Ð½ÑÑ (Ð£Ð§Ð) Ñ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð½ÐµÐ¹ÑÐ¾ÑÐµÑÐµÐ²ÑÑ Ð¿Ð¾Ð´ÑÐ¾Ð´Ð¾Ð² Ð´Ð»Ñ Ð½Ð°ÑÑÐ½ÑÑ ÑÐ¸Ð¼ÑÐ»ÑÑÐ¸Ð¹. ÐÐ²ÑÐ¾ÑÑ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸ÑÑÑÑ Ð¿
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#hallucinations", "#science", "#reasoning"], "emoji": "ð¬", "ru": {"title": "ÐÐ½Ð¾Ð³Ð¾Ð°Ð³ÐµÐ½ÑÐ½Ð¾Ðµ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð½Ð° Ð³ÑÐ°ÑÐ°Ñ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð¾ÑÐºÑÑÑÐ¸Ñ Ð¼Ð°ÑÐµÑÐ¸Ð°Ð»Ð¾Ð²", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ð° Ð¼Ð½Ð¾Ð³Ð¾Ð°Ð³ÐµÐ½ÑÐ½Ð°Ñ ÑÐ¸ÑÑÐµÐ¼Ð°, ÑÐ¿ÑÐ°Ð²Ð»ÑÐµÐ¼Ð°Ñ Ð³ÑÐ°ÑÐ°Ð¼Ð¸ Ð·Ð½Ð°Ð½Ð¸Ð¹, Ð´Ð»Ñ ÑÐµÑÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ Ð¼Ð°ÑÐµÑÐ¸Ð°Ð»Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ. Ð¡Ð¸ÑÑÐµÐ¼Ð° Ð¸Ð½ÑÐµÐ³ÑÐ¸ÑÑÐµÑ 
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#agents", "#benchmark"], "emoji": "ð²", "ru": {"title": "ÐÐ½Ð¾Ð¶ÐµÑÑÐ²ÐµÐ½Ð½ÑÐµ Ð¿ÑÐ¾Ð³Ð¾Ð½Ñ Ð²Ð¼ÐµÑÑÐ¾ Ð¾Ð´Ð½Ð¾Ð³Ð¾: Ð¿ÑÑÑ Ðº Ð½Ð°Ð´ÑÐ¶Ð½Ð¾Ð¹ Ð¾ÑÐµÐ½ÐºÐµ Ð°Ð³ÐµÐ½ÑÐ½ÑÑ ÑÐ¸ÑÑÐµÐ¼", "desc": "Ð ÑÑÐ¾Ð¹ ÑÐ°Ð±Ð¾ÑÐµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°ÑÐµÐ»Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸ÑÑÑÑ Ð½Ð°Ð´ÑÐ¶Ð½Ð¾ÑÑÑ Ð¾ÑÐµÐ½ÐºÐ¸ Ð°Ð³ÐµÐ½ÑÐ½ÑÑ ÑÐ¸ÑÑÐµÐ¼, ÐºÐ¾ÑÐ¾ÑÑÐµ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²ÑÑÑ Ñ Ð¾ÐºÑÑÐ¶ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ ÑÐµÑÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ. ÐÐ½Ð¸ Ð¾Ð±Ð½Ð°Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#open_source", "#security", "#leakage"], "emoji": "ð", "ru": {"title": "Ð¯ÐºÐ¾ÑÐ½Ð¾Ðµ Ð´ÐµÐºÐ¾Ð´Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ: ÐºÐ¾Ð½ÑÑÐ¾Ð»Ð¸ÑÑÐµÐ¼Ð°Ñ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ñ Ð±ÐµÐ· Ð½Ð°ÑÑÑÐµÐ½Ð¸Ñ Ð°Ð²ÑÐ¾ÑÑÐºÐ¸Ñ Ð¿ÑÐ°Ð²", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´Ð»Ð¾Ð¶ÐµÐ½ Ð¼ÐµÑÐ¾Ð´ Anchored Decoding, ÐºÐ¾ÑÐ¾ÑÑÐ¹ Ð¿Ð¾Ð´Ð°Ð²Ð»ÑÐµÑ Ð´Ð¾ÑÐ»Ð¾Ð²Ð½Ð¾Ðµ ÐºÐ¾Ð¿Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð· Ð¾Ð±ÑÑÐ°ÑÑÐ¸Ñ Ð´Ð°Ð½Ð½ÑÑ Ð¿ÑÐ¸ Ð³ÐµÐ½ÐµÑÐ°ÑÐ¸Ð¸ ÑÐµÐºÑÑ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#security", "#leakage"], "emoji": "ð", "ru": {"title": "Ð£Ð¼Ð½Ð°Ñ Ð·Ð°ÑÐ¸ÑÐ° ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²: Ð¸Ð·Ð±Ð¸ÑÐ°ÑÐµÐ»ÑÐ½ÑÐ¹ ÑÑÐ¼ Ð²Ð¼ÐµÑÑÐ¾ ÑÐ»ÐµÐ¿Ð¾Ð³Ð¾", "desc": "SPARSE â ÑÑÐ¾ ÑÑÐµÐ¹Ð¼Ð²Ð¾ÑÐº, Ð·Ð°ÑÐ¸ÑÐ°ÑÑÐ¸Ð¹ ÑÐµÐºÑÑÐ¾Ð²ÑÐµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð¾Ñ ÑÑÐµÑÐµÐº Ð¿ÑÐ¸Ð²Ð°ÑÐ½Ð¾Ð¹ Ð¸Ð½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¸ Ð¿ÑÑÑÐ¼ Ð¸Ð·Ð±Ð¸ÑÐ°ÑÐµÐ»ÑÐ½Ð¾Ð³Ð¾ Ð²Ð¾Ð·Ð¼ÑÑÐµÐ½Ð¸Ñ ÑÑÐ²ÑÑÐ²Ð¸ÑÐµÐ»ÑÐ½ÑÑ Ð¸Ð·Ð¼ÐµÑÐµÐ½Ð¸Ð¹. ÐÐµÑÐ¾Ð´ Ð¸ÑÐ¿Ð¾Ð»Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": [], "emoji": "ð§ ", "ru": {"title": "ÐÐ½ÑÑÑÐµÐ½Ð½Ð¸Ðµ ÑÑÐµÐ¼Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÑÐ°ÑÐºÑÑÐ²Ð°ÑÑ Ð¾ÑÐ¸Ð±ÐºÐ¸ ÐºÐ¾Ð´Ð°", "desc": "Ð ÑÑÐ¾Ð¹ ÑÐ°Ð±Ð¾ÑÐµ Ð¸ÑÑÐ»ÐµÐ´ÑÐµÑÑÑ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑÑ Ð¿ÑÐ¾Ð²ÐµÑÐºÐ¸ ÐºÐ¾ÑÑÐµÐºÑÐ½Ð¾ÑÑÐ¸ ÐºÐ¾Ð´Ð°, Ð³ÐµÐ½ÐµÑÐ¸ÑÑÐµÐ¼Ð¾Ð³Ð¾ ÑÐ·ÑÐºÐ¾Ð²ÑÐ¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸, ÑÐµÑÐµÐ· Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸Ñ Ð²Ð½ÑÑÑÐµÐ½Ð½ÐµÐ¹ Ð½ÐµÐ¹ÑÐ¾Ð½Ð½Ð¾Ð¹ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ¸ Ð²Ð¼ÐµÑÑÐ¾ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²Ð½ÐµÑÐ½Ð¸Ñ Ð¼ÐµÑÐ°Ð½Ð¸Ð·Ð¼Ð¾Ð², ÑÐ°ÐºÐ¸
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#inference", "#optimization", "#long_context", "#multilingual", "#low_resource", "#benchmark"], "emoji": "ð¦", "ru": {"title": "ÐÑÐµÐ½ÐºÐ° Ð½Ð¸Ð·ÐºÐ¾ÑÐ°Ð½Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾ÑÐµÐ½ÑÐ¸Ð°Ð»Ð° KV-ÐºÑÑÐ° Ð² Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑÑ", "desc": "ÐÐ²ÑÐ¾ÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÑÑ Ð¼ÐµÑÐ¾Ð´ KV-CoRE Ð´Ð»Ñ Ð¾ÑÐµÐ½ÐºÐ¸ ÑÐ¶Ð¸Ð¼Ð°ÐµÐ¼Ð¾ÑÑÐ¸ KV-ÐºÑÑÐ° Ð² Ð±Ð¾Ð»ÑÑÐ¸Ñ ÑÐ·
[10.02.2026 19:58] Using data from previous issue: {"categories": [], "emoji": "â¡", "ru": {"title": "Ð­ÑÑÐµÐºÑÐ¸Ð²Ð½ÑÐ¹ RAG Ð´Ð»Ñ ÑÐ¾Ð¿Ð¾ÑÑÐ°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑÑÐ½Ð¾ÑÑÐµÐ¹ Ð² Ð±Ð¾Ð»ÑÑÐ¸Ñ Ð´Ð°Ð½Ð½ÑÑ", "desc": "Ð¡ÑÐ°ÑÑÑ Ð¾Ð¿Ð¸ÑÑÐ²Ð°ÐµÑ CE-RAG4EM, Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÑ Ð´Ð»Ñ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÑÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ñ Ð°ÑÐ³Ð¼ÐµÐ½ÑÐ°ÑÐ¸ÐµÐ¹ Ð¿Ð¾ÐºÐ¾Ð»ÐµÐ½Ð¸Ñ (RAG), ÐºÐ¾ÑÐ¾ÑÐ°Ñ ÑÐ½Ð¸Ð¶Ð°ÐµÑ Ð²ÑÑÐ¸ÑÐ»Ð¸ÑÐµÐ»ÑÐ½ÑÐµ Ð·Ð°ÑÑÐ°ÑÑ Ð¿ÑÐ¸ ÑÐ¾Ð¿Ð¾ÑÑÐ°Ð²Ð»ÐµÐ½Ð¸Ð¸ ÑÑÑÐ½Ð¾ÑÑÐµÐ¹ Ð² Ð±Ð¾Ð»ÑÑÐ¸Ñ Ð¼Ð°ÑÑÑ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#video", "#hallucinations", "#audio", "#benchmark", "#rlhf", "#open_source", "#training"], "emoji": "ð", "ru": {"title": "ÐÑÐµÐ¾Ð´Ð¾Ð»ÐµÐ½Ð¸Ðµ Ð³Ð°Ð»Ð»ÑÑÐ¸Ð½Ð°ÑÐ¸Ð¹: Ð¼ÑÐ»ÑÑÐ¸Ð¼Ð¾Ð´Ð°Ð»ÑÐ½Ð¾Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ÑÐ¼Ð¾ÑÐ¸Ð¹ Ð±ÐµÐ· Ð»Ð¾Ð¶Ð½ÑÑ Ð°ÑÑÐ¾ÑÐ¸Ð°ÑÐ¸Ð¹", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ñ Ð±ÐµÐ½ÑÐ¼Ð°ÑÐº EmoReA
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#science", "#training", "#optimization", "#open_source", "#agents", "#plp"], "emoji": "ð¬", "ru": {"title": "ÐÐ²ÑÐ¾Ð¼Ð°ÑÐ¸Ð·Ð¸ÑÐ¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð½Ð°ÑÑÐ½Ð¾Ðµ Ð¾ÑÐºÑÑÑÐ¸Ðµ ÑÐµÑÐµÐ· Ð¸ÑÐµÑÐ°ÑÐ¸Ð²Ð½Ð¾Ðµ ÑÐ»ÑÑÑÐµÐ½Ð¸Ðµ Ð¿ÑÐ¾Ð³ÑÐ°Ð¼Ð¼", "desc": "Aster â ÑÑÐ¾ AI-Ð°Ð³ÐµÐ½Ñ Ð´Ð»Ñ Ð°Ð²ÑÐ¾Ð½Ð¾Ð¼Ð½Ð¾Ð³Ð¾ Ð½Ð°ÑÑÐ½Ð¾Ð³Ð¾ Ð¾ÑÐºÑÑÑÐ¸Ñ, ÐºÐ¾ÑÐ¾ÑÑÐ¹ Ð¸ÑÐµÑÐ°ÑÐ¸Ð²Ð½Ð¾ ÑÐ»ÑÑÑÐ°ÐµÑ Ð¿ÑÐ¾Ð³ÑÐ°Ð¼
[10.02.2026 19:58] Querying the API.
[10.02.2026 19:58] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy.  					AI-generated summary 				 Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-K identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5times, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.
[10.02.2026 19:58] Response: ```json
{
  "desc": "Col-Bandit â ÑÑÐ¾ Ð°Ð»Ð³Ð¾ÑÐ¸ÑÐ¼ Ð°Ð´Ð°Ð¿ÑÐ¸Ð²Ð½Ð¾Ð¹ Ð¾Ð±ÑÐµÐ·ÐºÐ¸, ÐºÐ¾ÑÐ¾ÑÑÐ¹ ÑÐ½Ð¸Ð¶Ð°ÐµÑ Ð²ÑÑÐ¸ÑÐ»Ð¸ÑÐµÐ»ÑÐ½ÑÐµ Ð·Ð°ÑÑÐ°ÑÑ Ð¿ÑÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð¼Ð½Ð¾Ð³Ð¾Ð²ÐµÐºÑÐ¾ÑÐ½ÑÑ Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²ÑÑ ÑÐ¸ÑÑÐµÐ¼ Ñ Ð¿Ð¾Ð·Ð´Ð½Ð¸Ð¼ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸ÐµÐ¼, ÑÐ°ÐºÐ¸Ñ ÐºÐ°Ðº ColBERT. ÐÐµÑÐ¾Ð´ ÑÐ¾ÑÐ¼ÑÐ»Ð¸ÑÑÐµÑ Ð·Ð°Ð´Ð°ÑÑ Ð¿ÐµÑÐµÑÐ°Ð½Ð¶Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ ÐºÐ°Ðº Ð¿ÑÐ¾Ð±Ð»ÐµÐ¼Ñ Ð²ÑÑÐ²Ð»ÐµÐ½Ð¸Ñ ÑÐ¾Ð¿-K ÑÐ»ÐµÐ¼ÐµÐ½ÑÐ¾Ð² Ð² ÐºÐ¾Ð½ÐµÑÐ½Ð¾Ð¹ ÑÐ¾Ð²Ð¾ÐºÑÐ¿Ð½Ð¾ÑÑÐ¸ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑÐ¶Ð¸Ð²Ð°ÐµÑ Ð³ÑÐ°Ð½Ð¸ÑÑ Ð½ÐµÐ¾Ð¿ÑÐµÐ´ÐµÐ»ÑÐ½Ð½Ð¾ÑÑÐ¸ Ð´Ð»Ñ ÑÐ°ÑÑÐ¸ÑÐ½Ð¾ Ð½Ð°Ð±Ð»ÑÐ´Ð°ÐµÐ¼ÑÑ Ð¾ÑÐµÐ½Ð¾Ðº Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ¾Ð². ÐÐ»Ð³Ð¾ÑÐ¸ÑÐ¼ ÑÐµÐ»ÐµÐºÑÐ¸Ð²Ð½Ð¾ Ð²ÑÑÐ¸ÑÐ»ÑÐµÑ ÑÐ¾Ð»ÑÐºÐ¾ Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼ÑÐµ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸Ñ MaxSim Ð¼ÐµÐ¶Ð´Ñ Ð·Ð°Ð¿ÑÐ¾ÑÐ¾Ð¼ Ð¸ Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ°Ð¼Ð¸ Ð½Ð° Ð»ÐµÑÑ, ÑÐ°Ð·ÑÐµÐ¶Ð¸Ð²Ð°Ñ Ð¼Ð°ÑÑÐ¸ÑÑ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸Ð¹ Ð²Ð¾ Ð²ÑÐµÐ¼Ñ Ð¾Ð±ÑÐ°Ð±Ð¾ÑÐºÐ¸ Ð·Ð°Ð¿ÑÐ¾ÑÐ°. Col-Bandit ÑÐ°Ð±Ð¾ÑÐ°ÐµÑ ÐºÐ°Ðº Ð½ÑÐ»ÐµÐ²Ð°Ñ Ð¿Ð¾ÑÑ-Ð¾Ð±ÑÐ°Ð±Ð¾ÑÐºÐ° Ð±ÐµÐ· Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾ÑÑÐ¸ Ð¿ÐµÑÐµÐ¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð»Ð¸ Ð¼Ð¾Ð´Ð¸ÑÐ¸ÐºÐ°ÑÐ¸Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ°, ÑÐ¾ÐºÑÐ°ÑÐ°Ñ Ð²ÑÑÐ¸ÑÐ»Ð¸ÑÐµÐ»ÑÐ½ÑÐµ Ð¾Ð¿ÐµÑÐ°ÑÐ¸Ð¸ Ð´Ð¾ 5 ÑÐ°Ð· Ð¿ÑÐ¸ ÑÐ¾ÑÑÐ°Ð½ÐµÐ½Ð¸Ð¸ ÐºÐ°ÑÐµÑÑÐ²Ð° ÑÐ°Ð½Ð¶Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ.",
  "emoji": "â¡",
  "title": "Ð£Ð¼Ð½Ð°Ñ Ð¾Ð±ÑÐµÐ·ÐºÐ° Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑÐ²Ð¸Ð¹ Ð´Ð»Ñ Ð±ÑÑÑÑÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° Ð±ÐµÐ· Ð¿Ð¾ÑÐµÑÐ¸ ÐºÐ°ÑÐµÑÑÐ²Ð°"
}
```
[10.02.2026 19:58] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy.  					AI-generated summary 				 Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-K identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5times, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time."

[10.02.2026 19:58] Response: ```python
["RAG", "INFERENCE", "BENCHMARK"]
```
[10.02.2026 19:58] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy.  					AI-generated summary 				 Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-K identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5times, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time."

[10.02.2026 19:58] Response: ```python
['OPTIMIZATION']
```
[10.02.2026 19:58] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Col-Bandit is a novel algorithm designed to enhance the efficiency of multi-vector late-interaction retrieval systems by adaptively reducing unnecessary token-level interactions during query processing. It addresses the high computational costs associated with calculating MaxSim interactions for each candidate document while ensuring that ranking accuracy is preserved. By framing the reranking process as a Top-K identification problem, Col-Bandit intelligently prunes interactions based on uncertainty-aware bounds, revealing only the necessary entries to determine top results. This approach allows it to function as a seamless addition to existing systems without requiring any changes to the index or model retraining, significantly lowering computational demands while maintaining performance.","title":"Efficient Retrieval with Adaptive Pruning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Col-Bandit is a novel algorithm designed to enhance the efficiency of multi-vector late-interaction retrieval systems by adaptively reducing unnecessary token-level interactions during query processing. It addresses the high computational costs associated with calculating MaxSim interactions for each candidate document while ensuring that ranking accuracy is preserved. By framing the reranking process as a Top-K identification problem, Col-Bandit intelligently prunes interactions based on uncertainty-aware bounds, revealing only the necessary entries to determine top results. This approach allows it to function as a seamless addition to existing systems without requiring any changes to the index or model retraining, significantly lowering computational demands while maintaining performance.', title='Efficient Retrieval with Adaptive Pruning'))
[10.02.2026 19:58] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Col-Banditæ¯ä¸ç§å¨å¤åéå»¶è¿äº¤äºæ£ç´¢ä¸­åå°è®¡ç®ææ¬çç®æ³ãå®éè¿å¨æ¥è¯¢å¤çè¿ç¨ä¸­èªéåºå°ä¿®åªä»¤ççº§äº¤äºï¼æ¥ä¿ææåçåç¡®æ§ãä¸ä¼ ç»æ¹æ³ä¸åï¼Col-Banditå¨æ¥è¯¢æ¶å¨æç¨çåäº¤äºç©éµï¼èä¸æ¯ç¦»çº¿ä¿®åªæ´ä¸ªææ¡£æä»¤çãå®éªè¡¨æï¼Col-Banditå¨ä¿ææååç¡®æ§çåæ¶ï¼å¯ä»¥å°MaxSimè®¡ç®éåå°å¤è¾¾5åï¼æ¾ç¤ºåºå¯éçå»¶è¿äº¤äºè¯åä¸­å­å¨æ¾èçåä½ã","title":"Col-Banditï¼é«æçæ¥è¯¢å¤çä¸åç¡®æå"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Col-Banditæ¯ä¸ç§å¨å¤åéå»¶è¿äº¤äºæ£ç´¢ä¸­åå°è®¡ç®ææ¬çç®æ³ãå®éè¿å¨æ¥è¯¢å¤çè¿ç¨ä¸­èªéåºå°ä¿®åªä»¤ççº§äº¤äºï¼æ¥ä¿ææåçåç¡®æ§ãä¸ä¼ ç»æ¹æ³ä¸åï¼Col-Banditå¨æ¥è¯¢æ¶å¨æç¨çåäº¤äºç©éµï¼èä¸æ¯ç¦»çº¿ä¿®åªæ´ä¸ªææ¡£æä»¤çãå®éªè¡¨æï¼Col-Banditå¨ä¿ææååç¡®æ§çåæ¶ï¼å¯ä»¥å°MaxSimè®¡ç®éåå°å¤è¾¾5åï¼æ¾ç¤ºåºå¯éçå»¶è¿äº¤äºè¯åä¸­å­å¨æ¾èçåä½ã', title='Col-Banditï¼é«æçæ¥è¯¢å¤çä¸åç¡®æå'))
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#science", "#graphs", "#open_source"], "emoji": "ð", "ru": {"title": "ÐÐ°ÑÑÑÐ°Ð±Ð¸ÑÑÐµÐ¼Ð¾Ðµ Ð¾Ð±Ð½Ð°ÑÑÐ¶ÐµÐ½Ð¸Ðµ Ð¿ÑÐ¸ÑÐ¸Ð½Ð½Ð¾ÑÑÐ¸ Ð² Ð±Ð¾Ð»ÑÑÐ¸Ñ Ð³ÑÐ°ÑÐ°Ñ ÑÐµÑÐµÐ· ÐºÐ¾Ð¼Ð¿ÑÐµÑÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð½ÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ð¸Ñ", "desc": "CauScale Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÐµÑ Ð½ÐµÐ¹ÑÐ¾ÑÐµÑÐµÐ²ÑÑ Ð°ÑÑÐ¸ÑÐµÐºÑÑÑÑ Ð´Ð»Ñ ÑÑÑÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ Ð¾Ð±Ð½Ð°ÑÑÐ¶ÐµÐ½Ð¸Ñ Ð¿ÑÐ¸ÑÐ¸Ð½Ð½Ð¾-ÑÐ»ÐµÐ´ÑÑÐ²ÐµÐ½Ð½ÑÑ ÑÐ²ÑÐ·ÐµÐ¹ Ð² Ð±
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#ethics", "#security"], "emoji": "ð ï¸", "ru": {"title": "ÐÐ°ÑÐºÐµÑÐ¿Ð»ÐµÐ¹Ñ Ð½Ð°Ð²ÑÐºÐ¾Ð² Ð´Ð»Ñ AI-Ð°Ð³ÐµÐ½ÑÐ¾Ð²: Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐºÐ¾ÑÐ¸ÑÑÐµÐ¼Ñ, ÑÐ¸ÑÐºÐ¾Ð² Ð¸ ÑÐµÐ½Ð´ÐµÐ½ÑÐ¸Ð¹ ÑÐ¿ÑÐ¾ÑÐ°", "desc": "Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐ¾Ð²Ð¾Ð´Ð¸ÑÑÑ ÐºÑÑÐ¿Ð½Ð¾Ð¼Ð°ÑÑÑÐ°Ð±Ð½ÑÐ¹ Ð°Ð½Ð°Ð»Ð¸Ð· 40 285 Ð¿ÑÐ±Ð»Ð¸ÑÐ½Ð¾ Ð´Ð¾ÑÑÑÐ¿Ð½ÑÑ Ð½Ð°Ð²ÑÐºÐ¾Ð² (skills) Ð´Ð»Ñ LLM-Ð°Ð³ÐµÐ½ÑÐ¾Ð² Ð¸Ð· Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð¼Ð°ÑÐºÐµÑÐ¿Ð»ÐµÐ¹ÑÐ°. ÐÐ²ÑÐ¾Ñ
[10.02.2026 19:58] Using data from previous issue: {"categories": [], "emoji": "ð", "ru": {"title": "Ð­Ð½ÑÑÐ¾Ð¿Ð¸Ñ ÐºÐ°Ðº Ð¼Ð¾ÑÑ Ðº Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ ÐºÐ¾Ð»Ð»ÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ Ð¿Ð¾ÑÑÐ´ÐºÐ° Ð² Ð¿ÑÐ¸ÑÐ¾Ð´Ðµ", "desc": "ÐÐ²ÑÐ¾ÑÑ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÑÑÑ dewi-kadita â Ð¾ÑÐºÑÑÑÑÑ Ð±Ð¸Ð±Ð»Ð¸Ð¾ÑÐµÐºÑ Ð½Ð° Python Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ ÐºÐ¾Ð»Ð»ÐµÐºÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ ÑÑÐ± Ñ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð·Ð¾Ð½Ñ-Ð±Ð°Ð·Ð¸ÑÐ¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Couzin Ð² ÑÑÑÑÐ¼ÐµÑÐ½Ð¾Ð¼ Ð¿ÑÐ¾ÑÑ
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#optimization", "#alignment", "#reasoning"], "emoji": "ð¯", "ru": {"title": "ÐÐ´Ð¸Ð½Ð°Ñ ÑÐ°Ð¼ÐºÐ° Ð²ÑÑÐ°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ñ ÑÐ·ÑÐºÐ¾Ð²ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÑÐµÑÐµÐ· f-Ð´Ð¸Ð²ÐµÑÐ³ÐµÐ½ÑÐ¸Ð¸", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´Ð»Ð¾Ð¶ÐµÐ½ ÐµÐ´Ð¸Ð½ÑÐ¹ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº Ð²ÑÑÐ°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ñ LLM, Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½ÑÐ¹ Ð½Ð° Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ð¸Ð¸ ÑÐµÐ»ÐµÐ²ÑÑ ÑÑÐ½ÐºÑÐ¸Ð¹ ÐºÐ°Ðº Ð´Ð¸Ð²ÐµÑÐ³ÐµÐ½ÑÐ¸Ð¹ Ð¼ÐµÐ¶Ð´Ñ ÑÐ°ÑÐ¿ÑÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÑÐ¼
[10.02.2026 19:58] Using data from previous issue: {"categories": ["#open_source", "#science"], "emoji": "â", "ru": {"title": "ÐÐ°ÑÐ¸Ð½Ð½Ð°Ñ Ð¼Ð°ÑÐµÐ¼Ð°ÑÐ¸ÐºÐ°: Ð²ÐµÑÐ¸ÑÐ¸ÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð½Ð°Ñ ÑÐµÐ¾ÑÐ¸Ñ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ ÑÐµÑÐµÐ· ÑÐµÐ»Ð¾Ð²ÐµÐºÐ¾-AI ÑÐ¾ÑÑÑÐ´Ð½Ð¸ÑÐµÑÑÐ²Ð¾", "desc": "Ð ÑÐ°Ð±Ð¾ÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½Ð° Ð¿ÐµÑÐ²Ð°Ñ Ð¿Ð¾Ð»Ð½Ð°Ñ ÑÐ¾ÑÐ¼Ð°Ð»Ð¸Ð·Ð°ÑÐ¸Ñ ÑÑÐ°ÑÐ¸ÑÑÐ¸ÑÐµÑÐºÐ¾Ð¹ ÑÐµÐ¾ÑÐ¸Ð¸ Ð¾Ð±ÑÑÐµÐ½Ð¸Ñ Ð² Lean 4, Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð½Ð° ÑÐ¼Ð¿Ð¸ÑÐ¸ÑÐµÑÐºÐ¾Ð¹ ÑÐµÐ¾ÑÐ¸Ð¸ Ð¿Ñ
[10.02.2026 19:58] Renaming data file.
[10.02.2026 19:58] Renaming previous data. hf_papers.json to ./d/2026-02-10.json
[10.02.2026 19:58] Saving new data file.
[10.02.2026 19:58] Generating page.
[10.02.2026 19:58] Renaming previous page.
[10.02.2026 19:58] Renaming previous data. index.html to ./d/2026-02-10.html
[10.02.2026 19:58] Writing result.
[10.02.2026 19:58] Renaming log file.
[10.02.2026 19:58] Renaming previous data. log.txt to ./logs/2026-02-10_last_log.txt
