[11.09.2025 04:14] Read previous papers.
[11.09.2025 04:14] Generating top page (month).
[11.09.2025 04:14] Writing top page (month).
[11.09.2025 05:11] Read previous papers.
[11.09.2025 05:11] Get feed.
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08827
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08826
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08755
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.05209
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06784
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07996
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08088
[11.09.2025 05:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08494
[11.09.2025 05:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.09.2025 05:11] No deleted papers detected.
[11.09.2025 05:11] Downloading and parsing papers (pdf, html). Total: 8.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.08827.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.08827.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.08827.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.08826.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.08826.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.08826.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.08755.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.08755.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.08755.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.05209.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.05209.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.05209.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.06784.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.06784.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.06784.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.07996.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.07996.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.07996.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.08088.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.08088.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.08088.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Downloading and parsing paper https://huggingface.co/papers/2509.08494.
[11.09.2025 05:11] Extra JSON file exists (./assets/json/2509.08494.json), skip PDF parsing.
[11.09.2025 05:11] Paper image links file exists (./assets/img_data/2509.08494.json), skip HTML parsing.
[11.09.2025 05:11] Success.
[11.09.2025 05:11] Enriching papers with extra data.
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 0. Reinforcement Learning enhances Large Language Models for complex reasoning tasks, facing challenges in scalability and infrastructure as the field advances.  					AI-generated summary 				 In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Mode...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 1. RewardDance is a scalable reward modeling framework that aligns with VLM architectures, enabling effective scaling of RMs and resolving reward hacking issues in generation models.  					AI-generated summary 				 Reward Models (RMs) are critical for improving generation models via Reinforcement Learn...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 2. AgentGym-RL is a modular RL framework for training LLM agents in diverse environments without supervised fine-tuning, featuring ScalingInter-RL for balanced exploration-exploitation.  					AI-generated summary 				 Developing autonomous LLM agents capable of making a series of intelligent decisions ...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 3. Hunyuan-MT-7B and Hunyuan-MT-Chimera-7B are multilingual translation models that outperform existing models, especially in translating between Mandarin and minority languages, through a combination of pre-training, supervised fine-tuning, and reinforcement learning.  					AI-generated summary 				 I...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 4. P3-SAM, a native 3D point-promptable part segmentation model, achieves precise and robust segmentation of complex 3D objects using a feature extractor, multiple segmentation heads, and an IoU predictor.  					AI-generated summary 				 Segmenting 3D assets into their constituent parts is crucial for ...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 5. This survey provides a comprehensive review of 3D and 4D world modeling and generation, establishing definitions, taxonomy, datasets, and evaluation metrics, and discussing applications and challenges.  					AI-generated summary 				 World modeling has become a cornerstone in AI research, enabling a...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 6. EnvX leverages Agentic AI to transform GitHub repositories into intelligent agents capable of natural language interaction and collaboration, automating the entire process of understanding, initializing, and operationalizing repository functionality.  					AI-generated summary 				 The widespread av...
[11.09.2025 05:11] ********************************************************************************
[11.09.2025 05:11] Abstract 7. A benchmark evaluates human agency in AI assistants using large language models, finding varying support across systems and dimensions.  					AI-generated summary 				 As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective...
[11.09.2025 05:11] Read previous papers.
[11.09.2025 05:11] Generating reviews via LLM API.
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#training", "#rl", "#rlhf", "#survey", "#reasoning"], "emoji": "üß†", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º: –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–∑–æ—Ä –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#rlhf", "#alignment", "#multimodal"], "emoji": "üíÉ", "ru": {"title": "RewardDance: –¢–∞–Ω—Ü—É—è —Å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è–º–∏ –≤ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–º –æ–±—É—á–µ–Ω–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RewardDance - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π, —Å–æ–≤–º–µ—Å—Ç–∏–º
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#rl", "#training", "#agents", "#games"], "emoji": "ü§ñ", "ru": {"title": "AgentGym-RL: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "AgentGym-RL - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥—É–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#low_resource", "#multilingual", "#rl", "#training"], "emoji": "üåê", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–º –º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ", "desc": "–ú–æ–¥–µ–ª–∏ Hunyuan-MT-7B –∏ Hunyuan-MT-Chimera-7B - —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏–µ —Å—É
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#optimization", "#3d", "#dataset", "#training", "#games"], "emoji": "üß©", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "P3-SAM - —ç—Ç–æ –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —á–∞—Å—Ç–µ–π 3D-–æ–±—ä–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#benchmark", "#survey", "#3d", "#dataset"], "emoji": "üåê", "ru": {"title": "–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è 3D –∏ 4D –º–∏—Ä–æ–≤: –æ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π", "desc": "–≠—Ç–æ—Ç –æ–±–∑–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D –∏ 4D –º–∏—Ä–æ–≤. –í –Ω–µ–º —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#agi", "#open_source", "#benchmark", "#multimodal", "#agents"], "emoji": "ü§ñ", "ru": {"title": "EnvX: –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –≤ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "EnvX - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–≥–µ–Ω—Ç–Ω—ã–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –¥–ª—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ –∏–Ω—Ç–µ–ª–ª–µ–∫
[11.09.2025 05:11] Using data from previous issue: {"categories": ["#ethics", "#alignment", "#benchmark", "#rlhf"], "emoji": "ü§ñ", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤ —ç–ø–æ—Ö—É –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ HumanAgencyBench (HAB) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤ –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à
[11.09.2025 05:11] Renaming data file.
[11.09.2025 05:11] Renaming previous data. hf_papers.json to ./d/2025-09-11.json
[11.09.2025 05:11] Saving new data file.
[11.09.2025 05:11] Generating page.
[11.09.2025 05:11] Renaming previous page.
[11.09.2025 05:11] Renaming previous data. index.html to ./d/2025-09-11.html
[11.09.2025 05:11] Writing result.
[11.09.2025 05:11] Renaming log file.
[11.09.2025 05:11] Renaming previous data. log.txt to ./logs/2025-09-11_last_log.txt
