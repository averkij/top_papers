[11.09.2025 19:08] Read previous papers.
[11.09.2025 19:08] Generating top page (month).
[11.09.2025 19:08] Writing top page (month).
[11.09.2025 20:10] Read previous papers.
[11.09.2025 20:10] Get feed.
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08827
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08826
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.07996
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08755
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06784
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.05209
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06870
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08358
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08088
[11.09.2025 20:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.08494
[11.09.2025 20:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.09.2025 20:10] No deleted papers detected.
[11.09.2025 20:10] Downloading and parsing papers (pdf, html). Total: 10.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.08827.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.08827.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.08827.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.08826.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.08826.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.08826.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.07996.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.07996.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.07996.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.08755.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.08755.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.08755.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.06784.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.06784.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.06784.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.05209.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.05209.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.05209.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.06870.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.06870.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.06870.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.08358.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.08358.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.08358.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.08088.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.08088.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.08088.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Downloading and parsing paper https://huggingface.co/papers/2509.08494.
[11.09.2025 20:10] Extra JSON file exists (./assets/json/2509.08494.json), skip PDF parsing.
[11.09.2025 20:10] Paper image links file exists (./assets/img_data/2509.08494.json), skip HTML parsing.
[11.09.2025 20:10] Success.
[11.09.2025 20:10] Enriching papers with extra data.
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 0. Reinforcement Learning enhances Large Language Models for complex reasoning tasks, facing challenges in scalability and infrastructure as the field advances.  					AI-generated summary 				 In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Mode...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 1. RewardDance is a scalable reward modeling framework that aligns with VLM architectures, enabling effective scaling of RMs and resolving reward hacking issues in generation models.  					AI-generated summary 				 Reward Models (RMs) are critical for improving generation models via Reinforcement Learn...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 2. This survey provides a comprehensive review of 3D and 4D world modeling and generation, establishing definitions, taxonomy, datasets, and evaluation metrics, and discussing applications and challenges.  					AI-generated summary 				 World modeling has become a cornerstone in AI research, enabling a...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 3. AgentGym-RL is a modular RL framework for training LLM agents in diverse environments without supervised fine-tuning, featuring ScalingInter-RL for balanced exploration-exploitation.  					AI-generated summary 				 Developing autonomous LLM agents capable of making a series of intelligent decisions ...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 4. P3-SAM, a native 3D point-promptable part segmentation model, achieves precise and robust segmentation of complex 3D objects using a feature extractor, multiple segmentation heads, and an IoU predictor.  					AI-generated summary 				 Segmenting 3D assets into their constituent parts is crucial for ...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 5. Hunyuan-MT-7B and Hunyuan-MT-Chimera-7B are multilingual translation models that outperform existing models, especially in translating between Mandarin and minority languages, through a combination of pre-training, supervised fine-tuning, and reinforcement learning.  					AI-generated summary 				 I...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 6. A reinforcement learning approach to aggregating multiple solutions for large language models improves performance on reasoning tasks by learning to synthesize correct answers from candidate solutions.  					AI-generated summary 				 Scaling up test-time compute, by generating multiple independent s...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 7. Models fine-tuned on synthetic toxic data generated by LLMs perform worse than those trained on human data due to a lexical diversity gap in the synthetic content.  					AI-generated summary 				 Modern Large Language Models (LLMs) are excellent at generating synthetic data. However, their performan...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 8. EnvX leverages Agentic AI to transform GitHub repositories into intelligent agents capable of natural language interaction and collaboration, automating the entire process of understanding, initializing, and operationalizing repository functionality.  					AI-generated summary 				 The widespread av...
[11.09.2025 20:10] ********************************************************************************
[11.09.2025 20:10] Abstract 9. A benchmark evaluates human agency in AI assistants using large language models, finding varying support across systems and dimensions.  					AI-generated summary 				 As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective...
[11.09.2025 20:10] Read previous papers.
[11.09.2025 20:10] Generating reviews via LLM API.
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#training", "#rl", "#rlhf", "#survey", "#reasoning"], "emoji": "üß†", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º: –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–∑–æ—Ä –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#rl", "#rlhf", "#alignment", "#multimodal"], "emoji": "üíÉ", "ru": {"title": "RewardDance: –¢–∞–Ω—Ü—É—è —Å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è–º–∏ –≤ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–º –æ–±—É—á–µ–Ω–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "RewardDance - —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π, —Å–æ–≤–º–µ—Å—Ç–∏–º
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#benchmark", "#survey", "#3d", "#dataset"], "emoji": "üåê", "ru": {"title": "–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è 3D –∏ 4D –º–∏—Ä–æ–≤: –æ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π", "desc": "–≠—Ç–æ—Ç –æ–±–∑–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D –∏ 4D –º–∏—Ä–æ–≤. –í –Ω–µ–º —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#rl", "#training", "#agents", "#games"], "emoji": "ü§ñ", "ru": {"title": "AgentGym-RL: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "AgentGym-RL - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥—É–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#optimization", "#3d", "#dataset", "#training", "#games"], "emoji": "üß©", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö 3D-–æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "P3-SAM - —ç—Ç–æ –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —á–∞—Å—Ç–µ–π 3D-–æ–±—ä–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#low_resource", "#multilingual", "#rl", "#training"], "emoji": "üåê", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–º –º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ", "desc": "–ú–æ–¥–µ–ª–∏ Hunyuan-MT-7B –∏ Hunyuan-MT-Chimera-7B - —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏–µ —Å—É
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#optimization", "#rl", "#training", "#reasoning", "#benchmark"], "emoji": "üß†", "ru": {"title": "–£–º–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π –ò–ò —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. –ú–µ—Ç–æ
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#ethics", "#training", "#data", "#healthcare", "#synthetic"], "emoji": "ü§ñ", "ru": {"title": "–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –¥
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#agi", "#open_source", "#benchmark", "#multimodal", "#agents"], "emoji": "ü§ñ", "ru": {"title": "EnvX: –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –≤ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "EnvX - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–≥–µ–Ω—Ç–Ω—ã–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –¥–ª—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ –∏–Ω—Ç–µ–ª–ª–µ–∫
[11.09.2025 20:10] Using data from previous issue: {"categories": ["#ethics", "#alignment", "#benchmark", "#rlhf"], "emoji": "ü§ñ", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤ —ç–ø–æ—Ö—É –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ HumanAgencyBench (HAB) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤ –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à
[11.09.2025 20:10] Renaming data file.
[11.09.2025 20:10] Renaming previous data. hf_papers.json to ./d/2025-09-11.json
[11.09.2025 20:10] Saving new data file.
[11.09.2025 20:10] Generating page.
[11.09.2025 20:10] Renaming previous page.
[11.09.2025 20:10] Renaming previous data. index.html to ./d/2025-09-11.html
[11.09.2025 20:10] Writing result.
[11.09.2025 20:10] Renaming log file.
[11.09.2025 20:10] Renaming previous data. log.txt to ./logs/2025-09-11_last_log.txt
