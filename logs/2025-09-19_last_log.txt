[19.09.2025 09:13] Read previous papers.
[19.09.2025 09:13] Generating top page (month).
[19.09.2025 09:13] Writing top page (month).
[19.09.2025 10:12] Read previous papers.
[19.09.2025 10:12] Get feed.
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15221
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15207
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14760
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15194
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15185
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13160
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15212
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14476
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15130
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14638
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15178
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14977
[19.09.2025 10:12] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06482
[19.09.2025 10:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[19.09.2025 10:12] No deleted papers detected.
[19.09.2025 10:12] Downloading and parsing papers (pdf, html). Total: 13.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15221.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15221.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15221.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15207.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15207.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15207.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.14760.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.14760.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.14760.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15194.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15194.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15194.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15185.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15185.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15185.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.13160.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.13160.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.13160.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15212.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15212.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15212.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.14476.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.14476.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.14476.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15130.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15130.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15130.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.14638.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.14638.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.14638.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.15178.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.15178.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.15178.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.14977.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.14977.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.14977.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.06482.
[19.09.2025 10:12] Extra JSON file exists (./assets/json/2509.06482.json), skip PDF parsing.
[19.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.06482.json), skip HTML parsing.
[19.09.2025 10:12] Success.
[19.09.2025 10:12] Enriching papers with extra data.
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 0. ScaleCUA, a large-scale dataset and model for computer use agents, achieves state-of-the-art performance across multiple platforms and tasks by leveraging data-driven scaling.  					AI-generated summary 				 Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that operate GUIs auto...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 1. FlowRL enhances LLM reinforcement learning by matching the full reward distribution through flow balancing, improving diversity and performance over reward-maximizing methods.  					AI-generated summary 				 We propose FlowRL: matching the full reward distribution via flow balancing instead of maxim...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 2. Align3, a lightweight method using Test-Time Deliberation, enhances specification alignment in large language models across diverse scenarios with minimal overhead.  					AI-generated summary 				 Large language models (LLMs) are increasingly applied in diverse real-world scenarios, each governed by...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 3. EVOL-RL, a label-free reinforcement learning method, enhances large language models by balancing stability and variation, preventing entropy collapse and improving generalization.  					AI-generated summary 				 Large language models (LLMs) are increasingly trained with reinforcement learning from v...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 4. Self-guided Training for AutoRegressive models (ST-AR) enhances image understanding and generation quality in autoregressive models by addressing key visual semantics challenges through self-supervised objectives.  					AI-generated summary 				 Recent studies have demonstrated the importance of hig...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 5. FinSearchComp is an open-source benchmark for evaluating financial search and reasoning capabilities of end-to-end agents, featuring realistic tasks and professional annotations.  					AI-generated summary 				 Search has emerged as core infrastructure for LLM-based agents and is widely viewed as cr...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 6. RynnVLA-001, a vision-language-action model, uses a two-stage pretraining approach and ActionVAE to achieve superior performance on robotics tasks.  					AI-generated summary 				 This paper presents RynnVLA-001, a vision-language-action(VLA) model built upon large-scale video generative pretraining...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 7. AToken, a unified visual tokenizer, achieves high-fidelity reconstruction and semantic understanding across images, videos, and 3D assets using a 4D transformer architecture with adversarial-free training.  					AI-generated summary 				 We present AToken, the first unified visual tokenizer that ach...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 8. WorldForge, a training-free framework, enhances video diffusion models with precise motion control and photorealistic content generation through recursive refinement, flow-gated latent fusion, and dual-path self-corrective guidance.  					AI-generated summary 				 Recent video diffusion models demon...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 9. MultiEdit, a comprehensive dataset with over 107K high-quality image editing samples, improves performance on sophisticated editing tasks using a novel pipeline with multi-modal large language models.  					AI-generated summary 				 Current instruction-based image editing (IBIE) methods struggle wit...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 10. A zero-shot framework using multimodal large language models for spatio-temporal video grounding employs decomposed spatio-temporal highlighting and temporal-augmented assembling strategies to improve grounding accuracy.  					AI-generated summary 				 Spatio-temporal video grounding (STVG) aims at ...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 11. EchoVLM, a vision-language model with a Mixture of Experts architecture, improves ultrasound report generation and diagnosis by leveraging data from multiple anatomical regions.  					AI-generated summary 				 Ultrasound imaging has become the preferred imaging modality for early cancer screening du...
[19.09.2025 10:12] ********************************************************************************
[19.09.2025 10:12] Abstract 12. FSG-Net addresses false alarms and semantic gaps in change detection by using a frequency-spatial synergistic approach with wavelet interaction, attention mechanisms, and gated fusion.  					AI-generated summary 				 Change detection from high-resolution remote sensing images lies as a cornerstone o...
[19.09.2025 10:12] Read previous papers.
[19.09.2025 10:12] Generating reviews via LLM API.
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#agents", "#cv"], "emoji": "üñ•Ô∏è", "ru": {"title": "ScaleCUA: –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö", "desc": "ScaleCUA –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –º–æ–¥–µ–ª—å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è. –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#rlhf", "#optimization", "#reasoning", "#training", "#math", "#rl"], "emoji": "üåä", "ru": {"title": "FlowRL: –±–∞–ª–∞–Ω—Å –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç FlowRL - –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –í –æ—Ç–ª–∏—á–∏
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#benchmark", "#training", "#alignment"], "emoji": "üéØ", "ru": {"title": "Align3: –¢–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Align3, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Test-Time Deliberation –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ–æ—Ç–≤
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#agi", "#rlhf", "#optimization", "#training", "#rl"], "emoji": "üß¨", "ru": {"title": "–≠–≤–æ–ª—é—Ü–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –º–µ—Ç–æ–∫", "desc": "–ú–µ—Ç–æ–¥ EVOL-RL –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω —Å–æ—á–µ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#cv"], "emoji": "üñºÔ∏è", "ru": {"title": "–°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —É–ª—É—á—à–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - Self-guided Trai
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#science", "#open_source", "#agents", "#reasoning", "#benchmark"], "emoji": "üíπ", "ru": {"title": "FinSearchComp: –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –ò–ò", "desc": "FinSearchComp - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#robotics", "#optimization", "#training", "#cv", "#games", "#rl"], "emoji": "ü§ñ", "ru": {"title": "RynnVLA-001: –ü–µ—Ä–µ–¥–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑—Ä–µ–Ω–∏—è-—è–∑—ã–∫–∞-–¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∏", "desc": "RynnVLA-001 - —ç—Ç–æ –º–æ–¥–µ–ª—å –∑—Ä–µ–Ω–∏—è-—è–∑—ã–∫–∞-–¥–µ–π—Å—Ç–≤–∏—è (VLA), —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è –∑–∞–¥–∞—á —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∏. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#3d", "#architecture", "#video", "#training", "#cv", "#benchmark", "#games"], "emoji": "üé≠", "ru": {"title": "–ï–¥–∏–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤—Å–µ—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "AToken - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, —Å–ø–æ—Å–æ–±–Ω—ã–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#3d", "#diffusion", "#video", "#inference", "#benchmark"], "emoji": "üé•", "ru": {"title": "WorldForge: –¢–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –¥–≤–∏–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", "desc": "WorldForge - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#cv", "#benchmark", "#games"], "emoji": "üñºÔ∏è", "ru": {"title": "MultiEdit: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç MultiEdit - –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –±–æ–ª–µ–µ 107 —Ç—ã—Å—è—á –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#video", "#games", "#multimodal", "#reasoning", "#benchmark"], "emoji": "üé•", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∑–∞–¥–∞—á–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#healthcare", "#architecture", "#games", "#cv", "#open_source", "#training", "#science", "#dataset"], "emoji": "üîä", "ru": {"title": "EchoVLM: –£–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —É–ª—å—Ç—Ä–∞–∑–≤—É–∫–æ–≤–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏", "desc": "EchoVLM - —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ª—å—Ç—Ä–∞–∑–≤—É–∫–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏—Å–ø–æ
[19.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#cv"], "emoji": "üõ∞Ô∏è", "ru": {"title": "FSG-Net: —Ç–æ—á–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–∞—Ö", "desc": "FSG-Net - —ç—Ç–æ –Ω–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–∞—Ö –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–π–≤–ª–µ—Ç-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Ö
[19.09.2025 10:12] Renaming data file.
[19.09.2025 10:12] Renaming previous data. hf_papers.json to ./d/2025-09-19.json
[19.09.2025 10:12] Saving new data file.
[19.09.2025 10:12] Generating page.
[19.09.2025 10:12] Renaming previous page.
[19.09.2025 10:12] Renaming previous data. index.html to ./d/2025-09-19.html
[19.09.2025 10:12] Writing result.
[19.09.2025 10:12] Renaming log file.
[19.09.2025 10:12] Renaming previous data. log.txt to ./logs/2025-09-19_last_log.txt
