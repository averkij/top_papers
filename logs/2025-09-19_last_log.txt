[19.09.2025 10:12] Read previous papers.
[19.09.2025 10:12] Generating top page (month).
[19.09.2025 10:12] Writing top page (month).
[19.09.2025 11:10] Read previous papers.
[19.09.2025 11:10] Get feed.
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15221
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15207
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14760
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15194
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15185
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.13160
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15212
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14476
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15130
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14638
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.15178
[19.09.2025 11:10] Extract page data from URL. URL: https://huggingface.co/papers/2509.15020
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.14977
[19.09.2025 11:10] Get page data from previous paper. URL: https://huggingface.co/papers/2509.06482
[19.09.2025 11:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[19.09.2025 11:10] No deleted papers detected.
[19.09.2025 11:10] Downloading and parsing papers (pdf, html). Total: 14.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15221.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15221.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15221.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15207.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15207.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15207.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.14760.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.14760.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.14760.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15194.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15194.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15194.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15185.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15185.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15185.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.13160.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.13160.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.13160.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15212.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15212.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15212.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.14476.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.14476.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.14476.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15130.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15130.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15130.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.14638.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.14638.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.14638.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15178.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.15178.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.15178.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.15020.
[19.09.2025 11:10] Downloading paper 2509.15020 from http://arxiv.org/pdf/2509.15020v1...
[19.09.2025 11:10] Extracting affiliations from text.
[19.09.2025 11:10] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Mind the Gap: Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs Mario Sanz-Guerrero Minh Duc Bui Katharina von der Wense Johannes Gutenberg University Mainz, Germany University of Colorado Boulder, USA {msanz, minhducbui, k.vonderwense}@uni-mainz.de 5 2 0 2 8 1 ] . [ 1 0 2 0 5 1 . 9 0 5 2 : r a "
[19.09.2025 11:10] Response: ```python
["Johannes Gutenberg University Mainz, Germany", "University of Colorado Boulder, USA"]
```
[19.09.2025 11:10] Deleting PDF ./assets/pdf/2509.15020.pdf.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.14977.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.14977.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.14977.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Downloading and parsing paper https://huggingface.co/papers/2509.06482.
[19.09.2025 11:10] Extra JSON file exists (./assets/json/2509.06482.json), skip PDF parsing.
[19.09.2025 11:10] Paper image links file exists (./assets/img_data/2509.06482.json), skip HTML parsing.
[19.09.2025 11:10] Success.
[19.09.2025 11:10] Enriching papers with extra data.
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 0. ScaleCUA, a large-scale dataset and model for computer use agents, achieves state-of-the-art performance across multiple platforms and tasks by leveraging data-driven scaling.  					AI-generated summary 				 Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that operate GUIs auto...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 1. FlowRL enhances LLM reinforcement learning by matching the full reward distribution through flow balancing, improving diversity and performance over reward-maximizing methods.  					AI-generated summary 				 We propose FlowRL: matching the full reward distribution via flow balancing instead of maxim...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 2. Align3, a lightweight method using Test-Time Deliberation, enhances specification alignment in large language models across diverse scenarios with minimal overhead.  					AI-generated summary 				 Large language models (LLMs) are increasingly applied in diverse real-world scenarios, each governed by...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 3. EVOL-RL, a label-free reinforcement learning method, enhances large language models by balancing stability and variation, preventing entropy collapse and improving generalization.  					AI-generated summary 				 Large language models (LLMs) are increasingly trained with reinforcement learning from v...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 4. Self-guided Training for AutoRegressive models (ST-AR) enhances image understanding and generation quality in autoregressive models by addressing key visual semantics challenges through self-supervised objectives.  					AI-generated summary 				 Recent studies have demonstrated the importance of hig...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 5. FinSearchComp is an open-source benchmark for evaluating financial search and reasoning capabilities of end-to-end agents, featuring realistic tasks and professional annotations.  					AI-generated summary 				 Search has emerged as core infrastructure for LLM-based agents and is widely viewed as cr...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 6. RynnVLA-001, a vision-language-action model, uses a two-stage pretraining approach and ActionVAE to achieve superior performance on robotics tasks.  					AI-generated summary 				 This paper presents RynnVLA-001, a vision-language-action(VLA) model built upon large-scale video generative pretraining...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 7. AToken, a unified visual tokenizer, achieves high-fidelity reconstruction and semantic understanding across images, videos, and 3D assets using a 4D transformer architecture with adversarial-free training.  					AI-generated summary 				 We present AToken, the first unified visual tokenizer that ach...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 8. WorldForge, a training-free framework, enhances video diffusion models with precise motion control and photorealistic content generation through recursive refinement, flow-gated latent fusion, and dual-path self-corrective guidance.  					AI-generated summary 				 Recent video diffusion models demon...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 9. MultiEdit, a comprehensive dataset with over 107K high-quality image editing samples, improves performance on sophisticated editing tasks using a novel pipeline with multi-modal large language models.  					AI-generated summary 				 Current instruction-based image editing (IBIE) methods struggle wit...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 10. A zero-shot framework using multimodal large language models for spatio-temporal video grounding employs decomposed spatio-temporal highlighting and temporal-augmented assembling strategies to improve grounding accuracy.  					AI-generated summary 				 Spatio-temporal video grounding (STVG) aims at ...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 11. Tokenizing the space with the answer letter in multiple-choice question answering improves LLM accuracy and calibration.  					AI-generated summary 				 When evaluating large language models (LLMs) with multiple-choice question answering (MCQA), it is common to end the prompt with the string "Answer...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 12. EchoVLM, a vision-language model with a Mixture of Experts architecture, improves ultrasound report generation and diagnosis by leveraging data from multiple anatomical regions.  					AI-generated summary 				 Ultrasound imaging has become the preferred imaging modality for early cancer screening du...
[19.09.2025 11:10] ********************************************************************************
[19.09.2025 11:10] Abstract 13. FSG-Net addresses false alarms and semantic gaps in change detection by using a frequency-spatial synergistic approach with wavelet interaction, attention mechanisms, and gated fusion.  					AI-generated summary 				 Change detection from high-resolution remote sensing images lies as a cornerstone o...
[19.09.2025 11:10] Read previous papers.
[19.09.2025 11:10] Generating reviews via LLM API.
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#agents", "#cv"], "emoji": "🖥️", "ru": {"title": "ScaleCUA: Масштабирование агентов компьютерного использования на основе данных", "desc": "ScaleCUA представляет собой масштабный датасет и модель для агентов компьютерного использования. Модель достигает п
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#rlhf", "#optimization", "#reasoning", "#training", "#math", "#rl"], "emoji": "🌊", "ru": {"title": "FlowRL: баланс потоков для разнообразного обучения языковых моделей", "desc": "Статья представляет FlowRL - новый метод обучения с подкреплением для больших языковых моделей. В отличи
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#benchmark", "#training", "#alignment"], "emoji": "🎯", "ru": {"title": "Align3: Точная настройка языковых моделей под пользовательские требования", "desc": "Статья представляет метод Align3, который использует Test-Time Deliberation для улучшения соотв
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#agi", "#rlhf", "#optimization", "#training", "#rl"], "emoji": "🧬", "ru": {"title": "Эволюция языковых моделей без меток", "desc": "Метод EVOL-RL предлагает новый подход к обучению с подкреплением без использования меток для улучшения больших языковых моделей. Он сочетает стабильнос
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#cv"], "emoji": "🖼️", "ru": {"title": "Самообучение авторегрессионных моделей улучшает генерацию изображений", "desc": "Статья представляет новый метод обучения авторегрессионных моделей для улучшения понимания и генерации изображений - Self-guided Trai
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#science", "#open_source", "#agents", "#reasoning", "#benchmark"], "emoji": "💹", "ru": {"title": "FinSearchComp: профессиональный тест для оценки финансового ИИ", "desc": "FinSearchComp - это открытый эталонный тест для оценки возможностей финансового поиска и рассуждений агентов на
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#robotics", "#optimization", "#training", "#cv", "#games", "#rl"], "emoji": "🤖", "ru": {"title": "RynnVLA-001: Передовая модель зрения-языка-действия для робототехники", "desc": "RynnVLA-001 - это модель зрения-языка-действия (VLA), разработанная для задач робототехники. Модель испо
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#3d", "#architecture", "#video", "#training", "#cv", "#benchmark", "#games"], "emoji": "🎭", "ru": {"title": "Единый токенизатор для всех визуальных данных", "desc": "AToken - это унифицированный визуальный токенизатор, способный обрабатывать изображен
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#3d", "#diffusion", "#video", "#inference", "#benchmark"], "emoji": "🎥", "ru": {"title": "WorldForge: Точный контроль движения в видео-диффузионных моделях без переобучения", "desc": "WorldForge - это фреймворк для улучшения видео-диффузионных моделей без дополнительного обучения. О
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#cv", "#benchmark", "#games"], "emoji": "🖼️", "ru": {"title": "MultiEdit: революция в редактировании изображений с помощью ИИ", "desc": "Статья представляет MultiEdit - новый набор данных, содержащий более 107 тысяч высококачественных образцов редактирова
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#video", "#games", "#multimodal", "#reasoning", "#benchmark"], "emoji": "🎥", "ru": {"title": "Улучшение пространственно-временной локализации в видео с помощью мультимодальных языковых моделей", "desc": "Статья представляет новый подход к задаче пространственно-временной локализации
[19.09.2025 11:10] Querying the API.
[19.09.2025 11:10] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Tokenizing the space with the answer letter in multiple-choice question answering improves LLM accuracy and calibration.  					AI-generated summary 				 When evaluating large language models (LLMs) with multiple-choice question answering (MCQA), it is common to end the prompt with the string "Answer:" to facilitate automated answer extraction via next-token probabilities. However, there is no consensus on how to tokenize the space following the colon, often overlooked as a trivial choice. In this paper, we uncover accuracy differences of up to 11% due to this (seemingly irrelevant) tokenization variation as well as reshuffled model rankings, raising concerns about the reliability of LLM comparisons in prior work. Surprisingly, we are able to recommend one specific strategy -- tokenizing the space together with the answer letter -- as we observe consistent and statistically significant performance improvements. Additionally, it improves model calibration, enhancing the reliability of the model's confidence estimates. Our findings underscore the importance of careful evaluation design and highlight the need for standardized, transparent evaluation protocols to ensure reliable and comparable results.
[19.09.2025 11:10] Response: {
  "desc": "Исследование показывает, что токенизация пробела вместе с буквой ответа в задачах множественного выбора значительно улучшает точность и калибровку больших языковых моделей (LLM). Эта, казалось бы, незначительная деталь может привести к разнице в точности до 11% и изменить рейтинги моделей. Авторы рекомендуют использовать эту стратегию токенизации для более надежной оценки LLM. Исследование подчеркивает важность тщательного проектирования методов оценки и стандартизации протоколов для обеспечения сопоставимых результатов.",
  "emoji": "🔬",
  "title": "Маленькая токенизация - большая разница в оценке языковых моделей"
}
[19.09.2025 11:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Tokenizing the space with the answer letter in multiple-choice question answering improves LLM accuracy and calibration.  					AI-generated summary 				 When evaluating large language models (LLMs) with multiple-choice question answering (MCQA), it is common to end the prompt with the string "Answer:" to facilitate automated answer extraction via next-token probabilities. However, there is no consensus on how to tokenize the space following the colon, often overlooked as a trivial choice. In this paper, we uncover accuracy differences of up to 11% due to this (seemingly irrelevant) tokenization variation as well as reshuffled model rankings, raising concerns about the reliability of LLM comparisons in prior work. Surprisingly, we are able to recommend one specific strategy -- tokenizing the space together with the answer letter -- as we observe consistent and statistically significant performance improvements. Additionally, it improves model calibration, enhancing the reliability of the model's confidence estimates. Our findings underscore the importance of careful evaluation design and highlight the need for standardized, transparent evaluation protocols to ensure reliable and comparable results."

[19.09.2025 11:10] Response: ```python
['DATA', 'BENCHMARK', 'TRAINING']
```
[19.09.2025 11:10] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Tokenizing the space with the answer letter in multiple-choice question answering improves LLM accuracy and calibration.  					AI-generated summary 				 When evaluating large language models (LLMs) with multiple-choice question answering (MCQA), it is common to end the prompt with the string "Answer:" to facilitate automated answer extraction via next-token probabilities. However, there is no consensus on how to tokenize the space following the colon, often overlooked as a trivial choice. In this paper, we uncover accuracy differences of up to 11% due to this (seemingly irrelevant) tokenization variation as well as reshuffled model rankings, raising concerns about the reliability of LLM comparisons in prior work. Surprisingly, we are able to recommend one specific strategy -- tokenizing the space together with the answer letter -- as we observe consistent and statistically significant performance improvements. Additionally, it improves model calibration, enhancing the reliability of the model's confidence estimates. Our findings underscore the importance of careful evaluation design and highlight the need for standardized, transparent evaluation protocols to ensure reliable and comparable results."

[19.09.2025 11:10] Response: ```python
['INTERPRETABILITY', 'OPTIMIZATION']
```
[19.09.2025 11:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper investigates the impact of tokenization strategies on the performance of large language models (LLMs) in multiple-choice question answering (MCQA). It reveals that the way space is tokenized after the prompt can lead to significant accuracy differences, affecting model rankings by up to 11%. The authors propose a specific method of tokenizing the space along with the answer letter, which consistently improves both accuracy and model calibration. These findings emphasize the necessity for standardized evaluation practices to ensure the reliability of LLM comparisons.","title":"Tokenization Matters: Boosting LLM Accuracy in MCQA!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper investigates the impact of tokenization strategies on the performance of large language models (LLMs) in multiple-choice question answering (MCQA). It reveals that the way space is tokenized after the prompt can lead to significant accuracy differences, affecting model rankings by up to 11%. The authors propose a specific method of tokenizing the space along with the answer letter, which consistently improves both accuracy and model calibration. These findings emphasize the necessity for standardized evaluation practices to ensure the reliability of LLM comparisons.', title='Tokenization Matters: Boosting LLM Accuracy in MCQA!'))
[19.09.2025 11:10] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了在多选题问答中，如何处理冒号后空格的分词对大型语言模型（LLM）准确性和校准的影响。研究发现，采用不同的分词方式可能导致准确率差异高达11%，并且可能改变模型排名，影响LLM比较的可靠性。我们推荐将空格与答案字母一起分词，这种方法在性能上表现出一致且显著的提升，同时也改善了模型的校准性。我们的研究强调了评估设计的重要性，并呼吁建立标准化和透明的评估协议，以确保结果的可靠性和可比性。","title":"优化分词提升LLM准确性与校准性"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了在多选题问答中，如何处理冒号后空格的分词对大型语言模型（LLM）准确性和校准的影响。研究发现，采用不同的分词方式可能导致准确率差异高达11%，并且可能改变模型排名，影响LLM比较的可靠性。我们推荐将空格与答案字母一起分词，这种方法在性能上表现出一致且显著的提升，同时也改善了模型的校准性。我们的研究强调了评估设计的重要性，并呼吁建立标准化和透明的评估协议，以确保结果的可靠性和可比性。', title='优化分词提升LLM准确性与校准性'))
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#healthcare", "#architecture", "#games", "#cv", "#open_source", "#training", "#science", "#dataset"], "emoji": "🔊", "ru": {"title": "EchoVLM: Умный помощник для ультразвуковой диагностики", "desc": "EchoVLM - это модель машинного обучения для анализа ультразвуковых изображений, испо
[19.09.2025 11:10] Using data from previous issue: {"categories": ["#benchmark", "#cv"], "emoji": "🛰️", "ru": {"title": "FSG-Net: точное обнаружение изменений на спутниковых снимках", "desc": "FSG-Net - это новая нейросетевая архитектура для обнаружения изменений на спутниковых снимках высокого разрешения. Она использует вейвлет-преобразование и мех
[19.09.2025 11:10] Renaming data file.
[19.09.2025 11:10] Renaming previous data. hf_papers.json to ./d/2025-09-19.json
[19.09.2025 11:10] Saving new data file.
[19.09.2025 11:10] Generating page.
[19.09.2025 11:10] Renaming previous page.
[19.09.2025 11:10] Renaming previous data. index.html to ./d/2025-09-19.html
[19.09.2025 11:10] Writing result.
[19.09.2025 11:10] Renaming log file.
[19.09.2025 11:10] Renaming previous data. log.txt to ./logs/2025-09-19_last_log.txt
