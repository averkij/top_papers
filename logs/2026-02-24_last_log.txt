[24.02.2026 08:38] Read previous papers.
[24.02.2026 08:38] Generating top page (month).
[24.02.2026 08:38] Writing top page (month).
[24.02.2026 09:44] Read previous papers.
[24.02.2026 09:44] Get feed.
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.20159
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.20093
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.19313
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.20161
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.19895
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.20021
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.19672
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.19128
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.20160
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.18915
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.12100
[24.02.2026 09:44] Get page data from previous paper. URL: https://huggingface.co/papers/2602.19455
[24.02.2026 09:44] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[24.02.2026 09:44] No deleted papers detected.
[24.02.2026 09:44] Downloading and parsing papers (pdf, html). Total: 12.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.20159.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.20159.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.20159.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.20093.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.20093.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.20093.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.19313.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.19313.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.19313.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.20161.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.20161.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.20161.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.19895.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.19895.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.19895.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.20021.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.20021.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.20021.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.19672.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.19672.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.19672.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.19128.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.19128.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.19128.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.20160.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.20160.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.20160.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.18915.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.18915.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.18915.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.12100.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.12100.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.12100.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Downloading and parsing paper https://huggingface.co/papers/2602.19455.
[24.02.2026 09:44] Extra JSON file exists (./assets/json/2602.19455.json), skip PDF parsing.
[24.02.2026 09:44] Paper image links file exists (./assets/img_data/2602.19455.json), skip HTML parsing.
[24.02.2026 09:44] Success.
[24.02.2026 09:44] Enriching papers with extra data.
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 0. Abstract A large-scale video reasoning dataset and benchmark are introduced to study video intelligence capabilities beyond visual quality, enabling systematic analysis of spatiotemporal reasoning and generalization across diverse tasks.  					AI-generated summary Rapid progress in video models has ...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 1. Abstract ManCAR is a recommendation framework that constrains latent reasoning within a collaborative manifold to prevent implausible trajectories and improve accuracy.  					AI-generated summary Sequential recommendation increasingly employs latent multi-step reasoning to enhance test-time computat...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 2. Abstract TOPReward is a probabilistically grounded temporal value function that uses pretrained video Vision-Language Models to estimate robotic task progress through internal token logits, achieving superior performance in zero-shot evaluations across diverse real-world tasks.  					AI-generated su...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 3. Abstract A compact vision-language-diffusion model called Mobile-O enables efficient unified multimodal understanding and generation on mobile devices through specialized architecture design and optimized training methodology.  					AI-generated summary Unified multimodal models can both understand ...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 4. Abstract DSDR is a reinforcement learning framework that enhances large language model reasoning by promoting diversity at both global and local levels through dual-scale regularization techniques.  					AI-generated summary Reinforcement learning with verifiers (RLVR) is a central paradigm for impr...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 5. Abstract Autonomous language-model-powered agents in a live laboratory environment exhibited numerous security and governance vulnerabilities including unauthorized actions, information disclosure, and system takeovers during a two-week study with twenty researchers.  					AI-generated summary We re...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 6. Abstract SkillOrchestra presents a skill-aware orchestration framework that improves compound AI system performance through fine-grained skill modeling and efficient agent selection, achieving superior results with significantly reduced learning costs compared to reinforcement learning-based methods...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 7. Abstract K-Search uses a co-evolving world model to optimize GPU kernels by separating high-level planning from low-level implementation, achieving significant performance improvements over existing evolutionary methods.  					AI-generated summary Optimizing GPU kernels is critical for efficient mod...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 8. Abstract A novel 3D reconstruction model called tttLRM uses a Test-Time Training layer to enable efficient, scalable autoregressive reconstruction with linear complexity, achieving better results than existing methods.  					AI-generated summary We propose tttLRM, a novel large 3D reconstruction mod...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 9. Abstract AAVGen is a generative AI framework that designs AAV capsids with improved traits through protein language models, supervised fine-tuning, and reinforcement learning techniques.  					AI-generated summary Adeno-associated viruses (AAVs) are promising vectors for gene therapy, but their nati...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 10. Abstract AssetFormer is an autoregressive Transformer-based model that generates modular 3D assets from textual descriptions by adapting language model techniques to handle design constraints.  					AI-generated summary The digital industry demands high-quality, diverse modular 3D assets, especially...
[24.02.2026 09:44] ********************************************************************************
[24.02.2026 09:44] Abstract 11. Abstract A hybrid knowledge-injection framework combines general reasoning large language models with time-series LLMs through reinforcement learning-based verifiable rewards to enhance time-series diagnostic reasoning performance.  					AI-generated summary Time-series diagnostic reasoning is essen...
[24.02.2026 09:44] Read previous papers.
[24.02.2026 09:44] Generating reviews via LLM API.
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#video", "#survey", "#dataset", "#benchmark", "#open_source", "#multimodal", "#reasoning"], "emoji": "üé¨", "ru": {"title": "–û–±—É—á–µ–Ω–∏–µ –≤–∏–¥–µ–æ–º–æ–¥–µ–ª–µ–π –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–º—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é —á–µ—Ä–µ–∑ –º–∞—Å—à—Ç–∞–±–Ω—ã–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –±–æ–ª—å—à–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –≤–∏–¥–µ–æ–¥–∞–Ω–Ω—ã—Ö VBVR Datase
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#open_source", "#reasoning", "#benchmark"], "emoji": "üß≠", "ru": {"title": "–†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –Ω–∞ –º–Ω–æ–≥–æ–æ–±—Ä–∞–∑–∏–∏: –∫–∞–∫ —É–¥–µ—Ä–∂–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø—É—Ç–∏", "desc": "ManCAR ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –≤ —Å–∫—Ä—ã—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#rl", "#robotics", "#benchmark", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ä–æ–±–æ—Ç–∞ —á–µ—Ä–µ–∑ —Å–∫—Ä—ã—Ç—ã–µ –∑–Ω–∞–Ω–∏—è –≤–∏–¥–µ–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "TOPReward ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–∏–¥–µ–æ Visio
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#dataset", "#inference", "#architecture", "#cv", "#open_source", "#training", "#small_models", "#multimodal"], "emoji": "üì±", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", "desc": "Mobil
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#training", "#rl", "#reasoning"], "emoji": "üå≥", "ru": {"title": "–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –≤ —Ä–∞–∑—É–º–µ: –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π", "desc": "DSDR ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#agents", "#ethics", "#security"], "emoji": "üîì", "ru": {"title": "–ö–æ–≥–¥–∞ –ø–æ–º–æ—â–Ω–∏–∫–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —É–≥—Ä–æ–∑–æ–π: —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–π –ª–∞
[24.02.2026 09:44] Using data from previous issue: {"categories": [], "emoji": "üéº", "ru": {"title": "–Ø–≤–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤ –≤–º–µ—Å—Ç–æ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "SkillOrchestra –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö AI —Å–∏—Å—Ç–µ–º, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –¥–µ—Ç–∞–ª—å–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –¥–ª—è —É–ª—É—á
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#optimization"], "emoji": "‚ö°", "ru": {"title": "–≠–≤–æ–ª—é—Ü–∏—è —Å –º–æ–¥–µ–ª—å—é –º–∏—Ä–∞: –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ", "desc": "K-Search –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ GPU —è–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π —Å–æ–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â—É—é—Å—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —ç–≤—Ä–∏—Å—Ç–∏–∫ –≤ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö. –§—Ä–µ–π–º–≤–æ—Ä–∫
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#transfer_learning", "#optimization", "#architecture", "#3d", "#long_context", "#training"], "emoji": "üé¨", "ru": {"title": "–õ–∏–Ω–µ–π–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤ 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å tttLRM –¥–ª—è 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#architecture", "#training", "#healthcare", "#rl"], "emoji": "üíâ", "ru": {"title": "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É—é—Ç –∏–¥–µ–∞–ª—å–Ω—ã–µ –≤–∏—Ä—É—Å–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—á–∏–∫–∏ –¥–ª—è –≥–µ–Ω–Ω–æ–π —Ç–µ—Ä–∞–ø–∏–∏", "desc": "AAVGen ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–ø—Å–∏–¥–æ–≤ –∞–¥–µ–Ω–æ–∞—Å—Å–æ—Ü–∏–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏—Ä—É—Å–æ–≤ (A
[24.02.2026 09:44] Using data from previous issue: {"categories": [], "emoji": "üèóÔ∏è", "ru": {"title": "–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –º–æ–¥—É–ª—å–Ω—ã–µ 3D-–∞–∫—Ç–∏–≤—ã —á–µ—Ä–µ–∑ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "desc": "AssetFormer ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–æ–¥—É–ª—å–Ω—ã–µ 3D-–∞–∫—Ç–∏–≤—ã –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π, –∞–¥–∞–ø—Ç–∏—Ä—É—è —Ç–µ—Ö–Ω–∏–∫–∏ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è 
[24.02.2026 09:44] Using data from previous issue: {"categories": ["#transfer_learning", "#optimization", "#benchmark", "#dataset", "#open_source", "#training", "#rl", "#reasoning"], "emoji": "‚öôÔ∏è", "ru": {"title": "–ì–∏–±—Ä–∏–¥–Ω—ã–π —Å–∏–Ω—Ç–µ–∑: –æ–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—â–∏–π —É–º —Å –¥–æ–º–µ–Ω–Ω–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–æ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –≥–∏–±—Ä–∏–¥–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ
[24.02.2026 09:44] Renaming data file.
[24.02.2026 09:44] Renaming previous data. hf_papers.json to ./d/2026-02-24.json
[24.02.2026 09:44] Saving new data file.
[24.02.2026 09:44] Generating page.
[24.02.2026 09:44] Renaming previous page.
[24.02.2026 09:44] Renaming previous data. index.html to ./d/2026-02-24.html
[24.02.2026 09:44] Writing result.
[24.02.2026 09:44] Renaming log file.
[24.02.2026 09:44] Renaming previous data. log.txt to ./logs/2026-02-24_last_log.txt
