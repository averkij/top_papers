[05.01.2026 04:02] Read previous papers.
[05.01.2026 04:02] Generating top page (month).
[05.01.2026 04:02] Writing top page (month).
[05.01.2026 05:02] Read previous papers.
[05.01.2026 05:02] Get feed.
[05.01.2026 05:02] Get page data from previous paper. URL: https://huggingface.co/papers/2512.24615
[05.01.2026 05:02] Get page data from previous paper. URL: https://huggingface.co/papers/2512.24330
[05.01.2026 05:02] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00664
[05.01.2026 05:02] Get page data from previous paper. URL: https://huggingface.co/papers/2512.24271
[05.01.2026 05:02] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00417
[05.01.2026 05:02] Get page data from previous paper. URL: https://huggingface.co/papers/2601.00671
[05.01.2026 05:02] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[05.01.2026 05:02] No deleted papers detected.
[05.01.2026 05:02] Downloading and parsing papers (pdf, html). Total: 6.
[05.01.2026 05:02] Downloading and parsing paper https://huggingface.co/papers/2512.24615.
[05.01.2026 05:02] Extra JSON file exists (./assets/json/2512.24615.json), skip PDF parsing.
[05.01.2026 05:02] Paper image links file exists (./assets/img_data/2512.24615.json), skip HTML parsing.
[05.01.2026 05:02] Success.
[05.01.2026 05:02] Downloading and parsing paper https://huggingface.co/papers/2512.24330.
[05.01.2026 05:02] Extra JSON file exists (./assets/json/2512.24330.json), skip PDF parsing.
[05.01.2026 05:02] Paper image links file exists (./assets/img_data/2512.24330.json), skip HTML parsing.
[05.01.2026 05:02] Success.
[05.01.2026 05:02] Downloading and parsing paper https://huggingface.co/papers/2601.00664.
[05.01.2026 05:02] Extra JSON file exists (./assets/json/2601.00664.json), skip PDF parsing.
[05.01.2026 05:02] Paper image links file exists (./assets/img_data/2601.00664.json), skip HTML parsing.
[05.01.2026 05:02] Success.
[05.01.2026 05:02] Downloading and parsing paper https://huggingface.co/papers/2512.24271.
[05.01.2026 05:02] Extra JSON file exists (./assets/json/2512.24271.json), skip PDF parsing.
[05.01.2026 05:02] Paper image links file exists (./assets/img_data/2512.24271.json), skip HTML parsing.
[05.01.2026 05:02] Success.
[05.01.2026 05:02] Downloading and parsing paper https://huggingface.co/papers/2601.00417.
[05.01.2026 05:02] Extra JSON file exists (./assets/json/2601.00417.json), skip PDF parsing.
[05.01.2026 05:02] Paper image links file exists (./assets/img_data/2601.00417.json), skip HTML parsing.
[05.01.2026 05:02] Success.
[05.01.2026 05:02] Downloading and parsing paper https://huggingface.co/papers/2601.00671.
[05.01.2026 05:02] Extra JSON file exists (./assets/json/2601.00671.json), skip PDF parsing.
[05.01.2026 05:02] Paper image links file exists (./assets/img_data/2601.00671.json), skip HTML parsing.
[05.01.2026 05:02] Success.
[05.01.2026 05:02] Enriching papers with extra data.
[05.01.2026 05:02] ********************************************************************************
[05.01.2026 05:02] Abstract 0. Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic ...
[05.01.2026 05:02] ********************************************************************************
[05.01.2026 05:02] Abstract 1. While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulat...
[05.01.2026 05:02] ********************************************************************************
[05.01.2026 05:02] Abstract 2. A framework called Avatar Forcing uses diffusion forcing and direct preference optimization with synthetic losing samples to enable real-time, expressive multimodal interactions in talking head avatars without labeled data.  					AI-generated summary 				 Talking head generation creates lifelike ava...
[05.01.2026 05:02] ********************************************************************************
[05.01.2026 05:02] Abstract 3. Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy commo...
[05.01.2026 05:02] ********************************************************************************
[05.01.2026 05:02] Abstract 4. The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to mode...
[05.01.2026 05:02] ********************************************************************************
[05.01.2026 05:02] Abstract 5. FwPKM introduces a dynamic, fast-weight episodic memory mechanism for sequence modeling that balances storage capacity and efficiency, achieving strong performance on long-context tasks like Needle in a Haystack evaluations.  					AI-generated summary 				 Sequence modeling layers in modern language...
[05.01.2026 05:02] Read previous papers.
[05.01.2026 05:02] Generating reviews via LLM API.
[05.01.2026 05:02] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#benchmark", "#optimization", "#training", "#agents"], "emoji": "ü§ñ", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —ç–≤–æ–ª—é—Ü–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –±–µ–∑ —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è Youtu-Agent ‚Äî –º–æ–¥—É–ª—å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏
[05.01.2026 05:02] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#benchmark", "#dataset", "#cv", "#open_source", "#optimization", "#training", "#multimodal", "#agents"], "emoji": "üîç", "ru": {"title": "–ê–≥–µ–Ω—Ç—Å–∫–æ–µ –≤–∏–¥–µ–Ω–∏–µ: –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø
[05.01.2026 05:02] Using data from previous issue: {"categories": ["#video", "#optimization", "#training", "#multimodal", "#synthetic", "#diffusion", "#rlhf"], "emoji": "üé≠", "ru": {"title": "–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–µ –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏–µ", "desc": "Avatar Forcing ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–≤–∞—Ç–∞—Ä–æ–≤ —Å –≥–æ–≤–æ—Ä—è—â
[05.01.2026 05:02] Using data from previous issue: {"categories": ["#rl", "#dataset", "#video", "#open_source", "#training", "#multimodal", "#synthetic", "#diffusion", "#hallucinations"], "emoji": "üé¨", "ru": {"title": "–ë–æ—Ä—å–±–∞ —Å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏ –≤ –≤–∏–¥–µ–æ-–º–æ–¥–µ–ª—è—Ö —á–µ—Ä–µ–∑ —Å–∏–Ω—Ç–µ–∑ –∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–†–∞–±–æ—Ç–∞ –ø–æ—Å–≤—è—â–µ–Ω–∞ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö
[05.01.2026 05:02] Using data from previous issue: {"categories": ["#architecture"], "emoji": "üîÑ", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ —Å–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è Deep Delta Learning (DDL) ‚Äî –æ–±–æ–±—â–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö —Å–≤—è–∑–µ–π –≤ –≥–ª—É–±–æ–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—è—Ü–∏—é —Ç–æ–∂–¥–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–æ–±—Ä
[05.01.2026 05:02] Using data from previous issue: {"categories": ["#optimization", "#training", "#architecture", "#long_context"], "emoji": "üìö", "ru": {"title": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —ç–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ FwPKM, –∫–æ—Ç–æ—Ä–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å P
[05.01.2026 05:02] Renaming data file.
[05.01.2026 05:02] Renaming previous data. hf_papers.json to ./d/2026-01-05.json
[05.01.2026 05:02] Saving new data file.
[05.01.2026 05:02] Generating page.
[05.01.2026 05:02] Renaming previous page.
[05.01.2026 05:02] Renaming previous data. index.html to ./d/2026-01-05.html
[05.01.2026 05:02] Writing result.
[05.01.2026 05:02] Renaming log file.
[05.01.2026 05:02] Renaming previous data. log.txt to ./logs/2026-01-05_last_log.txt
