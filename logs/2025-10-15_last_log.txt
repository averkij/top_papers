[15.10.2025 15:13] Read previous papers.
[15.10.2025 15:13] Generating top page (month).
[15.10.2025 15:13] Writing top page (month).
[15.10.2025 16:12] Read previous papers.
[15.10.2025 16:12] Get feed.
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12276
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09116
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12586
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11693
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12798
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12399
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12403
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12747
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11057
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12773
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12693
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12784
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12789
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12635
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11683
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11602
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12709
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12225
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12801
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.01171
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11919
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12777
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12088
[15.10.2025 16:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.11661
[15.10.2025 16:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.09259
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12793
[15.10.2025 16:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.12497
[15.10.2025 16:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.12402
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12323
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11892
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11851
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11606
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11570
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11545
[15.10.2025 16:12] Extract page data from URL. URL: https://huggingface.co/papers/2510.11330
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09263
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09062
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08783
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12269
[15.10.2025 16:12] Get page data from previous paper. URL: https://huggingface.co/papers/2510.08666
[15.10.2025 16:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.10.2025 16:12] No deleted papers detected.
[15.10.2025 16:12] Downloading and parsing papers (pdf, html). Total: 40.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12276.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12276.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12276.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.09116.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.09116.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.09116.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12586.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12586.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12586.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.11693.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.11693.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.11693.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12798.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12798.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12798.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12399.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12399.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12399.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12403.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12403.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12403.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12747.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12747.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12747.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.11057.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.11057.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.11057.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12773.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12773.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12773.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12693.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12693.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12693.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12784.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12784.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12784.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12789.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12789.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12789.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12635.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12635.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12635.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.11683.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.11683.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.11683.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.11602.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.11602.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.11602.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12709.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12709.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12709.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12225.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12225.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12225.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12801.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12801.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12801.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.01171.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.01171.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.01171.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.11919.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.11919.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.11919.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12777.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12777.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12777.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.12088.
[15.10.2025 16:12] Extra JSON file exists (./assets/json/2510.12088.json), skip PDF parsing.
[15.10.2025 16:12] Paper image links file exists (./assets/img_data/2510.12088.json), skip HTML parsing.
[15.10.2025 16:12] Success.
[15.10.2025 16:12] Downloading and parsing paper https://huggingface.co/papers/2510.11661.
[15.10.2025 16:12] Downloading paper 2510.11661 from http://arxiv.org/pdf/2510.11661v1...
[15.10.2025 16:13] Extracting affiliations from text.
[15.10.2025 16:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"SR-Scientist: Scientific Equation Discovery With Agentic AI Shijie Xia1,2,3*, Yuhan Sun1,3* and Pengfei Liu1,2,3 (cid:0) *Co-first authors, (cid:0)Corresponding author, 1Shanghai Jiao Tong University, 2SII, 3GAIR 2025-10-14 Code: https://github.com/GAIR-NLP/SR-Scientist Models: SR-Scientist-30B Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, framework that elevates the LLM from simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our methods robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agents capabilities. 1. Introduction In the era of Agentic AI, Large Language Models (LLMs) have evolved from simple knowledge retrievers to agentic models capable of completing complex tasks by interacting with their environments (Schneider, 2025), as exemplified by products like Claude Code (Anthropic, 2025) and Gemini CLI (Google, 2025). These agents exhibit many characteristics of human scientists, such as engaging in long-horizon interaction with environmental feedback, operat"
[15.10.2025 16:13] Response: ```python
["Shanghai Jiao Tong University", "SII", "GAIR"]
```
[15.10.2025 16:13] Deleting PDF ./assets/pdf/2510.11661.pdf.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.09259.
[15.10.2025 16:13] Downloading paper 2510.09259 from http://arxiv.org/pdf/2510.09259v1...
[15.10.2025 16:13] Extracting affiliations from text.
[15.10.2025 16:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Preprint. DETECTING DATA CONTAMINATION FROM REINFORCEMENT LEARNING POST-TRAINING FOR LARGE LANGUAGE MODELS Yongding Tao1 Tian Wang1 Yihong Dong1 Huanyu Liu1 Kechi Zhang1 Xiaolong Hu2 Ge Li1 1 School of Computer Science, Peking University ydtao25@stu.pku.edu.cn lige@pku.edu.cn 2 New H3C Technologies Co., Ltd 5 2 0 O 0 1 ] . [ 1 9 5 2 9 0 . 0 1 5 2 : r a "
[15.10.2025 16:13] Response: ```python
["School of Computer Science, Peking University", "New H3C Technologies Co., Ltd"]
```
[15.10.2025 16:13] Deleting PDF ./assets/pdf/2510.09259.pdf.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.12793.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.12793.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.12793.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.12497.
[15.10.2025 16:13] Downloading paper 2510.12497 from http://arxiv.org/pdf/2510.12497v1...
[15.10.2025 16:13] Extracting affiliations from text.
[15.10.2025 16:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 1 ] . [ 1 7 9 4 2 1 . 0 1 5 2 : r MITIGATING THE NOISE SHIFT FOR DENOISING GENERATIVE MODELS VIA NOISE AWARENESS GUIDANCE Jincheng Zhong1, Boyuan Jiang2, Xin Tao2, Pengfei Wan2, Kun Gai2, Mingsheng Long1(cid:0) 1School of Software, BNRist, Tsinghua University, China 2Kling Team, Kuaishou Technology, China {zhongjinchengwork, jiangsutx}@gmail.com {jiangboyuan,wanpengfei}@kuaishou.com mingsheng@tsinghua.edu.cn "
[15.10.2025 16:13] Response: ```python
["School of Software, BNRist, Tsinghua University, China", "Kling Team, Kuaishou Technology, China"]
```
[15.10.2025 16:13] Deleting PDF ./assets/pdf/2510.12497.pdf.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.12402.
[15.10.2025 16:13] Downloading paper 2510.12402 from http://arxiv.org/pdf/2510.12402v1...
[15.10.2025 16:13] Extracting affiliations from text.
[15.10.2025 16:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 1 ] . [ 1 2 0 4 2 1 . 0 1 5 2 : r a Lizhang Chen Jonathan Li Kaizhao Liang Baiyu Su Cong Xie Nuo Wang Pierse Chen Liang Ni Lao Qiang Liu Abstract We introduce Cautious Weight Decay (CWD), one-line, optimizer-agnostic modification that applies weight decay only to parameter coordinates whose signs align with the optimizer update. Unlike standard decoupled decay, which implicitly optimizes regularized or constrained objective, CWD preserves the original loss and admits bilevel interpretation: it induces sliding-mode behavior upon reaching the stationary manifold, allowing it to search for locally Pareto-optimal stationary points of the unmodified objective. In practice, CWD is drop-in change for optimizers such as AdamW, Lion, and Muon, requiring no new hyperparameters or additional tuning. For language model pre-training and ImageNet classification, CWD consistently improves final loss and accuracy at millionto billion-parameter scales. Algorithm 1 Cautious Weight Decay (CWD) given parameters xt, optimizer update ut, learning rates ηt > 0, weight decay coefficient λ 0 xt+1 xt ηt ut + λI(utxt 0)xt (cid:16) (cid:17) entrywise multiplication Optimization algorithms lie at the core of modern deep learning, shaping not only convergence speed but also training stability and generalization ability across domains such as natural language processing and computer vision. As models and datasets scale, traditional methods such as stochastic gradient descent (SGD) and SGD with momentum [SMDH13] encounter limitations, including slow convergence in non-convex landscapes, sensitivity to learning rate schedules, and poor robustness to sparse or noisy gradients [SM20, ZMB+25]. In response, wide range of alternatives have emerged, including adaptive gradient methods [DHS11, KB15], approximate second-order approaches [MG15, GKS18, YGS+21, LLH+24, NCLL24, WHML25], and specialized algorithms for extreme training regimes [LLCL24, LYL24, XZL+24, HZJ+25, ZCL+25]. Among these advanc"
[15.10.2025 16:13] Response: ```python
[]
```
[15.10.2025 16:13] Extracting affiliations from text.
[15.10.2025 16:13] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 1 ] . [ 1 2 0 4 2 1 . 0 1 5 2 : r aLizhang Chen Jonathan Li Kaizhao Liang Baiyu Su Cong Xie Nuo Wang Pierse Chen Liang Ni Lao Qiang Liu Abstract We introduce Cautious Weight Decay (CWD), one-line, optimizer-agnostic modification that applies weight decay only to parameter coordinates whose signs align with the optimizer update. Unlike standard decoupled decay, which implicitly optimizes regularized or constrained objective, CWD preserves the original loss and admits bilevel interpretation: it induces sliding-mode behavior upon reaching the stationary manifold, allowing it to search for locally Pareto-optimal stationary points of the unmodified objective. In practice, CWD is drop-in change for optimizers such as AdamW, Lion, and Muon, requiring no new hyperparameters or additional tuning. For language model pre-training and ImageNet classification, CWD consistently improves final loss and accuracy at millionto billion-parameter scales.Algorithm 1 Cautious Weight Decay (CWD) given parameters xt, optimizer update ut, learning rates ηt > 0, weight decay coefficient λ 0 xt+1 xt ηt ut + λI(utxt 0)xt (cid:16) (cid:17) entrywise multiplication Optimization algorithms lie at the core of modern deep learning, shaping not only convergence speed but also training stability and generalization ability across domains such as natural language processing and computer vision. As models and datasets scale, traditional methods such as stochastic gradient descent (SGD) and SGD with momentum [SMDH13] encounter limitations, including slow convergence in non-convex landscapes, sensitivity to learning rate schedules, and poor robustness to sparse or noisy gradients [SM20, ZMB+25]. In response, wide range of alternatives have emerged, including adaptive gradient methods [DHS11, KB15], approximate second-order approaches [MG15, GKS18, YGS+21, LLH+24, NCLL24, WHML25], and specialized algorithms for extreme training regimes [LLCL24, LYL24, XZL+24, HZJ+25, ZCL+25]. Among these advances, decoupled weight decay [LH19] has proven especially influential. In its general form, decoupled weight decay augments any optimizer update ut with decay term applied directly to the parameters, i.e. xt+1 xt ηt(ut + λxt), ut = OptimizerUpdate(xt). Equal contribution by LC and JL. Correspondence: lzchen, jli@cs.utexas.edu University of Texas at Austin Google Figure 1: Final validation loss vs. weight decay coefficient λ for 338M models trained on C4 under Chinchilla scaling. Our approach (red) achieves lower final loss than standard weight decay (blue) while preserving the optimizer-specific optimum in λ. For each optimizer (AdamW, Lion, Muon), both methods use the same hyperparameters. This technique improves training stability and generalization by preventing the adaptive learning rates from interfering with regularization, as exemplified by the success of AdamW in large model training [BMR+20, DBK+21, TMS+23] and the subsequent development of state-of-the-art optimizers such as Lion [CLH+23], Lion-K [CLLL24], and Muon [JJB+24, LSY+25]. However, decoupled weight decay remains agnostic to the directional alignment between the optimizer update and the parameters, which may hurt performance when they conflict. Intuitively, when the update ut and parameters xt point in the same direction for given dimension, weight decay acts as regularizer that improves stability; however, when their directions differ, applying decay actively resists beneficial movement toward the optimum. Furthermore, decoupled weight decay has been shown to implicitly impose regularization terms on the objective function [CLLL24, XL24], which corresponds to parameter norm constraints for AdamW, Lion, and Muon. In light of these limitations, we propose simple refinement: cautious weight decay (CWD), in which decay is applied only in dimensions where the update and parameter signs align (Algorithm 1). Our main contributions are as follows. We introduce cautious weight decay, sign-selective extension of decoupled decay that applies weight decay only when the parameters and update align. Our technique can be implemented as one-line modification without introducing additional hyperparameters compared to standard decoupled decay. We use Lyapunov analysis to show that standard optimizers (SGD(M), Lion-K, Adam) with cautious weight decay are asymptotically stable and unbiased, in the sense that they optimize the original loss rather than regularized surrogate. The regularization effect of cautious weight decay instead becomes bilevel objective of finding locally Pareto-optimal points within the stationary manifold (Figure 2). Furthermore, we show that discrete-time Adam with cautious weight decay attains standard convergence rate in the 2 Figure 2: Trajectories of Adam, AdamW, and Adam + CWD on toy example. Adam halts at minimizer, while AdamW minimizes the objective within constrained region (green). In contrast, Adam + CWD exhibits sliding mode dynamics within the minimizer manifold. smooth nonconvex setting. In language modeling [OWS+25, KFP+25] and ImageNet classification [DDS+09], we observe that cautious weight decay generally accelerates convergence and lowers final validation loss for AdamW, Lion, and Muon (e.g., Figure 1). These improvements translate into higher zero-shot accuracy on standard benchmarks from 338M to 2B parameters and across architectures without retuning baseline settings (20,000 NVIDIA H100 HBM3-80GB GPU hours for all experiments).Gradient-based optimizers with decoupled weight decay can be characterized by the update rule xt+1 = (1 ηtλ)xt ηtut, (1) where ut := U(xt, g1, . . . , gt, t) is an adaptive, often sign-normalized update vector constructed from first and second-moment estimates (e.g., momentum buffers, diagonal preconditioners), ηt > 0 is the learning rate, and λ 0 is the decoupled weight decay coefficient. This framework encapsulates wide range of standard optimizers for machine learning, including AdamW and Lion-K. AdamW. The update vector is given by ut = D1 (cid:98)mt is bias-corrected first-moment estimate. Explicitly, (cid:98)mt, where Dt is diagonal preconditioner and (cid:98)mt = β1mt1 + (1 β1)gt 1 βt 1 , (cid:98)vt = β2vt1 + (1 β2)g2 1 βt 2 , Dt = diag (cid:16)(cid:112) (cid:17) , (cid:98)vt + ϵ1 where β1 and β2 are momentum coefficients and ϵ is numerical stability constant. Lion-K. Given convex function K, the update vector ut is momentum-filtered step that is preconditioned using subgradient, i.e. mt = β2mt1 "
[15.10.2025 16:13] Mistral response. {"id": "388a43c92aad4e30bcb1e750f8b1f717", "created": 1760544828, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1630, "total_tokens": 1649, "completion_tokens": 19}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\n    \"University of Texas at Austin\",\n    \"Google\"\n]\n```"}}]}
[15.10.2025 16:13] Response: ```python
[
    "University of Texas at Austin",
    "Google"
]
```
[15.10.2025 16:13] Deleting PDF ./assets/pdf/2510.12402.pdf.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.12323.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.12323.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.12323.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.11892.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.11892.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.11892.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.11851.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.11851.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.11851.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.11606.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.11606.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.11606.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.11570.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.11570.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.11570.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.11545.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.11545.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.11545.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.11330.
[15.10.2025 16:13] Downloading paper 2510.11330 from http://arxiv.org/pdf/2510.11330v1...
[15.10.2025 16:13] Extracting affiliations from text.
[15.10.2025 16:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"DIFFUSION-LINK: DIFFUSION PROBABILISTIC MODEL FOR BRIDGING THE AUDIO-TEXT MODALITY GAP KiHyun Nam1, Jongmin Choi1, Hyeongkeun Lee1, Jungwoo Heo2, Joon Son Chung1 1Korea Advanced Institute of Science and Technology, South Korea, 2University of Seoul, South Korea 5 2 0 2 3 1 ] . [ 1 0 3 3 1 1 . 0 1 5 2 : r ABSTRACT Contrastive audiolanguage pretraining yields powerful joint representations, yet persistent audiotext modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, diffusion-based modalitybridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zeroshot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers promising direction beyond knowledgeretrieval-centric designs. Code will be released upon acceptance1. Index Terms diffusion probabilistic model, modality gap, large language model, audio captioning, multimodal representation learning 1. INTRODUCTION Large-scale audiolanguage models have shown "
[15.10.2025 16:13] Response: ```python
["Korea Advanced Institute of Science and Technology, South Korea", "University of Seoul, South Korea"]
```
[15.10.2025 16:13] Deleting PDF ./assets/pdf/2510.11330.pdf.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.09263.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.09263.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.09263.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.09062.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.09062.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.09062.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.08783.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.08783.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.08783.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.12269.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.12269.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.12269.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Downloading and parsing paper https://huggingface.co/papers/2510.08666.
[15.10.2025 16:13] Extra JSON file exists (./assets/json/2510.08666.json), skip PDF parsing.
[15.10.2025 16:13] Paper image links file exists (./assets/img_data/2510.08666.json), skip HTML parsing.
[15.10.2025 16:13] Success.
[15.10.2025 16:13] Enriching papers with extra data.
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 0. Vision-language-action (VLA) models have recently shown strong potential in enabling robots to follow language instructions and execute precise actions. However, most VLAs are built upon vision-language models pretrained solely on 2D data, which lack accurate spatial awareness and hinder their abili...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 1. A new evaluation framework, DITING, and a reasoning-driven multi-agent evaluation framework, AgentEval, are introduced to assess the quality of web novel translations, revealing that Chinese-trained LLMs outperform larger foreign models.  					AI-generated summary 				 Large language models (LLMs) h...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 2. Pixel-space generative models are often more difficult to train and generally underperform compared to their latent-space counterparts, leaving a persistent performance and efficiency gap. In this paper, we introduce a novel two-stage training framework that closes this gap for pixel-space diffusion...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 3. Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approac...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 4. Object detection has long been dominated by traditional coordinate regression-based models, such as YOLO, DETR, and Grounding DINO. Although recent efforts have attempted to leverage MLLMs to tackle this task, they face challenges like low recall rate, duplicate predictions, coordinate misalignment,...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 5. The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed "Vibe Coding" where developers validate AI-generated implementations through outcome observation rather than lin...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 6. Robot learning transitions from model-based to data-driven methods, leveraging reinforcement learning and behavioral cloning to develop versatile, language-conditioned models for diverse tasks and robot types.  					AI-generated summary 				 Robot learning is at an inflection point, driven by rapid ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 7. Diffusion models have recently advanced video restoration, but applying them to real-world video super-resolution (VSR) remains challenging due to high latency, prohibitive computation, and poor generalization to ultra-high resolutions. Our goal in this work is to make diffusion-based VSR practical ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 8. Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 9. Large Language Models (LLMs) process every token through all layers of a transformer stack, causing wasted computation on simple queries and insufficient flexibility for harder ones that need deeper reasoning. Adaptive-depth methods can improve efficiency, but prior approaches rely on costly inferen...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 10. Recent advances in embodied AI highlight the potential of vision language models (VLMs) as agents capable of perception, reasoning, and interaction in complex environments. However, top-performing systems rely on large-scale models that are costly to deploy, while smaller VLMs lack the necessary kno...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 11. Recently, remarkable progress has been made in Unified Multimodal Models (UMMs), which integrate vision-language generation and understanding capabilities within a single framework. However, a significant gap exists where a model's strong visual understanding often fails to transfer to its visual ge...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 12. Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images and text. This separation constrains diffusion models' ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 13. Large Language Models face challenges in long-horizon agentic tasks as their constrained memory is easily overwhelmed by distracting or irrelevant context. Existing working memory methods typically rely on external, heuristic mechanisms that are decoupled from the agent's core policy. In this work, ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 14. Boundary-Guided Policy Optimization (BGPO) improves reinforcement learning for diffusion large language models by efficiently approximating likelihoods with a memory-efficient lower bound, enhancing performance in tasks like math problem solving, code generation, and planning.  					AI-generated sum...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 15. Systematic analysis of attention mechanisms in Transformer models shows that token mixing is essential, while other aspects like sequence dependency and mathematical form can be relaxed or interleaved to maintain performance.  					AI-generated summary 				 The success of Transformer language models...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 16. Multimodal embedding models aim to yield informative unified representations that empower diverse cross-modal tasks. Despite promising developments in the evolution from CLIP-based dual-tower architectures to large vision-language models, prior works still face unavoidable challenges in real-world a...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 17. Recent advances in vision-language models (VLMs) have made them highly effective at reasoning tasks. However, the principles underlying the construction of performant VL reasoning training datasets remain poorly understood. In this work, we introduce several data curation approaches and study their ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 18. Multimodal Large Language Models (MLLMs) in real-world applications require access to external knowledge sources and must remain responsive to the dynamic and ever-changing real-world information in order to address information-seeking and knowledge-intensive user queries. Existing approaches, such ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 19. Typicality bias in preference data causes mode collapse in LLMs, and Verbalized Sampling is introduced as a prompting strategy to enhance diversity without compromising accuracy or safety.  					AI-generated summary 				 Post-training alignment often reduces LLM diversity, leading to a phenomenon kn...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 20. Large reasoning models (LRMs) have led to new possibilities in terms of problem-solving, through the devising of a natural language thought process prior to answering a query. While their capabilities are well known across mathematics and coding tasks, their impact on the task of machine translation...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 21. Understanding the dynamics of a physical scene involves reasoning about the diverse ways it can potentially change, especially as a result of local interactions. We present the Flow Poke Transformer (FPT), a novel framework for directly predicting the distribution of local motion, conditioned on spa...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 22. OneLife framework models complex, stochastic environments using conditionally-activated programmatic laws within a probabilistic programming framework, enabling learning from minimal, unguided interaction and outperforming baselines in state ranking and fidelity.  					AI-generated summary 				 Symb...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 23. SR-Scientist, an autonomous AI framework, leverages LLMs to generate, implement, and optimize scientific equations, outperforming baselines across multiple disciplines.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveragi...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 24. Self-Critique addresses data contamination in the RL post-training phase of LLMs by detecting policy collapse, outperforming existing methods with significant improvements in AUC.  					AI-generated summary 				 Data contamination poses a significant threat to the reliable evaluation of Large Langua...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 25. Existing Multimodal Large Language Models (MLLMs) suffer from increased inference costs due to the additional vision tokens introduced by image inputs. In this work, we propose Visual Consistency Learning (ViCO), a novel training algorithm that enables the model to represent images of varying semant...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 26. Noise Awareness Guidance (NAG) addresses noise shift in diffusion models by aligning sampling trajectories with the pre-defined noise schedule, improving generation quality.  					AI-generated summary 				 Existing denoising generative models rely on solving discretized reverse-time SDEs or ODEs. In...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 27. Cautious Weight Decay (CWD) enhances optimizer performance by applying weight decay selectively, improving accuracy and loss in large-scale models without additional tuning.  					AI-generated summary 				 We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic modification that app...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 28. RAG-Anything is a unified framework that enhances multimodal knowledge retrieval by integrating cross-modal relationships and semantic matching, outperforming existing methods on complex benchmarks.  					AI-generated summary 				 Retrieval-Augmented Generation (RAG) has emerged as a fundamental par...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 29. LLMs can enhance decision-making in digital environments but struggle with long-horizon simulations due to hallucination and static knowledge. R-WoM improves performance by integrating external, up-to-date knowledge.  					AI-generated summary 				 Large Language Models (LLMs) can serve as world mod...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 30. DR agents based on LLMs can generate detailed reports from harmful queries, highlighting alignment failures and the need for specialized safety measures.  					AI-generated summary 				 Deep Research (DR) agents built on Large Language Models (LLMs) can perform complex, multi-step research by decomp...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 31. ExpVid, a new benchmark for evaluating multimodal large language models on scientific experiment videos, highlights gaps in fine-grained perception, procedural understanding, and scientific reasoning.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) hold promise for accelerat...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 32. Reasoning-based safety guardrails in Large Reasoning Models are vulnerable to subtle prompt manipulations, leading to high attack success rates across various benchmarks.  					AI-generated summary 				 Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs), such as deliberative ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 33. PART reformulates reasoning traces to preserve information while disrupting unauthorized distillation in Large Language Models.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) show that extending the length of reasoning chains significantly improves performance on com...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 34. Diffusion-Link, a diffusion-based modality-bridging module, reduces the audio-text modality gap and enhances multimodal encoder-LLM coupling, achieving state-of-the-art performance in automatic audio captioning.  					AI-generated summary 				 Contrastive audio-language pretraining yields powerful j...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 35. SynthID-Image, a deep learning system for watermarking AI-generated imagery, demonstrates state-of-the-art performance in visual quality and robustness, and is deployed across Google's services.  					AI-generated summary 				 We introduce SynthID-Image, a deep learning-based system for invisibly wa...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 36. ReFIne, a new training framework, enhances the trustworthiness of reasoning models by improving interpretability, faithfulness, and reliability through structured traces, decisive information disclosure, and confidence estimates.  					AI-generated summary 				 Recent advances in long chain-of-thoug...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 37. In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, ...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 38. Tensor logic unifies neural and symbolic AI by using tensor equations, enabling scalable, learnable, and transparent AI systems.  					AI-generated summary 				 Progress in AI is hindered by the lack of a programming language with all the requisite features. Libraries like PyTorch and TensorFlow pro...
[15.10.2025 16:13] ********************************************************************************
[15.10.2025 16:13] Abstract 39. dInfer is an efficient and extensible framework for diffusion-based large language model inference, achieving significant speedups over existing systems without compromising output quality.  					AI-generated summary 				 Diffusion-based large language models (dLLMs) have emerged as a promising alte...
[15.10.2025 16:13] Read previous papers.
[15.10.2025 16:13] Generating reviews via LLM API.
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#3d", "#optimization", "#training", "#agents", "#alignment"], "emoji": "🤖", "ru": {"title": "Обучение роботов пространственному мышлению без 3D сенсоров", "desc": "Статья представляет Spatial Forcing (SF) — метод для улучшения vision-language-action (VLA) моделей в робототехнике. Пр
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#reasoning", "#dataset", "#multilingual", "#benchmark"], "emoji": "📚", "ru": {"title": "Китайские LLM побеждают в переводе веб-романов", "desc": "Исследователи представили DITING — первую комплексную систему оценки качества перевода веб-романо
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#training", "#diffusion", "#cv", "#optimization"], "emoji": "🎯", "ru": {"title": "Двухэтапное обучение закрывает разрыв между пиксельными и латентными генеративными моделями", "desc": "Исследователи предложили новый двухэтапный подход для обучения диффузионных моделей и consistency 
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#low_resource", "#data", "#benchmark", "#multimodal", "#transfer_learning", "#training", "#alignment"], "emoji": "🔗", "ru": {"title": "Генеративное предобучение как ключ к качественным мультимодальным эмбеддингам", "desc": "Исследователи обнаружили, что превосходство мультимодальных
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#training", "#optimization", "#rl"], "emoji": "🔍", "ru": {"title": "Rex-Omni: новый уровень в обнаружении объектов", "desc": "В статье рассматривается новая модель Rex-Omni, которая улучшает задачи обнаружения объектов, используя подходы LLM. Rex-Omni достигает
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#multimodal", "#training", "#survey", "#agi", "#agents", "#rl"], "emoji": "🎵", "ru": {"title": "Vibe Coding: когда разработчик проверяет результат, а не читает код", "desc": "Статья исследует новую парадигму разработки под названием \"Vibe Coding\", где разработчики проверяют работо
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#games", "#agents", "#robotics"], "emoji": "🤖", "ru": {"title": "От классики к данным: новая эра обучения роботов", "desc": "Статья представляет собой учебное руководство по современному машинному обучению для роботов. Авторы описывают переход о
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#video", "#open_source", "#inference", "#training", "#dataset", "#diffusion"], "emoji": "⚡", "ru": {"title": "Диффузионное видео super-resolution в реальном времени", "desc": "FlashVSR — первая диффузионная модель для видео super-resolution в реальном времени, работающая со скорость
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#multimodal", "#cv"], "emoji": "🎯", "ru": {"title": "Временное выравнивание для точной генерации в диффузионных моделях", "desc": "Диффузионные модели показывают отличные результаты в генерации, но накапливают ошибки в процессе работы, осо
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#optimization", "#training", "#inference"], "emoji": "🧭", "ru": {"title": "Умная маршрутизация слоёв: LLM учатся пропускать ненужные вычисления", "desc": "В статье представлен Dr.LLM — метод динамической маршрутизации слоёв для больших языковых моделей
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#transfer_learning", "#agents", "#rl"], "emoji": "🤖", "ru": {"title": "Маленькие модели учатся действовать как большие", "desc": "Статья представляет ERA — двухэтапный фреймворк для обучения компактных vision language models действовать в 
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#multimodal", "#transfer_learning"], "emoji": "🔄", "ru": {"title": "Самообучение мультимодальных моделей через внутреннюю самооценку", "desc": "Исследователи обнаружили парадокс: мультимодальные модели могут хорошо понимать изображения, но плохо их гене
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#reasoning", "#training", "#transfer_learning", "#diffusion"], "emoji": "🔗", "ru": {"title": "Единый энкодер для текста и изображений в диффузионных моделях", "desc": "UniFusion — это диффузионная модель для генерации изображений, которая использует замороженну
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#training", "#optimization", "#agents", "#rl"], "emoji": "🧠", "ru": {"title": "Память как действие: LLM учатся управлять своим контекстом", "desc": "Большие языковые модели сталкиваются с проблемой ограниченной памяти при решении длинных задач, когда к
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#games", "#rlhf", "#training", "#optimization", "#rl"], "emoji": "🎯", "ru": {"title": "Эффективное обучение диффузионных языковых моделей с помощью линейной аппроксимации", "desc": "Статья представляет метод BGPO для reinforcement learning в диффузионных LLM, которые сталкиваются с 
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#math", "#architecture", "#optimization", "#interpretability", "#training"], "emoji": "🔍", "ru": {"title": "Смешивание токенов важнее, чем точная формула attention", "desc": "Исследователи систематически изучили механизм внимания в Transformer моделях, разбирая его на составные част
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#multimodal"], "emoji": "⛵", "ru": {"title": "SAIL-Embedding: Универсальная мультимодальная модель для поиска и рекомендаций", "desc": "Статья представляет SAIL-Embedding — омнимодальную модель эмбеддингов, которая решает проблемы ограниченной поддержки
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#reasoning", "#dataset", "#benchmark", "#data"], "emoji": "🐝", "ru": {"title": "HoneyBee: Как правильно готовить данные для обучения визуального мышления", "desc": "Исследователи изучили принципы создания эффективных датасетов для обучения vision-language модел
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#training", "#dataset", "#agi", "#optimization", "#rag", "#benchmark"], "emoji": "🔍", "ru": {"title": "Мультимодальный поиск в интернете с обучением через подкрепление", "desc": "Статья представляет DeepMMSearch-R1 — первую мультимодальную LLM, способную
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#hallucinations", "#data", "#inference", "#training", "#alignment", "#story_generation", "#synthetic"], "emoji": "🎲", "ru": {"title": "Разблокировка разнообразия LLM через вербализацию вероятностей", "desc": "Исследователи обнаружили, что режимный коллапс в языковых моделях вызван с
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#low_resource", "#reasoning", "#training", "#multilingual", "#machine_translation", "#synthetic"], "emoji": "🤔", "ru": {"title": "Размышления не помогают LLM лучше переводить", "desc": "Исследователи изучили, помогают ли \"токены размышлений\" (thinking tokens) большим reasoning мод
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#cv", "#interpretability", "#open_source", "#reasoning", "#training", "#optimization", "#synthetic"], "emoji": "🔄", "ru": {"title": "Flow Poke Transformer: новая эра в предсказании движения", "desc": "В статье представлена новая модель Flow Poke Transformer (FPT), которая предсказыв
[15.10.2025 16:13] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#reasoning", "#optimization", "#games", "#agents"], "emoji": "🎮", "ru": {"title": "Обучение модели мира за одну жизнь без подсказок", "desc": "Статья представляет OneLife — фреймворк для символьного моделирования динамики сложных стохастических сред через програ
[15.10.2025 16:13] Querying the API.
[15.10.2025 16:13] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

SR-Scientist, an autonomous AI framework, leverages LLMs to generate, implement, and optimize scientific equations, outperforming baselines across multiple disciplines.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities.
[15.10.2025 16:13] Response: ```json
{
  "desc": "В статье представлен SR-Scientist — автономный AI-фреймворк, который использует LLM для открытия научных уравнений. В отличие от существующих методов, где LLM выступают только как генераторы уравнений, SR-Scientist действует как полноценный AI-учёный: анализирует данные, реализует уравнения в коде, тестирует их и оптимизирует на основе обратной связи. Система превосходит базовые методы на 6-35% на датасетах из четырёх научных дисциплин и демонстрирует устойчивость к шуму и способность к генерализации. Для дальнейшего улучшения агента авторы также разработали end-to-end reinforcement learning фреймворк.",
  "emoji": "🔬",
  "title": "AI-учёный, который сам открывает научные уравнения"
}
```
[15.10.2025 16:13] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SR-Scientist, an autonomous AI framework, leverages LLMs to generate, implement, and optimize scientific equations, outperforming baselines across multiple disciplines.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities."

[15.10.2025 16:14] Response: ```python
['AGENTS', 'RL', 'DATASET']
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"SR-Scientist, an autonomous AI framework, leverages LLMs to generate, implement, and optimize scientific equations, outperforming baselines across multiple disciplines.  					AI-generated summary 				 Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities."

[15.10.2025 16:14] Response: ```python
['SCIENCE', 'OPTIMIZATION']
```
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SR-Scientist is an advanced AI framework that utilizes Large Language Models (LLMs) to autonomously generate, implement, and optimize scientific equations. Unlike traditional methods that limit LLMs to proposing equations, SR-Scientist enables them to analyze data, write code, and refine equations based on experimental results. The framework incorporates a code interpreter and a suite of tools for data analysis, allowing the AI to operate with minimal human intervention. Empirical studies show that SR-Scientist significantly outperforms existing methods across various scientific disciplines, demonstrating its effectiveness and robustness in equation discovery and optimization.","title":"Empowering AI to Become Autonomous Scientists"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SR-Scientist is an advanced AI framework that utilizes Large Language Models (LLMs) to autonomously generate, implement, and optimize scientific equations. Unlike traditional methods that limit LLMs to proposing equations, SR-Scientist enables them to analyze data, write code, and refine equations based on experimental results. The framework incorporates a code interpreter and a suite of tools for data analysis, allowing the AI to operate with minimal human intervention. Empirical studies show that SR-Scientist significantly outperforms existing methods across various scientific disciplines, demonstrating its effectiveness and robustness in equation discovery and optimization.', title='Empowering AI to Become Autonomous Scientists'))
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"SR-Scientist是一个自主的人工智能框架，利用大型语言模型（LLMs）生成、实现和优化科学方程。与传统方法不同，SR-Scientist不仅仅是方程的提出者，而是一个能够编写代码、分析数据并根据实验反馈优化方程的自主AI科学家。该框架通过将代码解释器与数据分析和方程评估工具结合，提升了方程优化的效率。实验结果表明，SR-Scientist在四个科学领域的数据集上，性能超越了基线方法6%到35%。","title":"自主AI科学家：SR-Scientist的创新之路"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='SR-Scientist是一个自主的人工智能框架，利用大型语言模型（LLMs）生成、实现和优化科学方程。与传统方法不同，SR-Scientist不仅仅是方程的提出者，而是一个能够编写代码、分析数据并根据实验反馈优化方程的自主AI科学家。该框架通过将代码解释器与数据分析和方程评估工具结合，提升了方程优化的效率。实验结果表明，SR-Scientist在四个科学领域的数据集上，性能超越了基线方法6%到35%。', title='自主AI科学家：SR-Scientist的创新之路'))
[15.10.2025 16:14] Querying the API.
[15.10.2025 16:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Self-Critique addresses data contamination in the RL post-training phase of LLMs by detecting policy collapse, outperforming existing methods with significant improvements in AUC.  					AI-generated summary 				 Data contamination poses a significant threat to the reliable evaluation of Large Language Models (LLMs). This issue arises when benchmark samples may inadvertently appear in training sets, compromising the validity of reported performance. While detection methods have been developed for the pre-training and Supervised Fine-Tuning stages, a critical research gap exists for the increasingly significant phase of Reinforcement Learning (RL) post-training. As RL post-training becomes pivotal for advancing LLM reasoning, the absence of specialized contamination detection methods in this paradigm presents a critical vulnerability. To address this, we conduct the first systematic study of data detection within RL post-training scenario and propose Self-Critique. Our method is motivated by a key observation: after RL phase, the output entropy distribution of LLMs tends to collapse into highly specific and sparse modes. Self-Critique probes for the underlying policy collapse, i.e., the model's convergence to a narrow reasoning path, which causes this entropy reduction. To facilitate this research, we also introduce RL-MIA, a benchmark constructed to simulate this specific contamination scenario. Extensive experiments show that Self-Critique significantly outperforms baseline methods across multiple models and contamination tasks, achieving an AUC improvement of up to 30%. Whereas existing methods are close to a random guess for RL-phase contamination, our method makes detection possible.
[15.10.2025 16:14] Response: ```json
{
  "title": "Детектор загрязнения данных через коллапс политики в RL",
  "desc": "Исследователи представили метод Self-Critique для обнаружения загрязнения данных на этапе RL пост-тренинга больших языковых моделей. Метод основан на наблюдении, что после RL-обучения распределение энтропии выходов LLM схлопывается в узкие специфические режимы. Self-Critique детектирует коллапс политики модели — её схождение к узкому пути рассуждений, что указывает на возможное загрязнение данных. Метод показал улучшение метрики AUC до 30% по сравнению с существующими подходами, которые работают почти как случайное угадывание.",
  "emoji": "🔍",
  "desc_en": ""
}
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Self-Critique addresses data contamination in the RL post-training phase of LLMs by detecting policy collapse, outperforming existing methods with significant improvements in AUC.  					AI-generated summary 				 Data contamination poses a significant threat to the reliable evaluation of Large Language Models (LLMs). This issue arises when benchmark samples may inadvertently appear in training sets, compromising the validity of reported performance. While detection methods have been developed for the pre-training and Supervised Fine-Tuning stages, a critical research gap exists for the increasingly significant phase of Reinforcement Learning (RL) post-training. As RL post-training becomes pivotal for advancing LLM reasoning, the absence of specialized contamination detection methods in this paradigm presents a critical vulnerability. To address this, we conduct the first systematic study of data detection within RL post-training scenario and propose Self-Critique. Our method is motivated by a key observation: after RL phase, the output entropy distribution of LLMs tends to collapse into highly specific and sparse modes. Self-Critique probes for the underlying policy collapse, i.e., the model's convergence to a narrow reasoning path, which causes this entropy reduction. To facilitate this research, we also introduce RL-MIA, a benchmark constructed to simulate this specific contamination scenario. Extensive experiments show that Self-Critique significantly outperforms baseline methods across multiple models and contamination tasks, achieving an AUC improvement of up to 30%. Whereas existing methods are close to a random guess for RL-phase contamination, our method makes detection possible."

[15.10.2025 16:14] Response: ```python
['RL', 'BENCHMARK', 'TRAINING']
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Self-Critique addresses data contamination in the RL post-training phase of LLMs by detecting policy collapse, outperforming existing methods with significant improvements in AUC.  					AI-generated summary 				 Data contamination poses a significant threat to the reliable evaluation of Large Language Models (LLMs). This issue arises when benchmark samples may inadvertently appear in training sets, compromising the validity of reported performance. While detection methods have been developed for the pre-training and Supervised Fine-Tuning stages, a critical research gap exists for the increasingly significant phase of Reinforcement Learning (RL) post-training. As RL post-training becomes pivotal for advancing LLM reasoning, the absence of specialized contamination detection methods in this paradigm presents a critical vulnerability. To address this, we conduct the first systematic study of data detection within RL post-training scenario and propose Self-Critique. Our method is motivated by a key observation: after RL phase, the output entropy distribution of LLMs tends to collapse into highly specific and sparse modes. Self-Critique probes for the underlying policy collapse, i.e., the model's convergence to a narrow reasoning path, which causes this entropy reduction. To facilitate this research, we also introduce RL-MIA, a benchmark constructed to simulate this specific contamination scenario. Extensive experiments show that Self-Critique significantly outperforms baseline methods across multiple models and contamination tasks, achieving an AUC improvement of up to 30%. Whereas existing methods are close to a random guess for RL-phase contamination, our method makes detection possible."

[15.10.2025 16:14] Response: ```python
["SECURITY", "REASONING", "HALLUCINATIONS"]
```
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Self-Critique, a novel method designed to detect data contamination during the Reinforcement Learning (RL) post-training phase of Large Language Models (LLMs). Data contamination can lead to policy collapse, where the model\'s output becomes overly focused and less diverse, compromising its performance evaluation. The authors highlight a significant gap in existing detection methods, which primarily address earlier training stages but overlook the critical RL post-training phase. Through extensive experiments, Self-Critique demonstrates a substantial improvement in Area Under the Curve (AUC) metrics, outperforming traditional methods and providing a reliable solution for identifying contamination in LLMs.","title":"Self-Critique: Enhancing RL Post-Training Integrity in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces Self-Critique, a novel method designed to detect data contamination during the Reinforcement Learning (RL) post-training phase of Large Language Models (LLMs). Data contamination can lead to policy collapse, where the model's output becomes overly focused and less diverse, compromising its performance evaluation. The authors highlight a significant gap in existing detection methods, which primarily address earlier training stages but overlook the critical RL post-training phase. Through extensive experiments, Self-Critique demonstrates a substantial improvement in Area Under the Curve (AUC) metrics, outperforming traditional methods and providing a reliable solution for identifying contamination in LLMs.", title='Self-Critique: Enhancing RL Post-Training Integrity in LLMs'))
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"自我批评方法解决了大型语言模型（LLMs）在强化学习（RL）后训练阶段的数据污染问题，通过检测策略崩溃来提高性能。数据污染会影响LLMs的可靠评估，尤其是在RL后训练阶段缺乏有效的检测方法。我们首次系统研究了RL后训练中的数据检测，并提出了自我批评方法，能够识别模型收敛到狭窄推理路径的现象。实验结果表明，自我批评在多个模型和污染任务中显著优于现有方法，AUC提升可达30%。","title":"自我批评：提升RL后训练阶段的检测能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='自我批评方法解决了大型语言模型（LLMs）在强化学习（RL）后训练阶段的数据污染问题，通过检测策略崩溃来提高性能。数据污染会影响LLMs的可靠评估，尤其是在RL后训练阶段缺乏有效的检测方法。我们首次系统研究了RL后训练中的数据检测，并提出了自我批评方法，能够识别模型收敛到狭窄推理路径的现象。实验结果表明，自我批评在多个模型和污染任务中显著优于现有方法，AUC提升可达30%。', title='自我批评：提升RL后训练阶段的检测能力'))
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#cv", "#training", "#inference", "#interpretability", "#agi", "#optimization", "#multimodal"], "emoji": "🎯", "ru": {"title": "Умное сжатие визуальных токенов по сложности изображения", "desc": "Исследователи предложили метод Visual Consistency Learning (ViCO), который позволяет mult
[15.10.2025 16:14] Querying the API.
[15.10.2025 16:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Noise Awareness Guidance (NAG) addresses noise shift in diffusion models by aligning sampling trajectories with the pre-defined noise schedule, improving generation quality.  					AI-generated summary 				 Existing denoising generative models rely on solving discretized reverse-time SDEs or ODEs. In this paper, we identify a long-overlooked yet pervasive issue in this family of models: a misalignment between the pre-defined noise level and the actual noise level encoded in intermediate states during sampling. We refer to this misalignment as noise shift. Through empirical analysis, we demonstrate that noise shift is widespread in modern diffusion models and exhibits a systematic bias, leading to sub-optimal generation due to both out-of-distribution generalization and inaccurate denoising updates. To address this problem, we propose Noise Awareness Guidance (NAG), a simple yet effective correction method that explicitly steers sampling trajectories to remain consistent with the pre-defined noise schedule. We further introduce a classifier-free variant of NAG, which jointly trains a noise-conditional and a noise-unconditional model via noise-condition dropout, thereby eliminating the need for external classifiers. Extensive experiments, including ImageNet generation and various supervised fine-tuning tasks, show that NAG consistently mitigates noise shift and substantially improves the generation quality of mainstream diffusion models.
[15.10.2025 16:14] Response: ```json
{
  "title": "Исправление шума в диффузионных моделях для улучшения генерации",
  "desc": "Исследователи обнаружили проблему в диффузионных моделях: несоответствие между заранее определённым уровнем шума и фактическим шумом в промежуточных состояниях при генерации, что они назвали \"сдвигом шума\". Этот сдвиг приводит к ухудшению качества генерации из-за проблем с обобщением и неточного шумоподавления. Для решения предложен метод Noise Awareness Guidance (NAG), который корректирует траекторию сэмплирования, чтобы она соответствовала заданному расписанию шума. Эксперименты на ImageNet и других задачах показали, что NAG значительно улучшает качество генерации современных диффузионных моделей.",
  "emoji": "🎯"
}
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Noise Awareness Guidance (NAG) addresses noise shift in diffusion models by aligning sampling trajectories with the pre-defined noise schedule, improving generation quality.  					AI-generated summary 				 Existing denoising generative models rely on solving discretized reverse-time SDEs or ODEs. In this paper, we identify a long-overlooked yet pervasive issue in this family of models: a misalignment between the pre-defined noise level and the actual noise level encoded in intermediate states during sampling. We refer to this misalignment as noise shift. Through empirical analysis, we demonstrate that noise shift is widespread in modern diffusion models and exhibits a systematic bias, leading to sub-optimal generation due to both out-of-distribution generalization and inaccurate denoising updates. To address this problem, we propose Noise Awareness Guidance (NAG), a simple yet effective correction method that explicitly steers sampling trajectories to remain consistent with the pre-defined noise schedule. We further introduce a classifier-free variant of NAG, which jointly trains a noise-conditional and a noise-unconditional model via noise-condition dropout, thereby eliminating the need for external classifiers. Extensive experiments, including ImageNet generation and various supervised fine-tuning tasks, show that NAG consistently mitigates noise shift and substantially improves the generation quality of mainstream diffusion models."

[15.10.2025 16:14] Response: ```python
["DATA", "TRAINING", "CV"]
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Noise Awareness Guidance (NAG) addresses noise shift in diffusion models by aligning sampling trajectories with the pre-defined noise schedule, improving generation quality.  					AI-generated summary 				 Existing denoising generative models rely on solving discretized reverse-time SDEs or ODEs. In this paper, we identify a long-overlooked yet pervasive issue in this family of models: a misalignment between the pre-defined noise level and the actual noise level encoded in intermediate states during sampling. We refer to this misalignment as noise shift. Through empirical analysis, we demonstrate that noise shift is widespread in modern diffusion models and exhibits a systematic bias, leading to sub-optimal generation due to both out-of-distribution generalization and inaccurate denoising updates. To address this problem, we propose Noise Awareness Guidance (NAG), a simple yet effective correction method that explicitly steers sampling trajectories to remain consistent with the pre-defined noise schedule. We further introduce a classifier-free variant of NAG, which jointly trains a noise-conditional and a noise-unconditional model via noise-condition dropout, thereby eliminating the need for external classifiers. Extensive experiments, including ImageNet generation and various supervised fine-tuning tasks, show that NAG consistently mitigates noise shift and substantially improves the generation quality of mainstream diffusion models."

[15.10.2025 16:14] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Noise Awareness Guidance (NAG), a method designed to correct noise shift in diffusion models. Noise shift occurs when there is a mismatch between the expected noise level and the actual noise level during the sampling process, leading to poor generation quality. NAG aligns the sampling trajectories with a pre-defined noise schedule, ensuring that the model generates outputs that are more accurate and consistent. The authors also present a classifier-free version of NAG that simplifies the training process while maintaining high performance in generating images and other tasks.","title":"Aligning Noise for Better Generative Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces Noise Awareness Guidance (NAG), a method designed to correct noise shift in diffusion models. Noise shift occurs when there is a mismatch between the expected noise level and the actual noise level during the sampling process, leading to poor generation quality. NAG aligns the sampling trajectories with a pre-defined noise schedule, ensuring that the model generates outputs that are more accurate and consistent. The authors also present a classifier-free version of NAG that simplifies the training process while maintaining high performance in generating images and other tasks.', title='Aligning Noise for Better Generative Models'))
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"噪声意识引导（NAG）解决了扩散模型中的噪声偏移问题，通过将采样轨迹与预定义的噪声调度对齐，从而提高生成质量。我们发现，现有的去噪生成模型在采样过程中，预定义的噪声水平与实际噪声水平之间存在不匹配，这种现象被称为噪声偏移。通过实证分析，我们证明了噪声偏移在现代扩散模型中普遍存在，并导致生成效果不佳。NAG是一种简单有效的修正方法，能够显著改善主流扩散模型的生成质量。","title":"噪声意识引导：提升扩散模型生成质量的关键"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='噪声意识引导（NAG）解决了扩散模型中的噪声偏移问题，通过将采样轨迹与预定义的噪声调度对齐，从而提高生成质量。我们发现，现有的去噪生成模型在采样过程中，预定义的噪声水平与实际噪声水平之间存在不匹配，这种现象被称为噪声偏移。通过实证分析，我们证明了噪声偏移在现代扩散模型中普遍存在，并导致生成效果不佳。NAG是一种简单有效的修正方法，能够显著改善主流扩散模型的生成质量。', title='噪声意识引导：提升扩散模型生成质量的关键'))
[15.10.2025 16:14] Querying the API.
[15.10.2025 16:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Cautious Weight Decay (CWD) enhances optimizer performance by applying weight decay selectively, improving accuracy and loss in large-scale models without additional tuning.  					AI-generated summary 				 We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic modification that applies weight decay only to parameter coordinates whose signs align with the optimizer update. Unlike standard decoupled decay, which implicitly optimizes a regularized or constrained objective, CWD preserves the original loss and admits a bilevel interpretation: it induces sliding-mode behavior upon reaching the stationary manifold, allowing it to search for locally Pareto-optimal stationary points of the unmodified objective. In practice, CWD is a drop-in change for optimizers such as AdamW, Lion, and Muon, requiring no new hyperparameters or additional tuning. For language model pre-training and ImageNet classification, CWD consistently improves final loss and accuracy at million- to billion-parameter scales.
[15.10.2025 16:14] Response: ```json
{
  "title": "Осторожное затухание весов: умный способ регуляризации нейросетей",
  "desc": "В статье представлен метод Cautious Weight Decay (CWD) — простая модификация оптимизаторов, которая применяет weight decay только к тем параметрам, чьи знаки совпадают с направлением обновления. В отличие от стандартного decoupled weight decay, CWD сохраняет исходную функцию потерь и демонстрирует поведение скользящего режима при достижении стационарного многообразия. Метод работает как drop-in замена для популярных оптимизаторов типа AdamW, Lion и Muon, не требуя дополнительных гиперпараметров или настройки. На задачах предобучения языковых моделей и классификации ImageNet метод показывает стабильное улучшение точности и loss на моделях от миллионов до миллиардов параметров.",
  "emoji": "🎯"
}
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Cautious Weight Decay (CWD) enhances optimizer performance by applying weight decay selectively, improving accuracy and loss in large-scale models without additional tuning.  					AI-generated summary 				 We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic modification that applies weight decay only to parameter coordinates whose signs align with the optimizer update. Unlike standard decoupled decay, which implicitly optimizes a regularized or constrained objective, CWD preserves the original loss and admits a bilevel interpretation: it induces sliding-mode behavior upon reaching the stationary manifold, allowing it to search for locally Pareto-optimal stationary points of the unmodified objective. In practice, CWD is a drop-in change for optimizers such as AdamW, Lion, and Muon, requiring no new hyperparameters or additional tuning. For language model pre-training and ImageNet classification, CWD consistently improves final loss and accuracy at million- to billion-parameter scales."

[15.10.2025 16:14] Response: ```python
['TRAINING', 'ARCHITECTURE']
```
[15.10.2025 16:14] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Cautious Weight Decay (CWD) enhances optimizer performance by applying weight decay selectively, improving accuracy and loss in large-scale models without additional tuning.  					AI-generated summary 				 We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic modification that applies weight decay only to parameter coordinates whose signs align with the optimizer update. Unlike standard decoupled decay, which implicitly optimizes a regularized or constrained objective, CWD preserves the original loss and admits a bilevel interpretation: it induces sliding-mode behavior upon reaching the stationary manifold, allowing it to search for locally Pareto-optimal stationary points of the unmodified objective. In practice, CWD is a drop-in change for optimizers such as AdamW, Lion, and Muon, requiring no new hyperparameters or additional tuning. For language model pre-training and ImageNet classification, CWD consistently improves final loss and accuracy at million- to billion-parameter scales."

[15.10.2025 16:14] Response: ```python
["OPTIMIZATION"]
```
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Cautious Weight Decay (CWD) is a new technique that improves the performance of optimizers by applying weight decay selectively based on the direction of the optimizer\'s updates. This method differs from traditional weight decay by maintaining the original loss function, allowing for a more effective search for optimal solutions. CWD can be easily integrated into existing optimizers like AdamW, Lion, and Muon without needing extra tuning or new hyperparameters. In experiments, CWD has shown to enhance accuracy and reduce loss in large-scale models, particularly in language model training and ImageNet classification tasks.","title":"Selective Weight Decay for Optimizer Boosting"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="Cautious Weight Decay (CWD) is a new technique that improves the performance of optimizers by applying weight decay selectively based on the direction of the optimizer's updates. This method differs from traditional weight decay by maintaining the original loss function, allowing for a more effective search for optimal solutions. CWD can be easily integrated into existing optimizers like AdamW, Lion, and Muon without needing extra tuning or new hyperparameters. In experiments, CWD has shown to enhance accuracy and reduce loss in large-scale models, particularly in language model training and ImageNet classification tasks.", title='Selective Weight Decay for Optimizer Boosting'))
[15.10.2025 16:14] Response: ParsedChatCompletionMessage[Article](content='{"desc":"谨慎权重衰减（CWD）是一种优化器无关的修改方法，通过选择性地应用权重衰减来提升优化器的性能。它只对与优化器更新方向一致的参数坐标进行权重衰减，从而改善大规模模型的准确性和损失。与标准的解耦衰减不同，CWD保持了原始损失，并允许双层次的解释，能够在达到静态流形时诱导滑模行为。CWD可以直接应用于如AdamW、Lion和Muon等优化器，无需新的超参数或额外的调优。","title":"谨慎权重衰减：优化器性能的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='谨慎权重衰减（CWD）是一种优化器无关的修改方法，通过选择性地应用权重衰减来提升优化器的性能。它只对与优化器更新方向一致的参数坐标进行权重衰减，从而改善大规模模型的准确性和损失。与标准的解耦衰减不同，CWD保持了原始损失，并允许双层次的解释，能够在达到静态流形时诱导滑模行为。CWD可以直接应用于如AdamW、Lion和Muon等优化器，无需新的超参数或额外的调优。', title='谨慎权重衰减：优化器性能的新突破'))
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#long_context", "#multimodal", "#open_source", "#reasoning", "#agi", "#benchmark", "#rag"], "emoji": "🎯", "ru": {"title": "Мультимодальный RAG для работы с любыми типами данных", "desc": "RAG-Anything — это универсальная система для улучшения Retrieval-Augmented Generation (RAG), ко
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#hallucinations", "#agents", "#long_context", "#rag"], "emoji": "🔮", "ru": {"title": "Обучение AI агентов с внешними знаниями вместо галлюцинаций", "desc": "LLM могут служить моделями мира для планирования действий AI-агентов в цифровых средах, но страдают от галлюцинаций и устаревш
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#dataset", "#agents", "#ethics", "#rlhf", "#security", "#alignment", "#benchmark"], "emoji": "🔬", "ru": {"title": "Опасность исследовательских AI-агентов: когда умные помощники обходят защиту", "desc": "Исследователи обнаружили критическую уязвимость в Deep Research агентах на основ
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#cv", "#science", "#benchmark", "#open_source", "#reasoning", "#multimodal"], "emoji": "🔬", "ru": {"title": "Научные эксперименты — слабое место современных AI", "desc": "Исследователи представили ExpVid — первый бенчмарк для оценки мультимодальных LLM на видео научных экспериментов
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#open_source", "#reasoning", "#rlhf", "#security", "#alignment", "#benchmark", "#architecture"], "emoji": "🔓", "ru": {"title": "Хрупкая броня: как простые токены ломают защиту reasoning-моделей", "desc": "Исследователи обнаружили критическую уязвимость в системах безопасности больши
[15.10.2025 16:14] Using data from previous issue: {"categories": ["#hallucinations", "#reasoning", "#benchmark", "#data", "#training"], "emoji": "🛡️", "ru": {"title": "Защита рассуждений LLM от кражи через переформулирование", "desc": "Исследователи предложили метод PART для защиты детальных reasoning-цепочек больших языковых моделей от несанкциони
[15.10.2025 16:14] Querying the API.
[15.10.2025 16:14] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Diffusion-Link, a diffusion-based modality-bridging module, reduces the audio-text modality gap and enhances multimodal encoder-LLM coupling, achieving state-of-the-art performance in automatic audio captioning.  					AI-generated summary 				 Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance https://github.com/DevKiHyun/Diffusion-Link
[15.10.2025 16:15] Response: ```json
{
  "desc": "Статья представляет Diffusion-Link — модуль на основе диффузионных моделей для соединения аудио и текстовых модальностей. Модуль генеративно преобразует аудио-эмбеддинги в распределение текстовых эмбеддингов, уменьшая разрыв между модальностями. Это улучшает связь между мультимодальными энкодерами и LLM при решении задачи автоматического описания аудио (AAC). Метод достигает state-of-the-art результатов на датасете AudioCaps, показывая прирост до 52.5% в zero-shot режиме и 7.5% в полностью контролируемом обучении.",
  "emoji": "🎵",
  "title": "Диффузионный мост между звуком и текстом для LLM"
}
```
[15.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Diffusion-Link, a diffusion-based modality-bridging module, reduces the audio-text modality gap and enhances multimodal encoder-LLM coupling, achieving state-of-the-art performance in automatic audio captioning.  					AI-generated summary 				 Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance https://github.com/DevKiHyun/Diffusion-Link"

[15.10.2025 16:15] Response: ```python
['MULTIMODAL', 'AUDIO']
```
[15.10.2025 16:15] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Diffusion-Link, a diffusion-based modality-bridging module, reduces the audio-text modality gap and enhances multimodal encoder-LLM coupling, achieving state-of-the-art performance in automatic audio captioning.  					AI-generated summary 				 Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance https://github.com/DevKiHyun/Diffusion-Link"

[15.10.2025 16:15] Response: ```python
["DIFFUSION", "GAMES"]
```
[15.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces Diffusion-Link, a novel module designed to bridge the gap between audio and text modalities in multimodal learning. By using a diffusion-based approach, it effectively maps audio embeddings to the text-embedding space, enhancing the integration of multimodal encoders with large language models (LLMs). The authors demonstrate that Diffusion-Link significantly reduces the audio-text modality gap, leading to improved performance in automatic audio captioning tasks. Their results show that this method achieves state-of-the-art performance, highlighting the importance of closing modality gaps for better multimodal interactions.","title":"Bridging the Audio-Text Gap with Diffusion-Link"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces Diffusion-Link, a novel module designed to bridge the gap between audio and text modalities in multimodal learning. By using a diffusion-based approach, it effectively maps audio embeddings to the text-embedding space, enhancing the integration of multimodal encoders with large language models (LLMs). The authors demonstrate that Diffusion-Link significantly reduces the audio-text modality gap, leading to improved performance in automatic audio captioning tasks. Their results show that this method achieves state-of-the-art performance, highlighting the importance of closing modality gaps for better multimodal interactions.', title='Bridging the Audio-Text Gap with Diffusion-Link'))
[15.10.2025 16:15] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Diffusion-Link 是一种基于扩散的模态桥接模块，旨在缩小音频和文本之间的模态差距，从而增强多模态编码器与大型语言模型（LLM）的结合。该模块通过生成性映射将音频嵌入映射到文本嵌入分布，经过训练后能够有效减少模态差距。我们在自动音频字幕生成（AAC）任务中评估了 Diffusion-Link 的效果，结果显示其在零样本和完全监督的字幕生成中均达到了最先进的性能。研究表明，缩小模态差距对于多模态编码器与 LLM 的有效结合至关重要，扩散基础的模态桥接提供了一种超越知识检索设计的有前景的方向。","title":"缩小模态差距，提升多模态性能"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Diffusion-Link 是一种基于扩散的模态桥接模块，旨在缩小音频和文本之间的模态差距，从而增强多模态编码器与大型语言模型（LLM）的结合。该模块通过生成性映射将音频嵌入映射到文本嵌入分布，经过训练后能够有效减少模态差距。我们在自动音频字幕生成（AAC）任务中评估了 Diffusion-Link 的效果，结果显示其在零样本和完全监督的字幕生成中均达到了最先进的性能。研究表明，缩小模态差距对于多模态编码器与 LLM 的有效结合至关重要，扩散基础的模态桥接提供了一种超越知识检索设计的有前景的方向。', title='缩小模态差距，提升多模态性能'))
[15.10.2025 16:15] Using data from previous issue: {"categories": ["#optimization", "#security", "#multimodal", "#benchmark", "#cv"], "emoji": "🔏", "ru": {"title": "SynthID-Image: невидимые водяные знаки для AI-изображений в масштабе интернета", "desc": "Исследователи представили SynthID-Image — систему на основе глубокого обучения для невидимой вод
[15.10.2025 16:15] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#math", "#training", "#interpretability"], "emoji": "🔍", "ru": {"title": "Прозрачные рассуждения: как научить AI объяснять свои решения", "desc": "В статье представлен ReFIne — новый метод обучения, который делает reasoning модели более надёжными и пон
[15.10.2025 16:15] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#multimodal", "#benchmark"], "emoji": "🎨", "ru": {"title": "LLM как ранние оценщики пользовательских интерфейсов", "desc": "Исследование проверяет, могут ли мультимодальные LLM (большие языковые модели) оценивать пользовательские интерфейсы так же,
[15.10.2025 16:15] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#interpretability", "#plp", "#agi"], "emoji": "🔗", "ru": {"title": "Тензорная логика: мост между нейронным и символьным AI", "desc": "Статья предлагает tensor logic — новый язык программирования, который объединяет нейронные и символьные подходы в AI ч
[15.10.2025 16:15] Using data from previous issue: {"categories": ["#open_source", "#inference", "#diffusion", "#architecture"], "emoji": "⚡", "ru": {"title": "Диффузионные LLM в 10 раз быстрее с dInfer", "desc": "dInfer - это эффективный фреймворк для инференса диффузионных языковых моделей (dLLM), которые представляют альтернативу традиционным авт
[15.10.2025 16:15] Renaming data file.
[15.10.2025 16:15] Renaming previous data. hf_papers.json to ./d/2025-10-15.json
[15.10.2025 16:15] Saving new data file.
[15.10.2025 16:15] Generating page.
[15.10.2025 16:15] Renaming previous page.
[15.10.2025 16:15] Renaming previous data. index.html to ./d/2025-10-15.html
[15.10.2025 16:15] Writing result.
[15.10.2025 16:15] Renaming log file.
[15.10.2025 16:15] Renaming previous data. log.txt to ./logs/2025-10-15_last_log.txt
