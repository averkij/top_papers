[15.10.2025 05:13] Read previous papers.
[15.10.2025 05:13] Generating top page (month).
[15.10.2025 05:13] Writing top page (month).
[15.10.2025 06:18] Read previous papers.
[15.10.2025 06:18] Get feed.
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12586
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11693
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.09116
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12747
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12399
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12798
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12773
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12276
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12693
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12784
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12635
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11683
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12789
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12709
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12801
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12225
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11919
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12777
[15.10.2025 06:18] Extract page data from URL. URL: https://huggingface.co/papers/2510.11057
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.12793
[15.10.2025 06:18] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11606
[15.10.2025 06:18] Extract page data from URL. URL: https://huggingface.co/papers/2510.08783
[15.10.2025 06:18] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.10.2025 06:18] No deleted papers detected.
[15.10.2025 06:18] Downloading and parsing papers (pdf, html). Total: 22.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12586.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12586.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12586.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.11693.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.11693.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.11693.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.09116.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.09116.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.09116.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12747.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12747.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12747.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12399.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12399.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12399.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12798.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12798.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12798.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12773.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12773.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12773.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12276.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12276.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12276.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12693.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12693.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12693.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12784.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12784.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12784.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12635.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12635.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12635.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.11683.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.11683.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.11683.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12789.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12789.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12789.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12709.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12709.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12709.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12801.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12801.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12801.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12225.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12225.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12225.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.11919.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.11919.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.11919.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12777.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12777.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12777.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.11057.
[15.10.2025 06:18] Downloading paper 2510.11057 from http://arxiv.org/pdf/2510.11057v1...
[15.10.2025 06:18] Extracting affiliations from text.
[15.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 1 ] . [ 1 7 5 0 1 1 . 0 1 5 2 : r a TEMPORAL ALIGNMENT GUIDANCE: ON-MANIFOLD SAMPLING IN DIFFUSION MODELS Youngrok Park Hojung Jung Sangmin Bae KAIST AI {yr-park, ghwjd7281, bsmn0223, yunseyoung}@kaist.ac.kr Se-Young Yun "
[15.10.2025 06:18] Response: ```python
["KAIST AI"]
```
[15.10.2025 06:18] Deleting PDF ./assets/pdf/2510.11057.pdf.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.12793.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.12793.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.12793.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.11606.
[15.10.2025 06:18] Extra JSON file exists (./assets/json/2510.11606.json), skip PDF parsing.
[15.10.2025 06:18] Paper image links file exists (./assets/img_data/2510.11606.json), skip HTML parsing.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Downloading and parsing paper https://huggingface.co/papers/2510.08783.
[15.10.2025 06:18] Downloading paper 2510.08783 from http://arxiv.org/pdf/2510.08783v1...
[15.10.2025 06:18] Extracting affiliations from text.
[15.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"MLLM as UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces Ryan Rossi Adobe Research Reuben Luera University of California, Berkeley 5 2 0 2 9 ] . [ 1 3 8 7 8 0 . 0 1 5 2 : r a ABSTRACT In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research. KEYWORDS MLLM-as-a-Judge, UI, Evaluation, Benchmark ACM Reference Format: Reuben Luera, Ryan Rossi, Franck Dernoncourt, Samyadeep Basu, Sungchul Kim, Subhojyoti Mukherjee, Puneet Mathur, Ruiyi Zhang, Jihyung Kil, Nedim Lipka, Seunghyun Yoon, Jiuxiang Gu, Zichao Wang, Cindy Xiong Bearfield, and Branislav Kveton. 2025. MLLM as UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces. In . ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the fi"
[15.10.2025 06:18] Response: ```python
["Adobe Research", "University of California, Berkeley"]
```
[15.10.2025 06:18] Deleting PDF ./assets/pdf/2510.08783.pdf.
[15.10.2025 06:18] Success.
[15.10.2025 06:18] Enriching papers with extra data.
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 0. Pixel-space generative models are often more difficult to train and generally underperform compared to their latent-space counterparts, leaving a persistent performance and efficiency gap. In this paper, we introduce a novel two-stage training framework that closes this gap for pixel-space diffusion...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 1. Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approac...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 2. A new evaluation framework, DITING, and a reasoning-driven multi-agent evaluation framework, AgentEval, are introduced to assess the quality of web novel translations, revealing that Chinese-trained LLMs outperform larger foreign models.  					AI-generated summary 				 Large language models (LLMs) h...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 3. Diffusion models have recently advanced video restoration, but applying them to real-world video super-resolution (VSR) remains challenging due to high latency, prohibitive computation, and poor generalization to ultra-high resolutions. Our goal in this work is to make diffusion-based VSR practical ...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 4. The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed "Vibe Coding" where developers validate AI-generated implementations through outcome observation rather than lin...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 5. Object detection has long been dominated by traditional coordinate regression-based models, such as YOLO, DETR, and Grounding DINO. Although recent efforts have attempted to leverage MLLMs to tackle this task, they face challenges like low recall rate, duplicate predictions, coordinate misalignment,...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 6. Large Language Models (LLMs) process every token through all layers of a transformer stack, causing wasted computation on simple queries and insufficient flexibility for harder ones that need deeper reasoning. Adaptive-depth methods can improve efficiency, but prior approaches rely on costly inferen...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 7. Vision-language-action (VLA) models have recently shown strong potential in enabling robots to follow language instructions and execute precise actions. However, most VLAs are built upon vision-language models pretrained solely on 2D data, which lack accurate spatial awareness and hinder their abili...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 8. Recent advances in embodied AI highlight the potential of vision language models (VLMs) as agents capable of perception, reasoning, and interaction in complex environments. However, top-performing systems rely on large-scale models that are costly to deploy, while smaller VLMs lack the necessary kno...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 9. Recently, remarkable progress has been made in Unified Multimodal Models (UMMs), which integrate vision-language generation and understanding capabilities within a single framework. However, a significant gap exists where a model's strong visual understanding often fails to transfer to its visual ge...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 10. Large Language Models face challenges in long-horizon agentic tasks as their constrained memory is easily overwhelmed by distracting or irrelevant context. Existing working memory methods typically rely on external, heuristic mechanisms that are decoupled from the agent's core policy. In this work, ...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 11. Boundary-Guided Policy Optimization (BGPO) improves reinforcement learning for diffusion large language models by efficiently approximating likelihoods with a memory-efficient lower bound, enhancing performance in tasks like math problem solving, code generation, and planning.  					AI-generated sum...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 12. Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images and text. This separation constrains diffusion models' ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 13. Multimodal embedding models aim to yield informative unified representations that empower diverse cross-modal tasks. Despite promising developments in the evolution from CLIP-based dual-tower architectures to large vision-language models, prior works still face unavoidable challenges in real-world a...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 14. Multimodal Large Language Models (MLLMs) in real-world applications require access to external knowledge sources and must remain responsive to the dynamic and ever-changing real-world information in order to address information-seeking and knowledge-intensive user queries. Existing approaches, such ...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 15. Recent advances in vision-language models (VLMs) have made them highly effective at reasoning tasks. However, the principles underlying the construction of performant VL reasoning training datasets remain poorly understood. In this work, we introduce several data curation approaches and study their ...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 16. Large reasoning models (LRMs) have led to new possibilities in terms of problem-solving, through the devising of a natural language thought process prior to answering a query. While their capabilities are well known across mathematics and coding tasks, their impact on the task of machine translation...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 17. Understanding the dynamics of a physical scene involves reasoning about the diverse ways it can potentially change, especially as a result of local interactions. We present the Flow Poke Transformer (FPT), a novel framework for directly predicting the distribution of local motion, conditioned on spa...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 18. Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often ...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 19. Existing Multimodal Large Language Models (MLLMs) suffer from increased inference costs due to the additional vision tokens introduced by image inputs. In this work, we propose Visual Consistency Learning (ViCO), a novel training algorithm that enables the model to represent images of varying semant...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 20. ExpVid, a new benchmark for evaluating multimodal large language models on scientific experiment videos, highlights gaps in fine-grained perception, procedural understanding, and scientific reasoning.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) hold promise for accelerat...
[15.10.2025 06:18] ********************************************************************************
[15.10.2025 06:18] Abstract 21. In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, ...
[15.10.2025 06:18] Read previous papers.
[15.10.2025 06:18] Generating reviews via LLM API.
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#training", "#diffusion", "#cv", "#optimization"], "emoji": "🎯", "ru": {"title": "Двухэтапное обучение закрывает разрыв между пиксельными и латентными генеративными моделями", "desc": "Исследователи предложили новый двухэтапный подход для обучения диффузионных моделей и consistency 
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#low_resource", "#data", "#benchmark", "#multimodal", "#transfer_learning", "#training", "#alignment"], "emoji": "🔗", "ru": {"title": "Генеративное предобучение как ключ к качественным мультимодальным эмбеддингам", "desc": "Исследователи обнаружили, что превосходство мультимодальных
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#machine_translation", "#open_source", "#reasoning", "#dataset", "#multilingual", "#benchmark"], "emoji": "📚", "ru": {"title": "Китайские LLM побеждают в переводе веб-романов", "desc": "Исследователи представили DITING — первую комплексную систему оценки качества перевода веб-романо
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#video", "#open_source", "#inference", "#training", "#dataset", "#diffusion"], "emoji": "⚡", "ru": {"title": "Диффузионное видео super-resolution в реальном времени", "desc": "FlashVSR — первая диффузионная модель для видео super-resolution в реальном времени, работающая со скорость
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#multimodal", "#training", "#survey", "#agi", "#agents", "#rl"], "emoji": "🎵", "ru": {"title": "Vibe Coding: когда разработчик проверяет результат, а не читает код", "desc": "Статья исследует новую парадигму разработки под названием \"Vibe Coding\", где разработчики проверяют работо
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#training", "#optimization", "#rl"], "emoji": "🔍", "ru": {"title": "Rex-Omni: новый уровень в обнаружении объектов", "desc": "В статье рассматривается новая модель Rex-Omni, которая улучшает задачи обнаружения объектов, используя подходы LLM. Rex-Omni достигает
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#optimization", "#training", "#inference"], "emoji": "🧭", "ru": {"title": "Умная маршрутизация слоёв: LLM учатся пропускать ненужные вычисления", "desc": "В статье представлен Dr.LLM — метод динамической маршрутизации слоёв для больших языковых моделей
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#3d", "#optimization", "#training", "#agents", "#alignment"], "emoji": "🤖", "ru": {"title": "Обучение роботов пространственному мышлению без 3D сенсоров", "desc": "Статья представляет Spatial Forcing (SF) — метод для улучшения vision-language-action (VLA) моделей в робототехнике. Пр
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#reasoning", "#training", "#optimization", "#transfer_learning", "#agents", "#rl"], "emoji": "🤖", "ru": {"title": "Маленькие модели учатся действовать как большие", "desc": "Статья представляет ERA — двухэтапный фреймворк для обучения компактных vision language models действовать в 
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#training", "#optimization", "#multimodal", "#transfer_learning"], "emoji": "🔄", "ru": {"title": "Самообучение мультимодальных моделей через внутреннюю самооценку", "desc": "Исследователи обнаружили парадокс: мультимодальные модели могут хорошо понимать изображения, но плохо их гене
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#long_context", "#reasoning", "#training", "#optimization", "#agents", "#rl"], "emoji": "🧠", "ru": {"title": "Память как действие: LLM учатся управлять своим контекстом", "desc": "Большие языковые модели сталкиваются с проблемой ограниченной памяти при решении длинных задач, когда к
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#games", "#rlhf", "#training", "#optimization", "#rl"], "emoji": "🎯", "ru": {"title": "Эффективное обучение диффузионных языковых моделей с помощью линейной аппроксимации", "desc": "Статья представляет метод BGPO для reinforcement learning в диффузионных LLM, которые сталкиваются с 
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#reasoning", "#training", "#transfer_learning", "#diffusion"], "emoji": "🔗", "ru": {"title": "Единый энкодер для текста и изображений в диффузионных моделях", "desc": "UniFusion — это диффузионная модель для генерации изображений, которая использует замороженну
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#training", "#optimization", "#multimodal"], "emoji": "⛵", "ru": {"title": "SAIL-Embedding: Универсальная мультимодальная модель для поиска и рекомендаций", "desc": "Статья представляет SAIL-Embedding — омнимодальную модель эмбеддингов, которая решает проблемы ограниченной поддержки
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#training", "#dataset", "#agi", "#optimization", "#rag", "#benchmark"], "emoji": "🔍", "ru": {"title": "Мультимодальный поиск в интернете с обучением через подкрепление", "desc": "Статья представляет DeepMMSearch-R1 — первую мультимодальную LLM, способную
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#reasoning", "#dataset", "#benchmark", "#data"], "emoji": "🐝", "ru": {"title": "HoneyBee: Как правильно готовить данные для обучения визуального мышления", "desc": "Исследователи изучили принципы создания эффективных датасетов для обучения vision-language модел
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#low_resource", "#reasoning", "#training", "#multilingual", "#machine_translation", "#synthetic"], "emoji": "🤔", "ru": {"title": "Размышления не помогают LLM лучше переводить", "desc": "Исследователи изучили, помогают ли \"токены размышлений\" (thinking tokens) большим reasoning мод
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#interpretability", "#open_source", "#reasoning", "#training", "#optimization", "#synthetic"], "emoji": "🔄", "ru": {"title": "Flow Poke Transformer: новая эра в предсказании движения", "desc": "В статье представлена новая модель Flow Poke Transformer (FPT), которая предсказыв
[15.10.2025 06:18] Querying the API.
[15.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often breaks sample fidelity. In this paper, we propose a general solution to address the off-manifold phenomenon observed in diffusion models. Our approach leverages a time predictor to estimate deviations from the desired data manifold at each timestep, identifying that a larger time gap is associated with reduced generation quality. We then design a novel guidance mechanism, `Temporal Alignment Guidance' (TAG), attracting the samples back to the desired manifold at every timestep during generation. Through extensive experiments, we demonstrate that TAG consistently produces samples closely aligned with the desired manifold at each timestep, leading to significant improvements in generation quality across various downstream tasks.
[15.10.2025 06:18] Response: ```json
{
  "title": "Временное выравнивание для точной генерации в диффузионных моделях",
  "desc": "Диффузионные модели показывают отличные результаты в генерации, но накапливают ошибки в процессе работы, особенно при использовании guidance для управления свойствами генерируемых объектов. Авторы предлагают решение проблемы отклонения от целевого многообразия данных с помощью предиктора времени, который оценивает степень отклонения на каждом шаге генерации. Разработанный механизм Temporal Alignment Guidance (TAG) возвращает сэмплы на нужное многообразие на каждом временном шаге. Эксперименты показывают, что TAG значительно улучшает качество генерации в различных задачах, удерживая сэмплы близко к целевому распределению данных.",
  "emoji": "🎯"
}
```
[15.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often breaks sample fidelity. In this paper, we propose a general solution to address the off-manifold phenomenon observed in diffusion models. Our approach leverages a time predictor to estimate deviations from the desired data manifold at each timestep, identifying that a larger time gap is associated with reduced generation quality. We then design a novel guidance mechanism, `Temporal Alignment Guidance' (TAG), attracting the samples back to the desired manifold at every timestep during generation. Through extensive experiments, we demonstrate that TAG consistently produces samples closely aligned with the desired manifold at each timestep, leading to significant improvements in generation quality across various downstream tasks."

[15.10.2025 06:18] Response: ```python
["CV", "MULTIMODAL", "TRAINING"]
```
[15.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often breaks sample fidelity. In this paper, we propose a general solution to address the off-manifold phenomenon observed in diffusion models. Our approach leverages a time predictor to estimate deviations from the desired data manifold at each timestep, identifying that a larger time gap is associated with reduced generation quality. We then design a novel guidance mechanism, `Temporal Alignment Guidance' (TAG), attracting the samples back to the desired manifold at every timestep during generation. Through extensive experiments, we demonstrate that TAG consistently produces samples closely aligned with the desired manifold at each timestep, leading to significant improvements in generation quality across various downstream tasks."

[15.10.2025 06:18] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[15.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper addresses the issue of error accumulation in diffusion models during the sample generation process. When arbitrary guidance is applied, it can lead to a loss of fidelity in the generated samples. The authors introduce a method called \'Temporal Alignment Guidance\' (TAG), which uses a time predictor to correct deviations from the desired data manifold at each generation step. Their experiments show that TAG significantly enhances the quality of generated samples by ensuring they remain aligned with the target manifold throughout the process.","title":"Aligning Generative Samples with Temporal Guidance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper addresses the issue of error accumulation in diffusion models during the sample generation process. When arbitrary guidance is applied, it can lead to a loss of fidelity in the generated samples. The authors introduce a method called 'Temporal Alignment Guidance' (TAG), which uses a time predictor to correct deviations from the desired data manifold at each generation step. Their experiments show that TAG significantly enhances the quality of generated samples by ensuring they remain aligned with the target manifold throughout the process.", title='Aligning Generative Samples with Temporal Guidance'))
[15.10.2025 06:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"扩散模型作为生成模型取得了显著成功，但在生成过程中，即使是经过良好训练的模型也可能积累错误。这些错误在应用任意引导以调整样本属性时尤为严重，常常导致样本的真实性下降。本文提出了一种通用解决方案，旨在解决扩散模型中观察到的离散现象。我们设计了一种新的引导机制——时间对齐引导（TAG），在生成的每个时间步将样本吸引回期望的数据流形，从而显著提高生成质量。","title":"时间对齐引导：提升扩散模型生成质量的关键"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='扩散模型作为生成模型取得了显著成功，但在生成过程中，即使是经过良好训练的模型也可能积累错误。这些错误在应用任意引导以调整样本属性时尤为严重，常常导致样本的真实性下降。本文提出了一种通用解决方案，旨在解决扩散模型中观察到的离散现象。我们设计了一种新的引导机制——时间对齐引导（TAG），在生成的每个时间步将样本吸引回期望的数据流形，从而显著提高生成质量。', title='时间对齐引导：提升扩散模型生成质量的关键'))
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#training", "#inference", "#interpretability", "#agi", "#optimization", "#multimodal"], "emoji": "🎯", "ru": {"title": "Умное сжатие визуальных токенов по сложности изображения", "desc": "Исследователи предложили метод Visual Consistency Learning (ViCO), который позволяет mult
[15.10.2025 06:18] Using data from previous issue: {"categories": ["#cv", "#science", "#benchmark", "#open_source", "#reasoning", "#multimodal"], "emoji": "🔬", "ru": {"title": "Научные эксперименты — слабое место современных AI", "desc": "Исследователи представили ExpVid — первый бенчмарк для оценки мультимодальных LLM на видео научных экспериментов
[15.10.2025 06:18] Querying the API.
[15.10.2025 06:18] Claude request. Model: claude-sonnet-4-5-20250929. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from a crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research.
[15.10.2025 06:18] Response: ```json
{
  "desc": "Исследование проверяет, могут ли мультимодальные LLM (большие языковые модели) оценивать пользовательские интерфейсы так же, как люди. Авторы тестировали GPT-4o, Claude и Llama на 30 различных интерфейсах, сравнивая их оценки с мнениями реальных пользователей из краудсорсинговой платформы. Результаты показали, что AI-модели частично совпадают с человеческими предпочтениями по некоторым аспектам UI, но расходятся по другим. Это демонстрирует потенциал использования LLM для ранней оценки дизайна интерфейсов, но также выявляет их ограничения.",
  "emoji": "🎨",
  "title": "LLM как ранние оценщики пользовательских интерфейсов"
}
```
[15.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from a crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research."

[15.10.2025 06:18] Response: ```python
['MULTIMODAL', 'BENCHMARK']
```
[15.10.2025 06:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from a crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research."

[15.10.2025 06:18] Response: ```python
["ALIGNMENT", "INTERPRETABILITY"]
```
[15.10.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper explores the use of multimodal large language models (MLLMs) as tools for early evaluation in user interface (UI) design. It investigates whether these models can replicate human preferences when assessing different UIs, using data from a crowdsourcing platform. The study benchmarks several MLLMs, including GPT-4o, Claude, and Llama, against human judgments on various UI factors. The findings reveal that while MLLMs can approximate human preferences in some areas, they also show significant divergence in others, highlighting their potential and limitations in enhancing early user experience (UX) research.","title":"Harnessing MLLMs for Early UI Evaluation"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper explores the use of multimodal large language models (MLLMs) as tools for early evaluation in user interface (UI) design. It investigates whether these models can replicate human preferences when assessing different UIs, using data from a crowdsourcing platform. The study benchmarks several MLLMs, including GPT-4o, Claude, and Llama, against human judgments on various UI factors. The findings reveal that while MLLMs can approximate human preferences in some areas, they also show significant divergence in others, highlighting their potential and limitations in enhancing early user experience (UX) research.', title='Harnessing MLLMs for Early UI Evaluation'))
[15.10.2025 06:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本研究探讨了多模态大型语言模型（MLLMs）在用户界面（UI）设计中的应用，特别是在早期评估阶段。我们通过比较GPT-4o、Claude和Llama等模型在30个不同界面上的表现，评估它们是否能够模拟人类的偏好。研究结果表明，虽然MLLMs在某些方面能够接近人类的判断，但在其他方面则存在差异，这显示了它们在早期用户体验（UX）研究中的潜力和局限性。通过这种方式，设计师可以在正式测试之前更有效地缩小选择范围。","title":"利用MLLMs提升用户界面设计的早期评估"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本研究探讨了多模态大型语言模型（MLLMs）在用户界面（UI）设计中的应用，特别是在早期评估阶段。我们通过比较GPT-4o、Claude和Llama等模型在30个不同界面上的表现，评估它们是否能够模拟人类的偏好。研究结果表明，虽然MLLMs在某些方面能够接近人类的判断，但在其他方面则存在差异，这显示了它们在早期用户体验（UX）研究中的潜力和局限性。通过这种方式，设计师可以在正式测试之前更有效地缩小选择范围。', title='利用MLLMs提升用户界面设计的早期评估'))
[15.10.2025 06:19] Renaming data file.
[15.10.2025 06:19] Renaming previous data. hf_papers.json to ./d/2025-10-15.json
[15.10.2025 06:19] Saving new data file.
[15.10.2025 06:19] Generating page.
[15.10.2025 06:19] Renaming previous page.
[15.10.2025 06:19] Renaming previous data. index.html to ./d/2025-10-15.html
[15.10.2025 06:19] Writing result.
[15.10.2025 06:19] Renaming log file.
[15.10.2025 06:19] Renaming previous data. log.txt to ./logs/2025-10-15_last_log.txt
