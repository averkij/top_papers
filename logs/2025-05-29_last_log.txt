[29.05.2025 06:19] Read previous papers.
[29.05.2025 06:19] Generating top page (month).
[29.05.2025 06:19] Writing top page (month).
[29.05.2025 07:12] Read previous papers.
[29.05.2025 07:12] Get feed.
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22617
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21600
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22312
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22453
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21136
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22334
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19253
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22129
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21887
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22648
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.19187
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17663
[29.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.19075
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21925
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22613
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22525
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22523
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22338
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22203
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22019
[29.05.2025 07:12] Extract page data from URL. URL: https://huggingface.co/papers/2505.18600
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21876
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.18700
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22202
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21191
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17507
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.12667
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.22645
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.21960
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.20715
[29.05.2025 07:12] Get page data from previous paper. URL: https://huggingface.co/papers/2505.17870
[29.05.2025 07:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[29.05.2025 07:12] No deleted papers detected.
[29.05.2025 07:12] Downloading and parsing papers (pdf, html). Total: 31.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22617.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22617.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22617.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21600.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21600.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21600.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22312.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22312.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22312.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22453.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22453.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22453.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21136.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21136.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21136.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22334.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22334.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22334.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.19253.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.19253.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.19253.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22129.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22129.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22129.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21887.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21887.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21887.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22648.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22648.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22648.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.19187.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.19187.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.19187.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.17663.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.17663.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.17663.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.19075.
[29.05.2025 07:12] Downloading paper 2505.19075 from http://arxiv.org/pdf/2505.19075v2...
[29.05.2025 07:12] Extracting affiliations from text.
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 2 ] . [ 2 5 7 0 9 1 . 5 0 5 2 : r Universal Reasoner: Single, Composable Plug-and-Play Reasoner for Frozen LLMs Jaemin Kim* Hangeol Chang* Hyunmin Hwang* Choonghan Kim Jong Chul Ye Graduate School of AI *Equal contribution Korea Advanced Institute of Science and Technology (KAIST) {kjm981995, hangeol, hyunmin_hwang, choonghankim, jong.ye}@kaist.ac.kr "
[29.05.2025 07:12] Response: ```python
["Korea Advanced Institute of Science and Technology (KAIST)"]
```
[29.05.2025 07:12] Deleting PDF ./assets/pdf/2505.19075.pdf.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21925.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21925.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21925.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22613.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22613.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22613.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22525.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22525.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22525.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22523.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22523.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22523.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22338.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22338.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22338.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22203.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22203.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22203.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22019.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22019.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22019.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.18600.
[29.05.2025 07:12] Downloading paper 2505.18600 from http://arxiv.org/pdf/2505.18600v2...
[29.05.2025 07:12] Extracting affiliations from text.
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 2 ] . [ 2 0 0 6 8 1 . 5 0 5 2 : r Chain-of-Zoom: Extreme Super-Resolution via Scale Autoregression and Preference Alignment Bryan Sangwoo Kim Jeongsol Kim Jong Chul Ye KAIST AI {bryanswkim, jeongsol, jong.ye}@kaist.ac.kr Figure 1: Extreme super-resolution of photorealistic images by CoZ with up to 64 magnification (top) and 256 magnification (bottom). Fine details such as textures on wall, wrinkles on flag, and leaf veins are clearly seen. "
[29.05.2025 07:12] Response: ```python
["KAIST AI"]
```
[29.05.2025 07:12] Deleting PDF ./assets/pdf/2505.18600.pdf.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21876.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21876.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21876.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.18700.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.18700.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.18700.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22202.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22202.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22202.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21191.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21191.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21191.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.17507.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.17507.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.17507.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.12667.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.12667.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.12667.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.22645.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.22645.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.22645.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.21960.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.21960.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.21960.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.20715.
[29.05.2025 07:12] Extra JSON file exists (./assets/json/2505.20715.json), skip PDF parsing.
[29.05.2025 07:12] Paper image links file exists (./assets/img_data/2505.20715.json), skip HTML parsing.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Downloading and parsing paper https://huggingface.co/papers/2505.17870.
[29.05.2025 07:12] Downloading paper 2505.17870 from http://arxiv.org/pdf/2505.17870v1...
[29.05.2025 07:12] Extracting affiliations from text.
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 3 2 ] . [ 1 0 7 8 7 1 . 5 0 5 2 : r Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat Falsehoods Shaina Raza1 Rizwan Qureshi2 Marcelo Lotif1 Aman Chadha3 Deval Pandya1 Christos Emmanouilidis 1Vector Institute, Toronto, Canada 3Amazon Web Services 2University of Central Florida, Orlando, USA 4University of Groningen, Netherlands "
[29.05.2025 07:12] Response: ```python
["Vector Institute, Toronto, Canada", "Amazon Web Services", "University of Central Florida, Orlando, USA", "University of Groningen, Netherlands"]
```
[29.05.2025 07:12] Deleting PDF ./assets/pdf/2505.17870.pdf.
[29.05.2025 07:12] Success.
[29.05.2025 07:12] Enriching papers with extra data.
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 0. This paper aims to overcome a major obstacle in scaling RL for reasoning with LLMs, namely the collapse of policy entropy. Such phenomenon is consistently observed across vast RL runs without entropy intervention, where the policy entropy dropped sharply at the early training stage, this diminished ...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 1. Roads to Rome (R2R) selectively utilizes large language models for critical reasoning tasks to enhance efficiency and performance in lightweight models.  					AI-generated summary 				 Large Language Models (LLMs) achieve impressive reasoning capabilities at the cost of substantial inference overhea...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 2. The success of DeepSeek-R1 underscores the significant role of reinforcement learning (RL) in enhancing the reasoning capabilities of large language models (LLMs). In this work, we present Skywork-OR1, an effective and scalable RL implementation for long Chain-of-Thought (CoT) models. Building on th...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 3. Improving Multi-modal Large Language Models (MLLMs) in the post-training stage typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL). However, these supervised methods require expensive and manually annotated multi-modal data--an ultimately unsustainable resource. While rec...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 4. The efficiency of attention is critical because its time complexity grows quadratically with sequence length. SageAttention2 addresses this by utilizing quantization to accelerate matrix multiplications (Matmul) in attention. To further accelerate SageAttention2, we propose to utilize the faster ins...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 5. Recent advancements in large language models (LLMs) have demonstrated impressive chain-of-thought reasoning capabilities, with reinforcement learning (RL) playing a crucial role in this progress. While "aha moment" patterns--where models exhibit self-correction through reflection--are often attribut...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 6. DeepResearchGym provides an open-source evaluation framework for deep research systems using a reproducible search API and LLM-as-a-judge assessments.  					AI-generated summary 				 Deep research systems represent an emerging class of agentic information retrieval methods that generate comprehensiv...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 7. Analysis of fine-tuning diffusion models for panoramic image generation reveals distinct roles of attention module matrices and introduces UniPano, a memory-efficient and speed-enhanced baseline framework.  					AI-generated summary 				 Recent prosperity of text-to-image diffusion models, e.g. Stab...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 8. SVRPBench introduces a new benchmark for vehicle routing under uncertainty, simulating realistic urban conditions and highlighting the limitations of state-of-the-art RL solvers.  					AI-generated summary 				 Robust routing under uncertainty is central to real-world logistics, yet most benchmarks ...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 9. Addressing intricate real-world problems necessitates in-depth information seeking and multi-step reasoning. Recent progress in agentic systems, exemplified by Deep Research, underscores the potential for autonomous multi-step research. In this work, we present a cohesive paradigm for building end-t...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 10. A framework called PIR refines the importance of reasoning steps in large language models by pruning low-importance functional elements, leading to more concise reasoning chains with improved accuracy and reduced computational demands.  					AI-generated summary 				 Large language models (LLMs) hav...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 11. The DynToM benchmark evaluates LLMs' ability to track and understand the temporal progression of mental states, revealing significant gaps compared to human performance.  					AI-generated summary 				 As Large Language Models (LLMs) increasingly participate in human-AI interactions, evaluating thei...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 12. UniR, a lightweight reasoning module, enhances Large Language Models with specialized reasoning abilities through modular composition, improving performance and generalization at lower computational costs.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable gene...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 13. We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that does not require per-scene training or fine-tuning. Instead of taking a physics-centric approach to rendering, we formula...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 14. A novel iterative framework, RICO, improves image caption accuracy by using visual reconstruction and a text-to-image model to refine discrepancies, while RICO-Flash enhances efficiency using DPO.  					AI-generated summary 				 Image recaptioning is widely used to generate training datasets with en...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 15. Thinking with Generated Images allows large multimodal models to generate and critique intermediate visual steps, enhancing visual reasoning capabilities and achieving significant improvements in complex scenarios.  					AI-generated summary 				 We present Thinking with Generated Images, a novel pa...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 16. Generating high-quality, multi-layer transparent images from text prompts can unlock a new level of creative control, allowing users to edit each layer as effortlessly as editing text outputs from LLMs. However, the development of multi-layer generative models lags behind that of conventional text-t...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 17. Traditional RLHF optimizes language models with coarse, scalar rewards that mask the fine-grained reasons behind success or failure, leading to slow and opaque learning. Recent work augments RL with textual critiques through prompting or reflection, improving interpretability but leaving model param...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 18. The study examines the effectiveness and reliability of rule-based and model-based verifiers in reinforcement learning with verifiable reward, highlighting limitations and vulnerabilities in their use for mathematical reasoning tasks.  					AI-generated summary 				 Trustworthy verifiers are essenti...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 19. VRAG-RL, a reinforcement learning framework, enhances reasoning and visual information handling in RAG methods by integrating visual perception tokens and employing specialized action spaces and rewards.  					AI-generated summary 				 Effectively retrieving, reasoning and understanding visually ric...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 20. Chain-of-Zoom (CoZ) enhances single-image super-resolution models by using an autoregressive chain of intermediate scale-states and multi-scale-aware prompts to achieve extreme magnifications with high quality.  					AI-generated summary 				 Modern single-image super-resolution (SISR) models delive...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 21. EPiC is a framework for efficient 3D camera control in video diffusion models that constructs high-quality anchor videos through first-frame visibility masking, integrates them using a lightweight ControlNet module, and achieves state-of-the-art performance on I2V tasks with minimal resources.  				...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 22. Recent advances in Visual Language Models (VLMs) have demonstrated exceptional performance in visual reasoning tasks. However, geo-localization presents unique challenges, requiring the extraction of multigranular visual cues from images and their integration with external world knowledge for system...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 23. Pretrained language models can adapt to operate in sentence space, reason over structured semantic units, and achieve competitive performance with Chain-of-Thought while reducing inference-time FLOPs.  					AI-generated summary 				 Autoregressive language models (LMs) generate one token at a time, ...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 24. The finetuning of Large Language Models (LLMs) has significantly advanced their instruction-following capabilities, yet the underlying computational mechanisms driving these improvements remain poorly understood. This study systematically examines how fine-tuning reconfigures LLM computations by iso...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 25. HuggingKG, a large-scale knowledge graph, enhances open source ML resource management by enabling advanced queries and analyses via HuggingBench.  					AI-generated summary 				 The rapid growth of open source machine learning (ML) resources, such as models and datasets, has accelerated IR research....
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 26. Safe-Sora embeds invisible watermarks into AI-generated videos using a hierarchical adaptive matching mechanism and a 3D wavelet transform-enhanced Mamba architecture, achieving top performance in video quality, watermark fidelity, and robustness.  					AI-generated summary 				 The explosive growth...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 27. Research examines LLM performance biases between Simplified and Traditional Chinese in regional term and name choice tasks, attributing differences to training data and tokenization.  					AI-generated summary 				 While the capabilities of Large Language Models (LLMs) have been studied in both Simp...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 28. Time-independent Unified Encoder TiUE reduces inference time and improves diversity and quality in Text-to-Image diffusion models by sharing encoder features across decoder time steps.  					AI-generated summary 				 Text-to-Image (T2I) diffusion models have made remarkable advancements in generativ...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 29. MUSEG, an RL-based method with timestamp-aware multi-segment grounding, significantly enhances the temporal understanding of large language models by improving alignment with video segments and demonstrating superior performance in temporal reasoning tasks.  					AI-generated summary 				 Video temp...
[29.05.2025 07:12] ********************************************************************************
[29.05.2025 07:12] Abstract 30. A generative AI model is fine-tuned with labeled falsehoods to reduce misinformation generation, analogous to biological immunization.  					AI-generated summary 				 Generative AI models often learn and reproduce false information present in their training corpora. This position paper argues that, ...
[29.05.2025 07:12] Read previous papers.
[29.05.2025 07:12] Generating reviews via LLM API.
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#training", "#rl", "#optimization", "#reasoning"], "emoji": "🔬", "ru": {"title": "Управление энтропией для масштабирования обучения с подкреплением в больших языковых моделях", "desc": "Статья рассматривает проблему снижения энтропии политики при масштабировании обучения с подкрепле
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#small_models", "#architecture", "#optimization", "#reasoning", "#benchmark", "#math", "#training"], "emoji": "🛣️", "ru": {"title": "Эффективное сочетание больших и малых языковых моделей для улучшения рассуждений", "desc": "Статья представляет метод Roads to Rome (R2R), который сел
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#rl", "#benchmark", "#open_source", "#training"], "emoji": "🧠", "ru": {"title": "Усиление рассуждений языковых моделей с помощью обучения с подкреплением", "desc": "Статья представляет Skywork-OR1, эффективную реализацию обучения с подкреплением для ул
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#rlhf", "#multimodal", "#training", "#synthetic"], "emoji": "🤖", "ru": {"title": "Самосовершенствование ИИ без учителя", "desc": "Статья представляет новый метод MM-UPT для улучшения мультимодальных больших языковых моделей (MLLM) без использования размеченных д
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#inference"], "emoji": "🚀", "ru": {"title": "Ускорение механизма внимания без потери точности", "desc": "SageAttention2++ - это улучшенная версия SageAttention2, которая использует квантизацию для ускорения матричных умножений в механизме внимания. Основное нововвед
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#rl", "#multimodal", "#benchmark", "#open_source", "#training"], "emoji": "🧠", "ru": {"title": "Двухэтапное обучение для прорыва в мультимодальном рассуждении", "desc": "Статья исследует улучшение мультимодального рассуждения в больших языковых моделях. Авторы предлага
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#open_source", "#benchmark", "#alignment", "#rag"], "emoji": "🔬", "ru": {"title": "Открытая платформа для оценки систем глубокого исследования", "desc": "DeepResearchGym - это открытая система оценки для систем глубокого исследования, использующая воспроизводимый поисковый API и оце
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#training", "#diffusion", "#cv"], "emoji": "�panorama", "ru": {"title": "Раскрытие механизмов адаптации диффузионных моделей к панорамной генерации", "desc": "Исследование процесса тонкой настройки диффузионных моделей для генерации панорамных изображени
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#open_source", "#optimization", "#dataset", "#rl", "#benchmark"], "emoji": "🚚", "ru": {"title": "Реалистичный бенчмарк для маршрутизации в условиях городской неопределенности", "desc": "SVRPBench представляет новый бенчмарк для маршрутизации транспортных средств в условиях неопредел
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#agi", "#reasoning", "#agents", "#benchmark", "#training"], "emoji": "🕸️", "ru": {"title": "Новая парадигма обучения агентов для автономного поиска информации в сети", "desc": "Эта статья представляет новый подход к созданию агентов для автономного поиска информации. Авторы предлага
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#inference", "#reasoning", "#benchmark", "#training"], "emoji": "✂️", "ru": {"title": "PIR: Оптимизация рассуждений в ИИ через умное сокращение", "desc": "PIR - это фреймворк, который оптимизирует важность шагов рассуждения в больших языковых моделях путем удаления 
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#alignment"], "emoji": "🧠", "ru": {"title": "Большие языковые модели отстают от людей в понимании динамики психических состояний", "desc": "Представлен новый бенчмарк DynToM для оценки способности больших языковых моделей (LLM) отслеживать изменение психи
[29.05.2025 07:12] Querying the API.
[29.05.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

UniR, a lightweight reasoning module, enhances Large Language Models with specialized reasoning abilities through modular composition, improving performance and generalization at lower computational costs.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable general capabilities, but enhancing skills such as reasoning often demands substantial computational resources and may compromise their generalization. While Parameter-Efficient Fine-Tuning (PEFT) methods offer a more resource-conscious alternative, they typically requires retraining for each LLM backbone due to architectural dependencies. To address these challenges, here we propose Universal Reasoner (UniR) - a single, lightweight, composable, and plug-and-play reasoning module that can be used with any frozen LLM to endow it with specialized reasoning capabilities. Specifically, UniR decomposes the reward into a standalone reasoning module that is trained independently using predefined rewards, effectively translating trajectory-level signals into token-level guidance. Once trained, UniR can be combined with any frozen LLM at inference time by simply adding its output logits to those of the LLM backbone. This additive structure naturally enables modular composition: multiple UniR modules trained for different tasks can be jointly applied by summing their logits, enabling complex reasoning via composition. Experimental results on mathematical reasoning and machine translation tasks show that UniR significantly outperforms existing baseline fine-tuning methods using the Llama3.2 model. Furthermore, UniR demonstrates strong weak-to-strong generalization: reasoning modules trained on smaller models effectively guide much larger LLMs. This makes UniR a cost-efficient, adaptable, and robust solution for enhancing reasoning in LLMs without compromising their core capabilities. Code is open-sourced at https://github.com/hangeol/UniR
[29.05.2025 07:12] Response: {
  "desc": "UniR - это универсальный модуль рассуждений для больших языковых моделей (LLM). Он позволяет улучшить способности LLM к рассуждениям без полной переподготовки модели, что экономит вычислительные ресурсы. UniR можно комбинировать с любой замороженной LLM, добавляя его выходные логиты к логитам основной модели. Эксперименты показали, что UniR значительно превосходит существующие методы дообучения на задачах математических рассуждений и машинного перевода.",

  "emoji": "🧠",

  "title": "UniR: Универсальный модуль рассуждений для усиления больших языковых моделей"
}
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"UniR, a lightweight reasoning module, enhances Large Language Models with specialized reasoning abilities through modular composition, improving performance and generalization at lower computational costs.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable general capabilities, but enhancing skills such as reasoning often demands substantial computational resources and may compromise their generalization. While Parameter-Efficient Fine-Tuning (PEFT) methods offer a more resource-conscious alternative, they typically requires retraining for each LLM backbone due to architectural dependencies. To address these challenges, here we propose Universal Reasoner (UniR) - a single, lightweight, composable, and plug-and-play reasoning module that can be used with any frozen LLM to endow it with specialized reasoning capabilities. Specifically, UniR decomposes the reward into a standalone reasoning module that is trained independently using predefined rewards, effectively translating trajectory-level signals into token-level guidance. Once trained, UniR can be combined with any frozen LLM at inference time by simply adding its output logits to those of the LLM backbone. This additive structure naturally enables modular composition: multiple UniR modules trained for different tasks can be jointly applied by summing their logits, enabling complex reasoning via composition. Experimental results on mathematical reasoning and machine translation tasks show that UniR significantly outperforms existing baseline fine-tuning methods using the Llama3.2 model. Furthermore, UniR demonstrates strong weak-to-strong generalization: reasoning modules trained on smaller models effectively guide much larger LLMs. This makes UniR a cost-efficient, adaptable, and robust solution for enhancing reasoning in LLMs without compromising their core capabilities. Code is open-sourced at https://github.com/hangeol/UniR"

[29.05.2025 07:12] Response: ```python
["ARCHITECTURE", "TRAINING", "RLHF"]
```
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"UniR, a lightweight reasoning module, enhances Large Language Models with specialized reasoning abilities through modular composition, improving performance and generalization at lower computational costs.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable general capabilities, but enhancing skills such as reasoning often demands substantial computational resources and may compromise their generalization. While Parameter-Efficient Fine-Tuning (PEFT) methods offer a more resource-conscious alternative, they typically requires retraining for each LLM backbone due to architectural dependencies. To address these challenges, here we propose Universal Reasoner (UniR) - a single, lightweight, composable, and plug-and-play reasoning module that can be used with any frozen LLM to endow it with specialized reasoning capabilities. Specifically, UniR decomposes the reward into a standalone reasoning module that is trained independently using predefined rewards, effectively translating trajectory-level signals into token-level guidance. Once trained, UniR can be combined with any frozen LLM at inference time by simply adding its output logits to those of the LLM backbone. This additive structure naturally enables modular composition: multiple UniR modules trained for different tasks can be jointly applied by summing their logits, enabling complex reasoning via composition. Experimental results on mathematical reasoning and machine translation tasks show that UniR significantly outperforms existing baseline fine-tuning methods using the Llama3.2 model. Furthermore, UniR demonstrates strong weak-to-strong generalization: reasoning modules trained on smaller models effectively guide much larger LLMs. This makes UniR a cost-efficient, adaptable, and robust solution for enhancing reasoning in LLMs without compromising their core capabilities. Code is open-sourced at https://github.com/hangeol/UniR"

[29.05.2025 07:12] Response: ```python
["REASONING", "OPEN_SOURCE"]
```
[29.05.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces UniR, a lightweight reasoning module designed to enhance Large Language Models (LLMs) with specialized reasoning skills while minimizing computational costs. Unlike traditional methods that require extensive retraining for each LLM, UniR operates as a plug-and-play module that can be added to any frozen LLM. It achieves this by independently training a reasoning module that translates high-level rewards into actionable guidance for the LLM. Experimental results demonstrate that UniR not only improves performance on tasks like mathematical reasoning and machine translation but also exhibits strong generalization capabilities across different model sizes.","title":"Enhancing LLMs with Modular Reasoning: The Power of UniR"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces UniR, a lightweight reasoning module designed to enhance Large Language Models (LLMs) with specialized reasoning skills while minimizing computational costs. Unlike traditional methods that require extensive retraining for each LLM, UniR operates as a plug-and-play module that can be added to any frozen LLM. It achieves this by independently training a reasoning module that translates high-level rewards into actionable guidance for the LLM. Experimental results demonstrate that UniR not only improves performance on tasks like mathematical reasoning and machine translation but also exhibits strong generalization capabilities across different model sizes.', title='Enhancing LLMs with Modular Reasoning: The Power of UniR'))
[29.05.2025 07:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"UniR是一个轻量级的推理模块，通过模块化组合增强大型语言模型（LLM）的推理能力，提升性能和泛化能力，同时降低计算成本。它将奖励分解为独立的推理模块，使用预定义的奖励进行独立训练，从而有效地将轨迹级信号转化为标记级指导。UniR可以与任何冻结的LLM结合使用，只需在推理时将其输出与LLM的输出相加，支持模块化组合。实验结果表明，UniR在数学推理和机器翻译任务上显著优于现有的微调方法，且在小模型上训练的推理模块能够有效指导更大的LLM。","title":"UniR：轻量级推理模块，提升LLM推理能力"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='UniR是一个轻量级的推理模块，通过模块化组合增强大型语言模型（LLM）的推理能力，提升性能和泛化能力，同时降低计算成本。它将奖励分解为独立的推理模块，使用预定义的奖励进行独立训练，从而有效地将轨迹级信号转化为标记级指导。UniR可以与任何冻结的LLM结合使用，只需在推理时将其输出与LLM的输出相加，支持模块化组合。实验结果表明，UniR在数学推理和机器翻译任务上显著优于现有的微调方法，且在小模型上训练的推理模块能够有效指导更大的LLM。', title='UniR：轻量级推理模块，提升LLM推理能力'))
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#architecture", "#3d"], "emoji": "🎨", "ru": {"title": "Нейронный рендеринг без физики: от треугольников к пикселям", "desc": "RenderFormer - это нейронная система рендеринга, которая напрямую создает изображение из треугольного представления сцены с полными эффектами глобального осв
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#training", "#open_source", "#hallucinations", "#rlhf", "#multimodal"], "emoji": "🖼️", "ru": {"title": "Точные подписи к изображениям через визуальную реконструкцию", "desc": "RICO - это новая итеративная система для улучшения точности подписей к изображ
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#cv", "#reasoning", "#multimodal"], "emoji": "🧠", "ru": {"title": "Визуальное воображение ИИ: новый уровень мышления мультимодальных моделей", "desc": "Статья представляет новую парадигму 'Мышление с генерируемыми изображениями', которая позволяет крупн
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#data", "#cv", "#diffusion", "#dataset", "#open_source", "#synthetic"], "emoji": "🎨", "ru": {"title": "Прорыв в создании редактируемых многослойных изображений с помощью ИИ", "desc": "Данная статья представляет новый подход к генерации многослойных прозрачных изображений на основе т
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#interpretability", "#rlhf"], "emoji": "🔍", "ru": {"title": "Text2Grad: Точная настройка языковых моделей с помощью текстовых градиентов", "desc": "Статья представляет новый подход к обучению языковых моделей под названием Text2Grad. Этот метод преобраз
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#optimization", "#training", "#math", "#rl", "#security", "#reasoning"], "emoji": "🔍", "ru": {"title": "Ограничения верификаторов в RLVR: необходимость более надежных систем", "desc": "Исследование анализирует эффективность и надежность верификаторов на основе правил и моделей в обу
[29.05.2025 07:12] Using data from previous issue: {"categories": ["#rl", "#rag", "#multimodal", "#reasoning", "#optimization"], "emoji": "🧠", "ru": {"title": "VRAG-RL: Улучшение визуальных рассуждений в RAG с помощью обучения с подкреплением", "desc": "VRAG-RL - это новая система обучения с подкреплением для улучшения рассуждений и обработки визуал
[29.05.2025 07:12] Querying the API.
[29.05.2025 07:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Chain-of-Zoom (CoZ) enhances single-image super-resolution models by using an autoregressive chain of intermediate scale-states and multi-scale-aware prompts to achieve extreme magnifications with high quality.  					AI-generated summary 				 Modern single-image super-resolution (SISR) models deliver photo-realistic results at the scale factors on which they are trained, but collapse when asked to magnify far beyond that regime. We address this scalability bottleneck with Chain-of-Zoom (CoZ), a model-agnostic framework that factorizes SISR into an autoregressive chain of intermediate scale-states with multi-scale-aware prompts. CoZ repeatedly re-uses a backbone SR model, decomposing the conditional probability into tractable sub-problems to achieve extreme resolutions without additional training. Because visual cues diminish at high magnifications, we augment each zoom step with multi-scale-aware text prompts generated by a vision-language model (VLM). The prompt extractor itself is fine-tuned using Generalized Reward Policy Optimization (GRPO) with a critic VLM, aligning text guidance towards human preference. Experiments show that a standard 4x diffusion SR model wrapped in CoZ attains beyond 256x enlargement with high perceptual quality and fidelity. Project Page: https://bryanswkim.github.io/chain-of-zoom/ .
[29.05.2025 07:12] Response: {
  "desc": "Статья представляет Chain-of-Zoom (CoZ) - фреймворк для улучшения моделей сверхразрешения одиночных изображений. CoZ использует авторегрессивную цепочку промежуточных масштабных состояний и мультимасштабные подсказки для достижения экстремальных увеличений с высоким качеством. Метод разбивает задачу на более простые подзадачи, позволяя многократно использовать базовую модель сверхразрешения. Для улучшения результатов применяются текстовые подсказки, генерируемые языковой моделью компьютерного зрения.",
  "emoji": "🔍",
  "title": "Революция в сверхразрешении изображений: от пикселей к деталям"
}
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Chain-of-Zoom (CoZ) enhances single-image super-resolution models by using an autoregressive chain of intermediate scale-states and multi-scale-aware prompts to achieve extreme magnifications with high quality.  					AI-generated summary 				 Modern single-image super-resolution (SISR) models deliver photo-realistic results at the scale factors on which they are trained, but collapse when asked to magnify far beyond that regime. We address this scalability bottleneck with Chain-of-Zoom (CoZ), a model-agnostic framework that factorizes SISR into an autoregressive chain of intermediate scale-states with multi-scale-aware prompts. CoZ repeatedly re-uses a backbone SR model, decomposing the conditional probability into tractable sub-problems to achieve extreme resolutions without additional training. Because visual cues diminish at high magnifications, we augment each zoom step with multi-scale-aware text prompts generated by a vision-language model (VLM). The prompt extractor itself is fine-tuned using Generalized Reward Policy Optimization (GRPO) with a critic VLM, aligning text guidance towards human preference. Experiments show that a standard 4x diffusion SR model wrapped in CoZ attains beyond 256x enlargement with high perceptual quality and fidelity. Project Page: https://bryanswkim.github.io/chain-of-zoom/ ."

[29.05.2025 07:12] Response: ```python
['CV', 'RAG', 'RLHF']
```
[29.05.2025 07:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Chain-of-Zoom (CoZ) enhances single-image super-resolution models by using an autoregressive chain of intermediate scale-states and multi-scale-aware prompts to achieve extreme magnifications with high quality.  					AI-generated summary 				 Modern single-image super-resolution (SISR) models deliver photo-realistic results at the scale factors on which they are trained, but collapse when asked to magnify far beyond that regime. We address this scalability bottleneck with Chain-of-Zoom (CoZ), a model-agnostic framework that factorizes SISR into an autoregressive chain of intermediate scale-states with multi-scale-aware prompts. CoZ repeatedly re-uses a backbone SR model, decomposing the conditional probability into tractable sub-problems to achieve extreme resolutions without additional training. Because visual cues diminish at high magnifications, we augment each zoom step with multi-scale-aware text prompts generated by a vision-language model (VLM). The prompt extractor itself is fine-tuned using Generalized Reward Policy Optimization (GRPO) with a critic VLM, aligning text guidance towards human preference. Experiments show that a standard 4x diffusion SR model wrapped in CoZ attains beyond 256x enlargement with high perceptual quality and fidelity. Project Page: https://bryanswkim.github.io/chain-of-zoom/ ."

[29.05.2025 07:12] Response: ```python
["OPTIMIZATION", "ALIGNMENT", "DIFFUSION"]
```
[29.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Chain-of-Zoom (CoZ) is a novel framework that improves single-image super-resolution (SISR) by breaking down the process into an autoregressive sequence of intermediate scale-states. This approach allows the model to achieve extreme magnifications while maintaining high image quality, even beyond the typical training scale. CoZ utilizes multi-scale-aware prompts generated by a vision-language model to enhance the visual cues at high magnifications. By employing Generalized Reward Policy Optimization (GRPO) for fine-tuning, CoZ aligns the prompts with human preferences, resulting in superior perceptual quality in the generated images.","title":"Zooming into High-Quality Super-Resolution with CoZ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Chain-of-Zoom (CoZ) is a novel framework that improves single-image super-resolution (SISR) by breaking down the process into an autoregressive sequence of intermediate scale-states. This approach allows the model to achieve extreme magnifications while maintaining high image quality, even beyond the typical training scale. CoZ utilizes multi-scale-aware prompts generated by a vision-language model to enhance the visual cues at high magnifications. By employing Generalized Reward Policy Optimization (GRPO) for fine-tuning, CoZ aligns the prompts with human preferences, resulting in superior perceptual quality in the generated images.', title='Zooming into High-Quality Super-Resolution with CoZ'))
[29.05.2025 07:13] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Chain-of-Zoom (CoZ) 是一种增强单图像超分辨率模型的方法。它通过使用自回归的中间尺度状态链和多尺度感知提示，来实现高质量的极端放大。CoZ 将超分辨率任务分解为可处理的子问题，允许在不额外训练的情况下重复使用基础超分辨率模型。实验表明，使用 CoZ 的标准 4 倍扩散超分辨率模型可以实现超过 256 倍的放大，且保持高感知质量和保真度。","title":"超分辨率的新突破：Chain-of-Zoom"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Chain-of-Zoom (CoZ) 是一种增强单图像超分辨率模型的方法。它通过使用自回归的中间尺度状态链和多尺度感知提示，来实现高质量的极端放大。CoZ 将超分辨率任务分解为可处理的子问题，允许在不额外训练的情况下重复使用基础超分辨率模型。实验表明，使用 CoZ 的标准 4 倍扩散超分辨率模型可以实现超过 256 倍的放大，且保持高感知质量和保真度。', title='超分辨率的新突破：Chain-of-Zoom'))
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#optimization", "#video", "#training", "#transfer_learning", "#diffusion", "#3d", "#multimodal"], "emoji": "🎥", "ru": {"title": "Эффективный 3D-контроль камеры без сложных аннотаций", "desc": "EPiC - это фреймворк для эффективного 3D-контроля камеры в моделях видеодиффузии. Он созда
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#cv", "#interpretability", "#reasoning"], "emoji": "🌍", "ru": {"title": "Умное определение местоположения: VLM с усиленным географическим рассуждением", "desc": "Статья представляет набор инструментов Geo Reason Enhancement (GRE) Suite для улучшения геолока
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#architecture", "#inference", "#interpretability", "#data", "#reasoning"], "emoji": "🧠", "ru": {"title": "Языковые модели учатся мыслить предложениями", "desc": "Исследование показывает, что предобученные языковые модели могут быть адаптированы для работы в пространстве предложений,
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#interpretability", "#dataset", "#architecture"], "emoji": "🧠", "ru": {"title": "Раскрывая тайны дообучения: как LLM учатся выполнять инструкции", "desc": "Исследование анализирует, как дообучение изменяет вычислительные механизмы больших языковых модел
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#benchmark", "#graphs"], "emoji": "🧠", "ru": {"title": "HuggingKG: Структурированное представление ресурсов ML для продвинутого анализа", "desc": "HuggingKG - это первый крупномасштабный граф знаний, созданный на основе сообщества Hugging Face для управле
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#video", "#3d", "#architecture", "#security"], "emoji": "🎥", "ru": {"title": "Защита авторских прав на AI-видео с помощью невидимых водяных знаков", "desc": "Safe-Sora - это новая система для внедрения невидимых водяных знаков в видео, генерируемые искусственным интеллектом. Она исп
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#ethics", "#low_resource", "#multilingual", "#dataset", "#benchmark", "#open_source"], "emoji": "🇨🇳", "ru": {"title": "Скрытые предубеждения LLM в китайском языке: упрощенный vs традиционный", "desc": "Исследование анализирует различия в производительности больших языковых моделей (
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#architecture", "#optimization", "#diffusion", "#cv", "#inference"], "emoji": "🖼️", "ru": {"title": "Ускорение генерации изображений без потери качества", "desc": "Статья представляет Time-independent Unified Encoder (TiUE) - новый подход к дистилляции диффузионных моделей для генер
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#training", "#rl", "#multimodal", "#alignment", "#video", "#reasoning"], "emoji": "⏱️", "ru": {"title": "MUSEG: Прорыв во временном понимании видео для больших языковых моделей", "desc": "MUSEG - это новый метод, основанный на обучении с подкреплением, который улучшает временное пон
[29.05.2025 07:13] Using data from previous issue: {"categories": ["#training", "#rlhf", "#alignment", "#ethics", "#hallucinations"], "emoji": "💉", "ru": {"title": "Вакцинация ИИ против дезинформации", "desc": "Статья предлагает новый метод обучения генеративных моделей ИИ для снижения генерации дезинформации. Метод основан на аналогии с биологическ
[29.05.2025 07:13] Loading Chinese text from previous data.
[29.05.2025 07:13] Renaming data file.
[29.05.2025 07:13] Renaming previous data. hf_papers.json to ./d/2025-05-29.json
[29.05.2025 07:13] Saving new data file.
[29.05.2025 07:13] Generating page.
[29.05.2025 07:13] Renaming previous page.
[29.05.2025 07:13] Renaming previous data. index.html to ./d/2025-05-29.html
[29.05.2025 07:13] [Experimental] Generating Chinese page for reading.
[29.05.2025 07:13] Chinese vocab [{'word': 'OmniConsistency', 'pinyin': '', 'trans': 'OmniConsistency'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '变压器', 'pinyin': 'biàn yā qì', 'trans': 'transformer'}, {'word': '增强', 'pinyin': 'zēng qiáng', 'trans': 'enhance'}, {'word': '风格', 'pinyin': 'fēng gé', 'trans': 'style'}, {'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'}, {'word': '泛化', 'pinyin': 'fàn huà', 'trans': 'generalization'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'}, {'word': '退化', 'pinyin': 'tuì huà', 'trans': 'degeneration'}, {'word': '上下文', 'pinyin': 'shàng xià wén', 'trans': 'context'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '两阶段', 'pinyin': 'liǎng jiē duàn', 'trans': 'two-stage'}, {'word': '渐进', 'pinyin': 'jiàn jìn', 'trans': 'progressive'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '插播', 'pinyin': 'chā bō', 'trans': 'interpolation'}, {'word': '设计', 'pinyin': 'shè jì', 'trans': 'design'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '接近', 'pinyin': 'jiē jìn', 'trans': 'approach'}, {'word': '商业', 'pinyin': 'shāng yè', 'trans': 'commercial'}, {'word': '顶尖', 'pinyin': 'dǐng jiān', 'trans': 'top-notch'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': 'GPT-4o', 'pinyin': '', 'trans': 'GPT-4o'}]
[29.05.2025 07:13] Renaming previous Chinese page.
[29.05.2025 07:13] Renaming previous data. zh.html to ./d/2025-05-28_zh_reading_task.html
[29.05.2025 07:13] Writing Chinese reading task.
[29.05.2025 07:13] Writing result.
[29.05.2025 07:13] Renaming log file.
[29.05.2025 07:13] Renaming previous data. log.txt to ./logs/2025-05-29_last_log.txt
