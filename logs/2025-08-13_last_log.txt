[13.08.2025 07:15] Read previous papers.
[13.08.2025 07:15] Generating top page (month).
[13.08.2025 07:15] Writing top page (month).
[13.08.2025 08:16] Read previous papers.
[13.08.2025 08:16] Get feed.
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05748
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08086
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07976
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09138
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07409
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08088
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05615
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05399
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09062
[13.08.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2508.08665
[13.08.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2508.08940
[13.08.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2508.06964
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09101
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08244
[13.08.2025 08:16] Extract page data from URL. URL: https://huggingface.co/papers/2508.09123
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08791
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09050
[13.08.2025 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04195
[13.08.2025 08:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.08.2025 08:16] No deleted papers detected.
[13.08.2025 08:16] Downloading and parsing papers (pdf, html). Total: 18.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.05748.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.05748.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.05748.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.08086.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.08086.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.08086.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.07976.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.07976.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.07976.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.09138.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.09138.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.09138.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.07409.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.07409.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.07409.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.08088.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.08088.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.08088.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.05615.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.05615.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.05615.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.05399.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.05399.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.05399.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.09062.
[13.08.2025 08:16] Extra JSON file exists (./assets/json/2508.09062.json), skip PDF parsing.
[13.08.2025 08:16] Paper image links file exists (./assets/img_data/2508.09062.json), skip HTML parsing.
[13.08.2025 08:16] Success.
[13.08.2025 08:16] Downloading and parsing paper https://huggingface.co/papers/2508.08665.
[13.08.2025 08:16] Downloading paper 2508.08665 from http://arxiv.org/pdf/2508.08665v1...
[13.08.2025 08:16] Extracting affiliations from text.
[13.08.2025 08:16] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Aryabhata: An exam-focused language model for JEE Math Ritvik Rastogi PhysicsWallah ritvik.rastogi@pw.live Sachin Dharashivkar AthenaAgent sachin@athenaagent.com Sandeep Varma PhysicsWallah sandeep.varma@pw.live 5 2 0 2 2 ] . [ 1 5 6 6 8 0 . 8 0 5 2 : r a "
[13.08.2025 08:17] Response: ```python
["PhysicsWallah", "AthenaAgent"]
```
[13.08.2025 08:17] Deleting PDF ./assets/pdf/2508.08665.pdf.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.08940.
[13.08.2025 08:17] Downloading paper 2508.08940 from http://arxiv.org/pdf/2508.08940v1...
[13.08.2025 08:17] Extracting affiliations from text.
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 1 ] . [ 1 0 4 9 8 0 . 8 0 5 2 : r Preprint Under Review TRAIN LONG, THINK SHORT: CURRICULUM LEARNING FOR EFFICIENT REASONING Hasan Abed Al Kader Hammoud1 Kumail Alhamoud2 Abed Hammoud3 Elie Bou-Zeid3 Marzyeh Ghassemi2 Bernard Ghanem1 1King Abdullah University of Science and Technology (KAUST), Saudi Arabia 2Massachusetts Institute of Technology (MIT), Cambridge, MA, USA 3Princeton University, Princeton, NJ, USA "
[13.08.2025 08:17] Response: ```python
[
    "King Abdullah University of Science and Technology (KAUST), Saudi Arabia",
    "Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
    "Princeton University, Princeton, NJ, USA"
]
```
[13.08.2025 08:17] Deleting PDF ./assets/pdf/2508.08940.pdf.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.06964.
[13.08.2025 08:17] Downloading paper 2508.06964 from http://arxiv.org/pdf/2508.06964v2...
[13.08.2025 08:17] Extracting affiliations from text.
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Adversarial Video Promotion Against Text-to-Video Retrieval Xian Jiaotong University michaeltqw@stu.xjtu.edu.cn, {linchenhao, zhengyu.zhao, qianlix}@xjtu.edu.cn, {sh liu, chaoshen}@mail.xjtu.edu.cn 5 2 0 2 2 1 ] . [ 2 4 6 9 6 0 . 8 0 5 2 : r a "
[13.08.2025 08:17] Response: ```python
["Xian Jiaotong University"]
```
[13.08.2025 08:17] Deleting PDF ./assets/pdf/2508.06964.pdf.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.09101.
[13.08.2025 08:17] Extra JSON file exists (./assets/json/2508.09101.json), skip PDF parsing.
[13.08.2025 08:17] Paper image links file exists (./assets/img_data/2508.09101.json), skip HTML parsing.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.08244.
[13.08.2025 08:17] Extra JSON file exists (./assets/json/2508.08244.json), skip PDF parsing.
[13.08.2025 08:17] Paper image links file exists (./assets/img_data/2508.08244.json), skip HTML parsing.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.09123.
[13.08.2025 08:17] Downloading paper 2508.09123 from http://arxiv.org/pdf/2508.09123v1...
[13.08.2025 08:17] Extracting affiliations from text.
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 1 ] . [ 1 3 2 1 9 0 . 8 0 5 2 : r OPENCUA: Open Foundations for Computer-Use Agents Xinyuan Wang*x Bowen Wang*x Dunjie Lu*x Junlin Yang*x Tianbao Xie*x Junli Wang*x Jiaqi Dengx Xiaole Guox Yiheng Xux Chen Henry Wuc Zhennan Shenx Zhuokai Lix Ryan Lix Xiaochuan Lix Junda Chenx Boyuan Zhengx Peihang Lix Fangyu Leix Ruisheng Caox Yeqiao Fux Dongchan Shinx Martin Shinx Jiarui Hux Yuyan Wangx Jixuan Chenx Yuxiao Yex Danyang Zhangx Hao Hum Huarong Chenm Dikang Dum Zaida Zhoum Yipu Wangm Heng Wangm Diyi Yangs Victor Zhongw Flood Sungm Y. Charlesm Zhilin Yangm Tao Yux XLANG Lab, University of Hong Kong Moonshot AI Stanford University University of Waterloo Carnegie Mellon University OpenCUA Homepage (Tool, Model, Data): https://opencua.xlang.ai Abstract Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OPENCUA, comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AGENTNET, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) scalable pipeline that transforms demonstrations into stateaction pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OPENCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing new state-of-the-art (SOTA) among ope"
[13.08.2025 08:17] Response: ```python
[
    "XLANG Lab, University of Hong Kong",
    "Moonshot AI",
    "Stanford University",
    "University of Waterloo",
    "Carnegie Mellon University"
]
```
[13.08.2025 08:17] Deleting PDF ./assets/pdf/2508.09123.pdf.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.08791.
[13.08.2025 08:17] Extra JSON file exists (./assets/json/2508.08791.json), skip PDF parsing.
[13.08.2025 08:17] Paper image links file exists (./assets/img_data/2508.08791.json), skip HTML parsing.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.09050.
[13.08.2025 08:17] Extra JSON file exists (./assets/json/2508.09050.json), skip PDF parsing.
[13.08.2025 08:17] Paper image links file exists (./assets/img_data/2508.09050.json), skip HTML parsing.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Downloading and parsing paper https://huggingface.co/papers/2508.04195.
[13.08.2025 08:17] Extra JSON file exists (./assets/json/2508.04195.json), skip PDF parsing.
[13.08.2025 08:17] Paper image links file exists (./assets/img_data/2508.04195.json), skip HTML parsing.
[13.08.2025 08:17] Success.
[13.08.2025 08:17] Enriching papers with extra data.
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 0. WebWatcher, a multimodal agent with enhanced visual-language reasoning, outperforms existing agents in complex visual and textual information retrieval tasks using synthetic trajectories and reinforcement learning.  					AI-generated summary 				 Web agents such as Deep Research have demonstrated su...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 1. Matrix-3D generates wide-coverage 3D worlds from single images or text using panoramic video diffusion and reconstruction models.  					AI-generated summary 				 Explorable 3D world generation from a single image or text prompt forms a cornerstone of spatial intelligence. Recent works utilize video ...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 2. ASearcher is an open-source project that uses scalable asynchronous RL training to enhance search agents, achieving high performance on QA tasks with long-horizon search capabilities.  					AI-generated summary 				 Recent advancements in LLM-based agents have demonstrated remarkable capabilities in...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 3. Two methods, Temporal Self-Consistency Voting and Temporal Consistency Reinforcement, improve diffusion large language models by leveraging temporal consistency in intermediate predictions.  					AI-generated summary 				 Diffusion large language models (dLLMs) generate text through iterative denois...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 4. CharacterShot is a 4D character animation framework that uses a DiT-based model and dual-attention module to generate consistent 3D animations from a single image and 2D pose sequence.  					AI-generated summary 				 In this paper, we propose CharacterShot, a controllable and consistent 4D character...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 5. HierSearch, a hierarchical agentic deep search framework using hierarchical RL, improves performance in multi-source retrieval tasks by coordinating local and Web search agents and refining knowledge.  					AI-generated summary 				 Recently, large reasoning models have demonstrated strong mathemati...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 6. GUI-RC and GUI-RCPO enhance GUI grounding accuracy by leveraging spatial consistency and reinforcement learning without additional training data.  					AI-generated summary 				 Graphical User Interface (GUI) grounding, the task of mapping natural language instructions to precise screen coordinates,...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 7. UNCAGE, a training-free method using contrastive attention guidance, enhances compositional fidelity in text-to-image generation by prioritizing the unmasking of object-representing tokens.  					AI-generated summary 				 Text-to-image (T2I) generation has been actively studied using Diffusion Model...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 8. VertexRegen generates meshes with continuous detail by reversing edge collapse through a generative model, offering anytime generation and flexibility in detail levels.  					AI-generated summary 				 We introduce VertexRegen, a novel mesh generation framework that enables generation at a continuous...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 9. Aryabhata 1.0, a compact math reasoning model, outperforms existing models on educational exams and benchmarks by using supervised fine-tuning, reinforcement learning with verifiable rewards, and novel exploration strategies.  					AI-generated summary 				 We present Aryabhata 1.0, a compact 7B par...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 10. A curriculum learning strategy using Group Relative Policy Optimization (GRPO) enhances the reasoning abilities of large language models by progressively tightening token budgets, improving accuracy and token efficiency.  					AI-generated summary 				 Recent work on enhancing the reasoning abilitie...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 11. The Video Promotion attack (ViPro) enhances the robustness of text-to-video retrieval (T2VR) by promoting videos towards selected queries, demonstrating significant improvements over existing baselines in various attack scenarios.  					AI-generated summary 				 Thanks to the development of cross-mo...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 12. AutoCodeGen creates a large-scale, multilingual code generation benchmark, AutoCodeBench, to evaluate LLMs on diverse and complex tasks without manual annotations.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, with code...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 13. Cut2Next, a framework using a Diffusion Transformer with in-context tuning and hierarchical prompting, generates high-quality, cinematically coherent shots that adhere to professional editing patterns.  					AI-generated summary 				 Effective multi-shot generation demands purposeful, film-like tran...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 14. OpenCUA is an open-source framework for vision-language models as computer-use agents, featuring an annotation infrastructure, a large-scale dataset, and a scalable pipeline that achieves state-of-the-art performance.  					AI-generated summary 				 Vision-language models have demonstrated impressiv...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 15. An automated pipeline for constructing training environments and a verifiable reward mechanism enhance large language models' tool-use performance without compromising general capabilities.  					AI-generated summary 				 Effective tool use is essential for large language models (LLMs) to interact m...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 16. Quantum game theory demonstrated on IBM Quantum hardware using the Eisert-Wilkens-Lewenstein framework shows persistent quantum advantages in strategic coordination despite noise and decoherence.  					AI-generated summary 				 Implementing quantum game theory on real hardware is challenging due to ...
[13.08.2025 08:17] ********************************************************************************
[13.08.2025 08:17] Abstract 17. NVSpeech is a pipeline that integrates the recognition and synthesis of paralinguistic vocalizations in Mandarin, using a large annotated dataset and models that treat these cues as decodable tokens.  					AI-generated summary 				 Paralinguistic vocalizations-including non-verbal sounds like laught...
[13.08.2025 08:17] Read previous papers.
[13.08.2025 08:17] Generating reviews via LLM API.
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#reasoning", "#synthetic", "#multimodal", "#agents", "#rl", "#benchmark", "#open_source"], "emoji": "🕵️", "ru": {"title": "WebWatcher: Мультимодальный агент для глубокого исследования визуальной и текстовой информации", "desc": "WebWatcher - это мультимодальный агент с улучшенными в
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#diffusion", "#3d", "#synthetic"], "emoji": "🌐", "ru": {"title": "Генерация исследуемых 3D-миров из одного изображения или текста", "desc": "Matrix-3D - это система для создания исследуемых трехмерных миров на основе одного изображения или текстового запроса. Она использ
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#training", "#agents", "#rl", "#long_context", "#open_source"], "emoji": "🔍", "ru": {"title": "ASearcher: Революция в обучении поисковых ИИ-агентов", "desc": "ASearcher - это проект с открытым исходным кодом, использующий масштабируемое асинхронное обучение с подкреплени
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#benchmark", "#rl"], "emoji": "⏳", "ru": {"title": "Использование временной динамики для улучшения диффузионных языковых моделей", "desc": "Статья представляет два метода улучшения диффузионных больших языковых моделей (dLLM): Временное са
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#3d", "#optimization", "#open_source"], "emoji": "🎭", "ru": {"title": "Оживление персонажей в 3D из одного изображения", "desc": "CharacterShot - это фреймворк для 4D-анимации персонажей, использующий модель на основе DiT и модуль двойного внимания. Он позв
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#hallucinations", "#rag", "#reasoning", "#agents", "#benchmark", "#rl", "#healthcare"], "emoji": "🔍", "ru": {"title": "Иерархический глубокий поиск для эффективного многоисточникового извлечения информации", "desc": "HierSearch - это иерархическая система глубокого поиска, использую
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#inference", "#optimization", "#agents", "#rlhf", "#rl"], "emoji": "🖥️", "ru": {"title": "Повышение точности ИИ-агентов для GUI без дополнительных данных", "desc": "В статье представлены методы GUI-RC и GUI-RCPO для повышения точности привязки графического интерфейса без использован
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#benchmark", "#cv"], "emoji": "🎭", "ru": {"title": "Точная композиция в генерации изображений через умное раскрытие токенов", "desc": "UNCAGE - это новый метод без дополнительного обучения, улучшающий композиционную точность в генерации из
[13.08.2025 08:17] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "🔍", "ru": {"title": "Гибкая генерация 3D-сеток с любым уровнем детализации", "desc": "VertexRegen - это новая система генерации трехмерных сеток с непрерывным уровнем детализации. Она использует обратный процесс схлопывания ребер, обучаемы
[13.08.2025 08:17] Querying the API.
[13.08.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Aryabhata 1.0, a compact math reasoning model, outperforms existing models on educational exams and benchmarks by using supervised fine-tuning, reinforcement learning with verifiable rewards, and novel exploration strategies.  					AI-generated summary 				 We present Aryabhata 1.0, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-n rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation alongwith novel exploration strategies such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback (https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0{Aryabhata 1.0 on Hugging Face}); PW is actively training future models to further improve learning outcomes for students.
[13.08.2025 08:17] Response: {
  "desc": "Представлена модель Aryabhata 1.0 - компактная языковая модель для математических рассуждений с 7 миллиардами параметров. Модель оптимизирована для индийского вступительного экзамена JEE и превосходит существующие модели на образовательных тестах. Aryabhata 1.0 использует контролируемое обучение, обучение с подкреплением с проверяемыми наградами и новые стратегии исследования. Модель демонстрирует высокую точность и эффективность как на целевых, так и на сторонних наборах данных, предоставляя пошаговые рассуждения.",

  "emoji": "🧮",

  "title": "Компактная ИИ-модель превосходит аналоги в математических рассуждениях"
}
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Aryabhata 1.0, a compact math reasoning model, outperforms existing models on educational exams and benchmarks by using supervised fine-tuning, reinforcement learning with verifiable rewards, and novel exploration strategies.  					AI-generated summary 				 We present Aryabhata 1.0, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-n rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation alongwith novel exploration strategies such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback (https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0{Aryabhata 1.0 on Hugging Face}); PW is actively training future models to further improve learning outcomes for students."

[13.08.2025 08:17] Response: ```python
['DATASET', 'TRAINING', 'RL', 'MATH', 'SMALL_MODELS']
```
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Aryabhata 1.0, a compact math reasoning model, outperforms existing models on educational exams and benchmarks by using supervised fine-tuning, reinforcement learning with verifiable rewards, and novel exploration strategies.  					AI-generated summary 				 We present Aryabhata 1.0, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-n rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation alongwith novel exploration strategies such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback (https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0{Aryabhata 1.0 on Hugging Face}); PW is actively training future models to further improve learning outcomes for students."

[13.08.2025 08:17] Response: ```python
['REASONING', 'OPEN_SOURCE']
```
[13.08.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Aryabhata 1.0 is a compact math reasoning model designed specifically for the Joint Entrance Examination (JEE) in India. It utilizes supervised fine-tuning and reinforcement learning with verifiable rewards to enhance its performance on educational tasks. The model incorporates innovative exploration strategies to improve its reasoning capabilities, allowing it to provide detailed step-by-step solutions. Evaluated against various benchmarks, Aryabhata 1.0 demonstrates superior accuracy and efficiency compared to existing models, making it a valuable tool for educational purposes.","title":"Revolutionizing Math Reasoning for Education with Aryabhata 1.0"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Aryabhata 1.0 is a compact math reasoning model designed specifically for the Joint Entrance Examination (JEE) in India. It utilizes supervised fine-tuning and reinforcement learning with verifiable rewards to enhance its performance on educational tasks. The model incorporates innovative exploration strategies to improve its reasoning capabilities, allowing it to provide detailed step-by-step solutions. Evaluated against various benchmarks, Aryabhata 1.0 demonstrates superior accuracy and efficiency compared to existing models, making it a valuable tool for educational purposes.', title='Revolutionizing Math Reasoning for Education with Aryabhata 1.0'))
[13.08.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Aryabhata 1.0 是一个紧凑的数学推理模型，专为印度的联合入学考试（JEE）优化。它通过监督微调、可验证奖励的强化学习和新颖的探索策略，超越了现有模型的表现。该模型结合了强大的开放权重推理模型，并采用了课程学习和链式思维的验证样本进行训练。经过评估，Aryabhata 在准确性和效率上均优于现有模型，同时提供了有助于教学的逐步推理过程。","title":"Aryabhata 1.0：教育考试的数学推理新标杆"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Aryabhata 1.0 是一个紧凑的数学推理模型，专为印度的联合入学考试（JEE）优化。它通过监督微调、可验证奖励的强化学习和新颖的探索策略，超越了现有模型的表现。该模型结合了强大的开放权重推理模型，并采用了课程学习和链式思维的验证样本进行训练。经过评估，Aryabhata 在准确性和效率上均优于现有模型，同时提供了有助于教学的逐步推理过程。', title='Aryabhata 1.0：教育考试的数学推理新标杆'))
[13.08.2025 08:17] Querying the API.
[13.08.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A curriculum learning strategy using Group Relative Policy Optimization (GRPO) enhances the reasoning abilities of large language models by progressively tightening token budgets, improving accuracy and token efficiency.  					AI-generated summary 				 Recent work on enhancing the reasoning abilities of large language models (LLMs) has introduced explicit length control as a means of constraining computational cost while preserving accuracy. However, existing approaches rely on fixed-length training budgets, which do not take advantage of the natural progression from exploration to compression during learning. In this work, we propose a curriculum learning strategy for length-controlled reasoning using Group Relative Policy Optimization (GRPO). Our method starts with generous token budgets and gradually tightens them over training, encouraging models to first discover effective solution strategies and then distill them into more concise reasoning traces. We augment GRPO with a reward function that balances three signals: task correctness (via verifier feedback), length efficiency, and formatting adherence (via structural tags). Experiments on GSM8K, MATH500, SVAMP, College Math, and GSM+ demonstrate that curriculum-based training consistently outperforms fixed-budget baselines at the same final budget, achieving higher accuracy and significantly improved token efficiency. We further ablate the impact of reward weighting and decay schedule design, showing that progressive constraint serves as a powerful inductive bias for training efficient reasoning models. Our code and checkpoints are released at: https://github.com/hammoudhasan/curriculum_grpo.
[13.08.2025 08:17] Response: {
  "desc": "Эта статья представляет стратегию обучения с учителем, использующую Group Relative Policy Optimization (GRPO) для улучшения способностей больших языковых моделей к рассуждению. Метод постепенно ужесточает ограничения на количество токенов, что позволяет моделям сначала находить эффективные стратегии решения, а затем сжимать их в более краткие цепочки рассуждений. Авторы дополняют GRPO функцией вознаграждения, учитывающей правильность задачи, эффективность длины и соблюдение форматирования. Эксперименты на нескольких наборах данных показывают, что этот подход превосходит базовые модели с фиксированным бюджетом токенов, достигая более высокой точности и значительно улучшенной эффективности использования токенов.",
  "emoji": "🧠",
  "title": "Эффективное обучение языковых моделей через постепенное сжатие рассуждений"
}
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A curriculum learning strategy using Group Relative Policy Optimization (GRPO) enhances the reasoning abilities of large language models by progressively tightening token budgets, improving accuracy and token efficiency.  					AI-generated summary 				 Recent work on enhancing the reasoning abilities of large language models (LLMs) has introduced explicit length control as a means of constraining computational cost while preserving accuracy. However, existing approaches rely on fixed-length training budgets, which do not take advantage of the natural progression from exploration to compression during learning. In this work, we propose a curriculum learning strategy for length-controlled reasoning using Group Relative Policy Optimization (GRPO). Our method starts with generous token budgets and gradually tightens them over training, encouraging models to first discover effective solution strategies and then distill them into more concise reasoning traces. We augment GRPO with a reward function that balances three signals: task correctness (via verifier feedback), length efficiency, and formatting adherence (via structural tags). Experiments on GSM8K, MATH500, SVAMP, College Math, and GSM+ demonstrate that curriculum-based training consistently outperforms fixed-budget baselines at the same final budget, achieving higher accuracy and significantly improved token efficiency. We further ablate the impact of reward weighting and decay schedule design, showing that progressive constraint serves as a powerful inductive bias for training efficient reasoning models. Our code and checkpoints are released at: https://github.com/hammoudhasan/curriculum_grpo."

[13.08.2025 08:17] Response: ```python
['TRAINING', 'RLHF', 'MATH']
```
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A curriculum learning strategy using Group Relative Policy Optimization (GRPO) enhances the reasoning abilities of large language models by progressively tightening token budgets, improving accuracy and token efficiency.  					AI-generated summary 				 Recent work on enhancing the reasoning abilities of large language models (LLMs) has introduced explicit length control as a means of constraining computational cost while preserving accuracy. However, existing approaches rely on fixed-length training budgets, which do not take advantage of the natural progression from exploration to compression during learning. In this work, we propose a curriculum learning strategy for length-controlled reasoning using Group Relative Policy Optimization (GRPO). Our method starts with generous token budgets and gradually tightens them over training, encouraging models to first discover effective solution strategies and then distill them into more concise reasoning traces. We augment GRPO with a reward function that balances three signals: task correctness (via verifier feedback), length efficiency, and formatting adherence (via structural tags). Experiments on GSM8K, MATH500, SVAMP, College Math, and GSM+ demonstrate that curriculum-based training consistently outperforms fixed-budget baselines at the same final budget, achieving higher accuracy and significantly improved token efficiency. We further ablate the impact of reward weighting and decay schedule design, showing that progressive constraint serves as a powerful inductive bias for training efficient reasoning models. Our code and checkpoints are released at: https://github.com/hammoudhasan/curriculum_grpo."

[13.08.2025 08:17] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[13.08.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a novel curriculum learning strategy that utilizes Group Relative Policy Optimization (GRPO) to enhance the reasoning capabilities of large language models (LLMs). The approach involves starting with a generous token budget and progressively tightening it, allowing models to first explore various solution strategies before refining them into concise reasoning. By incorporating a reward function that balances task correctness, length efficiency, and formatting adherence, the method improves both accuracy and token efficiency. Experiments demonstrate that this curriculum-based training consistently outperforms traditional fixed-budget methods across multiple datasets, highlighting the effectiveness of progressive constraints in model training.","title":"Progressive Learning for Efficient Reasoning in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a novel curriculum learning strategy that utilizes Group Relative Policy Optimization (GRPO) to enhance the reasoning capabilities of large language models (LLMs). The approach involves starting with a generous token budget and progressively tightening it, allowing models to first explore various solution strategies before refining them into concise reasoning. By incorporating a reward function that balances task correctness, length efficiency, and formatting adherence, the method improves both accuracy and token efficiency. Experiments demonstrate that this curriculum-based training consistently outperforms traditional fixed-budget methods across multiple datasets, highlighting the effectiveness of progressive constraints in model training.', title='Progressive Learning for Efficient Reasoning in LLMs'))
[13.08.2025 08:17] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种基于课程学习策略的长度控制推理方法，使用群体相对策略优化（GRPO）来增强大型语言模型的推理能力。该方法通过逐步收紧令牌预算，鼓励模型首先探索有效的解决策略，然后将其提炼为更简洁的推理过程。我们引入了一种奖励函数，平衡任务正确性、长度效率和格式遵循三个信号。实验结果表明，基于课程的训练在相同的最终预算下，始终优于固定预算的基线，达到了更高的准确性和显著提高的令牌效率。","title":"课程学习提升推理能力的策略"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种基于课程学习策略的长度控制推理方法，使用群体相对策略优化（GRPO）来增强大型语言模型的推理能力。该方法通过逐步收紧令牌预算，鼓励模型首先探索有效的解决策略，然后将其提炼为更简洁的推理过程。我们引入了一种奖励函数，平衡任务正确性、长度效率和格式遵循三个信号。实验结果表明，基于课程的训练在相同的最终预算下，始终优于固定预算的基线，达到了更高的准确性和显著提高的令牌效率。', title='课程学习提升推理能力的策略'))
[13.08.2025 08:17] Querying the API.
[13.08.2025 08:17] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The Video Promotion attack (ViPro) enhances the robustness of text-to-video retrieval (T2VR) by promoting videos towards selected queries, demonstrating significant improvements over existing baselines in various attack scenarios.  					AI-generated summary 				 Thanks to the development of cross-modal models, text-to-video retrieval (T2VR) is advancing rapidly, but its robustness remains largely unexamined. Existing attacks against T2VR are designed to push videos away from queries, i.e., suppressing the ranks of videos, while the attacks that pull videos towards selected queries, i.e., promoting the ranks of videos, remain largely unexplored. These attacks can be more impactful as attackers may gain more views/clicks for financial benefits and widespread (mis)information. To this end, we pioneer the first attack against T2VR to promote videos adversarially, dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement (MoRe) to capture the finer-grained, intricate interaction between visual and textual modalities to enhance black-box transferability. Comprehensive experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing datasets with over 10k videos, evaluated under 3 scenarios. All experiments are conducted in a multi-target setting to reflect realistic scenarios where attackers seek to promote the video regarding multiple queries simultaneously. We also evaluated our attacks for defences and imperceptibility. Overall, ViPro surpasses other baselines by over 30/10/4% for white/grey/black-box settings on average. Our work highlights an overlooked vulnerability, provides a qualitative analysis on the upper/lower bound of our attacks, and offers insights into potential counterplays. Code will be publicly available at https://github.com/michaeltian108/ViPro.
[13.08.2025 08:17] Response: {
  "desc": "Эта статья представляет новый метод атаки на системы поиска видео по текстовому запросу, названный Video Promotion (ViPro). В отличие от существующих подходов, ViPro нацелен на продвижение видео к определенным запросам, а не на их подавление. Авторы предлагают технику Modal Refinement (MoRe) для улучшения переносимости атаки между различными моделями. Эксперименты показывают значительное превосходство ViPro над базовыми методами в различных сценариях атак.",
  "emoji": "🎥",
  "title": "ViPro: Новый метод атаки для продвижения видео в системах поиска"
}
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Video Promotion attack (ViPro) enhances the robustness of text-to-video retrieval (T2VR) by promoting videos towards selected queries, demonstrating significant improvements over existing baselines in various attack scenarios.  					AI-generated summary 				 Thanks to the development of cross-modal models, text-to-video retrieval (T2VR) is advancing rapidly, but its robustness remains largely unexamined. Existing attacks against T2VR are designed to push videos away from queries, i.e., suppressing the ranks of videos, while the attacks that pull videos towards selected queries, i.e., promoting the ranks of videos, remain largely unexplored. These attacks can be more impactful as attackers may gain more views/clicks for financial benefits and widespread (mis)information. To this end, we pioneer the first attack against T2VR to promote videos adversarially, dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement (MoRe) to capture the finer-grained, intricate interaction between visual and textual modalities to enhance black-box transferability. Comprehensive experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing datasets with over 10k videos, evaluated under 3 scenarios. All experiments are conducted in a multi-target setting to reflect realistic scenarios where attackers seek to promote the video regarding multiple queries simultaneously. We also evaluated our attacks for defences and imperceptibility. Overall, ViPro surpasses other baselines by over 30/10/4% for white/grey/black-box settings on average. Our work highlights an overlooked vulnerability, provides a qualitative analysis on the upper/lower bound of our attacks, and offers insights into potential counterplays. Code will be publicly available at https://github.com/michaeltian108/ViPro."

[13.08.2025 08:17] Response: ```python
['VIDEO', 'MULTIMODAL']
```
[13.08.2025 08:17] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The Video Promotion attack (ViPro) enhances the robustness of text-to-video retrieval (T2VR) by promoting videos towards selected queries, demonstrating significant improvements over existing baselines in various attack scenarios.  					AI-generated summary 				 Thanks to the development of cross-modal models, text-to-video retrieval (T2VR) is advancing rapidly, but its robustness remains largely unexamined. Existing attacks against T2VR are designed to push videos away from queries, i.e., suppressing the ranks of videos, while the attacks that pull videos towards selected queries, i.e., promoting the ranks of videos, remain largely unexplored. These attacks can be more impactful as attackers may gain more views/clicks for financial benefits and widespread (mis)information. To this end, we pioneer the first attack against T2VR to promote videos adversarially, dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement (MoRe) to capture the finer-grained, intricate interaction between visual and textual modalities to enhance black-box transferability. Comprehensive experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing datasets with over 10k videos, evaluated under 3 scenarios. All experiments are conducted in a multi-target setting to reflect realistic scenarios where attackers seek to promote the video regarding multiple queries simultaneously. We also evaluated our attacks for defences and imperceptibility. Overall, ViPro surpasses other baselines by over 30/10/4% for white/grey/black-box settings on average. Our work highlights an overlooked vulnerability, provides a qualitative analysis on the upper/lower bound of our attacks, and offers insights into potential counterplays. Code will be publicly available at https://github.com/michaeltian108/ViPro."

[13.08.2025 08:17] Response: ```python
["SECURITY"]
```
[13.08.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The Video Promotion attack (ViPro) introduces a novel approach to enhance the robustness of text-to-video retrieval (T2VR) systems by promoting videos towards specific queries. Unlike traditional attacks that aim to suppress video rankings, ViPro focuses on increasing the visibility of videos, which can lead to greater financial gains for attackers. The paper also presents Modal Refinement (MoRe), a technique that improves the interaction between visual and textual data, enhancing the effectiveness of the attack across different scenarios. Comprehensive experiments demonstrate that ViPro significantly outperforms existing methods, revealing a critical vulnerability in T2VR systems and suggesting avenues for future defenses.","title":"Promoting Videos: A New Threat to Text-to-Video Retrieval"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The Video Promotion attack (ViPro) introduces a novel approach to enhance the robustness of text-to-video retrieval (T2VR) systems by promoting videos towards specific queries. Unlike traditional attacks that aim to suppress video rankings, ViPro focuses on increasing the visibility of videos, which can lead to greater financial gains for attackers. The paper also presents Modal Refinement (MoRe), a technique that improves the interaction between visual and textual data, enhancing the effectiveness of the attack across different scenarios. Comprehensive experiments demonstrate that ViPro significantly outperforms existing methods, revealing a critical vulnerability in T2VR systems and suggesting avenues for future defenses.', title='Promoting Videos: A New Threat to Text-to-Video Retrieval'))
[13.08.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"视频推广攻击（ViPro）通过将视频向选定查询推广，增强了文本到视频检索（T2VR）的鲁棒性。与现有的攻击方法不同，ViPro专注于提升视频的排名，而不是将其压制。我们还提出了模态精炼（MoRe）方法，以捕捉视觉和文本模态之间更细致的交互，从而提高黑箱转移性。实验结果显示，ViPro在多种攻击场景下的表现优于现有基线，展示了这一领域被忽视的脆弱性。","title":"视频推广攻击：提升T2VR鲁棒性的创新方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='视频推广攻击（ViPro）通过将视频向选定查询推广，增强了文本到视频检索（T2VR）的鲁棒性。与现有的攻击方法不同，ViPro专注于提升视频的排名，而不是将其压制。我们还提出了模态精炼（MoRe）方法，以捕捉视觉和文本模态之间更细致的交互，从而提高黑箱转移性。实验结果显示，ViPro在多种攻击场景下的表现优于现有基线，展示了这一领域被忽视的脆弱性。', title='视频推广攻击：提升T2VR鲁棒性的创新方法'))
[13.08.2025 08:18] Using data from previous issue: {"categories": ["#dataset", "#multilingual", "#games", "#benchmark", "#open_source"], "emoji": "🖥️", "ru": {"title": "AutoCodeBench: автоматизированный многоязычный бенчмарк для оценки генерации кода ИИ", "desc": "AutoCodeGen представляет собой метод автоматического создания многоязычного бенчмарка 
[13.08.2025 08:18] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#benchmark", "#story_generation", "#dataset", "#architecture"], "emoji": "🎬", "ru": {"title": "Искусственный интеллект освоил профессиональный киномонтаж", "desc": "Cut2Next - это фреймворк для генерации высококачественных кинематографических кадров с использова
[13.08.2025 08:18] Querying the API.
[13.08.2025 08:18] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

OpenCUA is an open-source framework for vision-language models as computer-use agents, featuring an annotation infrastructure, a large-scale dataset, and a scalable pipeline that achieves state-of-the-art performance.  					AI-generated summary 				 Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.
[13.08.2025 08:18] Response: {
  "desc": "OpenCUA - это открытая инфраструктура для моделей компьютерного зрения и обработки естественного языка, действующих как агенты для использования компьютера. Она включает систему аннотирования, масштабный набор данных и расширяемый конвейер, достигающий передовых результатов. Фреймворк состоит из инструмента для записи действий человека на компьютере, датасета AgentNet с задачами для 3 операционных систем и более 200 приложений, а также pipeline для преобразования демонстраций в пары состояние-действие с рефлексивными рассуждениями. Модель OpenCUA-32B достигает нового уровня производительности среди открытых моделей на бенчмарке OSWorld-Verified.",
  "emoji": "🖥️",
  "title": "OpenCUA: открытая платформа для создания ИИ-ассистентов нового поколения"
}
[13.08.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"OpenCUA is an open-source framework for vision-language models as computer-use agents, featuring an annotation infrastructure, a large-scale dataset, and a scalable pipeline that achieves state-of-the-art performance.  					AI-generated summary 				 Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research."

[13.08.2025 08:18] Response: ```python
['DATASET', 'AGENTS', 'MULTIMODAL', 'BENCHMARK']
```
[13.08.2025 08:18] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"OpenCUA is an open-source framework for vision-language models as computer-use agents, featuring an annotation infrastructure, a large-scale dataset, and a scalable pipeline that achieves state-of-the-art performance.  					AI-generated summary 				 Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research."

[13.08.2025 08:18] Response: ```python
['OPEN_SOURCE', 'AGI', 'REASONING']
```
[13.08.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OpenCUA is an innovative open-source framework designed for vision-language models that function as computer-use agents (CUAs). It includes a robust annotation infrastructure, a large-scale dataset called AgentNet, and a scalable pipeline that enhances performance through reflective reasoning. The framework allows researchers to access and study the capabilities and limitations of CUAs, which are becoming increasingly important in automating digital tasks. With state-of-the-art results, OpenCUA-32B sets a new benchmark in the field, promoting further research and development in open CUA systems.","title":"Empowering Research with OpenCUA: The Future of Computer-Use Agents"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='OpenCUA is an innovative open-source framework designed for vision-language models that function as computer-use agents (CUAs). It includes a robust annotation infrastructure, a large-scale dataset called AgentNet, and a scalable pipeline that enhances performance through reflective reasoning. The framework allows researchers to access and study the capabilities and limitations of CUAs, which are becoming increasingly important in automating digital tasks. With state-of-the-art results, OpenCUA-32B sets a new benchmark in the field, promoting further research and development in open CUA systems.', title='Empowering Research with OpenCUA: The Future of Computer-Use Agents'))
[13.08.2025 08:18] Response: ParsedChatCompletionMessage[Article](content='{"desc":"OpenCUA是一个开源框架，专为视觉-语言模型作为计算机使用代理而设计。它提供了一个注释基础设施、大规模数据集和可扩展的管道，能够实现最先进的性能。该框架包括捕捉人类计算机使用演示的注释工具，以及涵盖多个操作系统和应用程序的大规模计算机使用任务数据集。我们的研究表明，OpenCUA在多个基准测试中表现出色，推动了开放源代码模型的发展。","title":"开放源代码，推动计算机使用代理的未来"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='OpenCUA是一个开源框架，专为视觉-语言模型作为计算机使用代理而设计。它提供了一个注释基础设施、大规模数据集和可扩展的管道，能够实现最先进的性能。该框架包括捕捉人类计算机使用演示的注释工具，以及涵盖多个操作系统和应用程序的大规模计算机使用任务数据集。我们的研究表明，OpenCUA在多个基准测试中表现出色，推动了开放源代码模型的发展。', title='开放源代码，推动计算机使用代理的未来'))
[13.08.2025 08:18] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#rl"], "emoji": "🛠️", "ru": {"title": "Автоматизация обучения LLM эффективному использованию инструментов", "desc": "Предложена автоматизированная система для создания обучающих сред и механизма проверяемого вознаграждения, улучшающая спос
[13.08.2025 08:18] Using data from previous issue: {"categories": ["#agents", "#games", "#optimization", "#math"], "emoji": "🎮", "ru": {"title": "Квантовая теория игр побеждает шум: эксперимент на IBM Quantum", "desc": "В этой статье представлена одна из первых полных экспериментальных реализаций квантовой теории игр на реальном квантовом оборудован
[13.08.2025 08:18] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#data", "#audio"], "emoji": "🗣️", "ru": {"title": "Единая система распознавания и синтеза паралингвистических сигналов в речи", "desc": "NVSpeech - это комплексный конвейер для распознавания и синтеза паралингвистических вокализаций в мандаринском китайск
[13.08.2025 08:18] Renaming data file.
[13.08.2025 08:18] Renaming previous data. hf_papers.json to ./d/2025-08-13.json
[13.08.2025 08:18] Saving new data file.
[13.08.2025 08:18] Generating page.
[13.08.2025 08:18] Renaming previous page.
[13.08.2025 08:18] Renaming previous data. index.html to ./d/2025-08-13.html
[13.08.2025 08:18] Writing result.
[13.08.2025 08:18] Renaming log file.
[13.08.2025 08:18] Renaming previous data. log.txt to ./logs/2025-08-13_last_log.txt
