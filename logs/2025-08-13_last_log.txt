[13.08.2025 16:12] Read previous papers.
[13.08.2025 16:12] Generating top page (month).
[13.08.2025 16:12] Writing top page (month).
[13.08.2025 17:09] Read previous papers.
[13.08.2025 17:09] Get feed.
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05748
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08086
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07976
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07409
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08088
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09138
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05615
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09062
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08940
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08665
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05399
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.07485
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08896
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06964
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08244
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08938
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08791
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09101
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09125
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09123
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09050
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08680
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.08855
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06813
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06485
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05813
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04676
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05769
[13.08.2025 17:09] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04195
[13.08.2025 17:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[13.08.2025 17:09] No deleted papers detected.
[13.08.2025 17:09] Downloading and parsing papers (pdf, html). Total: 29.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.05748.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.05748.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.05748.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08086.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08086.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08086.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.07976.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.07976.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.07976.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.07409.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.07409.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.07409.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08088.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08088.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08088.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.09138.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.09138.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.09138.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.05615.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.05615.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.05615.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.09062.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.09062.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.09062.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08940.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08940.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08940.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08665.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08665.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08665.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.05399.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.05399.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.05399.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.07485.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.07485.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.07485.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08896.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08896.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08896.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.06964.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.06964.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.06964.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08244.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08244.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08244.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08938.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08938.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08938.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08791.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08791.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08791.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.09101.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.09101.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.09101.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.09125.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.09125.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.09125.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.09123.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.09123.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.09123.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.09050.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.09050.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.09050.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08680.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08680.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08680.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.08855.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.08855.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.08855.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.06813.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.06813.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.06813.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.06485.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.06485.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.06485.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.05813.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.05813.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.05813.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.04676.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.04676.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.04676.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.05769.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.05769.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.05769.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Downloading and parsing paper https://huggingface.co/papers/2508.04195.
[13.08.2025 17:09] Extra JSON file exists (./assets/json/2508.04195.json), skip PDF parsing.
[13.08.2025 17:09] Paper image links file exists (./assets/img_data/2508.04195.json), skip HTML parsing.
[13.08.2025 17:09] Success.
[13.08.2025 17:09] Enriching papers with extra data.
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 0. WebWatcher, a multimodal agent with enhanced visual-language reasoning, outperforms existing agents in complex visual and textual information retrieval tasks using synthetic trajectories and reinforcement learning.  					AI-generated summary 				 Web agents such as Deep Research have demonstrated su...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 1. Matrix-3D generates wide-coverage 3D worlds from single images or text using panoramic video diffusion and reconstruction models.  					AI-generated summary 				 Explorable 3D world generation from a single image or text prompt forms a cornerstone of spatial intelligence. Recent works utilize video ...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 2. ASearcher is an open-source project that uses scalable asynchronous RL training to enhance search agents, achieving high performance on QA tasks with long-horizon search capabilities.  					AI-generated summary 				 Recent advancements in LLM-based agents have demonstrated remarkable capabilities in...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 3. CharacterShot is a 4D character animation framework that uses a DiT-based model and dual-attention module to generate consistent 3D animations from a single image and 2D pose sequence.  					AI-generated summary 				 In this paper, we propose CharacterShot, a controllable and consistent 4D character...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 4. HierSearch, a hierarchical agentic deep search framework using hierarchical RL, improves performance in multi-source retrieval tasks by coordinating local and Web search agents and refining knowledge.  					AI-generated summary 				 Recently, large reasoning models have demonstrated strong mathemati...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 5. Two methods, Temporal Self-Consistency Voting and Temporal Consistency Reinforcement, improve diffusion large language models by leveraging temporal consistency in intermediate predictions.  					AI-generated summary 				 Diffusion large language models (dLLMs) generate text through iterative denois...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 6. GUI-RC and GUI-RCPO enhance GUI grounding accuracy by leveraging spatial consistency and reinforcement learning without additional training data.  					AI-generated summary 				 Graphical User Interface (GUI) grounding, the task of mapping natural language instructions to precise screen coordinates,...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 7. VertexRegen generates meshes with continuous detail by reversing edge collapse through a generative model, offering anytime generation and flexibility in detail levels.  					AI-generated summary 				 We introduce VertexRegen, a novel mesh generation framework that enables generation at a continuous...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 8. A curriculum learning strategy using Group Relative Policy Optimization (GRPO) enhances the reasoning abilities of large language models by progressively tightening token budgets, improving accuracy and token efficiency.  					AI-generated summary 				 Recent work on enhancing the reasoning abilitie...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 9. Aryabhata 1.0, a compact math reasoning model, outperforms existing models on educational exams and benchmarks by using supervised fine-tuning, reinforcement learning with verifiable rewards, and novel exploration strategies.  					AI-generated summary 				 We present Aryabhata 1.0, a compact 7B par...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 10. UNCAGE, a training-free method using contrastive attention guidance, enhances compositional fidelity in text-to-image generation by prioritizing the unmasking of object-representing tokens.  					AI-generated summary 				 Text-to-image (T2I) generation has been actively studied using Diffusion Model...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 11. An evaluation harness allows large language models to play Diplomacy without fine-tuning, providing insights into their strategic reasoning capabilities.  					AI-generated summary 				 We present the first evaluation harness that enables any out-of-the-box, local, Large Language Models (LLMs) to pl...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 12. AffordDex is a two-stage framework that learns a universal grasping policy with motion priors and object affordances, outperforming state-of-the-art methods in dexterous grasping and human-like postures.  					AI-generated summary 				 A dexterous hand capable of generalizable grasping objects is fu...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 13. The Video Promotion attack (ViPro) enhances the robustness of text-to-video retrieval (T2VR) by promoting videos towards selected queries, demonstrating significant improvements over existing baselines in various attack scenarios.  					AI-generated summary 				 Thanks to the development of cross-mo...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 14. Cut2Next, a framework using a Diffusion Transformer with in-context tuning and hierarchical prompting, generates high-quality, cinematically coherent shots that adhere to professional editing patterns.  					AI-generated summary 				 Effective multi-shot generation demands purposeful, film-like tran...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 15. Decoder-Centric Regularization in Encoder-Decoder (DeCRED) improves ASR robustness and generalization by adding auxiliary classifiers to the decoder, reducing internal language model perplexity and WER.  					AI-generated summary 				 This paper presents a simple yet effective regularization for the...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 16. An automated pipeline for constructing training environments and a verifiable reward mechanism enhance large language models' tool-use performance without compromising general capabilities.  					AI-generated summary 				 Effective tool use is essential for large language models (LLMs) to interact m...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 17. AutoCodeGen creates a large-scale, multilingual code generation benchmark, AutoCodeBench, to evaluate LLMs on diverse and complex tasks without manual annotations.  					AI-generated summary 				 Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, with code...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 18. LogicIFGen and LogicIFEval assess the instruction-following capabilities of LLMs on complex, logic-rich instructions, revealing significant performance gaps.  					AI-generated summary 				 Instruction following has catalyzed the recent era of Large Language Models (LLMs) and is the foundational ski...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 19. OpenCUA is an open-source framework for vision-language models as computer-use agents, featuring an annotation infrastructure, a large-scale dataset, and a scalable pipeline that achieves state-of-the-art performance.  					AI-generated summary 				 Vision-language models have demonstrated impressiv...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 20. Quantum game theory demonstrated on IBM Quantum hardware using the Eisert-Wilkens-Lewenstein framework shows persistent quantum advantages in strategic coordination despite noise and decoherence.  					AI-generated summary 				 Implementing quantum game theory on real hardware is challenging due to ...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 21. TopXGen uses LLMs to generate high-quality, topic-diverse target-side texts for LRLs, which can be backtranslated to improve translation performance in ICL and fine-tuning.  					AI-generated summary 				 LLMs have been shown to perform well in machine translation (MT) with the use of in-context lea...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 22. BiasGym is a framework for injecting, analyzing, and mitigating biases in Large Language Models through token-based fine-tuning and signal analysis.  					AI-generated summary 				 Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing e...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 23. A comprehensive approach is presented for adapting large language models to the Q programming language, achieving superior performance compared to existing models on a newly created benchmark dataset.  					AI-generated summary 				 Even though large language models are becoming increasingly capable...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 24. WGAST, a weakly-supervised generative network, enhances daily 10 m land surface temperature estimation using spatio-temporal fusion of Terra MODIS, Landsat 8, and Sentinel-2 data.  					AI-generated summary 				 Urbanization, climate change, and agricultural stress are increasing the demand for prec...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 25. A novel method for style transfer of 3D Gaussian splats involves generating a graph structure and using a feed-forward, surface-based stylization technique without reconstruction or optimization.  					AI-generated summary 				 The task of style transfer for 3D Gaussian splats has been explored in m...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 26. General Sample Replay (GeRe) framework with threshold-based margin (TM) loss addresses catastrophic forgetting in large language models by maintaining activation state consistency during replay learning.  					AI-generated summary 				 The continual learning capability of large language models (LLMs...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 27. A partial-convolution-based style transfer network improves stylization of specific image regions by accurately applying style features and using network-internal blending techniques.  					AI-generated summary 				 Artistic style transfer has long been possible with the advancements of convolution-...
[13.08.2025 17:09] ********************************************************************************
[13.08.2025 17:09] Abstract 28. NVSpeech is a pipeline that integrates the recognition and synthesis of paralinguistic vocalizations in Mandarin, using a large annotated dataset and models that treat these cues as decodable tokens.  					AI-generated summary 				 Paralinguistic vocalizations-including non-verbal sounds like laught...
[13.08.2025 17:09] Read previous papers.
[13.08.2025 17:09] Generating reviews via LLM API.
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#reasoning", "#synthetic", "#multimodal", "#agents", "#rl", "#benchmark", "#open_source"], "emoji": "üïµÔ∏è", "ru": {"title": "WebWatcher: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "WebWatcher - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –≤
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#dataset", "#diffusion", "#3d", "#synthetic"], "emoji": "üåê", "ru": {"title": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å—Å–ª–µ–¥—É–µ–º—ã—Ö 3D-–º–∏—Ä–æ–≤ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞", "desc": "Matrix-3D - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å—Å–ª–µ–¥—É–µ–º—ã—Ö —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –º–∏—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#dataset", "#training", "#agents", "#rl", "#long_context", "#open_source"], "emoji": "üîç", "ru": {"title": "ASearcher: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "ASearcher - —ç—Ç–æ –ø—Ä–æ–µ–∫—Ç —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#3d", "#optimization", "#open_source"], "emoji": "üé≠", "ru": {"title": "–û–∂–∏–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ 3D –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", "desc": "CharacterShot - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è 4D-–∞–Ω–∏–º–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ DiT –∏ –º–æ–¥—É–ª—å –¥–≤–æ–π–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è. –û–Ω –ø–æ–∑–≤
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#hallucinations", "#rag", "#reasoning", "#agents", "#benchmark", "#rl", "#healthcare"], "emoji": "üîç", "ru": {"title": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–Ω–æ–≥–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "HierSearch - —ç—Ç–æ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞, –∏—Å–ø–æ–ª—å–∑—É—é
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#benchmark", "#rl"], "emoji": "‚è≥", "ru": {"title": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–∞ –º–µ—Ç–æ–¥–∞ —É–ª—É—á—à–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (dLLM): –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–∞
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#inference", "#optimization", "#agents", "#rlhf", "#rl"], "emoji": "üñ•Ô∏è", "ru": {"title": "–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è GUI –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –º–µ—Ç–æ–¥—ã GUI-RC –∏ GUI-RCPO –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏–≤—è–∑–∫–∏ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#games", "#optimization", "#3d"], "emoji": "üîç", "ru": {"title": "–ì–∏–±–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 3D-—Å–µ—Ç–æ–∫ —Å –ª—é–±—ã–º —É—Ä–æ–≤–Ω–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏", "desc": "VertexRegen - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö —Å–µ—Ç–æ–∫ —Å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º —É—Ä–æ–≤–Ω–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Å—Ö–ª–æ–ø—ã–≤–∞–Ω–∏—è —Ä–µ–±–µ—Ä, –æ–±—É—á–∞–µ–º—ã
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#reasoning", "#rlhf", "#optimization", "#training", "#math"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —Å–∂–∞—Ç–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º, –∏—Å–ø–æ–ª—å–∑—É—é—â—É—é Group Relative Policy Optimization (
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#small_models", "#dataset", "#reasoning", "#training", "#open_source", "#rl", "#math"], "emoji": "üßÆ", "ru": {"title": "–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –ò–ò-–º–æ–¥–µ–ª—å –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –∞–Ω–∞–ª–æ–≥–∏ –≤ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å Aryabhata 1.0 - –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö 
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#training", "#optimization", "#diffusion", "#benchmark", "#cv"], "emoji": "üé≠", "ru": {"title": "–¢–æ—á–Ω–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ —É–º–Ω–æ–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–æ–∫–µ–Ω–æ–≤", "desc": "UNCAGE - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —É–ª—É—á—à–∞—é—â–∏–π –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#games", "#benchmark", "#rl", "#reasoning", "#open_source"], "emoji": "üé≠", "ru": {"title": "–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ LLM: –∏–≥—Ä–∞ –≤ Diplomacy –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏, –ø–æ–∑–≤–æ–ª—è—é—â—É—é –±–æ–ª—å—à–∏–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º (LLM) –∏–≥—Ä–∞—Ç—å –≤ Diplomacy –±–µ–∑
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#agents", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞—Ö–≤–∞—Ç —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–æ–≤", "desc": "AffordDex - —ç—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏ –∑–∞—Ö–≤–∞—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏–æ—Ä–æ–≤ –¥–≤–∏–∂–µ–Ω–∏—è –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–æ–≤. –ù–∞ –ø
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#multimodal", "#security", "#video"], "emoji": "üé•", "ru": {"title": "ViPro: –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞—Ç–∞–∫–∏ –¥–ª—è –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö –ø–æ–∏—Å–∫–∞", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞—Ç–∞–∫–∏ –Ω–∞ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –≤–∏–¥–µ–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É, –Ω–∞–∑–≤–∞–Ω–Ω—ã–π Video Promotion (ViPro). –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#cv", "#diffusion", "#benchmark", "#story_generation", "#dataset", "#architecture"], "emoji": "üé¨", "ru": {"title": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –æ—Å–≤–æ–∏–ª –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–∏–Ω–æ–º–æ–Ω—Ç–∞–∂", "desc": "Cut2Next - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∫–∞–¥—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#audio", "#training", "#optimization"], "emoji": "üéôÔ∏è", "ru": {"title": "DeCRED: –ü–æ–≤—ã—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –¥–µ–∫–æ–¥–µ—Ä–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (ASR) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º DeCRED. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ 
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#training", "#reasoning", "#optimization", "#rl"], "emoji": "üõ†Ô∏è", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è LLM —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤", "desc": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—É—á–∞—é—â–∏—Ö —Å—Ä–µ–¥ –∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–≥–æ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, —É–ª—É—á—à–∞—é—â–∞—è —Å–ø–æ—Å
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#dataset", "#multilingual", "#games", "#benchmark", "#open_source"], "emoji": "üñ•Ô∏è", "ru": {"title": "AutoCodeBench: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –ò–ò", "desc": "AutoCodeGen –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞ 
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#benchmark", "#dataset", "#reasoning"], "emoji": "üß†", "ru": {"title": "–õ–æ–≥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ - –∞—Ö–∏–ª–ª–µ—Å–æ–≤–∞ –ø—è—Ç–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "LogicIFGen –∏ LogicIFEval - —ç—Ç–æ –Ω–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–ª–µ–¥–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–º –ª–æ–≥–∏—á–µ—Å–∫–∏–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º. LogicIFGen –∞–≤—Ç–æ
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#agents", "#dataset", "#reasoning", "#multimodal", "#agi", "#benchmark", "#open_source"], "emoji": "üñ•Ô∏è", "ru": {"title": "OpenCUA: –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "OpenCUA - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#agents", "#games", "#optimization", "#math"], "emoji": "üéÆ", "ru": {"title": "–ö–≤–∞–Ω—Ç–æ–≤–∞—è —Ç–µ–æ—Ä–∏—è –∏–≥—Ä –ø–æ–±–µ–∂–¥–∞–µ—Ç —à—É–º: —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–∞ IBM Quantum", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –æ–¥–Ω–∞ –∏–∑ –ø–µ—Ä–≤—ã—Ö –ø–æ–ª–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ç–µ–æ—Ä–∏–∏ –∏–≥—Ä –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –∫–≤–∞–Ω—Ç–æ–≤–æ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#multilingual", "#machine_translation", "#training", "#low_resource", "#synthetic", "#dataset"], "emoji": "üåê", "ru": {"title": "TopXGen: –ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –º–∞–ª–æ—Ä–µ—Å—É—Ä—Å–Ω—ã—Ö —è–∑—ã–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM", "desc": "TopXGen - —ç—Ç–æ –ø–æ–¥—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –¥–ª—è
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#data", "#interpretability", "#training", "#ethics"], "emoji": "üß†", "ru": {"title": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—è–º–∏ –≤ LLM: –∏–Ω—ä–µ–∫—Ü–∏–∏, –∞–Ω–∞–ª–∏–∑ –∏ —Å–º—è–≥—á–µ–Ω–∏–µ", "desc": "BiasGym - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è, –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–º—è–≥—á–µ–Ω–∏—è –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–µ–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM) —Å –ø–æ–º–æ—â—å—é —Ç–æ–∫–µ–Ω-–æ—Ä–∏
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#reasoning", "#plp", "#dataset", "#open_source", "#training", "#benchmark", "#transfer_learning", "#rl"], "emoji": "üìä", "ru": {"title": "–ê–¥–∞–ø—Ç–∞—Ü–∏—è LLM –¥–ª—è –Ω–∏—à–µ–≤—ã—Ö —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: –ø—Ä–æ—Ä—ã–≤ –≤ Q", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM)
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#dataset", "#data", "#synthetic", "#optimization", "#cv", "#training", "#science"], "emoji": "üõ∞Ô∏è", "ru": {"title": "–ü—Ä–æ—Ä—ã–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ü–µ–Ω–∫–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –ó–µ–º–ª–∏", "desc": "WGAST - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å–æ —Å–ª–∞–±—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –∑–µ–º–ª–∏ 
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#graphs", "#open_source", "#games", "#3d"], "emoji": "üé®", "ru": {"title": "–ë—ã—Å—Ç—Ä–∞—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è 3D –≥–∞—É—Å—Å–æ–≤—ã—Ö —Å–ø–ª–∞—Ç–æ–≤ –±–µ–∑ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç–∏–ª—è –¥–ª—è 3D –≥–∞—É—Å—Å–æ–≤—ã—Ö —Å–ø–ª–∞—Ç–æ–≤. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø–æ–¥—Ö–æ–¥, –Ω–µ —Ç—Ä–µ–±—É—é—â–∏–π —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#agi", "#training", "#optimization"], "emoji": "üß†", "ru": {"title": "GeRe: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∑–∞–±—ã–≤—á–∏–≤–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ General Sample Replay (GeRe) –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–æ–π –∑–∞–±—ã–≤—á–∏–≤–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#optimization", "#dataset", "#cv", "#open_source"], "emoji": "üé®", "ru": {"title": "–¢–æ—á–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç–∏–ª—è –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–µ—Ä–µ–Ω–æ—Å—É —Å—Ç–∏–ª—è –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–≤—ë—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å
[13.08.2025 17:09] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#data", "#audio"], "emoji": "üó£Ô∏è", "ru": {"title": "–ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ —Å–∏–Ω—Ç–µ–∑–∞ –ø–∞—Ä–∞–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ —Ä–µ—á–∏", "desc": "NVSpeech - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ —Å–∏–Ω—Ç–µ–∑–∞ –ø–∞—Ä–∞–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–∫–∞–ª–∏–∑–∞—Ü–∏–π –≤ –º–∞–Ω–¥–∞—Ä–∏–Ω—Å–∫–æ–º –∫–∏—Ç–∞–π—Å–∫
[13.08.2025 17:09] Renaming data file.
[13.08.2025 17:09] Renaming previous data. hf_papers.json to ./d/2025-08-13.json
[13.08.2025 17:09] Saving new data file.
[13.08.2025 17:09] Generating page.
[13.08.2025 17:09] Renaming previous page.
[13.08.2025 17:09] Renaming previous data. index.html to ./d/2025-08-13.html
[13.08.2025 17:09] Writing result.
[13.08.2025 17:09] Renaming log file.
[13.08.2025 17:09] Renaming previous data. log.txt to ./logs/2025-08-13_last_log.txt
