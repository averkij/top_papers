[03.09.2025 09:14] Read previous papers.
[03.09.2025 09:14] Generating top page (month).
[03.09.2025 09:14] Writing top page (month).
[03.09.2025 10:11] Read previous papers.
[03.09.2025 10:11] Get feed.
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02479
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02547
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02544
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00676
[03.09.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.21496
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01215
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01055
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02208
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01563
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02522
[03.09.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2509.02333
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01363
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02460
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02534
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01644
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01360
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02040
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00425
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01440
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00244
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02046
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01052
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01984
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00531
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02379
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.02133
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01610
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01584
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.01250
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00581
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00578
[03.09.2025 10:11] Get page data from previous paper. URL: https://huggingface.co/papers/2509.00404
[03.09.2025 10:11] Extract page data from URL. URL: https://huggingface.co/papers/2508.20586
[03.09.2025 10:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.09.2025 10:11] No deleted papers detected.
[03.09.2025 10:11] Downloading and parsing papers (pdf, html). Total: 33.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.02479.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.02479.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.02479.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.02547.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.02547.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.02547.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.02544.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.02544.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.02544.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.00676.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.00676.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.00676.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2508.21496.
[03.09.2025 10:11] Downloading paper 2508.21496 from http://arxiv.org/pdf/2508.21496v2...
[03.09.2025 10:11] Extracting affiliations from text.
[03.09.2025 10:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding Hao Lu*, Jiahao Wang*, Yaolun Zhang, Ruohui Wang, Xuanyu Zheng, Yepeng Tang, Dahua Lin and Lewei Lu SenseTime Research 5 2 0 2 2 ] . [ 2 6 9 4 1 2 . 8 0 5 2 : r a "
[03.09.2025 10:11] Response: ```python
["SenseTime Research"]
```
[03.09.2025 10:11] Deleting PDF ./assets/pdf/2508.21496.pdf.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.01215.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.01215.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.01215.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.01055.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.01055.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.01055.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.02208.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.02208.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.02208.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.01563.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.01563.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.01563.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.02522.
[03.09.2025 10:11] Extra JSON file exists (./assets/json/2509.02522.json), skip PDF parsing.
[03.09.2025 10:11] Paper image links file exists (./assets/img_data/2509.02522.json), skip HTML parsing.
[03.09.2025 10:11] Success.
[03.09.2025 10:11] Downloading and parsing paper https://huggingface.co/papers/2509.02333.
[03.09.2025 10:11] Downloading paper 2509.02333 from http://arxiv.org/pdf/2509.02333v1...
[03.09.2025 10:12] Extracting affiliations from text.
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 2 ] . [ 1 3 3 3 2 0 . 9 0 5 2 : r DCPO: Dynamic Clipping Policy Optimization DCPO: DYNAMIC CLIPPING POLICY OPTIMIZATION Shihui Yang, Chengfeng Dou, Peidong Guo, Kai Lu Qiang Ju, Fei Deng, Rihui Xin Baichuan.inc yangshihui@baichuan-inc.com https://github.com/lime-RL/DCPO "
[03.09.2025 10:12] Response: ```python
["Baichuan.inc"]
```
[03.09.2025 10:12] Deleting PDF ./assets/pdf/2509.02333.pdf.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01363.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01363.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01363.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.02460.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.02460.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.02460.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.02534.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.02534.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.02534.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01644.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01644.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01644.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01360.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01360.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01360.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.02040.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.02040.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.02040.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.00425.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.00425.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.00425.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01440.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01440.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01440.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.00244.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.00244.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.00244.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.02046.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.02046.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.02046.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01052.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01052.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01052.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01984.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01984.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01984.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.00531.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.00531.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.00531.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.02379.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.02379.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.02379.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.02133.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.02133.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.02133.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01610.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01610.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01610.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01584.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01584.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01584.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.01250.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.01250.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.01250.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.00581.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.00581.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.00581.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.00578.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.00578.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.00578.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2509.00404.
[03.09.2025 10:12] Extra JSON file exists (./assets/json/2509.00404.json), skip PDF parsing.
[03.09.2025 10:12] Paper image links file exists (./assets/img_data/2509.00404.json), skip HTML parsing.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Downloading and parsing paper https://huggingface.co/papers/2508.20586.
[03.09.2025 10:12] Downloading paper 2508.20586 from http://arxiv.org/pdf/2508.20586v1...
[03.09.2025 10:12] Extracting affiliations from text.
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 2 ] . [ 1 6 8 5 0 2 . 8 0 5 2 : r FASTFIT: ACCELERATING MULTI-REFERENCE VIRTUAL TRY-ON VIA CACHEABLE DIFFUSION MODELS Zheng Chong1,2,3, Yanwei Lei1, Shiyue Zhang1, Zhuandi He1, Zhen Wang1, Xujie Zhang1, Xiao Dong1, Yiling Wu3, Dongmei Jiang3 & Xiaodan Liang1,3 1Sun Yat-sen University 2LavieAI {chongzheng98,dx.icandoti,xdliang328}@gmail.com, {leiyw5,zhangshy223,zhuandihe86,wangzh669,zhangxj59}@mail2.sysu.edu.cn, {wuyl02,jiangdm}@pcl.ac.cn 3Pengcheng Laboratory Figure 1: FastFit provides unified and accelerated solution for diverse virtual try-on tasks, including single-reference, person-to-person, and our primary focus, multi-reference composition. By decoupling the reference images from the denoising process, our cacheable diffusion architecture delivers high-fidelity virtual try-on across multiple challenging scenarios at much faster speed. "
[03.09.2025 10:12] Response: ```python
["Sun Yat-sen University", "LavieAI", "Pengcheng Laboratory"]
```
[03.09.2025 10:12] Deleting PDF ./assets/pdf/2508.20586.pdf.
[03.09.2025 10:12] Success.
[03.09.2025 10:12] Enriching papers with extra data.
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 0. SimpleTIR stabilizes multi-turn Tool-Integrated Reasoning training by filtering out void turns, achieving state-of-the-art performance on math reasoning benchmarks.  					AI-generated summary 				 Large Language Models (LLMs) can significantly improve their reasoning capabilities by interacting with...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 1. Agentic reinforcement learning transforms large language models into autonomous decision-making agents by leveraging temporally extended POMDPs, enhancing capabilities like planning and reasoning through reinforcement learning.  					AI-generated summary 				 The emergence of agentic reinforcement l...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 2. UI-TARS-2, a native GUI-centered agent model, addresses challenges in data scalability, multi-turn reinforcement learning, and environment stability, achieving significant improvements over its predecessor and strong baselines across various benchmarks.  					AI-generated summary 				 The developmen...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 3. Reinforcement learning on preference-labeled critic datasets enhances a generative model's performance, creating a unified multimodal system that excels in both evaluation and generation.  					AI-generated summary 				 In vision-language modeling, critic models are typically trained to evaluate out...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 4. A benchmark for long-video hallucination identifies and investigates Semantic Aggregation Hallucination (SAH), showing its prevalence in complex and rapidly changing semantic contexts, and proposes strategies to mitigate it.  					AI-generated summary 				 Video multimodal large language models (Vid...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 5. A framework for constructing high-quality document extraction datasets and models through synthetic data generation and iterative self-improvement outperforms existing models.  					AI-generated summary 				 High-quality labeled data is essential for training accurate document conversion models, par...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 6. VerlTool is a unified and modular framework for Agentic Reinforcement Learning with Tool use, addressing inefficiencies in existing approaches and providing competitive performance across multiple domains.  					AI-generated summary 				 Reinforcement Learning with Verifiable Rewards (RLVR) has demo...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 7. A dynamic verification framework using reinforcement learning and a novel algorithm improves the performance of a large medical language model in real-world clinical decision-making.  					AI-generated summary 				 As large language models (LLMs) advance in conversational and reasoning capabilities,...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 8. Keye-VL-1.5 enhances video understanding through a Slow-Fast encoding strategy, progressive pre-training, and post-training reasoning improvements, outperforming existing models on video tasks while maintaining general multimodal performance.  					AI-generated summary 				 In recent years, the deve...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 9. PACS, a novel RLVR framework, reformulates RLVR as a supervised learning task, improving stability and efficiency in training large language models for reasoning tasks.  					AI-generated summary 				 Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have empowered large langu...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 10. DCPO, a novel reinforcement learning framework, enhances large language models by dynamically adjusting clipping bounds and standardizing rewards, leading to improved performance and efficiency.  					AI-generated summary 				 Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a pr...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 11. Reasoning capabilities from reinforcement learning can be extracted as a task vector and transferred to other models to improve performance on diverse benchmarks.  					AI-generated summary 				 Large language models often require costly optimization, such as reinforcement learning, to master comple...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 12. A novel Diffusion Transformer pipeline automates video compositing by adaptively injecting identity and motion information, maintaining consistency and enabling user customization.  					AI-generated summary 				 Video compositing combines live-action footage to create video production, serving as a...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 13. DARLING, a diversity-aware reinforcement learning framework, enhances both the quality and diversity of large language model outputs across various tasks.  					AI-generated summary 				 Post-training of Large Language Models (LMs) often prioritizes accuracy and helpfulness at the expense of diversi...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 14. OpenVision 2 simplifies the original architecture by removing the text encoder and contrastive loss, achieving competitive performance with reduced training time and memory usage, and enabling scaling to over 1 billion parameters.  					AI-generated summary 				 This paper provides a simplification ...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 15. M3Ret, a unified visual encoder trained on a large-scale hybrid-modality dataset, achieves state-of-the-art zero-shot image-to-image retrieval and cross-modal alignment using generative and contrastive self-supervised learning paradigms.  					AI-generated summary 				 Medical image retrieval is ess...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 16. Genetic Prompt enhances synthetic data quality and diversity in NLP by combining genetic algorithms with LLMs, improving downstream model performance.  					AI-generated summary 				 Large Language Models (LLMs) excel at generating synthetic data, but ensuring its quality and diversity remains chall...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 17. Camlang, a constructed language, is used to evaluate whether LLMs can master unfamiliar languages through metalinguistic reasoning, revealing that current models lack systematic grammatical mastery compared to humans.  					AI-generated summary 				 Large Language Models (LLMs) achieve gold-medal pe...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 18. A comprehensive evaluation of recent optimization techniques for Large Language Models provides guidance on selecting the best optimizer for different pretraining scenarios.  					AI-generated summary 				 The recent development of Large Language Models (LLMs) has been accompanied by an effervescenc...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 19. Universal Deep Research (UDR) is a flexible system that allows users to customize deep research strategies using any language model without additional training or fine-tuning.  					AI-generated summary 				 Deep research tools are among the most impactful and most commonly encountered agentic syste...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 20. A systematic study reveals that fair comparisons of deep learning optimizers require rigorous hyperparameter tuning and evaluations across various model scales and data-to-model ratios, showing that matrix-based optimizers like Muon and Soap offer diminishing speedups as model size increases.  					...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 21. FlashAdventure benchmark and COAST framework improve GUI agents' performance in completing full story arcs in Flash-based adventure games by addressing the observation-behavior gap.  					AI-generated summary 				 GUI agents powered by LLMs show promise in interacting with diverse digital environmen...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 22. VARIN, a noise inversion-based editing technique for visual autoregressive models, enables precise image editing aligned with textual prompts while preserving original details.  					AI-generated summary 				 Visual autoregressive models (VAR) have recently emerged as a promising class of generative...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 23. MobiAgent, a comprehensive mobile agent system, achieves state-of-the-art performance in real-world mobile scenarios through its MobiMind-series models, AgentRR framework, and MobiFlow benchmarking suite, while also reducing data annotation costs.  					AI-generated summary 				 With the rapid advan...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 24. MedDINOv3, a framework adapting DINOv3 with multi-scale token aggregation, achieves state-of-the-art performance in medical image segmentation by overcoming challenges in domain adaptation and backbone performance.  					AI-generated summary 				 Accurate segmentation of organs and tumors in CT and ...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 25. Ambekar framework uses a Constitution-Aware Decoding Layer to mitigate caste and religious biases in LLM outputs through speculative decoding without retraining.  					AI-generated summary 				 Large Language Models (LLMs) can inadvertently reflect societal biases present in their training data, lea...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 26. A Panel-of-Peers learning framework enhances Large Vision and Language Models by simulating peer reviews, improving performance without extensive human-labeled datasets.  					AI-generated summary 				 Traditional alignment methods for Large Vision and Language Models (LVLMs) primarily rely on human...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 27. ViSTA-SLAM is a real-time monocular SLAM system that uses a lightweight STA model for pose estimation and pointmap regression, and a Sim(3) pose graph for drift correction, achieving superior tracking and reconstruction.  					AI-generated summary 				 We present ViSTA-SLAM as a real-time monocular ...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 28. Point-PQAE, a two-view cross-reconstruction generative paradigm, enhances 3D self-supervised learning by introducing greater diversity and variance, outperforming single-view methods in point cloud reconstruction tasks.  					AI-generated summary 				 Point cloud learning, especially in a self-super...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 29. A multi-agent framework decomposes the Text2SQL task into several components, using in-context learning and taxonomy-guided error modification to achieve state-of-the-art results.  					AI-generated summary 				 Converting natural language queries into SQL queries is a crucial challenge in both indu...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 30. Context-Aware Fusion enhances DiffusionDet by integrating global scene context with local features using cross-attention, improving performance on fine-grained object detection tasks.  					AI-generated summary 				 Fine-grained object detection in challenging visual domains, such as vehicle damage ...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 31. Metis addresses training instability in low-bit quantized large language models by using spectral decomposition, adaptive learning rates, and dual-range regularization to improve performance and stability.  					AI-generated summary 				 This work identifies anisotropic parameter distributions as a ...
[03.09.2025 10:12] ********************************************************************************
[03.09.2025 10:12] Abstract 32. FastFit, a high-speed virtual try-on framework using a cacheable diffusion architecture with a Semi-Attention mechanism, achieves significant speedup and maintains high fidelity in multi-reference outfit compositions.  					AI-generated summary 				 Despite its great potential, virtual try-on techno...
[03.09.2025 10:12] Read previous papers.
[03.09.2025 10:12] Generating reviews via LLM API.
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#math", "#optimization", "#rl", "#training"], "emoji": "🧠", "ru": {"title": "Стабильное обучение AI рассуждать с инструментами", "desc": "Статья представляет алгоритм SimpleTIR, стабилизирующий обучение многоходовых моделей с интегрированными инструментам
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#reasoning", "#agi", "#survey", "#rl", "#open_source"], "emoji": "🤖", "ru": {"title": "Большие языковые модели становятся автономными агентами", "desc": "Агентное обучение с подкреплением (Agentic RL) трансформирует большие языковые модели в автономных агент
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#games", "#benchmark", "#training", "#reasoning", "#agents", "#rl"], "emoji": "🤖", "ru": {"title": "UI-TARS-2: Новый уровень GUI-агентов с улучшенным обучением и обобщением", "desc": "UI-TARS-2 - это модель агента для графических пользовательских интерфейсов, решающ
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#games", "#rlhf", "#multimodal", "#benchmark", "#reasoning", "#rl"], "emoji": "🤖", "ru": {"title": "Объединение критика и генератора: новый шаг в мультимодальном ИИ", "desc": "В этой статье предлагается новый подход к обучению мультимодальных языковых моделей, объед
[03.09.2025 10:12] Querying the API.
[03.09.2025 10:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A benchmark for long-video hallucination identifies and investigates Semantic Aggregation Hallucination (SAH), showing its prevalence in complex and rapidly changing semantic contexts, and proposes strategies to mitigate it.  					AI-generated summary 				 Video multimodal large language models (Video-MLLMs) have achieved remarkable progress in video understanding. However, they remain vulnerable to hallucination-producing content inconsistent with or unrelated to video inputs. Previous video hallucination benchmarks primarily focus on short-videos. They attribute hallucinations to factors such as strong language priors, missing frames, or vision-language biases introduced by the visual encoder. While these causes indeed account for most hallucinations in short videos, they still oversimplify the cause of hallucinations. Sometimes, models generate incorrect outputs but with correct frame-level semantics. We refer to this type of hallucination as Semantic Aggregation Hallucination (SAH), which arises during the process of aggregating frame-level semantics into event-level semantic groups. Given that SAH becomes particularly critical in long videos due to increased semantic complexity across multiple events, it is essential to separate and thoroughly investigate the causes of this type of hallucination. To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH. Our experiments confirm the existence of SAH and show that it increases with semantic complexity. Additionally, we find that models are more prone to SAH on rapidly changing semantics. Moreover, we discuss potential approaches to mitigate SAH. We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events. To support this, we curate a dataset of 8K adversarial data pairs and achieve improvements on both ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.
[03.09.2025 10:12] Response: {
  "desc": "Статья представляет новый бенчмарк ELV-Halluc для оценки галлюцинаций в длинных видео. Авторы вводят понятие Семантической Агрегационной Галлюцинации (САГ), которая возникает при объединении семантики отдельных кадров в семантические группы событий. Исследование показывает, что САГ усиливается с ростом семантической сложности и быстрой сменой контекста в видео. Предлагаются стратегии по снижению САГ, включая улучшение позиционного кодирования и применение метода DPO.",
  "emoji": "🎬",
  "title": "Борьба с галлюцинациями в длинных видео: новый бенчмарк и стратегии"
}
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A benchmark for long-video hallucination identifies and investigates Semantic Aggregation Hallucination (SAH), showing its prevalence in complex and rapidly changing semantic contexts, and proposes strategies to mitigate it.  					AI-generated summary 				 Video multimodal large language models (Video-MLLMs) have achieved remarkable progress in video understanding. However, they remain vulnerable to hallucination-producing content inconsistent with or unrelated to video inputs. Previous video hallucination benchmarks primarily focus on short-videos. They attribute hallucinations to factors such as strong language priors, missing frames, or vision-language biases introduced by the visual encoder. While these causes indeed account for most hallucinations in short videos, they still oversimplify the cause of hallucinations. Sometimes, models generate incorrect outputs but with correct frame-level semantics. We refer to this type of hallucination as Semantic Aggregation Hallucination (SAH), which arises during the process of aggregating frame-level semantics into event-level semantic groups. Given that SAH becomes particularly critical in long videos due to increased semantic complexity across multiple events, it is essential to separate and thoroughly investigate the causes of this type of hallucination. To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH. Our experiments confirm the existence of SAH and show that it increases with semantic complexity. Additionally, we find that models are more prone to SAH on rapidly changing semantics. Moreover, we discuss potential approaches to mitigate SAH. We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events. To support this, we curate a dataset of 8K adversarial data pairs and achieve improvements on both ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio."

[03.09.2025 10:12] Response: ```python
['BENCHMARK', 'VIDEO', 'DATASET']
```
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A benchmark for long-video hallucination identifies and investigates Semantic Aggregation Hallucination (SAH), showing its prevalence in complex and rapidly changing semantic contexts, and proposes strategies to mitigate it.  					AI-generated summary 				 Video multimodal large language models (Video-MLLMs) have achieved remarkable progress in video understanding. However, they remain vulnerable to hallucination-producing content inconsistent with or unrelated to video inputs. Previous video hallucination benchmarks primarily focus on short-videos. They attribute hallucinations to factors such as strong language priors, missing frames, or vision-language biases introduced by the visual encoder. While these causes indeed account for most hallucinations in short videos, they still oversimplify the cause of hallucinations. Sometimes, models generate incorrect outputs but with correct frame-level semantics. We refer to this type of hallucination as Semantic Aggregation Hallucination (SAH), which arises during the process of aggregating frame-level semantics into event-level semantic groups. Given that SAH becomes particularly critical in long videos due to increased semantic complexity across multiple events, it is essential to separate and thoroughly investigate the causes of this type of hallucination. To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH. Our experiments confirm the existence of SAH and show that it increases with semantic complexity. Additionally, we find that models are more prone to SAH on rapidly changing semantics. Moreover, we discuss potential approaches to mitigate SAH. We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events. To support this, we curate a dataset of 8K adversarial data pairs and achieve improvements on both ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio."

[03.09.2025 10:12] Response: ```python
["HALLUCINATIONS", "LONG_CONTEXT"]
```
[03.09.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new benchmark called ELV-Halluc, specifically designed to study Semantic Aggregation Hallucination (SAH) in long videos. SAH occurs when models incorrectly aggregate frame-level semantics into event-level groups, particularly in complex and rapidly changing contexts. The research shows that SAH is more prevalent in longer videos due to increased semantic complexity and provides strategies to mitigate this issue. By implementing a positional encoding strategy and a DPO approach, the authors demonstrate a significant reduction in SAH, improving the model\'s performance on video understanding tasks.","title":"Tackling Semantic Aggregation Hallucination in Long Videos"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces a new benchmark called ELV-Halluc, specifically designed to study Semantic Aggregation Hallucination (SAH) in long videos. SAH occurs when models incorrectly aggregate frame-level semantics into event-level groups, particularly in complex and rapidly changing contexts. The research shows that SAH is more prevalent in longer videos due to increased semantic complexity and provides strategies to mitigate this issue. By implementing a positional encoding strategy and a DPO approach, the authors demonstrate a significant reduction in SAH, improving the model's performance on video understanding tasks.", title='Tackling Semantic Aggregation Hallucination in Long Videos'))
[03.09.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"这篇论文提出了一个针对长视频幻觉的新基准，重点研究了语义聚合幻觉（SAH）。SAH在复杂和快速变化的语义环境中尤为普遍，导致模型生成与视频输入不一致的内容。研究表明，SAH的发生与语义复杂性增加有关，尤其是在多个事件中。为了解决这个问题，论文提出了ELV-Halluc基准，并探讨了缓解SAH的策略，如位置编码和DPO策略。","title":"揭示长视频中的语义聚合幻觉"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='这篇论文提出了一个针对长视频幻觉的新基准，重点研究了语义聚合幻觉（SAH）。SAH在复杂和快速变化的语义环境中尤为普遍，导致模型生成与视频输入不一致的内容。研究表明，SAH的发生与语义复杂性增加有关，尤其是在多个事件中。为了解决这个问题，论文提出了ELV-Halluc基准，并探讨了缓解SAH的策略，如位置编码和DPO策略。', title='揭示长视频中的语义聚合幻觉'))
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#dataset", "#data", "#optimization", "#synthetic", "#training"], "emoji": "📄", "ru": {"title": "Автоматическое создание высококачественных моделей для извлечения данных из документов", "desc": "Статья представляет новый фреймворк для создания высококачественных наборов данных и моде
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#architecture", "#rl", "#open_source", "#agi", "#agents", "#reasoning", "#rlhf", "#training", "#multimodal"], "emoji": "🛠️", "ru": {"title": "VerlTool: Универсальный фреймворк для обучения с подкреплением с использованием инструментов", "desc": "VerlTool - это унифицированный и моду
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#rl", "#open_source", "#reasoning", "#agents", "#alignment", "#training", "#healthcare"], "emoji": "🩺", "ru": {"title": "Динамическая верификация LLM для реальной клинической практики", "desc": "Эта статья представляет новую динамическую систему верифи
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#video", "#long_context", "#rl", "#training", "#alignment"], "emoji": "🎥", "ru": {"title": "Революция в понимании видео: Keye-VL-1.5 объединяет эффективность и точность", "desc": "Keye-VL-1.5 - это новая модель машинного обучения для понимания видео. Она
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#optimization", "#rl", "#training", "#open_source"], "emoji": "🧠", "ru": {"title": "PACS: Эффективное обучение языковых моделей рассуждению через супервизорный RLVR", "desc": "PACS - это новый фреймворк для обучения с подкреплением с проверяемыми наградам
[03.09.2025 10:12] Querying the API.
[03.09.2025 10:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

DCPO, a novel reinforcement learning framework, enhances large language models by dynamically adjusting clipping bounds and standardizing rewards, leading to improved performance and efficiency.  					AI-generated summary 				 Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a promising framework for enhancing the reasoning capabilities of large language models. However, existing approaches such as GRPO often suffer from zero gradients. This problem arises primarily due to fixed clipping bounds for token-level probability ratios and the standardization of identical rewards, which can lead to ineffective gradient updates and underutilization of generated responses. In this work, we propose Dynamic Clipping Policy Optimization (DCPO), which introduces a dynamic clipping strategy that adaptively adjusts the clipping bounds based on token-specific prior probabilities to enhance token-level exploration, and a smooth advantage standardization technique that standardizes rewards across cumulative training steps to improve the response-level effective utilization of generated responses. DCPO achieved state-of-the-art performance on four benchmarks based on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24 benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO (20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the nonzero advantage over GRPO in four models, doubled the training efficiency over DAPO, and significantly reduced the token clipping ratio by an order of magnitude compared to both GRPO and DAPO, while achieving superior performance. These results highlight DCPO's effectiveness in leveraging generated data more efficiently for reinforcement learning in large language models.
[03.09.2025 10:12] Response: {
  "desc": "DCPO - это новый метод обучения с подкреплением для улучшения больших языковых моделей. Он динамически настраивает границы отсечения и стандартизирует вознаграждения, что повышает эффективность обучения. DCPO превзошел существующие методы на нескольких бенчмарках, используя различные модели. Метод значительно улучшил использование сгенерированных данных при обучении с подкреплением больших языковых моделей.",
  "emoji": "🚀",
  "title": "DCPO: Динамическая оптимизация для мощного обучения языковых моделей"
}
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DCPO, a novel reinforcement learning framework, enhances large language models by dynamically adjusting clipping bounds and standardizing rewards, leading to improved performance and efficiency.  					AI-generated summary 				 Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a promising framework for enhancing the reasoning capabilities of large language models. However, existing approaches such as GRPO often suffer from zero gradients. This problem arises primarily due to fixed clipping bounds for token-level probability ratios and the standardization of identical rewards, which can lead to ineffective gradient updates and underutilization of generated responses. In this work, we propose Dynamic Clipping Policy Optimization (DCPO), which introduces a dynamic clipping strategy that adaptively adjusts the clipping bounds based on token-specific prior probabilities to enhance token-level exploration, and a smooth advantage standardization technique that standardizes rewards across cumulative training steps to improve the response-level effective utilization of generated responses. DCPO achieved state-of-the-art performance on four benchmarks based on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24 benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO (20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the nonzero advantage over GRPO in four models, doubled the training efficiency over DAPO, and significantly reduced the token clipping ratio by an order of magnitude compared to both GRPO and DAPO, while achieving superior performance. These results highlight DCPO's effectiveness in leveraging generated data more efficiently for reinforcement learning in large language models."

[03.09.2025 10:12] Response: ```python
['RL', 'RLHF', 'TRAINING', 'BENCHMARK']
```
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"DCPO, a novel reinforcement learning framework, enhances large language models by dynamically adjusting clipping bounds and standardizing rewards, leading to improved performance and efficiency.  					AI-generated summary 				 Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a promising framework for enhancing the reasoning capabilities of large language models. However, existing approaches such as GRPO often suffer from zero gradients. This problem arises primarily due to fixed clipping bounds for token-level probability ratios and the standardization of identical rewards, which can lead to ineffective gradient updates and underutilization of generated responses. In this work, we propose Dynamic Clipping Policy Optimization (DCPO), which introduces a dynamic clipping strategy that adaptively adjusts the clipping bounds based on token-specific prior probabilities to enhance token-level exploration, and a smooth advantage standardization technique that standardizes rewards across cumulative training steps to improve the response-level effective utilization of generated responses. DCPO achieved state-of-the-art performance on four benchmarks based on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24 benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO (20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the nonzero advantage over GRPO in four models, doubled the training efficiency over DAPO, and significantly reduced the token clipping ratio by an order of magnitude compared to both GRPO and DAPO, while achieving superior performance. These results highlight DCPO's effectiveness in leveraging generated data more efficiently for reinforcement learning in large language models."

[03.09.2025 10:12] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[03.09.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DCPO is a new reinforcement learning framework designed to improve large language models by dynamically adjusting clipping bounds and standardizing rewards. This approach addresses the issue of zero gradients that can occur with fixed clipping bounds and identical rewards, which hinder effective learning. By adapting clipping strategies based on token-specific probabilities and smoothing reward standardization, DCPO enhances exploration and utilization of generated responses. The framework has demonstrated state-of-the-art performance across multiple benchmarks, significantly improving training efficiency and reducing clipping ratios compared to previous methods.","title":"Dynamic Clipping for Enhanced Learning in Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DCPO is a new reinforcement learning framework designed to improve large language models by dynamically adjusting clipping bounds and standardizing rewards. This approach addresses the issue of zero gradients that can occur with fixed clipping bounds and identical rewards, which hinder effective learning. By adapting clipping strategies based on token-specific probabilities and smoothing reward standardization, DCPO enhances exploration and utilization of generated responses. The framework has demonstrated state-of-the-art performance across multiple benchmarks, significantly improving training efficiency and reducing clipping ratios compared to previous methods.', title='Dynamic Clipping for Enhanced Learning in Language Models'))
[03.09.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"DCPO是一种新颖的强化学习框架，旨在通过动态调整剪切边界和标准化奖励来增强大型语言模型的性能和效率。该方法解决了现有技术中由于固定剪切边界导致的零梯度问题，从而提高了梯度更新的有效性。DCPO引入了一种动态剪切策略，根据特定的先验概率自适应调整剪切边界，促进了令牌级别的探索。实验结果表明，DCPO在多个基准测试中表现优异，显著提高了训练效率和生成响应的有效利用。","title":"动态剪切策略优化：提升语言模型的强化学习效率"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='DCPO是一种新颖的强化学习框架，旨在通过动态调整剪切边界和标准化奖励来增强大型语言模型的性能和效率。该方法解决了现有技术中由于固定剪切边界导致的零梯度问题，从而提高了梯度更新的有效性。DCPO引入了一种动态剪切策略，根据特定的先验概率自适应调整剪切边界，促进了令牌级别的探索。实验结果表明，DCPO在多个基准测试中表现优异，显著提高了训练效率和生成响应的有效利用。', title='动态剪切策略优化：提升语言模型的强化学习效率'))
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#training", "#rl", "#open_source", "#transfer_learning", "#optimization", "#reasoning"], "emoji": "🧠", "ru": {"title": "Передача способностей к рассуждению между языковыми моделями", "desc": "Исследование показывает, что способности к рассуждению, полученные с помощью 
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#diffusion", "#dataset", "#video"], "emoji": "🎬", "ru": {"title": "Генеративный видеокомпозитинг: новый уровень автоматизации в производстве видео", "desc": "Статья представляет новый подход к автоматизации видеокомпозитинга с использованием генеративных моделей. Авторы разработали 
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#games", "#story_generation", "#rlhf", "#optimization", "#rl", "#training"], "emoji": "🌈", "ru": {"title": "DARLING: Качество и разнообразие в гармонии", "desc": "DARLING - это фреймворк обучения с подкреплением, который улучшает как качество, так и разнообразие выходных данных боль
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#training", "#architecture"], "emoji": "🚀", "ru": {"title": "Упрощение архитектуры для эффективного обучения мультимодальных моделей", "desc": "OpenVision 2 представляет собой упрощенную версию архитектуры OpenVision, в которой удален текстовый энкоде
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#dataset", "#transfer_learning", "#optimization", "#healthcare"], "emoji": "🏥", "ru": {"title": "Единый энкодер для мультимодальных медицинских изображений", "desc": "M3Ret - это унифицированный визуальный энкодер, обученный на крупномасштабном наборе данных с 
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#data", "#synthetic", "#training", "#dataset"], "emoji": "🧬", "ru": {"title": "Генетический подход к созданию качественных синтетических данных для NLP", "desc": "Genetic Prompt - это новый метод улучшения качества и разнообразия синтетических данных в обработке ест
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#dataset", "#multilingual", "#reasoning", "#long_context", "#benchmark"], "emoji": "🗣️", "ru": {"title": "Искусственный язык раскрывает ограничения языковых моделей", "desc": "Исследователи создали искусственный язык Camlang для оценки способности больших языковых моделей (LLM) осва
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#open_source", "#optimization", "#training"], "emoji": "🔬", "ru": {"title": "Оптимизаторы для LLM: всесторонний анализ и практические рекомендации", "desc": "Статья представляет комплексную оценку современных методов оптимизации для больших языковых моделей (LLM). Авто
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#agents"], "emoji": "🔍", "ru": {"title": "Универсальный инструмент для настройки стратегий глубокого исследования", "desc": "Universal Deep Research (UDR) - это гибкая система, позволяющая пользователям настраивать стратегии глубокого исследования с использованием любой языковой мод
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#training"], "emoji": "🔬", "ru": {"title": "Справедливое сравнение оптимизаторов требует тщательного анализа", "desc": "Исследование показывает, что для справедливого сравнения оптимизаторов глубокого обучения необходима тщательная настройка гиперпараметров и оценка
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#optimization", "#games"], "emoji": "🕹️", "ru": {"title": "Преодолевая разрыв между наблюдением и действием в играх-квестах", "desc": "В статье представлен новый бенчмарк FlashAdventure для оценки агентов с графическим интерфейсом в Flash-играх жанра квест. 
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#cv", "#multimodal", "#diffusion"], "emoji": "🖌️", "ru": {"title": "VARIN: Точное редактирование изображений с помощью инверсии шума для VAR-моделей", "desc": "VARIN - это новый метод редактирования изображений для визуальных авторегрессионных моделей (VAR). Он испо
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#dataset", "#agents", "#data", "#benchmark"], "emoji": "📱", "ru": {"title": "MobiAgent: передовая система мобильных агентов для реальных задач", "desc": "MobiAgent - это комплексная система мобильных агентов, состоящая из трех ключевых компонентов: серии моделей MobiMind, фреймворка
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#dataset", "#architecture", "#transfer_learning", "#optimization", "#healthcare"], "emoji": "🏥", "ru": {"title": "MedDINOv3: Универсальный сегментатор медицинских изображений на основе фундаментальных моделей", "desc": "MedDINOv3 - это новая архитектура для сегм
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#data", "#multilingual", "#ethics", "#open_source", "#alignment", "#inference"], "emoji": "🇮🇳", "ru": {"title": "Конституционное декодирование для справедливых языковых моделей", "desc": "Фреймворк AMBEDKAR предлагает новый подход к снижению предвзятости в выводах больших языковых м
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#benchmark", "#multimodal", "#rlhf", "#hallucinations", "#alignment"], "emoji": "👥", "ru": {"title": "Коллективное обучение ИИ: имитация процесса рецензирования для улучшения языково-визуальных моделей", "desc": "Предложена новая методика обучения больших языково-визуальных моделей 
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#architecture", "#3d", "#cv"], "emoji": "🗺️", "ru": {"title": "Эффективная монокулярная SLAM-система без калибровки камеры", "desc": "ViSTA-SLAM - это система одновременной локализации и картографирования в реальном времени, использующая монокулярную камеру. Она применяет легковесну
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#optimization", "#3d", "#synthetic"], "emoji": "🔍", "ru": {"title": "Двухракурсное самообучение улучшает 3D реконструкцию облаков точек", "desc": "Статья представляет новый метод самообучения для трехмерных облаков точек под названием Point-PQAE. Этот подход использует двухракурсную
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#data", "#optimization", "#reasoning", "#agents", "#dataset"], "emoji": "🤖", "ru": {"title": "Мультиагентный подход с обучением в контексте революционизирует Text2SQL", "desc": "Статья представляет новый подход к решению задачи Text2SQL, используя мультиагентную систему. Авторы пред
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#diffusion", "#benchmark", "#architecture", "#optimization", "#cv"], "emoji": "🔍", "ru": {"title": "Контекстное слияние для точной детекции мелких объектов", "desc": "Статья представляет новый метод Context-Aware Fusion (CAF) для улучшения модели DiffusionDet в задаче детекции мелки
[03.09.2025 10:12] Using data from previous issue: {"categories": ["#low_resource", "#inference", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное обучение LLM с низкой битностью", "desc": "Статья представляет Metis - фреймворк для обучения больших языковых моделей (LLM) с низкобитной квантизацией. Метод использует спектраль
[03.09.2025 10:12] Querying the API.
[03.09.2025 10:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

FastFit, a high-speed virtual try-on framework using a cacheable diffusion architecture with a Semi-Attention mechanism, achieves significant speedup and maintains high fidelity in multi-reference outfit compositions.  					AI-generated summary 				 Despite its great potential, virtual try-on technology is hindered from real-world application by two major challenges: the inability of current methods to support multi-reference outfit compositions (including garments and accessories), and their significant inefficiency caused by the redundant re-computation of reference features in each denoising step. To address these challenges, we propose FastFit, a high-speed multi-reference virtual try-on framework based on a novel cacheable diffusion architecture. By employing a Semi-Attention mechanism and substituting traditional timestep embeddings with class embeddings for reference items, our model fully decouples reference feature encoding from the denoising process with negligible parameter overhead. This allows reference features to be computed only once and losslessly reused across all steps, fundamentally breaking the efficiency bottleneck and achieving an average 3.5x speedup over comparable methods. Furthermore, to facilitate research on complex, multi-reference virtual try-on, we introduce DressCode-MR, a new large-scale dataset. It comprises 28,179 sets of high-quality, paired images covering five key categories (tops, bottoms, dresses, shoes, and bags), constructed through a pipeline of expert models and human feedback refinement. Extensive experiments on the VITON-HD, DressCode, and our DressCode-MR datasets show that FastFit surpasses state-of-the-art methods on key fidelity metrics while offering its significant advantage in inference efficiency.
[03.09.2025 10:12] Response: {
  "desc": "FastFit - это новая высокоскоростная система виртуальной примерки одежды, использующая кэшируемую архитектуру диффузионных моделей с механизмом полувнимания (Semi-Attention). Она позволяет значительно ускорить процесс, сохраняя при этом высокое качество генерации изображений с несколькими предметами одежды. FastFit решает проблему неэффективности существующих методов, устраняя необходимость повторных вычислений для каждого элемента гардероба. Авторы также представили новый датасет DressCode-MR для исследований в этой области.",
  "emoji": "👚",
  "title": "Быстрая и точная виртуальная примерка с FastFit"
}
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FastFit, a high-speed virtual try-on framework using a cacheable diffusion architecture with a Semi-Attention mechanism, achieves significant speedup and maintains high fidelity in multi-reference outfit compositions.  					AI-generated summary 				 Despite its great potential, virtual try-on technology is hindered from real-world application by two major challenges: the inability of current methods to support multi-reference outfit compositions (including garments and accessories), and their significant inefficiency caused by the redundant re-computation of reference features in each denoising step. To address these challenges, we propose FastFit, a high-speed multi-reference virtual try-on framework based on a novel cacheable diffusion architecture. By employing a Semi-Attention mechanism and substituting traditional timestep embeddings with class embeddings for reference items, our model fully decouples reference feature encoding from the denoising process with negligible parameter overhead. This allows reference features to be computed only once and losslessly reused across all steps, fundamentally breaking the efficiency bottleneck and achieving an average 3.5x speedup over comparable methods. Furthermore, to facilitate research on complex, multi-reference virtual try-on, we introduce DressCode-MR, a new large-scale dataset. It comprises 28,179 sets of high-quality, paired images covering five key categories (tops, bottoms, dresses, shoes, and bags), constructed through a pipeline of expert models and human feedback refinement. Extensive experiments on the VITON-HD, DressCode, and our DressCode-MR datasets show that FastFit surpasses state-of-the-art methods on key fidelity metrics while offering its significant advantage in inference efficiency."

[03.09.2025 10:12] Response: ```python
['DATASET', 'DATA', 'BENCHMARK', 'CV', 'INFERENCE']
```
[03.09.2025 10:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"FastFit, a high-speed virtual try-on framework using a cacheable diffusion architecture with a Semi-Attention mechanism, achieves significant speedup and maintains high fidelity in multi-reference outfit compositions.  					AI-generated summary 				 Despite its great potential, virtual try-on technology is hindered from real-world application by two major challenges: the inability of current methods to support multi-reference outfit compositions (including garments and accessories), and their significant inefficiency caused by the redundant re-computation of reference features in each denoising step. To address these challenges, we propose FastFit, a high-speed multi-reference virtual try-on framework based on a novel cacheable diffusion architecture. By employing a Semi-Attention mechanism and substituting traditional timestep embeddings with class embeddings for reference items, our model fully decouples reference feature encoding from the denoising process with negligible parameter overhead. This allows reference features to be computed only once and losslessly reused across all steps, fundamentally breaking the efficiency bottleneck and achieving an average 3.5x speedup over comparable methods. Furthermore, to facilitate research on complex, multi-reference virtual try-on, we introduce DressCode-MR, a new large-scale dataset. It comprises 28,179 sets of high-quality, paired images covering five key categories (tops, bottoms, dresses, shoes, and bags), constructed through a pipeline of expert models and human feedback refinement. Extensive experiments on the VITON-HD, DressCode, and our DressCode-MR datasets show that FastFit surpasses state-of-the-art methods on key fidelity metrics while offering its significant advantage in inference efficiency."

[03.09.2025 10:12] Response: ```python
["DIFFUSION", "OPEN_SOURCE"]
```
[03.09.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FastFit is a virtual try-on framework that enhances the speed and quality of outfit compositions by using a cacheable diffusion architecture combined with a Semi-Attention mechanism. It addresses the inefficiencies of existing methods by allowing reference features to be computed once and reused, which significantly reduces redundant calculations during the denoising process. This innovation leads to an impressive average speedup of 3.5 times compared to other techniques while maintaining high fidelity in the generated images. Additionally, the introduction of the DressCode-MR dataset supports further research in multi-reference virtual try-on applications, providing a rich resource for training and evaluation.","title":"FastFit: Speeding Up Virtual Try-Ons with Smart Caching!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FastFit is a virtual try-on framework that enhances the speed and quality of outfit compositions by using a cacheable diffusion architecture combined with a Semi-Attention mechanism. It addresses the inefficiencies of existing methods by allowing reference features to be computed once and reused, which significantly reduces redundant calculations during the denoising process. This innovation leads to an impressive average speedup of 3.5 times compared to other techniques while maintaining high fidelity in the generated images. Additionally, the introduction of the DressCode-MR dataset supports further research in multi-reference virtual try-on applications, providing a rich resource for training and evaluation.', title='FastFit: Speeding Up Virtual Try-Ons with Smart Caching!'))
[03.09.2025 10:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"FastFit是一种高速度的虚拟试衣框架，采用可缓存的扩散架构和半注意力机制，能够在多参考服装组合中实现显著的加速并保持高保真度。该技术解决了当前方法在多参考服装组合支持和每个去噪步骤中冗余重新计算参考特征的效率低下问题。通过将传统的时间步嵌入替换为参考项目的类别嵌入，我们的模型实现了参考特征编码与去噪过程的完全解耦，从而在所有步骤中仅计算一次参考特征并无损重用。实验结果表明，FastFit在关键保真度指标上超越了最先进的方法，同时在推理效率上具有显著优势。","title":"FastFit：高效虚拟试衣的新突破"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='FastFit是一种高速度的虚拟试衣框架，采用可缓存的扩散架构和半注意力机制，能够在多参考服装组合中实现显著的加速并保持高保真度。该技术解决了当前方法在多参考服装组合支持和每个去噪步骤中冗余重新计算参考特征的效率低下问题。通过将传统的时间步嵌入替换为参考项目的类别嵌入，我们的模型实现了参考特征编码与去噪过程的完全解耦，从而在所有步骤中仅计算一次参考特征并无损重用。实验结果表明，FastFit在关键保真度指标上超越了最先进的方法，同时在推理效率上具有显著优势。', title='FastFit：高效虚拟试衣的新突破'))
[03.09.2025 10:12] Renaming data file.
[03.09.2025 10:12] Renaming previous data. hf_papers.json to ./d/2025-09-03.json
[03.09.2025 10:12] Saving new data file.
[03.09.2025 10:12] Generating page.
[03.09.2025 10:12] Renaming previous page.
[03.09.2025 10:12] Renaming previous data. index.html to ./d/2025-09-03.html
[03.09.2025 10:12] Writing result.
[03.09.2025 10:12] Renaming log file.
[03.09.2025 10:12] Renaming previous data. log.txt to ./logs/2025-09-03_last_log.txt
