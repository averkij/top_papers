[21.01.2026 14:34] Read previous papers.
[21.01.2026 14:34] Generating top page (month).
[21.01.2026 14:34] Writing top page (month).
[21.01.2026 15:35] Read previous papers.
[21.01.2026 15:35] Get feed.
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12993
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11655
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14192
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13836
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14250
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11969
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13029
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11522
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12294
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13247
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11888
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14232
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14251
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13288
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14046
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13976
[21.01.2026 15:35] Extract page data from URL. URL: https://huggingface.co/papers/2601.14249
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12937
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10237
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13075
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12910
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10700
[21.01.2026 15:35] Extract page data from URL. URL: https://huggingface.co/papers/2601.13697
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13677
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13253
[21.01.2026 15:35] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13251
[21.01.2026 15:35] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.01.2026 15:35] No deleted papers detected.
[21.01.2026 15:35] Downloading and parsing papers (pdf, html). Total: 26.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.12993.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.12993.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.12993.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.11655.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.11655.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.11655.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.14192.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.14192.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.14192.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13836.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13836.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13836.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.14250.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.14250.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.14250.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.11969.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.11969.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.11969.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13029.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13029.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13029.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.11522.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.11522.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.11522.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.12294.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.12294.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.12294.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13247.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13247.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13247.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.11888.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.11888.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.11888.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.14232.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.14232.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.14232.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.14251.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.14251.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.14251.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13288.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13288.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13288.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.14046.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.14046.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.14046.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13976.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13976.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13976.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.14249.
[21.01.2026 15:35] Downloading paper 2601.14249 from https://arxiv.org/pdf/2601.14249v1...
[21.01.2026 15:35] Extracting affiliations from text.
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"2026-1-21 Which Reasoning Trajectories Teach Students to Reason Better? Simple Metric of Informative Alignment Yuming Yang1,2, Mingyoung Lai3, Wanxu Zhao1, Xiaoran Fan1, Zhiheng Xi1, Mingqi Wu1, Chiyue Huang4, Jun Zhao1, Haijun Lv2, Jian Tong2, Yunhua Zhou2, Yicheng Zou2,, Qipeng Guo2, Tao Gui1, Qi Zhang1, and Xuanjing Huang1 1Fudan University, 2Shanghai AI Laboratory, 3University of Toronto, 4University of Sydney Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of datastudent suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the models current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), simple metric that captures both alignment and informativeness to assess the suitability of reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of trajectorys average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection. 1. Introduction Recent advances in reasoning-oriented large language models (LLMs) are largely driven by their ability to generate long chain-of-thought (CoT) trajectories [12, 48]. Beyond enabling complex "
[21.01.2026 15:35] Response: ```python
[
    "Fudan University",
    "Shanghai AI Laboratory",
    "University of Toronto",
    "University of Sydney"
]
```
[21.01.2026 15:35] Deleting PDF ./assets/pdf/2601.14249.pdf.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.12937.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.12937.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.12937.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.10237.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.10237.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.10237.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13075.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13075.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13075.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.12910.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.12910.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.12910.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.10700.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.10700.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.10700.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13697.
[21.01.2026 15:35] Downloading paper 2601.13697 from https://arxiv.org/pdf/2601.13697v1...
[21.01.2026 15:35] Extracting affiliations from text.
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 2 ] . [ 1 7 9 6 3 1 . 1 0 6 2 : r Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning Zhihang Yuan1, Chengyu Yue1, Long Huang1, Litu Ou2, Lei Shi1, * 1Alibaba Cloud Computing 2The University of Edinburgh 1{yuanzhihang.yzh,yuechengyu.ycy, baixuan.hl, juetian.sl}@alibaba-inc.com 2litu.ou@ed.ac.uk "
[21.01.2026 15:35] Response: ```python
["Alibaba Cloud Computing", "The University of Edinburgh"]
```
[21.01.2026 15:35] Deleting PDF ./assets/pdf/2601.13697.pdf.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13677.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13677.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13677.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13253.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13253.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13253.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Downloading and parsing paper https://huggingface.co/papers/2601.13251.
[21.01.2026 15:35] Extra JSON file exists (./assets/json/2601.13251.json), skip PDF parsing.
[21.01.2026 15:35] Paper image links file exists (./assets/img_data/2601.13251.json), skip HTML parsing.
[21.01.2026 15:35] Success.
[21.01.2026 15:35] Enriching papers with extra data.
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 0. Being-H0.5 is a Vision-Language-Action model that enables robust cross-embodiment generalization through human-centric learning and a Mixture-of-Transformers architecture with specialized embodiment handling.  					AI-generated summary 				 We introduce Being-H0.5, a foundational Vision-Language-Act...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 1. Large language models face significant challenges in software issue resolution, prompting the development of autonomous coding agents through various training-free and training-based methodologies.  					AI-generated summary 				 Issue resolution, a complex Software Engineering (SWE) task integral t...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 2. Efficiency in agentic systems is examined across memory, tool learning, and planning components, analyzing trade-offs between effectiveness and computational costs through various optimization strategies and benchmarks.  					AI-generated summary 				 Recent years have witnessed increasing interest ...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 3. FutureOmni presents the first benchmark for evaluating multimodal models' ability to forecast future events from audio-visual data, revealing current limitations and proposing an improved training strategy for better performance.  					AI-generated summary 				 Although Multimodal Large Language Mod...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 4. OmniTransfer presents a unified framework for spatio-temporal video transfer that enhances appearance consistency and temporal control through multi-view information and multimodal semantic guidance.  					AI-generated summary 				 Videos convey richer information than images or text, capturing both...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 5. A benchmark called MemoryRewardBench is introduced to systematically evaluate reward models' ability to assess long-term memory management in large language models across various context lengths and memory patterns.  					AI-generated summary 				 Existing works increasingly adopt memory-centric mec...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 6. Think3D enhances vision-language models' 3D reasoning capabilities by enabling interactive spatial exploration through 3D reconstruction and camera-based operations, improving performance without additional training.  					AI-generated summary 				 Understanding and reasoning about the physical worl...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 7. UniX presents a unified medical foundation model that decouples visual understanding and generation tasks using distinct autoregressive and diffusion branches with cross-modal attention for enhanced performance.  					AI-generated summary 				 Despite recent progress, medical foundation models still...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 8. ToolPRMBench is introduced as a large-scale benchmark for evaluating process reward models in tool-using agents, featuring step-level test cases and multi-LLM verification to ensure data quality.  					AI-generated summary 				 Reward-guided search methods have demonstrated strong potential in enhan...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 9. WorldMind addresses the modal disconnect in LLMs by autonomously building a symbolic world knowledge repository that enhances physical feasibility and task optimality through experience-based learning.  					AI-generated summary 				 Current Large Language Models (LLMs) exhibit a critical modal disc...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 10. A novel retriever training framework for agentic search that uses both local relevance and global answer correctness metrics with iterative optimization between the search agent and retriever.  					AI-generated summary 				 Agentic search has recently emerged as a powerful paradigm, where an agent ...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 11. KAGE-Env is a JAX-native 2D platformer environment that isolates visual shifts from underlying control problems, enabling systematic analysis of visual generalization in reinforcement learning.  					AI-generated summary 				 Pixel-based reinforcement learning agents often fail under purely visual d...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 12. LightOnOCR-2-1B is a compact 1B-parameter vision-language model that performs end-to-end document image-to-text conversion with improved localization and robustness through specialized training techniques.  					AI-generated summary 				 We present LightOnOCR-2-1B, a 1B-parameter end-to-end multilin...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 13. Lightweight probes trained on hidden states of LLMs enable efficient classification tasks without additional computational overhead, improving safety and sentiment analysis performance.  					AI-generated summary 				 Production LLM systems often rely on separate models for safety and other classifi...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 14. PRiSM benchmark evaluates phonetic perception in speech models through standardized transcription-based metrics and downstream applications across clinical, educational, and multilingual domains.  					AI-generated summary 				 Phone recognition (PR) serves as the atomic interface for language-agnos...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 15. FantasyVLN presents a unified implicit reasoning framework for vision-and-language navigation that enhances reasoning capabilities without explicit token overhead, achieving real-time performance with improved accuracy.  					AI-generated summary 				 Achieving human-level performance in Vision-and-...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 16. Researchers introduce a novel metric called Rank-Surprisal Ratio (RSR) to better assess the suitability of reasoning trajectories for distilling knowledge from large language models, demonstrating superior performance compared to existing methods.  					AI-generated summary 				 Long chain-of-though...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 17. Membership inference attacks fail to reliably detect copyrighted text usage in large language models when training data is paraphrased using structure-aware methods that preserve semantic content.  					AI-generated summary 				 As large language models (LLMs) are trained on increasingly opaque corp...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 18. Differentially private stochastic gradient descent with shuffled sampling faces fundamental privacy-utility trade-offs that require substantial noise for meaningful privacy protection, limiting practical performance.  					AI-generated summary 				 Differentially Private Stochastic Gradient Descent ...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 19. AI mentor METIS outperforms GPT-5 and Claude Sonnet 4.5 in supporting undergraduate research writing across multiple stages, with higher student scores and improved document-grounded outputs, though challenges remain in tool routing and stage classification.  					AI-generated summary 				 Many stud...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 20. SciCoQA is a dataset for identifying mismatches between scientific publications and code implementations, containing 611 discrepancies across multiple disciplines and demonstrating the challenge of detecting such issues even for advanced language models.  					AI-generated summary 				 We present Sc...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 21. A framework for generating structured counterfactual pairs using LLMs and SCMs enables improved evaluation and analysis of concept-based explanations in high-stakes domains.  					AI-generated summary 				 Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influ...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 22. GRADFILTERING is an uncertainty-aware data selection framework for instruction tuning that uses gradient signal-to-noise ratio to improve LLM adaptation efficiency and performance.  					AI-generated summary 				 Instruction tuning is a standard paradigm for adapting large language models (LLMs), bu...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 23. Class-stratified Scheduled Power Predictive Entropy (ClaSP PE) is a novel active learning strategy that improves 3D biomedical image segmentation by addressing class imbalance and selection redundancy through stratified querying and power noising with decay scheduling.  					AI-generated summary 			...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 24. A hybrid methodology combining FastText embeddings, clustering, and AI classification generates a large-scale Turkish semantic relations dataset with high accuracy validation.  					AI-generated summary 				 We present a hybrid methodology for generating large-scale semantic relationship datasets in...
[21.01.2026 15:35] ********************************************************************************
[21.01.2026 15:35] Abstract 25. A large-scale semantic clustering system addresses the limitation of neural embeddings in distinguishing synonyms from antonyms through a specialized three-way discriminator and novel clustering algorithm.  					AI-generated summary 				 Neural embeddings have a notorious blind spot: they can't reli...
[21.01.2026 15:35] Read previous papers.
[21.01.2026 15:35] Generating reviews via LLM API.
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#architecture", "#dataset", "#training", "#multimodal", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —è–∑—ã–∫ –¥–ª—è –≤—Å–µ—Ö —Ä–æ–±–æ—Ç–æ–≤: universal VLA —Å –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–º –æ–±–æ–±—â–µ–Ω–∏–µ–º", "desc": "Being-H0.5 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å Vision-Language-Action (VLA), —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è —Ä–æ–±–æ—Ç–æ—Ç
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#dataset", "#agents", "#data", "#training", "#open_source", "#plp", "#survey"], "emoji": "ü§ñ", "ru": {"title": "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –æ—à–∏–±–æ–∫", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∫–æ–¥–∏—Ä—É—é—â–∏—Ö –∞–≥–µ–Ω
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#rl", "#optimization", "#long_context", "#agents", "#benchmark"], "emoji": "‚ö°", "ru": {"title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º: –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∞–Ω–∞–ª–∏–∑–∏—Ä
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#audio", "#video", "#benchmark", "#dataset", "#training", "#multimodal"], "emoji": "üîÆ", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±—É–¥—É—â–µ–≥–æ: —É—á–∏–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ—Ç—å –∑–∞–≤—Ç—Ä–∞", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ FutureOmni ‚Äî –ø–µ—Ä–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å–∫–∞
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#video", "#transfer_learning", "#architecture", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ", "desc": "OmniTransfer –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø—Ä–æ—Å
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#long_context", "#survey", "#benchmark", "#dataset"], "emoji": "üß†", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏: –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω MemoryRewardBench ‚Äî –ø–µ—Ä–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#open_source", "#reasoning"], "emoji": "üßä", "ru": {"title": "–¢—Ä—ë—Ö–º–µ—Ä–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –¥–ª—è –≤–∏–¥–µ–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "Think3D ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—à–∏—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –ø–æ–∑–≤–æ–ª—è—è –∏–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —á–µ—Ä–µ–∑ 3
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#diffusion", "#training", "#data", "#architecture", "#open_source", "#multimodal", "#healthcare"], "emoji": "ü´Ä", "ru": {"title": "–°–∏–Ω–µ—Ä–≥–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏—è: —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –≤–µ—Ç–≤–∏ –¥–ª—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", "desc": "UniX ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å-—Ñ—É–Ω–¥–∞
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#dataset", "#rl"], "emoji": "üîß", "ru": {"title": "–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ ToolPRMBench ‚Äî –º–∞—Å—à—Ç–∞–±–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ —à–∞–≥–æ–≤
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#transfer_learning", "#alignment", "#hallucinations", "#reasoning"], "emoji": "üåç", "ru": {"title": "–ì—Äounded –º–∏—Ä –¥–ª—è LLM: –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –∫ —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –æ—Å—É—â–µ—Å—Ç–≤–∏–º—ã–º –ø–ª–∞–Ω–∞–º", "desc": "WorldMind —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –º–æ–¥–∞–ª—å–Ω–æ–π —Ä–∞—Å—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –ø—É—Ç—ë–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#training", "#rag"], "emoji": "üîÑ", "ru": {"title": "–î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞ –∏ –ø–æ–∏—Å–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—èÊ°ÜÊû∂ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è retriever'–∞, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–æ–≤. 
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#optimization", "#cv", "#games", "#benchmark", "#rl"], "emoji": "üéÆ", "ru": {"title": "–ß–∏—Å—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ–±–æ–±—â–∞–µ–º–æ—Å—Ç–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –Ω–∞–±–ª—é–¥–µ–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ KAGE-Env ‚Äî —Å—Ä–µ–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ JAX, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#training", "#multimodal", "#small_models", "#dataset", "#cv", "#multilingual", "#benchmark"], "emoji": "üìÑ", "ru": {"title": "–õ—ë–≥–∫–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Å –µ–¥–∏–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω LightOnOCR-2-1B ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è vision-language –º–æ–¥–µ–ª—å —Å 1 –º
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#training", "#inference", "#small_models"], "emoji": "üîç", "ru": {"title": "–õ—ë–≥–∫–∏–µ –∑–æ–Ω–¥—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π LLM –±–µ–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –ª—ë–≥–∫–∏—Ö –∑–æ–Ω–¥–æ–≤ (probes) –Ω–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#open_source", "#audio", "#dataset", "#low_resource", "#multilingual", "#benchmark"], "emoji": "üî§", "ru": {"title": "–ì–ª—É–±–æ–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö —Ä–µ—á–µ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –±–µ–Ω—á–º–∞—Ä–∫ PRiSM –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è —Ñ–æ–Ω–µ—Ç–∏–∫–∏ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö —Ä–∞—Å–ø–æ
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#training", "#agents", "#interpretability", "#multimodal", "#reasoning", "#architecture"], "emoji": "üß≠", "ru": {"title": "–°–∫—Ä—ã—Ç–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", "desc": "FantasyVLN –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∑—Ä–µ–Ω–∏—è
[21.01.2026 15:35] Querying the API.
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Researchers introduce a novel metric called Rank-Surprisal Ratio (RSR) to better assess the suitability of reasoning trajectories for distilling knowledge from large language models, demonstrating superior performance compared to existing methods.  					AI-generated summary 				 Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.
[21.01.2026 15:35] Response: ```json
{
  "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –Ω–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Rank-Surprisal Ratio (RSR) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ø—Ä–∏ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –∏–∑ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ú–µ—Ç—Ä–∏–∫–∞ —É—á–∏—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏, –∏–∑–±–µ–≥–∞—è —Å–º–µ—â–µ–Ω–∏—è –≤ —Å—Ç–æ—Ä–æ–Ω—É –ø—Ä–∏–º–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—Å—Ç–æ —Ö–æ—Ä–æ—à–æ —Å–æ–≥–ª–∞—Å—É—é—Ç—Å—è —Å —Ç–µ–∫—É—â–∏–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏. RSR –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∫ —Å—Ä–µ–¥–Ω–µ–π –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å–∏–ª—å–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –º–µ—Ç—Ä–∏–∫–∞ –ø–æ–∫–∞–∑–∞–ª–∞ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —á–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–¥—Ö–æ–¥—ã, –ø—Ä–∏ –æ—Ç–±–æ—Ä–µ –∫–∞–∫ —Å–∞–º–∏—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π, —Ç–∞–∫ –∏ —É—á–∏—Ç–µ–ª—å—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π.",
  "emoji": "üéØ",
  "title": "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"
}
```
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers introduce a novel metric called Rank-Surprisal Ratio (RSR) to better assess the suitability of reasoning trajectories for distilling knowledge from large language models, demonstrating superior performance compared to existing methods.  					AI-generated summary 				 Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection."

[21.01.2026 15:35] Response: ```python
["TRAINING", "DATA"]
```
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Researchers introduce a novel metric called Rank-Surprisal Ratio (RSR) to better assess the suitability of reasoning trajectories for distilling knowledge from large language models, demonstrating superior performance compared to existing methods.  					AI-generated summary 				 Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection."

[21.01.2026 15:35] Response: ```python
["REASONING", "TRANSFER_LEARNING"]
```
[21.01.2026 15:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new metric called Rank-Surprisal Ratio (RSR) designed to evaluate how well reasoning trajectories can help in transferring knowledge from large language models (LLMs). The authors highlight that simply using trajectories from stronger models does not guarantee better performance in student models, emphasizing the need for a better assessment of data suitability. RSR measures both the alignment of a trajectory with the student model and its informativeness, providing a more balanced evaluation. The results show that RSR correlates strongly with the performance of student models, making it a valuable tool for selecting effective reasoning trajectories and teachers.","title":"Rank-Surprisal Ratio: A New Way to Evaluate Knowledge Transfer in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new metric called Rank-Surprisal Ratio (RSR) designed to evaluate how well reasoning trajectories can help in transferring knowledge from large language models (LLMs). The authors highlight that simply using trajectories from stronger models does not guarantee better performance in student models, emphasizing the need for a better assessment of data suitability. RSR measures both the alignment of a trajectory with the student model and its informativeness, providing a more balanced evaluation. The results show that RSR correlates strongly with the performance of student models, making it a valuable tool for selecting effective reasoning trajectories and teachers.', title='Rank-Surprisal Ratio: A New Way to Evaluate Knowledge Transfer in LLMs'))
[21.01.2026 15:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Á†îÁ©∂‰∫∫ÂëòÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂ∫¶ÈáèÊ†áÂáÜÔºåÁß∞‰∏∫ÊéíÂêçÊÉäËÆ∂ÊØîÁéáÔºàRank-Surprisal RatioÔºåRSRÔºâÔºåÁî®‰∫éÊõ¥Â•ΩÂú∞ËØÑ‰º∞Êé®ÁêÜËΩ®ËøπÂú®‰ªéÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏≠ÊèêÂèñÁü•ËØÜÁöÑÈÄÇÁî®ÊÄß„ÄÇÈïøÈìæÊé®ÁêÜËΩ®Ëøπ‰∏∫‰ªéÊïôÂ∏àÊ®°ÂûãÂà∞Â≠¶ÁîüÊ®°ÂûãÁöÑÁü•ËØÜËí∏È¶èÊèê‰æõ‰∫Ü‰∏∞ÂØåÁöÑÁõëÁù£‰ø°Âè∑Ôºå‰ΩÜÂº∫ÊïôÂ∏àÁöÑËΩ®ËøπÂπ∂‰∏ç‰∏ÄÂÆöËÉΩ‰∫ßÁîüÊõ¥Â•ΩÁöÑÂ≠¶ÁîüÔºåÂº∫Ë∞É‰∫ÜÊï∞ÊçÆ‰∏éÂ≠¶ÁîüÈÄÇÁî®ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÈÄöËøáÂ≠¶ÁîüÁöÑÂèØËÉΩÊÄßÊù•ËØÑ‰º∞ÈÄÇÁî®ÊÄßÔºåÂÅèÂêë‰∫é‰∏éÊ®°ÂûãÂΩìÂâçË°å‰∏∫Á¥ßÂØÜÂØπÈΩêÁöÑËΩ®ËøπÔºåËÄåÂøΩËßÜ‰∫ÜÊõ¥ÂÖ∑‰ø°ÊÅØÈáèÁöÑËΩ®Ëøπ„ÄÇRSRÈÄöËøáÁªìÂêà‰ΩéÁªùÂØπÊ¶ÇÁéáÂíåÁõ∏ÂØπÈ´òÊéíÂêçÁöÑÊ†áËÆ∞ÔºåÂπ≥Ë°°Â≠¶‰π†‰ø°Âè∑Âº∫Â∫¶ÂíåË°å‰∏∫ÂØπÈΩêÔºåÂ±ïÁé∞Âá∫‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇ","title":"ÂºïÂÖ•ÊéíÂêçÊÉäËÆ∂ÊØîÁéáÔºåÊèêÂçáÁü•ËØÜËí∏È¶èÊïàÊûú"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Á†îÁ©∂‰∫∫ÂëòÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂ∫¶ÈáèÊ†áÂáÜÔºåÁß∞‰∏∫ÊéíÂêçÊÉäËÆ∂ÊØîÁéáÔºàRank-Surprisal RatioÔºåRSRÔºâÔºåÁî®‰∫éÊõ¥Â•ΩÂú∞ËØÑ‰º∞Êé®ÁêÜËΩ®ËøπÂú®‰ªéÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏≠ÊèêÂèñÁü•ËØÜÁöÑÈÄÇÁî®ÊÄß„ÄÇÈïøÈìæÊé®ÁêÜËΩ®Ëøπ‰∏∫‰ªéÊïôÂ∏àÊ®°ÂûãÂà∞Â≠¶ÁîüÊ®°ÂûãÁöÑÁü•ËØÜËí∏È¶èÊèê‰æõ‰∫Ü‰∏∞ÂØåÁöÑÁõëÁù£‰ø°Âè∑Ôºå‰ΩÜÂº∫ÊïôÂ∏àÁöÑËΩ®ËøπÂπ∂‰∏ç‰∏ÄÂÆöËÉΩ‰∫ßÁîüÊõ¥Â•ΩÁöÑÂ≠¶ÁîüÔºåÂº∫Ë∞É‰∫ÜÊï∞ÊçÆ‰∏éÂ≠¶ÁîüÈÄÇÁî®ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÈÄöËøáÂ≠¶ÁîüÁöÑÂèØËÉΩÊÄßÊù•ËØÑ‰º∞ÈÄÇÁî®ÊÄßÔºåÂÅèÂêë‰∫é‰∏éÊ®°ÂûãÂΩìÂâçË°å‰∏∫Á¥ßÂØÜÂØπÈΩêÁöÑËΩ®ËøπÔºåËÄåÂøΩËßÜ‰∫ÜÊõ¥ÂÖ∑‰ø°ÊÅØÈáèÁöÑËΩ®Ëøπ„ÄÇRSRÈÄöËøáÁªìÂêà‰ΩéÁªùÂØπÊ¶ÇÁéáÂíåÁõ∏ÂØπÈ´òÊéíÂêçÁöÑÊ†áËÆ∞ÔºåÂπ≥Ë°°Â≠¶‰π†‰ø°Âè∑Âº∫Â∫¶ÂíåË°å‰∏∫ÂØπÈΩêÔºåÂ±ïÁé∞Âá∫‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇ', title='ÂºïÂÖ•ÊéíÂêçÊÉäËÆ∂ÊØîÁéáÔºåÊèêÂçáÁü•ËØÜËí∏È¶èÊïàÊûú'))
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#training", "#security", "#leakage"], "emoji": "üîì", "ru": {"title": "–•—Ä—É–ø–∫–æ—Å—Ç—å –∞—Ç–∞–∫ –≤—ã–≤–æ–¥–∞ —á–ª–µ–Ω—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥ —Å–µ–º–∞–Ω—Ç–∏–∫–æ-—Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–º –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∞—Ç–∞–∫ –≤—ã–≤–æ–¥–∞ —á–ª–µ–Ω—Å—Ç–≤–∞ (MIA) –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä—Å–∫–∏–º –ø—Ä–∞–≤–æ–º —Ç–µ–∫—Å—Ç–∞ –ø
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#security", "#optimization", "#training", "#math"], "emoji": "üîê", "ru": {"title": "–§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å—é –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é –≤ DP-SGD", "desc": "–í —Å—Ç–∞—Ç—å–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ (DP-SGD) –≤ —Ä–∞–º–∫–∞—Ö f-–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –ø—Ä–∏
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#benchmark", "#training", "#agents", "#science"], "emoji": "üìö", "ru": {"title": "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ò–ò-–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –¥–ª—è –Ω–∞—É—á–Ω–æ–≥–æ –ø–∏—Å—å–º–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ METIS ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#long_context", "#hallucinations", "#synthetic", "#science"], "emoji": "üîç", "ru": {"title": "–í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –æ—à–∏–±–æ–∫: –∫–æ–≥–¥–∞ –∫–æ–¥ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–µ", "desc": "SciCoQA ‚Äî —ç—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –º–µ–∂–¥—É –æ–ø–∏—Å–∞–Ω–∏–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –≤ –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏—è—Ö –∏ –∏—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏
[21.01.2026 15:35] Using data from previous issue: {"categories": ["#healthcare", "#interpretability", "#ethics", "#benchmark", "#dataset", "#synthetic"], "emoji": "üîç", "ru": {"title": "–û–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø—Ä–∏—á–∏–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç—ã", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç LIBERTy ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–∏
[21.01.2026 15:35] Querying the API.
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

GRADFILTERING is an uncertainty-aware data selection framework for instruction tuning that uses gradient signal-to-noise ratio to improve LLM adaptation efficiency and performance.  					AI-generated summary 				 Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.
[21.01.2026 15:35] Response: ```json
{
  "desc": "GRADFILTERING ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–æ–Ω–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –∫ —à—É–º—É –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏. –ú–µ—Ç–æ–¥ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —à—É–º–∞ –∏ –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –∏–∑–±–µ–≥–∞—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–µ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ-–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–¥—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –Ω–µ–±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å-–ø—Ä–æ–∫—Å–∏ GPT-2 —Å –∞–Ω—Å–∞–º–±–ª–µ–º LoRA –∏ –∞–≥—Ä–µ–≥–∏—Ä—É—é—â–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ –º–µ—Ç—Ä–∏–∫—É Gradient Signal-to-Noise Ratio (G-SNR). –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ç–æ–ª—å–∫–æ —É–ª—É—á—à–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –æ—Ü–µ–Ω–∫–∞—Ö, –Ω–æ –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–º –±—é–¥–∂–µ—Ç–µ.",
  "emoji": "üéØ",
  "title": "–£–º–Ω—ã–π –æ—Ç–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM"
}
```
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"GRADFILTERING is an uncertainty-aware data selection framework for instruction tuning that uses gradient signal-to-noise ratio to improve LLM adaptation efficiency and performance.  					AI-generated summary 				 Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring."

[21.01.2026 15:35] Response: ```python
["DATA", "TRAINING", "SMALL_MODELS"]
```
[21.01.2026 15:35] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"GRADFILTERING is an uncertainty-aware data selection framework for instruction tuning that uses gradient signal-to-noise ratio to improve LLM adaptation efficiency and performance.  					AI-generated summary 				 Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring."

[21.01.2026 15:35] Response: ```python
["OPTIMIZATION", "INTERPRETABILITY"]
```

**Justification:**

1. **OPTIMIZATION**: The paper proposes GRADFILTERING, a data selection framework designed to improve training efficiency by selecting high-quality instruction tuning data. This directly addresses optimization of the training process by reducing computational costs and improving convergence speed.

2. **INTERPRETABILITY**: The paper explicitly mentions "a key source of LLM interpretability" and discusses using gradient signals and uncertainty estimation to understand which training examples are most valuable, which relates to analyzing and explaining model behavior.
[21.01.2026 15:35] Error. Failed to parse JSON from LLM. ["OPTIMIZATION", "INTERPRETABILITY"]


**Justification:**

1. **OPTIMIZATION**: The paper proposes GRADFILTERING, a data selection framework designed to improve training efficiency by selecting high-quality instruction tuning data. This directly addresses optimization of the training process by reducing computational costs and improving convergence speed.

2. **INTERPRETABILITY**: The paper explicitly mentions "a key source of LLM interpretability" and discusses using gradient signals and uncertainty estimation to understand which training examples are most valuable, which relates to analyzing and explaining model behavior.
[21.01.2026 15:35] Response: ParsedChatCompletionMessage[Article](content='{"desc":"GRADFILTERING is a new framework designed to select the best data for instruction tuning of large language models (LLMs) by focusing on uncertainty. It uses a measure called Gradient Signal-to-Noise Ratio (G-SNR) to evaluate the usefulness of each data point, which helps in identifying the most informative examples. This approach is more efficient than traditional methods that often rely on static scores or expensive data storage. As a result, GRADFILTERING not only improves the performance of LLMs but also speeds up the training process by selecting high-quality data subsets.","title":"Enhancing LLM Efficiency with Uncertainty-Aware Data Selection"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='GRADFILTERING is a new framework designed to select the best data for instruction tuning of large language models (LLMs) by focusing on uncertainty. It uses a measure called Gradient Signal-to-Noise Ratio (G-SNR) to evaluate the usefulness of each data point, which helps in identifying the most informative examples. This approach is more efficient than traditional methods that often rely on static scores or expensive data storage. As a result, GRADFILTERING not only improves the performance of LLMs but also speeds up the training process by selecting high-quality data subsets.', title='Enhancing LLM Efficiency with Uncertainty-Aware Data Selection'))
[21.01.2026 15:36] Response: ParsedChatCompletionMessage[Article](content='{"desc":"GRADFILTERINGÊòØ‰∏ÄÁßçÂÖ≥Ê≥®‰∏çÁ°ÆÂÆöÊÄßÁöÑÊï∞ÊçÆÊòæÁ§∫ÈÄâÊã©Ê°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈÄÇÂ∫îÊïàÁéáÂíåÊÄßËÉΩ„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®Â∞èÂûãGPT-2‰ª£ÁêÜÂíåLoRAÈõÜÊàêÔºåÂ∞ÜÊØè‰∏™Á§∫‰æãÁöÑÊ¢ØÂ∫¶ËÅöÂêàÊàêÊ¢ØÂ∫¶‰ø°Âô™ÊØîÔºàG-SNRÔºâÊïàÁî®Ôºå‰ªéËÄåÂÆûÁé∞Êï∞ÊçÆÈÄâÊã©„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåGRADFILTERINGÂú®Â§ßÂ§öÊï∞LLMËØÑ‰º∞‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÁîöËá≥Âú®‰∫∫Â∑•ËØÑ‰º∞‰∏≠‰πü‰ºò‰∫éÈöèÊú∫Â≠êÈõÜÂíåÂº∫Âü∫Á∫ø„ÄÇÈÄöËøáÂÖ≥Ê≥®‰∏çÁ°ÆÂÆöÊÄßËØÑÂàÜÔºåGRADFILTERINGÈÄâÊã©ÁöÑÂ≠êÈõÜÂú®Áõ∏ÂêåËÆ°ÁÆóÈ¢ÑÁÆó‰∏ãÊî∂ÊïõÈÄüÂ∫¶Êõ¥Âø´„ÄÇ","title":"GRADFILTERINGÔºöÊèêÂçáLLMÈÄÇÂ∫îÊÄßÁöÑÊô∫ËÉΩÊï∞ÊçÆÈÄâÊã©"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='GRADFILTERINGÊòØ‰∏ÄÁßçÂÖ≥Ê≥®‰∏çÁ°ÆÂÆöÊÄßÁöÑÊï∞ÊçÆÊòæÁ§∫ÈÄâÊã©Ê°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈÄÇÂ∫îÊïàÁéáÂíåÊÄßËÉΩ„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®Â∞èÂûãGPT-2‰ª£ÁêÜÂíåLoRAÈõÜÊàêÔºåÂ∞ÜÊØè‰∏™Á§∫‰æãÁöÑÊ¢ØÂ∫¶ËÅöÂêàÊàêÊ¢ØÂ∫¶‰ø°Âô™ÊØîÔºàG-SNRÔºâÊïàÁî®Ôºå‰ªéËÄåÂÆûÁé∞Êï∞ÊçÆÈÄâÊã©„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåGRADFILTERINGÂú®Â§ßÂ§öÊï∞LLMËØÑ‰º∞‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÁîöËá≥Âú®‰∫∫Â∑•ËØÑ‰º∞‰∏≠‰πü‰ºò‰∫éÈöèÊú∫Â≠êÈõÜÂíåÂº∫Âü∫Á∫ø„ÄÇÈÄöËøáÂÖ≥Ê≥®‰∏çÁ°ÆÂÆöÊÄßËØÑÂàÜÔºåGRADFILTERINGÈÄâÊã©ÁöÑÂ≠êÈõÜÂú®Áõ∏ÂêåËÆ°ÁÆóÈ¢ÑÁÆó‰∏ãÊî∂ÊïõÈÄüÂ∫¶Êõ¥Âø´„ÄÇ', title='GRADFILTERINGÔºöÊèêÂçáLLMÈÄÇÂ∫îÊÄßÁöÑÊô∫ËÉΩÊï∞ÊçÆÈÄâÊã©'))
[21.01.2026 15:36] Using data from previous issue: {"categories": ["#data", "#cv", "#benchmark", "#healthcare"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω—ã–π –≤—ã–±–æ—Ä: –∞–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è 3D —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ClaSP PE –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã
[21.01.2026 15:36] Using data from previous issue: {"categories": ["#multilingual", "#data", "#low_resource", "#dataset", "#open_source", "#synthetic"], "emoji": "üáπüá∑", "ru": {"title": "–ú–∞—Å—à—Ç–∞–±–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π —Ç—É—Ä–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞ —á–µ—Ä–µ–∑ –≥–∏–±—Ä–∏–¥–Ω—É—é –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª
[21.01.2026 15:36] Using data from previous issue: {"categories": [], "emoji": "üéØ", "ru": {"title": "–†–∞–∑–ª–∏—á–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –∞–Ω—Ç–æ–Ω–∏–º–æ–≤: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –±–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥—Ä–µ–π—Ñ–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–∞–∑–ª–∏—á–∞—Ç—å —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –∞–Ω—Ç–æ–Ω–∏–º—ã. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π
[21.01.2026 15:36] Renaming data file.
[21.01.2026 15:36] Renaming previous data. hf_papers.json to ./d/2026-01-21.json
[21.01.2026 15:36] Saving new data file.
[21.01.2026 15:36] Generating page.
[21.01.2026 15:36] Renaming previous page.
[21.01.2026 15:36] Renaming previous data. index.html to ./d/2026-01-21.html
[21.01.2026 15:36] Writing result.
[21.01.2026 15:36] Renaming log file.
[21.01.2026 15:36] Renaming previous data. log.txt to ./logs/2026-01-21_last_log.txt
