[21.01.2026 15:36] Read previous papers.
[21.01.2026 15:36] Generating top page (month).
[21.01.2026 15:36] Writing top page (month).
[21.01.2026 16:52] Read previous papers.
[21.01.2026 16:52] Get feed.
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12993
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11655
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14192
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13836
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14250
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11969
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13029
[21.01.2026 16:52] Extract page data from URL. URL: https://huggingface.co/papers/2601.14004
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11522
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12294
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13247
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.11888
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14232
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13288
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14251
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14249
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.14046
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13976
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12937
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10237
[21.01.2026 16:52] Extract page data from URL. URL: https://huggingface.co/papers/2601.14209
[21.01.2026 16:52] Extract page data from URL. URL: https://huggingface.co/papers/2601.13591
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13075
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.12910
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.10700
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13697
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13677
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13253
[21.01.2026 16:52] Get page data from previous paper. URL: https://huggingface.co/papers/2601.13251
[21.01.2026 16:52] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[21.01.2026 16:52] No deleted papers detected.
[21.01.2026 16:52] Downloading and parsing papers (pdf, html). Total: 29.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.12993.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.12993.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.12993.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.11655.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.11655.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.11655.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14192.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.14192.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.14192.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.13836.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.13836.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.13836.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14250.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.14250.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.14250.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.11969.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.11969.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.11969.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.13029.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.13029.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.13029.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14004.
[21.01.2026 16:52] Downloading paper 2601.14004 from https://arxiv.org/pdf/2601.14004v1...
[21.01.2026 16:52] Extracting affiliations from text.
[21.01.2026 16:52] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Locate, Steer, and Improve: Practical Survey of Actionable Mechanistic Interpretability in Large Language Models Hengyuan Zhang1, Zhihao Zhang2, Mingyang Wang3 Zunhai Su4 Yiwei Wang5 Qianli Wang6 Shuzhou Yuan7 Ercong Nie3 Xufeng Duan8 Qibo Xue9 Zeping Yu10 Chenming Shang11 Xiao Liang12 Jing Xiong1 Hui Shen13 Chaofan Tao1 Zhengwu Liu1 Senjie Jin2 Zhiheng Xi2 Dongdong Zhang14 Sophia Ananiadou10 Tao Gui2 Ruobing Xie Hayden Kwok-Hay So1 Hinrich Sch√ºtze3 Xuanjing Huang2 Qi Zhang2, Ngai Wong1, 1The University of Hong Kong 2Fudan University 3LMU Munich 4Tsinghua University 5Technische Universit√§t Darmstadt 6Technische Universit√§t Berlin 7Technische Universit√§t Dresden 8The Chinese University of Hong Kong 9Nanjing University 10University of Manchester 11Dartmouth College 12University of California, Los Angeles 13University of Michigan 14Microsoft 15Tencent Abstract: Mechanistic Interpretability (MI) has emerged as vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking systematic framework for actionable intervention. To bridge this gap, we present practical survey structured around the pipeline: Locate, Steer, and Improve. We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. With actionable mechanistic interpretability evolving at fast pace, we pledge to keep this survey up to date, ensuring it reflects the cutting-edge advances in this area. Equal Contribution Corresponding Author Keywords: Actionable Interpretability, Large Language Models, Localizing and Steering, Model Improvement Date: January 20, 2026 Gith"
[21.01.2026 16:52] Response: ```python
[
    "The University of Hong Kong",
    "Fudan University",
    "LMU Munich",
    "Tsinghua University",
    "Technische Universit√§t Darmstadt",
    "Technische Universit√§t Berlin",
    "Technische Universit√§t Dresden",
    "The Chinese University of Hong Kong",
    "Nanjing University",
    "University of Manchester",
    "Dartmouth College",
    "University of California, Los Angeles",
    "University of Michigan",
    "Microsoft",
    "Tencent"
]
```
[21.01.2026 16:52] Deleting PDF ./assets/pdf/2601.14004.pdf.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.11522.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.11522.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.11522.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.12294.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.12294.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.12294.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.13247.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.13247.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.13247.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.11888.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.11888.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.11888.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14232.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.14232.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.14232.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.13288.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.13288.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.13288.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14251.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.14251.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.14251.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14249.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.14249.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.14249.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14046.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.14046.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.14046.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.13976.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.13976.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.13976.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.12937.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.12937.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.12937.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.10237.
[21.01.2026 16:52] Extra JSON file exists (./assets/json/2601.10237.json), skip PDF parsing.
[21.01.2026 16:52] Paper image links file exists (./assets/img_data/2601.10237.json), skip HTML parsing.
[21.01.2026 16:52] Success.
[21.01.2026 16:52] Downloading and parsing paper https://huggingface.co/papers/2601.14209.
[21.01.2026 16:52] Downloading paper 2601.14209 from https://arxiv.org/pdf/2601.14209v1...
[21.01.2026 16:53] Extracting affiliations from text.
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning Matthew Y. R. Yang1, Hao Bai2, Ian Wu1, Gene Yang1, Amrith Setlur1 and Aviral Kumar1 1Carnegie Mellon University, 2University of Illinois Urbana-Champaign 6 2 0 2 0 2 ] . [ 1 9 0 2 4 1 . 1 0 6 2 : r Figure 1: Intervention training (InT) for improving credit assignment. InT proposes single-step interventions to replace incorrect intermediate steps in reasoning traces (1). Conditioned on these localized corrections, the model can generate counterfactual continuations that succeed where the original failed (2). We then perform supervised fine-tuning on these interventions, enabling effective credit assignment by upweighting the likelihood of the interventions in place of the mistakes. Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While natural remedy is to train process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying model-generated solution is easier than generating correct one from scratch, the model identifies the first error in its reasoning and proposes single-step intervention to redirect the tra"
[21.01.2026 16:53] Response: ```python
[
    "Carnegie Mellon University",
    "University of Illinois Urbana-Champaign"
]
```
[21.01.2026 16:53] Deleting PDF ./assets/pdf/2601.14209.pdf.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.13591.
[21.01.2026 16:53] Downloading paper 2601.13591 from https://arxiv.org/pdf/2601.13591v1...
[21.01.2026 16:53] Extracting affiliations from text.
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"6 2 0 2 0 2 ] . [ 1 1 9 5 3 1 . 1 0 6 2 : r DSAEval: Evaluating Data Science Agents on Wide Range of Real-World Data Science Problems Maojun Sun1* Yifei Xie1* Yue Wu1* Ruijian Han1 Binyan Jiang1 Defeng Sun2 Yancheng Yuan2 Jian Huang1,2 1Department of Data Science and Artificial Intelligence, Hong Kong Polytechnic University 2Department of Applied Mathematics, Hong Kong Polytechnic University "
[21.01.2026 16:53] Response: ```python
[
    "Department of Data Science and Artificial Intelligence, Hong Kong Polytechnic University",
    "Department of Applied Mathematics, Hong Kong Polytechnic University"
]
```
[21.01.2026 16:53] Deleting PDF ./assets/pdf/2601.13591.pdf.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.13075.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.13075.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.13075.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.12910.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.12910.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.12910.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.10700.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.10700.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.10700.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.13697.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.13697.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.13697.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.13677.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.13677.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.13677.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.13253.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.13253.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.13253.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Downloading and parsing paper https://huggingface.co/papers/2601.13251.
[21.01.2026 16:53] Extra JSON file exists (./assets/json/2601.13251.json), skip PDF parsing.
[21.01.2026 16:53] Paper image links file exists (./assets/img_data/2601.13251.json), skip HTML parsing.
[21.01.2026 16:53] Success.
[21.01.2026 16:53] Enriching papers with extra data.
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 0. Being-H0.5 is a Vision-Language-Action model that enables robust cross-embodiment generalization through human-centric learning and a Mixture-of-Transformers architecture with specialized embodiment handling.  					AI-generated summary 				 We introduce Being-H0.5, a foundational Vision-Language-Act...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 1. Large language models face significant challenges in software issue resolution, prompting the development of autonomous coding agents through various training-free and training-based methodologies.  					AI-generated summary 				 Issue resolution, a complex Software Engineering (SWE) task integral t...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 2. Efficiency in agentic systems is examined across memory, tool learning, and planning components, analyzing trade-offs between effectiveness and computational costs through various optimization strategies and benchmarks.  					AI-generated summary 				 Recent years have witnessed increasing interest ...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 3. FutureOmni presents the first benchmark for evaluating multimodal models' ability to forecast future events from audio-visual data, revealing current limitations and proposing an improved training strategy for better performance.  					AI-generated summary 				 Although Multimodal Large Language Mod...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 4. OmniTransfer presents a unified framework for spatio-temporal video transfer that enhances appearance consistency and temporal control through multi-view information and multimodal semantic guidance.  					AI-generated summary 				 Videos convey richer information than images or text, capturing both...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 5. A benchmark called MemoryRewardBench is introduced to systematically evaluate reward models' ability to assess long-term memory management in large language models across various context lengths and memory patterns.  					AI-generated summary 				 Existing works increasingly adopt memory-centric mec...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 6. Think3D enhances vision-language models' 3D reasoning capabilities by enabling interactive spatial exploration through 3D reconstruction and camera-based operations, improving performance without additional training.  					AI-generated summary 				 Understanding and reasoning about the physical worl...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 7. Mechanistic interpretability is presented as an actionable framework for understanding and optimizing large language models through systematic localization, steering, and improvement methods.  					AI-generated summary 				 Mechanistic Interpretability (MI) has emerged as a vital approach to demysti...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 8. UniX presents a unified medical foundation model that decouples visual understanding and generation tasks using distinct autoregressive and diffusion branches with cross-modal attention for enhanced performance.  					AI-generated summary 				 Despite recent progress, medical foundation models still...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 9. ToolPRMBench is introduced as a large-scale benchmark for evaluating process reward models in tool-using agents, featuring step-level test cases and multi-LLM verification to ensure data quality.  					AI-generated summary 				 Reward-guided search methods have demonstrated strong potential in enhan...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 10. WorldMind addresses the modal disconnect in LLMs by autonomously building a symbolic world knowledge repository that enhances physical feasibility and task optimality through experience-based learning.  					AI-generated summary 				 Current Large Language Models (LLMs) exhibit a critical modal disc...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 11. A novel retriever training framework for agentic search that uses both local relevance and global answer correctness metrics with iterative optimization between the search agent and retriever.  					AI-generated summary 				 Agentic search has recently emerged as a powerful paradigm, where an agent ...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 12. KAGE-Env is a JAX-native 2D platformer environment that isolates visual shifts from underlying control problems, enabling systematic analysis of visual generalization in reinforcement learning.  					AI-generated summary 				 Pixel-based reinforcement learning agents often fail under purely visual d...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 13. Lightweight probes trained on hidden states of LLMs enable efficient classification tasks without additional computational overhead, improving safety and sentiment analysis performance.  					AI-generated summary 				 Production LLM systems often rely on separate models for safety and other classifi...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 14. LightOnOCR-2-1B is a compact 1B-parameter vision-language model that performs end-to-end document image-to-text conversion with improved localization and robustness through specialized training techniques.  					AI-generated summary 				 We present LightOnOCR-2-1B, a 1B-parameter end-to-end multilin...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 15. Researchers introduce a novel metric called Rank-Surprisal Ratio (RSR) to better assess the suitability of reasoning trajectories for distilling knowledge from large language models, demonstrating superior performance compared to existing methods.  					AI-generated summary 				 Long chain-of-though...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 16. PRiSM benchmark evaluates phonetic perception in speech models through standardized transcription-based metrics and downstream applications across clinical, educational, and multilingual domains.  					AI-generated summary 				 Phone recognition (PR) serves as the atomic interface for language-agnos...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 17. FantasyVLN presents a unified implicit reasoning framework for vision-and-language navigation that enhances reasoning capabilities without explicit token overhead, achieving real-time performance with improved accuracy.  					AI-generated summary 				 Achieving human-level performance in Vision-and-...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 18. Membership inference attacks fail to reliably detect copyrighted text usage in large language models when training data is paraphrased using structure-aware methods that preserve semantic content.  					AI-generated summary 				 As large language models (LLMs) are trained on increasingly opaque corp...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 19. Differentially private stochastic gradient descent with shuffled sampling faces fundamental privacy-utility trade-offs that require substantial noise for meaningful privacy protection, limiting practical performance.  					AI-generated summary 				 Differentially Private Stochastic Gradient Descent ...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 20. Intervention Training improves large language model reasoning by enabling fine-grained credit assignment through targeted corrections that localize errors and enhance reinforcement learning performance.  					AI-generated summary 				 Outcome-reward reinforcement learning (RL) has proven effective a...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 21. A comprehensive benchmark for evaluating LLM-based data agents across diverse data science tasks demonstrates superior performance for multimodal agents while highlighting persistent challenges in unstructured data domains.  					AI-generated summary 				 Recent LLM-based data agents aim to automate...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 22. AI mentor METIS outperforms GPT-5 and Claude Sonnet 4.5 in supporting undergraduate research writing across multiple stages, with higher student scores and improved document-grounded outputs, though challenges remain in tool routing and stage classification.  					AI-generated summary 				 Many stud...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 23. SciCoQA is a dataset for identifying mismatches between scientific publications and code implementations, containing 611 discrepancies across multiple disciplines and demonstrating the challenge of detecting such issues even for advanced language models.  					AI-generated summary 				 We present Sc...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 24. A framework for generating structured counterfactual pairs using LLMs and SCMs enables improved evaluation and analysis of concept-based explanations in high-stakes domains.  					AI-generated summary 				 Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influ...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 25. GRADFILTERING is an uncertainty-aware data selection framework for instruction tuning that uses gradient signal-to-noise ratio to improve LLM adaptation efficiency and performance.  					AI-generated summary 				 Instruction tuning is a standard paradigm for adapting large language models (LLMs), bu...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 26. Class-stratified Scheduled Power Predictive Entropy (ClaSP PE) is a novel active learning strategy that improves 3D biomedical image segmentation by addressing class imbalance and selection redundancy through stratified querying and power noising with decay scheduling.  					AI-generated summary 			...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 27. A hybrid methodology combining FastText embeddings, clustering, and AI classification generates a large-scale Turkish semantic relations dataset with high accuracy validation.  					AI-generated summary 				 We present a hybrid methodology for generating large-scale semantic relationship datasets in...
[21.01.2026 16:53] ********************************************************************************
[21.01.2026 16:53] Abstract 28. A large-scale semantic clustering system addresses the limitation of neural embeddings in distinguishing synonyms from antonyms through a specialized three-way discriminator and novel clustering algorithm.  					AI-generated summary 				 Neural embeddings have a notorious blind spot: they can't reli...
[21.01.2026 16:53] Read previous papers.
[21.01.2026 16:53] Generating reviews via LLM API.
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#architecture", "#dataset", "#training", "#multimodal", "#robotics"], "emoji": "ü§ñ", "ru": {"title": "–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —è–∑—ã–∫ –¥–ª—è –≤—Å–µ—Ö —Ä–æ–±–æ—Ç–æ–≤: universal VLA —Å –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–º –æ–±–æ–±—â–µ–Ω–∏–µ–º", "desc": "Being-H0.5 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å Vision-Language-Action (VLA), —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è —Ä–æ–±–æ—Ç–æ—Ç
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#rl", "#benchmark", "#dataset", "#agents", "#data", "#training", "#open_source", "#plp", "#survey"], "emoji": "ü§ñ", "ru": {"title": "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –æ—à–∏–±–æ–∫", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∫–æ–¥–∏—Ä—É—é—â–∏—Ö –∞–≥–µ–Ω
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#rl", "#optimization", "#long_context", "#agents", "#benchmark"], "emoji": "‚ö°", "ru": {"title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º: –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∞–Ω–∞–ª–∏–∑–∏—Ä
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#audio", "#video", "#benchmark", "#dataset", "#training", "#multimodal"], "emoji": "üîÆ", "ru": {"title": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±—É–¥—É—â–µ–≥–æ: —É—á–∏–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ—Ç—å –∑–∞–≤—Ç—Ä–∞", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ FutureOmni ‚Äî –ø–µ—Ä–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å–∫–∞
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#video", "#transfer_learning", "#architecture", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ-–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ", "desc": "OmniTransfer –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞ –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø—Ä–æ—Å
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#long_context", "#survey", "#benchmark", "#dataset"], "emoji": "üß†", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏: –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω MemoryRewardBench ‚Äî –ø–µ—Ä–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#open_source", "#reasoning"], "emoji": "üßä", "ru": {"title": "–¢—Ä—ë—Ö–º–µ—Ä–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –¥–ª—è –≤–∏–¥–µ–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "Think3D ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—à–∏—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ-—è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –ø–æ–∑–≤–æ–ª—è—è –∏–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —á–µ—Ä–µ–∑ 3
[21.01.2026 16:53] Querying the API.
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Mechanistic interpretability is presented as an actionable framework for understanding and optimizing large language models through systematic localization, steering, and improvement methods.  					AI-generated summary 				 Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.
[21.01.2026 16:53] Response: ```json
{
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ö–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –∫–∞–∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å—Ö–µ–º—É, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ —Ç—Ä—ë—Ö —ç—Ç–∞–ø–∞—Ö: –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è (–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞), —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (–∏–Ω—Ç–µ—Ä–≤–µ–Ω—Ü–∏—è) –∏ —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π. –†–∞–±–æ—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –º–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞—Ç—å —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, –∫–∞–∫ –º–æ–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏, —É–ª—É—á—à–∞—è –∏—Ö –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ, —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.",
  "emoji": "üîç",
  "title": "–û—Ç –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∫ –¥–µ–π—Å—Ç–≤–∏—é: –ª–æ–∫–∞–ª–∏–∑—É–π, —É–ø—Ä–∞–≤–ª—è–π, —É–ª—É—á—à–∞–π"
}
```
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mechanistic interpretability is presented as an actionable framework for understanding and optimizing large language models through systematic localization, steering, and improvement methods.  					AI-generated summary 				 Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey."

[21.01.2026 16:53] Response: ```python
["TRAINING"]
```

The paper focuses on mechanistic interpretability as a framework for understanding and optimizing large language models through systematic methods for localization, steering, and improvement. This directly relates to improving model training and fine-tuning methods, which is the core concern of the TRAINING topic.
[21.01.2026 16:53] Error. Failed to parse JSON from LLM. ["TRAINING"]


The paper focuses on mechanistic interpretability as a framework for understanding and optimizing large language models through systematic methods for localization, steering, and improvement. This directly relates to improving model training and fine-tuning methods, which is the core concern of the TRAINING topic.
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Mechanistic interpretability is presented as an actionable framework for understanding and optimizing large language models through systematic localization, steering, and improvement methods.  					AI-generated summary 				 Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey."

[21.01.2026 16:53] Response: ```python
["INTERPRETABILITY", "ALIGNMENT", "SURVEY", "OPEN_SOURCE"]
```
[21.01.2026 16:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces Mechanistic Interpretability (MI) as a structured approach to enhance our understanding and optimization of Large Language Models (LLMs). It critiques existing methods for being too observational and proposes a systematic framework called \'Locate, Steer, and Improve\' for actionable interventions. The authors categorize techniques for diagnosing and intervening in LLMs based on specific Interpretable Objects, creating a clear protocol for improvements. By applying this framework, the paper demonstrates how to achieve better alignment, capability, and efficiency in LLMs, making MI a practical tool for model enhancement.","title":"Unlocking Large Language Models: Locate, Steer, Improve!"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc="This paper introduces Mechanistic Interpretability (MI) as a structured approach to enhance our understanding and optimization of Large Language Models (LLMs). It critiques existing methods for being too observational and proposes a systematic framework called 'Locate, Steer, and Improve' for actionable interventions. The authors categorize techniques for diagnosing and intervening in LLMs based on specific Interpretable Objects, creating a clear protocol for improvements. By applying this framework, the paper demonstrates how to achieve better alignment, capability, and efficiency in LLMs, making MI a practical tool for model enhancement.", title='Unlocking Large Language Models: Locate, Steer, Improve!'))
[21.01.2026 16:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú∫Ê¢∞ÂèØËß£ÈáäÊÄßÔºàMIÔºâÊòØ‰∏ÄÁßçÈáçË¶ÅÁöÑÊñπÊ≥ïÔºåÁî®‰∫éÁêÜËß£Âíå‰ºòÂåñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÂÜ≥Á≠ñËøáÁ®ã„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Á≥ªÁªüÂåñÁöÑÊ°ÜÊû∂ÔºåÂåÖÂê´ÂÆö‰Ωç„ÄÅÂºïÂØºÂíåÊîπËøõ‰∏â‰∏™Ê≠•È™§Ôºå‰ª•‰æøÂØπÊ®°ÂûãËøõË°åÊúâÊïàÂπ≤È¢Ñ„ÄÇÊàë‰ª¨Â∞ÜÂÆö‰ΩçÔºàËØäÊñ≠ÔºâÂíåÂºïÂØºÔºàÂπ≤È¢ÑÔºâÊñπÊ≥ïËøõË°åÊ≠£ÂºèÂàÜÁ±ªÔºå‰ª•Âª∫Á´ã‰∏•Ê†ºÁöÑÂπ≤È¢ÑÂçèËÆÆ„ÄÇÈÄöËøáËøô‰∏™Ê°ÜÊû∂ÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØπÈΩê„ÄÅËÉΩÂäõÂíåÊïàÁéáÊñπÈù¢ÂÆûÁé∞ÂÆûÈôÖÊîπËøõÔºå‰ªéËÄåÂ∞ÜMIËΩ¨Âåñ‰∏∫ÂèØÊìç‰ΩúÁöÑÊ®°Âûã‰ºòÂåñÊñπÊ≥ï„ÄÇ","title":"Êú∫Ê¢∞ÂèØËß£ÈáäÊÄßÔºö‰ºòÂåñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúâÊïàÊ°ÜÊû∂"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú∫Ê¢∞ÂèØËß£ÈáäÊÄßÔºàMIÔºâÊòØ‰∏ÄÁßçÈáçË¶ÅÁöÑÊñπÊ≥ïÔºåÁî®‰∫éÁêÜËß£Âíå‰ºòÂåñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÂÜ≥Á≠ñËøáÁ®ã„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Á≥ªÁªüÂåñÁöÑÊ°ÜÊû∂ÔºåÂåÖÂê´ÂÆö‰Ωç„ÄÅÂºïÂØºÂíåÊîπËøõ‰∏â‰∏™Ê≠•È™§Ôºå‰ª•‰æøÂØπÊ®°ÂûãËøõË°åÊúâÊïàÂπ≤È¢Ñ„ÄÇÊàë‰ª¨Â∞ÜÂÆö‰ΩçÔºàËØäÊñ≠ÔºâÂíåÂºïÂØºÔºàÂπ≤È¢ÑÔºâÊñπÊ≥ïËøõË°åÊ≠£ÂºèÂàÜÁ±ªÔºå‰ª•Âª∫Á´ã‰∏•Ê†ºÁöÑÂπ≤È¢ÑÂçèËÆÆ„ÄÇÈÄöËøáËøô‰∏™Ê°ÜÊû∂ÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØπÈΩê„ÄÅËÉΩÂäõÂíåÊïàÁéáÊñπÈù¢ÂÆûÁé∞ÂÆûÈôÖÊîπËøõÔºå‰ªéËÄåÂ∞ÜMIËΩ¨Âåñ‰∏∫ÂèØÊìç‰ΩúÁöÑÊ®°Âûã‰ºòÂåñÊñπÊ≥ï„ÄÇ', title='Êú∫Ê¢∞ÂèØËß£ÈáäÊÄßÔºö‰ºòÂåñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊúâÊïàÊ°ÜÊû∂'))
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#diffusion", "#training", "#data", "#architecture", "#open_source", "#multimodal", "#healthcare"], "emoji": "ü´Ä", "ru": {"title": "–°–∏–Ω–µ—Ä–≥–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏—è: —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ –≤–µ—Ç–≤–∏ –¥–ª—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", "desc": "UniX ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –º–æ–¥–µ–ª—å-—Ñ—É–Ω–¥–∞
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#dataset", "#rl"], "emoji": "üîß", "ru": {"title": "–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ ToolPRMBench ‚Äî –º–∞—Å—à—Ç–∞–±–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ —à–∞–≥–æ–≤
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#transfer_learning", "#alignment", "#hallucinations", "#reasoning"], "emoji": "üåç", "ru": {"title": "–ì—Äounded –º–∏—Ä –¥–ª—è LLM: –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –∫ —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –æ—Å—É—â–µ—Å—Ç–≤–∏–º—ã–º –ø–ª–∞–Ω–∞–º", "desc": "WorldMind —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –º–æ–¥–∞–ª—å–Ω–æ–π —Ä–∞—Å—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –ø—É—Ç—ë–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#agents", "#benchmark", "#training", "#rag"], "emoji": "üîÑ", "ru": {"title": "–î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞ –∏ –ø–æ–∏—Å–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—èÊ°ÜÊû∂ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è retriever'–∞, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–æ–≤. 
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#optimization", "#cv", "#games", "#benchmark", "#rl"], "emoji": "üéÆ", "ru": {"title": "–ß–∏—Å—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ–±–æ–±—â–∞–µ–º–æ—Å—Ç–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –Ω–∞–±–ª—é–¥–µ–Ω–∏–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ KAGE-Env ‚Äî —Å—Ä–µ–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ JAX, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#training", "#inference", "#small_models"], "emoji": "üîç", "ru": {"title": "–õ—ë–≥–∫–∏–µ –∑–æ–Ω–¥—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π LLM –±–µ–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –ª—ë–≥–∫–∏—Ö –∑–æ–Ω–¥–æ–≤ (probes) –Ω–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#training", "#multimodal", "#small_models", "#dataset", "#cv", "#multilingual", "#benchmark"], "emoji": "üìÑ", "ru": {"title": "–õ—ë–≥–∫–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Å –µ–¥–∏–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω LightOnOCR-2-1B ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è vision-language –º–æ–¥–µ–ª—å —Å 1 –º
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#data", "#training", "#reasoning", "#transfer_learning"], "emoji": "üéØ", "ru": {"title": "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –Ω–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Rank-Surprisal Ratio (RSR) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–µ–∫—Ç–æ
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#open_source", "#audio", "#dataset", "#low_resource", "#multilingual", "#benchmark"], "emoji": "üî§", "ru": {"title": "–ì–ª—É–±–æ–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö —Ä–µ—á–µ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –±–µ–Ω—á–º–∞—Ä–∫ PRiSM –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è —Ñ–æ–Ω–µ—Ç–∏–∫–∏ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö —Ä–∞—Å–ø–æ
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#training", "#agents", "#interpretability", "#multimodal", "#reasoning", "#architecture"], "emoji": "üß≠", "ru": {"title": "–°–∫—Ä—ã—Ç–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", "desc": "FantasyVLN –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∑—Ä–µ–Ω–∏—è
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#training", "#security", "#leakage"], "emoji": "üîì", "ru": {"title": "–•—Ä—É–ø–∫–æ—Å—Ç—å –∞—Ç–∞–∫ –≤—ã–≤–æ–¥–∞ —á–ª–µ–Ω—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥ —Å–µ–º–∞–Ω—Ç–∏–∫–æ-—Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–º –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∞—Ç–∞–∫ –≤—ã–≤–æ–¥–∞ —á–ª–µ–Ω—Å—Ç–≤–∞ (MIA) –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä—Å–∫–∏–º –ø—Ä–∞–≤–æ–º —Ç–µ–∫—Å—Ç–∞ –ø
[21.01.2026 16:53] Using data from previous issue: {"categories": ["#security", "#optimization", "#training", "#math"], "emoji": "üîê", "ru": {"title": "–§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å—é –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é –≤ DP-SGD", "desc": "–í —Å—Ç–∞—Ç—å–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ (DP-SGD) –≤ —Ä–∞–º–∫–∞—Ö f-–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –ø—Ä–∏
[21.01.2026 16:53] Querying the API.
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Intervention Training improves large language model reasoning by enabling fine-grained credit assignment through targeted corrections that localize errors and enhance reinforcement learning performance.  					AI-generated summary 				 Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.
[21.01.2026 16:53] Response: ```json
{
  "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç Intervention Training (InT) ‚Äî –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö —á–µ—Ä–µ–∑ —É—Å–∏–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ reinforcement learning —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –Ω–∞–≥—Ä–∞–¥—É —Ç–æ–ª—å–∫–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, —à—Ç—Ä–∞—Ñ—É—è –≤—Å–µ —ç—Ç–∞–ø—ã —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏ –ø–æ–æ—â—Ä—è—è –∏—Ö –ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ—à–∏–±–∫–∞–º –≤ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–∏ –∫—Ä–µ–¥–∏—Ç–∞. InT —Ä–µ—à–∞–µ—Ç —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É, –∑–∞—Å—Ç–∞–≤–ª—è—è –º–æ–¥–µ–ª—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞, –ø—Ä–µ–¥–ª–∞–≥–∞—è —Ü–µ–ª–µ–≤—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –≤ —Å–≤–æ–∏—Ö —Ü–µ–ø–æ—á–∫–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–∞—á–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —à–∞–≥–µ, –≤—ã–∑–≤–∞–≤—à–µ–º —Å–±–æ–π. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞ –∫ –º–æ–¥–µ–ª—è–º –ø–æ–∫–∞–∑–∞–ª–æ —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ 14% –∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–º–∏ –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –≤ –∑–∞–¥–∞—á–∞—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.",
  "emoji": "üéØ",
  "title": "–¢–æ—á–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –æ—à–∏–±–∫–∏ –≤ —Ü–µ–ø–æ—á–∫–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π"
}
```
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Intervention Training improves large language model reasoning by enabling fine-grained credit assignment through targeted corrections that localize errors and enhance reinforcement learning performance.  					AI-generated summary 				 Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b."

[21.01.2026 16:53] Response: ```python
["RL", "TRAINING", "SMALL_MODELS"]
```
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Intervention Training improves large language model reasoning by enabling fine-grained credit assignment through targeted corrections that localize errors and enhance reinforcement learning performance.  					AI-generated summary 				 Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b."

[21.01.2026 16:53] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[21.01.2026 16:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Intervention Training (InT) enhances the reasoning abilities of large language models (LLMs) by allowing them to assign credit more precisely during their reasoning processes. Traditional reinforcement learning (RL) methods penalize entire reasoning paths for incorrect answers, which can discourage correct steps and reinforce incorrect ones. InT addresses this by enabling models to identify and correct specific errors in their reasoning, using targeted interventions that guide them towards better solutions. This approach leads to significant improvements in model performance, achieving nearly 14% higher accuracy on benchmark tasks compared to larger models.","title":"Fine-Grained Credit Assignment for Better Reasoning in LLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Intervention Training (InT) enhances the reasoning abilities of large language models (LLMs) by allowing them to assign credit more precisely during their reasoning processes. Traditional reinforcement learning (RL) methods penalize entire reasoning paths for incorrect answers, which can discourage correct steps and reinforce incorrect ones. InT addresses this by enabling models to identify and correct specific errors in their reasoning, using targeted interventions that guide them towards better solutions. This approach leads to significant improvements in model performance, achieving nearly 14% higher accuracy on benchmark tasks compared to larger models.', title='Fine-Grained Credit Assignment for Better Reasoning in LLMs'))
[21.01.2026 16:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Âπ≤È¢ÑËÆ≠ÁªÉÔºàIntervention TrainingÔºâÈÄöËøáÈíàÂØπÊÄß‰øÆÊ≠£Êù•ÊîπÂñÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üËøõË°åÁªÜÁ≤íÂ∫¶ÁöÑ‰ø°Áî®ÂàÜÈÖç„ÄÇ‰º†ÁªüÁöÑÂº∫ÂåñÂ≠¶‰π†Âú®ÁªìÊûúÈîôËØØÊó∂Âè™ÂØπÊúÄÁªàÁ≠îÊ°àËøõË°åÊÉ©ÁΩöÔºåÂØºËá¥Êï¥‰∏™Êé®ÁêÜËøáÁ®ãÂèóÂà∞ÂΩ±ÂìçÔºåËÄåÂú®ÁªìÊûúÊ≠£Á°ÆÊó∂ÂàôÂØπÊâÄÊúâÊ≠•È™§ËøõË°åÁªü‰∏ÄÂº∫Âåñ„ÄÇÂπ≤È¢ÑËÆ≠ÁªÉÈÄöËøáËÆ©Ê®°ÂûãËØÜÂà´Êé®ÁêÜ‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ÈîôËØØÂπ∂ÊèêÂá∫ÂçïÊ≠•Âπ≤È¢ÑÔºåÊù•ÂºïÂØºÊé®ÁêÜËΩ®ËøπÊúùÂêëÊõ¥È´òÁöÑÂ•ñÂä±„ÄÇÁªèËøáÂπ≤È¢ÑËÆ≠ÁªÉÂíåÂêéÁª≠ÁöÑÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÂêéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®IMO-AnswerBench‰∏äÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜËøë14%„ÄÇ","title":"Âπ≤È¢ÑËÆ≠ÁªÉÔºöÊèêÂçáÊé®ÁêÜËÉΩÂäõÁöÑÂÖ≥ÈîÆ"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Âπ≤È¢ÑËÆ≠ÁªÉÔºàIntervention TrainingÔºâÈÄöËøáÈíàÂØπÊÄß‰øÆÊ≠£Êù•ÊîπÂñÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üËøõË°åÁªÜÁ≤íÂ∫¶ÁöÑ‰ø°Áî®ÂàÜÈÖç„ÄÇ‰º†ÁªüÁöÑÂº∫ÂåñÂ≠¶‰π†Âú®ÁªìÊûúÈîôËØØÊó∂Âè™ÂØπÊúÄÁªàÁ≠îÊ°àËøõË°åÊÉ©ÁΩöÔºåÂØºËá¥Êï¥‰∏™Êé®ÁêÜËøáÁ®ãÂèóÂà∞ÂΩ±ÂìçÔºåËÄåÂú®ÁªìÊûúÊ≠£Á°ÆÊó∂ÂàôÂØπÊâÄÊúâÊ≠•È™§ËøõË°åÁªü‰∏ÄÂº∫Âåñ„ÄÇÂπ≤È¢ÑËÆ≠ÁªÉÈÄöËøáËÆ©Ê®°ÂûãËØÜÂà´Êé®ÁêÜ‰∏≠ÁöÑÁ¨¨‰∏Ä‰∏™ÈîôËØØÂπ∂ÊèêÂá∫ÂçïÊ≠•Âπ≤È¢ÑÔºåÊù•ÂºïÂØºÊé®ÁêÜËΩ®ËøπÊúùÂêëÊõ¥È´òÁöÑÂ•ñÂä±„ÄÇÁªèËøáÂπ≤È¢ÑËÆ≠ÁªÉÂíåÂêéÁª≠ÁöÑÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÂêéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®IMO-AnswerBench‰∏äÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜËøë14%„ÄÇ', title='Âπ≤È¢ÑËÆ≠ÁªÉÔºöÊèêÂçáÊé®ÁêÜËÉΩÂäõÁöÑÂÖ≥ÈîÆ'))
[21.01.2026 16:53] Querying the API.
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A comprehensive benchmark for evaluating LLM-based data agents across diverse data science tasks demonstrates superior performance for multimodal agents while highlighting persistent challenges in unstructured data domains.  					AI-generated summary 				 Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.
[21.01.2026 16:53] Response: ```json
{
  "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω DSAEval ‚Äî –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ LLM-based –∞–≥–µ–Ω—Ç–æ–≤, –≤—ã–ø–æ–ª–Ω—è—é—â–∏—Ö –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ 641 —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã –∏ 285 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤. –ë–µ–Ω—á–º–∞—Ä–∫ –≤–∫–ª—é—á–∞–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–µ —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –∞ —Ç–∞–∫–∂–µ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É, –æ—Ö–≤–∞—Ç—ã–≤–∞—é—â—É—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ–¥ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–æ—Å—Ç–∏–≥–∞—é—Ç –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, —É–ª—É—á—à–∞—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ 2-11%, –ø—Ä–∏—á—ë–º Claude-Sonnet-4.5 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–µ –æ–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏. –û–¥–Ω–∞–∫–æ –≤—ã—è–≤–ª–µ–Ω—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è data science –∞–≥–µ–Ω—Ç–æ–≤.",
  "emoji": "üìä",
  "title": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç –≤ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –±–æ—Ä—é—Ç—Å—è —Å –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"
}
```
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A comprehensive benchmark for evaluating LLM-based data agents across diverse data science tasks demonstrates superior performance for multimodal agents while highlighting persistent challenges in unstructured data domains.  					AI-generated summary 				 Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents."

[21.01.2026 16:53] Response: ```python
['BENCHMARK', 'AGENTS', 'MULTIMODAL', 'DATASET']
```
[21.01.2026 16:53] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"A comprehensive benchmark for evaluating LLM-based data agents across diverse data science tasks demonstrates superior performance for multimodal agents while highlighting persistent challenges in unstructured data domains.  					AI-generated summary 				 Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents."

[21.01.2026 16:53] Response: ```python
['SURVEY', 'REASONING']
```
[21.01.2026 16:53] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents DSAEval, a benchmark designed to evaluate large language model (LLM)-based data agents on a variety of real-world data science tasks. It highlights the superior performance of multimodal agents, which can process both text and visual data, while also addressing the ongoing challenges faced in unstructured data environments. The benchmark includes 641 problems across 285 datasets, emphasizing the need for agents to handle complex, open-ended data science scenarios. The findings reveal that while current agents excel in structured data tasks, there is still significant room for improvement in unstructured data domains.","title":"Unlocking the Power of Multimodal Data Agents in Data Science"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents DSAEval, a benchmark designed to evaluate large language model (LLM)-based data agents on a variety of real-world data science tasks. It highlights the superior performance of multimodal agents, which can process both text and visual data, while also addressing the ongoing challenges faced in unstructured data environments. The benchmark includes 641 problems across 285 datasets, emphasizing the need for agents to handle complex, open-ended data science scenarios. The findings reveal that while current agents excel in structured data tasks, there is still significant room for improvement in unstructured data domains.', title='Unlocking the Power of Multimodal Data Agents in Data Science'))
[21.01.2026 16:54] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Êú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™Âêç‰∏∫DSAEvalÁöÑÂü∫ÂáÜÊµãËØïÔºåÁî®‰∫éËØÑ‰º∞Âü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊï∞ÊçÆ‰ª£ÁêÜÂú®Â§öÁßçÊï∞ÊçÆÁßëÂ≠¶‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇËØ•Âü∫ÂáÜÂåÖÂê´641‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑÊï∞ÊçÆÁßëÂ≠¶ÈóÆÈ¢òÔºåÊ∂µÁõñ285‰∏™Â§öÊ†∑ÂåñÁöÑÊï∞ÊçÆÈõÜÔºåÂåÖÊã¨ÁªìÊûÑÂåñÂíåÈùûÁªìÊûÑÂåñÊï∞ÊçÆ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂ§öÊ®°ÊÄÅ‰ª£ÁêÜÂú®ËßÜËßâÁõ∏ÂÖ≥‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòË∂äÔºåÊèêÂçáÂπÖÂ∫¶Âú®2.04%Âà∞11.30%‰πãÈó¥„ÄÇÂ∞ΩÁÆ°ÂΩìÂâçÁöÑÊï∞ÊçÆÁßëÂ≠¶‰ª£ÁêÜÂú®ÁªìÊûÑÂåñÊï∞ÊçÆÂíåÂ∏∏ËßÑÊï∞ÊçÆÂàÜÊûêÂ∑•‰ΩúÊµÅ‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®ÈùûÁªìÊûÑÂåñÈ¢ÜÂüü‰ªçÈù¢‰∏¥ÈáçÂ§ßÊåëÊàò„ÄÇ","title":"Â§öÊ®°ÊÄÅ‰ª£ÁêÜÊèêÂçáÊï∞ÊçÆÁßëÂ≠¶‰ªªÂä°Ë°®Áé∞"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Êú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™Âêç‰∏∫DSAEvalÁöÑÂü∫ÂáÜÊµãËØïÔºåÁî®‰∫éËØÑ‰º∞Âü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊï∞ÊçÆ‰ª£ÁêÜÂú®Â§öÁßçÊï∞ÊçÆÁßëÂ≠¶‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇËØ•Âü∫ÂáÜÂåÖÂê´641‰∏™ÁúüÂÆû‰∏ñÁïåÁöÑÊï∞ÊçÆÁßëÂ≠¶ÈóÆÈ¢òÔºåÊ∂µÁõñ285‰∏™Â§öÊ†∑ÂåñÁöÑÊï∞ÊçÆÈõÜÔºåÂåÖÊã¨ÁªìÊûÑÂåñÂíåÈùûÁªìÊûÑÂåñÊï∞ÊçÆ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂ§öÊ®°ÊÄÅ‰ª£ÁêÜÂú®ËßÜËßâÁõ∏ÂÖ≥‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòË∂äÔºåÊèêÂçáÂπÖÂ∫¶Âú®2.04%Âà∞11.30%‰πãÈó¥„ÄÇÂ∞ΩÁÆ°ÂΩìÂâçÁöÑÊï∞ÊçÆÁßëÂ≠¶‰ª£ÁêÜÂú®ÁªìÊûÑÂåñÊï∞ÊçÆÂíåÂ∏∏ËßÑÊï∞ÊçÆÂàÜÊûêÂ∑•‰ΩúÊµÅ‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®ÈùûÁªìÊûÑÂåñÈ¢ÜÂüü‰ªçÈù¢‰∏¥ÈáçÂ§ßÊåëÊàò„ÄÇ', title='Â§öÊ®°ÊÄÅ‰ª£ÁêÜÊèêÂçáÊï∞ÊçÆÁßëÂ≠¶‰ªªÂä°Ë°®Áé∞'))
[21.01.2026 16:54] Using data from previous issue: {"categories": ["#benchmark", "#training", "#agents", "#science"], "emoji": "üìö", "ru": {"title": "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ò–ò-–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –¥–ª—è –Ω–∞—É—á–Ω–æ–≥–æ –ø–∏—Å—å–º–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ METIS ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞
[21.01.2026 16:54] Using data from previous issue: {"categories": ["#long_context", "#hallucinations", "#synthetic", "#science"], "emoji": "üîç", "ru": {"title": "–í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –æ—à–∏–±–æ–∫: –∫–æ–≥–¥–∞ –∫–æ–¥ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–µ", "desc": "SciCoQA ‚Äî —ç—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –º–µ–∂–¥—É –æ–ø–∏—Å–∞–Ω–∏–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –≤ –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏—è—Ö –∏ –∏—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏
[21.01.2026 16:54] Using data from previous issue: {"categories": ["#healthcare", "#interpretability", "#ethics", "#benchmark", "#dataset", "#synthetic"], "emoji": "üîç", "ru": {"title": "–û–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø—Ä–∏—á–∏–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç—ã", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç LIBERTy ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–∏
[21.01.2026 16:54] Using data from previous issue: {"categories": ["#data", "#training", "#small_models"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω—ã–π –æ—Ç–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM", "desc": "GRADFILTERING ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–æ–Ω–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω
[21.01.2026 16:54] Using data from previous issue: {"categories": ["#data", "#cv", "#benchmark", "#healthcare"], "emoji": "üéØ", "ru": {"title": "–£–º–Ω—ã–π –≤—ã–±–æ—Ä: –∞–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è 3D —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ClaSP PE –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ç—Ä—ë—Ö–º–µ—Ä–Ω—ã—Ö –±–∏–æ–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã
[21.01.2026 16:54] Using data from previous issue: {"categories": ["#multilingual", "#data", "#low_resource", "#dataset", "#open_source", "#synthetic"], "emoji": "üáπüá∑", "ru": {"title": "–ú–∞—Å—à—Ç–∞–±–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π —Ç—É—Ä–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞ —á–µ—Ä–µ–∑ –≥–∏–±—Ä–∏–¥–Ω—É—é –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª
[21.01.2026 16:54] Using data from previous issue: {"categories": [], "emoji": "üéØ", "ru": {"title": "–†–∞–∑–ª–∏—á–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –∞–Ω—Ç–æ–Ω–∏–º–æ–≤: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –±–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥—Ä–µ–π—Ñ–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–∞–∑–ª–∏—á–∞—Ç—å —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –∞–Ω—Ç–æ–Ω–∏–º—ã. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π
[21.01.2026 16:54] Renaming data file.
[21.01.2026 16:54] Renaming previous data. hf_papers.json to ./d/2026-01-21.json
[21.01.2026 16:54] Saving new data file.
[21.01.2026 16:54] Generating page.
[21.01.2026 16:54] Renaming previous page.
[21.01.2026 16:54] Renaming previous data. index.html to ./d/2026-01-21.html
[21.01.2026 16:54] Writing result.
[21.01.2026 16:54] Renaming log file.
[21.01.2026 16:54] Renaming previous data. log.txt to ./logs/2026-01-21_last_log.txt
