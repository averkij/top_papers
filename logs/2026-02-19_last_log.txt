[19.02.2026 17:45] Read previous papers.
[19.02.2026 17:45] Generating top page (month).
[19.02.2026 17:45] Writing top page (month).
[19.02.2026 18:48] Read previous papers.
[19.02.2026 18:48] Get feed.
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.12675
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16705
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.14979
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.14080
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16317
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16008
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15922
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16301
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15989
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16666
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16493
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.07345
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.16682
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.15927
[19.02.2026 18:48] Extract page data from URL. URL: https://huggingface.co/papers/2602.16704
[19.02.2026 18:48] Get page data from previous paper. URL: https://huggingface.co/papers/2602.08392
[19.02.2026 18:48] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[19.02.2026 18:48] No deleted papers detected.
[19.02.2026 18:48] Downloading and parsing papers (pdf, html). Total: 16.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.12675.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.12675.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.12675.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16705.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16705.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16705.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.14979.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.14979.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.14979.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.14080.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.14080.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.14080.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16317.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16317.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16317.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16008.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16008.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16008.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.15922.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.15922.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.15922.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16301.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16301.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16301.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.15989.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.15989.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.15989.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16666.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16666.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16666.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16493.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16493.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16493.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.07345.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.07345.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.07345.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16682.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.16682.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.16682.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.15927.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.15927.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.15927.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.16704.
[19.02.2026 18:48] Downloading paper 2602.16704 from https://arxiv.org/pdf/2602.16704v1...
[19.02.2026 18:48] Extracting affiliations from text.
[19.02.2026 18:48] Claude request. Model: claude-haiku-4-5. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Reinforced Fast Weights with Next-Sequence Prediction Hee Seung Hwang * Xindi Wu * Sanghyuk Chun Olga Russakovsky 6 2 0 2 8 1 ] . [ 1 4 0 7 6 1 . 2 0 6 2 : r a "
[19.02.2026 18:48] Response: ```python
[]
```
[19.02.2026 18:48] Extracting affiliations from text.
[19.02.2026 18:48] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Reinforced Fast Weights with Next-Sequence Prediction Hee Seung Hwang * Xindi Wu * Sanghyuk Chun Olga Russakovsky6 2 0 2 8 1 ] . [ 1 4 0 7 6 1 . 2 0 6 2 : r aFast weight architectures offer promising alternative to attention-based transformers for longcontext modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns selfsupervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, longcontext question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures. Our code is publicly available. *Equal contribution . Correspondence to: Hee Seung Hwang <hee.h@princeton.edu>. Figure 1. Comparison of standard NTP and REFINE. Standard NTP (top) computes cross-entropy loss at each token position, providing only token-level supervision to fast weight models. REFINE (bottom) provides sequence-level supervision by generating multi-token rollouts at high-entropy positions, assigning sequencelevel rewards from hidden states, and optimizing with RL. 1. Introduction Long-context modeling has become essential for large language models (LLMs). Tasks such as long-document understanding (Shaham et al., 2022; Dong et al., 2024), many-shot in-context learning (Agarwal et al., 2024; Li et al., 2024), and code generation (Liu et al., 2023; Nichols et al., 2024) require models to extract, store, and reuse information from contexts spanning thousands of tokens (Yen et al., 2024; Bai et al., 2024; 2025). While attention-based transformers demonstrate strong performance on these tasks, their computational and memory costs scale quadratically (Keles et al., 2023) with context length, creating fundamental bottleneck for both training and inference. Fast weight architectures offer promising alternative by addressing this scaling problem through structural changes to the transformer block. Models such as DeltaNet (Yang et al., 2024), GatedDeltaNet (Yang et al., 2025), and LaCT (Zhang et al., 2025) replace global attention with fixed-size memory that is dynamically updated as new tokens are processed, storing contextual information directly in model parameters 1 Reinforced Fast Weights with Next-Sequence Prediction  (Fig. 2)  . This design enables efficient inference with constant memory overhead regardless of context length (Tandon et al., 2025). Despite their architectural differences, fast weight models are typically pre-trained with the same next-token prediction (NTP) objective used for standard transformer LLMs (Sun et al., 2024; Behrouz et al., 2024; 2025a; Yang et al., 2024; 2025; Zhang et al., 2025). In this work, we argue that NTP is suboptimal objective for fast weight models. The NTP objective only has an immediate effect on the next token and disregards the quality of subsequent predictions that depend on the same internal state (Gloeckle et al., 2024). As result, NTPs token-level feedback encourages parameter updates that optimize only short-term likelihood, limiting the adaptive capacity of fast weights and model behavior over longer horizons. To better align the training objective with the intended function of fast weights as long-context memory, we propose the next-sequence prediction (NSP) objective as variation of NTP. NSP encourages model to predict semantically coherent sequence of future tokens conditioned on given prefix. This objective directly reflects whether the information stored in fast weights enables accurate continuation over multiple steps, providing more appropriate training signal for long-context adaptation compared to the standard NTP. However, training with NSP introduces two key challenges: (i) standard cross-entropy loss does not naturally extend to multi-token prediction without explicitly generating full continuations, and (ii) generating multiple tokens for every prefix is computationally prohibitive for long contexts. We address these challenges by formulating NSP as reinforcement learning (RL) problem: model is trained to maximize sequence-level rewards derived from its predictions. Our method focuses on informative regions of the context and optimizes for NSP using policy gradient updates. Empirically, we show that RL for NSP yields superior fast weight initialization and consistently outperforms pure supervised fine-tuning (SFT) under the NTP objective. We introduce Reinforced Fast Weights with Next Sequence Prediction (REFINE), phase-agnostic framework that can be applied in multiple stages of the language model training lifecycle (Tab. 1). We demonstrate the effectiveness of REFINE in three stages: (i) mid-training, where we reinforce fast weight models on pretraining-like corpora to improve long-context adaptation; (ii) post-training, where RL is integrated into task-specific training loops to refine fast weights under downstream supervision; and (iii) test-time training, where REFINE reinforces fast weights directly on the prompt without additional labels. Our experiments show that REFINE improves fast weight initialization in all three settings. For example, applying 2 Figure 2. Comparison of Standard Transformer and Fast Weight Models, adapted from Zhang et al. (2025). Fast weight models replace attention with fixed-size memory implemented as weight matrix (W ), and updated according to Eq. (1). REFINE on LaCT-760M notably improves the average performance on RULER (Hsieh et al., 2024) long-context QA tasks by 8."
[19.02.2026 18:48] Mistral response. {"id": "4bfc8447f3284c4a9ff8476bff9f4084", "created": 1771526907, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1455, "total_tokens": 1465, "completion_tokens": 10, "prompt_tokens_details": {"cached_tokens": 0}}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[\"Princeton University\"]\n```"}}]}
[19.02.2026 18:48] Response: ```python
["Princeton University"]
```
[19.02.2026 18:48] Deleting PDF ./assets/pdf/2602.16704.pdf.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Downloading and parsing paper https://huggingface.co/papers/2602.08392.
[19.02.2026 18:48] Extra JSON file exists (./assets/json/2602.08392.json), skip PDF parsing.
[19.02.2026 18:48] Paper image links file exists (./assets/img_data/2602.08392.json), skip HTML parsing.
[19.02.2026 18:48] Success.
[19.02.2026 18:48] Enriching papers with extra data.
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 0. SLA2 improves sparse-linear attention in diffusion models by introducing a learnable router, direct attention formulation, and quantization-aware fine-tuning for enhanced efficiency and quality.  					AI-generated summary 				 Sparse-Linear Attention (SLA) combines sparse and linear attention to acc...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 1. HERO enables humanoid robots to perform object manipulation in diverse real-world environments by combining accurate end-effector control with open-vocabulary vision models for generalizable scene understanding.  					AI-generated summary 				 Visual loco-manipulation of arbitrary objects in the wil...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 2. RynnBrain is an open-source spatiotemporal foundation model for embodied intelligence that unifies perception, reasoning, and planning capabilities across multiple scales and task-specific variants.  					AI-generated summary 				 Despite rapid progress in multimodal foundation models, embodied inte...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 3. LLMs demonstrate near-complete factual encoding but struggle with retrieval accessibility, where errors stem from access limitations rather than knowledge gaps, with reasoning improving recall of encoded information.  					AI-generated summary 				 Standard factuality evaluations of LLMs treat all e...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 4. CADEvolve presents an evolution-based approach using VLM-guided edits to generate complex CAD programs from simple primitives, creating a large dataset for improved Image2CAD performance.  					AI-generated summary 				 Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering an...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 5. MAEB is a large-scale audio benchmark evaluating 50+ models across 30 tasks in speech, music, and environmental sounds, revealing diverse model strengths and establishing correlations with audio LLM performance.  					AI-generated summary 				 We introduce the Massive Audio Embedding Benchmark (MAEB...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 6. DreamZero is a World Action Model that leverages video diffusion to enable better generalization of physical motions across novel environments and embodiments compared to vision-language-action models.  					AI-generated summary 				 State-of-the-art Vision-Language-Action (VLA) models excel at sema...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 7. Sequence models enable cooperative behavior emergence in multi-agent reinforcement learning through in-context learning without hardcoded assumptions or timescale separation.  					AI-generated summary 				 Achieving cooperation among self-interested agents remains a fundamental challenge in multi-a...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 8. A promptable 3D human mesh recovery model using a novel parametric representation and encoder-decoder architecture achieves state-of-the-art performance with strong generalization across diverse conditions.  					AI-generated summary 				 We introduce SAM 3D Body (3DB), a promptable model for single...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 9. Traditional benchmark evaluations of AI agents fail to capture critical reliability issues, prompting the development of comprehensive metrics that assess consistency, robustness, predictability, and safety across multiple dimensions.  					AI-generated summary 				 AI agents are increasingly deploy...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 10. Multimodal Memory Agent (MMA) improves long-horizon agent performance by dynamically scoring memory reliability and handling visual biases in retrieval-augmented systems.  					AI-generated summary 				 Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval oft...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 11. Adaptive Matching Distillation introduces a self-correcting mechanism to improve generative model training by detecting and escaping unstable regions in the optimization landscape.  					AI-generated summary 				 Distribution Matching Distillation (DMD) is a powerful acceleration paradigm, yet its s...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 12. SAW-Bench presents a new benchmark for evaluating egocentric situated awareness in multimodal foundation models through real-world video datasets with human-annotated question-answer pairs, focusing on observer-centric spatial reasoning tasks.  					AI-generated summary 				 A core aspect of human p...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 13. Visual Memory Injection attack enables covert manipulation of generative vision-language models through manipulated images that trigger targeted responses only under specific prompts during multi-turn conversations.  					AI-generated summary 				 Generative large vision-language models (LVLMs) have...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 14. REFINE is a reinforcement learning framework that improves fast weight models for long-context modeling by training under next-sequence prediction instead of next-token prediction, enhancing their ability to capture long-range dependencies.  					AI-generated summary 				 Fast weight architectures o...
[19.02.2026 18:48] ********************************************************************************
[19.02.2026 18:48] Abstract 15. BiManiBench evaluates multimodal large language models on bimanual robotic tasks, revealing limitations in spatial grounding and control despite strong high-level reasoning capabilities.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI,...
[19.02.2026 18:48] Read previous papers.
[19.02.2026 18:48] Generating reviews via LLM API.
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#video", "#optimization", "#diffusion", "#inference", "#training", "#architecture"], "emoji": "‚ö°", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ SLA2, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ-–ª–∏–Ω–µ–π–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –≤ –¥–∏—Ñ
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#robotics", "#training"], "emoji": "ü§ñ", "ru": {"title": "–ö–æ–≥–¥–∞ —Ä–æ–±–æ—Ç —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ª–æ–≤–∫–∏–º: —Ç–æ—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ + –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã", "desc": "HERO ‚Äî —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥—É–º–∞–Ω–æ–∏–¥–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ–≤ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏—é –æ–±—ä–µ–∫—Ç–∞–º–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ –ø—É—Ç—ë–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ—á–Ω–æ–≥–æ —É–ø—Ä
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#architecture", "#robotics", "#open_source", "#transfer_learning", "#multimodal", "#reasoning", "#benchmark", "#training", "#cv"], "emoji": "ü§ñ", "ru": {"title": "–ï–¥–∏–Ω–∞—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è, —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–æ–±–æ—Ç–∞", "desc": "RynnBrain ‚Äî —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –ø—Ä–æ—Å—Ç
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#interpretability", "#rag", "#hallucinations", "#dataset", "#reasoning", "#benchmark"], "emoji": "üîë", "ru": {"title": "–ó–Ω–∞–Ω–∏—è –µ—Å—Ç—å, –Ω–æ –∫–ª—é—á–∏ –ø–æ—Ç–µ—Ä—è–Ω—ã: –∫–∞–∫ LLM –∫–æ–¥–∏—Ä—É—é—Ç —Ñ–∞–∫—Ç—ã, –Ω–æ –Ω–µ –º–æ–≥—É—Ç –∏—Ö –≤—Å–ø–æ–º–Ω–∏—Ç—å", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM –∫–æ–¥–∏—Ä—É—é—Ç –ø–æ—á—Ç–∏ –≤—Å–µ —Ñ–∞–∫—Ç—ã (9
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#synthetic", "#plp", "#benchmark", "#multimodal", "#science"], "emoji": "üèóÔ∏è", "ru": {"title": "–≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö CAD-–ø—Ä–æ–≥—Ä–∞–º–º —á–µ—Ä–µ–∑ –Ω–∞–ø—Ä–∞–≤–ª—è–µ–º–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ VLM", "desc": "CADEvolve –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#dataset", "#audio", "#multimodal", "#open_source", "#survey", "#multilingual", "#low_resource", "#benchmark"], "emoji": "üéµ", "ru": {"title": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∞—É–¥–∏–æ–º–æ–¥–µ–ª–µ–π: –Ω–µ—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π –Ω–∞ –≤—Å–µ —Å–ª—É—á–∞–∏ –∂–∏–∑–Ω–∏", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω Massive Audio Embedding Benchmark (MAEB) ‚Äî –∫—Ä—É–ø–Ω
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#video", "#optimization", "#diffusion", "#multimodal", "#training", "#robotics", "#transfer_learning"], "emoji": "ü§ñ", "ru": {"title": "–î–∏–Ω–∞–º–∏–∫–∞ –≤–º–µ—Å—Ç–æ —Å–µ–º–∞–Ω—Ç–∏–∫–∏: –≤–∏–¥–µ–æ-–¥–∏—Ñ—Ñ—É–∑–∏—è –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–±–æ—Ç–æ–º", "desc": "DreamZero ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π (World Action Model)
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#rl", "#agents", "#games", "#reasoning", "#architecture"], "emoji": "ü§ù", "ru": {"title": "–ö–æ–æ–ø–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø–æ–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã) –ø–æ–∑–≤–æ–ª—è—é—Ç –∞–≥–µ–Ω—Ç–∞–º –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ —Å
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#3d", "#benchmark", "#open_source", "#data", "#architecture", "#dataset"], "emoji": "üßç", "ru": {"title": "–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏", "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç SAM 3D Body (3DB) ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Ç—Ä—ë—Ö–º–µ—Ä–Ω–æ
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#benchmark", "#agents"], "emoji": "‚öôÔ∏è", "ru": {"title": "–ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ —Ç–æ—á–Ω–æ—Å—Ç–∏: –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ AI –∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –∫—Ä–∏—Ç–∏–∫—É–µ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –º–µ—Ç—Ä–∏–∫—É —É—Å–ø–µ—Ö–∞ –∏ –Ω–µ –≤—ã—è–≤–ª—è—é—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏. –ê
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#interpretability", "#rag", "#agents", "#security", "#benchmark", "#multimodal", "#open_source", "#long_context", "#dataset"], "emoji": "üß†", "ru": {"title": "–ù–∞–¥–µ–∂–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –∏ –±–æ—Ä—å–±–∞ —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ —Å–º–µ—â–µ–Ω–∏—è–º–∏", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –∞–≥–µ–Ω—Ç Mu
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#training", "#benchmark", "#video", "#optimization", "#diffusion"], "emoji": "‚ö°", "ru": {"title": "–°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –∑–æ–Ω –æ–±—É—á–µ–Ω–∏—è", "desc": "–í —Ä–∞–±–æ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ Adaptive Matching Distillation (AMD) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –≥–µ–Ω–µ
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#video", "#survey", "#benchmark", "#multimodal", "#reasoning", "#dataset"], "emoji": "üëì", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —ç–≥–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–∏—Ä–∞ —á–µ—Ä–µ–∑ –≥–ª–∞–∑–∞ –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª—è", "desc": "SAW-Bench ‚Äî —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö foundation models –ø–æ–Ω–∏–º–∞—Ç—å –æ–∫—Ä—É–∂
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#long_context", "#open_source", "#multimodal", "#benchmark", "#cv", "#security"], "emoji": "üé≠", "ru": {"title": "–°–∫—Ä—ã—Ç–∞—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è —á–µ—Ä–µ–∑ –≤–æ–∑–º—É—â—ë–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã—Ö –¥–∏–∞–ª–æ–≥–∞—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∞—Ç–∞–∫—É Visual Memory Injection, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–∫—Ä—ã—Ç–Ω–æ –º–∞–Ω–∏–ø
[19.02.2026 18:48] Querying the API.
[19.02.2026 18:48] Claude request. Model: claude-haiku-4-5. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

REFINE is a reinforcement learning framework that improves fast weight models for long-context modeling by training under next-sequence prediction instead of next-token prediction, enhancing their ability to capture long-range dependencies.  					AI-generated summary 				 Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.
[19.02.2026 18:48] Response: ```json
{
  "desc": "REFINE ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç –º–æ–¥–µ–ª–∏ —Å –±—ã—Å—Ç—Ä—ã–º–∏ –≤–µ—Å–∞–º–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–ª–∏–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏. –í–º–µ—Å—Ç–æ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–π –ø–∞—Ä–∞–¥–∏–≥–º—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ (NTP), –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (NSP), —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—Ç—å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏. –§—Ä–µ–π–º–≤–æ—Ä–∫ –æ—Ç–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–Ω–æ–≥–æ—Ç–æ–∫–µ–Ω–Ω—ã–µ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é –≥—Ä—É–ø–ø–æ–≤–æ–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ (GRPO). –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ REFINE –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Å NTP –Ω–∞ –∑–∞–¥–∞—á–∞—Ö –ø–æ–∏—Å–∫–∞ –≤ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö –∏ –≤–æ–ø—Ä–æ—Å–æ-–æ—Ç–≤–µ—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö.",
  "emoji": "üîÑ",
  "title": "–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –≤–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"
}
```
[19.02.2026 18:48] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"REFINE is a reinforcement learning framework that improves fast weight models for long-context modeling by training under next-sequence prediction instead of next-token prediction, enhancing their ability to capture long-range dependencies.  					AI-generated summary 				 Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures."

[19.02.2026 18:48] Response: ```python
['RL', 'ARCHITECTURE', 'TRAINING']
```
[19.02.2026 18:48] Claude request. Model: claude-haiku-4-5. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"REFINE is a reinforcement learning framework that improves fast weight models for long-context modeling by training under next-sequence prediction instead of next-token prediction, enhancing their ability to capture long-range dependencies.  					AI-generated summary 				 Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures."

[19.02.2026 18:48] Response: ```python
['LONG_CONTEXT', 'OPTIMIZATION', 'REASONING']
```
[19.02.2026 18:48] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"REFINE is a novel reinforcement learning framework designed to enhance fast weight models for long-context tasks by shifting from next-token prediction to next-sequence prediction. This approach allows the models to better capture long-range dependencies by focusing on the coherence of multiple tokens rather than just single-token predictions. By utilizing prediction entropy to select informative token positions and generating multi-token rollouts, REFINE optimizes the model with self-supervised rewards and group relative policy optimization. Experiments show that REFINE significantly outperforms traditional supervised fine-tuning methods across various long-context tasks, demonstrating its effectiveness in improving fast weight architectures.","title":"REFINE: Revolutionizing Long-Context Modeling with Next-Sequence Prediction"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='REFINE is a novel reinforcement learning framework designed to enhance fast weight models for long-context tasks by shifting from next-token prediction to next-sequence prediction. This approach allows the models to better capture long-range dependencies by focusing on the coherence of multiple tokens rather than just single-token predictions. By utilizing prediction entropy to select informative token positions and generating multi-token rollouts, REFINE optimizes the model with self-supervised rewards and group relative policy optimization. Experiments show that REFINE significantly outperforms traditional supervised fine-tuning methods across various long-context tasks, demonstrating its effectiveness in improving fast weight architectures.', title='REFINE: Revolutionizing Long-Context Modeling with Next-Sequence Prediction'))
[19.02.2026 18:48] Response: ParsedChatCompletionMessage[~ResponseFormatT](content='{"desc":"REFINEÊòØ‰∏ÄÁßçÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÊó®Âú®ÈÄöËøá‰∏ã‰∏Ä‰∏™Â∫èÂàóÈ¢ÑÊµãÊù•ÊèêÂçáÂø´ÈÄüÊùÉÈáçÊ®°ÂûãÂú®Èïø‰∏ä‰∏ãÊñáÂª∫Ê®°‰∏≠ÁöÑË°®Áé∞„ÄÇ‰∏é‰º†ÁªüÁöÑ‰∏ã‰∏Ä‰∏™Ê†áËÆ∞È¢ÑÊµã‰∏çÂêåÔºåREFINEËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÈïøË∑ùÁ¶ª‰æùËµñÂÖ≥Á≥ª„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÈÄâÊã©‰ø°ÊÅØ‰∏∞ÂØåÁöÑÊ†áËÆ∞‰ΩçÁΩÆ„ÄÅÁîüÊàêÂ§öÊ†áËÆ∞ÁöÑÂõûÊªöÔºåÂπ∂‰ΩøÁî®Ëá™ÁõëÁù£ÁöÑÂ∫èÂàóÁ∫ßÂ•ñÂä±Êù•‰ºòÂåñÊ®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåREFINEÂú®Â§ö‰∏™‰ªªÂä°‰∏≠Âùá‰ºò‰∫é‰º†ÁªüÁöÑÁõëÁù£ÂæÆË∞ÉÊñπÊ≥ïÔºåÂ±ïÁé∞‰∫ÜÂÖ∂Âú®Âø´ÈÄüÊùÉÈáçÊû∂ÊûÑ‰∏≠ÊèêÂçáÈïø‰∏ä‰∏ãÊñáÂª∫Ê®°ÁöÑÊúâÊïàÊÄß„ÄÇ","title":"REFINEÔºöÊèêÂçáÈïø‰∏ä‰∏ãÊñáÂª∫Ê®°ÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='REFINEÊòØ‰∏ÄÁßçÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÊó®Âú®ÈÄöËøá‰∏ã‰∏Ä‰∏™Â∫èÂàóÈ¢ÑÊµãÊù•ÊèêÂçáÂø´ÈÄüÊùÉÈáçÊ®°ÂûãÂú®Èïø‰∏ä‰∏ãÊñáÂª∫Ê®°‰∏≠ÁöÑË°®Áé∞„ÄÇ‰∏é‰º†ÁªüÁöÑ‰∏ã‰∏Ä‰∏™Ê†áËÆ∞È¢ÑÊµã‰∏çÂêåÔºåREFINEËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâÈïøË∑ùÁ¶ª‰æùËµñÂÖ≥Á≥ª„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÈÄâÊã©‰ø°ÊÅØ‰∏∞ÂØåÁöÑÊ†áËÆ∞‰ΩçÁΩÆ„ÄÅÁîüÊàêÂ§öÊ†áËÆ∞ÁöÑÂõûÊªöÔºåÂπ∂‰ΩøÁî®Ëá™ÁõëÁù£ÁöÑÂ∫èÂàóÁ∫ßÂ•ñÂä±Êù•‰ºòÂåñÊ®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåREFINEÂú®Â§ö‰∏™‰ªªÂä°‰∏≠Âùá‰ºò‰∫é‰º†ÁªüÁöÑÁõëÁù£ÂæÆË∞ÉÊñπÊ≥ïÔºåÂ±ïÁé∞‰∫ÜÂÖ∂Âú®Âø´ÈÄüÊùÉÈáçÊû∂ÊûÑ‰∏≠ÊèêÂçáÈïø‰∏ä‰∏ãÊñáÂª∫Ê®°ÁöÑÊúâÊïàÊÄß„ÄÇ', title='REFINEÔºöÊèêÂçáÈïø‰∏ä‰∏ãÊñáÂª∫Ê®°ÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂'))
[19.02.2026 18:48] Using data from previous issue: {"categories": ["#benchmark", "#robotics", "#multimodal", "#reasoning", "#hallucinations"], "emoji": "ü§ñ", "ru": {"title": "–ö–æ–≥–¥–∞ –¥–≤–µ —Ä—É–∫–∏ –ª—É—á—à–µ, —á–µ–º –æ–¥–Ω–∞: –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–µ", "desc": "BiManiBench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å
[19.02.2026 18:48] Renaming data file.
[19.02.2026 18:48] Renaming previous data. hf_papers.json to ./d/2026-02-19.json
[19.02.2026 18:48] Saving new data file.
[19.02.2026 18:48] Generating page.
[19.02.2026 18:48] Renaming previous page.
[19.02.2026 18:48] Renaming previous data. index.html to ./d/2026-02-19.html
[19.02.2026 18:48] Writing result.
[19.02.2026 18:48] Renaming log file.
[19.02.2026 18:48] Renaming previous data. log.txt to ./logs/2026-02-19_last_log.txt
