[15.08.2025 19:09] Read previous papers.
[15.08.2025 19:09] Generating top page (month).
[15.08.2025 19:09] Writing top page (month).
[15.08.2025 20:13] Read previous papers.
[15.08.2025 20:13] Get feed.
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10433
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10711
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10881
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09848
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10833
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10898
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10893
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10751
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10875
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10576
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10637
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10860
[15.08.2025 20:13] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10482
[15.08.2025 20:13] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.08.2025 20:13] No deleted papers detected.
[15.08.2025 20:13] Downloading and parsing papers (pdf, html). Total: 13.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10433.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10433.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10433.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10711.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10711.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10711.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10881.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10881.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10881.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.09848.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.09848.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.09848.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10833.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10833.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10833.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10898.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10898.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10898.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10893.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10893.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10893.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10751.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10751.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10751.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10875.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10875.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10875.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10576.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10576.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10576.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10637.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10637.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10637.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10860.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10860.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10860.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Downloading and parsing paper https://huggingface.co/papers/2508.10482.
[15.08.2025 20:13] Extra JSON file exists (./assets/json/2508.10482.json), skip PDF parsing.
[15.08.2025 20:13] Paper image links file exists (./assets/img_data/2508.10482.json), skip HTML parsing.
[15.08.2025 20:13] Success.
[15.08.2025 20:13] Enriching papers with extra data.
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 0. We-Math 2.0 enhances MLLMs' mathematical reasoning through a structured knowledge system, model-centric data space modeling, and reinforcement learning, demonstrating competitive performance on benchmarks.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have demonstrated imp...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 1. NextStep-1, a 14B autoregressive model with a 157M flow matching head, achieves state-of-the-art performance in text-to-image generation and image editing by processing discrete text tokens and continuous image tokens.  					AI-generated summary 				 Prevailing autoregressive (AR) models for text-to...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 2. ToonComposer is a generative model that unifies inbetweening and colorization in cartoon production, using sparse sketches and a cartoon adaptation method to improve visual quality and efficiency.  					AI-generated summary 				 Traditional cartoon and anime production involves keyframing, inbetween...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 3. A benchmark called PRELUDE evaluates long-context understanding by assessing the consistency of prequel stories with original books, revealing significant challenges for models compared to humans.  					AI-generated summary 				 We introduce PRELUDE, a benchmark for evaluating long-context understan...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 4. UI-Venus, a multimodal large language model-based UI agent, achieves state-of-the-art performance in UI grounding and navigation tasks using reinforcement fine-tuning and novel self-evolving frameworks.  					AI-generated summary 				 We present UI-Venus, a native UI agent that takes only screenshot...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 5. Puppeteer is a framework that automates rigging and animation of 3D models using an auto-regressive transformer, attention-based architecture, and differentiable optimization, outperforming existing methods in accuracy and efficiency.  					AI-generated summary 				 Modern interactive applications i...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 6. STream3R reformulates 3D reconstruction as a decoder-only Transformer problem, using causal attention to efficiently process image sequences and outperform existing methods in both static and dynamic scenes.  					AI-generated summary 				 We present STream3R, a novel approach to 3D reconstruction t...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 7. Using Pass@k as a reward in reinforcement learning with verifiable rewards improves exploration and reveals that exploration and exploitation can mutually enhance each other.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR), which typically adopts Pass@1 as the r...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 8. Diffusion Language Models offer parallel token generation, reducing inference latency and capturing bidirectional context, and are compared to autoregressive models in various NLP tasks.  					AI-generated summary 				 Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 9. HumanSense is a benchmark for evaluating human-centered perception and interaction in Multimodal Large Language Models, focusing on multimodal context understanding and rational feedback through reinforcement learning.  					AI-generated summary 				 While Multimodal Large Language Models (MLLMs) sh...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 10. Visual encoders encode subtle image acquisition parameters that can significantly impact semantic predictions based on their correlation with semantic labels.  					AI-generated summary 				 Prior work has analyzed the robustness of visual encoders to image transformations and corruptions, particula...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 11. A multi-dimensional modeling framework enhances automated interpreting quality assessment by integrating feature engineering, data augmentation, and explainable machine learning, focusing on transparency and detailed diagnostic feedback.  					AI-generated summary 				 Recent advancements in machine...
[15.08.2025 20:13] ********************************************************************************
[15.08.2025 20:13] Abstract 12. The study investigates the relationship between privacy and explainability in NLP, using Differential Privacy and Post-hoc Explainability methods, and provides recommendations for balancing both.  					AI-generated summary 				 In the study of trustworthy Natural Language Processing (NLP), a number ...
[15.08.2025 20:13] Read previous papers.
[15.08.2025 20:13] Generating reviews via LLM API.
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#benchmark", "#reasoning", "#training", "#data", "#rl"], "emoji": "üßÆ", "ru": {"title": "–£—Å–∏–ª–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –ò–ò —á–µ—Ä–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "We-Math 2.0 - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#cv", "#architecture", "#diffusion", "#training"], "emoji": "üé®", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: NextStep-1 –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é", "desc": "NextStep-1 - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É, —Å–æ—Å—Ç–æ—è—â–∞—è –∏–∑ –∞
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#multimodal", "#diffusion", "#games", "#cv", "#benchmark"], "emoji": "üé®", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –∞–Ω–∏–º–∞—Ü–∏–∏: –µ–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤ –∏ —Ä–∞—Å–∫—Ä–∞—à–∏–≤–∞–Ω–∏—è", "desc": "ToonComposer - —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø—Ä–æ—Ü–µ—Å—Å—ã —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤ –∏ —Ä–∞—Å–∫—Ä–∞—à–∏–≤–∞
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#multimodal", "#long_context"], "emoji": "üìö", "ru": {"title": "PRELUDE: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –æ—Ü–µ–Ω–∫–µ –≥–ª—É–±–∏–Ω—ã –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ PRELUDE –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#data", "#open_source", "#rl", "#games", "#optimization", "#multimodal", "#training", "#agents"], "emoji": "üñ•Ô∏è", "ru": {"title": "UI-Venus: –ò–ò-–∞–≥–µ–Ω—Ç –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏", "desc": "UI-Venus - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ–≤
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#3d", "#games", "#architecture", "#benchmark", "#optimization"], "emoji": "üé≠", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–∏–≥–≥–∏–Ω–≥–∞ –∏ –∞–Ω–∏–º–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "Puppeteer - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ä–∏–≥–≥–∏–Ω–≥–∞ –∏ –∞–Ω–∏–º–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#optimization", "#architecture", "#training", "#3d", "#agi"], "emoji": "üåê", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", "desc": "STream3R - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ 3D-—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–µ–∫–æ–¥–µ—Ä-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±–ª
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#rl", "#rlhf", "#training", "#optimization", "#reasoning"], "emoji": "üîç", "ru": {"title": "Pass@k: –∫–ª—é—á –∫ –±–∞–ª–∞–Ω—Å—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ Pass@k –≤ –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞–≥—Ä–∞–¥—ã –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#training", "#multimodal", "#optimization", "#inference", "#data", "#survey", "#diffusion"], "emoji": "üåä", "ru": {"title": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞", "desc": "–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (DLM) –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–æ–∫–µ–Ω–æ–≤
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#interpretability", "#reasoning", "#rl", "#multimodal"], "emoji": "üß†", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —á–µ–ª–æ–≤–µ–∫–æ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö", "desc": "HumanSense - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#cv"], "emoji": "üîç", "ru": {"title": "–ù–µ–≤–∏–¥–∏–º—ã–µ —Å–ª–µ–¥—ã –≤ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: —Å–∫—Ä—ã—Ç–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–ò", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–Ω–∫–æ–¥–µ—Ä—ã –∫–æ–¥–∏—Ä—É—é—Ç —Ç–æ–Ω–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –≤–ª–∏—è—Ç—å –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. –≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, 
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#multilingual", "#science", "#dataset", "#optimization", "#interpretability", "#training", "#data"], "emoji": "üó£Ô∏è", "ru": {"title": "–ü—Ä–æ–∑—Ä–∞—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —É—Å—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ–º–µ—Ä–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —É—Å—Ç–Ω–æ–≥–æ 
[15.08.2025 20:13] Using data from previous issue: {"categories": ["#multilingual", "#data", "#ethics", "#interpretability"], "emoji": "üîê", "ru": {"title": "–ë–∞–ª–∞–Ω—Å –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏ –≤ NLP: –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏ –≤—ã–∑–æ–≤—ã", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∏–∑—É—á–µ–Ω–∏—é –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å—é –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ
[15.08.2025 20:13] Renaming data file.
[15.08.2025 20:13] Renaming previous data. hf_papers.json to ./d/2025-08-15.json
[15.08.2025 20:13] Saving new data file.
[15.08.2025 20:13] Generating page.
[15.08.2025 20:13] Renaming previous page.
[15.08.2025 20:13] Renaming previous data. index.html to ./d/2025-08-15.html
[15.08.2025 20:13] Writing result.
[15.08.2025 20:13] Renaming log file.
[15.08.2025 20:13] Renaming previous data. log.txt to ./logs/2025-08-15_last_log.txt
