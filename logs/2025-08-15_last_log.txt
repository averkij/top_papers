[15.08.2025 03:49] Read previous papers.
[15.08.2025 03:49] Generating top page (month).
[15.08.2025 03:49] Writing top page (month).
[15.08.2025 04:23] Read previous papers.
[15.08.2025 04:23] Get feed.
[15.08.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10433
[15.08.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10711
[15.08.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09848
[15.08.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10833
[15.08.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10576
[15.08.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2508.10860
[15.08.2025 04:23] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.08.2025 04:23] No deleted papers detected.
[15.08.2025 04:23] Downloading and parsing papers (pdf, html). Total: 6.
[15.08.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2508.10433.
[15.08.2025 04:23] Extra JSON file exists (./assets/json/2508.10433.json), skip PDF parsing.
[15.08.2025 04:23] Paper image links file exists (./assets/img_data/2508.10433.json), skip HTML parsing.
[15.08.2025 04:23] Success.
[15.08.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2508.10711.
[15.08.2025 04:23] Extra JSON file exists (./assets/json/2508.10711.json), skip PDF parsing.
[15.08.2025 04:23] Paper image links file exists (./assets/img_data/2508.10711.json), skip HTML parsing.
[15.08.2025 04:23] Success.
[15.08.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2508.09848.
[15.08.2025 04:23] Extra JSON file exists (./assets/json/2508.09848.json), skip PDF parsing.
[15.08.2025 04:23] Paper image links file exists (./assets/img_data/2508.09848.json), skip HTML parsing.
[15.08.2025 04:23] Success.
[15.08.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2508.10833.
[15.08.2025 04:23] Extra JSON file exists (./assets/json/2508.10833.json), skip PDF parsing.
[15.08.2025 04:23] Paper image links file exists (./assets/img_data/2508.10833.json), skip HTML parsing.
[15.08.2025 04:23] Success.
[15.08.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2508.10576.
[15.08.2025 04:23] Extra JSON file exists (./assets/json/2508.10576.json), skip PDF parsing.
[15.08.2025 04:23] Paper image links file exists (./assets/img_data/2508.10576.json), skip HTML parsing.
[15.08.2025 04:23] Success.
[15.08.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2508.10860.
[15.08.2025 04:23] Extra JSON file exists (./assets/json/2508.10860.json), skip PDF parsing.
[15.08.2025 04:23] Paper image links file exists (./assets/img_data/2508.10860.json), skip HTML parsing.
[15.08.2025 04:23] Success.
[15.08.2025 04:23] Enriching papers with extra data.
[15.08.2025 04:23] ********************************************************************************
[15.08.2025 04:23] Abstract 0. We-Math 2.0 enhances MLLMs' mathematical reasoning through a structured knowledge system, model-centric data space modeling, and reinforcement learning, demonstrating competitive performance on benchmarks.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have demonstrated imp...
[15.08.2025 04:23] ********************************************************************************
[15.08.2025 04:23] Abstract 1. NextStep-1, a 14B autoregressive model with a 157M flow matching head, achieves state-of-the-art performance in text-to-image generation and image editing by processing discrete text tokens and continuous image tokens.  					AI-generated summary 				 Prevailing autoregressive (AR) models for text-to...
[15.08.2025 04:23] ********************************************************************************
[15.08.2025 04:23] Abstract 2. A benchmark called PRELUDE evaluates long-context understanding by assessing the consistency of prequel stories with original books, revealing significant challenges for models compared to humans.  					AI-generated summary 				 We introduce PRELUDE, a benchmark for evaluating long-context understan...
[15.08.2025 04:23] ********************************************************************************
[15.08.2025 04:23] Abstract 3. UI-Venus, a multimodal large language model-based UI agent, achieves state-of-the-art performance in UI grounding and navigation tasks using reinforcement fine-tuning and novel self-evolving frameworks.  					AI-generated summary 				 We present UI-Venus, a native UI agent that takes only screenshot...
[15.08.2025 04:23] ********************************************************************************
[15.08.2025 04:23] Abstract 4. HumanSense is a benchmark for evaluating human-centered perception and interaction in Multimodal Large Language Models, focusing on multimodal context understanding and rational feedback through reinforcement learning.  					AI-generated summary 				 While Multimodal Large Language Models (MLLMs) sh...
[15.08.2025 04:23] ********************************************************************************
[15.08.2025 04:23] Abstract 5. A multi-dimensional modeling framework enhances automated interpreting quality assessment by integrating feature engineering, data augmentation, and explainable machine learning, focusing on transparency and detailed diagnostic feedback.  					AI-generated summary 				 Recent advancements in machine...
[15.08.2025 04:23] Read previous papers.
[15.08.2025 04:23] Generating reviews via LLM API.
[15.08.2025 04:23] Using data from previous issue: {"categories": ["#dataset", "#optimization", "#benchmark", "#reasoning", "#training", "#data", "#rl"], "emoji": "üßÆ", "ru": {"title": "–£—Å–∏–ª–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –ò–ò —á–µ—Ä–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "We-Math 2.0 - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º
[15.08.2025 04:23] Using data from previous issue: {"categories": ["#open_source", "#multimodal", "#cv", "#architecture", "#diffusion", "#training"], "emoji": "üé®", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: NextStep-1 –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é", "desc": "NextStep-1 - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É, —Å–æ—Å—Ç–æ—è—â–∞—è –∏–∑ –∞
[15.08.2025 04:23] Using data from previous issue: {"categories": ["#reasoning", "#benchmark", "#multimodal", "#long_context"], "emoji": "üìö", "ru": {"title": "PRELUDE: –Ω–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –æ—Ü–µ–Ω–∫–µ –≥–ª—É–±–∏–Ω—ã –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ PRELUDE –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω
[15.08.2025 04:23] Using data from previous issue: {"categories": ["#data", "#open_source", "#rl", "#games", "#optimization", "#multimodal", "#training", "#agents"], "emoji": "üñ•Ô∏è", "ru": {"title": "UI-Venus: –ò–ò-–∞–≥–µ–Ω—Ç –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏", "desc": "UI-Venus - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ–≤
[15.08.2025 04:23] Using data from previous issue: {"categories": ["#rlhf", "#benchmark", "#interpretability", "#reasoning", "#rl", "#multimodal"], "emoji": "üß†", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —á–µ–ª–æ–≤–µ–∫–æ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–º–æ–¥–µ–ª—è—Ö", "desc": "HumanSense - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞
[15.08.2025 04:23] Using data from previous issue: {"categories": ["#multilingual", "#science", "#dataset", "#optimization", "#interpretability", "#training", "#data"], "emoji": "üó£Ô∏è", "ru": {"title": "–ü—Ä–æ–∑—Ä–∞—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —É—Å—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ–º–µ—Ä–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —É—Å—Ç–Ω–æ–≥–æ 
[15.08.2025 04:23] Renaming data file.
[15.08.2025 04:23] Renaming previous data. hf_papers.json to ./d/2025-08-15.json
[15.08.2025 04:23] Saving new data file.
[15.08.2025 04:23] Generating page.
[15.08.2025 04:23] Renaming previous page.
[15.08.2025 04:23] Renaming previous data. index.html to ./d/2025-08-15.html
[15.08.2025 04:23] Writing result.
[15.08.2025 04:23] Renaming log file.
[15.08.2025 04:23] Renaming previous data. log.txt to ./logs/2025-08-15_last_log.txt
