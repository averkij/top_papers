[15.07.2025 14:13] Read previous papers.
[15.07.2025 14:13] Generating top page (month).
[15.07.2025 14:13] Writing top page (month).
[15.07.2025 15:11] Read previous papers.
[15.07.2025 15:11] Get feed.
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.09862
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.10532
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.10548
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.10524
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.10541
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04404
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.09104
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.10065
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04218
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08267
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.09074
[15.07.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08924
[15.07.2025 15:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[15.07.2025 15:11] No deleted papers detected.
[15.07.2025 15:11] Downloading and parsing papers (pdf, html). Total: 12.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.09862.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.09862.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.09862.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.10532.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.10532.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.10532.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.10548.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.10548.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.10548.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.10524.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.10524.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.10524.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.10541.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.10541.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.10541.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.04404.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.04404.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.04404.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.09104.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.09104.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.09104.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.10065.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.10065.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.10065.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.04218.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.04218.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.04218.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.08267.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.08267.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.08267.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.09074.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.09074.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.09074.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2507.08924.
[15.07.2025 15:11] Extra JSON file exists (./assets/json/2507.08924.json), skip PDF parsing.
[15.07.2025 15:11] Paper image links file exists (./assets/img_data/2507.08924.json), skip HTML parsing.
[15.07.2025 15:11] Success.
[15.07.2025 15:11] Enriching papers with extra data.
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 0. A large-scale dataset named SpeakerVid-5M is introduced for audio-visual dyadic interactive virtual human generation, featuring diverse interactions and high-quality data for various virtual human tasks.  					AI-generated summary 				 The rapid development of large-scale models has catalyzed signif...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 1. Research on enhancing LLM reasoning through RL reveals that accurate reward signals are crucial for performance improvement, and current benchmarks may be unreliable due to data contamination.  					AI-generated summary 				 The reasoning capabilities of large language models (LLMs) have been a long...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 2. A new dataset, EmRACE-3K, evaluates vision-language models in embodied settings, showing limitations in spatial reasoning and long-horizon planning, and demonstrates improvements through supervised and reinforcement learning fine-tuning.  					AI-generated summary 				 Recent advanced vision-languag...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 3. Mixture-of-Recursions (MoR) achieves parameter and computational efficiency in large language models through shared layers and adaptive recursion depths, improving performance metrics and throughput.  					AI-generated summary 				 Scaling language models unlocks impressive capabilities, but the acc...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 4. REST evaluates large reasoning models under simultaneous multi-context pressure, revealing performance differences not apparent in single-question tests and highlighting the importance of contextual priority allocation and cognitive load management.  					AI-generated summary 				 Recent Large Reaso...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 5. A token-aware, layer-localized contrastive decoding method improves factual accuracy in large language models by selectively suppressing attention to specific token types at their respective depths.  					AI-generated summary 				 Large language models (LLMs) excel at natural language understanding ...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 6. CompassJudger-2, a generalist judge model, achieves superior performance across multiple benchmarks through task-driven data curation, verifiable rewards, and a refined learning objective with margin policy gradient loss.  					AI-generated summary 				 Recently, the role of LLM-as-judge in evaluati...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 7. MoVieS synthesizes 4D dynamic novel views from monocular videos using Gaussian primitives, enabling unified modeling of appearance, geometry, and motion with minimal task-specific supervision.  					AI-generated summary 				 We present MoVieS, a novel feed-forward model that synthesizes 4D dynamic n...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 8. DreamPoster generates high-quality posters from images and text prompts using a progressive training strategy and Seedream3.0 model, outperforming existing methods in usability.  					AI-generated summary 				 We present DreamPoster, a Text-to-Image generation framework that intelligently synthesize...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 9. A combination of extended supervised fine-tuning and reinforcement learning from online inference enhances the mathematical reasoning capabilities of large language models, achieving top-tier performance on benchmarks like the AI Mathematical Olympiad.  					AI-generated summary 				 Enhancing the m...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 10. This paper presents a novel method of executable steganography using the alpha transparency layer of ICO image files to embed and deliver self-decompressing JavaScript payloads within web browsers. By targeting the least significant bit (LSB) of non-transparent alpha layer image values, the proposed...
[15.07.2025 15:11] ********************************************************************************
[15.07.2025 15:11] Abstract 11. Korean expert-level benchmarks, KMMLU-Redux and KMMLU-Pro, are introduced to evaluate Large Language Models across academic and industrial domains in Korea.  					AI-generated summary 				 The development of Large Language Models (LLMs) requires robust benchmarks that encompass not only academic dom...
[15.07.2025 15:11] Read previous papers.
[15.07.2025 15:11] Generating reviews via LLM API.
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#data", "#benchmark", "#dataset"], "emoji": "ü§ñ", "ru": {"title": "SpeakerVid-5M: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –ª—é–¥–µ–π", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö SpeakerVid-5M –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ–≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–∏–∞–¥–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –ª—é–¥–µ–π. –î–∞—Ç–∞—Å–µ—Ç
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#leakage", "#dataset", "#synthetic", "#benchmark", "#rl", "#reasoning"], "emoji": "üßÆ", "ru": {"title": "–ß–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ - –∫–ª—é—á –∫ –Ω–∞–¥–µ–∂–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –¥–ª—è LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é —Å
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#reasoning", "#long_context", "#multimodal", "#benchmark", "#rl", "#dataset"], "emoji": "ü§ñ", "ru": {"title": "EmRACE-3K: –ù–æ–≤—ã–π —Ä—É–±–µ–∂ –≤ –æ–±—É—á–µ–Ω–∏–∏ –≤–æ–ø–ª–æ—â–µ–Ω–Ω–æ–≥–æ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö EmRACE-3K –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#small_models"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Ä–µ–∫—É—Ä—Å–∏—é –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Mixture-of-Recursions (MoR) - –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–æ–≤—ã—à–µ–Ω–∏—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#benchmark", "#training", "#reasoning", "#optimization"], "emoji": "üß†", "ru": {"title": "REST: —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç –¥–ª—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞", "desc": "REST - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–µ—à–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ. –û–Ω –≤—ã—è–≤–ª—è
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#training", "#hallucinations", "#benchmark", "#architecture", "#interpretability"], "emoji": "üéØ", "ru": {"title": "–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —Ç–æ–∫–µ–Ω-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#data", "#architecture", "#training", "#benchmark", "#dataset", "#agi", "#reasoning", "#optimization"], "emoji": "‚öñÔ∏è", "ru": {"title": "CompassJudger-2: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å—É–¥—å—è –¥–ª—è –ò–ò-–º–æ–¥–µ–ª–µ–π", "desc": "CompassJudger-2 - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å-—Å—É–¥—å—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#video", "#3d"], "emoji": "üé•", "ru": {"title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –≤–∏–¥–æ–≤, —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤ 3D", "desc": "MoVieS - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤–∏–¥—ã –∏–∑ –º–æ–Ω–æ–∫—É–ª—è—Ä–Ω—ã—Ö –≤–∏–¥–µ–æ –∑–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ—Ç–∫–∏ –≥–∞—É—Å—Å–æ–≤—ã—Ö –ø—Ä–∏–º–∏—Ç–∏–≤–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#training", "#synthetic", "#benchmark", "#dataset", "#cv", "#data"], "emoji": "üé®", "ru": {"title": "DreamPoster: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "DreamPoster - —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ—Å—Ç–µ—Ä—ã –∏–∑
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#open_source", "#math", "#optimization", "#reasoning", "#training", "#benchmark"], "emoji": "üßÆ", "ru": {"title": "–°–∏–º–±–∏–æ–∑ SFT –∏ RL: –ø—É—Ç—å –∫ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤—É –≤ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –º—ã—à–ª–µ–Ω–∏–∏ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#multimodal", "#audio", "#dataset", "#data", "#video", "#healthcare", "#security"], "emoji": "üïµÔ∏è", "ru": {"title": "–ù–µ–≤–∏–¥–∏–º—ã–π JavaScript: –°—Ç–µ–≥–∞–Ω–æ–≥—Ä–∞—Ñ–∏—è –≤ —Ñ–∞–≤–∏–∫–æ–Ω–∫–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–π —Å—Ç–µ–≥–∞–Ω–æ–≥—Ä–∞—Ñ–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ ICO-—Ñ–∞–π–ª–æ–≤
[15.07.2025 15:11] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#science", "#open_source"], "emoji": "üá∞üá∑", "ru": {"title": "–ù–æ–≤—ã–µ –∫–æ—Ä–µ–π—Å–∫–∏–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ LLM –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–≤–∞ –Ω–æ–≤—ã—Ö —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –Ω–∞ –∫–æ—Ä–µ–π—Å–∫–æ–º —è–∑—ã–∫–µ: KMMLU-Redux –∏ 
[15.07.2025 15:11] Renaming data file.
[15.07.2025 15:11] Renaming previous data. hf_papers.json to ./d/2025-07-15.json
[15.07.2025 15:11] Saving new data file.
[15.07.2025 15:11] Generating page.
[15.07.2025 15:11] Renaming previous page.
[15.07.2025 15:11] Renaming previous data. index.html to ./d/2025-07-15.html
[15.07.2025 15:11] Writing result.
[15.07.2025 15:11] Renaming log file.
[15.07.2025 15:11] Renaming previous data. log.txt to ./logs/2025-07-15_last_log.txt
