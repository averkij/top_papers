[03.02.2025 14:10] Read previous papers.
[03.02.2025 14:10] Generating top page (month).
[03.02.2025 14:10] Writing top page (month).
[03.02.2025 15:10] Read previous papers.
[03.02.2025 15:10] Get feed.
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.19393
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.19324
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18119
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04983
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18837
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18841
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18753
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18128
[03.02.2025 15:10] Get page data from previous paper. URL: https://huggingface.co/papers/2404.07097
[03.02.2025 15:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.02.2025 15:10] No deleted papers detected.
[03.02.2025 15:10] Downloading and parsing papers (pdf, html). Total: 9.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.19393.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.19393.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.19393.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.19324.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.19324.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.19324.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.18119.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.18119.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.18119.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2411.04983.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2411.04983.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2411.04983.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.18837.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.18837.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.18837.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.18841.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.18841.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.18841.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.18753.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.18753.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.18753.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2501.18128.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2501.18128.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2501.18128.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Downloading and parsing paper https://huggingface.co/papers/2404.07097.
[03.02.2025 15:10] Extra JSON file exists (./assets/json/2404.07097.json), skip PDF parsing.
[03.02.2025 15:10] Paper image links file exists (./assets/img_data/2404.07097.json), skip HTML parsing.
[03.02.2025 15:10] Success.
[03.02.2025 15:10] Enriching papers with extra data.
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 0. Test-time scaling is a promising new approach to language modeling that uses extra test-time compute to improve performance. Recently, OpenAI's o1 model showed this capability but did not publicly share its methodology, leading to many replication efforts. We seek the simplest approach to achieve te...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 1. ...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 2. Due to the presence of the natural gap between Knowledge Graph (KG) structures and the natural language, the effective integration of holistic structural information of KGs with Large Language Models (LLMs) has emerged as a significant question. To this end, we propose a two-stage framework to learn...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 3. The ability to predict future outcomes given control actions is fundamental for physical reasoning. However, such predictive models, often called world models, have proven challenging to learn and are typically developed for task-specific solutions with online policy learning. We argue that the true...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 4. Large language models (LLMs) are vulnerable to universal jailbreaks-prompting strategies that systematically bypass model safeguards and enable users to carry out harmful processes that require many model interactions, like manufacturing illegal substances at scale. To defend against these attacks, ...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 5. We conduct experiments on the impact of increasing inference-time compute in reasoning models (specifically OpenAI o1-preview and o1-mini) on their robustness to adversarial attacks. We find that across a variety of attacks, increased inference-time compute leads to improved robustness. In many case...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 6. Task-generic promptable image segmentation aims to achieve segmentation of diverse samples under a single task description by utilizing only one task-generic prompt. Current methods leverage the generalization capabilities of Vision-Language Models (VLMs) to infer instance-specific prompts from thes...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 7. Given the recent introduction of multiple language models and the ongoing demand for improved Natural Language Processing tasks, particularly summarization, this work provides a comprehensive benchmarking of 20 recent language models, focusing on smaller ones for the news summarization task. In this...
[03.02.2025 15:10] ********************************************************************************
[03.02.2025 15:10] Abstract 8. This paper addresses the long-standing challenge of reconstructing 3D structures from videos with dynamic content. Current approaches to this problem were not designed to operate on casual videos recorded by standard cameras or require a long optimization time.   Aiming to significantly improve the ...
[03.02.2025 15:10] Read previous papers.
[03.02.2025 15:10] Generating reviews via LLM API.
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#reasoning", "#training", "#math", "#optimization", "#data"], "emoji": "üß†", "ru": {"title": "–ü—Ä–æ—Å—Ç–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —è–∑—ã–∫–æ–≤–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π —Ç–µ—Å—Ç–æ–≤—ã–º –º–∞—Å—à
[03.02.2025 15:10] Using data from previous issue: {"categories": [], "emoji": "ü§ñ", "ru": {"title": "–ù–æ–≤—ã–π —à–∞–≥ –≤ –æ–±—É—á–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é LLM, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —É–ª—É—á—à–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#inference", "#graphs", "#transfer_learning", "#training", "#multimodal", "#data"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–æ–≤ –∑–Ω–∞–Ω–∏–π –∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–¥—ã", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–æ–≤ –∑–Ω–∞–Ω–∏–π —Å –±–æ–ª—å—à–∏–º–∏ 
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#cv", "#agents", "#reasoning", "#optimization", "#rl"], "emoji": "üß†", "ru": {"title": "DINO-WM: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –±–µ–∑ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏ –±–µ–∑ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –º–∏—Ä–∞ - DI
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#synthetic", "#training", "#architecture", "#dataset", "#security", "#inference"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω—ã–µ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã: –Ω–∞–¥–µ–∂–Ω–∞—è –∑–∞—â–∏—Ç–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω—ã—Ö –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ - –∑–∞—â–∏—Ç–Ω—ã—Ö –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –¥–ª
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#security", "#reasoning", "#inference"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ë–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π - –≤—ã—à–µ –∑–∞—â–∏—Ç–∞: –ø–æ–≤—ã—à–µ–Ω–∏–µ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –ò–ò –∫ –∞—Ç–∞–∫–∞–º", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –≤–ª–∏—è–Ω–∏—é —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –≤–æ –≤—Ä–µ–º—è –≤—ã–≤–æ–¥–∞ –Ω–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∫ —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#dataset", "#healthcare", "#optimization", "#cv"], "emoji": "üîç", "ru": {"title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø—Ä–æ–º–ø—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º INT (Instance-specific Negative Mining fo
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#survey", "#multilingual", "#small_models", "#benchmark", "#transfer_learning"], "emoji": "üì∞", "ru": {"title": "–ú–∞–ª–µ–Ω—å–∫–∏–µ –º–æ–¥–µ–ª–∏ –±—Ä–æ—Å–∞—é—Ç –≤—ã–∑–æ–≤ –≥–∏–≥–∞–Ω—Ç–∞–º –≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π", "desc": "–í —ç—Ç–æ–π —Ä–∞–±–æ—Ç–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ 20 —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –º–µ
[03.02.2025 15:10] Using data from previous issue: {"categories": ["#3d", "#training", "#cv", "#architecture"], "emoji": "üé•", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∏–∑ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç TracksTo4D - –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ 3D —Å—Ç—Ä—É–∫—Ç—É—Ä –∏–∑ –≤–∏–¥–µ–æ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ
[03.02.2025 15:10] Loading Chinese text from previous data.
[03.02.2025 15:10] Renaming data file.
[03.02.2025 15:10] Renaming previous data. hf_papers.json to ./d/2025-02-03.json
[03.02.2025 15:10] Saving new data file.
[03.02.2025 15:10] Generating page.
[03.02.2025 15:10] Renaming previous page.
[03.02.2025 15:10] Renaming previous data. index.html to ./d/2025-02-03.html
[03.02.2025 15:10] [Experimental] Generating Chinese page for reading.
[03.02.2025 15:10] Chinese vocab [{'word': 'Âª∫Ê®°', 'pinyin': 'ji√†n m√≥', 'trans': 'modeling'}, {'word': 'Áß∞‰∏∫', 'pinyin': 'chƒìng w√©i', 'trans': 'called'}, {'word': 'Áº©Êîæ', 'pinyin': 'su≈ç f√†ng', 'trans': 'scaling'}, {'word': 'Â±ïÁ§∫', 'pinyin': 'zh«én sh√¨', 'trans': 'demonstrate'}, {'word': 'ËÉΩÂäõ', 'pinyin': 'n√©ng l√¨', 'trans': 'capability'}, {'word': 'ÂÖ¨ÂºÄ', 'pinyin': 'g≈çng kƒÅi', 'trans': 'public'}, {'word': 'Â§çÂà∂', 'pinyin': 'f√π zh√¨', 'trans': 'replicate'}, {'word': 'Âä™Âäõ', 'pinyin': 'n«î l√¨', 'trans': 'efforts'}, {'word': 'Êï¥ÁêÜ', 'pinyin': 'zhƒõng l«ê', 'trans': 'organize'}, {'word': 'È¢ÑÁÆó', 'pinyin': 'y√π su√†n', 'trans': 'budget'}, {'word': 'Âº∫Âà∂', 'pinyin': 'qi√°ng zh√¨', 'trans': 'enforcement'}, {'word': 'ÈÄîÂæÑ', 'pinyin': 't√∫ j√¨ng', 'trans': 'means'}, {'word': 'ÂÆûÁé∞', 'pinyin': 'sh√≠ xi√†n', 'trans': 'achieve'}, {'word': 'Êé®ÁêÜ', 'pinyin': 'tuƒ´ l«ê', 'trans': 'reasoning'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'Ë∂ÖË∂ä', 'pinyin': 'chƒÅo yu√®', 'trans': 'surpass'}, {'word': 'ÂºÄÊ∫ê', 'pinyin': 'kƒÅi yu√°n', 'trans': 'open-source'}]
[03.02.2025 15:10] Renaming previous Chinese page.
[03.02.2025 15:10] Renaming previous data. zh.html to ./d/2025-02-02_zh_reading_task.html
[03.02.2025 15:10] Writing Chinese reading task.
[03.02.2025 15:10] Writing result.
[03.02.2025 15:10] Renaming log file.
[03.02.2025 15:10] Renaming previous data. log.txt to ./logs/2025-02-03_last_log.txt
