[03.02.2025 21:09] Read previous papers.
[03.02.2025 21:09] Generating top page (month).
[03.02.2025 21:09] Writing top page (month).
[03.02.2025 22:09] Read previous papers.
[03.02.2025 22:09] Get feed.
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.19393
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.19324
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18119
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.19339
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.14677
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.19399
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04983
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18837
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18841
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18052
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18804
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18965
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18753
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2501.18128
[03.02.2025 22:09] Get page data from previous paper. URL: https://huggingface.co/papers/2404.07097
[03.02.2025 22:09] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[03.02.2025 22:09] No deleted papers detected.
[03.02.2025 22:09] Downloading and parsing papers (pdf, html). Total: 15.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.19393.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.19393.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.19393.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.19324.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.19324.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.19324.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18119.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18119.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18119.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.19339.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.19339.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.19339.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.14677.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.14677.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.14677.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.19399.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.19399.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.19399.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2411.04983.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2411.04983.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2411.04983.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18837.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18837.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18837.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18841.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18841.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18841.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18052.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18052.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18052.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18804.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18804.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18804.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18965.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18965.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18965.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18753.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18753.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18753.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2501.18128.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2501.18128.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2501.18128.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Downloading and parsing paper https://huggingface.co/papers/2404.07097.
[03.02.2025 22:09] Extra JSON file exists (./assets/json/2404.07097.json), skip PDF parsing.
[03.02.2025 22:09] Paper image links file exists (./assets/img_data/2404.07097.json), skip HTML parsing.
[03.02.2025 22:09] Success.
[03.02.2025 22:09] Enriching papers with extra data.
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 0. Test-time scaling is a promising new approach to language modeling that uses extra test-time compute to improve performance. Recently, OpenAI's o1 model showed this capability but did not publicly share its methodology, leading to many replication efforts. We seek the simplest approach to achieve te...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 1. ...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 2. Due to the presence of the natural gap between Knowledge Graph (KG) structures and the natural language, the effective integration of holistic structural information of KGs with Large Language Models (LLMs) has emerged as a significant question. To this end, we propose a two-stage framework to learn...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 3. Existing foundation models typically process visual input as pixels and textual input as tokens, a paradigm that contrasts with human perception, where both modalities are processed in a unified manner. With the rise of embodied and agentic AI, where inputs primarily come from camera pixels, the nee...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 4. Auxiliary-free human video matting methods, which rely solely on input frames, often struggle with complex or ambiguous backgrounds. To address this, we propose MatAnyone, a robust framework tailored for target-assigned video matting. Specifically, building on a memory-based paradigm, we introduce a...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 5. The maximum element of the vector output by the Softmax function approaches zero as the input vector size increases. Transformer-based language models rely on Softmax to compute attention scores, causing the attention distribution to flatten as the context size grows. This reduces the model's abilit...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 6. The ability to predict future outcomes given control actions is fundamental for physical reasoning. However, such predictive models, often called world models, have proven challenging to learn and are typically developed for task-specific solutions with online policy learning. We argue that the true...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 7. Large language models (LLMs) are vulnerable to universal jailbreaks-prompting strategies that systematically bypass model safeguards and enable users to carry out harmful processes that require many model interactions, like manufacturing illegal substances at scale. To defend against these attacks, ...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 8. We conduct experiments on the impact of increasing inference-time compute in reasoning models (specifically OpenAI o1-preview and o1-mini) on their robustness to adversarial attacks. We find that across a variety of attacks, increased inference-time compute leads to improved robustness. In many case...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 9. Diffusion models, while powerful, can inadvertently generate harmful or undesirable content, raising significant ethical and safety concerns. Recent machine unlearning approaches offer potential solutions but often lack transparency, making it difficult to understand the changes they introduce to th...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 10. Current methods for 3D scene reconstruction from sparse posed images employ intermediate 3D representations such as neural fields, voxel grids, or 3D Gaussians, to achieve multi-view consistent scene appearance and geometry. In this paper we introduce MVGD, a diffusion-based architecture capable of ...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 11. We show that learning-rate schedules for large model training behave surprisingly similar to a performance bound from non-smooth convex optimization theory. We provide a bound for the constant schedule with linear cooldown; in particular, the practical benefit of cooldown is reflected in the bound d...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 12. Task-generic promptable image segmentation aims to achieve segmentation of diverse samples under a single task description by utilizing only one task-generic prompt. Current methods leverage the generalization capabilities of Vision-Language Models (VLMs) to infer instance-specific prompts from thes...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 13. Given the recent introduction of multiple language models and the ongoing demand for improved Natural Language Processing tasks, particularly summarization, this work provides a comprehensive benchmarking of 20 recent language models, focusing on smaller ones for the news summarization task. In this...
[03.02.2025 22:09] ********************************************************************************
[03.02.2025 22:09] Abstract 14. This paper addresses the long-standing challenge of reconstructing 3D structures from videos with dynamic content. Current approaches to this problem were not designed to operate on casual videos recorded by standard cameras or require a long optimization time.   Aiming to significantly improve the ...
[03.02.2025 22:09] Read previous papers.
[03.02.2025 22:09] Generating reviews via LLM API.
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#reasoning", "#training", "#math", "#optimization", "#data"], "emoji": "🧠", "ru": {"title": "Простое масштабирование для улучшения рассуждений языковых моделей", "desc": "Статья представляет новый подход к языковому моделированию, называемый тестовым масш
[03.02.2025 22:09] Using data from previous issue: {"categories": [], "emoji": "🤖", "ru": {"title": "Новый шаг в обучении больших языковых моделей", "desc": "В статье рассматривается новый подход к обучению LLM, который позволяет моделям лучше понимать контекст и улучшать качество генерации текста. Исследователи предложили метод, который использует 
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#inference", "#graphs", "#transfer_learning", "#training", "#multimodal", "#data"], "emoji": "🧠", "ru": {"title": "Эффективная интеграция графов знаний и языковых моделей через квантованные коды", "desc": "Статья представляет двухэтапный подход к интеграции графов знаний с большими 
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#agi", "#benchmark", "#optimization", "#dataset", "#open_source", "#reasoning", "#multimodal", "#interpretability", "#cv"], "emoji": "🧠", "ru": {"title": "Единый пиксельный взгляд на мир: новая парадигма для ИИ", "desc": "В статье предлагается новый подход к обработке различных мода
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#training", "#dataset", "#video"], "emoji": "✂️", "ru": {"title": "MatAnyone: Точное выделение объектов на видео с помощью памяти и адаптивного обучения", "desc": "MatAnyone - это новый подход к выделению объектов на видео без вспомогательных данных. Он использует модуль памяти для 
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#architecture", "#training", "#long_context", "#optimization"], "emoji": "🔍", "ru": {"title": "SSMax: улучшение внимания трансформеров для длинных текстов", "desc": "Статья представляет новую функцию Scalable-Softmax (SSMax) для улучшения работы трансформеров с длинными контекстами.
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#cv", "#agents", "#reasoning", "#optimization", "#rl"], "emoji": "🧠", "ru": {"title": "DINO-WM: универсальная модель мира для планирования поведения без реконструкции", "desc": "Статья представляет новый метод моделирования визуальной динамики без реконструкции визуального мира - DI
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#synthetic", "#training", "#architecture", "#dataset", "#security", "#inference"], "emoji": "🛡️", "ru": {"title": "Конституционные Классификаторы: надежная защита языковых моделей", "desc": "Исследование представляет концепцию Конституционных Классификаторов - защитных механизмов дл
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#security", "#reasoning", "#inference"], "emoji": "🛡️", "ru": {"title": "Больше вычислений - выше защита: повышение устойчивости ИИ к атакам", "desc": "Исследование посвящено влиянию увеличения вычислительных ресурсов во время вывода на устойчивость моделей рассуждений к состязатель
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#dataset", "#interpretability", "#security", "#architecture", "#ethics", "#training", "#benchmark"], "emoji": "🧹", "ru": {"title": "Чистка нейросетей: SAeUron удаляет нежелательные концепции из диффузионных моделей", "desc": "SAeUron - это новый метод удаления нежелательных концепци
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#training", "#3d", "#diffusion", "#architecture", "#benchmark", "#optimization"], "emoji": "🎭", "ru": {"title": "Генерация 3D сцен из разных ракурсов с помощью диффузионной модели", "desc": "Статья представляет MVGD - архитектуру на основе диффузии для генерации изображений и карт г
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#transfer_learning", "#math", "#training", "#optimization"], "emoji": "📈", "ru": {"title": "Оптимизация графиков обучения для больших языковых моделей", "desc": "В статье исследуются графики изменения скорости обучения для больших моделей машинного обучения. Авторы обнаружили неожид
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#dataset", "#healthcare", "#optimization", "#cv"], "emoji": "🔍", "ru": {"title": "Адаптивная сегментация изображений с помощью интеллектуального отбора промптов", "desc": "Статья представляет новый метод сегментации изображений под названием INT (Instance-specific Negative Mining fo
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#survey", "#multilingual", "#small_models", "#benchmark", "#transfer_learning"], "emoji": "📰", "ru": {"title": "Маленькие модели бросают вызов гигантам в суммаризации новостей", "desc": "В этой работе проводится комплексное сравнение 20 современных языковых моделей, с акцентом на ме
[03.02.2025 22:09] Using data from previous issue: {"categories": ["#3d", "#training", "#cv", "#architecture"], "emoji": "🎥", "ru": {"title": "Эффективная 3D реконструкция из видео с помощью глубокого обучения", "desc": "Статья представляет TracksTo4D - новый подход к реконструкции 3D структур из видео с динамическим содержанием. Метод использует не
[03.02.2025 22:09] Loading Chinese text from previous data.
[03.02.2025 22:09] Renaming data file.
[03.02.2025 22:09] Renaming previous data. hf_papers.json to ./d/2025-02-03.json
[03.02.2025 22:09] Saving new data file.
[03.02.2025 22:09] Generating page.
[03.02.2025 22:09] Renaming previous page.
[03.02.2025 22:09] Renaming previous data. index.html to ./d/2025-02-03.html
[03.02.2025 22:09] [Experimental] Generating Chinese page for reading.
[03.02.2025 22:09] Chinese vocab [{'word': '建模', 'pinyin': 'jiàn mó', 'trans': 'modeling'}, {'word': '称为', 'pinyin': 'chēng wéi', 'trans': 'called'}, {'word': '缩放', 'pinyin': 'suō fàng', 'trans': 'scaling'}, {'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'}, {'word': '能力', 'pinyin': 'néng lì', 'trans': 'capability'}, {'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'}, {'word': '复制', 'pinyin': 'fù zhì', 'trans': 'replicate'}, {'word': '努力', 'pinyin': 'nǔ lì', 'trans': 'efforts'}, {'word': '整理', 'pinyin': 'zhěng lǐ', 'trans': 'organize'}, {'word': '预算', 'pinyin': 'yù suàn', 'trans': 'budget'}, {'word': '强制', 'pinyin': 'qiáng zhì', 'trans': 'enforcement'}, {'word': '途径', 'pinyin': 'tú jìng', 'trans': 'means'}, {'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '超越', 'pinyin': 'chāo yuè', 'trans': 'surpass'}, {'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'}]
[03.02.2025 22:09] Renaming previous Chinese page.
[03.02.2025 22:09] Renaming previous data. zh.html to ./d/2025-02-02_zh_reading_task.html
[03.02.2025 22:09] Writing Chinese reading task.
[03.02.2025 22:09] Writing result.
[03.02.2025 22:09] Renaming log file.
[03.02.2025 22:09] Renaming previous data. log.txt to ./logs/2025-02-03_last_log.txt
