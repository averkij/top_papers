[25.02.2025 16:13] Read previous papers.
[25.02.2025 16:13] Generating top page (month).
[25.02.2025 16:13] Writing top page (month).
[25.02.2025 17:11] Read previous papers.
[25.02.2025 17:11] Get feed.
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17129
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17258
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17157
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15814
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16584
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17435
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16614
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16894
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17407
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16033
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15894
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17110
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17055
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16707
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15987
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16922
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.16701
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15425
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.14132
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17414
[25.02.2025 17:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.15799
[25.02.2025 17:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.14429
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15122
[25.02.2025 17:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.15823
[25.02.2025 17:11] Extract page data from URL. URL: https://huggingface.co/papers/2502.16622
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.15167
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.17237
[25.02.2025 17:11] Get page data from previous paper. URL: https://huggingface.co/papers/2502.13074
[25.02.2025 17:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[25.02.2025 17:11] No deleted papers detected.
[25.02.2025 17:11] Downloading and parsing papers (pdf, html). Total: 28.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17129.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17129.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17129.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17258.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17258.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17258.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17157.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17157.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17157.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15814.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.15814.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.15814.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16584.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16584.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16584.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17435.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17435.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17435.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16614.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16614.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16614.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16894.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16894.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16894.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17407.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17407.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17407.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16033.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16033.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16033.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15894.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.15894.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.15894.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17110.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17110.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17110.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17055.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17055.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17055.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16707.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16707.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16707.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15987.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.15987.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.15987.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16922.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16922.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16922.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.16701.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.16701.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.16701.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15425.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.15425.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.15425.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.14132.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.14132.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.14132.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.17414.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.17414.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.17414.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15799.
[25.02.2025 17:11] Downloading paper 2502.15799 from http://arxiv.org/pdf/2502.15799v1...
[25.02.2025 17:11] Extracting affiliations from text.
[25.02.2025 17:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models Artyom Kharinaev(cid:51) 1, Viktor Moskvoretskii 1,3, Egor Shvetsov1, Kseniia Studenikina(cid:51), Bykov Mikhail(cid:51), Evgeny Burnaev 1,2 1 Skolkovo Institute of Science and Technology 2 Artificial Intelligence Research Institute 3 HSE University Correspondence: e.shvetsov@skol.tech indicates equal contribution. (cid:51) indicates that the work was partially done during SMILES summer school. Abstract 5 2 0 2 8 1 ] . [ 1 9 9 7 5 1 . 2 0 5 2 : r Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains significant barrier to widespread adoption. Quantization has emerged as promising technique to democratize access and enable low resource device deployment. Despite these advancements, the safety and trustworthiness of quantized models remain underexplored, as prior studies often overlook contemporary architectures and rely on overly simplistic benchmarks and evaluations. To address this gap, we introduce OpenSafetyMini, novel openended safety dataset designed to better distinguish between models. We evaluate 4 state-ofthe-art quantization techniques across LLaMA and Mistral models using 4 benchmarks, including human evaluations. Our findings reveal that the optimal quantization method varies for 4-bit precision, while vector quantization techniques deliver the best safety and trustworthiness performance at 2-bit precision, providing foundation for future research. The modern state of artificial intelligence (AI) is built on the scaling paradigm, initially focusing on increasing model size (Hoffmann et al., 2022) and later shifting toward test-time compute scaling (Snell et al., 2024; Geiping et al., 2025). These paradigms demand substantial computational resources, particularly for inference involving longer meta-reasoning (Gao et al., 2024). To dem"
[25.02.2025 17:11] Response: ```python
["Skolkovo Institute of Science and Technology", "Artificial Intelligence Research Institute", "HSE University"]
```
[25.02.2025 17:11] Deleting PDF ./assets/pdf/2502.15799.pdf.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.14429.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.14429.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.14429.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15122.
[25.02.2025 17:11] Extra JSON file exists (./assets/json/2502.15122.json), skip PDF parsing.
[25.02.2025 17:11] Paper image links file exists (./assets/img_data/2502.15122.json), skip HTML parsing.
[25.02.2025 17:11] Success.
[25.02.2025 17:11] Downloading and parsing paper https://huggingface.co/papers/2502.15823.
[25.02.2025 17:11] Downloading paper 2502.15823 from http://arxiv.org/pdf/2502.15823v1...
[25.02.2025 17:12] Extracting affiliations from text.
[25.02.2025 17:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 0 2 ] . [ 1 3 2 8 5 1 . 2 0 5 2 : r InductionBench: LLMs Fail in the Simplest Complexity Class Wenyue Hua1 Tyler Wong1 Sun Fei2 Liangming Pan3 Adam Jardine4 William Yang Wang1 1University of California, Santa Barbara, 2Independent Researcher 3University of Arizona, 4Rutgers University, New Brunswick February 25, "
[25.02.2025 17:12] Response: ```python
["University of California, Santa Barbara", "Independent Researcher", "University of Arizona", "Rutgers University, New Brunswick"]
```
[25.02.2025 17:12] Deleting PDF ./assets/pdf/2502.15823.pdf.
[25.02.2025 17:12] Success.
[25.02.2025 17:12] Downloading and parsing paper https://huggingface.co/papers/2502.16622.
[25.02.2025 17:12] Extra JSON file exists (./assets/json/2502.16622.json), skip PDF parsing.
[25.02.2025 17:12] Paper image links file exists (./assets/img_data/2502.16622.json), skip HTML parsing.
[25.02.2025 17:12] Success.
[25.02.2025 17:12] Downloading and parsing paper https://huggingface.co/papers/2502.15167.
[25.02.2025 17:12] Extra JSON file exists (./assets/json/2502.15167.json), skip PDF parsing.
[25.02.2025 17:12] Paper image links file exists (./assets/img_data/2502.15167.json), skip HTML parsing.
[25.02.2025 17:12] Success.
[25.02.2025 17:12] Downloading and parsing paper https://huggingface.co/papers/2502.17237.
[25.02.2025 17:12] Extra JSON file exists (./assets/json/2502.17237.json), skip PDF parsing.
[25.02.2025 17:12] Paper image links file exists (./assets/img_data/2502.17237.json), skip HTML parsing.
[25.02.2025 17:12] Success.
[25.02.2025 17:12] Downloading and parsing paper https://huggingface.co/papers/2502.13074.
[25.02.2025 17:12] Extra JSON file exists (./assets/json/2502.13074.json), skip PDF parsing.
[25.02.2025 17:12] Paper image links file exists (./assets/img_data/2502.13074.json), skip HTML parsing.
[25.02.2025 17:12] Success.
[25.02.2025 17:12] Enriching papers with extra data.
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 0. Long context is an important topic in Natural Language Processing (NLP), running through the development of NLP architectures, and offers immense opportunities for Large Language Models (LLMs) giving LLMs the lifelong learning potential akin to humans. Unfortunately, the pursuit of a long context is...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 1. Recent advancements in diffusion models have significantly improved video generation and editing capabilities. However, multi-grained video editing, which encompasses class-level, instance-level, and part-level modifications, remains a formidable challenge. The major difficulties in multi-grained ed...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 2. Our primary goal here is to create a good, generalist perception model that can tackle multiple tasks, within limits on computational resources and training data. To achieve this, we resort to text-to-image diffusion models pre-trained on billions of images. Our exhaustive evaluation metrics demonst...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 3. We introduce Slam, a recipe for training high-quality Speech Language Models (SLMs) on a single academic GPU in 24 hours. We do so through empirical analysis of model initialisation and architecture, synthetic training data, preference optimisation with synthetic data and tweaking all other componen...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 4. Recent advancements in audio tokenization have significantly enhanced the integration of audio capabilities into large language models (LLMs). However, audio understanding and generation are often treated as distinct tasks, hindering the development of truly unified audio-language models. While inst...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 5. Color constancy methods often struggle to generalize across different camera sensors due to varying spectral sensitivities. We present GCC, which leverages diffusion models to inpaint color checkers into images for illumination estimation. Our key innovations include (1) a single-step deterministic ...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 6. The critique capacity of Large Language Models (LLMs) is essential for reasoning abilities, which can provide necessary suggestions (e.g., detailed analysis and constructive feedback). Therefore, how to evaluate the critique capacity of LLMs has drawn great attention and several critique benchmarks ...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 7. While Low-Rank Adaptation (LoRA) enables parameter-efficient fine-tuning for Large Language Models (LLMs), its performance often falls short of Full Fine-Tuning (Full FT). Current methods optimize LoRA by initializing with static singular value decomposition (SVD) subsets, leading to suboptimal leve...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 8. Scaling pre-training compute has proven effective for achieving mulitlinguality, but does the same hold for test-time scaling? In this work, we introduce MCLM, a multilingual math benchmark featuring competition-level problems in 55 languages. We test three test-time scaling methods-Outcome Reward M...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 9. Existing Multimodal Large Language Models (MLLMs) are predominantly trained and tested on consistent visual-textual inputs, leaving open the question of whether they can handle inconsistencies in real-world, layout-rich content. To bridge this gap, we propose the Multimodal Inconsistency Reasoning (...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 10. Recent advancements in video generation have enabled models to synthesize high-quality, minute-long videos. However, generating even longer videos with temporal coherence remains a major challenge, and existing length extrapolation methods lead to temporal repetition or motion deceleration. In this ...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 11. The rapid increase in mobile device usage necessitates improved automation for seamless task management. However, many AI-driven frameworks struggle due to insufficient operational knowledge. Manually written knowledge helps but is labor-intensive and inefficient. To address these challenges, we int...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 12. This paper comprehensively evaluates several recently proposed optimizers for 4-bit training, revealing that low-bit precision amplifies sensitivity to learning rates and often causes unstable gradient norms, leading to divergence at higher learning rates. Among these, SPAM, a recent optimizer featu...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 13. Solving complex long-horizon robotic manipulation problems requires sophisticated high-level planning capabilities, the ability to reason about the physical world, and reactively choose appropriate motor skills. Vision-language models (VLMs) pretrained on Internet data could in principle offer a fra...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 14. As the open-weight AI landscape continues to proliferate-with model development, significant investment, and user interest-it becomes increasingly important to predict which models will ultimately drive innovation and shape AI ecosystems. Building on parallels with citation dynamics in scientific li...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 15. Temporal reasoning is fundamental to human cognition and is crucial for various real-world applications. While recent advances in Large Language Models have demonstrated promising capabilities in temporal reasoning, existing benchmarks primarily rely on rule-based construction, lack contextual depth...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 16. Generative AI release decisions determine whether system components are made available, but release does not address many other elements that change how users and stakeholders are able to engage with a system. Beyond release, access to system components informs potential risks and benefits. Access r...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 17. Hierarchical organization is fundamental to biological systems and human societies, yet artificial intelligence systems often rely on monolithic architectures that limit adaptability and scalability. Current hierarchical reinforcement learning (HRL) approaches typically restrict hierarchies to two l...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 18. Two commonly-employed strategies to combat the rise of misinformation on social media are (i) fact-checking by professional organisations and (ii) community moderation by platform users. Policy changes by Twitter/X and, more recently, Meta, signal a shift away from partnerships with fact-checking or...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 19. We present X-Dancer, a novel zero-shot music-driven image animation pipeline that creates diverse and long-range lifelike human dance videos from a single static image. As its core, we introduce a unified transformer-diffusion framework, featuring an autoregressive transformer model that synthesize ...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 20. Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains a significant barrier to widespread adoption. Quantization has emerged as a promising technique to democratize access and ena...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 21. Quality estimation is omnipresent in machine translation, for both evaluation and generation. Unfortunately, quality estimation models are often opaque and computationally expensive, making them impractical to be part of large-scale pipelines. In this work, we tackle two connected challenges: (1) re...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 22. We introduce MONSTER-the MONash Scalable Time Series Evaluation Repository-a collection of large datasets for time series classification. The field of time series classification has benefitted from common benchmarks set by the UCR and UEA time series classification repositories. However, the dataset...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 23. Large language models (LLMs) have shown remarkable improvements in reasoning and many existing benchmarks have been addressed by models such as o1 and o3 either fully or partially. However, a majority of these benchmarks emphasize deductive reasoning, including mathematical and coding tasks in which...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 24. The COVID-19 pandemic strained healthcare resources and prompted discussion about how machine learning can alleviate physician burdens and contribute to diagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but few studies predict the severity of a patient's condition from CXRs. In this...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 25. The rapid advancement of AI-generated image (AGI) models has introduced significant challenges in evaluating their quality, which requires considering multiple dimensions such as perceptual quality, prompt correspondence, and authenticity. To address these challenges, we propose M3-AGIQA, a comprehe...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 26. Retrieving images from the same location as a given query is an important component of multiple computer vision tasks, like Visual Place Recognition, Landmark Retrieval, Visual Localization, 3D reconstruction, and SLAM. However, existing solutions are built to specifically work for one of these task...
[25.02.2025 17:12] ********************************************************************************
[25.02.2025 17:12] Abstract 27. The Brownian sphere is a random metric space, homeomorphic to the two-dimensional sphere, which arises as the universal scaling limit of many types of random planar maps. The direct construction of the Brownian sphere is via a continuous analogue of the Cori--Vauquelin--Schaeffer (CVS) bijection. Th...
[25.02.2025 17:12] Read previous papers.
[25.02.2025 17:12] Generating reviews via LLM API.
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#benchmark", "#long_context", "#survey", "#training", "#architecture"], "emoji": "🔍", "ru": {"title": "Преодолевая границы: путь к LLM с длинным контекстом", "desc": "Данная статья представляет обзор исследований в области обработки длинного контекста в больших языковых моделях (LLM
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#diffusion", "#video", "#multimodal"], "emoji": "🎬", "ru": {"title": "Точное редактирование видео с помощью искусственного интеллекта", "desc": "VideoGrain - это новый подход к многоуровневому редактированию видео с использованием диффузионных моделей. Он решает проблемы семантическ
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#optimization", "#transfer_learning", "#diffusion", "#cv", "#dataset", "#training"], "emoji": "🧠", "ru": {"title": "Универсальное восприятие через диффузию текста в изображения", "desc": "Статья представляет DICEPTION - универсальную модель восприятия, основанную на предобученных ди
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#audio", "#synthetic", "#data", "#optimization", "#architecture", "#open_source", "#training"], "emoji": "🗣️", "ru": {"title": "Революция в обучении речевых моделей: качество и скорость на доступном оборудовании", "desc": "Исследователи представляют Slam - метод обучения высококачес
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#audio", "#dataset"], "emoji": "🎵", "ru": {"title": "Единая модель для понимания и генерации аудио", "desc": "Статья представляет Audio-FLAN - масштабный датасет для обучения языковых моделей работе с аудио. Он охватывает 80 разнообразных задач в области речи, музыки и звука, содерж
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#inference", "#cv"], "emoji": "🎨", "ru": {"title": "Универсальная оценка освещения для любых камер", "desc": "Статья представляет новый метод GCC для оценки освещения на изображениях с использованием диффузионных моделей. GCC применяет однократное детерминистическое предсказание для
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#reasoning"], "emoji": "🔬", "ru": {"title": "CodeCriticBench: комплексная оценка критических способностей LLM в задачах работы с кодом", "desc": "Статья представляет новый бенчмарк CodeCriticBench для оценки способностей больших языковых моделей (LLM) крити
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#training", "#optimization", "#architecture", "#reasoning"], "emoji": "🐐", "ru": {"title": "GOAT: Эффективная низкоранговая адаптация на уровне полной тонкой настройки", "desc": "Этa статья представляет новый метод под названием GOAT (Great LoRA Mixture-of-Expert) для улучшения эффе
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#low_resource", "#dataset", "#long_context", "#multilingual", "#benchmark", "#math"], "emoji": "🌐", "ru": {"title": "Масштабирование ЯМ во время вывода: вызовы многоязычности", "desc": "Исследование представляет MCLM - многоязычный математический бенчмарк с задачами соревновательног
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#open_source", "#reasoning"], "emoji": "🧠", "ru": {"title": "Новый рубеж в мультимодальном анализе: оценка способности ИИ распознавать несоответствия", "desc": "Статья представляет новый бенчмарк MMIR для оценки способности мультимодальных больших языков
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#synthetic", "#optimization", "#diffusion", "#video"], "emoji": "🎬", "ru": {"title": "RIFLEx: Революция в генерации длинных видео без повторений", "desc": "Статья представляет новый метод RIFLEx для генерации длинных видео с сохранением временной когерентности. Авторы анализируют ро
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#video", "#agents"], "emoji": "📱", "ru": {"title": "Видео-инструкции для ИИ: революция в автоматизации мобильных устройств", "desc": "Mobile-Agent-V - это новая система автоматизации мобильных устройств, использующая видеоинструкции для обучения. Она применяет стратегию скользящего 
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#optimization", "#inference", "#training"], "emoji": "🧠", "ru": {"title": "Стабильное обучение нейросетей с низкой битностью", "desc": "Статья представляет всестороннюю оценку оптимизаторов для 4-битного обучения нейронных сетей. Авторы выявили, что низкобитная точность усиливает чу
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#reasoning", "#agents", "#optimization", "#robotics", "#multimodal"], "emoji": "🤖", "ru": {"title": "Рефлексивное улучшение VLM для продвинутой роботизированной манипуляции", "desc": "Статья представляет новый подход к улучшению возможностей моделей компьютерного зрения и обработки 
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#science", "#benchmark", "#open_source", "#training"], "emoji": "📈", "ru": {"title": "Измеряем влияние ИИ-моделей через призму научных цитирований", "desc": "Статья предлагает framework для количественной оценки влияния open-weight моделей в сфере ИИ. Авторы адаптируют модель Ванга 
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#science", "#reasoning", "#multilingual", "#benchmark"], "emoji": "⏳", "ru": {"title": "CTM: Новый рубеж в оценке временных рассуждений языковых моделей", "desc": "Статья представляет новый бенчмарк для оценки способностей больших языковых моделей (LLM) в области временных рассужден
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#ethics", "#open_source"], "emoji": "🔓", "ru": {"title": "Доступ к ИИ: больше, чем просто релиз", "desc": "Статья рассматривает вопросы доступа к компонентам систем искусственного интеллекта, выходящие за рамки простого решения о релизе. Авторы предлагают фреймворк для анализа досту
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#optimization", "#rl", "#games", "#architecture", "#agents", "#benchmark", "#training"], "emoji": "🌳", "ru": {"title": "Децентрализованная иерархия для масштабируемых мультиагентных систем", "desc": "Статья представляет TAME Agent Framework (TAG) - новый подход к созданию полностью 
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#multimodal", "#science", "#ethics", "#data", "#dataset"], "emoji": "🔍", "ru": {"title": "Фактчекинг - ключ к эффективной пользовательской модерации", "desc": "Это исследование анализирует взаимосвязь между профессиональным фактчекингом и пользовательской модерацией в социальных сет
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#architecture", "#video", "#multimodal"], "emoji": "💃", "ru": {"title": "Танцующие изображения: ИИ оживляет фото под музыку", "desc": "X-Dancer - это новая система для создания анимированных видео танцев из статичного изображения под музыку без предвар
[25.02.2025 17:12] Querying the API.
[25.02.2025 17:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains a significant barrier to widespread adoption. Quantization has emerged as a promising technique to democratize access and enable low resource device deployment. Despite these advancements, the safety and trustworthiness of quantized models remain underexplored, as prior studies often overlook contemporary architectures and rely on overly simplistic benchmarks and evaluations. To address this gap, we introduce OpenSafetyMini, a novel open-ended safety dataset designed to better distinguish between models. We evaluate 4 state-of-the-art quantization techniques across LLaMA and Mistral models using 4 benchmarks, including human evaluations. Our findings reveal that the optimal quantization method varies for 4-bit precision, while vector quantization techniques deliver the best safety and trustworthiness performance at 2-bit precision, providing foundation for future research.
[25.02.2025 17:12] Response: {
  "desc": "Эта статья исследует влияние квантования на безопасность и надежность больших языковых моделей (LLM). Авторы представляют новый набор данных OpenSafetyMini для лучшей оценки моделей. Они сравнивают 4 современных метода квантования на моделях LLaMA и Mistral, используя 4 бенчмарка, включая оценку людьми. Результаты показывают, что оптимальный метод квантования варьируется для 4-битной точности, а методы векторного квантования дают лучшие результаты при 2-битной точности.",
  "emoji": "🔬",
  "title": "Безопасное квантование: путь к доступным и надежным LLM"
}
[25.02.2025 17:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains a significant barrier to widespread adoption. Quantization has emerged as a promising technique to democratize access and enable low resource device deployment. Despite these advancements, the safety and trustworthiness of quantized models remain underexplored, as prior studies often overlook contemporary architectures and rely on overly simplistic benchmarks and evaluations. To address this gap, we introduce OpenSafetyMini, a novel open-ended safety dataset designed to better distinguish between models. We evaluate 4 state-of-the-art quantization techniques across LLaMA and Mistral models using 4 benchmarks, including human evaluations. Our findings reveal that the optimal quantization method varies for 4-bit precision, while vector quantization techniques deliver the best safety and trustworthiness performance at 2-bit precision, providing foundation for future research."

[25.02.2025 17:12] Response: ```python
['DATASET', 'INFERENCE', 'BENCHMARK']
```
[25.02.2025 17:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains a significant barrier to widespread adoption. Quantization has emerged as a promising technique to democratize access and enable low resource device deployment. Despite these advancements, the safety and trustworthiness of quantized models remain underexplored, as prior studies often overlook contemporary architectures and rely on overly simplistic benchmarks and evaluations. To address this gap, we introduce OpenSafetyMini, a novel open-ended safety dataset designed to better distinguish between models. We evaluate 4 state-of-the-art quantization techniques across LLaMA and Mistral models using 4 benchmarks, including human evaluations. Our findings reveal that the optimal quantization method varies for 4-bit precision, while vector quantization techniques deliver the best safety and trustworthiness performance at 2-bit precision, providing foundation for future research."

[25.02.2025 17:12] Response: ```python
['OPEN_SOURCE', 'SECURITY']
```
[25.02.2025 17:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the challenges of using Large Language Models (LLMs) due to their high computational costs. It introduces quantization as a method to make these models more accessible for low-resource devices. The authors present OpenSafetyMini, a new safety dataset that helps evaluate the safety and trustworthiness of quantized models more effectively. Their experiments with various quantization techniques on LLaMA and Mistral models show that different methods perform best at different precision levels, highlighting the need for careful evaluation in model deployment.","title":"Democratizing LLMs: Ensuring Safety in Quantization"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the challenges of using Large Language Models (LLMs) due to their high computational costs. It introduces quantization as a method to make these models more accessible for low-resource devices. The authors present OpenSafetyMini, a new safety dataset that helps evaluate the safety and trustworthiness of quantized models more effectively. Their experiments with various quantization techniques on LLaMA and Mistral models show that different methods perform best at different precision levels, highlighting the need for careful evaluation in model deployment.', title='Democratizing LLMs: Ensuring Safety in Quantization'))
[25.02.2025 17:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"大型语言模型（LLMs）在解决现代挑战和实际应用中展现出强大的能力，但其计算成本仍然是广泛应用的主要障碍。量化技术被认为是一种有前景的方法，可以降低资源需求并促进低资源设备的部署。尽管如此，量化模型的安全性和可信度仍然未得到充分研究，之前的研究往往忽视了现代架构，并依赖过于简单的基准和评估。为了解决这一问题，我们引入了OpenSafetyMini，一个新颖的开放式安全数据集，以更好地区分模型，并评估了四种最先进的量化技术在LLaMA和Mistral模型上的表现。","title":"量化技术助力安全可信的语言模型"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, parsed=Article(desc='大型语言模型（LLMs）在解决现代挑战和实际应用中展现出强大的能力，但其计算成本仍然是广泛应用的主要障碍。量化技术被认为是一种有前景的方法，可以降低资源需求并促进低资源设备的部署。尽管如此，量化模型的安全性和可信度仍然未得到充分研究，之前的研究往往忽视了现代架构，并依赖过于简单的基准和评估。为了解决这一问题，我们引入了OpenSafetyMini，一个新颖的开放式安全数据集，以更好地区分模型，并评估了四种最先进的量化技术在LLaMA和Mistral模型上的表现。', title='量化技术助力安全可信的语言模型'))
[25.02.2025 17:12] Querying the API.
[25.02.2025 17:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Quality estimation is omnipresent in machine translation, for both evaluation and generation. Unfortunately, quality estimation models are often opaque and computationally expensive, making them impractical to be part of large-scale pipelines. In this work, we tackle two connected challenges: (1) reducing the cost of quality estimation at scale, and (2) developing an inexpensive uncertainty estimation method for quality estimation. To address the latter, we introduce Instant Confidence COMET, an uncertainty-aware quality estimation model that matches the performance of previous approaches at a fraction of their costs. We extend this to Early-Exit COMET, a quality estimation model that can compute quality scores and associated confidences already at early model layers, allowing us to early-exit computations and reduce evaluation costs. We also apply our model to machine translation reranking. We combine Early-Exit COMET with an upper confidence bound bandit algorithm to find the best candidate from a large pool without having to run the full evaluation model on all candidates. In both cases (evaluation and reranking) our methods reduce the required compute by 50% with very little degradation in performance.
[25.02.2025 17:12] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[25.02.2025 17:12] Using data from previous issue: {"categories": ["#benchmark", "#dataset"], "emoji": "🦖", "ru": {"title": "Большие данные для больших прорывов в классификации временных рядов", "desc": "MONSTER - это новый набор крупных датасетов для классификации временных рядов. Он создан в противовес существующим бенчмаркам UCR и UEA, которые со
[25.02.2025 17:12] Querying the API.
[25.02.2025 17:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Large language models (LLMs) have shown remarkable improvements in reasoning and many existing benchmarks have been addressed by models such as o1 and o3 either fully or partially. However, a majority of these benchmarks emphasize deductive reasoning, including mathematical and coding tasks in which rules such as mathematical axioms or programming syntax are clearly defined, based on which LLMs can plan and apply these rules to arrive at a solution. In contrast, inductive reasoning, where one infers the underlying rules from observed data, remains less explored. Such inductive processes lie at the heart of scientific discovery, as they enable researchers to extract general principles from empirical observations. To assess whether LLMs possess this capacity, we introduce InductionBench, a new benchmark designed to evaluate the inductive reasoning ability of LLMs. Our experimental findings reveal that even the most advanced models available struggle to master the simplest complexity classes within the subregular hierarchy of functions, highlighting a notable deficiency in current LLMs' inductive reasoning capabilities. Coda and data are available https://github.com/Wenyueh/inductive_reasoning_benchmark.
[25.02.2025 17:12] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[25.02.2025 17:12] Querying the API.
[25.02.2025 17:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The COVID-19 pandemic strained healthcare resources and prompted discussion about how machine learning can alleviate physician burdens and contribute to diagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but few studies predict the severity of a patient's condition from CXRs. In this study, we produce a large COVID severity dataset by merging three sources and investigate the efficacy of transfer learning using ImageNet- and CXR-pretrained models and vision transformers (ViTs) in both severity regression and classification tasks. A pretrained DenseNet161 model performed the best on the three class severity prediction problem, reaching 80% accuracy overall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases, respectively. The ViT had the best regression results, with a mean absolute error of 0.5676 compared to radiologist-predicted severity scores. The project's source code is publicly available.
[25.02.2025 17:13] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[25.02.2025 17:13] Using data from previous issue: {"categories": ["#training", "#multimodal", "#optimization", "#benchmark", "#interpretability", "#agi"], "emoji": "🖼️", "ru": {"title": "Комплексная оценка качества ИИ-изображений с помощью мультимодального анализа", "desc": "В статье представлена новая система оценки качества изображений, созданных
[25.02.2025 17:13] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#cv"], "emoji": "🗺️", "ru": {"title": "MegaLoc: универсальный инструмент для визуальной навигации и локализации", "desc": "MegaLoc - это модель для извлечения изображений, которая эффективна в различных задачах компьютерного зрения. Она объединяет существую
[25.02.2025 17:13] Using data from previous issue: {"categories": ["#math"], "emoji": "🌐", "ru": {"title": "Обратное отображение броуновской сферы в случайное дерево", "desc": "Статья описывает обратное отображение непрерывной версии биекции Кори-Вокелена-Шеффера (CVS) для броуновской сферы. Броуновская сфера - это случайное метрическое пространство
[25.02.2025 17:13] Loading Chinese text from previous data.
[25.02.2025 17:13] Renaming data file.
[25.02.2025 17:13] Renaming previous data. hf_papers.json to ./d/2025-02-25.json
[25.02.2025 17:13] Saving new data file.
[25.02.2025 17:13] Generating page.
[25.02.2025 17:13] Renaming previous page.
[25.02.2025 17:13] Renaming previous data. index.html to ./d/2025-02-25.html
[25.02.2025 17:13] [Experimental] Generating Chinese page for reading.
[25.02.2025 17:13] Chinese vocab [{'word': '创建', 'pinyin': 'chuàng jiàn', 'trans': 'create'}, {'word': '计算资源', 'pinyin': 'jì suàn zī yuán', 'trans': 'computational resources'}, {'word': '训练数据', 'pinyin': 'xùn liàn shù jù', 'trans': 'training data'}, {'word': '有限', 'pinyin': 'yǒu xiàn', 'trans': 'limited'}, {'word': '多任务', 'pinyin': 'duō rèn wù', 'trans': 'multi-task'}, {'word': '通用', 'pinyin': 'tōng yòng', 'trans': 'general-purpose'}, {'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'perception'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-trained'}, {'word': '文本到图像', 'pinyin': 'wén běn dào tú xiàng', 'trans': 'text-to-image'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '表明', 'pinyin': 'biǎo míng', 'trans': 'indicate'}, {'word': '优异', 'pinyin': 'yōu yì', 'trans': 'excellent'}, {'word': '仅', 'pinyin': 'jǐn', 'trans': 'only'}, {'word': '统一', 'pinyin': 'tǒng yī', 'trans': 'unify'}, {'word': '编码', 'pinyin': 'biān mǎ', 'trans': 'encoding'}, {'word': '充分利用', 'pinyin': 'chōng fèn lì yòng', 'trans': 'fully utilize'}, {'word': '适应', 'pinyin': 'shì yìng', 'trans': 'adapt'}, {'word': '微调', 'pinyin': 'wēi tiáo', 'trans': 'fine-tune'}]
[25.02.2025 17:13] Renaming previous Chinese page.
[25.02.2025 17:13] Renaming previous data. zh.html to ./d/2025-02-24_zh_reading_task.html
[25.02.2025 17:13] Writing Chinese reading task.
[25.02.2025 17:13] Writing result.
[25.02.2025 17:13] Renaming log file.
[25.02.2025 17:13] Renaming previous data. log.txt to ./logs/2025-02-25_last_log.txt
