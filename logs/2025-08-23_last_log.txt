[23.08.2025 01:51] Read previous papers.
[23.08.2025 01:51] Generating top page (month).
[23.08.2025 01:51] Writing top page (month).
[23.08.2025 06:33] Read previous papers.
[23.08.2025 06:33] Get feed.
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15763
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15144
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15760
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15260
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15761
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15769
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15361
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15772
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15767
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15126
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15752
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.14892
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15641
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15418
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.15202
[23.08.2025 06:33] Get page data from previous paper. URL: https://huggingface.co/papers/2508.09998
[23.08.2025 06:33] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[23.08.2025 06:33] No deleted papers detected.
[23.08.2025 06:33] Downloading and parsing papers (pdf, html). Total: 16.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15763.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15763.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15763.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15144.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15144.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15144.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15760.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15760.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15760.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15260.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15260.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15260.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15761.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15761.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15761.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15769.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15769.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15769.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15361.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15361.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15361.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15772.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15772.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15772.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15767.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15767.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15767.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15126.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15126.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15126.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15752.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15752.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15752.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.14892.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.14892.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.14892.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15641.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15641.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15641.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15418.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15418.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15418.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.15202.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.15202.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.15202.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Downloading and parsing paper https://huggingface.co/papers/2508.09998.
[23.08.2025 06:33] Extra JSON file exists (./assets/json/2508.09998.json), skip PDF parsing.
[23.08.2025 06:33] Paper image links file exists (./assets/img_data/2508.09998.json), skip HTML parsing.
[23.08.2025 06:33] Success.
[23.08.2025 06:33] Enriching papers with extra data.
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 0. Intern-S1, a multimodal Mixture-of-Experts model with extensive pre-training and reinforcement learning, achieves top-tier performance in general reasoning and outperforms closed-source models in scientific tasks.  					AI-generated summary 				 In recent years, a plethora of open-source foundation ...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 1. GUI-Owl and Mobile-Agent-v3 are open-source GUI agent models and frameworks that achieve state-of-the-art performance across various benchmarks using innovations in environment infrastructure, agent capabilities, and scalable reinforcement learning.  					AI-generated summary 				 This paper introdu...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 2. LiveMCP-101 benchmarks AI agents' ability to use multiple tools in real-world scenarios, revealing challenges in tool orchestration and inefficiencies in token usage.  					AI-generated summary 				 Tool calling has emerged as a critical capability for AI agents to interact with the real world and s...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 3. DeepConf enhances reasoning efficiency and performance by filtering low-quality reasoning traces using model-internal confidence signals, achieving high accuracy and reducing token generation.  					AI-generated summary 				 Large Language Models (LLMs) have shown great potential in reasoning tasks ...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 4. Waver, a high-performance foundation model, generates high-quality videos and images using a Hybrid Stream DiT architecture, excelling in text-to-video, image-to-video, and text-to-image tasks.  					AI-generated summary 				 We present Waver, a high-performance foundation model for unified image an...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 5. SceneGen generates multiple 3D assets from a single scene image using a novel framework that integrates local and global scene information, enabling efficient and robust 3D content creation.  					AI-generated summary 				 3D content generation has recently attracted significant research interest du...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 6. A systematic review of large language model benchmarks identifies issues such as data contamination, cultural biases, and lack of process credibility, and proposes a design paradigm for future improvements.  					AI-generated summary 				 In recent years, with the rapid development of the depth and ...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 7. VAREdit, a visual autoregressive framework, improves image editing adherence and efficiency by using a Scale-Aligned Reference module to condition source image tokens.  					AI-generated summary 				 Recent advances in diffusion models have brought remarkable visual fidelity to instruction-guided im...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 8. ATLAS is a high-fidelity body model that decouples shape and skeleton bases, improving pose accuracy and shape expressivity using 600k high-resolution scans.  					AI-generated summary 				 Parametric body models offer expressive 3D representation of humans across a wide range of poses, shapes, and ...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 9. aiXiv is an open-access platform that facilitates the submission, review, and refinement of scientific proposals and papers by both human and AI scientists, enhancing the quality and dissemination of AI-generated research.  					AI-generated summary 				 Recent advances in large language models (LLM...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 10. Geo-Visual Agents integrate geospatial images and GIS data to answer nuanced visual-spatial inquiries about the world.  					AI-generated summary 				 Interactive digital maps have revolutionized how people travel and learn about the world; however, they rely on pre-existing structured data in GIS d...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 11. A method reconstructs 3D human bodies from two sparse views using a redesigned geometry model and enhancement algorithm, achieving state-of-the-art performance.  					AI-generated summary 				 Reconstructing 3D human bodies from sparse views has been an appealing topic, which is crucial to broader t...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 12. Grounded VideoDiT addresses temporal perception and entity interaction in videos through a Diffusion Temporal Latent encoder, object grounded representations, and mixed token scheme, achieving state-of-the-art results on VideoQA benchmarks.  					AI-generated summary 				 Understanding videos requir...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 13. LLaSO is an open framework for large-scale speech-language modeling that provides alignment data, instruction-tuning datasets, and evaluation benchmarks to enhance reproducibility and performance.  					AI-generated summary 				 The development of Large Speech-Language Models (LSLMs) has been slowed...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 14. Fin-PRM, a domain-specialized reward model for finance, enhances intermediate reasoning in LLMs through step-level and trajectory-level supervision, improving performance in supervised learning, reinforcement learning, and test-time inference.  					AI-generated summary 				 Process Reward Models (P...
[23.08.2025 06:33] ********************************************************************************
[23.08.2025 06:33] Abstract 15. A benchmark evaluates companionship behaviors in language models, revealing differences in how models handle emotional support and boundary-setting.  					AI-generated summary 				 AI companionship, where users develop emotional bonds with AI systems, has emerged as a significant pattern with positi...
[23.08.2025 06:33] Read previous papers.
[23.08.2025 06:33] Generating reviews via LLM API.
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#agi", "#science", "#reasoning", "#dataset", "#open_source", "#rl", "#training", "#multimodal", "#benchmark"], "emoji": "üß†", "ru": {"title": "Intern-S1: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å-—ç–∫—Å–ø–µ—Ä—Ç –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö –∑–∞–¥–∞—á", "desc": "Intern-S1 - —ç—Ç–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Ç–∏–ø–∞ Mixture-of-Experts —Å 28 –º–∏
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#games", "#open_source", "#agents", "#rl", "#training"], "emoji": "ü§ñ", "ru": {"title": "–û—Ç–∫—Ä—ã—Ç—ã–µ –º–æ–¥–µ–ª–∏ GUI-–∞–≥–µ–Ω—Ç–æ–≤ –¥–æ—Å—Ç–∏–≥–∞—é—Ç –ø—Ä–æ—Ä—ã–≤–∞ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç GUI-Owl –∏ Mobile-Agent-v3 - –æ—Ç–∫—Ä—ã—Ç—ã–µ –º–æ–¥–µ–ª–∏ –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º 
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#agents", "#optimization", "#benchmark", "#reasoning", "#agi"], "emoji": "ü§ñ", "ru": {"title": "LiveMCP-101: –ò—Å–ø—ã—Ç–∞–Ω–∏–µ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö", "desc": "LiveMCP-101 - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#reasoning", "#training", "#inference", "#optimization", "#benchmark"], "emoji": "üß†", "ru": {"title": "–£–º–Ω–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ: DeepConf –ø–æ–≤—ã—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò", "desc": "DeepConf - —ç—Ç–æ –º–µ—Ç–æ–¥, —É–ª—É—á—à–∞—é—â–∏–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#games", "#training", "#multimodal", "#data", "#open_source", "#video"], "emoji": "üé¨", "ru": {"title": "Waver: –ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è", "desc": "Waver - —ç—Ç–æ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—ã—Å–æ
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#3d"], "emoji": "üñºÔ∏è", "ru": {"title": "–û—Ç 2D –∫ 3D: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö —Å—Ü–µ–Ω", "desc": "SceneGen - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ü–µ–Ω—ã. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –ª–æ–∫–∞–ª—å–Ω—É—é –∏ –≥–ª–æ–±–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#ethics", "#benchmark", "#survey"], "emoji": "üéØ", "ru": {"title": "–ù–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –æ—Ü–µ–Ω–∫—É —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –æ—Ç –ø—Ä–æ–±–ª–µ–º –∫ –∏–Ω–Ω–æ–≤–∞—Ü–∏—è–º", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ê–≤—Ç–æ—Ä—ã –≤—ã—è–≤–ª—è—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–µ–Ω—á–º–∞
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#benchmark", "#architecture", "#optimization", "#cv", "#diffusion"], "emoji": "üñºÔ∏è", "ru": {"title": "VAREdit: –¢–æ—á–Ω–æ–µ –∏ –±—ã—Å—Ç—Ä–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–∏", "desc": "VAREdit - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#3d"], "emoji": "ü¶æ", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ç–µ–ª–∞: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã –∏ —Å–∫–µ–ª–µ—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏", "desc": "ATLAS - —ç—Ç–æ –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å —Ç–µ–ª–∞ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–∑–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤—ã —Ñ–æ—Ä–º—ã –∏ —Å–∫–µ–ª–µ—Ç–∞, —É–ª—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–∑—ã –∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#science", "#architecture", "#open_source"], "emoji": "üß†", "ru": {"title": "aiXiv: –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —á–µ–ª–æ–≤–µ–∫–∞ –∏ –ò–ò", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ aiXiv, –∫–æ—Ç–æ—Ä–∞—è –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–¥–∞—á—É, —Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–æ—Ä–∞–±–æ—Ç–∫—É –Ω–∞—É—á–Ω—ã—Ö
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#cv"], "emoji": "üåç", "ru": {"title": "–ì–µ–æ-–í–∏–∑—É–∞–ª—å–Ω—ã–µ –ê–≥–µ–Ω—Ç—ã: –ù–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –∞–Ω–∞–ª–∏–∑ –≥–µ–æ–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –ì–µ–æ-–í–∏–∑—É–∞–ª—å–Ω—ã—Ö –ê–≥–µ–Ω—Ç–æ–≤ - –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ –≤–∏–∑—É–∞–ª
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#3d"], "emoji": "üë§", "ru": {"title": "–†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è 3D-–º–æ–¥–µ–ª–∏ —á–µ–ª–æ–≤–µ–∫–∞ –ø–æ –¥–≤—É–º —Ñ–æ—Ç–æ –∑–∞ –¥–æ–ª–∏ —Å–µ–∫—É–Ω–¥—ã", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ç–µ–ª–∞ –ø–æ –¥–≤—É–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º - —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–º—É –∏ –∑–∞–¥–Ω–µ–º—É –≤–∏–¥—É. –ê–≤—Ç–æ—Ä—ã redesigned geometry reconstruction 
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#diffusion", "#benchmark", "#video"], "emoji": "üé¨", "ru": {"title": "–¢–æ—á–Ω–æ–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "Grounded VideoDiT - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç–Ω–∫–æ–¥–µ—Ä Dif
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#data", "#audio", "#open_source"], "emoji": "üó£Ô∏è", "ru": {"title": "–û—Ç–∫—Ä—ã—Ç–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–µ—á–µ–≤—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "LLaSO - —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏ —è–∑—ã–∫–∞. –û–Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã—Ä
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#science", "#reasoning", "#rlhf", "#healthcare", "#training", "#optimization"], "emoji": "üíπ", "ru": {"title": "Fin-PRM: –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ LLM —Å –ø–æ–º–æ—â—å—é —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è", "desc": "Fin-PRM - —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è —Ñ–∏–Ω
[23.08.2025 06:33] Using data from previous issue: {"categories": ["#alignment", "#ethics", "#multimodal", "#benchmark"], "emoji": "ü§ñ", "ru": {"title": "–û—Ü–µ–Ω–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–∞–∫ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–∞–Ω—å–æ–Ω–æ–≤: –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏ –≥—Ä–∞–Ω–∏—Ü–∞–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ INTIMA –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ä–æ–ª–∏ –∫–æ–º–ø–∞–Ω—å–æ–Ω–æ–≤. –ù
[23.08.2025 06:33] Renaming data file.
[23.08.2025 06:33] Renaming previous data. hf_papers.json to ./d/2025-08-22.json
[23.08.2025 06:33] Saving new data file.
[23.08.2025 06:33] Generating page.
[23.08.2025 06:33] Renaming previous page.
[23.08.2025 06:33] Renaming previous data. index.html to ./d/2025-08-22.html
[23.08.2025 06:33] Writing result.
[23.08.2025 06:33] Renaming log file.
[23.08.2025 06:33] Renaming previous data. log.txt to ./logs/2025-08-23_last_log.txt
