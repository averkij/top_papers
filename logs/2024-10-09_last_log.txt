[10.10.2024 00:57] Get feed.
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04717
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04199
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.01912
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05193
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03864
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03290
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02743
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.02705
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04422
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.05076
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.03399
[10.10.2024 00:57] Extract page data from URL. URL: https://huggingface.co/papers/2410.04343
[10.10.2024 00:57] Get page data from previous paper. URL: https://huggingface.co/papers/2410.04081
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 0. Understanding and accurately following instructions is critical for large language models (LLMs) to be effective across diverse tasks. In this work, we rigorously examine the key factors that enable models to generalize to unseen instructions, providing insights to guide the collection of data for i...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 1. Current long-context benchmarks primarily focus on retrieval-based tests, requiring Large Language Models (LLMs) to locate specific information within extensive input contexts, such as the needle-in-a-haystack (NIAH) benchmark. Long-context generation refers to the ability of a language model to gen...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 2. This work tackles the information loss bottleneck of vector-quantization (VQ) autoregressive image generation by introducing a novel model architecture called the 2-Dimensional Autoregression (DnD) Transformer. The DnD-Transformer predicts more codes for an image by introducing a new autoregression ...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 3. With significant efforts in recent studies, LLM-as-a-Judge has become a cost-effective alternative to human evaluation for assessing the text generation quality in a wide range of tasks. However, there still remains a reliability gap between LLM-as-a-Judge and human evaluation. One important reason ...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 4. Enhancing the capability of large language models (LLMs) in reasoning has gained significant attention in recent years. Previous studies have demonstrated the effectiveness of various prompting strategies in aiding LLMs in reasoning (called "reasoning actions"), such as step-by-step thinking, reflec...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 5. Video Large Language Models (Video-LLMs) have demonstrated remarkable capabilities in coarse-grained video understanding, however, they struggle with fine-grained temporal grounding. In this paper, we introduce Grounded-VideoLLM, a novel Video-LLM adept at perceiving and reasoning over specific vide...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 6. Reinforcement learning from human feedback (RLHF) has demonstrated effectiveness in aligning large language models (LLMs) with human preferences. However, token-level RLHF suffers from the credit assignment problem over long sequences, where delayed rewards make it challenging for the model to disce...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 7. Autoregressive (AR) models have reformulated image generation as next-token prediction, demonstrating remarkable potential and emerging as strong competitors to diffusion models. However, control-to-image generation, akin to ControlNet, remains largely unexplored within AR models. Although a natural...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 8. Long-context language models (LCLM), characterized by their extensive context window, is becoming increasingly popular. Meanwhile, many long-context benchmarks present challenging tasks that even the most advanced LCLMs struggle to complete. However, the underlying sources of various challenging lon...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 9. Large language models (LLMs) have driven significant advancements across diverse NLP tasks, with long-context models gaining prominence for handling extended inputs. However, the expanding key-value (KV) cache size required by Transformer architectures intensifies the memory constraints, particularl...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 10. Event sequences, characterized by irregular sampling intervals and a mix of categorical and numerical features, are common data structures in various real-world domains such as healthcare, finance, and user interaction logs. Despite advances in temporal data modeling techniques, there is no standard...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 11. The scaling of inference computation has unlocked the potential of long-context large language models (LLMs) across diverse settings. For knowledge-intensive tasks, the increased compute is often allocated to incorporate more external knowledge. However, without effectively utilizing such knowledge,...
[10.10.2024 00:57] ********************************************************************************
[10.10.2024 00:57] Abstract 12. In generative modeling, tokenization simplifies complex data into compact, structured representations, creating a more efficient, learnable space. For high-dimensional visual data, it reduces redundancy and emphasizes key features for high-quality generation. Current visual tokenization methods rely...
[10.10.2024 00:57] Read previous papers.
[10.10.2024 00:57] Generating reviews via LLM API.
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —Ñ–∞–∫—Ç–æ—Ä—ã, –ø–æ–∑–≤–æ–ª—è—é—â–∏–µ —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –æ–±–æ–±—â–∞—Ç—å –Ω–∞–≤—ã–∫–∏ –Ω–∞ –Ω–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏–µ, —á—Ç–æ —Ç–∞–∫–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–∏ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –¥–æ–º–µ–Ω–∞–º. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏
[10.10.2024 00:57] Using data from previous issue: {"desc": "LongGenBench - —ç—Ç–æ –Ω–æ–≤—ã–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ—Å—Ç–æ–≤, —Ñ–æ–∫—É—Å–∏—Ä—É—é—â–∏—Ö—Å—è –Ω–∞ –ø–æ–∏—Å–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, LongGenBench —Ç—Ä–µ–±—É–µ—Ç –æ—Ç –º–æ–¥–µ–ª–µ–π —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–æ—Å—Ç–Ω—ã—Ö –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ –≤—Å–µ 
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º 2-Dimensional Autoregression (DnD) Transformer –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. DnD-Transformer —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –ø–æ—Ç–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–∏, –≤–≤–æ–¥—è –Ω–æ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–∏ - –≥–ª—É–±–∏–Ω—É –º–æ–¥–µ–ª–∏. –ü–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω
[10.10.2024 00:57] Using data from previous issue: {"desc": "RevisEval - —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ –æ—Ü–µ–Ω–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥ –æ—Ç–≤–µ—Ç —ç—Ç–∞–ª–æ–Ω—ã. –ú–µ—Ç–æ–¥ –∑–∞–¥–µ–π—Å—Ç–≤—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —ç—Ç–∞–ª–æ–Ω–∞. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ RevisEval –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç DOTS - –ø–æ–¥—Ö–æ–¥, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Ä–∞—Å—Å—É–∂–¥–∞—Ç—å –ø—É—Ç–µ–º –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –ú–µ—Ç–æ–¥ –≤–∫–ª—é—á–∞–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞—Ç–æ–º–∞—Ä–Ω—ã—Ö –º–æ–¥—É–ª–µ–π –¥–µ–π—Å—Ç–≤–∏–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø–ª
[10.10.2024 00:57] Using data from previous issue: {"desc": "Grounded-VideoLLM - —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å Video-LLM, —Å–ø–æ—Å–æ–±–Ω–∞—è –∫ –¥–µ—Ç–∞–ª—å–Ω–æ–º—É –ø–æ–Ω–∏–º–∞–Ω–∏—é –≤–∏–¥–µ–æ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ—Ç–æ–∫ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ –∏ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫. –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –ø–æ—ç—Ç–∞–ø–Ω
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ—Ç —á–µ–ª–æ–≤–µ–∫–∞ (RLHF) –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ MA-RLHF –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞–∫—Ä–æ–¥–µ–π—Å—Ç–≤–∏—è - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏–ª–∏ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ - –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è.
[10.10.2024 00:57] Using data from previous issue: {"desc": "ControlAR - —ç—Ç–æ –Ω–æ–≤—ã–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –≤ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã. ControlAR –ø—Ä–∏–º–µ–Ω—è–µ—Ç —É—Å–ª–æ–≤–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ
[10.10.2024 00:57] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (LCLM) –∏ –∏—Ö —Ç—Ä—É–¥–Ω–æ—Å—Ç—è–º –≤ —Ä–µ—à–µ–Ω–∏–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á. –ê–≤—Ç–æ—Ä—ã –≤—ã—è–≤–∏–ª–∏ –¥–≤–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö. –≠—Ç–∏ –∑–∞–¥–∞—á–∏ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –≥–∏–ø–µ—Ä–º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–º–∏, —á—Ç–æ –ø—Ä–µ–≤—ã—à–∞
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç TidalDecode - –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏ —Ç–æ—á–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ–∑–∏—Ü–∏–∏. TidalDecode –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –∏ –≤–≤–æ
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç EBES - –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π, —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ —Å–æ–±—ã—Ç–∏–π. EBES —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∑–∞–¥–∞—á–∞—Ö —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–∫–ª—é—á–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ
[10.10.2024 00:57] Querying the API.
[10.10.2024 00:57] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–≤–æ–¥–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (RAG) –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ê–≤—Ç–æ—Ä—ã —Ñ–æ–∫—É—Å–∏—Ä—É—é—Ç—Å—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–∞–∫ —Å–ø–æ—Å–æ–±–∞—Ö —É–ª—É—á—à–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–ª—è–µ—Ç –ø–æ—á—Ç–∏ –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –ø–æ–≤—ã—à–µ–Ω–∏–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—ã–≤–æ–¥–∞.",
  "tags": ["#RAG", "#InferenceScaling", "#ContextUtilization"],
  "emoji": "üìà",
  "title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –¥–ª—è RAG: –∑–∞–∫–æ–Ω –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–≤–æ–¥–∞"
}
[10.10.2024 00:57] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–º –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏. –í–º–µ—Å—Ç–æ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –∞–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø—Ä–æ—Ü–µ—Å—Å –¥–∏—Ñ—Ñ—É–∑–∏–∏ –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —É–ª—É—á—à–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Å–æ—á–µ—Ç–∞–µ—Ç —Å–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö —ç–Ω–∫–æ–¥–µ—Ä–æ–º –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞
[10.10.2024 00:57] Renaming data file.
[10.10.2024 00:57] Renaming previous data. hf_papers.json to 2024-10-09_hf_papers.json
[10.10.2024 00:57] Saving new data file.
[10.10.2024 00:57] Generating page.
[10.10.2024 00:57] Renaming previous page.
[10.10.2024 00:57] Renaming previous data. index.html to 2024-10-09_hf_papers.html
[10.10.2024 00:57] Writing result.
[10.10.2024 00:57] Renaming log file.
[10.10.2024 00:57] Renaming previous data. log.txt to 2024-10-09_last_log.txt
