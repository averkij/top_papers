[29.10.2025 05:13] Read previous papers.
[29.10.2025 05:13] Generating top page (month).
[29.10.2025 05:13] Writing top page (month).
[29.10.2025 06:19] Read previous papers.
[29.10.2025 06:19] Get feed.
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24668
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24701
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23763
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23691
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24699
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24717
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24711
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24657
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24514
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24320
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23642
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24694
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24693
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24698
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24697
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24695
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24563
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22037
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24645
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24591
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22099
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24448
[29.10.2025 06:19] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21323
[29.10.2025 06:19] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[29.10.2025 06:19] No deleted papers detected.
[29.10.2025 06:19] Downloading and parsing papers (pdf, html). Total: 23.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24668.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24668.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24668.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24701.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24701.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24701.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.23763.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.23763.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.23763.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.23691.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.23691.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.23691.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24699.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24699.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24699.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24717.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24717.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24717.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24711.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24711.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24711.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24657.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24657.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24657.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24514.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24514.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24514.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24320.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24320.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24320.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.23642.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.23642.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.23642.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24694.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24694.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24694.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24693.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24693.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24693.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24698.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24698.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24698.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24697.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24697.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24697.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24695.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24695.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24695.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24563.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24563.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24563.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.22037.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.22037.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.22037.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24645.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24645.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24645.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24591.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24591.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24591.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.22099.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.22099.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.22099.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.24448.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.24448.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.24448.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Downloading and parsing paper https://huggingface.co/papers/2510.21323.
[29.10.2025 06:19] Extra JSON file exists (./assets/json/2510.21323.json), skip PDF parsing.
[29.10.2025 06:19] Paper image links file exists (./assets/img_data/2510.21323.json), skip HTML parsing.
[29.10.2025 06:19] Success.
[29.10.2025 06:19] Enriching papers with extra data.
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 0. InteractComp evaluates search agents' ability to recognize and resolve query ambiguity through interaction, revealing significant gaps in current models' capabilities.  					AI-generated summary 				 Language agents have demonstrated remarkable potential in web search and information retrieval. Howe...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 1. Tongyi DeepResearch, a large language model with agentic capabilities, achieves top performance in various deep research tasks through an end-to-end training framework and automated data synthesis.  					AI-generated summary 				 We present Tongyi DeepResearch, an agentic large language model, which...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 2. RoboOmni, a Perceiver-Thinker-Talker-Executor framework using end-to-end omni-modal LLMs, improves robotic manipulation by inferring user intentions from spoken dialogue, environmental sounds, and visual cues.  					AI-generated summary 				 Recent advances in Multimodal Large Language Models (MLLMs...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 3. Game-TARS, a generalist game agent trained with a unified action space, achieves superior performance across various domains and benchmarks through large-scale pre-training and efficient reasoning strategies.  					AI-generated summary 				 We present Game-TARS, a generalist game agent trained with ...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 4. AgentFold, a novel proactive context management paradigm for LLM-based web agents, achieves superior performance on long-horizon tasks through dynamic context folding, surpassing larger models and proprietary agents.  					AI-generated summary 				 LLM-based web agents show immense promise for infor...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 5. URSA, a discrete generative model, bridges the gap with continuous approaches in video generation by using a Linearized Metric Path and Resolution-dependent Timestep Shifting, achieving high-resolution and long-duration synthesis with fewer inference steps.  					AI-generated summary 				 Continuous...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 6. ProMoE, an MoE framework with conditional and prototypical routing, enhances expert specialization in Diffusion Transformers, achieving state-of-the-art performance on ImageNet.  					AI-generated summary 				 Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity whi...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 7. Group Relative Attention Guidance enhances image editing quality by modulating token deltas in Diffusion-in-Transformer models, providing fine-grained control over editing intensity.  					AI-generated summary 				 Recently, image editing based on Diffusion-in-Transformer models has undergone rapid ...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 8. Latent Sketchpad enhances Multimodal Large Language Models with an internal visual scratchpad, enabling generative visual thought and improved reasoning performance.  					AI-generated summary 				 While Multimodal Large Language Models (MLLMs) excel at visual understanding, they often struggle in c...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 9. Critique-RL is an online reinforcement learning approach for developing critiquing language models without strong supervision, using a two-stage optimization strategy to improve both the critic's discriminability and helpfulness.  					AI-generated summary 				 Training critiquing language models to...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 10. VisCoder2, a family of multi-language visualization models, outperforms open-source baselines and approaches proprietary models by leveraging VisCode-Multi-679K and VisPlotBench for iterative self-debugging and multi-turn correction.  					AI-generated summary 				 Large language models (LLMs) have ...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 11. Entity-aware Group Relative Policy Optimization (E-GRPO) enhances search agents by incorporating entity information into the reward function, improving accuracy and efficiency in knowledge-intensive tasks.  					AI-generated summary 				 LLM-based search agents are increasingly trained on entity-cen...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 12. STAR-Bench measures audio 4D intelligence by evaluating sound dynamics in time and 3D space, revealing gaps in fine-grained perceptual reasoning among existing models.  					AI-generated summary 				 Despite rapid progress in Multi-modal Large Language Models and Large Audio-Language Models, existin...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 13. ParallelMuse enhances problem-solving by efficiently reusing paths and compressing reasoning in deep information-seeking agents, improving performance and reducing token consumption.  					AI-generated summary 				 Parallel thinking expands exploration breadth, complementing the deep exploration of ...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 14. WebLeaper framework improves information seeking efficiency and effectiveness by constructing high-coverage tasks and generating efficient solution trajectories using tree-structured reasoning and curated Wikipedia tables.  					AI-generated summary 				 Large Language Model (LLM)-based agents have ...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 15. A ZPD-guided data synthesis approach enhances large language model capabilities by training them on tasks just beyond their current abilities, leading to state-of-the-art performance on complex benchmarks.  					AI-generated summary 				 Training large language model agents on tasks at the frontier ...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 16. OSWorld-MCP is a benchmark that evaluates multimodal agents' tool invocation, GUI operation, and decision-making abilities, highlighting the importance of assessing tool usage in real-world scenarios.  					AI-generated summary 				 With advances in decision-making and reasoning capabilities, multim...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 17. The study introduces ATLAS, a multilingual scaling law that improves out-of-sample generalization and provides insights into cross-lingual transfer, optimal scaling, and computational crossover points for model training.  					AI-generated summary 				 Scaling laws research has focused overwhelmingl...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 18. FunReason-MT is a novel data synthesis framework that enhances multi-turn function calling in large language models by addressing challenges in environment interaction, query synthesis, and chain-of-thought generation, achieving state-of-the-art performance on the Berkeley Function-Calling Leaderboa...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 19. ReplicationBench evaluates AI agents' ability to replicate astrophysics research papers, providing insights into their faithfulness and correctness in scientific research tasks.  					AI-generated summary 				 Frontier AI agents show increasing promise as scientific research assistants, and may even...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 20. A framework using the Information Bottleneck principle and Dynamic Mode Steering algorithm improves the reliability of Large Language Models by balancing generalization and memorization.  					AI-generated summary 				 Large Language Models (LLMs) exhibit a troubling duality, capable of both remarka...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 21. Video Diffusion Models (VDMs) show higher data efficiency than large language models across various visual tasks, suggesting video pretraining can enhance visual foundation models.  					AI-generated summary 				 Large language models (LLMs) have demonstrated that large-scale pretraining enables sys...
[29.10.2025 06:19] ********************************************************************************
[29.10.2025 06:19] Abstract 22. VL-SAE, a sparse autoencoder, enhances vision-language alignment by correlating neurons to unified concepts, improving interpretability and performance in tasks like zero-shot image classification and hallucination elimination.  					AI-generated summary 				 The alignment of vision-language represe...
[29.10.2025 06:19] Read previous papers.
[29.10.2025 06:19] Generating reviews via LLM API.
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#benchmark", "#agents", "#reasoning"], "emoji": "❓", "ru": {"title": "Поисковые агенты не умеют задавать уточняющие вопросы", "desc": "Исследователи представили бенчмарк InteractComp для оценки способности поисковых AI-агентов распознавать неоднозн
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#long_context", "#synthetic", "#dataset", "#benchmark", "#training", "#open_source", "#agi", "#agents"], "emoji": "🔍", "ru": {"title": "Автономный AI-агент для глубоких исследований", "desc": "Tongyi DeepResearch - это большая языковая модель с агентными способностями, специализирую
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#agents", "#dataset", "#optimization", "#games", "#multimodal", "#interpretability"], "emoji": "🤖", "ru": {"title": "Робот, который понимает намерения без прямых команд", "desc": "Статья представляет RoboOmni — систему для роботизированной манипуляции, которая понимает намерения пол
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#agents", "#training", "#games", "#benchmark", "#multimodal", "#reasoning"], "emoji": "🎮", "ru": {"title": "Универсальный игровой агент через единое пространство действий", "desc": "Game-TARS — это универсальный игровой агент, обученный на едином пространстве действий, основанном на
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#training", "#agents"], "emoji": "🗂️", "ru": {"title": "Динамическое сворачивание контекста для эффективных веб-агентов", "desc": "AgentFold — это новая парадигма управления контекстом для веб-агентов на основе LLM, вдохновленная процессом ретроспектив
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#diffusion", "#benchmark", "#architecture", "#video"], "emoji": "🎥", "ru": {"title": "URSA: Новая эра дискретной генерации видео", "desc": "В статье представлена модель URSA, которая улучшает генерацию видео с использованием дискретных подходов, приближая их к непрерывным методам. U
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#optimization", "#cv", "#benchmark", "#diffusion"], "emoji": "🎨", "ru": {"title": "Специализация экспертов в диффузионных моделях через двухэтапную маршрутизацию", "desc": "Статья представляет ProMoE — новый подход к использованию Mixture-of-Experts 
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#cv", "#diffusion"], "emoji": "🎚️", "ru": {"title": "Точная настройка силы редактирования через модуляцию токенов", "desc": "Исследователи предложили метод Group Relative Attention Guidance (GRAG) для улучшения контроля 
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#cv", "#multimodal", "#interpretability"], "emoji": "✏️", "ru": {"title": "Визуальное мышление для AI: когда нейросеть учится рисовать свои мысли", "desc": "Статья представляет Latent Sketchpad — фреймворк, который добавляет мультимодальным LLM внутренний в
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#training", "#rlhf"], "emoji": "🧠", "ru": {"title": "Critique-RL: Улучшение языковых моделей без сильного надзора", "desc": "Critique-RL — это метод обучения с подкреплением для создания языковых моделей, которые могут критиковать без сильного н
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#open_source", "#science", "#dataset", "#multilingual", "#benchmark", "#agents"], "emoji": "📊", "ru": {"title": "Мультиязычный AI-агент для визуализации данных с самоотладкой", "desc": "Представлена семья моделей VisCoder2 для генерации кода визуализаций на 12 языках программировани
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#agents", "#reasoning"], "emoji": "🎯", "ru": {"title": "Учимся на «почти правильных» ответах: награды за найденные сущности", "desc": "Статья представляет Entity-aware Group Relative Policy Optimization (E-GRPO) — улучшенный метод обучения LLM-аг
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#interpretability", "#data", "#audio", "#reasoning", "#benchmark", "#open_source"], "emoji": "🎧", "ru": {"title": "4D аудио-интеллект: новый уровень понимания звука в пространстве и времени", "desc": "Статья представляет STAR-Bench — новый бенчмарк для оценки «4D аудио-интеллекта» у
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#training", "#optimization", "#benchmark", "#agents", "#reasoning"], "emoji": "🔀", "ru": {"title": "Параллельное мышление для AI-агентов: быстрее думаем, меньше тратим", "desc": "Исследователи представили ParallelMuse — систему, которая улучшает работу AI-агентов при решении сложных
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#dataset", "#survey", "#training", "#optimization", "#benchmark", "#agents", "#reasoning"], "emoji": "🌳", "ru": {"title": "WebLeaper: Эффективный поиск информации через древовидное рассуждение", "desc": "Статья представляет WebLeaper — фреймворк для улучшения эффективности информаци
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#dataset", "#training", "#benchmark", "#synthetic", "#data", "#agents", "#reasoning"], "emoji": "🎯", "ru": {"title": "Обучение AI в зоне ближайшего развития", "desc": "Исследователи предложили подход к синтезу данных для обучения LLM, основанный на педагогической концепции зоны ближ
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark", "#optimization", "#open_source", "#agents"], "emoji": "🛠️", "ru": {"title": "Новый стандарт оценки AI-агентов: не только GUI, но и умение пользоваться инструментами", "desc": "OSWorld-MCP — это первый комплексный бенчмарк для оценки мультимо
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#low_resource", "#multilingual", "#transfer_learning", "#dataset", "#training"], "emoji": "🌍", "ru": {"title": "Законы масштабирования для многоязычного AI", "desc": "ATLAS — это новый закон масштабирования для многоязычных языковых моделей, основанный на 774 экспериментах с моделям
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#dataset", "#training", "#optimization", "#data", "#agents", "#transfer_learning"], "emoji": "🔧", "ru": {"title": "Учим LLM правильно пользоваться инструментами в несколько шагов", "desc": "FunReason-MT — это новый фреймворк для синтеза данных, который улучшает способность больших я
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#benchmark", "#science", "#agents"], "emoji": "🔭", "ru": {"title": "Проверка AI-агентов на репликацию научных исследований", "desc": "Исследователи представили ReplicationBench — бенчмарк для оценки способности AI-агентов воспроизводить научные работы по астрофизике. Каждая задача в
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#inference", "#training"], "emoji": "🧭", "ru": {"title": "Управление режимами мышления: как научить LLM обобщать, а не заучивать", "desc": "Исследователи предлагают новый подход к проблеме, когда большие языковые модели то блестяще обобщают знания,
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#multimodal", "#transfer_learning", "#games", "#diffusion", "#benchmark", "#video"], "emoji": "🎬", "ru": {"title": "Видео-диффузия побеждает языковые модели в визуальных задачах", "desc": "Исследователи сравнили Video Diffusion Models (VDMs) и большие языковые модели (LLM) в визуаль
[29.10.2025 06:19] Using data from previous issue: {"categories": ["#alignment", "#multimodal", "#interpretability", "#cv", "#hallucinations", "#training"], "emoji": "🔍", "ru": {"title": "Разреженный автоэнкодер для понимания и усиления связи между зрением и языком", "desc": "VL-SAE — это разреженный автоэнкодер, который повышает интерпретируемость 
[29.10.2025 06:19] Renaming data file.
[29.10.2025 06:19] Renaming previous data. hf_papers.json to ./d/2025-10-29.json
[29.10.2025 06:19] Saving new data file.
[29.10.2025 06:19] Generating page.
[29.10.2025 06:19] Renaming previous page.
[29.10.2025 06:19] Renaming previous data. index.html to ./d/2025-10-29.html
[29.10.2025 06:19] Writing result.
[29.10.2025 06:19] Renaming log file.
[29.10.2025 06:19] Renaming previous data. log.txt to ./logs/2025-10-29_last_log.txt
