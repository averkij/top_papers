[29.10.2025 20:13] Read previous papers.
[29.10.2025 20:13] Generating top page (month).
[29.10.2025 20:13] Writing top page (month).
[29.10.2025 21:10] Read previous papers.
[29.10.2025 21:10] Get feed.
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24668
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24701
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24699
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23763
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23691
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24717
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24694
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24563
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24657
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24697
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24698
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24695
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24514
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23642
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24711
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24693
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24320
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21978
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22037
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17439
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20661
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24702
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24081
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23925
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22768
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24684
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24645
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24448
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.24591
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22795
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22099
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.23667
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22373
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22319
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21323
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20155
[29.10.2025 21:10] Get page data from previous paper. URL: https://huggingface.co/papers/2510.22264
[29.10.2025 21:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[29.10.2025 21:10] No deleted papers detected.
[29.10.2025 21:10] Downloading and parsing papers (pdf, html). Total: 37.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24668.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24668.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24668.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24701.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24701.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24701.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24699.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24699.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24699.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.23763.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.23763.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.23763.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.23691.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.23691.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.23691.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24717.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24717.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24717.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24694.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24694.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24694.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24563.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24563.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24563.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24657.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24657.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24657.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24697.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24697.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24697.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24698.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24698.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24698.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24695.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24695.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24695.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24514.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24514.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24514.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.23642.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.23642.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.23642.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24711.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24711.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24711.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24693.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24693.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24693.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24320.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24320.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24320.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.21978.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.21978.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.21978.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22037.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22037.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22037.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.17439.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.17439.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.17439.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.20661.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.20661.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.20661.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24702.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24702.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24702.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24081.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24081.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24081.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.23925.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.23925.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.23925.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22768.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22768.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22768.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24684.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24684.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24684.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24645.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24645.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24645.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24448.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24448.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24448.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.24591.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.24591.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.24591.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22795.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22795.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22795.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22099.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22099.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22099.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.23667.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.23667.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.23667.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22373.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22373.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22373.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22319.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22319.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22319.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.21323.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.21323.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.21323.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.20155.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.20155.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.20155.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Downloading and parsing paper https://huggingface.co/papers/2510.22264.
[29.10.2025 21:10] Extra JSON file exists (./assets/json/2510.22264.json), skip PDF parsing.
[29.10.2025 21:10] Paper image links file exists (./assets/img_data/2510.22264.json), skip HTML parsing.
[29.10.2025 21:10] Success.
[29.10.2025 21:10] Enriching papers with extra data.
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 0. InteractComp evaluates search agents' ability to recognize and resolve query ambiguity through interaction, revealing significant gaps in current models' capabilities.  					AI-generated summary 				 Language agents have demonstrated remarkable potential in web search and information retrieval. Howe...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 1. Tongyi DeepResearch, a large language model with agentic capabilities, achieves top performance in various deep research tasks through an end-to-end training framework and automated data synthesis.  					AI-generated summary 				 We present Tongyi DeepResearch, an agentic large language model, which...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 2. AgentFold, a novel proactive context management paradigm for LLM-based web agents, achieves superior performance on long-horizon tasks through dynamic context folding, surpassing larger models and proprietary agents.  					AI-generated summary 				 LLM-based web agents show immense promise for infor...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 3. RoboOmni, a Perceiver-Thinker-Talker-Executor framework using end-to-end omni-modal LLMs, improves robotic manipulation by inferring user intentions from spoken dialogue, environmental sounds, and visual cues.  					AI-generated summary 				 Recent advances in Multimodal Large Language Models (MLLMs...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 4. Game-TARS, a generalist game agent trained with a unified action space, achieves superior performance across various domains and benchmarks through large-scale pre-training and efficient reasoning strategies.  					AI-generated summary 				 We present Game-TARS, a generalist game agent trained with ...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 5. URSA, a discrete generative model, bridges the gap with continuous approaches in video generation by using a Linearized Metric Path and Resolution-dependent Timestep Shifting, achieving high-resolution and long-duration synthesis with fewer inference steps.  					AI-generated summary 				 Continuous...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 6. Entity-aware Group Relative Policy Optimization (E-GRPO) enhances search agents by incorporating entity information into the reward function, improving accuracy and efficiency in knowledge-intensive tasks.  					AI-generated summary 				 LLM-based search agents are increasingly trained on entity-cen...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 7. OSWorld-MCP is a benchmark that evaluates multimodal agents' tool invocation, GUI operation, and decision-making abilities, highlighting the importance of assessing tool usage in real-world scenarios.  					AI-generated summary 				 With advances in decision-making and reasoning capabilities, multim...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 8. Group Relative Attention Guidance enhances image editing quality by modulating token deltas in Diffusion-in-Transformer models, providing fine-grained control over editing intensity.  					AI-generated summary 				 Recently, image editing based on Diffusion-in-Transformer models has undergone rapid ...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 9. WebLeaper framework improves information seeking efficiency and effectiveness by constructing high-coverage tasks and generating efficient solution trajectories using tree-structured reasoning and curated Wikipedia tables.  					AI-generated summary 				 Large Language Model (LLM)-based agents have ...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 10. ParallelMuse enhances problem-solving by efficiently reusing paths and compressing reasoning in deep information-seeking agents, improving performance and reducing token consumption.  					AI-generated summary 				 Parallel thinking expands exploration breadth, complementing the deep exploration of ...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 11. A ZPD-guided data synthesis approach enhances large language model capabilities by training them on tasks just beyond their current abilities, leading to state-of-the-art performance on complex benchmarks.  					AI-generated summary 				 Training large language model agents on tasks at the frontier ...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 12. Latent Sketchpad enhances Multimodal Large Language Models with an internal visual scratchpad, enabling generative visual thought and improved reasoning performance.  					AI-generated summary 				 While Multimodal Large Language Models (MLLMs) excel at visual understanding, they often struggle in c...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 13. VisCoder2, a family of multi-language visualization models, outperforms open-source baselines and approaches proprietary models by leveraging VisCode-Multi-679K and VisPlotBench for iterative self-debugging and multi-turn correction.  					AI-generated summary 				 Large language models (LLMs) have ...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 14. ProMoE, an MoE framework with conditional and prototypical routing, enhances expert specialization in Diffusion Transformers, achieving state-of-the-art performance on ImageNet.  					AI-generated summary 				 Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity whi...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 15. STAR-Bench measures audio 4D intelligence by evaluating sound dynamics in time and 3D space, revealing gaps in fine-grained perceptual reasoning among existing models.  					AI-generated summary 				 Despite rapid progress in Multi-modal Large Language Models and Large Audio-Language Models, existin...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 16. Critique-RL is an online reinforcement learning approach for developing critiquing language models without strong supervision, using a two-stage optimization strategy to improve both the critic's discriminability and helpfulness.  					AI-generated summary 				 Training critiquing language models to...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 17. RECAP, a dynamic objective reweighting strategy, enhances reinforcement learning with verifiable rewards by preserving general knowledge and improving reasoning through flexible reward trade-offs.  					AI-generated summary 				 Reinforcement learning with verifiable rewards (RLVR) has delivered imp...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 18. The study introduces ATLAS, a multilingual scaling law that improves out-of-sample generalization and provides insights into cross-lingual transfer, optimal scaling, and computational crossover points for model training.  					AI-generated summary 				 Scaling laws research has focused overwhelmingl...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 19. FALCON enhances vision-language-action models by integrating rich 3D spatial tokens into the action head, improving spatial reasoning and modality transferability.  					AI-generated summary 				 Existing vision-language-action (VLA) models act in 3D real-world but are typically built on 2D encoders...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 20. A new dataset and frequency-aware post-training method improve fine-grained detail synthesis in ultra-high-resolution text-to-image diffusion models.  					AI-generated summary 				 Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable progress. However, two key challenges rema...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 21. The agent data protocol (ADP) standardizes diverse agent training datasets, enabling improved performance across various tasks without domain-specific tuning.  					AI-generated summary 				 Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the c...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 22. Global PIQA is a multilingual commonsense reasoning benchmark that highlights performance gaps of large language models across different cultures and languages.  					AI-generated summary 				 To date, there exist almost no culturally-specific evaluation benchmarks for large language models (LLMs) t...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 23. The proposed method reformulates reasoning in Large Vision-Language Models as posterior inference using amortized variational inference and a sparse reward function, improving effectiveness, generalization, and interpretability.  					AI-generated summary 				 Chain-of-thought (CoT) reasoning is cri...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 24. MMPersuade is a framework for studying multimodal persuasion in Large Vision-Language Models, revealing insights into their susceptibility and the effectiveness of various persuasive strategies across different contexts.  					AI-generated summary 				 As Large Vision-Language Models (LVLMs) are inc...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 25. SPICE, a reinforcement learning framework, uses self-play in a corpus environment to continuously improve a model's reasoning capabilities through adversarial dynamics and document grounding.  					AI-generated summary 				 Self-improving systems require environmental interaction for continuous adap...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 26. FunReason-MT is a novel data synthesis framework that enhances multi-turn function calling in large language models by addressing challenges in environment interaction, query synthesis, and chain-of-thought generation, achieving state-of-the-art performance on the Berkeley Function-Calling Leaderboa...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 27. Video Diffusion Models (VDMs) show higher data efficiency than large language models across various visual tasks, suggesting video pretraining can enhance visual foundation models.  					AI-generated summary 				 Large language models (LLMs) have demonstrated that large-scale pretraining enables sys...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 28. ReplicationBench evaluates AI agents' ability to replicate astrophysics research papers, providing insights into their faithfulness and correctness in scientific research tasks.  					AI-generated summary 				 Frontier AI agents show increasing promise as scientific research assistants, and may even...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 29. SAO-Instruct, a generative model based on Stable Audio Open, allows flexible audio editing using natural language instructions, outperforming existing methods in both objective and subjective evaluations.  					AI-generated summary 				 Generative models have made significant progress in synthesizin...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 30. A framework using the Information Bottleneck principle and Dynamic Mode Steering algorithm improves the reliability of Large Language Models by balancing generalization and memorization.  					AI-generated summary 				 Large Language Models (LLMs) exhibit a troubling duality, capable of both remarka...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 31. OAT, a deep-learning framework combining autoencoder, neural-field decoder, and latent-diffusion model, achieves fast and general topology optimization with high performance across various conditions and resolutions.  					AI-generated summary 				 Structural topology optimization (TO) is central to...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 32. VisJudge-Bench is a benchmark for evaluating MLLMs' performance in assessing visualization aesthetics and quality, revealing gaps compared to human experts and demonstrating improvements with the VisJudge model.  					AI-generated summary 				 Visualization, a domain-specific yet widely used form of...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 33. GRPO-Guard enhances GRPO-based reinforcement learning by normalizing importance ratios and reweighting gradients, mitigating over-optimization in flow-matching models without heavy KL regularization.  					AI-generated summary 				 Recently, GRPO-based reinforcement learning has shown remarkable pro...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 34. VL-SAE, a sparse autoencoder, enhances vision-language alignment by correlating neurons to unified concepts, improving interpretability and performance in tasks like zero-shot image classification and hallucination elimination.  					AI-generated summary 				 The alignment of vision-language represe...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 35. PartNeXt, a high-quality, textured 3D dataset with fine-grained part labels, improves performance in class-agnostic part segmentation and 3D part-centric question answering, highlighting gaps in open-vocabulary part grounding.  					AI-generated summary 				 Understanding objects at the level of the...
[29.10.2025 21:10] ********************************************************************************
[29.10.2025 21:10] Abstract 36. PatenTEB is a comprehensive benchmark for patent text embeddings with 15 tasks, and the patembed model family demonstrates strong generalization across various patent-specific challenges.  					AI-generated summary 				 Patent text embeddings enable prior art search, technology landscaping, and pate...
[29.10.2025 21:10] Read previous papers.
[29.10.2025 21:10] Generating reviews via LLM API.
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#alignment", "#interpretability", "#benchmark", "#agents", "#reasoning"], "emoji": "❓", "ru": {"title": "Поисковые агенты не умеют задавать уточняющие вопросы", "desc": "Исследователи представили бенчмарк InteractComp для оценки способности поисковых AI-агентов распознавать неоднозн
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#long_context", "#synthetic", "#dataset", "#benchmark", "#training", "#open_source", "#agi", "#agents"], "emoji": "🔍", "ru": {"title": "Автономный AI-агент для глубоких исследований", "desc": "Tongyi DeepResearch - это большая языковая модель с агентными способностями, специализирую
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#long_context", "#benchmark", "#training", "#agents"], "emoji": "🗂️", "ru": {"title": "Динамическое сворачивание контекста для эффективных веб-агентов", "desc": "AgentFold — это новая парадигма управления контекстом для веб-агентов на основе LLM, вдохновленная процессом ретроспектив
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#agents", "#dataset", "#optimization", "#games", "#multimodal", "#interpretability"], "emoji": "🤖", "ru": {"title": "Робот, который понимает намерения без прямых команд", "desc": "Статья представляет RoboOmni — систему для роботизированной манипуляции, которая понимает намерения пол
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#agents", "#training", "#games", "#benchmark", "#multimodal", "#reasoning"], "emoji": "🎮", "ru": {"title": "Универсальный игровой агент через единое пространство действий", "desc": "Game-TARS — это универсальный игровой агент, обученный на едином пространстве действий, основанном на
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#diffusion", "#benchmark", "#architecture", "#video"], "emoji": "🎥", "ru": {"title": "URSA: Новая эра дискретной генерации видео", "desc": "В статье представлена модель URSA, которая улучшает генерацию видео с использованием дискретных подходов, приближая их к непрерывным методам. U
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#training", "#optimization", "#rl", "#agents", "#reasoning"], "emoji": "🎯", "ru": {"title": "Учимся на «почти правильных» ответах: награды за найденные сущности", "desc": "Статья представляет Entity-aware Group Relative Policy Optimization (E-GRPO) — улучшенный метод обучения LLM-аг
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#benchmark", "#optimization", "#open_source", "#agents"], "emoji": "🛠️", "ru": {"title": "Новый стандарт оценки AI-агентов: не только GUI, но и умение пользоваться инструментами", "desc": "OSWorld-MCP — это первый комплексный бенчмарк для оценки мультимо
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#training", "#optimization", "#cv", "#diffusion"], "emoji": "🎚️", "ru": {"title": "Точная настройка силы редактирования через модуляцию токенов", "desc": "Исследователи предложили метод Group Relative Attention Guidance (GRAG) для улучшения контроля 
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#survey", "#training", "#optimization", "#benchmark", "#agents", "#reasoning"], "emoji": "🌳", "ru": {"title": "WebLeaper: Эффективный поиск информации через древовидное рассуждение", "desc": "Статья представляет WebLeaper — фреймворк для улучшения эффективности информаци
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#training", "#optimization", "#benchmark", "#agents", "#reasoning"], "emoji": "🔀", "ru": {"title": "Параллельное мышление для AI-агентов: быстрее думаем, меньше тратим", "desc": "Исследователи представили ParallelMuse — систему, которая улучшает работу AI-агентов при решении сложных
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#training", "#benchmark", "#synthetic", "#data", "#agents", "#reasoning"], "emoji": "🎯", "ru": {"title": "Обучение AI в зоне ближайшего развития", "desc": "Исследователи предложили подход к синтезу данных для обучения LLM, основанный на педагогической концепции зоны ближ
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#reasoning", "#dataset", "#cv", "#multimodal", "#interpretability"], "emoji": "✏️", "ru": {"title": "Визуальное мышление для AI: когда нейросеть учится рисовать свои мысли", "desc": "Статья представляет Latent Sketchpad — фреймворк, который добавляет мультимодальным LLM внутренний в
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#open_source", "#science", "#dataset", "#multilingual", "#benchmark", "#agents"], "emoji": "📊", "ru": {"title": "Мультиязычный AI-агент для визуализации данных с самоотладкой", "desc": "Представлена семья моделей VisCoder2 для генерации кода визуализаций на 12 языках программировани
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#optimization", "#cv", "#benchmark", "#diffusion"], "emoji": "🎨", "ru": {"title": "Специализация экспертов в диффузионных моделях через двухэтапную маршрутизацию", "desc": "Статья представляет ProMoE — новый подход к использованию Mixture-of-Experts 
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#interpretability", "#data", "#audio", "#reasoning", "#benchmark", "#open_source"], "emoji": "🎧", "ru": {"title": "4D аудио-интеллект: новый уровень понимания звука в пространстве и времени", "desc": "Статья представляет STAR-Bench — новый бенчмарк для оценки «4D аудио-интеллекта» у
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#rl", "#reasoning", "#optimization", "#training", "#rlhf"], "emoji": "🧠", "ru": {"title": "Critique-RL: Улучшение языковых моделей без сильного надзора", "desc": "Critique-RL — это метод обучения с подкреплением для создания языковых моделей, которые могут критиковать без сильного н
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#optimization", "#training", "#benchmark", "#reasoning", "#rl", "#rlhf"], "emoji": "⚖️", "ru": {"title": "Динамическое перевзвешивание целей для сохранения знаний при обучении с подкреплением", "desc": "Статья представляет RECAP — метод для решения проблемы деградации базовых навыко
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#low_resource", "#multilingual", "#transfer_learning", "#dataset", "#training"], "emoji": "🌍", "ru": {"title": "Законы масштабирования для многоязычного AI", "desc": "ATLAS — это новый закон масштабирования для многоязычных языковых моделей, основанный на 774 экспериментах с моделям
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#3d", "#reasoning", "#architecture", "#benchmark", "#alignment", "#transfer_learning", "#multimodal"], "emoji": "🧠", "ru": {"title": "FALCON: Прорыв в пространственном мышлении для VLA моделей", "desc": "В статье представлена новая модель FALCON, которая улучшает пространственное мы
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#training", "#benchmark", "#synthetic", "#dataset", "#diffusion", "#cv"], "emoji": "🔬", "ru": {"title": "Совершенство в деталях: частотная настройка для сверхвысокого разрешения", "desc": "Статья представляет новый датасет UltraHR-100K из 100 тысяч ультравысокого разрешения изображе
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#open_source", "#agents", "#training", "#dataset", "#optimization", "#benchmark"], "emoji": "🔗", "ru": {"title": "Единый язык данных для обучения AI-агентов", "desc": "Исследователи представили Agent Data Protocol (ADP) — универсальный формат для стандартизации разнородных датасетов
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#ethics", "#multilingual", "#low_resource", "#benchmark"], "emoji": "🌍", "ru": {"title": "Культурное разнообразие обнажает слабости языковых моделей", "desc": "Global PIQA — это мультиязычный бенчмарк для оценки здравого смысла LLM, созданный вручную исслед
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#interpretability", "#training", "#multimodal", "#benchmark", "#reasoning", "#rl", "#rlhf"], "emoji": "🧠", "ru": {"title": "Байесовский подход к обучению рассуждению в мультимодальных LLM", "desc": "Статья предлагает новый метод обучения больших мультимодальных моделей (LVLMs) рассу
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#ethics", "#multimodal", "#alignment", "#benchmark"], "emoji": "🎭", "ru": {"title": "Как изображения делают AI-модели более внушаемыми", "desc": "В статье представлен MMPersuade - фреймворк для изучения мультимодального убеждения в больших vision-language моделях (LVLMs)
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#optimization", "#rl", "#benchmark", "#reasoning", "#rlhf"], "emoji": "🎭", "ru": {"title": "Две роли одной модели: самообучение через adversarial игру с документами", "desc": "SPICE - это фреймворк для reinforcement learning, где одна модель играет две роли: Challenger ищет документ
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#training", "#optimization", "#data", "#agents", "#transfer_learning"], "emoji": "🔧", "ru": {"title": "Учим LLM правильно пользоваться инструментами в несколько шагов", "desc": "FunReason-MT — это новый фреймворк для синтеза данных, который улучшает способность больших я
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#multimodal", "#transfer_learning", "#games", "#diffusion", "#benchmark", "#video"], "emoji": "🎬", "ru": {"title": "Видео-диффузия побеждает языковые модели в визуальных задачах", "desc": "Исследователи сравнили Video Diffusion Models (VDMs) и большие языковые модели (LLM) в визуаль
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#science", "#agents"], "emoji": "🔭", "ru": {"title": "Проверка AI-агентов на репликацию научных исследований", "desc": "Исследователи представили ReplicationBench — бенчмарк для оценки способности AI-агентов воспроизводить научные работы по астрофизике. Каждая задача в
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#open_source", "#audio", "#synthetic"], "emoji": "🎨", "ru": {"title": "Редактирование аудио свободными текстовыми командами", "desc": "SAO-Instruct — это генеративная модель на основе Stable Audio Open, которая позволяет редактировать аудио с помощью произвольных текстов
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#reasoning", "#interpretability", "#inference", "#training"], "emoji": "🧭", "ru": {"title": "Управление режимами мышления: как научить LLM обобщать, а не заучивать", "desc": "Исследователи предлагают новый подход к проблеме, когда большие языковые модели то блестяще обобщают знания,
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#inference", "#benchmark", "#dataset", "#diffusion", "#optimization", "#open_source", "#architecture"], "emoji": "🏗️", "ru": {"title": "OAT: универсальная AI-система для мгновенной оптимизации любых конструкций", "desc": "Представлена OAT — framework на основе deep learning для топо
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#interpretability", "#multimodal", "#optimization"], "emoji": "📊", "ru": {"title": "VisJudge: учим AI понимать красоту графиков", "desc": "Статья представляет VisJudge-Bench — первый комплексный бенчмарк для оценки способности multimodal LLM оценивать эстетику и качест
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl"], "emoji": "🛡️", "ru": {"title": "Защита от переобучения в reinforcement learning для диффузионных моделей", "desc": "Статья представляет GRPO-Guard — улучшенный метод обучения с подкреплением для flow-matching моделей. Авторы обнаружили, 
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#alignment", "#multimodal", "#interpretability", "#cv", "#hallucinations", "#training"], "emoji": "🔍", "ru": {"title": "Разреженный автоэнкодер для понимания и усиления связи между зрением и языком", "desc": "VL-SAE — это разреженный автоэнкодер, который повышает интерпретируемость 
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#dataset", "#3d", "#benchmark", "#cv"], "emoji": "🧩", "ru": {"title": "PartNeXt: текстурированные 3D модели с детальной разметкой частей для продвинутого понимания объектов", "desc": "Исследователи представили PartNeXt — новый датасет из более чем 23,000 высококачественных текстурир
[29.10.2025 21:10] Using data from previous issue: {"categories": ["#benchmark", "#training", "#open_source", "#multimodal", "#transfer_learning", "#dataset"], "emoji": "📜", "ru": {"title": "PatenTEB: специализированный бенчмарк для патентных эмбеддингов нового поколения", "desc": "Исследователи представили PatenTEB — комплексный бенчмарк для оценки
[29.10.2025 21:10] Renaming data file.
[29.10.2025 21:10] Renaming previous data. hf_papers.json to ./d/2025-10-29.json
[29.10.2025 21:10] Saving new data file.
[29.10.2025 21:10] Generating page.
[29.10.2025 21:10] Renaming previous page.
[29.10.2025 21:10] Renaming previous data. index.html to ./d/2025-10-29.html
[29.10.2025 21:10] Writing result.
[29.10.2025 21:10] Renaming log file.
[29.10.2025 21:10] Renaming previous data. log.txt to ./logs/2025-10-29_last_log.txt
