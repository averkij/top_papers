[27.11.2024 07:11] Read previous papers.
[27.11.2024 07:11] Generating top page (month).
[27.11.2024 07:11] Writing top page (month).
[27.11.2024 07:13] Read previous papers.
[27.11.2024 07:13] Get feed.
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17465
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17116
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17686
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.15296
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.14740
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17673
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17467
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.16819
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17223
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.16173
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17691
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.16754
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.16856
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.17383
[27.11.2024 07:13] Get page data from previous paper. URL: https://huggingface.co/papers/2411.15411
[27.11.2024 07:13] Downloading and parsing papers (pdf, html). Total: 15.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17465.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17465.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17465.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17116.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17116.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17116.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17686.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17686.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17686.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.15296.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.15296.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.15296.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.14740.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.14740.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.14740.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17673.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17673.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17673.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17467.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17467.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17467.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.16819.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.16819.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.16819.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17223.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17223.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17223.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.16173.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.16173.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.16173.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17691.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17691.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17691.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.16754.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.16754.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.16754.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.16856.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.16856.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.16856.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.17383.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.17383.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.17383.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Downloading and parsing paper https://huggingface.co/papers/2411.15411.
[27.11.2024 07:13] Extra JSON file exists (./assets/json/2411.15411.json), skip PDF parsing.
[27.11.2024 07:13] Paper image links file exists (./assets/img_data/2411.15411.json), skip HTML parsing.
[27.11.2024 07:13] Success.
[27.11.2024 07:13] Enriching papers with extra data.
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 0. Building Graphical User Interface (GUI) assistants holds significant promise for enhancing human workflow productivity. While most agents are language-based, relying on closed-source API with text-rich meta-information (e.g., HTML or accessibility tree), they show limitations in perceiving UI visual...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 1. Inference with Transformer-based Large Language Models (LLMs) on long sequences is both costly and slow due to the quadratic complexity of the self-attention mechanism. We introduce Star Attention, a two-phase block-sparse approximation that improves computational efficiency by sharding attention ac...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 2. To accelerate the inference of heavy Multimodal Large Language Models (MLLMs), this study rethinks the current landscape of training-free token reduction research. We regret to find that the critical components of existing methods are tightly intertwined, with their interconnections and effects rema...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 3. As a prominent direction of Artificial General Intelligence (AGI), Multimodal Large Language Models (MLLMs) have garnered increased attention from both industry and academia. Building upon pre-trained LLMs, this family of models further develops multimodal perception and reasoning capabilities that ...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 4. While high-quality texture maps are essential for realistic 3D asset rendering, few studies have explored learning directly in the texture space, especially on large-scale datasets. In this work, we depart from the conventional approach of relying on pre-trained 2D diffusion models for test-time opt...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 5. Sketching serves as a versatile tool for externalizing ideas, enabling rapid exploration and visual communication that spans various disciplines. While artificial systems have driven substantial advances in content creation and human-computer interaction, capturing the dynamic and abstract nature of...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 6. Self-supervised learning has emerged as a promising approach for acquiring transferable 3D representations from unlabeled 3D point clouds. Unlike 2D images, which are widely accessible, acquiring 3D assets requires specialized expertise or professional 3D scanning equipment, making it difficult to s...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 7. Recent advances in image editing, driven by image diffusion models, have shown remarkable progress. However, significant challenges remain, as these models often struggle to follow complex edit instructions accurately and frequently compromise fidelity by altering key elements of the original image....
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 8. Subject-driven image inpainting has emerged as a popular task in image editing alongside recent advancements in diffusion models. Previous methods primarily focus on identity preservation but struggle to maintain the editability of inserted objects. In response, this paper introduces DreamMix, a dif...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 9. Despite advances in Large Multi-modal Models, applying them to long and untrimmed video content remains challenging due to limitations in context length and substantial memory overhead. These constraints often lead to significant information loss and reduced relevance in the model responses. With th...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 10. We reveal that low-bit quantization favors undertrained large language models (LLMs) by observing that models with larger sizes or fewer training tokens experience less quantization-induced degradation (QiD) when applying low-bit quantization, whereas smaller models with extensive training tokens su...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 11. The proliferation of AI techniques for image generation, coupled with their increasing accessibility, has raised significant concerns about the potential misuse of these images to spread misinformation. Recent AI-generated image detection (AGID) methods include CNNDetection, NPR, DM Image Detection,...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 12. Autoregressive models have demonstrated remarkable success across various fields, from large language models (LLMs) to large multimodal models (LMMs) and 2D content generation, moving closer to artificial general intelligence (AGI). Despite these advances, applying autoregressive approaches to 3D ob...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 13. The automatic generation of anchor-style product promotion videos presents promising opportunities in online commerce, advertising, and consumer engagement. However, this remains a challenging task despite significant advancements in pose-guided human video generation. In addressing this challenge, ...
[27.11.2024 07:13] ********************************************************************************
[27.11.2024 07:13] Abstract 14. The advent of large Vision-Language Models (VLMs) has significantly advanced multimodal tasks, enabling more sophisticated and accurate reasoning across various applications, including image and video captioning, visual question answering, and cross-modal retrieval. Despite their superior capabiliti...
[27.11.2024 07:13] Read previous papers.
[27.11.2024 07:13] Generating reviews via LLM API.
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#training", "#data", "#games", "#optimization", "#cv", "#agents", "#graphs", "#dataset"], "emoji": "🖥️", "ru": {"title": "ShowUI: Революция в создании интеллектуальных графических интерфейсов", "desc": "Статья представляет ShowUI - модель для создания графических пользовательских ин
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#long_context", "#inference", "#optimization", "#architecture"], "emoji": "⭐", "ru": {"title": "Звездное внимание: ускорение LLM без потери точности", "desc": "Статья представляет метод Star Attention для улучшения эффективности вычислений в трансформерных моделях большого языка (LL
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#optimization", "#inference", "#benchmark", "#multimodal"], "emoji": "🚀", "ru": {"title": "Ускорение MLLM: новая парадигма сокращения токенов", "desc": "Данная статья представляет новый подход к ускорению вывода мультимодальных больших языковых моделей (MLLM). Авторы предлагают униф
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#benchmark", "#agi", "#survey", "#multimodal"], "emoji": "🧠", "ru": {"title": "Комплексный подход к оценке мультимодальных языковых моделей", "desc": "Эта статья представляет собой обзор методов оценки мультимодальных больших языковых моделей (MLLM). Авторы рассматривают четыре ключ
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#3d", "#games", "#architecture", "#cv", "#diffusion"], "emoji": "🎨", "ru": {"title": "Революция в генерации 3D-текстур: обучение диффузионной модели прямо в UV-пространстве", "desc": "Статья представляет новый подход к генерации текстурных карт для 3D-объектов. Авторы обучили крупну
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#multimodal", "#agents"], "emoji": "✏️", "ru": {"title": "SketchAgent: диалоговое рисование с помощью языковых моделей", "desc": "В статье представлен SketchAgent - метод генерации эскизов, управляемый языком. Он позволяет пользователям создавать и модифицировать эскизы через диалог
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#3d", "#dataset", "#transfer_learning", "#synthetic"], "emoji": "🧊", "ru": {"title": "Самообучение 3D-представлениям без семантики: геометрия важнее смысла", "desc": "Статья представляет новый подход к самообучению для получения трехмерных представлений из немаркированных облаков то
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#diffusion", "#video", "#cv", "#multimodal"], "emoji": "🎬", "ru": {"title": "Редактирование изображений через призму видео: новый взгляд на старую задачу", "desc": "Эта статья предлагает новый подход к редактированию изображений с использованием моделей генерации видео. Авторы перео
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#open_source", "#cv"], "emoji": "🎨", "ru": {"title": "DreamMix: Вставка и редактирование объектов на изображениях с помощью текста", "desc": "DreamMix - это генеративная модель на основе диффузии для вставки объектов в изображения. Она позволяет не тольк
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#architecture", "#video", "#long_context", "#multimodal", "#dataset"], "emoji": "🎥", "ru": {"title": "SALOVA: умный помощник для анализа длинных видео", "desc": "SALOVA - это новая система для обработки длинных видео с помощью больших мультимодальных моделей. Она решает проблему огр
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#low_resource", "#dataset", "#open_source", "#inference"], "emoji": "🧠", "ru": {"title": "Квантование раскрывает тайны обучения языковых моделей", "desc": "Исследование показывает, что квантование с низким битрейтом менее вредно для недообученных больших языковых моделей (LLM), чем 
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#open_source", "#cv", "#benchmark", "#security", "#ethics", "#dataset"], "emoji": "🕵️", "ru": {"title": "Новый подход к выявлению ИИ-генерированных изображений", "desc": "В статье рассматривается проблема обнаружения изображений, сгенерированных искусственным интеллектом (ИИ), в кон
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#multimodal", "#3d", "#architecture", "#games", "#agi"], "emoji": "🧊", "ru": {"title": "SAR3D: Быстрая генерация и глубокое понимание 3D объектов", "desc": "Статья представляет новый фреймворк SAR3D для генерации и понимания 3D объектов с использованием авторегрессионного подхода. S
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#training", "#video", "#cv", "#diffusion"], "emoji": "🎬", "ru": {"title": "AnchorCrafter: ИИ создает реалистичные промо-видео с взаимодействием человека и товара", "desc": "Статья представляет AnchorCrafter - новую систему на основе диффузии для генерации видео с взаимодействием чел
[27.11.2024 07:13] Using data from previous issue: {"categories": ["#training", "#multimodal", "#games", "#cv", "#dataset", "#reasoning"], "emoji": "🔬", "ru": {"title": "Новый подход к композиционному описанию изображений с помощью усовершенствованных мультимодальных языковых моделей", "desc": "В статье представлена новая модель FINECAPTION, способн
[27.11.2024 07:13] Loading Chinese text from previous data.
[27.11.2024 07:13] Renaming data file.
[27.11.2024 07:13] Renaming previous data. hf_papers.json to ./d/2024-11-27.json
[27.11.2024 07:13] Saving new data file.
[27.11.2024 07:13] Generating page.
[27.11.2024 07:13] Renaming previous page.
[27.11.2024 07:13] Renaming previous data. index.html to ./d/2024-11-27.html
[27.11.2024 07:13] [Experimental] Generating Chinese page for reading.
[27.11.2024 07:13] Chinese vocab [{'word': '展示', 'pinyin': 'zhǎnshì', 'trans': 'display'}, {'word': 'Material', 'pinyin': 'Méitèriǎl', 'trans': 'Material'}, {'word': 'Anything', 'pinyin': 'Ēnìthìng', 'trans': 'Anything'}, {'word': '自动化', 'pinyin': 'zìdònghuà', 'trans': 'automated'}, {'word': '统一', 'pinyin': 'tǒngyī', 'trans': 'unified'}, {'word': '扩散', 'pinyin': 'kuòsàn', 'trans': 'diffusion'}, {'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'}, {'word': '旨在', 'pinyin': 'zhǐzài', 'trans': 'aim to'}, {'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'}, {'word': '物理', 'pinyin': 'wùlǐ', 'trans': 'physics'}, {'word': '材质', 'pinyin': 'cáizhì', 'trans': 'material'}, {'word': '依赖', 'pinyin': 'yīlài', 'trans': 'rely on'}, {'word': '复杂', 'pinyin': 'fùzá', 'trans': 'complex'}, {'word': '流水线', 'pinyin': 'liúshuǐxiàn', 'trans': 'pipeline'}, {'word': '特定', 'pinyin': 'tèdìng', 'trans': 'specific'}, {'word': '案例', 'pinyin': 'ànlì', 'trans': 'case'}, {'word': '优化', 'pinyin': 'yōuhuà', 'trans': 'optimization'}, {'word': '健壮', 'pinyin': 'jiànzhuàng', 'trans': 'robust'}, {'word': '端到端', 'pinyin': 'duāndàoduān', 'trans': 'end-to-end'}, {'word': '解决方案', 'pinyin': 'jiějué fāngàn', 'trans': 'solution'}, {'word': '利用', 'pinyin': 'lìyòng', 'trans': 'utilize'}, {'word': '预训练', 'pinyin': 'yùxùnliàn', 'trans': 'pre-trained'}, {'word': '图像', 'pinyin': 'túxiàng', 'trans': 'image'}, {'word': '结合', 'pinyin': 'jiéhé', 'trans': 'combine'}, {'word': '三头架构', 'pinyin': 'sāntóu jiàgòu', 'trans': 'three-headed architecture'}, {'word': '渲染', 'pinyin': 'xuànrán', 'trans': 'rendering'}, {'word': '损失', 'pinyin': 'sǔnshī', 'trans': 'loss'}, {'word': '稳定性', 'pinyin': 'wěndìngxìng', 'trans': 'stability'}, {'word': '质量', 'pinyin': 'zhìliàng', 'trans': 'quality'}, {'word': '置信', 'pinyin': 'zhìxìn', 'trans': 'confidence'}, {'word': '掩码', 'pinyin': 'yǎnmǎ', 'trans': 'mask'}, {'word': '动态', 'pinyin': 'dòngtài', 'trans': 'dynamic'}, {'word': '开关', 'pinyin': 'kāiguān', 'trans': 'switch'}, {'word': '有效', 'pinyin': 'yǒuxiào', 'trans': 'effective'}, {'word': '纹理', 'pinyin': 'wénlǐ', 'trans': 'texture'}, {'word': '渐进', 'pinyin': 'jiànjìn', 'trans': 'progressive'}, {'word': '策略', 'pinyin': 'cèlüè', 'trans': 'strategy'}, {'word': 'UV空间', 'pinyin': 'UV kōngjiān', 'trans': 'UV space'}, {'word': '精炼器', 'pinyin': 'jīngliànqì', 'trans': 'refiner'}, {'word': '确保', 'pinyin': 'quèbǎo', 'trans': 'ensure'}, {'word': '一致', 'pinyin': 'yīzhì', 'trans': 'consistent'}, {'word': '准备好', 'pinyin': 'zhǔnbèi hǎo', 'trans': 'ready'}, {'word': '广泛', 'pinyin': 'guǎngfàn', 'trans': 'extensive'}, {'word': '类别', 'pinyin': 'lèibié', 'trans': 'category'}, {'word': '优于', 'pinyin': 'yōuyú', 'trans': 'superior to'}]
[27.11.2024 07:13] Renaming previous Chinese page.
[27.11.2024 07:13] Renaming previous data. zh.html to ./d/2024-11-26_zh_reading_task.html
[27.11.2024 07:13] Writing Chinese reading task.
[27.11.2024 07:13] Writing result.
[27.11.2024 07:13] Renaming log file.
[27.11.2024 07:13] Renaming previous data. log.txt to ./logs/2024-11-27_last_log.txt
