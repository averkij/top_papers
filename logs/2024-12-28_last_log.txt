[28.12.2024 06:28] Read previous papers.
[28.12.2024 06:28] Generating top page (month).
[28.12.2024 06:28] Writing top page (month).
[28.12.2024 12:38] Read previous papers.
[28.12.2024 12:38] Get feed.
[28.12.2024 12:38] Get page data from previous paper. URL: https://huggingface.co/papers/2412.17743
[28.12.2024 12:38] Get page data from previous paper. URL: https://huggingface.co/papers/2412.17483
[28.12.2024 12:38] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18176
[28.12.2024 12:38] Get page data from previous paper. URL: https://huggingface.co/papers/2412.18072
[28.12.2024 12:38] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.12.2024 12:38] No deleted papers detected.
[28.12.2024 12:38] Downloading and parsing papers (pdf, html). Total: 4.
[28.12.2024 12:38] Downloading and parsing paper https://huggingface.co/papers/2412.17743.
[28.12.2024 12:38] Extra JSON file exists (./assets/json/2412.17743.json), skip PDF parsing.
[28.12.2024 12:38] Paper image links file exists (./assets/img_data/2412.17743.json), skip HTML parsing.
[28.12.2024 12:38] Success.
[28.12.2024 12:38] Downloading and parsing paper https://huggingface.co/papers/2412.17483.
[28.12.2024 12:38] Extra JSON file exists (./assets/json/2412.17483.json), skip PDF parsing.
[28.12.2024 12:38] Paper image links file exists (./assets/img_data/2412.17483.json), skip HTML parsing.
[28.12.2024 12:38] Success.
[28.12.2024 12:38] Downloading and parsing paper https://huggingface.co/papers/2412.18176.
[28.12.2024 12:38] Extra JSON file exists (./assets/json/2412.18176.json), skip PDF parsing.
[28.12.2024 12:38] Paper image links file exists (./assets/img_data/2412.18176.json), skip HTML parsing.
[28.12.2024 12:38] Success.
[28.12.2024 12:38] Downloading and parsing paper https://huggingface.co/papers/2412.18072.
[28.12.2024 12:38] Extra JSON file exists (./assets/json/2412.18072.json), skip PDF parsing.
[28.12.2024 12:38] Paper image links file exists (./assets/img_data/2412.18072.json), skip HTML parsing.
[28.12.2024 12:38] Success.
[28.12.2024 12:38] Enriching papers with extra data.
[28.12.2024 12:38] ********************************************************************************
[28.12.2024 12:38] Abstract 0. Effective pre-training of large language models (LLMs) has been challenging due to the immense resource demands and the complexity of the technical processes involved. This paper presents a detailed technical report on YuLan-Mini, a highly capable base model with 2.42B parameters that achieves top-t...
[28.12.2024 12:38] ********************************************************************************
[28.12.2024 12:38] Abstract 1. In this work, we provide a thorough investigation of gist-based context compression methods to improve long-context processing in large language models. We focus on two key questions: (1) How well can these methods replace full attention models? and (2) What potential failure patterns arise due to c...
[28.12.2024 12:38] ********************************************************************************
[28.12.2024 12:38] Abstract 2. Sequential recommendation (SR) systems have evolved significantly over the past decade, transitioning from traditional collaborative filtering to deep learning approaches and, more recently, to large language models (LLMs). While the adoption of LLMs has driven substantial advancements, these models...
[28.12.2024 12:38] ********************************************************************************
[28.12.2024 12:38] Abstract 3. With advances in foundational and vision-language models, and effective fine-tuning techniques, a large number of both general and special-purpose models have been developed for a variety of visual tasks. Despite the flexibility and accessibility of these models, no single model is able to handle al...
[28.12.2024 12:38] Read previous papers.
[28.12.2024 12:38] Generating reviews via LLM API.
[28.12.2024 12:38] Using data from previous issue: {"categories": ["#long_context", "#open_source", "#optimization", "#small_models", "#data", "#training"], "emoji": "ğŸš€", "ru": {"title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¼Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ YuLan-Mini - ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ 2.42 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ´
[28.12.2024 12:38] Using data from previous issue: {"categories": ["#training", "#rag", "#optimization", "#long_context", "#data"], "emoji": "ğŸ—œï¸", "ru": {"title": "Ğ¡Ğ¶Ğ°Ñ‚Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…", "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼ ÑĞ¶Ğ°Ñ‚Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ³Ğ¸ÑÑ‚-Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ 
[28.12.2024 12:38] Using data from previous issue: {"categories": ["#dataset", "#multimodal", "#games", "#optimization"], "emoji": "ğŸ§ ", "ru": {"title": "Molar: ĞœÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ ĞºĞ¾Ğ»Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸", "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Molar - Ğ½Ğ¾Ğ²ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ½Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹Ğº
[28.12.2024 12:38] Using data from previous issue: {"categories": ["#benchmark", "#agi", "#optimization", "#agents", "#multimodal"], "emoji": "ğŸ­", "ru": {"title": "MMFactory: ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ„Ğ°Ğ±Ñ€Ğ¸ĞºĞ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡", "desc": "MMFactory - ÑÑ‚Ğ¾ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°
[28.12.2024 12:38] Trying to get texts in Chinese.
[28.12.2024 12:38] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

Effective pre-training of large language models (LLMs) has been challenging due to the immense resource demands and the complexity of the technical processes involved. This paper presents a detailed technical report on YuLan-Mini, a highly capable base model with 2.42B parameters that achieves top-tier performance among models of similar parameter scale. Our pre-training approach focuses on enhancing training efficacy through three key technical contributions: an elaborate data pipeline combines data cleaning with data schedule strategies, a robust optimization method to mitigate training instability, and an effective annealing approach that incorporates targeted data selection and long context training. Remarkably, YuLan-Mini, trained on 1.08T tokens, achieves performance comparable to industry-leading models that require significantly more data. To facilitate reproduction, we release the full details of the data composition for each training phase. Project details can be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.
[28.12.2024 12:39] Mistral response. {"id": "8a516381d3b1441c8c754e971033c594", "object": "chat.completion", "created": 1735389538, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aYuLan-Mini\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u6a21\u578b\u67092.42B\u53c2\u6570\uff0c\u6027\u80fd\u5353\u8d8a\u3002\u7814\u7a76\u56e2\u961f\u901a\u8fc7\u4e09\u79cd\u6280\u672f\u8d21\u732e\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff1a\u6570\u636e\u7ba1\u9053\u3001\u4f18\u5316\u65b9\u6cd5\u548c\u9000\u706b\u65b9\u6cd5\u3002YuLan-Mini\u57281.08T tokens\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u4e0e\u9700\u8981\u66f4\u591a\u6570\u636e\u7684\u884c\u4e1a\u9886\u5148\u6a21\u578b\u76f8\u5f53\u3002\u9879\u76ee\u7ec6\u8282\u53ef\u4ee5\u5728GitHub\u4e0a\u627e\u5230\u3002"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 249, "total_tokens": 384, "completion_tokens": 135}}
[28.12.2024 12:39] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªåä¸ºYuLan-Miniçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰2.42Bå‚æ•°ï¼Œæ€§èƒ½å“è¶Šã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸‰ç§æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08T tokensä¸Šè®­ç»ƒï¼Œæ€§èƒ½ä¸éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ç›¸å½“ã€‚é¡¹ç›®ç»†èŠ‚å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[28.12.2024 12:39] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªåä¸ºYuLan-Miniçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰2.42Bå‚æ•°ï¼Œæ€§èƒ½å“è¶Šã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸‰ç§æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08T tokensä¸Šè®­ç»ƒï¼Œæ€§èƒ½ä¸éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ç›¸å½“ã€‚é¡¹ç›®ç»†èŠ‚å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[28.12.2024 12:39] Mistral response. {"id": "51ac4855616d423e89ddded0797255d0", "object": "chat.completion", "created": 1735389541, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "\u8fd9\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aYuLan-Mini\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\nZh\u00e8 pi\u0101n w\u00e9nzh\u0101ng ji\u00e8sh\u00e0o le y\u012bg\u00e8 m\u00edngw\u00e8i YuLan-Mini de d\u00e0x\u00edng y\u01d4y\u00e1n m\u00f3x\u00edng.\n\n\u8be5\u6a21\u578b\u67092.42B\u53c2\u6570\uff0c\u6027\u80fd\u5353\u8d8a\u3002\nG\u01cei m\u00f3x\u00edng y\u01d2u 2.42B c\u0101nsh\u00f9, x\u00ecngn\u00e9ng zhu\u00f3yu\u00e8.\n\n\u7814\u7a76\u56e2\u961f\u901a\u8fc7\u4e09\u79cd\u6280\u672f\u8d21\u732e\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff1a\u6570\u636e\u7ba1\u9053\u3001\u4f18\u5316\u65b9\u6cd5\u548c\u9000\u706b\u65b9\u6cd5\u3002\nY\u00e1nji\u016b tu\u00e1ndu\u00ec t\u014dnggu\u00f2 s\u0101n zh\u01d2ng j\u00ecsh\u00f9 g\u00f2ngxi\u00e0n t\u00edg\u0101o le x\u00f9nli\u00e0n xi\u00e0ol\u01dc: sh\u00f9j\u00f9 gu\u01cend\u00e0o, y\u014duhu\u00e0 f\u0101ngf\u01ce h\u00e9 tu\u00echu\u01d2 f\u0101ngf\u01ce.\n\nYuLan-Mini\u57281.08T tokens\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u4e0e\u9700\u8981\u66f4\u591a\u6570\u636e\u7684\u884c\u4e1a\u9886\u5148\u6a21\u578b\u76f8\u5f53\u3002\nYuLan-Mini z\u00e0i 1.08T tokens sh\u00e0ng x\u00f9nli\u00e0n, x\u00ecngn\u00e9ng y\u01d4 x\u016by\u00e0o g\u00e8ng du\u014d sh\u00f9j\u00f9 de h\u00e1ngy\u00e8 l\u01d0ngxi\u0101n m\u00f3x\u00edng xi\u0101ngd\u0101ng.\n\n\u9879\u76ee\u7ec6\u8282\u53ef\u4ee5\u5728GitHub\u4e0a\u627e\u5230\u3002\nXi\u00e0ngm\u00f9 x\u00ecji\u00e9 k\u011by\u01d0 z\u00e0i GitHub sh\u00e0ng zh\u01ceo d\u00e0o."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 150, "total_tokens": 565, "completion_tokens": 415}}
[28.12.2024 12:39] Response: è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªåä¸ºYuLan-Miniçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚
ZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le yÄ«gÃ¨ mÃ­ngwÃ¨i YuLan-Mini de dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng.

è¯¥æ¨¡å‹æœ‰2.42Bå‚æ•°ï¼Œæ€§èƒ½å“è¶Šã€‚
GÇi mÃ³xÃ­ng yÇ’u 2.42B cÄnshÃ¹, xÃ¬ngnÃ©ng zhuÃ³yuÃ¨.

ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸‰ç§æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚
YÃ¡njiÅ« tuÃ¡nduÃ¬ tÅngguÃ² sÄn zhÇ’ng jÃ¬shÃ¹ gÃ²ngxiÃ n tÃ­gÄo le xÃ¹nliÃ n xiÃ olÇœ: shÃ¹jÃ¹ guÇndÃ o, yÅuhuÃ  fÄngfÇ hÃ© tuÃ¬huÇ’ fÄngfÇ.

YuLan-Miniåœ¨1.08T tokensä¸Šè®­ç»ƒï¼Œæ€§èƒ½ä¸éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ç›¸å½“ã€‚
YuLan-Mini zÃ i 1.08T tokens shÃ ng xÃ¹nliÃ n, xÃ¬ngnÃ©ng yÇ” xÅ«yÃ o gÃ¨ng duÅ shÃ¹jÃ¹ de hÃ¡ngyÃ¨ lÇngxiÄn mÃ³xÃ­ng xiÄngdÄng.

é¡¹ç›®ç»†èŠ‚å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
XiÃ ngmÃ¹ xÃ¬jiÃ© kÄ›yÇ zÃ i GitHub shÃ ng zhÇo dÃ o.
[28.12.2024 12:39] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªåä¸ºYuLan-Miniçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰2.42Bå‚æ•°ï¼Œæ€§èƒ½å“è¶Šã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸‰ç§æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08T tokensä¸Šè®­ç»ƒï¼Œæ€§èƒ½ä¸éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ç›¸å½“ã€‚é¡¹ç›®ç»†èŠ‚å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[28.12.2024 12:39] Mistral response. {"id": "dcf885dc20f640418e5b14890d48f1d3", "object": "chat.completion", "created": 1735389549, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "[\n    {\"word\": \"\u8bed\u8a00\u6a21\u578b\", \"pinyin\": \"y\u01d4y\u00e1n m\u00f3x\u00edng\", \"trans\": \"language model\"},\n    {\"word\": \"\u53c2\u6570\", \"pinyin\": \"c\u0101nsh\u00f9\", \"trans\": \"parameters\"},\n    {\"word\": \"\u6027\u80fd\", \"pinyin\": \"x\u00ecngn\u00e9ng\", \"trans\": \"performance\"},\n    {\"word\": \"\u5353\u8d8a\", \"pinyin\": \"zhu\u00f3yu\u00e8\", \"trans\": \"outstanding\"},\n    {\"word\": \"\u7814\u7a76\u56e2\u961f\", \"pinyin\": \"y\u00e1nji\u016b tu\u00e1ndu\u00ec\", \"trans\": \"research team\"},\n    {\"word\": \"\u6280\u672f\u8d21\u732e\", \"pinyin\": \"j\u00ecsh\u00f9 g\u00f2ngxi\u00e0n\", \"trans\": \"technical contributions\"},\n    {\"word\": \"\u63d0\u9ad8\", \"pinyin\": \"t\u00edg\u0101o\", \"trans\": \"improve\"},\n    {\"word\": \"\u6548\u7387\", \"pinyin\": \"xi\u00e0ol\u01dc\", \"trans\": \"efficiency\"},\n    {\"word\": \"\u6570\u636e\u7ba1\u9053\", \"pinyin\": \"sh\u00f9j\u00f9 gu\u01cend\u00e0o\", \"trans\": \"data pipeline\"},\n    {\"word\": \"\u4f18\u5316\u65b9\u6cd5\", \"pinyin\": \"y\u014duhu\u00e0 f\u0101ngf\u01ce\", \"trans\": \"optimization methods\"},\n    {\"word\": \"\u9000\u706b\u65b9\u6cd5\", \"pinyin\": \"tu\u00echu\u01d2 f\u0101ngf\u01ce\", \"trans\": \"annealing methods\"},\n    {\"word\": \"tokens\", \"pinyin\": \"tokens\", \"trans\": \"tokens\"},\n    {\"word\": \"\u884c\u4e1a\u9886\u5148\", \"pinyin\": \"h\u00e1ngy\u00e8 l\u01d0ngxi\u0101n\", \"trans\": \"industry-leading\"},\n    {\"word\": \"\u9879\u76ee\u7ec6\u8282\", \"pinyin\": \"xi\u00e0ngm\u00f9 x\u00ecji\u00e9\", \"trans\": \"project details\"},\n    {\"word\": \"GitHub\", \"pinyin\": \"GitHub\", \"trans\": \"GitHub\"}\n]"}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 182, "total_tokens": 662, "completion_tokens": 480}}
[28.12.2024 12:39] Response: [
    {"word": "è¯­è¨€æ¨¡å‹", "pinyin": "yÇ”yÃ¡n mÃ³xÃ­ng", "trans": "language model"},
    {"word": "å‚æ•°", "pinyin": "cÄnshÃ¹", "trans": "parameters"},
    {"word": "æ€§èƒ½", "pinyin": "xÃ¬ngnÃ©ng", "trans": "performance"},
    {"word": "å“è¶Š", "pinyin": "zhuÃ³yuÃ¨", "trans": "outstanding"},
    {"word": "ç ”ç©¶å›¢é˜Ÿ", "pinyin": "yÃ¡njiÅ« tuÃ¡nduÃ¬", "trans": "research team"},
    {"word": "æŠ€æœ¯è´¡çŒ®", "pinyin": "jÃ¬shÃ¹ gÃ²ngxiÃ n", "trans": "technical contributions"},
    {"word": "æé«˜", "pinyin": "tÃ­gÄo", "trans": "improve"},
    {"word": "æ•ˆç‡", "pinyin": "xiÃ olÇœ", "trans": "efficiency"},
    {"word": "æ•°æ®ç®¡é“", "pinyin": "shÃ¹jÃ¹ guÇndÃ o", "trans": "data pipeline"},
    {"word": "ä¼˜åŒ–æ–¹æ³•", "pinyin": "yÅuhuÃ  fÄngfÇ", "trans": "optimization methods"},
    {"word": "é€€ç«æ–¹æ³•", "pinyin": "tuÃ¬huÇ’ fÄngfÇ", "trans": "annealing methods"},
    {"word": "tokens", "pinyin": "tokens", "trans": "tokens"},
    {"word": "è¡Œä¸šé¢†å…ˆ", "pinyin": "hÃ¡ngyÃ¨ lÇngxiÄn", "trans": "industry-leading"},
    {"word": "é¡¹ç›®ç»†èŠ‚", "pinyin": "xiÃ ngmÃ¹ xÃ¬jiÃ©", "trans": "project details"},
    {"word": "GitHub", "pinyin": "GitHub", "trans": "GitHub"}
]
[28.12.2024 12:39] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªåä¸ºYuLan-Miniçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰2.42Bå‚æ•°ï¼Œæ€§èƒ½å“è¶Šã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸‰ç§æŠ€æœ¯è´¡çŒ®æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼šæ•°æ®ç®¡é“ã€ä¼˜åŒ–æ–¹æ³•å’Œé€€ç«æ–¹æ³•ã€‚YuLan-Miniåœ¨1.08T tokensä¸Šè®­ç»ƒï¼Œæ€§èƒ½ä¸éœ€è¦æ›´å¤šæ•°æ®çš„è¡Œä¸šé¢†å…ˆæ¨¡å‹ç›¸å½“ã€‚é¡¹ç›®ç»†èŠ‚å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚
[28.12.2024 12:39] Mistral response. {"id": "27e95af155334c568ceb09545ed919bb", "object": "chat.completion", "created": 1735389559, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "tool_calls": null, "content": "This article introduces a large language model named YuLan-Mini. The model has 2.42B parameters and delivers outstanding performance. The research team enhanced training efficiency through three technical contributions: data pipelines, optimization methods, and annealing techniques. YuLan-Mini was trained on 1.08T tokens and performs comparably to industry-leading models that require more data. Project details can be found on GitHub."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 148, "total_tokens": 243, "completion_tokens": 95}}
[28.12.2024 12:39] Response: This article introduces a large language model named YuLan-Mini. The model has 2.42B parameters and delivers outstanding performance. The research team enhanced training efficiency through three technical contributions: data pipelines, optimization methods, and annealing techniques. YuLan-Mini was trained on 1.08T tokens and performs comparably to industry-leading models that require more data. Project details can be found on GitHub.
[28.12.2024 12:39] Renaming data file.
[28.12.2024 12:39] Renaming previous data. hf_papers.json to ./d/2024-12-27.json
[28.12.2024 12:39] Saving new data file.
[28.12.2024 12:39] Generating page.
[28.12.2024 12:39] Renaming previous page.
[28.12.2024 12:39] Renaming previous data. index.html to ./d/2024-12-27.html
[28.12.2024 12:39] [Experimental] Generating Chinese page for reading.
[28.12.2024 12:39] Chinese vocab [{'word': 'è¯­è¨€æ¨¡å‹', 'pinyin': 'yÇ”yÃ¡n mÃ³xÃ­ng', 'trans': 'language model'}, {'word': 'å‚æ•°', 'pinyin': 'cÄnshÃ¹', 'trans': 'parameters'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ngnÃ©ng', 'trans': 'performance'}, {'word': 'å“è¶Š', 'pinyin': 'zhuÃ³yuÃ¨', 'trans': 'outstanding'}, {'word': 'ç ”ç©¶å›¢é˜Ÿ', 'pinyin': 'yÃ¡njiÅ« tuÃ¡nduÃ¬', 'trans': 'research team'}, {'word': 'æŠ€æœ¯è´¡çŒ®', 'pinyin': 'jÃ¬shÃ¹ gÃ²ngxiÃ n', 'trans': 'technical contributions'}, {'word': 'æé«˜', 'pinyin': 'tÃ­gÄo', 'trans': 'improve'}, {'word': 'æ•ˆç‡', 'pinyin': 'xiÃ olÇœ', 'trans': 'efficiency'}, {'word': 'æ•°æ®ç®¡é“', 'pinyin': 'shÃ¹jÃ¹ guÇndÃ o', 'trans': 'data pipeline'}, {'word': 'ä¼˜åŒ–æ–¹æ³•', 'pinyin': 'yÅuhuÃ  fÄngfÇ', 'trans': 'optimization methods'}, {'word': 'é€€ç«æ–¹æ³•', 'pinyin': 'tuÃ¬huÇ’ fÄngfÇ', 'trans': 'annealing methods'}, {'word': 'tokens', 'pinyin': 'tokens', 'trans': 'tokens'}, {'word': 'è¡Œä¸šé¢†å…ˆ', 'pinyin': 'hÃ¡ngyÃ¨ lÇngxiÄn', 'trans': 'industry-leading'}, {'word': 'é¡¹ç›®ç»†èŠ‚', 'pinyin': 'xiÃ ngmÃ¹ xÃ¬jiÃ©', 'trans': 'project details'}, {'word': 'GitHub', 'pinyin': 'GitHub', 'trans': 'GitHub'}]
[28.12.2024 12:39] Renaming previous Chinese page.
[28.12.2024 12:39] Renaming previous data. zh.html to ./d/2024-12-27_zh_reading_task.html
[28.12.2024 12:39] Writing Chinese reading task.
[28.12.2024 12:39] Writing result.
[28.12.2024 12:39] Renaming log file.
[28.12.2024 12:39] Renaming previous data. log.txt to ./logs/2024-12-28_last_log.txt
