[11.08.2025 16:15] Read previous papers.
[11.08.2025 16:15] Generating top page (month).
[11.08.2025 16:15] Writing top page (month).
[11.08.2025 17:14] Read previous papers.
[11.08.2025 17:14] Get feed.
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06471
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04825
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05731
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06433
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05988
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.02831
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05547
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.05502
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.01242
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2507.22025
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.06494
[11.08.2025 17:14] Get page data from previous paper. URL: https://huggingface.co/papers/2508.04482
[11.08.2025 17:14] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.08.2025 17:14] No deleted papers detected.
[11.08.2025 17:14] Downloading and parsing papers (pdf, html). Total: 12.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.06471.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.06471.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.06471.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.04825.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.04825.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.04825.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.05731.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.05731.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.05731.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.06433.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.06433.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.06433.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.05988.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.05988.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.05988.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.02831.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.02831.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.02831.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.05547.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.05547.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.05547.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.05502.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.05502.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.05502.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.01242.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.01242.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.01242.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2507.22025.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2507.22025.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2507.22025.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.06494.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.06494.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.06494.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Downloading and parsing paper https://huggingface.co/papers/2508.04482.
[11.08.2025 17:14] Extra JSON file exists (./assets/json/2508.04482.json), skip PDF parsing.
[11.08.2025 17:14] Paper image links file exists (./assets/img_data/2508.04482.json), skip HTML parsing.
[11.08.2025 17:14] Success.
[11.08.2025 17:14] Enriching papers with extra data.
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 0. GLM-4.5, a Mixture-of-Experts large language model with 355B parameters, achieves strong performance across agentic, reasoning, and coding tasks using multi-stage training and reinforcement learning.  					AI-generated summary 				 We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large la...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 1. Voost, a unified diffusion transformer framework, jointly learns virtual try-on and try-off, enhancing garment-body correspondence and achieving state-of-the-art results across benchmarks.  					AI-generated summary 				 Virtual try-on aims to synthesize a realistic image of a person wearing a targe...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 2. Adaptive Exploration Policy Optimization (AEPO) enhances semantic alignment in Multimodal Large Language Models (MLLMs) for GUI interaction, improving performance on benchmarks by up to 9.0% compared to RLVR.  					AI-generated summary 				 The emergence of Multimodal Large Language Models (MLLMs) h...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 3. Agents equipped with a learnable, updatable procedural memory system, Memp, achieve improved performance and efficiency across tasks by distilling past experiences into detailed instructions and higher-level abstractions.  					AI-generated summary 				 Large Language Models (LLMs) based agents exce...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 4. ASAP, a novel coarse-to-fine framework, compresses Chain-of-Thought in code reasoning by preserving core structure and essential steps, reducing costs and improving efficiency.  					AI-generated summary 				 Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code r...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 5. GENIE combines NeRF's photorealistic rendering with Gaussian Splatting's editable and structured representation, enabling real-time, locality-aware editing and integration with physics-based simulation.  					AI-generated summary 				 Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) have re...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 6. A comprehensive survey of unsupervised adaptation methods for Vision-Language Models (VLMs) categorizes approaches based on the availability of unlabeled visual data and discusses methodologies, benchmarks, and future research directions.  					AI-generated summary 				 Vision-Language Models (VLMs)...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 7. MELLA, a multimodal, multilingual dataset, enhances MLLMs in low-resource languages by improving linguistic capability and cultural groundedness through native web alt-text and MLLM-generated captions.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have shown remarkable per...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 8. MeshLLM uses large language models to generate and understand text-serialized 3D meshes by decomposing them into meaningful subunits and training with local mesh assembly strategies.  					AI-generated summary 				 We present MeshLLM, a novel framework that leverages large language models (LLMs) to ...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 9. UI-AGILE enhances GUI agents through improved training with a Continuous Reward function, Simple Thinking reward, and Cropping-based Resampling, and inference with Decomposed Grounding with Selection, achieving state-of-the-art performance on GUI benchmarks.  					AI-generated summary 				 The emerg...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 10. Lightswitch, a material-relighting diffusion framework, enhances 3D relighting by integrating multi-view and material cues, achieving superior quality and efficiency compared to existing methods.  					AI-generated summary 				 Recent approaches for 3D relighting have shown promise in integrating 2D...
[11.08.2025 17:14] ********************************************************************************
[11.08.2025 17:14] Abstract 11. The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution of (multi-modal) large language models ((M)LLMs), this dream is closer to reality, as (M)LLM-based Agents using computing devices (e.g., computer...
[11.08.2025 17:14] Read previous papers.
[11.08.2025 17:14] Generating reviews via LLM API.
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#agents", "#rl", "#open_source", "#reasoning", "#architecture", "#agi", "#training"], "emoji": "üß†", "ru": {"title": "GLM-4.5: –ú–æ—â–Ω–∞—è MoE-–º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ò–ò", "desc": "GLM-4.5 - —ç—Ç–æ –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π Mixture-of-Experts, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è 355 
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#diffusion", "#cv", "#optimization", "#inference", "#architecture", "#benchmark", "#multimodal"], "emoji": "üëö", "ru": {"title": "Voost: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–µ –æ–¥–µ–∂–¥—ã", "desc": "Voost - —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ –æ–±—É—á
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#optimization", "#alignment", "#training", "#rl", "#benchmark", "#agents", "#multimodal"], "emoji": "üîç", "ru": {"title": "AEPO: –ü—Ä–æ—Ä—ã–≤ –≤ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–∏ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#optimization", "#agi", "#agents"], "emoji": "üß†", "ru": {"title": "Memp: —É–º–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤", "desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ Memp - –æ–±—É—á–∞–µ–º–∞—è –∏ –æ–±–Ω–æ–≤–ª—è–µ–º–∞—è –ø—Ä–æ—Ü–µ–¥—É—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). Memp –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ 
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#optimization", "#reasoning", "#training", "#architecture", "#data", "#benchmark"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º", "desc": "ASAP - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–∂–∞—Ç–∏—è —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (Chain-of-Thought) –≤ –∑–∞–¥–∞—á–∞—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "üé®", "ru": {"title": "GENIE: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ NeRF –∏ Gaussian Splatting –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è 3D-—Å—Ü–µ–Ω", "desc": "GENIE - —ç—Ç–æ –≥–∏–±—Ä–∏–¥–Ω–∞—è –º–æ–¥–µ–ª—å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ NeRF —Å —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º—ã–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º Gaussian Splat
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#survey", "#transfer_learning", "#multimodal"], "emoji": "üîç", "ru": {"title": "–°–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏", "desc": "–≠—Ç–æ –æ–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–∑—Ä–µ–Ω–∏–µ + —è–∑—ã–∫) –±–µ–∑ —É—á–∏—Ç–µ–ª—è. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#low_resource", "#dataset", "#multilingual", "#training", "#data", "#multimodal"], "emoji": "üåç", "ru": {"title": "MELLA: –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ MLLM –¥–ª—è –Ω–∏–∑–∫–æ—Ä–µ—Å—É—Ä—Å–Ω—ã—Ö —è–∑—ã–∫–æ–≤", "desc": "–î–∞—Ç–∞—Å–µ—Ç MELLA –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω—ã–π –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –Ω–∞ —É–ª—É—á—à–µ–Ω
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#games", "#dataset", "#optimization", "#3d", "#multimodal"], "emoji": "üßä", "ru": {"title": "MeshLLM: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ 3D-–º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "MeshLLM - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–º–æ–¥–µ–ª–µ–π –≤ —Ç–µ–∫—Å—Ç–æ
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#games", "#cv", "#optimization", "#benchmark", "#training", "#reasoning", "#agents"], "emoji": "üñ•Ô∏è", "ru": {"title": "UI-AGILE: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –∏ –≤—ã–≤–æ–¥–µ –∞–≥–µ–Ω—Ç–æ–≤ GUI", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ UI-AGILE, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É –∞–≥–µ–Ω—Ç–æ–≤ GUI —Å –ø–æ–º–æ—â—å—é —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#cv", "#3d", "#diffusion"], "emoji": "üí°", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ 3D-—Ä–µ–ª–∞–π—Ç–∏–Ω–≥–µ: Lightswitch –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ", "desc": "Lightswitch - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è 3D-—Ä–µ–ª–∞–π—Ç–∏–Ω–≥–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ —É—á–∏—Ç—ã–≤–∞—é—â–∞—è —Å–≤–æ–π—Å—Ç–≤–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –û–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø–µ—Ä–µ—Ä–∏
[11.08.2025 17:14] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#survey", "#agents", "#open_source"], "emoji": "ü§ñ", "ru": {"title": "–û–°-–∞–≥–µ–Ω—Ç—ã: –®–∞–≥ –∫ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–æ–º–æ—â–Ω–∏–∫–æ–≤ —É—Ä–æ–≤–Ω—è –î.–ñ.–ê.–†.–í.–ò.–°.", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±–∑–æ—Ä –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π
[11.08.2025 17:14] Renaming data file.
[11.08.2025 17:14] Renaming previous data. hf_papers.json to ./d/2025-08-11.json
[11.08.2025 17:14] Saving new data file.
[11.08.2025 17:14] Generating page.
[11.08.2025 17:14] Renaming previous page.
[11.08.2025 17:14] Renaming previous data. index.html to ./d/2025-08-11.html
[11.08.2025 17:14] Writing result.
[11.08.2025 17:14] Renaming log file.
[11.08.2025 17:14] Renaming previous data. log.txt to ./logs/2025-08-11_last_log.txt
