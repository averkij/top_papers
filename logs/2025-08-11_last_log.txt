[11.08.2025 01:01] Read previous papers.
[11.08.2025 01:01] Generating top page (month).
[11.08.2025 01:01] Writing top page (month).
[11.08.2025 03:27] Read previous papers.
[11.08.2025 03:27] Get feed.
[11.08.2025 03:27] Extract page data from URL. URL: https://huggingface.co/papers/2508.05731
[11.08.2025 03:27] Extract page data from URL. URL: https://huggingface.co/papers/2508.05988
[11.08.2025 03:27] Extract page data from URL. URL: https://huggingface.co/papers/2508.04825
[11.08.2025 03:27] Extract page data from URL. URL: https://huggingface.co/papers/2508.05502
[11.08.2025 03:27] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[11.08.2025 03:27] Downloading and parsing papers (pdf, html). Total: 4.
[11.08.2025 03:27] Downloading and parsing paper https://huggingface.co/papers/2508.05731.
[11.08.2025 03:27] Downloading paper 2508.05731 from http://arxiv.org/pdf/2508.05731v1...
[11.08.2025 03:28] Extracting affiliations from text.
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization Yuhang Liu1,3*, Zeyu Liu2*, Shuanghe Zhu1, Pengxiang Li2, Congkai Xie3, Jiasheng Wang4,3, Xavier Hu1, Xiaotian Han, Jianbo Yuan5, Xinyao Wang5, Shengyu Zhang1, Hongxia Yang2,3, Fei Wu1 1Zhejiang University 2The Hong Kong Polytechnic University 3InfiX.ai 4The University of Chicago 5Amazon {liuyuhang, sy zhang}@zju.edu.cn, hongxia.yang@polyu.edu.hk 5 2 0 2 7 ] . [ 1 1 3 7 5 0 . 8 0 5 2 : r a "
[11.08.2025 03:28] Response: ```python
[
    "Zhejiang University",
    "The Hong Kong Polytechnic University",
    "InfiX.ai",
    "The University of Chicago",
    "Amazon"
]
```
[11.08.2025 03:28] Deleting PDF ./assets/pdf/2508.05731.pdf.
[11.08.2025 03:28] Success.
[11.08.2025 03:28] Downloading and parsing paper https://huggingface.co/papers/2508.05988.
[11.08.2025 03:28] Downloading paper 2508.05988 from http://arxiv.org/pdf/2508.05988v1...
[11.08.2025 03:28] Extracting affiliations from text.
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 8 ] . [ 1 8 8 9 5 0 . 8 0 5 2 : r Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal Wenhao Zeng1, Yaoning Wang2, Chao Hu1, Yuling Shi1, Chengcheng Wan3, Hongyu Zhang4, Xiaodong Gu1 * 1Shanghai Jiao Tong University, 2Fudan University, 3East China Normal University, 4Chongqing University zengwh cs@sjtu.edu.cn, xiaodong.gu@sjtu.edu.cn Abstract Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code reasoning by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces introduce substantial challenges in terms of training cost, inference latency, and deployment feasibility. While various CoT compression approaches have emerged to address this challenge, they face inherent tradeoffs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps. In this paper, we propose ASAP (Anchor-guided, SurprisAlbased Pruning), novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. It then enables logic-aware pruning by selecting logically essential reasoning steps based on novel first-token surprisal metric. Finally, ASAP teaches models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning in coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy across multiple code generation benchmarks while substantially reducing training and inference costs. On the challenging LiveCodeBench v4 v5 benchmark, our approach reduces token generation by 23.5% and inference latency by 43.5% compared to the strongest baseline, while achieving competitive accuracy of 36.19% in Pass@1. Our results highlight promising direction for building powerful and efficient LRMs.1 Fi"
[11.08.2025 03:28] Response: ```python
[
    "Shanghai Jiao Tong University",
    "Fudan University",
    "East China Normal University",
    "Chongqing University"
]
```
[11.08.2025 03:28] Deleting PDF ./assets/pdf/2508.05988.pdf.
[11.08.2025 03:28] Success.
[11.08.2025 03:28] Downloading and parsing paper https://huggingface.co/papers/2508.04825.
[11.08.2025 03:28] Downloading paper 2508.04825 from http://arxiv.org/pdf/2508.04825v1...
[11.08.2025 03:28] Extracting affiliations from text.
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Voost: Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off Seungyong Lee* Jeong-gi Kwak* https://nxnai.github.io/Voost 5 2 0 2 6 ] . [ 1 5 2 8 4 0 . 8 0 5 2 : r Figure 1. Teaser We present single diffusion transformer that jointly addresses virtual try-on and try-off, producing high-quality results that remain robust across diverse poses, garment types, backgrounds, lighting conditions, and image compositions. "
[11.08.2025 03:28] Response: []
[11.08.2025 03:28] Extracting affiliations from text.
[11.08.2025 03:28] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"Voost: Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off Seungyong Lee* Jeong-gi Kwak*https://nxnai.github.io/Voost 5 2 0 2 6 ] . [ 1 5 2 8 4 0 . 8 0 5 2 : r Figure 1. Teaser We present single diffusion transformer that jointly addresses virtual try-on and try-off, producing high-quality results that remain robust across diverse poses, garment types, backgrounds, lighting conditions, and image compositions.Virtual try-on aims to synthesize realistic image of person wearing target garment, but accurately modeling garmentbody correspondence remains persistent challenge, especially under pose and appearance variation. In this paper, we propose Voosta unified and scalable framework that jointly learns virtual try-on and try-off with single diffusion transformer. By modeling both tasks jointly, Voost enables each garment-person pair to supervise both directions and supports flexible conditioning over gen- *Equal contribution Corresponding author 1 eration direction and garment categoryenhancing garmentbody relational reasoning without task-specific networks, auxiliary losses, or additional labels. In addition, we introduce two inference-time techniques: attention temperature scaling for robustness to resolution or mask variation, and self-corrective sampling that leverages bidirectional consistency between tasks. Extensive experiments demonstrate that Voost achieves state-of-the-art results on both try-on and try-off benchmarks, consistently outperforming strong baselines in alignment accuracy, visual fidelity, and generalization. 1. Introduction Virtual try-on (VTON) is an emerging generative task that enables realistic garment transfer onto person image, offering new paradigm for fashion in e-commerce and AR/VR. Despite its promise, VTON remains challenging due to the need for precise alignment, detail preservation, and robustness to occlusion and pose variation. Early approaches [13, 21, 27, 85] have adopted warpingbased strategies, often combined with generative modeling, but have struggled to maintain garment fidelity and structural consistency. Effectively adapting T2I diffusion models [18, 66] to virtual try-on requires strong image-based conditioning and accurate modeling of garmentperson correspondence. To this end, various efforts have been made to improve spatial alignment and relational understanding. These include incorporating auxiliary objectives [41, 91], leveraging reference networks [14, 84, 92], or injecting conditioning signals through spatial concatenation [15]. Despite these efforts, existing methods often fail to establish precise garment person correspondence. As illustrated in Fig. 2, the dispersed attention patterns reflect limited relational understanding, often resulting in lower visual quality and failure to faithfully reconstruct garment details. To address these challenges, we introduce Voost, unified framework that jointly learns virtual try-on and its inverse task, virtual try-off, which aims to reconstruct the original appearance of the worn garment from person image, within single diffusion transformer. Voost adopts token-level concatenation structure, where spatially aligned garment and person images are fed into shared embedding space. This design enables the model to reason bidirectionally across try-on and try-off scenarios using common conditioning layout. By jointly training both directions, Voost strengthens garmentperson correspondence while requiring no task-specific networks, auxiliary losses, or additional annotations, as each garment-person pair naturally provides supervision for the reverse process. Our framework leverages token-level concatenation and the architectural flexibility of diffusion transformers to handle diverse poses, aspect ratios, and spatial layouts. task token encodes both generation direction and garment category, enabling scalable learning without task-specific models or fixed resolutions. This unified setup not only supports multitask learning but also mitigates architectural, task-specific, and category-specific inductive biases by exposing the model to broader structural variation. In addition, we propose two simple inference-time techniques to improve robustness. Attention temperature scaling mitigates resolution or mask size mismatch between training and test time. We also introduce self-corrective sampling, where try-on and try-off predictions iteratively refine each other within the unified model. Remarkably, our unified diffusion transformer achieves state-of-the-art performance on both VTON and VTOFF benchmarks, surpassing strong task-specific baselines [14, 15, 41, 78, 82, 91] optimized individually for each task. We provide extensive qualitative and quantitative analyses that validate the effectiveness of our unified approach and its ability to model garmentperson interaction across diverse scenarios. 2. Related work Image-conditioned diffusion models. Diffusion models have rapidly evolved to support image-conditioned generation beyond the text-to-image setting [62, 66]. Early methods such as Textual Inversion [19] and DreamBooth [67] enabled concept-specific synthesis via embedding injection or fine-tuning, but incurred high computational costs. Later approaches improved efficiency by leveraging pre-trained encoders like CLIP [63] and DINO [9, 59], as seen in IPAdapter [86] and AnyDoor [12], which use image embeddings to guide generation. To improve spatial consistency, MasaCtrl [6] introduced mutual self-attention to preserve object identity. This was extended by reference-based methods [11, 14, 34, 76, 84] that inject structured visual features through dedicated networks. More recently, concatenationbased methods [15, 35, 75] have emerged as lightweight alternatives that directly feed conditioning signals without auxiliary modules. Additionally, image-conditioned diffusion has expanded beyond image-to-image generation to video [5, 26, 34, 71] and 3D synthesis [45, 49, 79], broadening its applicability. Virtual try-on using generative models. Early virtual try-on systems primarily relied on warping-based methods [20, 28, 80], where the main challenge was to deform and align the garment image to match the target persons pose and body shape. With the emergence of Generative Adversarial Networks (GANs) [22, 38, 39], series of GAN-based approaches [1, 13, 21, 27, 36, 53, 83, 85, 90] achieved more realistic image synthesis through adversarial learning. However, these mod"
[11.08.2025 03:28] Mistral response. {"id": "ed37645973ac4ec487f0fc805a4210ff", "created": 1754882898, "model": "mistral-large-latest", "usage": {"prompt_tokens": 1382, "total_tokens": 1388, "completion_tokens": 6}, "object": "chat.completion", "choices": [{"index": 0, "finish_reason": "stop", "message": {"role": "assistant", "tool_calls": null, "content": "```python\n[]\n```"}}]}
[11.08.2025 03:28] Response: ```python
[]
```
[11.08.2025 03:28] Deleting PDF ./assets/pdf/2508.04825.pdf.
[11.08.2025 03:28] Success.
[11.08.2025 03:28] Downloading and parsing paper https://huggingface.co/papers/2508.05502.
[11.08.2025 03:28] Downloading paper 2508.05502 from http://arxiv.org/pdf/2508.05502v1...
[11.08.2025 03:28] Extracting affiliations from text.
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 7 ] . [ 1 2 0 5 5 0 . 8 0 5 2 : r MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs Yufei Gao1,2 Jiaying Fei1 Nuo Chen3 Ruirui Chen4 Guohang Yan1 Yunshi Lan2 Botian Shi1 1Shanghai Artificial Intelligence Laboratory 2 East China Normal University 3 The Chinese University of Hong Kong, Shenzhen 4 Institute of High Performance Computing, A*STAR yfgao.agmail.com "
[11.08.2025 03:28] Response: ```python
[
    "Shanghai Artificial Intelligence Laboratory",
    "East China Normal University",
    "The Chinese University of Hong Kong, Shenzhen",
    "Institute of High Performance Computing, A*STAR"
]
```
[11.08.2025 03:28] Deleting PDF ./assets/pdf/2508.05502.pdf.
[11.08.2025 03:28] Success.
[11.08.2025 03:28] Enriching papers with extra data.
[11.08.2025 03:28] ********************************************************************************
[11.08.2025 03:28] Abstract 0. Adaptive Exploration Policy Optimization (AEPO) enhances semantic alignment in Multimodal Large Language Models (MLLMs) for GUI interaction, improving performance on benchmarks by up to 9.0% compared to RLVR.  					AI-generated summary 				 The emergence of Multimodal Large Language Models (MLLMs) h...
[11.08.2025 03:28] ********************************************************************************
[11.08.2025 03:28] Abstract 1. ASAP, a novel coarse-to-fine framework, compresses Chain-of-Thought in code reasoning by preserving core structure and essential steps, reducing costs and improving efficiency.  					AI-generated summary 				 Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code r...
[11.08.2025 03:28] ********************************************************************************
[11.08.2025 03:28] Abstract 2. Voost, a unified diffusion transformer framework, jointly learns virtual try-on and try-off, enhancing garment-body correspondence and achieving state-of-the-art results across benchmarks.  					AI-generated summary 				 Virtual try-on aims to synthesize a realistic image of a person wearing a targe...
[11.08.2025 03:28] ********************************************************************************
[11.08.2025 03:28] Abstract 3. MELLA, a multimodal, multilingual dataset, enhances MLLMs in low-resource languages by improving linguistic capability and cultural groundedness through native web alt-text and MLLM-generated captions.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have shown remarkable per...
[11.08.2025 03:28] Read previous papers.
[11.08.2025 03:28] Generating reviews via LLM API.
[11.08.2025 03:28] Querying the API.
[11.08.2025 03:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Adaptive Exploration Policy Optimization (AEPO) enhances semantic alignment in Multimodal Large Language Models (MLLMs) for GUI interaction, improving performance on benchmarks by up to 9.0% compared to RLVR.  					AI-generated summary 				 The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at https://github.com/InfiXAI/InfiGUI-G1.
[11.08.2025 03:28] Response: {
  "desc": "Статья представляет новый метод оптимизации политики адаптивного исследования (AEPO) для улучшения семантического выравнивания в мультимодальных больших языковых моделях (MLLM) при взаимодействии с графическим интерфейсом пользователя. AEPO использует стратегию генерации множественных ответов для обеспечения более широкого исследования, которое затем направляется теоретически обоснованной функцией вознаграждения адаптивного исследования (AER). Модели, обученные с помощью AEPO, достигают значительных улучшений до 9.0% по сравнению с базовым методом RLVR на тестах, оценивающих обобщение и семантическое понимание. Этот подход решает проблему неэффективного исследования, которая ограничивает семантическое выравнивание в существующих методах.",
  "emoji": "🔍",
  "title": "AEPO: Прорыв в семантическом выравнивании для мультимодальных ИИ-агентов"
}
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adaptive Exploration Policy Optimization (AEPO) enhances semantic alignment in Multimodal Large Language Models (MLLMs) for GUI interaction, improving performance on benchmarks by up to 9.0% compared to RLVR.  					AI-generated summary 				 The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at https://github.com/InfiXAI/InfiGUI-G1."

[11.08.2025 03:28] Response: ```python
['RL', 'AGENTS', 'MULTIMODAL', 'BENCHMARK', 'TRAINING']
```
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Adaptive Exploration Policy Optimization (AEPO) enhances semantic alignment in Multimodal Large Language Models (MLLMs) for GUI interaction, improving performance on benchmarks by up to 9.0% compared to RLVR.  					AI-generated summary 				 The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at https://github.com/InfiXAI/InfiGUI-G1."

[11.08.2025 03:28] Response: ```python
["ALIGNMENT", "OPTIMIZATION"]
```
[11.08.2025 03:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Adaptive Exploration Policy Optimization (AEPO) is a novel framework designed to enhance semantic alignment in Multimodal Large Language Models (MLLMs) for effective interaction with Graphical User Interfaces (GUIs). The paper identifies that while existing methods like Reinforcement Learning with Verifiable Rewards (RLVR) improve spatial alignment, they struggle with semantic alignment due to inefficient exploration strategies. AEPO addresses this by implementing a multi-answer generation approach that encourages broader exploration, guided by an Adaptive Exploration Reward (AER) function. As a result, models trained with AEPO demonstrate significant performance improvements, achieving state-of-the-art results on various GUI grounding benchmarks.","title":"Enhancing GUI Interaction with Adaptive Exploration in MLLMs"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Adaptive Exploration Policy Optimization (AEPO) is a novel framework designed to enhance semantic alignment in Multimodal Large Language Models (MLLMs) for effective interaction with Graphical User Interfaces (GUIs). The paper identifies that while existing methods like Reinforcement Learning with Verifiable Rewards (RLVR) improve spatial alignment, they struggle with semantic alignment due to inefficient exploration strategies. AEPO addresses this by implementing a multi-answer generation approach that encourages broader exploration, guided by an Adaptive Exploration Reward (AER) function. As a result, models trained with AEPO demonstrate significant performance improvements, achieving state-of-the-art results on various GUI grounding benchmarks.', title='Enhancing GUI Interaction with Adaptive Exploration in MLLMs'))
[11.08.2025 03:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"自适应探索策略优化（AEPO）通过增强多模态大型语言模型（MLLMs）在图形用户界面（GUI）交互中的语义对齐，显著提升了模型的性能。该方法解决了自然语言指令与UI元素之间的语义对齐问题，克服了传统强化学习方法在探索效率上的瓶颈。AEPO采用多答案生成策略，结合理论基础的自适应探索奖励函数，促进了更广泛的探索。经过AEPO训练的模型在多个GUI基准测试中取得了最高9.0%的相对提升，展示了其在语义理解和泛化能力上的优势。","title":"自适应探索，提升语义对齐！"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='自适应探索策略优化（AEPO）通过增强多模态大型语言模型（MLLMs）在图形用户界面（GUI）交互中的语义对齐，显著提升了模型的性能。该方法解决了自然语言指令与UI元素之间的语义对齐问题，克服了传统强化学习方法在探索效率上的瓶颈。AEPO采用多答案生成策略，结合理论基础的自适应探索奖励函数，促进了更广泛的探索。经过AEPO训练的模型在多个GUI基准测试中取得了最高9.0%的相对提升，展示了其在语义理解和泛化能力上的优势。', title='自适应探索，提升语义对齐！'))
[11.08.2025 03:28] Querying the API.
[11.08.2025 03:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

ASAP, a novel coarse-to-fine framework, compresses Chain-of-Thought in code reasoning by preserving core structure and essential steps, reducing costs and improving efficiency.  					AI-generated summary 				 Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code reasoning by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces introduce substantial challenges in terms of training cost, inference latency, and deployment feasibility. While various CoT compression approaches have emerged to address this challenge, they face inherent trade-offs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps. In this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. It then enables a logic-aware pruning by selecting logically essential reasoning steps based on a novel first-token surprisal metric. Finally, ASAP teaches models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning in coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy across multiple code generation benchmarks while substantially reducing training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark, our approach reduces token generation by 23.5% and inference latency by 43.5% compared to the strongest baseline, while achieving a competitive accuracy of 36.19% in Pass@1. Our results highlight a promising direction for building powerful and efficient LRMs.
[11.08.2025 03:28] Response: {
  "desc": "ASAP - это новый фреймворк для сжатия цепочек рассуждений (Chain-of-Thought) в задачах рассуждения о коде. Он использует двухэтапный подход: сначала сохраняет основную структуру рассуждений, а затем выбирает логически важные шаги на основе метрики неожиданности первого токена. ASAP позволяет моделям автономно генерировать и использовать сжатые цепочки рассуждений во время вывода. Эксперименты показывают, что ASAP достигает современного уровня точности при значительном снижении затрат на обучение и вывод.",
  "emoji": "🧠",
  "title": "Эффективное сжатие рассуждений для улучшения работы с кодом"
}
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ASAP, a novel coarse-to-fine framework, compresses Chain-of-Thought in code reasoning by preserving core structure and essential steps, reducing costs and improving efficiency.  					AI-generated summary 				 Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code reasoning by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces introduce substantial challenges in terms of training cost, inference latency, and deployment feasibility. While various CoT compression approaches have emerged to address this challenge, they face inherent trade-offs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps. In this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. It then enables a logic-aware pruning by selecting logically essential reasoning steps based on a novel first-token surprisal metric. Finally, ASAP teaches models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning in coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy across multiple code generation benchmarks while substantially reducing training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark, our approach reduces token generation by 23.5% and inference latency by 43.5% compared to the strongest baseline, while achieving a competitive accuracy of 36.19% in Pass@1. Our results highlight a promising direction for building powerful and efficient LRMs."

[11.08.2025 03:28] Response: ```python
['DATA', 'BENCHMARK', 'TRAINING', 'ARCHITECTURE']
```
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"ASAP, a novel coarse-to-fine framework, compresses Chain-of-Thought in code reasoning by preserving core structure and essential steps, reducing costs and improving efficiency.  					AI-generated summary 				 Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code reasoning by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces introduce substantial challenges in terms of training cost, inference latency, and deployment feasibility. While various CoT compression approaches have emerged to address this challenge, they face inherent trade-offs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps. In this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. It then enables a logic-aware pruning by selecting logically essential reasoning steps based on a novel first-token surprisal metric. Finally, ASAP teaches models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning in coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy across multiple code generation benchmarks while substantially reducing training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark, our approach reduces token generation by 23.5% and inference latency by 43.5% compared to the strongest baseline, while achieving a competitive accuracy of 36.19% in Pass@1. Our results highlight a promising direction for building powerful and efficient LRMs."

[11.08.2025 03:28] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[11.08.2025 03:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"The paper introduces ASAP, a new framework designed to compress Chain-of-Thought (CoT) in code reasoning while maintaining essential logical structures. It addresses the challenges posed by long reasoning traces, which can increase training costs and slow down inference. ASAP uses anchor-guided pruning to focus on core reasoning elements and applies a novel first-token surprisal metric to identify critical reasoning steps. The results demonstrate that ASAP not only improves efficiency by reducing token generation and inference latency but also maintains high accuracy in code generation tasks.","title":"Efficient Code Reasoning with ASAP: Smart Compression for Better Performance"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='The paper introduces ASAP, a new framework designed to compress Chain-of-Thought (CoT) in code reasoning while maintaining essential logical structures. It addresses the challenges posed by long reasoning traces, which can increase training costs and slow down inference. ASAP uses anchor-guided pruning to focus on core reasoning elements and applies a novel first-token surprisal metric to identify critical reasoning steps. The results demonstrate that ASAP not only improves efficiency by reducing token generation and inference latency but also maintains high accuracy in code generation tasks.', title='Efficient Code Reasoning with ASAP: Smart Compression for Better Performance'))
[11.08.2025 03:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种名为ASAP的新的粗到细框架，用于压缩代码推理中的思维链（CoT），旨在保留核心结构和关键步骤，从而降低成本并提高效率。ASAP首先通过锚点引导修剪来保留核心推理结构，减少后续处理的搜索空间。接着，它基于新颖的首个令牌惊讶度指标，选择逻辑上重要的推理步骤进行逻辑感知修剪。实验结果表明，ASAP在多个代码生成基准上实现了最先进的准确性，同时显著降低了训练和推理成本。","title":"ASAP：高效的代码推理思维链压缩框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种名为ASAP的新的粗到细框架，用于压缩代码推理中的思维链（CoT），旨在保留核心结构和关键步骤，从而降低成本并提高效率。ASAP首先通过锚点引导修剪来保留核心推理结构，减少后续处理的搜索空间。接着，它基于新颖的首个令牌惊讶度指标，选择逻辑上重要的推理步骤进行逻辑感知修剪。实验结果表明，ASAP在多个代码生成基准上实现了最先进的准确性，同时显著降低了训练和推理成本。', title='ASAP：高效的代码推理思维链压缩框架'))
[11.08.2025 03:28] Querying the API.
[11.08.2025 03:28] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Voost, a unified diffusion transformer framework, jointly learns virtual try-on and try-off, enhancing garment-body correspondence and achieving state-of-the-art results across benchmarks.  					AI-generated summary 				 Virtual try-on aims to synthesize a realistic image of a person wearing a target garment, but accurately modeling garment-body correspondence remains a persistent challenge, especially under pose and appearance variation. In this paper, we propose Voost - a unified and scalable framework that jointly learns virtual try-on and try-off with a single diffusion transformer. By modeling both tasks jointly, Voost enables each garment-person pair to supervise both directions and supports flexible conditioning over generation direction and garment category, enhancing garment-body relational reasoning without task-specific networks, auxiliary losses, or additional labels. In addition, we introduce two inference-time techniques: attention temperature scaling for robustness to resolution or mask variation, and self-corrective sampling that leverages bidirectional consistency between tasks. Extensive experiments demonstrate that Voost achieves state-of-the-art results on both try-on and try-off benchmarks, consistently outperforming strong baselines in alignment accuracy, visual fidelity, and generalization.
[11.08.2025 03:28] Response: {
  "desc": "Voost - это унифицированная система на основе диффузионного трансформера, которая совместно обучается виртуальной примерке одежды и ее снятию. Она улучшает соответствие между одеждой и телом человека, используя двунаправленную согласованность между задачами. Voost поддерживает гибкое управление направлением генерации и категорией одежды без специфичных для задачи сетей. Система достигает лучших результатов на различных тестовых наборах данных, превосходя существующие методы по точности сопоставления и визуальному качеству.",
  "emoji": "👚",
  "title": "Voost: революция в виртуальной примерке одежды"
}
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Voost, a unified diffusion transformer framework, jointly learns virtual try-on and try-off, enhancing garment-body correspondence and achieving state-of-the-art results across benchmarks.  					AI-generated summary 				 Virtual try-on aims to synthesize a realistic image of a person wearing a target garment, but accurately modeling garment-body correspondence remains a persistent challenge, especially under pose and appearance variation. In this paper, we propose Voost - a unified and scalable framework that jointly learns virtual try-on and try-off with a single diffusion transformer. By modeling both tasks jointly, Voost enables each garment-person pair to supervise both directions and supports flexible conditioning over generation direction and garment category, enhancing garment-body relational reasoning without task-specific networks, auxiliary losses, or additional labels. In addition, we introduce two inference-time techniques: attention temperature scaling for robustness to resolution or mask variation, and self-corrective sampling that leverages bidirectional consistency between tasks. Extensive experiments demonstrate that Voost achieves state-of-the-art results on both try-on and try-off benchmarks, consistently outperforming strong baselines in alignment accuracy, visual fidelity, and generalization."

[11.08.2025 03:28] Response: ```python
['CV', 'BENCHMARK', 'INFERENCE', 'MULTIMODAL', 'ARCHITECTURE']
```
[11.08.2025 03:28] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Voost, a unified diffusion transformer framework, jointly learns virtual try-on and try-off, enhancing garment-body correspondence and achieving state-of-the-art results across benchmarks.  					AI-generated summary 				 Virtual try-on aims to synthesize a realistic image of a person wearing a target garment, but accurately modeling garment-body correspondence remains a persistent challenge, especially under pose and appearance variation. In this paper, we propose Voost - a unified and scalable framework that jointly learns virtual try-on and try-off with a single diffusion transformer. By modeling both tasks jointly, Voost enables each garment-person pair to supervise both directions and supports flexible conditioning over generation direction and garment category, enhancing garment-body relational reasoning without task-specific networks, auxiliary losses, or additional labels. In addition, we introduce two inference-time techniques: attention temperature scaling for robustness to resolution or mask variation, and self-corrective sampling that leverages bidirectional consistency between tasks. Extensive experiments demonstrate that Voost achieves state-of-the-art results on both try-on and try-off benchmarks, consistently outperforming strong baselines in alignment accuracy, visual fidelity, and generalization."

[11.08.2025 03:28] Response: ```python
["DIFFUSION", "OPTIMIZATION"]
```
[11.08.2025 03:28] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Voost is a new framework that uses a diffusion transformer to improve virtual try-on and try-off tasks in fashion technology. It learns to create realistic images of people wearing clothes by understanding how garments fit the body, even when poses and appearances change. By training both tasks together, Voost enhances the relationship between garments and bodies without needing extra networks or labels. The framework also includes innovative techniques to improve performance during image generation, leading to top results in accuracy and visual quality across various benchmarks.","title":"Voost: Revolutionizing Virtual Try-On with Unified Learning"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Voost is a new framework that uses a diffusion transformer to improve virtual try-on and try-off tasks in fashion technology. It learns to create realistic images of people wearing clothes by understanding how garments fit the body, even when poses and appearances change. By training both tasks together, Voost enhances the relationship between garments and bodies without needing extra networks or labels. The framework also includes innovative techniques to improve performance during image generation, leading to top results in accuracy and visual quality across various benchmarks.', title='Voost: Revolutionizing Virtual Try-On with Unified Learning'))
[11.08.2025 03:29] Response: ParsedChatCompletionMessage[Article](content='{"desc":"Voost是一个统一的扩散变换器框架，能够同时学习虚拟试穿和试脱。它通过联合建模这两个任务，增强了服装与身体之间的对应关系，解决了在姿势和外观变化下的挑战。该框架支持灵活的生成方向和服装类别，避免了特定任务的网络和额外标签。实验结果表明，Voost在试穿和试脱的基准测试中均取得了最先进的成果。","title":"Voost：虚拟试穿与试脱的统一框架"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='Voost是一个统一的扩散变换器框架，能够同时学习虚拟试穿和试脱。它通过联合建模这两个任务，增强了服装与身体之间的对应关系，解决了在姿势和外观变化下的挑战。该框架支持灵活的生成方向和服装类别，避免了特定任务的网络和额外标签。实验结果表明，Voost在试穿和试脱的基准测试中均取得了最先进的成果。', title='Voost：虚拟试穿与试脱的统一框架'))
[11.08.2025 03:29] Querying the API.
[11.08.2025 03:29] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

MELLA, a multimodal, multilingual dataset, enhances MLLMs in low-resource languages by improving linguistic capability and cultural groundedness through native web alt-text and MLLM-generated captions.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have shown remarkable performance in high-resource languages. However, their effectiveness diminishes significantly in the contexts of low-resource languages. Current multilingual enhancement methods are often limited to text modality or rely solely on machine translation. While such approaches help models acquire basic linguistic capabilities and produce "thin descriptions", they neglect the importance of multimodal informativeness and cultural groundedness, both of which are crucial for serving low-resource language users effectively. To bridge this gap, in this study, we identify two significant objectives for a truly effective MLLM in low-resource language settings, namely 1) linguistic capability and 2) cultural groundedness, placing special emphasis on cultural awareness. To achieve these dual objectives, we propose a dual-source strategy that guides the collection of data tailored to each goal, sourcing native web alt-text for culture and MLLM-generated captions for linguistics. As a concrete implementation, we introduce MELLA, a multimodal, multilingual dataset. Experiment results show that after fine-tuning on MELLA, there is a general performance improvement for the eight languages on various MLLM backbones, with models producing "thick descriptions". We verify that the performance gains are from both cultural knowledge enhancement and linguistic capability enhancement. Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.
[11.08.2025 03:29] Response: {
  "desc": "Датасет MELLA представляет собой многомодальный многоязычный набор данных, направленный на улучшение работы мультимодальных больших языковых моделей (MLLM) для низкоресурсных языков. MELLA использует двойной подход, сочетая альтернативный текст с веб-страниц и подписи, сгенерированные MLLM, для улучшения лингвистических возможностей и культурной осведомленности моделей. Эксперименты показали общее улучшение производительности для восьми языков на различных архитектурах MLLM после дообучения на MELLA. Результаты подтверждают, что улучшения связаны как с расширением культурных знаний, так и с повышением лингвистических способностей моделей.",
  "emoji": "🌍",
  "title": "MELLA: Расширение горизонтов MLLM для низкоресурсных языков"
}
[11.08.2025 03:29] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MELLA, a multimodal, multilingual dataset, enhances MLLMs in low-resource languages by improving linguistic capability and cultural groundedness through native web alt-text and MLLM-generated captions.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have shown remarkable performance in high-resource languages. However, their effectiveness diminishes significantly in the contexts of low-resource languages. Current multilingual enhancement methods are often limited to text modality or rely solely on machine translation. While such approaches help models acquire basic linguistic capabilities and produce "thin descriptions", they neglect the importance of multimodal informativeness and cultural groundedness, both of which are crucial for serving low-resource language users effectively. To bridge this gap, in this study, we identify two significant objectives for a truly effective MLLM in low-resource language settings, namely 1) linguistic capability and 2) cultural groundedness, placing special emphasis on cultural awareness. To achieve these dual objectives, we propose a dual-source strategy that guides the collection of data tailored to each goal, sourcing native web alt-text for culture and MLLM-generated captions for linguistics. As a concrete implementation, we introduce MELLA, a multimodal, multilingual dataset. Experiment results show that after fine-tuning on MELLA, there is a general performance improvement for the eight languages on various MLLM backbones, with models producing "thick descriptions". We verify that the performance gains are from both cultural knowledge enhancement and linguistic capability enhancement. Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus."

[11.08.2025 03:29] Response: ```python
['DATASET', 'DATA', 'MULTIMODAL', 'MULTILINGUAL', 'TRAINING']
```
[11.08.2025 03:29] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"MELLA, a multimodal, multilingual dataset, enhances MLLMs in low-resource languages by improving linguistic capability and cultural groundedness through native web alt-text and MLLM-generated captions.  					AI-generated summary 				 Multimodal Large Language Models (MLLMs) have shown remarkable performance in high-resource languages. However, their effectiveness diminishes significantly in the contexts of low-resource languages. Current multilingual enhancement methods are often limited to text modality or rely solely on machine translation. While such approaches help models acquire basic linguistic capabilities and produce "thin descriptions", they neglect the importance of multimodal informativeness and cultural groundedness, both of which are crucial for serving low-resource language users effectively. To bridge this gap, in this study, we identify two significant objectives for a truly effective MLLM in low-resource language settings, namely 1) linguistic capability and 2) cultural groundedness, placing special emphasis on cultural awareness. To achieve these dual objectives, we propose a dual-source strategy that guides the collection of data tailored to each goal, sourcing native web alt-text for culture and MLLM-generated captions for linguistics. As a concrete implementation, we introduce MELLA, a multimodal, multilingual dataset. Experiment results show that after fine-tuning on MELLA, there is a general performance improvement for the eight languages on various MLLM backbones, with models producing "thick descriptions". We verify that the performance gains are from both cultural knowledge enhancement and linguistic capability enhancement. Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus."

[11.08.2025 03:29] Response: ```python
["LOW_RESOURCE"]
```
[11.08.2025 03:29] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces MELLA, a new dataset designed to improve Multimodal Large Language Models (MLLMs) for low-resource languages. It focuses on enhancing both linguistic capabilities and cultural groundedness by using native web alt-text and MLLM-generated captions. The study highlights the limitations of existing methods that rely solely on text or machine translation, which often fail to provide rich, informative content. By fine-tuning MLLMs on MELLA, the results show significant performance improvements across multiple languages, enabling models to generate more detailed and culturally aware descriptions.","title":"Enhancing MLLMs for Low-Resource Languages with MELLA"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces MELLA, a new dataset designed to improve Multimodal Large Language Models (MLLMs) for low-resource languages. It focuses on enhancing both linguistic capabilities and cultural groundedness by using native web alt-text and MLLM-generated captions. The study highlights the limitations of existing methods that rely solely on text or machine translation, which often fail to provide rich, informative content. By fine-tuning MLLMs on MELLA, the results show significant performance improvements across multiple languages, enabling models to generate more detailed and culturally aware descriptions.', title='Enhancing MLLMs for Low-Resource Languages with MELLA'))
[11.08.2025 03:29] Response: ParsedChatCompletionMessage[Article](content='{"desc":"MELLA是一个多模态、多语言的数据集，旨在提升低资源语言中的多模态大型语言模型（MLLM）的语言能力和文化基础。该研究提出了一种双源策略，通过收集本地网页的替代文本和MLLM生成的标题，来实现语言能力和文化基础的双重目标。实验结果表明，在MELLA上进行微调后，八种语言的模型在多种MLLM基础上普遍提高了性能，能够生成更丰富的描述。我们的数据集强调了文化知识和语言能力的增强，适用于低资源语言用户。","title":"提升低资源语言的多模态语言模型"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='MELLA是一个多模态、多语言的数据集，旨在提升低资源语言中的多模态大型语言模型（MLLM）的语言能力和文化基础。该研究提出了一种双源策略，通过收集本地网页的替代文本和MLLM生成的标题，来实现语言能力和文化基础的双重目标。实验结果表明，在MELLA上进行微调后，八种语言的模型在多种MLLM基础上普遍提高了性能，能够生成更丰富的描述。我们的数据集强调了文化知识和语言能力的增强，适用于低资源语言用户。', title='提升低资源语言的多模态语言模型'))
[11.08.2025 03:29] Renaming data file.
[11.08.2025 03:29] Renaming previous data. hf_papers.json to ./d/2025-08-11.json
[11.08.2025 03:29] Saving new data file.
[11.08.2025 03:29] Generating page.
[11.08.2025 03:29] Renaming previous page.
[11.08.2025 03:29] Renaming previous data. index.html to ./d/2025-08-11.html
[11.08.2025 03:29] Writing result.
[11.08.2025 03:29] Renaming log file.
[11.08.2025 03:29] Renaming previous data. log.txt to ./logs/2025-08-11_last_log.txt
