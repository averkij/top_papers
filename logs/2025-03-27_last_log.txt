[27.03.2025 14:11] Read previous papers.
[27.03.2025 14:11] Generating top page (month).
[27.03.2025 14:11] Writing top page (month).
[27.03.2025 15:11] Read previous papers.
[27.03.2025 15:11] Get feed.
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19757
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20215
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19990
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20314
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20201
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20240
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19480
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20672
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20020
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20757
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19950
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19462
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20271
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19846
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20756
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20198
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.20220
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.19953
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17358
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.16870
[27.03.2025 15:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.15893
[27.03.2025 15:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.10997
[27.03.2025 15:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.20641
[27.03.2025 15:11] Extract page data from URL. URL: https://huggingface.co/papers/2503.18929
[27.03.2025 15:11] Get page data from previous paper. URL: https://huggingface.co/papers/2503.17970
[27.03.2025 15:11] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[27.03.2025 15:11] No deleted papers detected.
[27.03.2025 15:11] Downloading and parsing papers (pdf, html). Total: 25.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19757.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19757.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19757.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20215.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20215.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20215.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19990.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19990.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19990.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20314.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20314.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20314.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20201.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20201.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20201.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20240.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20240.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20240.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19480.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19480.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19480.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20672.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20672.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20672.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20020.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20020.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20020.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20757.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20757.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20757.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19950.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19950.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19950.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19462.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19462.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19462.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20271.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20271.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20271.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19846.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19846.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19846.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20756.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20756.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20756.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20198.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20198.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20198.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20220.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.20220.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.20220.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.19953.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.19953.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.19953.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.17358.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.17358.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.17358.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.16870.
[27.03.2025 15:11] Extra JSON file exists (./assets/json/2503.16870.json), skip PDF parsing.
[27.03.2025 15:11] Paper image links file exists (./assets/img_data/2503.16870.json), skip HTML parsing.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.15893.
[27.03.2025 15:11] Downloading paper 2503.15893 from http://arxiv.org/pdf/2503.15893v2...
[27.03.2025 15:11] Extracting affiliations from text.
[27.03.2025 15:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UniHDSA: Unified Relation Prediction Approach for Hierarchical Document Structure Analysis Jiawei Wanga,b,1,, Kai Hua,b,1, Qiang Huob aDepartment of EEIS, University of Science and Technology of China, Hefei, 230026, China bMicrosoft Research Asia, Beijing, 100080, China "
[27.03.2025 15:11] Response: ```python
["Department of EEIS, University of Science and Technology of China, Hefei, 230026, China", "Microsoft Research Asia, Beijing, 100080, China"]
```
[27.03.2025 15:11] Deleting PDF ./assets/pdf/2503.15893.pdf.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.10997.
[27.03.2025 15:11] Downloading paper 2503.10997 from http://arxiv.org/pdf/2503.10997v1...
[27.03.2025 15:11] Extracting affiliations from text.
[27.03.2025 15:11] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RONA: Pragmatically Diverse Image Captioning with Coherence Relations Aashish Anantha Ramakrishnan1, Aadarsh Anantha Ramakrishnan2, Dongwon Lee1 1The Pennsylvania State University; 2National Institute of Technology, Tiruchirappalli 1{aza6352, dul13}@psu.edu, 2106121001@nitt.edu 5 2 0 2 4 1 ] . [ 1 7 9 9 0 1 . 3 0 5 2 : r a "
[27.03.2025 15:11] Response: ```python
["The Pennsylvania State University", "National Institute of Technology, Tiruchirappalli"]
```
[27.03.2025 15:11] Deleting PDF ./assets/pdf/2503.10997.pdf.
[27.03.2025 15:11] Success.
[27.03.2025 15:11] Downloading and parsing paper https://huggingface.co/papers/2503.20641.
[27.03.2025 15:11] Downloading paper 2503.20641 from http://arxiv.org/pdf/2503.20641v1...
[27.03.2025 15:12] Extracting affiliations from text.
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 6 2 ] . [ 1 1 4 6 0 2 . 3 0 5 2 : r Efficient Long-to-Short LLM Reasoning with Model Merging UNLOCKING EFFICIENT LONG-TO-SHORT LLM REASONING WITH MODEL MERGING Han Wu, Yuxuan Yao, Shuqi Liu, Zehua Liu, Xiaojin Fu, Xiongwei Han, Xing Li Hui-Ling Zhen, Tao Zhong, Mingxuan Yuan {wu.han1,hanxiongwei,zhongtao5,Yuan.Mingxuan}@huawei.com Huawei Noahs Ark Lab Figure 1: Performance of various model merging methods on DeepSeek-R1-7B and Qwen2.5-Math7B models. (TL;DR) Summary of our findings: Model merging is highly efficient approach for long-to-short reasoning, as it directly operates on model parameters without requiring additional training. Task-vector based merging methods, especially like TA and Ties-Merging, can achieve long-to-short reasoning with around 50% length reduction alongside accuracy parity or even marginal gains on 7B models. SVD-based merging methods exhibit limited effectiveness, delivering moderate performance and serving as viable alternatives only when task vectors inherently possess lowrank spectral characteristics. Activation-based merging is the future, as it demonstrates impressive performance in terms of both reasoning accuracy (+1.9) and response length compression ratios (-49.8%). Model merging methods applied to 1.5B-scale models remain effective on simple tasks. Smaller models struggle to learn long CoT reasoning ability through model merging. The merging of large-scale models (14B and 32B) poses significant challenges in simultaneously maintaining reasoning performance while substantially reducing response length. Work in progress. * indicates equal contribution. 1 Efficient Long-to-Short LLM Reasoning with Model Merging "
[27.03.2025 15:12] Response: ```python
["Huawei Noahs Ark Lab"]
```
[27.03.2025 15:12] Deleting PDF ./assets/pdf/2503.20641.pdf.
[27.03.2025 15:12] Success.
[27.03.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2503.18929.
[27.03.2025 15:12] Downloading paper 2503.18929 from http://arxiv.org/pdf/2503.18929v1...
[27.03.2025 15:12] Extracting affiliations from text.
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"TRAJECTORY BALANCE WITH ASYNCHRONY: DECOUPLING EXPLORATION AND LEARNING FOR FAST, SCALABLE LLM POST-TRAINING Brian R. Bartoldson1, Siddarth Venkatraman2,3, James Diffenderfer1, Moksh Jain2,3, Tal Ben-Nun1, Seanie Lee4, Minsu Kim2,4, Johan Obando-Ceron2,3, Yoshua Bengio2,3,5 Bhavya Kailkhura1 1Lawrence Livermore National Laboratory, 2Mila Quebec AI Institute 3Universite de Montreal 4KAIST 5CIFAR Fellow {bartoldson,diffenderfer2,kailkhura1}@llnl.gov, {siddarth.venkatraman,moksh.jain}@mila.quebec "
[27.03.2025 15:12] Response: ```python
[
    "Lawrence Livermore National Laboratory",
    "Mila Quebec AI Institute",
    "Universite de Montreal",
    "KAIST",
    "CIFAR Fellow"
]
```
[27.03.2025 15:12] Deleting PDF ./assets/pdf/2503.18929.pdf.
[27.03.2025 15:12] Success.
[27.03.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2503.17970.
[27.03.2025 15:12] Extra JSON file exists (./assets/json/2503.17970.json), skip PDF parsing.
[27.03.2025 15:12] Paper image links file exists (./assets/img_data/2503.17970.json), skip HTML parsing.
[27.03.2025 15:12] Success.
[27.03.2025 15:12] Enriching papers with extra data.
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 0. While recent vision-language-action models trained on diverse robot datasets exhibit promising generalization capabilities with limited in-domain data, their reliance on compact action heads to predict discretized or continuous actions constrains adaptability to heterogeneous action spaces. We prese...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 1. In this report, we present Qwen2.5-Omni, an end-to-end multimodal model designed to perceive diverse modalities, including text, images, audio, and video, while simultaneously generating text and natural speech responses in a streaming manner. To enable the streaming of multimodal information inputs...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 2. Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multim...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 3. This report presents Wan, a comprehensive and open suite of video foundation models designed to push the boundaries of video generation. Built upon the mainstream diffusion transformer paradigm, Wan achieves significant advancements in generative capabilities through a series of innovations, includi...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 4. We introduce Open Deep Search (ODS) to close the increasing gap between the proprietary search AI solutions, such as Perplexity's Sonar Reasoning Pro and OpenAI's GPT-4o Search Preview, and their open-source counterparts. The main innovation introduced in ODS is to augment the reasoning capabilities...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 5. Classifier-Free Guidance (CFG) is a fundamental technique in training conditional diffusion models. The common practice for CFG-based training is to use a single network to learn both conditional and unconditional noise prediction, with a small dropout rate for conditioning. However, we observe that...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 6. The synergy between generative and discriminative models receives growing attention. While discriminative Contrastive Language-Image Pre-Training (CLIP) excels in high-level semantics, it struggles with perceiving fine-grained visual details. Generally, to enhance representations, generative models ...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 7. Recently, state-of-the-art text-to-image generation models, such as Flux and Ideogram 2.0, have made significant progress in sentence-level visual text rendering. In this paper, we focus on the more challenging scenarios of article-level visual text rendering and address a novel task of generating h...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 8. Recent advancements in large multimodal models have led to the emergence of remarkable generalist capabilities in digital domains, yet their translation to physical agents such as robots remains a significant challenge. This report introduces a new family of AI models purposefully designed for robot...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 9. We introduce MCTS-RAG, a novel approach that enhances the reasoning capabilities of small language models on knowledge-intensive tasks by leveraging retrieval-augmented generation (RAG) to provide relevant context and Monte Carlo Tree Search (MCTS) to refine reasoning paths. MCTS-RAG dynamically int...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 10. We introduce LogQuant, a groundbreaking 2-bit quantization technique for KV Cache in large language model (LLM) inference, delivering substantial memory savings while preserving superior performance. Previous methods either assume that later tokens are more important or attempt to predict important ...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 11. Diffusion models have achieved remarkable progress in the field of video generation. However, their iterative denoising nature requires a large number of inference steps to generate a video, which is slow and computationally expensive. In this paper, we begin with a detailed analysis of the challeng...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 12. Process-supervised reward models serve as a fine-grained function that provides detailed step-wise feedback to model responses, facilitating effective selection of reasoning trajectories for complex tasks. Despite its advantages, evaluation on PRMs remains less explored, especially in the multimodal...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 13. Computer vision models have been shown to exhibit and amplify biases across a wide array of datasets and tasks. Existing methods for quantifying bias in classification models primarily focus on dataset distribution and model performance on subgroups, overlooking the internal workings of a model. We ...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 14. Recent advancements in Large Multimodal Models (LMMs) have shown promise in Autonomous Driving Systems (ADS). However, their direct application to ADS is hindered by challenges such as misunderstanding of traffic knowledge, complex road conditions, and diverse states of vehicle. To address these cha...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 15. Recent advancements in autoregressive and diffusion models have led to strong performance in image generation with short scene text words. However, generating coherent, long-form text in images, such as paragraphs in slides or documents, remains a major challenge for current generative models. We pr...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 16. Category-level 3D/6D pose estimation is a crucial step towards comprehensive 3D scene understanding, which would enable a broad range of applications in robotics and embodied AI. Recent works explored neural mesh models that approach a range of 2D and 3D tasks from an analysis-by-synthesis perspecti...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 17. Estimating motion in videos is an essential computer vision problem with many downstream applications, including controllable video generation and robotics. Current solutions are primarily trained using synthetic data or require tuning of situation-specific heuristics, which inherently limits these ...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 18. In many robotics and VR/AR applications, fast camera motions cause a high level of motion blur, causing existing camera pose estimation methods to fail. In this work, we propose a novel framework that leverages motion blur as a rich cue for motion estimation rather than treating it as an unwanted ar...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 19. Knowledge distillation can be a cost-effective technique to distill knowledge in Large Language Models, if the teacher output logits can be pre-computed and cached. However, successfully applying this to pre-training remains largely unexplored. In this work, we prove that naive approaches for sparse...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 20. Document structure analysis, aka document layout analysis, is crucial for understanding both the physical layout and logical structure of documents, serving information retrieval, document summarization, knowledge extraction, etc. Hierarchical Document Structure Analysis (HDSA) specifically aims to ...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 21. Writing Assistants (e.g., Grammarly, Microsoft Copilot) traditionally generate diverse image captions by employing syntactic and semantic variations to describe image components. However, human-written captions prioritize conveying a central message alongside visual descriptions using pragmatic cues...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 22. The transition from System 1 to System 2 reasoning in large language models (LLMs) has marked significant advancements in handling complex tasks through deliberate, iterative thinking. However, this progress often comes at the cost of efficiency, as models tend to overthink, generating redundant rea...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 23. Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, existing on-policy algorithms used for post-training are inherently incompatible with the use of experience replay buffers, which can be populated scalably by distributed off-policy actors to en...
[27.03.2025 15:12] ********************************************************************************
[27.03.2025 15:12] Abstract 24. Breast cancer survival prediction in computational pathology presents a remarkable challenge due to tumor heterogeneity. For instance, different regions of the same tumor in the pathology image can show distinct morphological and molecular characteristics. This makes it difficult to extract represen...
[27.03.2025 15:12] Read previous papers.
[27.03.2025 15:12] Generating reviews via LLM API.
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#open_source", "#multimodal", "#architecture", "#diffusion", "#agents", "#training"], "emoji": "🤖", "ru": {"title": "Универсальное обучение роботов с помощью диффузионных трансформеров", "desc": "Статья представляет Dita - масштабируемую модель для обучения роботов, использую
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#architecture", "#agi", "#benchmark", "#multimodal", "#video", "#games", "#audio"], "emoji": "🤖", "ru": {"title": "Qwen2.5-Omni: Мультимодальный ИИ нового поколения", "desc": "Qwen2.5-Omni - это мультимодальная модель, способная воспринимать текст, изображения, аудио и видео, генери
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#robotics", "#benchmark", "#multimodal", "#reasoning"], "emoji": "🧩", "ru": {"title": "LEGO-Puzzles: выявление пробелов в пространственном мышлении ИИ", "desc": "Статья представляет LEGO-Puzzles - новый бенчмарк для оценки пространственного мышления и последовательного рассуждения у
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#video", "#open_source", "#multimodal", "#architecture", "#diffusion", "#benchmark", "#dataset"], "emoji": "🎬", "ru": {"title": "Wan: Открытый набор передовых видео-моделей для революции в генерации видео", "desc": "Статья представляет Wan - комплексный набор видео-моделей, основанн
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#multimodal", "#open_source", "#agents", "#benchmark", "#reasoning"], "emoji": "🔍", "ru": {"title": "ODS: открытый ИИ-поиск на уровне проприетарных решений", "desc": "Open Deep Search (ODS) - это новая система, объединяющая возможности открытых языковых моделей с инструментами веб-п
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#training", "#diffusion", "#video"], "emoji": "🔀", "ru": {"title": "Улучшение CFG: замена безусловного шума для качественной генерации", "desc": "Статья посвящена улучшению метода Classifier-Free Guidance (CFG) в обучении условных диффузионных моделей. Авторы обнаружили, что 
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#open_source", "#multimodal", "#architecture", "#optimization", "#benchmark", "#training"], "emoji": "🔬", "ru": {"title": "GenHancer: Улучшение визуальных репрезентаций через синергию генеративных и дискриминативных моделей", "desc": "Статья исследует синергию между генератив
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#long_context", "#cv", "#synthetic", "#dataset", "#rag"], "emoji": "📊", "ru": {"title": "Революция в генерации бизнес-контента: от текста к инфографике", "desc": "Статья представляет новый подход к генерации бизнес-контента, включая инфографику и слайды, на основе пользовательских з
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#multimodal", "#optimization", "#agents", "#agi", "#ethics", "#games", "#reasoning", "#robotics"], "emoji": "🤖", "ru": {"title": "Gemini Robotics: ИИ выходит в реальный мир", "desc": "Статья представляет семейство моделей Gemini Robotics, основанных на Gemini 2.0 и предназначенных д
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#hallucinations", "#reasoning", "#rag", "#small_models"], "emoji": "🧠", "ru": {"title": "MCTS-RAG: Усиление рассуждений малых языковых моделей", "desc": "MCTS-RAG - это новый подход, объединяющий retrieval-augmented generation (RAG) и Monte Carlo Tree Search (MCTS) для улучшения рас
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#benchmark", "#inference", "#optimization"], "emoji": "🧠", "ru": {"title": "Эффективное сжатие памяти для ускорения работы языковых моделей", "desc": "LogQuant - это новая техника 2-битной квантизации для KV-кэша при инференсе больших языковых моделей. Она применяет логарифмический 
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#inference", "#video", "#dataset", "#synthetic"], "emoji": "🎬", "ru": {"title": "Ускорение генерации видео с помощью синтетических данных и дистилляции диффузионных моделей", "desc": "Статья представляет новый метод AccVideo для ускорения генерации вид
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#open_source", "#reasoning", "#benchmark", "#optimization", "#multimodal", "#dataset"], "emoji": "🧠", "ru": {"title": "Прогресс в оценке и улучшении мультимодальных моделей вознаграждения", "desc": "Статья исследует эффективность моделей вознаграждения, контролируемых процессом (PRM
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#ethics", "#benchmark", "#cv", "#dataset", "#interpretability"], "emoji": "👁️", "ru": {"title": "Новый взгляд на предвзятость нейросетей через призму внимания", "desc": "Статья представляет новый метод оценки предвзятости в моделях компьютерного зрения - Attention-IoU. В отличие от 
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#dataset"], "emoji": "🚗", "ru": {"title": "Редактирование знаний для улучшения автономного вождения", "desc": "Статья описывает применение больших мультимодальных моделей (LMM) в системах автономного вождения (ADS). Авторы предлагают использовать редактиров
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#long_context", "#cv", "#multimodal"], "emoji": "🖼️", "ru": {"title": "Новая эра генерации изображений с длинными текстами", "desc": "Современные autoregressive и diffusion модели хорошо справляются с генерацией изображений с короткими текстами, но испытывают трудности с длинными те
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#transfer_learning", "#3d", "#robotics", "#optimization"], "emoji": "🚗", "ru": {"title": "Точная 3D-поза без 3D-разметки", "desc": "DINeMo - это новая нейронная сетевая модель для оценки 3D/6D позы объектов на уровне категорий без использования 3D-разметки. Модель использует псевдо-
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#video"], "emoji": "🎥", "ru": {"title": "Самообучаемая оценка движения в видео без размеченных данных", "desc": "Opt-CWM - это самообучаемый метод для оценки потока и окклюзии на основе предобученной модели предсказания следующего кадра. Он работает путем оптимизации контрфак
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#dataset", "#robotics", "#training", "#cv", "#benchmark"], "emoji": "📷", "ru": {"title": "Размытие в движении как ключ к точному позиционированию камеры", "desc": "Статья представляет новый подход к оценке положения камеры в условиях сильного размытия изображения при быстром движени
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#optimization", "#training"], "emoji": "🧠", "ru": {"title": "Эффективная дистилляция знаний для больших языковых моделей", "desc": "Статья представляет новый метод дистилляции знаний для обучения больших языковых моделей. Авторы показывают, что наивные подходы к разреженной дистилля
[27.03.2025 15:12] Querying the API.
[27.03.2025 15:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Document structure analysis, aka document layout analysis, is crucial for understanding both the physical layout and logical structure of documents, serving information retrieval, document summarization, knowledge extraction, etc. Hierarchical Document Structure Analysis (HDSA) specifically aims to restore the hierarchical structure of documents created using authoring software with hierarchical schemas. Previous research has primarily followed two approaches: one focuses on tackling specific subtasks of HDSA in isolation, such as table detection or reading order prediction, while the other adopts a unified framework that uses multiple branches or modules, each designed to address a distinct task. In this work, we propose a unified relation prediction approach for HDSA, called UniHDSA, which treats various HDSA sub-tasks as relation prediction problems and consolidates relation prediction labels into a unified label space. This allows a single relation prediction module to handle multiple tasks simultaneously, whether at a page-level or document-level structure analysis. To validate the effectiveness of UniHDSA, we develop a multimodal end-to-end system based on Transformer architectures. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance on a hierarchical document structure analysis benchmark, Comp-HRDoc, and competitive results on a large-scale document layout analysis dataset, DocLayNet, effectively illustrating the superiority of our method across all sub-tasks. The Comp-HRDoc benchmark and UniHDSA's configurations are publicly available at https://github.com/microsoft/CompHRDoc.
[27.03.2025 15:12] Response: {
  "desc": "Статья представляет новый подход к иерархическому анализу структуры документов (HDSA) под названием UniHDSA. Этот метод рассматривает различные подзадачи HDSA как проблемы предсказания отношений и объединяет метки предсказания отношений в единое пространство меток. UniHDSA использует единый модуль предсказания отношений для одновременной обработки нескольких задач на уровне страницы и документа. Авторы разработали мультимодальную систему на основе архитектуры Transformer для валидации эффективности UniHDSA.",

  "emoji": "📄",

  "title": "Унифицированный подход к анализу иерархической структуры документов"
}
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Document structure analysis, aka document layout analysis, is crucial for understanding both the physical layout and logical structure of documents, serving information retrieval, document summarization, knowledge extraction, etc. Hierarchical Document Structure Analysis (HDSA) specifically aims to restore the hierarchical structure of documents created using authoring software with hierarchical schemas. Previous research has primarily followed two approaches: one focuses on tackling specific subtasks of HDSA in isolation, such as table detection or reading order prediction, while the other adopts a unified framework that uses multiple branches or modules, each designed to address a distinct task. In this work, we propose a unified relation prediction approach for HDSA, called UniHDSA, which treats various HDSA sub-tasks as relation prediction problems and consolidates relation prediction labels into a unified label space. This allows a single relation prediction module to handle multiple tasks simultaneously, whether at a page-level or document-level structure analysis. To validate the effectiveness of UniHDSA, we develop a multimodal end-to-end system based on Transformer architectures. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance on a hierarchical document structure analysis benchmark, Comp-HRDoc, and competitive results on a large-scale document layout analysis dataset, DocLayNet, effectively illustrating the superiority of our method across all sub-tasks. The Comp-HRDoc benchmark and UniHDSA's configurations are publicly available at https://github.com/microsoft/CompHRDoc."

[27.03.2025 15:12] Response: ```python
['DATASET', 'BENCHMARK', 'MULTIMODAL', 'ARCHITECTURE']
```
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Document structure analysis, aka document layout analysis, is crucial for understanding both the physical layout and logical structure of documents, serving information retrieval, document summarization, knowledge extraction, etc. Hierarchical Document Structure Analysis (HDSA) specifically aims to restore the hierarchical structure of documents created using authoring software with hierarchical schemas. Previous research has primarily followed two approaches: one focuses on tackling specific subtasks of HDSA in isolation, such as table detection or reading order prediction, while the other adopts a unified framework that uses multiple branches or modules, each designed to address a distinct task. In this work, we propose a unified relation prediction approach for HDSA, called UniHDSA, which treats various HDSA sub-tasks as relation prediction problems and consolidates relation prediction labels into a unified label space. This allows a single relation prediction module to handle multiple tasks simultaneously, whether at a page-level or document-level structure analysis. To validate the effectiveness of UniHDSA, we develop a multimodal end-to-end system based on Transformer architectures. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance on a hierarchical document structure analysis benchmark, Comp-HRDoc, and competitive results on a large-scale document layout analysis dataset, DocLayNet, effectively illustrating the superiority of our method across all sub-tasks. The Comp-HRDoc benchmark and UniHDSA's configurations are publicly available at https://github.com/microsoft/CompHRDoc."

[27.03.2025 15:12] Response: []
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new method called UniHDSA for Hierarchical Document Structure Analysis (HDSA), which focuses on understanding the layout and structure of documents. Unlike previous methods that tackled individual tasks separately, UniHDSA treats various HDSA tasks as relation prediction problems, allowing for a more integrated approach. The method uses a single relation prediction module to analyze both page-level and document-level structures simultaneously. Experimental results show that UniHDSA outperforms existing methods on benchmark datasets, demonstrating its effectiveness in document layout analysis.","title":"Unified Relation Prediction for Enhanced Document Structure Analysis"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new method called UniHDSA for Hierarchical Document Structure Analysis (HDSA), which focuses on understanding the layout and structure of documents. Unlike previous methods that tackled individual tasks separately, UniHDSA treats various HDSA tasks as relation prediction problems, allowing for a more integrated approach. The method uses a single relation prediction module to analyze both page-level and document-level structures simultaneously. Experimental results show that UniHDSA outperforms existing methods on benchmark datasets, demonstrating its effectiveness in document layout analysis.', title='Unified Relation Prediction for Enhanced Document Structure Analysis'))
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"文档结构分析对于理解文档的物理布局和逻辑结构至关重要，涉及信息检索、文档摘要和知识提取等应用。本文提出了一种统一的关系预测方法UniHDSA，旨在将文档结构分析的各个子任务视为关系预测问题，并将关系预测标签整合到一个统一的标签空间中。通过这种方法，单一的关系预测模块能够同时处理多个任务，无论是在页面级别还是文档级别的结构分析。实验结果表明，UniHDSA在层次文档结构分析基准Comp-HRDoc上达到了最先进的性能，并在大规模文档布局分析数据集DocLayNet上也取得了竞争力的结果，展示了该方法在各个子任务上的优越性。","title":"统一关系预测，提升文档结构分析"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='文档结构分析对于理解文档的物理布局和逻辑结构至关重要，涉及信息检索、文档摘要和知识提取等应用。本文提出了一种统一的关系预测方法UniHDSA，旨在将文档结构分析的各个子任务视为关系预测问题，并将关系预测标签整合到一个统一的标签空间中。通过这种方法，单一的关系预测模块能够同时处理多个任务，无论是在页面级别还是文档级别的结构分析。实验结果表明，UniHDSA在层次文档结构分析基准Comp-HRDoc上达到了最先进的性能，并在大规模文档布局分析数据集DocLayNet上也取得了竞争力的结果，展示了该方法在各个子任务上的优越性。', title='统一关系预测，提升文档结构分析'))
[27.03.2025 15:12] Querying the API.
[27.03.2025 15:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Writing Assistants (e.g., Grammarly, Microsoft Copilot) traditionally generate diverse image captions by employing syntactic and semantic variations to describe image components. However, human-written captions prioritize conveying a central message alongside visual descriptions using pragmatic cues. To enhance pragmatic diversity, it is essential to explore alternative ways of communicating these messages in conjunction with visual content. To address this challenge, we propose RONA, a novel prompting strategy for Multi-modal Large Language Models (MLLM) that leverages Coherence Relations as an axis for variation. We demonstrate that RONA generates captions with better overall diversity and ground-truth alignment, compared to MLLM baselines across multiple domains. Our code is available at: https://github.com/aashish2000/RONA
[27.03.2025 15:12] Response: {
  "desc": "Статья представляет новый метод RONA для генерации разнообразных подписей к изображениям с помощью мультимодальных языковых моделей (MLLM). В отличие от традиционных подходов, RONA использует отношения согласованности для создания прагматически разнообразных подписей. Эксперименты показывают, что RONA превосходит базовые MLLM по общему разнообразию и соответствию эталонным подписям в различных доменах. Авторы предоставляют открытый исходный код своего метода.",
  "emoji": "🖼️",
  "title": "RONA: прагматическое разнообразие в генерации подписей к изображениям"
}
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Writing Assistants (e.g., Grammarly, Microsoft Copilot) traditionally generate diverse image captions by employing syntactic and semantic variations to describe image components. However, human-written captions prioritize conveying a central message alongside visual descriptions using pragmatic cues. To enhance pragmatic diversity, it is essential to explore alternative ways of communicating these messages in conjunction with visual content. To address this challenge, we propose RONA, a novel prompting strategy for Multi-modal Large Language Models (MLLM) that leverages Coherence Relations as an axis for variation. We demonstrate that RONA generates captions with better overall diversity and ground-truth alignment, compared to MLLM baselines across multiple domains. Our code is available at: https://github.com/aashish2000/RONA"

[27.03.2025 15:12] Response: ```python
['MULTIMODAL', 'CV']
```
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Writing Assistants (e.g., Grammarly, Microsoft Copilot) traditionally generate diverse image captions by employing syntactic and semantic variations to describe image components. However, human-written captions prioritize conveying a central message alongside visual descriptions using pragmatic cues. To enhance pragmatic diversity, it is essential to explore alternative ways of communicating these messages in conjunction with visual content. To address this challenge, we propose RONA, a novel prompting strategy for Multi-modal Large Language Models (MLLM) that leverages Coherence Relations as an axis for variation. We demonstrate that RONA generates captions with better overall diversity and ground-truth alignment, compared to MLLM baselines across multiple domains. Our code is available at: https://github.com/aashish2000/RONA"

[27.03.2025 15:12] Response: ```python
["STORY_GENERATION", "OPEN_SOURCE"]
```
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces RONA, a new prompting strategy designed for Multi-modal Large Language Models (MLLM) to improve the diversity of image captions. Unlike traditional methods that focus on syntactic and semantic variations, RONA emphasizes pragmatic cues to convey a central message alongside visual descriptions. By utilizing Coherence Relations, RONA enhances the way messages are communicated in relation to images. The results show that RONA outperforms existing MLLM baselines in generating captions that are more diverse and closely aligned with ground-truth descriptions across various domains.","title":"RONA: Enhancing Caption Diversity with Pragmatic Cues"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces RONA, a new prompting strategy designed for Multi-modal Large Language Models (MLLM) to improve the diversity of image captions. Unlike traditional methods that focus on syntactic and semantic variations, RONA emphasizes pragmatic cues to convey a central message alongside visual descriptions. By utilizing Coherence Relations, RONA enhances the way messages are communicated in relation to images. The results show that RONA outperforms existing MLLM baselines in generating captions that are more diverse and closely aligned with ground-truth descriptions across various domains.', title='RONA: Enhancing Caption Diversity with Pragmatic Cues'))
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文提出了一种新的提示策略RONA，用于多模态大语言模型（MLLM），旨在提高图像标题的多样性。传统的写作助手生成的标题往往侧重于语法和语义的变化，而人类撰写的标题则更注重传达中心信息。RONA通过利用一致性关系作为变化的轴心，探索了与视觉内容结合的替代沟通方式。实验结果表明，RONA生成的标题在多样性和真实对齐度上优于现有的MLLM基线。","title":"RONA：提升图像标题多样性的创新策略"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文提出了一种新的提示策略RONA，用于多模态大语言模型（MLLM），旨在提高图像标题的多样性。传统的写作助手生成的标题往往侧重于语法和语义的变化，而人类撰写的标题则更注重传达中心信息。RONA通过利用一致性关系作为变化的轴心，探索了与视觉内容结合的替代沟通方式。实验结果表明，RONA生成的标题在多样性和真实对齐度上优于现有的MLLM基线。', title='RONA：提升图像标题多样性的创新策略'))
[27.03.2025 15:12] Querying the API.
[27.03.2025 15:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

The transition from System 1 to System 2 reasoning in large language models (LLMs) has marked significant advancements in handling complex tasks through deliberate, iterative thinking. However, this progress often comes at the cost of efficiency, as models tend to overthink, generating redundant reasoning steps without proportional improvements in output quality. Long-to-Short (L2S) reasoning has emerged as a promising solution to this challenge, aiming to balance reasoning depth with practical efficiency. While existing approaches, such as supervised fine-tuning (SFT), reinforcement learning (RL), and prompt engineering, have shown potential, they are either computationally expensive or unstable. Model merging, on the other hand, offers a cost-effective and robust alternative by integrating the quick-thinking capabilities of System 1 models with the methodical reasoning of System 2 models. In this work, we present a comprehensive empirical study on model merging for L2S reasoning, exploring diverse methodologies, including task-vector-based, SVD-based, and activation-informed merging. Our experiments reveal that model merging can reduce average response length by up to 55% while preserving or even improving baseline performance. We also identify a strong correlation between model scale and merging efficacy with extensive evaluations on 1.5B/7B/14B/32B models. Furthermore, we investigate the merged model's ability to self-critique and self-correct, as well as its adaptive response length based on task complexity. Our findings highlight model merging as a highly efficient and effective paradigm for L2S reasoning, offering a practical solution to the overthinking problem while maintaining the robustness of System 2 reasoning. This work can be found on Github https://github.com/hahahawu/Long-to-Short-via-Model-Merging.
[27.03.2025 15:12] Response: {
  "desc": "Статья посвящена проблеме избыточного мышления в больших языковых моделях (LLM) при переходе от быстрого интуитивного мышления (System 1) к медленному аналитическому (System 2). Авторы предлагают метод объединения моделей (model merging) для достижения баланса между глубиной рассуждений и эффективностью. Эксперименты показывают, что этот подход может сократить среднюю длину ответа на 55% при сохранении или улучшении производительности. Исследование также выявляет сильную корреляцию между масштабом модели и эффективностью объединения.",
  "emoji": "🧠",
  "title": "Эффективное рассуждение в LLM: от длинного к короткому через объединение моделей"
}
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The transition from System 1 to System 2 reasoning in large language models (LLMs) has marked significant advancements in handling complex tasks through deliberate, iterative thinking. However, this progress often comes at the cost of efficiency, as models tend to overthink, generating redundant reasoning steps without proportional improvements in output quality. Long-to-Short (L2S) reasoning has emerged as a promising solution to this challenge, aiming to balance reasoning depth with practical efficiency. While existing approaches, such as supervised fine-tuning (SFT), reinforcement learning (RL), and prompt engineering, have shown potential, they are either computationally expensive or unstable. Model merging, on the other hand, offers a cost-effective and robust alternative by integrating the quick-thinking capabilities of System 1 models with the methodical reasoning of System 2 models. In this work, we present a comprehensive empirical study on model merging for L2S reasoning, exploring diverse methodologies, including task-vector-based, SVD-based, and activation-informed merging. Our experiments reveal that model merging can reduce average response length by up to 55% while preserving or even improving baseline performance. We also identify a strong correlation between model scale and merging efficacy with extensive evaluations on 1.5B/7B/14B/32B models. Furthermore, we investigate the merged model's ability to self-critique and self-correct, as well as its adaptive response length based on task complexity. Our findings highlight model merging as a highly efficient and effective paradigm for L2S reasoning, offering a practical solution to the overthinking problem while maintaining the robustness of System 2 reasoning. This work can be found on Github https://github.com/hahahawu/Long-to-Short-via-Model-Merging."

[27.03.2025 15:12] Response: ```python
['TRAINING', 'ARCHITECTURE']
```
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"The transition from System 1 to System 2 reasoning in large language models (LLMs) has marked significant advancements in handling complex tasks through deliberate, iterative thinking. However, this progress often comes at the cost of efficiency, as models tend to overthink, generating redundant reasoning steps without proportional improvements in output quality. Long-to-Short (L2S) reasoning has emerged as a promising solution to this challenge, aiming to balance reasoning depth with practical efficiency. While existing approaches, such as supervised fine-tuning (SFT), reinforcement learning (RL), and prompt engineering, have shown potential, they are either computationally expensive or unstable. Model merging, on the other hand, offers a cost-effective and robust alternative by integrating the quick-thinking capabilities of System 1 models with the methodical reasoning of System 2 models. In this work, we present a comprehensive empirical study on model merging for L2S reasoning, exploring diverse methodologies, including task-vector-based, SVD-based, and activation-informed merging. Our experiments reveal that model merging can reduce average response length by up to 55% while preserving or even improving baseline performance. We also identify a strong correlation between model scale and merging efficacy with extensive evaluations on 1.5B/7B/14B/32B models. Furthermore, we investigate the merged model's ability to self-critique and self-correct, as well as its adaptive response length based on task complexity. Our findings highlight model merging as a highly efficient and effective paradigm for L2S reasoning, offering a practical solution to the overthinking problem while maintaining the robustness of System 2 reasoning. This work can be found on Github https://github.com/hahahawu/Long-to-Short-via-Model-Merging."

[27.03.2025 15:12] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper discusses the transition from quick, intuitive reasoning (System 1) to more deliberate, analytical reasoning (System 2) in large language models (LLMs). It highlights the inefficiencies that arise when models overthink, leading to unnecessary complexity without significant gains in output quality. The authors propose a method called Long-to-Short (L2S) reasoning, which aims to optimize the balance between deep reasoning and efficiency. They introduce model merging as a solution, which combines the strengths of both reasoning systems, demonstrating that this approach can significantly reduce response length while maintaining or enhancing performance.","title":"Efficient Reasoning through Model Merging"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper discusses the transition from quick, intuitive reasoning (System 1) to more deliberate, analytical reasoning (System 2) in large language models (LLMs). It highlights the inefficiencies that arise when models overthink, leading to unnecessary complexity without significant gains in output quality. The authors propose a method called Long-to-Short (L2S) reasoning, which aims to optimize the balance between deep reasoning and efficiency. They introduce model merging as a solution, which combines the strengths of both reasoning systems, demonstrating that this approach can significantly reduce response length while maintaining or enhancing performance.', title='Efficient Reasoning through Model Merging'))
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"本文探讨了大型语言模型（LLMs）在复杂任务中从系统1推理到系统2推理的转变。尽管这种进步提高了推理的深度，但往往导致效率下降，模型可能会产生冗余的推理步骤。为了解决这个问题，长到短（L2S）推理提出了一种平衡推理深度与效率的方案。通过模型合并，我们能够将系统1模型的快速思维与系统2模型的系统性推理结合，从而在保持性能的同时显著减少响应长度。","title":"模型合并：高效的长到短推理解决方案"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='本文探讨了大型语言模型（LLMs）在复杂任务中从系统1推理到系统2推理的转变。尽管这种进步提高了推理的深度，但往往导致效率下降，模型可能会产生冗余的推理步骤。为了解决这个问题，长到短（L2S）推理提出了一种平衡推理深度与效率的方案。通过模型合并，我们能够将系统1模型的快速思维与系统2模型的系统性推理结合，从而在保持性能的同时显著减少响应长度。', title='模型合并：高效的长到短推理解决方案'))
[27.03.2025 15:12] Querying the API.
[27.03.2025 15:12] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, existing on-policy algorithms used for post-training are inherently incompatible with the use of experience replay buffers, which can be populated scalably by distributed off-policy actors to enhance exploration as compute increases. We propose efficiently obtaining this benefit of replay buffers via Trajectory Balance with Asynchrony (TBA), a massively scalable LLM RL system. In contrast to existing approaches, TBA uses a larger fraction of compute on search, constantly generating off-policy data for a central replay buffer. A training node simultaneously samples data from this buffer based on reward or recency to update the policy using Trajectory Balance (TB), a diversity-seeking RL objective introduced for GFlowNets. TBA offers three key advantages: (1) decoupled training and search, speeding up training wall-clock time by 4x or more; (2) improved diversity through large-scale off-policy sampling; and (3) scalable search for sparse reward settings. On mathematical reasoning, preference-tuning, and automated red-teaming (diverse and representative post-training tasks), TBA produces speed and performance improvements over strong baselines.
[27.03.2025 15:12] Response: {
  "desc": "Эта статья представляет новый метод обучения с подкреплением для крупных языковых моделей под названием Trajectory Balance with Asynchrony (TBA). TBA использует буфер воспроизведения опыта для улучшения исследования и разнообразия данных. Метод предлагает асинхронный подход, разделяющий процессы поиска и обучения, что значительно ускоряет общее время обучения. TBA демонстрирует улучшения производительности в задачах математических рассуждений, настройки предпочтений и автоматизированного тестирования безопасности по сравнению с существующими методами.",
  "emoji": "🧠",
  "title": "TBA: Масштабируемое обучение с подкреплением для крупных языковых моделей"
}
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, existing on-policy algorithms used for post-training are inherently incompatible with the use of experience replay buffers, which can be populated scalably by distributed off-policy actors to enhance exploration as compute increases. We propose efficiently obtaining this benefit of replay buffers via Trajectory Balance with Asynchrony (TBA), a massively scalable LLM RL system. In contrast to existing approaches, TBA uses a larger fraction of compute on search, constantly generating off-policy data for a central replay buffer. A training node simultaneously samples data from this buffer based on reward or recency to update the policy using Trajectory Balance (TB), a diversity-seeking RL objective introduced for GFlowNets. TBA offers three key advantages: (1) decoupled training and search, speeding up training wall-clock time by 4x or more; (2) improved diversity through large-scale off-policy sampling; and (3) scalable search for sparse reward settings. On mathematical reasoning, preference-tuning, and automated red-teaming (diverse and representative post-training tasks), TBA produces speed and performance improvements over strong baselines."

[27.03.2025 15:12] Response: ```python
['RL', 'TRAINING']
```
[27.03.2025 15:12] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, existing on-policy algorithms used for post-training are inherently incompatible with the use of experience replay buffers, which can be populated scalably by distributed off-policy actors to enhance exploration as compute increases. We propose efficiently obtaining this benefit of replay buffers via Trajectory Balance with Asynchrony (TBA), a massively scalable LLM RL system. In contrast to existing approaches, TBA uses a larger fraction of compute on search, constantly generating off-policy data for a central replay buffer. A training node simultaneously samples data from this buffer based on reward or recency to update the policy using Trajectory Balance (TB), a diversity-seeking RL objective introduced for GFlowNets. TBA offers three key advantages: (1) decoupled training and search, speeding up training wall-clock time by 4x or more; (2) improved diversity through large-scale off-policy sampling; and (3) scalable search for sparse reward settings. On mathematical reasoning, preference-tuning, and automated red-teaming (diverse and representative post-training tasks), TBA produces speed and performance improvements over strong baselines."

[27.03.2025 15:12] Response: ```python
["REASONING", "OPTIMIZATION"]
```
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper introduces a new method called Trajectory Balance with Asynchrony (TBA) for improving reinforcement learning in large language models (LLMs). TBA allows the use of experience replay buffers, which help in better exploration by storing past experiences and using them for training. The method separates the training and search processes, leading to faster training times and enhanced diversity in the data sampled. Overall, TBA shows significant improvements in performance and efficiency on various post-training tasks compared to existing methods.","title":"Boosting LLM Training with Efficient Replay and Exploration"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper introduces a new method called Trajectory Balance with Asynchrony (TBA) for improving reinforcement learning in large language models (LLMs). TBA allows the use of experience replay buffers, which help in better exploration by storing past experiences and using them for training. The method separates the training and search processes, leading to faster training times and enhanced diversity in the data sampled. Overall, TBA shows significant improvements in performance and efficiency on various post-training tasks compared to existing methods.', title='Boosting LLM Training with Efficient Replay and Exploration'))
[27.03.2025 15:12] Response: ParsedChatCompletionMessage[Article](content='{"desc":"强化学习（RL）是大型语言模型（LLM）后训练的重要组成部分。现有的在线算法与经验重放缓冲区不兼容，而我们提出的轨迹平衡与异步（TBA）方法可以有效利用重放缓冲区的优势。TBA通过将计算资源更多地用于搜索，持续生成离线数据来更新策略，从而加速训练过程。该方法在数学推理、偏好调优和自动红队等任务上表现出显著的速度和性能提升。","title":"提升强化学习效率的轨迹平衡与异步方法"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='强化学习（RL）是大型语言模型（LLM）后训练的重要组成部分。现有的在线算法与经验重放缓冲区不兼容，而我们提出的轨迹平衡与异步（TBA）方法可以有效利用重放缓冲区的优势。TBA通过将计算资源更多地用于搜索，持续生成离线数据来更新策略，从而加速训练过程。该方法在数学推理、偏好调优和自动红队等任务上表现出显著的速度和性能提升。', title='提升强化学习效率的轨迹平衡与异步方法'))
[27.03.2025 15:12] Using data from previous issue: {"categories": ["#cv", "#healthcare", "#training"], "emoji": "🔬", "ru": {"title": "Повышение точности прогноза рака груди с помощью улучшения изображений и глубокого обучения", "desc": "PathoHR - это новый метод для точного прогнозирования выживаемости при раке молочной железы, который улучшает каче
[27.03.2025 15:12] Loading Chinese text from previous data.
[27.03.2025 15:12] Renaming data file.
[27.03.2025 15:12] Renaming previous data. hf_papers.json to ./d/2025-03-27.json
[27.03.2025 15:12] Saving new data file.
[27.03.2025 15:12] Generating page.
[27.03.2025 15:12] Renaming previous page.
[27.03.2025 15:12] Renaming previous data. index.html to ./d/2025-03-27.html
[27.03.2025 15:12] [Experimental] Generating Chinese page for reading.
[27.03.2025 15:12] Chinese vocab [{'word': '视觉', 'pinyin': 'shìjué', 'trans': 'vision'}, {'word': '语言', 'pinyin': 'yǔyán', 'trans': 'language'}, {'word': '动作', 'pinyin': 'dòngzuò', 'trans': 'action'}, {'word': '模型', 'pinyin': 'móxíng', 'trans': 'model'}, {'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'}, {'word': '称为', 'pinyin': 'chēngwéi', 'trans': 'called'}, {'word': 'Transformer', 'pinyin': 'Tuōnghuànzhè', 'trans': 'Transformer'}, {'word': '架构', 'pinyin': 'jiàgòu', 'trans': 'architecture'}, {'word': '直接', 'pinyin': 'zhíjiē', 'trans': 'directly'}, {'word': '统一', 'pinyin': 'tǒngyī', 'trans': 'unified'}, {'word': '多模态', 'pinyin': 'duōmóshuài', 'trans': 'multimodal'}, {'word': '扩散', 'pinyin': 'kuòsàn', 'trans': 'diffusion'}, {'word': '过程', 'pinyin': 'guòchéng', 'trans': 'process'}, {'word': '去噪', 'pinyin': 'qùzào', 'trans': 'denoise'}, {'word': '连续', 'pinyin': 'liánxù', 'trans': 'continuous'}, {'word': '序列', 'pinyin': 'xùliè', 'trans': 'sequence'}, {'word': '上下文', 'pinyin': 'shàngxiàwén', 'trans': 'context'}, {'word': '条件', 'pinyin': 'tiáojiàn', 'trans': 'condition'}, {'word': '设置', 'pinyin': 'shèzhì', 'trans': 'setting'}, {'word': '实现', 'pinyin': 'shíxiàn', 'trans': 'achieve'}, {'word': '细粒度', 'pinyin': 'xìlìdù', 'trans': 'fine-grained'}, {'word': '对齐', 'pinyin': 'duìqí', 'trans': 'alignment'}, {'word': '原始', 'pinyin': 'yuánshǐ', 'trans': 'original'}, {'word': '标记', 'pinyin': 'biāojì', 'trans': 'marker'}, {'word': '设计', 'pinyin': 'shèjì', 'trans': 'design'}, {'word': '显著', 'pinyin': 'xiǎnzhù', 'trans': 'significant'}, {'word': '提高', 'pinyin': 'tígāo', 'trans': 'improve'}, {'word': '适应性', 'pinyin': 'shìyìngxìng', 'trans': 'adaptability'}, {'word': '鲁棒性', 'pinyin': 'lǔbāngxìng', 'trans': 'robustness'}, {'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'}, {'word': '环境', 'pinyin': 'huánjìng', 'trans': 'environment'}, {'word': '实验', 'pinyin': 'shíyàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jiéguǒ', 'trans': 'result'}, {'word': '表明', 'pinyin': 'biǎomíng', 'trans': 'indicate'}, {'word': '模拟', 'pinyin': 'mónǐ', 'trans': 'simulation'}, {'word': '实际', 'pinyin': 'shíjì', 'trans': 'actual'}, {'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chūsè', 'trans': 'outstanding'}, {'word': '特别', 'pinyin': 'tèbié', 'trans': 'especially'}, {'word': '复杂', 'pinyin': 'fùzá', 'trans': 'complex'}, {'word': '长时间', 'pinyin': 'chángshíjiān', 'trans': 'long-term'}]
[27.03.2025 15:12] Renaming previous Chinese page.
[27.03.2025 15:12] Renaming previous data. zh.html to ./d/2025-03-26_zh_reading_task.html
[27.03.2025 15:12] Writing Chinese reading task.
[27.03.2025 15:12] Writing result.
[27.03.2025 15:12] Renaming log file.
[27.03.2025 15:12] Renaming previous data. log.txt to ./logs/2025-03-27_last_log.txt
