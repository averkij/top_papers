[14.05.2025 05:12] Read previous papers.
[14.05.2025 05:12] Generating top page (month).
[14.05.2025 05:12] Writing top page (month).
[14.05.2025 06:16] Read previous papers.
[14.05.2025 06:16] Get feed.
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07062
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07608
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07747
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07787
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07447
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.06548
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07818
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07293
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07263
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.03733
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07796
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07596
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.06176
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07260
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.00612
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07819
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07812
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07291
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.04066
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07793
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07233
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.06324
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.04918
[14.05.2025 06:16] Get page data from previous paper. URL: https://huggingface.co/papers/2505.07086
[14.05.2025 06:16] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[14.05.2025 06:16] No deleted papers detected.
[14.05.2025 06:16] Downloading and parsing papers (pdf, html). Total: 24.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07062.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07062.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07062.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07608.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07608.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07608.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07747.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07747.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07747.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07787.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07787.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07787.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07447.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07447.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07447.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.06548.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.06548.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.06548.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07818.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07818.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07818.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07293.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07293.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07293.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07263.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07263.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07263.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.03733.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.03733.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.03733.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07796.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07796.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07796.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07596.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07596.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07596.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.06176.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.06176.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.06176.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07260.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07260.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07260.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.00612.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.00612.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.00612.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07819.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07819.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07819.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07812.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07812.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07812.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07291.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07291.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07291.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.04066.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.04066.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.04066.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07793.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07793.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07793.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07233.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07233.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07233.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.06324.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.06324.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.06324.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.04918.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.04918.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.04918.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Downloading and parsing paper https://huggingface.co/papers/2505.07086.
[14.05.2025 06:16] Extra JSON file exists (./assets/json/2505.07086.json), skip PDF parsing.
[14.05.2025 06:16] Paper image links file exists (./assets/img_data/2505.07086.json), skip HTML parsing.
[14.05.2025 06:16] Success.
[14.05.2025 06:16] Enriching papers with extra data.
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 0. We present Seed1.5-VL, a vision-language foundation model designed to advance general-purpose multimodal understanding and reasoning. Seed1.5-VL is composed with a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B active parameters. Despite its relatively compact architecture, ...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 1. We present MiMo-7B, a large language model born for reasoning tasks, with optimization across both pre-training and post-training stages. During pre-training, we enhance the data preprocessing pipeline and employ a three-stage data mixing strategy to strengthen the base model's reasoning potential. ...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 2. While generative artificial intelligence has advanced significantly across text, image, audio, and video domains, 3D generation remains comparatively underdeveloped due to fundamental challenges such as data scarcity, algorithmic limitations, and ecosystem fragmentation. To this end, we present Step...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 3. Large Reasoning Models (LRMs) have the ability to self-correct even when they make mistakes in their reasoning paths. However, our study reveals that when the reasoning process starts with a short but poor beginning, it becomes difficult for the model to recover. We refer to this phenomenon as the "...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 4. Recent advances in continuous generative models, including multi-step approaches like diffusion and flow-matching (typically requiring 8-1000 sampling steps) and few-step methods such as consistency models (typically 1-8 steps), have demonstrated impressive generative performance. However, existing ...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 5. Instruction-based Large Language Models (LLMs) have proven effective in numerous few-shot or zero-shot Natural Language Processing (NLP) tasks. However, creating human-annotated instruction data is time-consuming, expensive, and often limited in quantity and task diversity. Previous research endeavo...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 6. Recent breakthroughs in generative models-particularly diffusion models and rectified flows-have revolutionized visual content creation, yet aligning model outputs with human preferences remains a critical challenge. Existing reinforcement learning (RL)-based methods for visual generation face criti...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 7. Recently, there has been growing interest in collecting reasoning-intensive pretraining data to improve LLMs' complex reasoning ability. Prior approaches typically rely on supervised classifiers to identify such data, which requires labeling by humans or LLMs, often introducing domain-specific biase...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 8. We propose Skywork-VL Reward, a multimodal reward model that provides reward signals for both multimodal understanding and reasoning tasks. Our technical approach comprises two key components: First, we construct a large-scale multimodal preference dataset that covers a wide range of tasks and scena...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 9. LLM-based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructi...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 10. Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain perfo...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 11. Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 12. Retouching is an essential task in post-manipulation of raw photographs. Generative editing, guided by text or strokes, provides a new tool accessible to users but can easily change the identity of the original objects in unacceptable and unpredictable ways. In contrast, although traditional procedu...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 13. Sparse Mixture of Experts (MoE) architectures have emerged as a promising approach for scaling Transformer models. While initial works primarily incorporated MoE into feed-forward network (FFN) layers, recent studies have explored extending the MoE paradigm to attention layers to enhance model perfo...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 14. In this position paper, we observe that empirical evaluation in Generative AI is at a crisis point since traditional ML evaluation and benchmarking strategies are insufficient to meet the needs of evaluating modern GenAI models and systems. There are many reasons for this, including the fact that th...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 15. Visuomotor policy learning has witnessed substantial progress in robotic manipulation, with recent approaches predominantly relying on generative models to model the action distribution. However, these methods often overlook the critical coupling between visual perception and action prediction. In t...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 16. Conventional wisdom suggests that autoregressive models are used to process discrete data. When applied to continuous modalities such as visual data, Visual AutoRegressive modeling (VAR) typically resorts to quantization-based approaches to cast the data into a discrete space, which can introduce si...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 17. We introduce INTELLECT-2, the first globally distributed reinforcement learning (RL) training run of a 32 billion parameter language model. Unlike traditional centralized training efforts, INTELLECT-2 trains a reasoning model using fully asynchronous RL across a dynamic, heterogeneous swarm of permi...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 18. We introduce LlamaPIE, the first real-time proactive assistant designed to enhance human conversations through discreet, concise guidance delivered via hearable devices. Unlike traditional language models that require explicit user invocation, this assistant operates in the background, anticipating ...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 19. A recent trend in LLMs is developing recurrent sub-quadratic models that improve long-context processing efficiency. We investigate leading large long-context models, focusing on how their fixed-size recurrent memory affects their performance. Our experiments reveal that, even when these models are ...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 20. Retrieval-augmented generation (RAG) systems combine large language models (LLMs) with external knowledge retrieval, making them highly effective for knowledge-intensive tasks. A crucial but often under-explored component of these systems is the reranker, which refines retrieved documents to enhance...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 21. As Large Language Models (LLMs) are increasingly applied to document-based tasks - such as document summarization, question answering, and information extraction - where user requirements focus on retrieving information from provided documents rather than relying on the model's parametric knowledge,...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 22. Although deep learning models have demonstrated remarkable potential in weather prediction, most of them overlook either the physics of the underlying weather evolution or the topology of the Earth's surface. In light of these disadvantages, we develop PASSAT, a novel Physics-ASSisted And Topology-i...
[14.05.2025 06:16] ********************************************************************************
[14.05.2025 06:16] Abstract 23. Designing biological sequences that satisfy multiple, often conflicting, functional and biophysical criteria remains a central challenge in biomolecule engineering. While discrete flow matching models have recently shown promise for efficient sampling in high-dimensional sequence spaces, existing ap...
[14.05.2025 06:16] Read previous papers.
[14.05.2025 06:16] Generating reviews via LLM API.
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#agi", "#multimodal", "#survey", "#architecture", "#training", "#reasoning", "#data"], "emoji": "🧠", "ru": {"title": "Компактная мультимодальная модель с выдающимися способностями", "desc": "Seed1.5-VL - это мультимодальная модель, сочетающая зрение и язык для общего понимания и рас
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#plp", "#reasoning", "#optimization", "#dataset", "#math", "#rl", "#data", "#training"], "emoji": "🧠", "ru": {"title": "MiMo-7B: Мощная языковая модель для сложных рассуждений", "desc": "MiMo-7B - это большая языковая модель, оптимизированная для задач рассуждения. В процессе предва
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#architecture", "#data", "#diffusion", "#transfer_learning", "#3d", "#benchmark"], "emoji": "🧊", "ru": {"title": "Открытая платформа для AI-генерации 3D-объектов нового поколения", "desc": "Статья представляет Step1X-3D - открытую систему для генерации 3D
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#math", "#training", "#small_models", "#reasoning", "#dataset"], "emoji": "🧠", "ru": {"title": "Коллективный разум: как модели машинного обучения учатся друг у друга", "desc": "Исследование показывает, что крупные модели рассуждений (LRM) могут попадать в 'ловушку д
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#training", "#cv"], "emoji": "🔄", "ru": {"title": "Единый фреймворк для непрерывных генеративных моделей: от многошаговых до малошаговых", "desc": "Статья представляет унифицированный подход к обучению и сэмплированию непрерывных генеративных моделей. 
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#training", "#small_models", "#rl", "#dataset", "#data"], "emoji": "🤖", "ru": {"title": "Малые модели и RL улучшают генерацию инструкций для обучения больших ЯМ", "desc": "Статья исследует эффективность малых открытых языковых моделей (LLaMA 2-7B, LL
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#alignment", "#optimization", "#video", "#multimodal", "#rl", "#diffusion", "#benchmark", "#rlhf"], "emoji": "🎨", "ru": {"title": "DanceGRPO: Революция в обучении с подкреплением для генерации визуального контента", "desc": "Статья представляет DanceGRPO - унифицированный фреймворк 
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#reasoning", "#training", "#dataset", "#benchmark", "#data", "#optimization", "#small_models"], "emoji": "🧠", "ru": {"title": "Улучшение способности ЯМ к рассуждениям через умный отбор данных", "desc": "Статья представляет метод AttentionInfluence для отбора данных, улучшающих спосо
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#benchmark", "#alignment", "#open_source", "#training", "#architecture", "#dataset"], "emoji": "🌟", "ru": {"title": "Универсальная мультимодальная модель вознаграждения для улучшения ИИ-рассуждений", "desc": "Исследователи представили Skywork-VL Rewar
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#games", "#benchmark", "#training", "#agents", "#dataset"], "emoji": "🌐", "ru": {"title": "WebGen-Bench: Новый рубеж в оценке LLM-агентов для веб-разработки", "desc": "WebGen-Bench - это новый бенчмарк для оценки способности LLM-агентов создавать многофайловые веб-с
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#transfer_learning", "#training"], "emoji": "📈", "ru": {"title": "Раскрытие секретов непрерывного предобучения языковых моделей", "desc": "Статья исследует динамику обучения при непрерывном предобучении (CPT) больших языковых моделей. Авторы наблюдают, как меняется 
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#reasoning", "#rag", "#agents", "#optimization", "#hallucinations", "#rl", "#training"], "emoji": "🧠", "ru": {"title": "Умный поиск: когда искать, а когда довериться себе", "desc": "Статья представляет новый подход к улучшению работы больших языковых моделей (LLM) с использованием м
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#synthetic", "#optimization", "#training", "#dataset", "#data", "#multimodal", "#interpretability", "#cv"], "emoji": "🖼️", "ru": {"title": "Интеллектуальная ретушь фотографий: MLLM на страже профессионального качества", "desc": "Статья представляет новый подход к ретуши фотографий с
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#architecture", "#training", "#optimization"], "emoji": "🧠", "ru": {"title": "Унификация MoE в Transformer: повышение эффективности через переосмысление внимания", "desc": "Статья представляет новый подход к архитектуре Разреженной смеси экспертов (Sparse Mixture of Experts, MoE) дл
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#leakage", "#benchmark", "#evaluation"], "emoji": "🏆", "ru": {"title": "Соревнования по ИИ - ключ к надежной оценке генеративных моделей", "desc": "Эта статья рассматривает кризис в эмпирической оценке генеративного ИИ, указывая на недостаточность традиционных методов оценки машинно
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#diffusion", "#agents", "#robotics", "#optimization"], "emoji": "🤖", "ru": {"title": "Иерархическое обучение для улучшения визуомоторного контроля роботов", "desc": "Статья представляет новый подход к обучению визуомоторной политики для робототехнической манипуляции - Триединую Иера
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#optimization", "#data", "#diffusion", "#training", "#architecture"], "emoji": "🔄", "ru": {"title": "Непрерывное визуальное авторегрессионное моделирование без квантования", "desc": "Статья представляет новый подход к визуальному авторегрессионному моделированию (VAR) для непрерывны
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#open_source", "#training", "#optimization", "#rl", "#dataset", "#reasoning"], "emoji": "🌐", "ru": {"title": "Глобальное распределенное обучение с подкреплением для крупномасштабных языковых моделей", "desc": "INTELLECT-2 представляет собой первую глобально распределенную систему об
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#multimodal", "#small_models", "#dataset", "#data"], "emoji": "🎧", "ru": {"title": "LlamaPIE: Незаметный помощник для живых разговоров", "desc": "LlamaPIE - это первый в реальном времени проактивный ассистент, разработанный для улучшения человеческих разговоров через незаметные, кра
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#benchmark", "#training", "#architecture", "#long_context"], "emoji": "🧠", "ru": {"title": "Чанки побеждают рекуррентность в обработке длинных контекстов", "desc": "Исследование фокусируется на рекуррентных суб-квадратичных моделях для обработки длинных контекстов в больших языковых
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#rag", "#optimization", "#interpretability", "#rl"], "emoji": "🔄", "ru": {"title": "Динамическая оптимизация извлечения знаний для генеративных ИИ-систем", "desc": "DynamicRAG - это новая система генерации с извлечением информации (RAG), использующая динамический ранжировщик докумен
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#training", "#interpretability", "#multimodal", "#hallucinations"], "emoji": "🔍", "ru": {"title": "Повышение надежности атрибуции в LLM: от текстового включения до механизма внимания", "desc": "Эта статья посвящена проблеме атрибуции в больших языковых моделях (LLM) при работе с док
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#data", "#optimization", "#dataset", "#graphs", "#architecture", "#training"], "emoji": "🌎", "ru": {"title": "PASSAT: Физически обоснованный прогноз погоды с учетом топологии Земли", "desc": "PASSAT - это новая модель глубокого обучения для прогнозирования погоды, учитывающая физику
[14.05.2025 06:16] Using data from previous issue: {"categories": ["#training", "#dataset", "#science", "#data", "#optimization"], "emoji": "🧬", "ru": {"title": "Многоцелевая оптимизация биологических последовательностей с помощью дискретного сопоставления потоков", "desc": "Статья представляет новый метод машинного обучения под названием Multi-Obje
[14.05.2025 06:16] Loading Chinese text from previous data.
[14.05.2025 06:16] Renaming data file.
[14.05.2025 06:16] Renaming previous data. hf_papers.json to ./d/2025-05-14.json
[14.05.2025 06:16] Saving new data file.
[14.05.2025 06:16] Generating page.
[14.05.2025 06:16] Renaming previous page.
[14.05.2025 06:16] Renaming previous data. index.html to ./d/2025-05-14.html
[14.05.2025 06:16] [Experimental] Generating Chinese page for reading.
[14.05.2025 06:16] Chinese vocab [{'word': '介绍', 'pinyin': 'jiè shào', 'trans': 'introduce'}, {'word': 'Seed1.5-VL', 'pinyin': 'Seed1.5-VL', 'trans': 'Seed1.5-VL'}, {'word': '推进', 'pinyin': 'tuī jìn', 'trans': 'promote'}, {'word': '通用', 'pinyin': 'tōng yòng', 'trans': 'general'}, {'word': '多模态', 'pinyin': 'duō mó shuài', 'trans': 'multimodal'}, {'word': '理解', 'pinyin': 'lǐ jiě', 'trans': 'understanding'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'}, {'word': '语言', 'pinyin': 'yǔ yán', 'trans': 'language'}, {'word': '基础模型', 'pinyin': 'jī chǔ mó xíng', 'trans': 'foundation model'}, {'word': '由', 'pinyin': 'yóu', 'trans': 'consist of'}, {'word': '参数', 'pinyin': 'cān shǔ', 'trans': 'parameters'}, {'word': '视觉编码器', 'pinyin': 'shì jué biān mǎ qì', 'trans': 'visual encoder'}, {'word': '混合专家', 'pinyin': 'hùn hé zhuān jiā', 'trans': 'mixture of experts'}, {'word': 'LLM', 'pinyin': 'LLM', 'trans': 'LLM'}, {'word': '组成', 'pinyin': 'zǔ chéng', 'trans': 'composed of'}, {'word': '尽管', 'pinyin': 'jǐn guǎn', 'trans': 'although'}, {'word': '架构', 'pinyin': 'jià gòu', 'trans': 'architecture'}, {'word': '相对', 'pinyin': 'xiāng duì', 'trans': 'relatively'}, {'word': '紧凑', 'pinyin': 'jǐn còu', 'trans': 'compact'}, {'word': '但', 'pinyin': 'dàn', 'trans': 'but'}, {'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'}, {'word': '出色', 'pinyin': 'chū sè', 'trans': 'outstanding'}, {'word': '公共', 'pinyin': 'gōng gòng', 'trans': 'public'}, {'word': '基准测试', 'pinyin': 'jī zhǔn cè shì', 'trans': 'benchmark tests'}, {'word': '代理任务', 'pinyin': 'dài lǐ rèn wù', 'trans': 'proxy tasks'}, {'word': '优于', 'pinyin': 'yōu yú', 'trans': 'superior to'}, {'word': 'OpenAI', 'pinyin': 'OpenAI', 'trans': 'OpenAI'}, {'word': 'CUA', 'pinyin': 'CUA', 'trans': 'CUA'}, {'word': 'Claude', 'pinyin': 'Claude', 'trans': 'Claude'}, {'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'}, {'word': '强大', 'pinyin': 'qiáng dà', 'trans': 'powerful'}, {'word': '适用于', 'pinyin': 'shì yòng yú', 'trans': 'applicable to'}, {'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'}, {'word': '希望', 'pinyin': 'xī wàng', 'trans': 'hope'}, {'word': '推动', 'pinyin': 'tuī dòng', 'trans': 'drive'}, {'word': '广泛', 'pinyin': 'guǎng fàn', 'trans': 'widespread'}, {'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'application'}]
[14.05.2025 06:16] Renaming previous Chinese page.
[14.05.2025 06:16] Renaming previous data. zh.html to ./d/2025-05-13_zh_reading_task.html
[14.05.2025 06:16] Writing Chinese reading task.
[14.05.2025 06:16] Writing result.
[14.05.2025 06:16] Renaming log file.
[14.05.2025 06:16] Renaming previous data. log.txt to ./logs/2025-05-14_last_log.txt
