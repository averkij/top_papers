[16.11.2024 06:29] Read previous papers.
[16.11.2024 06:29] Generating top page (month).
[16.11.2024 06:29] Writing top page (month).
[16.11.2024 12:40] Read previous papers.
[16.11.2024 12:40] Get feed.
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09595
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09703
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.09009
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06469
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.08768
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.08954
[16.11.2024 12:40] Get page data from previous paper. URL: https://huggingface.co/papers/2411.06490
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 0. This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling con...
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 1. Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques. In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas. Our system features a streamlined yet functionally robust interfa...
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 2. As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabu...
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 3. Large Language Models (LLMs) hold great promise to revolutionize current clinical systems for their superior capacities on medical text processing tasks and medical licensing exams. Meanwhile, traditional ML models such as SVM and XGBoost have still been mainly adopted in clinical prediction tasks. ...
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 4. ...
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 5. ...
[16.11.2024 12:40] ********************************************************************************
[16.11.2024 12:40] Abstract 6. ...
[16.11.2024 12:40] Read previous papers.
[16.11.2024 12:40] Generating reviews via LLM API.
[16.11.2024 12:40] Using data from previous issue: {"categories": ["#optimization", "#games", "#3d", "#multimodal", "#training"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ¯Ğ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑƒÑ‡Ğ°Ñ‚ÑÑ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ 3D-Ğ¼Ğ¸Ñ€Ñ‹", "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ LLaMA-Mesh
[16.11.2024 12:40] Using data from previous issue: {"categories": ["#diffusion", "#multimodal", "#cv"], "emoji": "ğŸ–Œï¸", "ru": {"title": "MagicQuill: Ğ˜Ğ½Ñ‚ÑƒĞ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜", "desc": "MagicQuill - ÑÑ‚Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ±Ğ¾Ğ»ÑŒÑˆÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (MLLM) Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°
[16.11.2024 12:40] Using data from previous issue: {"categories": ["#optimization", "#training", "#inference"], "emoji": "ğŸ§ ", "ru": {"title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸: ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹", "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Cut Cross-Entropy (CCE) Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ² ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. CCE Ğ·Ğ½
[16.11.2024 12:40] Using data from previous issue: {"categories": ["#science", "#benchmark", "#healthcare", "#reasoning"], "emoji": "ğŸ¥", "ru": {"title": "LLM vs Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ ML: ĞºÑ‚Ğ¾ Ğ¿Ğ¾Ğ±ĞµĞ´Ğ¸Ñ‚ Ğ² ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸?", "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº ClinicalBench Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¸ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´
[16.11.2024 12:40] Using data from previous issue: {"categories": [], "emoji": "ğŸš€", "ru": {"title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ, ÑĞ¾Ñ‡ĞµÑ‚Ğ°ÑÑ‰Ñƒ
[16.11.2024 12:40] Using data from previous issue: {"categories": [], "emoji": "ğŸš€", "ru": {"title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ AI", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ñ Ğ¿Ğ¾
[16.11.2024 12:40] Using data from previous issue: {"categories": [], "emoji": "ğŸš€", "ru": {"title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°", "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ, ÑĞ¾Ñ‡ĞµÑ‚Ğ°ÑÑ‰Ñƒ
[16.11.2024 12:40] Trying to get texts in Chinese.
[16.11.2024 12:40] Mistral request. Model: mistral-large-latest. Prompt: Write simple and brief explanation (4-5 sentences) of an article in Chinese. Use short sentences. Text:

This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling conversational 3D generation and mesh understanding. A primary challenge is effectively tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly. To address this, we introduce LLaMA-Mesh, a novel approach that represents the vertex coordinates and face definitions of 3D meshes as plain text, allowing direct integration with LLMs without expanding the vocabulary. We construct a supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate 3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs as required, and (3) understand and interpret 3D meshes. Our work is the first to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge for 3D mesh generation in a text-based format, effectively unifying the 3D and text modalities. LLaMA-Mesh achieves mesh generation quality on par with models trained from scratch while maintaining strong text generation performance.
[16.11.2024 12:40] Mistral response. {"id": "2c4a317b5c2b4654bf789f1f1bd22571", "object": "chat.completion", "created": 1731760805, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "\u8fd9\u7bc7\u6587\u7ae0\u63a2\u8ba8\u4e86\u6269\u5c55\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u62103D\u7f51\u683c\u7684\u80fd\u529b\u3002\u5b83\u5229\u7528LLMs\u4e2d\u4ece\u6587\u672c\u6765\u6e90\uff08\u59823D\u6559\u7a0b\uff09\u83b7\u5f97\u7684\u7a7a\u95f4\u77e5\u8bc6\uff0c\u5e76\u5b9e\u73b0\u5bf9\u8bdd\u5f0f3D\u751f\u6210\u548c\u7f51\u683c\u7406\u89e3\u3002\u6587\u7ae0\u4ecb\u7ecd\u4e86LLaMA-Mesh\uff0c\u4e00\u79cd\u5c063D\u7f51\u683c\u6570\u636e\u8868\u793a\u4e3a\u7eaf\u6587\u672c\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7fLLMs\u80fd\u76f4\u63a5\u5904\u7406\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u6570\u636e\u96c6\uff0cLLMs\u53ef\u4ee5\u751f\u62103D\u7f51\u683c\u3001\u4ea7\u751f\u4ea4\u66ff\u7684\u6587\u672c\u548c3D\u7f51\u683c\u8f93\u51fa\uff0c\u5e76\u7406\u89e3\u548c\u89e3\u91ca3D\u7f51\u683c\u3002\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u5c55\u793a\u4e86LLMs\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u83b7\u5f97\u590d\u6742\u7684\u7a7a\u95f4\u77e5\u8bc6\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u76843D\u7f51\u683c\u3002", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 308, "total_tokens": 511, "completion_tokens": 203}}
[16.11.2024 12:40] Response: è¿™ç¯‡æ–‡ç« æ¢è®¨äº†æ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆ3Dç½‘æ ¼çš„èƒ½åŠ›ã€‚å®ƒåˆ©ç”¨LLMsä¸­ä»æ–‡æœ¬æ¥æºï¼ˆå¦‚3Dæ•™ç¨‹ï¼‰è·å¾—çš„ç©ºé—´çŸ¥è¯†ï¼Œå¹¶å®ç°å¯¹è¯å¼3Dç”Ÿæˆå’Œç½‘æ ¼ç†è§£ã€‚æ–‡ç« ä»‹ç»äº†LLaMA-Meshï¼Œä¸€ç§å°†3Dç½‘æ ¼æ•°æ®è¡¨ç¤ºä¸ºçº¯æ–‡æœ¬çš„æ–°æ–¹æ³•ï¼Œä½¿LLMsèƒ½ç›´æ¥å¤„ç†ã€‚é€šè¿‡ç›‘ç£å¾®è°ƒæ•°æ®é›†ï¼ŒLLMså¯ä»¥ç”Ÿæˆ3Dç½‘æ ¼ã€äº§ç”Ÿäº¤æ›¿çš„æ–‡æœ¬å’Œ3Dç½‘æ ¼è¾“å‡ºï¼Œå¹¶ç†è§£å’Œè§£é‡Š3Dç½‘æ ¼ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡å±•ç¤ºäº†LLMså¯ä»¥é€šè¿‡å¾®è°ƒè·å¾—å¤æ‚çš„ç©ºé—´çŸ¥è¯†ï¼Œç”Ÿæˆé«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚
[16.11.2024 12:40] Mistral request. Model: mistral-large-latest. Prompt: Write pinyin transcription for text. Text:

è¿™ç¯‡æ–‡ç« æ¢è®¨äº†æ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆ3Dç½‘æ ¼çš„èƒ½åŠ›ã€‚å®ƒåˆ©ç”¨LLMsä¸­ä»æ–‡æœ¬æ¥æºï¼ˆå¦‚3Dæ•™ç¨‹ï¼‰è·å¾—çš„ç©ºé—´çŸ¥è¯†ï¼Œå¹¶å®ç°å¯¹è¯å¼3Dç”Ÿæˆå’Œç½‘æ ¼ç†è§£ã€‚æ–‡ç« ä»‹ç»äº†LLaMA-Meshï¼Œä¸€ç§å°†3Dç½‘æ ¼æ•°æ®è¡¨ç¤ºä¸ºçº¯æ–‡æœ¬çš„æ–°æ–¹æ³•ï¼Œä½¿LLMsèƒ½ç›´æ¥å¤„ç†ã€‚é€šè¿‡ç›‘ç£å¾®è°ƒæ•°æ®é›†ï¼ŒLLMså¯ä»¥ç”Ÿæˆ3Dç½‘æ ¼ã€äº§ç”Ÿäº¤æ›¿çš„æ–‡æœ¬å’Œ3Dç½‘æ ¼è¾“å‡ºï¼Œå¹¶ç†è§£å’Œè§£é‡Š3Dç½‘æ ¼ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡å±•ç¤ºäº†LLMså¯ä»¥é€šè¿‡å¾®è°ƒè·å¾—å¤æ‚çš„ç©ºé—´çŸ¥è¯†ï¼Œç”Ÿæˆé«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚
[16.11.2024 12:40] Mistral response. {"id": "a0b71aee670c45b4a5cf4788952e17b4", "object": "chat.completion", "created": 1731760810, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "Zh\u00e8 pi\u0101n w\u00e9nzh\u0101ng t\u00e0nt\u01ceo le ku\u00f2zh\u01cen d\u00e0x\u00edng y\u01d4y\u00e1n m\u00f3x\u00edng (LLMs) sh\u0113ngch\u00e9ng 3D w\u01cengg\u00e9 de n\u00e9ngl\u00ec. T\u0101 l\u00ecy\u00f2ng LLMs zh\u014dng c\u00f3ng w\u00e9nb\u011bn l\u00e1iyu\u00e1n (r\u00fa 3D ji\u00e0ocheng) hu\u00f2d\u00e9 k\u014dngji\u00e0n zh\u012bshi, b\u00ecng sh\u00edxi\u00e0n du\u00echu\u00e0 sh\u00ec 3D sh\u0113ngch\u00e9ng h\u00e9 w\u01cengg\u00e9 l\u01d0ji\u011b. W\u00e9nzh\u0101ng ji\u00e8sh\u00e0o le LLaMA-Mesh, y\u012bzh\u01d2ng b\u01ce 3D w\u01cengg\u00e9 sh\u00f9j\u00f9 bi\u01ceosh\u00ec w\u00e9i ch\u00fan w\u00e9nb\u011bn de x\u012bn f\u0101ngf\u01ce, sh\u01d0 LLMs n\u00e9ng zh\u00edji\u0113 ch\u01d4l\u01d0. T\u014dnggu\u00f2 ji\u0101nd\u016b w\u0113iti\u00e1o sh\u00f9j\u00f9j\u00ed, LLMs k\u011by\u01d0 sh\u0113ngch\u00e9ng 3D w\u01cengg\u00e9, ch\u01censh\u0113ng ji\u0101ot\u00ec de w\u00e9nb\u011bn h\u00e9 3D w\u01cengg\u00e9 sh\u016br\u00f9, b\u00ecng l\u01d0ji\u011b h\u00e9 ji\u011bsh\u00ec 3D w\u01cengg\u00e9. Zh\u00e8 xi\u00e0ng g\u014dngzu\u00f2 sh\u01d2uc\u00ec zh\u01censh\u00ec LLMs k\u011by\u01d0 t\u014dnggu\u00f2 w\u0113iti\u00e1o hu\u00f2d\u00e9 f\u00f9z\u00e1 de k\u014dngji\u00e0n zh\u012bshi, sh\u0113ngch\u00e9ng g\u0101o zh\u00ecli\u00e0ng de 3D w\u01cengg\u00e9.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 218, "total_tokens": 618, "completion_tokens": 400}}
[16.11.2024 12:40] Response: ZhÃ¨ piÄn wÃ©nzhÄng tÃ ntÇo le kuÃ²zhÇn dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng (LLMs) shÄ“ngchÃ©ng 3D wÇnggÃ© de nÃ©nglÃ¬. TÄ lÃ¬yÃ²ng LLMs zhÅng cÃ³ng wÃ©nbÄ›n lÃ¡iyuÃ¡n (rÃº 3D jiÃ ocheng) huÃ²dÃ© kÅngjiÃ n zhÄ«shi, bÃ¬ng shÃ­xiÃ n duÃ¬huÃ  shÃ¬ 3D shÄ“ngchÃ©ng hÃ© wÇnggÃ© lÇjiÄ›. WÃ©nzhÄng jiÃ¨shÃ o le LLaMA-Mesh, yÄ«zhÇ’ng bÇ 3D wÇnggÃ© shÃ¹jÃ¹ biÇoshÃ¬ wÃ©i chÃºn wÃ©nbÄ›n de xÄ«n fÄngfÇ, shÇ LLMs nÃ©ng zhÃ­jiÄ“ chÇ”lÇ. TÅngguÃ² jiÄndÅ« wÄ“itiÃ¡o shÃ¹jÃ¹jÃ­, LLMs kÄ›yÇ shÄ“ngchÃ©ng 3D wÇnggÃ©, chÇnshÄ“ng jiÄotÃ¬ de wÃ©nbÄ›n hÃ© 3D wÇnggÃ© shÅ«rÃ¹, bÃ¬ng lÇjiÄ› hÃ© jiÄ›shÃ¬ 3D wÇnggÃ©. ZhÃ¨ xiÃ ng gÅngzuÃ² shÇ’ucÃ¬ zhÇnshÃ¬ LLMs kÄ›yÇ tÅngguÃ² wÄ“itiÃ¡o huÃ²dÃ© fÃ¹zÃ¡ de kÅngjiÃ n zhÄ«shi, shÄ“ngchÃ©ng gÄo zhÃ¬liÃ ng de 3D wÇnggÃ©.
[16.11.2024 12:40] Mistral request. Model: mistral-large-latest. Prompt: Write vocab of difficult words for this text as an array of objects with fields 'word', 'pinyin', 'trans'. Return as python list without formatting. Return list and nothing else. Text:

è¿™ç¯‡æ–‡ç« æ¢è®¨äº†æ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆ3Dç½‘æ ¼çš„èƒ½åŠ›ã€‚å®ƒåˆ©ç”¨LLMsä¸­ä»æ–‡æœ¬æ¥æºï¼ˆå¦‚3Dæ•™ç¨‹ï¼‰è·å¾—çš„ç©ºé—´çŸ¥è¯†ï¼Œå¹¶å®ç°å¯¹è¯å¼3Dç”Ÿæˆå’Œç½‘æ ¼ç†è§£ã€‚æ–‡ç« ä»‹ç»äº†LLaMA-Meshï¼Œä¸€ç§å°†3Dç½‘æ ¼æ•°æ®è¡¨ç¤ºä¸ºçº¯æ–‡æœ¬çš„æ–°æ–¹æ³•ï¼Œä½¿LLMsèƒ½ç›´æ¥å¤„ç†ã€‚é€šè¿‡ç›‘ç£å¾®è°ƒæ•°æ®é›†ï¼ŒLLMså¯ä»¥ç”Ÿæˆ3Dç½‘æ ¼ã€äº§ç”Ÿäº¤æ›¿çš„æ–‡æœ¬å’Œ3Dç½‘æ ¼è¾“å‡ºï¼Œå¹¶ç†è§£å’Œè§£é‡Š3Dç½‘æ ¼ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡å±•ç¤ºäº†LLMså¯ä»¥é€šè¿‡å¾®è°ƒè·å¾—å¤æ‚çš„ç©ºé—´çŸ¥è¯†ï¼Œç”Ÿæˆé«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚
[16.11.2024 12:40] Mistral response. {"id": "ee0d3779149047afabf5edf740e93b2e", "object": "chat.completion", "created": 1731760825, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "[\n    {\"word\": \"\u6269\u5c55\", \"pinyin\": \"ku\u00f2zh\u01cen\", \"trans\": \"extend\"},\n    {\"word\": \"\u5927\u578b\u8bed\u8a00\u6a21\u578b\", \"pinyin\": \"d\u00e0x\u00edng y\u01d4y\u00e1n m\u00f3x\u00edng\", \"trans\": \"large language models\"},\n    {\"word\": \"\u751f\u6210\", \"pinyin\": \"sh\u0113ngch\u00e9ng\", \"trans\": \"generate\"},\n    {\"word\": \"3D\u7f51\u683c\", \"pinyin\": \"3D w\u01cengg\u00e9\", \"trans\": \"3D mesh\"},\n    {\"word\": \"\u80fd\u529b\", \"pinyin\": \"n\u00e9ngl\u00ec\", \"trans\": \"ability\"},\n    {\"word\": \"\u5229\u7528\", \"pinyin\": \"l\u00ecy\u00f2ng\", \"trans\": \"utilize\"},\n    {\"word\": \"\u7a7a\u95f4\u77e5\u8bc6\", \"pinyin\": \"k\u014dngji\u0101n zh\u012bshi\", \"trans\": \"spatial knowledge\"},\n    {\"word\": \"\u6587\u672c\u6765\u6e90\", \"pinyin\": \"w\u00e9nb\u011bn l\u00e1iyu\u00e1n\", \"trans\": \"textual sources\"},\n    {\"word\": \"\u5b9e\u73b0\", \"pinyin\": \"sh\u00edxi\u00e0n\", \"trans\": \"achieve\"},\n    {\"word\": \"\u5bf9\u8bdd\u5f0f\", \"pinyin\": \"du\u00echu\u00e0sh\u00ec\", \"trans\": \"conversational\"},\n    {\"word\": \"\u7406\u89e3\", \"pinyin\": \"l\u01d0ji\u011b\", \"trans\": \"understand\"},\n    {\"word\": \"\u4ecb\u7ecd\", \"pinyin\": \"ji\u00e8sh\u00e0o\", \"trans\": \"introduce\"},\n    {\"word\": \"LLaMA-Mesh\", \"pinyin\": \"LLaMA-Mesh\", \"trans\": \"LLaMA-Mesh\"},\n    {\"word\": \"\u8868\u793a\", \"pinyin\": \"bi\u01ceosh\u00ec\", \"trans\": \"represent\"},\n    {\"word\": \"\u7eaf\u6587\u672c\", \"pinyin\": \"ch\u00fan w\u00e9nb\u011bn\", \"trans\": \"pure text\"},\n    {\"word\": \"\u76f4\u63a5\u5904\u7406\", \"pinyin\": \"zh\u00edji\u0113 ch\u01d4l\u01d0\", \"trans\": \"directly process\"},\n    {\"word\": \"\u76d1\u7763\u5fae\u8c03\", \"pinyin\": \"ji\u0101nd\u016b w\u0113iti\u00e1o\", \"trans\": \"supervised fine-tuning\"},\n    {\"word\": \"\u6570\u636e\u96c6\", \"pinyin\": \"sh\u00f9j\u00f9j\u00ed\", \"trans\": \"dataset\"},\n    {\"word\": \"\u4ea7\u751f\", \"pinyin\": \"ch\u01censh\u0113ng\", \"trans\": \"produce\"},\n    {\"word\": \"\u4ea4\u66ff\", \"pinyin\": \"ji\u0101ot\u00ec\", \"trans\": \"alternate\"},\n    {\"word\": \"\u8f93\u51fa\", \"pinyin\": \"sh\u016bch\u016b\", \"trans\": \"output\"},\n    {\"word\": \"\u89e3\u91ca\", \"pinyin\": \"ji\u011bsh\u00ec\", \"trans\": \"explain\"},\n    {\"word\": \"\u9996\u6b21\", \"pinyin\": \"sh\u01d2uc\u00ec\", \"trans\": \"for the first time\"},\n    {\"word\": \"\u5c55\u793a\", \"pinyin\": \"zh\u01censh\u00ec\", \"trans\": \"demonstrate\"},\n    {\"word\": \"\u5fae\u8c03\", \"pinyin\": \"w\u0113iti\u00e1o\", \"trans\": \"fine-tuning\"},\n    {\"word\": \"\u590d\u6742\", \"pinyin\": \"f\u00f9z\u00e1\", \"trans\": \"complex\"},\n    {\"word\": \"\u9ad8\u8d28\u91cf\", \"pinyin\": \"g\u0101o zh\u00ecli\u00e0ng\", \"trans\": \"high quality\"}\n]", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 250, "total_tokens": 1079, "completion_tokens": 829}}
[16.11.2024 12:40] Response: [
    {"word": "æ‰©å±•", "pinyin": "kuÃ²zhÇn", "trans": "extend"},
    {"word": "å¤§å‹è¯­è¨€æ¨¡å‹", "pinyin": "dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng", "trans": "large language models"},
    {"word": "ç”Ÿæˆ", "pinyin": "shÄ“ngchÃ©ng", "trans": "generate"},
    {"word": "3Dç½‘æ ¼", "pinyin": "3D wÇnggÃ©", "trans": "3D mesh"},
    {"word": "èƒ½åŠ›", "pinyin": "nÃ©nglÃ¬", "trans": "ability"},
    {"word": "åˆ©ç”¨", "pinyin": "lÃ¬yÃ²ng", "trans": "utilize"},
    {"word": "ç©ºé—´çŸ¥è¯†", "pinyin": "kÅngjiÄn zhÄ«shi", "trans": "spatial knowledge"},
    {"word": "æ–‡æœ¬æ¥æº", "pinyin": "wÃ©nbÄ›n lÃ¡iyuÃ¡n", "trans": "textual sources"},
    {"word": "å®ç°", "pinyin": "shÃ­xiÃ n", "trans": "achieve"},
    {"word": "å¯¹è¯å¼", "pinyin": "duÃ¬huÃ shÃ¬", "trans": "conversational"},
    {"word": "ç†è§£", "pinyin": "lÇjiÄ›", "trans": "understand"},
    {"word": "ä»‹ç»", "pinyin": "jiÃ¨shÃ o", "trans": "introduce"},
    {"word": "LLaMA-Mesh", "pinyin": "LLaMA-Mesh", "trans": "LLaMA-Mesh"},
    {"word": "è¡¨ç¤º", "pinyin": "biÇoshÃ¬", "trans": "represent"},
    {"word": "çº¯æ–‡æœ¬", "pinyin": "chÃºn wÃ©nbÄ›n", "trans": "pure text"},
    {"word": "ç›´æ¥å¤„ç†", "pinyin": "zhÃ­jiÄ“ chÇ”lÇ", "trans": "directly process"},
    {"word": "ç›‘ç£å¾®è°ƒ", "pinyin": "jiÄndÅ« wÄ“itiÃ¡o", "trans": "supervised fine-tuning"},
    {"word": "æ•°æ®é›†", "pinyin": "shÃ¹jÃ¹jÃ­", "trans": "dataset"},
    {"word": "äº§ç”Ÿ", "pinyin": "chÇnshÄ“ng", "trans": "produce"},
    {"word": "äº¤æ›¿", "pinyin": "jiÄotÃ¬", "trans": "alternate"},
    {"word": "è¾“å‡º", "pinyin": "shÅ«chÅ«", "trans": "output"},
    {"word": "è§£é‡Š", "pinyin": "jiÄ›shÃ¬", "trans": "explain"},
    {"word": "é¦–æ¬¡", "pinyin": "shÇ’ucÃ¬", "trans": "for the first time"},
    {"word": "å±•ç¤º", "pinyin": "zhÇnshÃ¬", "trans": "demonstrate"},
    {"word": "å¾®è°ƒ", "pinyin": "wÄ“itiÃ¡o", "trans": "fine-tuning"},
    {"word": "å¤æ‚", "pinyin": "fÃ¹zÃ¡", "trans": "complex"},
    {"word": "é«˜è´¨é‡", "pinyin": "gÄo zhÃ¬liÃ ng", "trans": "high quality"}
]
[16.11.2024 12:40] Mistral request. Model: mistral-large-latest. Prompt: Translate this text in English. Text:

è¿™ç¯‡æ–‡ç« æ¢è®¨äº†æ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆ3Dç½‘æ ¼çš„èƒ½åŠ›ã€‚å®ƒåˆ©ç”¨LLMsä¸­ä»æ–‡æœ¬æ¥æºï¼ˆå¦‚3Dæ•™ç¨‹ï¼‰è·å¾—çš„ç©ºé—´çŸ¥è¯†ï¼Œå¹¶å®ç°å¯¹è¯å¼3Dç”Ÿæˆå’Œç½‘æ ¼ç†è§£ã€‚æ–‡ç« ä»‹ç»äº†LLaMA-Meshï¼Œä¸€ç§å°†3Dç½‘æ ¼æ•°æ®è¡¨ç¤ºä¸ºçº¯æ–‡æœ¬çš„æ–°æ–¹æ³•ï¼Œä½¿LLMsèƒ½ç›´æ¥å¤„ç†ã€‚é€šè¿‡ç›‘ç£å¾®è°ƒæ•°æ®é›†ï¼ŒLLMså¯ä»¥ç”Ÿæˆ3Dç½‘æ ¼ã€äº§ç”Ÿäº¤æ›¿çš„æ–‡æœ¬å’Œ3Dç½‘æ ¼è¾“å‡ºï¼Œå¹¶ç†è§£å’Œè§£é‡Š3Dç½‘æ ¼ã€‚è¿™é¡¹å·¥ä½œé¦–æ¬¡å±•ç¤ºäº†LLMså¯ä»¥é€šè¿‡å¾®è°ƒè·å¾—å¤æ‚çš„ç©ºé—´çŸ¥è¯†ï¼Œç”Ÿæˆé«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚
[16.11.2024 12:40] Mistral response. {"id": "7d73278b82ae46f4ab691ae235c93e63", "object": "chat.completion", "created": 1731760852, "model": "mistral-large-latest", "choices": [{"index": 0, "message": {"role": "assistant", "content": "This article explores the capability of extending large language models (LLMs) to generate 3D meshes. It leverages spatial knowledge derived from textual sources, such as 3D tutorials, within LLMs to achieve conversational 3D generation and mesh understanding. The article introduces LLaMA-Mesh, a new method for representing 3D mesh data as pure text, enabling LLMs to process it directly. Through a supervised fine-tuning dataset, LLMs can generate 3D meshes, produce alternating text and 3D mesh outputs, and understand and interpret 3D meshes. This work demonstrates for the first time that LLMs can acquire complex spatial knowledge through fine-tuning to generate high-quality 3D meshes.", "tool_calls": null}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 216, "total_tokens": 378, "completion_tokens": 162}}
[16.11.2024 12:40] Response: This article explores the capability of extending large language models (LLMs) to generate 3D meshes. It leverages spatial knowledge derived from textual sources, such as 3D tutorials, within LLMs to achieve conversational 3D generation and mesh understanding. The article introduces LLaMA-Mesh, a new method for representing 3D mesh data as pure text, enabling LLMs to process it directly. Through a supervised fine-tuning dataset, LLMs can generate 3D meshes, produce alternating text and 3D mesh outputs, and understand and interpret 3D meshes. This work demonstrates for the first time that LLMs can acquire complex spatial knowledge through fine-tuning to generate high-quality 3D meshes.
[16.11.2024 12:40] Renaming data file.
[16.11.2024 12:40] Renaming previous data. hf_papers.json to ./d/2024-11-15.json
[16.11.2024 12:40] Saving new data file.
[16.11.2024 12:40] Generating page.
[16.11.2024 12:40] Renaming previous page.
[16.11.2024 12:40] Renaming previous data. index.html to ./d/2024-11-15.html
[16.11.2024 12:40] [Experimental] Generating Chinese page for reading.
[16.11.2024 12:40] Chinese vocab [{'word': 'æ‰©å±•', 'pinyin': 'kuÃ²zhÇn', 'trans': 'extend'}, {'word': 'å¤§å‹è¯­è¨€æ¨¡å‹', 'pinyin': 'dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng', 'trans': 'large language models'}, {'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generate'}, {'word': '3Dç½‘æ ¼', 'pinyin': '3D wÇnggÃ©', 'trans': '3D mesh'}, {'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©nglÃ¬', 'trans': 'ability'}, {'word': 'åˆ©ç”¨', 'pinyin': 'lÃ¬yÃ²ng', 'trans': 'utilize'}, {'word': 'ç©ºé—´çŸ¥è¯†', 'pinyin': 'kÅngjiÄn zhÄ«shi', 'trans': 'spatial knowledge'}, {'word': 'æ–‡æœ¬æ¥æº', 'pinyin': 'wÃ©nbÄ›n lÃ¡iyuÃ¡n', 'trans': 'textual sources'}, {'word': 'å®ç°', 'pinyin': 'shÃ­xiÃ n', 'trans': 'achieve'}, {'word': 'å¯¹è¯å¼', 'pinyin': 'duÃ¬huÃ shÃ¬', 'trans': 'conversational'}, {'word': 'ç†è§£', 'pinyin': 'lÇjiÄ›', 'trans': 'understand'}, {'word': 'ä»‹ç»', 'pinyin': 'jiÃ¨shÃ o', 'trans': 'introduce'}, {'word': 'LLaMA-Mesh', 'pinyin': 'LLaMA-Mesh', 'trans': 'LLaMA-Mesh'}, {'word': 'è¡¨ç¤º', 'pinyin': 'biÇoshÃ¬', 'trans': 'represent'}, {'word': 'çº¯æ–‡æœ¬', 'pinyin': 'chÃºn wÃ©nbÄ›n', 'trans': 'pure text'}, {'word': 'ç›´æ¥å¤„ç†', 'pinyin': 'zhÃ­jiÄ“ chÇ”lÇ', 'trans': 'directly process'}, {'word': 'ç›‘ç£å¾®è°ƒ', 'pinyin': 'jiÄndÅ« wÄ“itiÃ¡o', 'trans': 'supervised fine-tuning'}, {'word': 'æ•°æ®é›†', 'pinyin': 'shÃ¹jÃ¹jÃ­', 'trans': 'dataset'}, {'word': 'äº§ç”Ÿ', 'pinyin': 'chÇnshÄ“ng', 'trans': 'produce'}, {'word': 'äº¤æ›¿', 'pinyin': 'jiÄotÃ¬', 'trans': 'alternate'}, {'word': 'è¾“å‡º', 'pinyin': 'shÅ«chÅ«', 'trans': 'output'}, {'word': 'è§£é‡Š', 'pinyin': 'jiÄ›shÃ¬', 'trans': 'explain'}, {'word': 'é¦–æ¬¡', 'pinyin': 'shÇ’ucÃ¬', 'trans': 'for the first time'}, {'word': 'å±•ç¤º', 'pinyin': 'zhÇnshÃ¬', 'trans': 'demonstrate'}, {'word': 'å¾®è°ƒ', 'pinyin': 'wÄ“itiÃ¡o', 'trans': 'fine-tuning'}, {'word': 'å¤æ‚', 'pinyin': 'fÃ¹zÃ¡', 'trans': 'complex'}, {'word': 'é«˜è´¨é‡', 'pinyin': 'gÄo zhÃ¬liÃ ng', 'trans': 'high quality'}]
[16.11.2024 12:40] Renaming previous Chinese page.
[16.11.2024 12:40] Renaming previous data. zh.html to ./d/2024-11-15_zh_reading_task.html
[16.11.2024 12:40] Writing Chinese reading task.
[16.11.2024 12:40] Writing result.
[16.11.2024 12:40] Renaming log file.
[16.11.2024 12:40] Renaming previous data. log.txt to ./logs/2024-11-16_last_log.txt
