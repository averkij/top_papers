[26.08.2025 16:14] Read previous papers.
[26.08.2025 16:14] Generating top page (month).
[26.08.2025 16:14] Writing top page (month).
[26.08.2025 17:10] Read previous papers.
[26.08.2025 17:10] Get feed.
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18265
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18032
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16577
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17472
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16949
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16745
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17188
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17580
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17290
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17298
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.16790
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18190
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18159
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17973
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17821
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17811
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.18076
[26.08.2025 17:10] Get page data from previous paper. URL: https://huggingface.co/papers/2508.17061
[26.08.2025 17:10] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[26.08.2025 17:10] No deleted papers detected.
[26.08.2025 17:10] Downloading and parsing papers (pdf, html). Total: 18.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.18265.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.18265.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.18265.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.18032.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.18032.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.18032.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.16577.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.16577.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.16577.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17472.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17472.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17472.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.16949.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.16949.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.16949.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.16745.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.16745.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.16745.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17188.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17188.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17188.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17580.
[26.08.2025 17:10] Downloading paper 2508.17580 from http://arxiv.org/pdf/2508.17580v1...
[26.08.2025 17:10] Failed to download and parse paper https://huggingface.co/papers/2508.17580: maximum recursion depth exceeded
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17290.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17290.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17290.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17298.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17298.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17298.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.16790.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.16790.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.16790.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.18190.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.18190.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.18190.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.18159.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.18159.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.18159.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17973.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17973.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17973.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17821.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17821.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17821.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17811.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17811.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17811.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.18076.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.18076.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.18076.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Downloading and parsing paper https://huggingface.co/papers/2508.17061.
[26.08.2025 17:10] Extra JSON file exists (./assets/json/2508.17061.json), skip PDF parsing.
[26.08.2025 17:10] Paper image links file exists (./assets/img_data/2508.17061.json), skip HTML parsing.
[26.08.2025 17:10] Success.
[26.08.2025 17:10] Enriching papers with extra data.
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 0. InternVL 3.5 introduces Cascade RL, ViR, and DvD to enhance reasoning, efficiency, and performance in multimodal models.  					AI-generated summary 				 We introduce InternVL 3.5, a new family of open-source multimodal models that significantly advances versatility, reasoning capability, and inferen...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 1. The Visual-Chain of Guidance (Visual-CoG) paradigm enhances text-to-image generation by providing stage-aware rewards, improving performance across multiple benchmarks.  					AI-generated summary 				 Despite the promising progress of recent autoregressive models in text-to-image (T2I) generation, t...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 2. MV-RAG enhances text-to-3D generation by retrieving 2D images and conditioning a multiview diffusion model to improve consistency and accuracy, especially for out-of-domain concepts.  					AI-generated summary 				 Text-to-3D generation approaches have advanced significantly by leveraging pretrained...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 3. T2I-ReasonBench evaluates the reasoning capabilities of text-to-image models across four dimensions using a two-stage protocol, analyzing their performance comprehensively.  					AI-generated summary 				 We propose T2I-ReasonBench, a benchmark evaluating reasoning capabilities of text-to-image (T2I...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 4. RuscaRL, a novel instructional scaffolding framework, enhances LLM reasoning by using rubrics for exploration and verifiable rewards, significantly improving performance on reasoning tasks.  					AI-generated summary 				 Recent advances in Large Language Models (LLMs) have underscored the potential...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 5. Models trained on random Boolean functions in a cellular automata framework show that increasing depth, recurrence, memory, and test-time compute scaling enhances multi-step reasoning capabilities.  					AI-generated summary 				 Reasoning is a core capability of large language models, yet understan...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 6. PosterGen, a multi-agent framework using large language models, automates paper-to-poster generation with high design quality and minimal manual refinement.  					AI-generated summary 				 Multi-agent systems built upon large language models (LLMs) have demonstrated remarkable capabilities in tackli...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 7. UQ is a benchmark for evaluating AI models on unsolved questions, combining difficulty and realism to assess capabilities like reasoning, factuality, and browsing.  					AI-generated summary 				 Benchmarks shape progress in AI research. A useful benchmark should be both difficult and realistic: que...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 8. MEENA, a Persian-English dataset, evaluates vision-language models across scientific, reasoning, and human-level understanding tasks, enhancing capabilities beyond English.  					AI-generated summary 				 Recent advancements in large vision-language models (VLMs) have primarily focused on English, w...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 9. A comprehensive survey of compositional visual reasoning from 2023 to 2025 reviews advancements in multimodal AI, highlighting architectural designs, benchmarks, and future directions.  					AI-generated summary 				 Compositional visual reasoning has emerged as a key research frontier in multimodal...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 10. TaDiCodec, a Text-aware Diffusion Transformer Speech Codec, achieves low frame rates and bitrates with superior speech generation performance using end-to-end optimization and text guidance.  					AI-generated summary 				 Speech tokenizers serve as foundational components for speech language models...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 11. ST-Raptor, a tree-based framework using large language models, addresses challenges in answering questions from semi-structured tables by introducing a Hierarchical Orthogonal Tree and a two-stage verification mechanism.  					AI-generated summary 				 Semi-structured tables, widely used in real-wor...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 12. SpotEdit is a benchmark for evaluating visually-guided image editing methods, revealing performance disparities and hallucination issues across diffusion, autoregressive, and hybrid generative models.  					AI-generated summary 				 Visually-guided image editing, where edits are conditioned on both ...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 13. A large-scale German dataset and model for readability-controlled paraphrasing are introduced, achieving state-of-the-art performance in text simplification.  					AI-generated summary 				 The ability to paraphrase texts across different complexity levels is essential for creating accessible texts ...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 14. Theoretical and empirical analysis of softmax normalization in attention mechanisms reveals limitations in token selection and gradient sensitivity, highlighting the need for improved normalization strategies.  					AI-generated summary 				 This paper investigates the limitations of the normalizati...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 15. MeshSplat uses Gaussian Splatting and a feed-forward network to reconstruct surfaces from sparse views, improving accuracy with a Weighted Chamfer Distance Loss and normal prediction.  					AI-generated summary 				 Surface reconstruction has been widely studied in computer vision and graphics. Howe...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 16. The paper critiques the use of large language models as judges for evaluating natural language generation systems, questioning their reliability, capabilities, scalability, and cost-effectiveness.  					AI-generated summary 				 Evaluating natural language generation (NLG) systems remains a core cha...
[26.08.2025 17:10] ********************************************************************************
[26.08.2025 17:10] Abstract 17. A dual-stage generative network framework enhances photorealism in real-time video game rendering by improving inference speed and visual quality.  					AI-generated summary 				 Photorealism is an important aspect of modern video games since it can shape the player experience and simultaneously imp...
[26.08.2025 17:10] Read previous papers.
[26.08.2025 17:10] Generating reviews via LLM API.
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#training", "#agents", "#reasoning", "#architecture", "#inference", "#open_source", "#multimodal", "#rl"], "emoji": "üß†", "ru": {"title": "InternVL 3.5: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º –ò–ò —á–µ—Ä–µ–∑ –∫–∞—Å–∫–∞–¥–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "InternVL 3.5 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–æ–≤–æ–µ —Å–µ–º–µ–π—Å—Ç–≤–æ 
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#games", "#benchmark", "#reasoning", "#rl", "#optimization", "#cv"], "emoji": "üé®", "ru": {"title": "–ü–æ—ç—Ç–∞–ø–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É Visual-Chain of Guidance (Visual-CoG) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#synthetic", "#diffusion", "#3d", "#multimodal", "#benchmark", "#rag"], "emoji": "üñºÔ∏è", "ru": {"title": "–£–ª—É—á—à–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –∏–∑–≤–ª–µ—á–µ–Ω–∏—è 2D-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "MV-RAG - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#cv", "#benchmark", "#reasoning"], "emoji": "üß†", "ru": {"title": "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑—É–º–Ω–æ—Å—Ç–∏ text-to-image –º–æ–¥–µ–ª–µ–π", "desc": "T2I-ReasonBench - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–µ–π text-to-image –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç —á–µ—Ç—ã—Ä–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è: –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∏–¥–∏–æ–º, —Ç–µ–∫—Å—Ç
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#training", "#rl", "#rlhf", "#reasoning", "#benchmark"], "emoji": "üß†", "ru": {"title": "RuscaRL: –£—Å–∏–ª–µ–Ω–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –ò–ò –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "desc": "RuscaRL - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ–¥–∫—Ä–µ–ø–ª—è—é—â–µ–≥–æ –æ–±—É—á–µ
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#reasoning", "#architecture", "#training"], "emoji": "üß†", "ru": {"title": "–ì–ª—É–±–∏–Ω–∞ –∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å - –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π", "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É–µ—Ç—Å—è, –∫–∞–∫ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –º–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è –≤–ª–∏—è—é—Ç –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∫ –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –≤ 
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#multimodal", "#agents", "#optimization", "#agi", "#cv"], "emoji": "üñºÔ∏è", "ru": {"title": "PosterGen: –ò–ò-–¥–∏–∑–∞–π–Ω–µ—Ä –Ω–∞—É—á–Ω—ã—Ö –ø–æ—Å—Ç–µ—Ä–æ–≤", "desc": "PosterGen - —ç—Ç–æ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å—Ç–µ—Ä–æ–≤ –∏–∑ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π. –°–∏—Å—Ç–µ
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#data", "#survey", "#reasoning", "#open_source"], "emoji": "üß†", "ru": {"title": "UQ: –û—Ü–µ–Ω–∫–∞ –ò–ò –Ω–∞ –≥—Ä–∞–Ω–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π", "desc": "UQ - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –Ω–∞ –Ω–µ—Ä–µ—à–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö, —Å–æ—á–µ—Ç–∞—é—â–∏–π —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∏ —Ä–µ–∞–ª–∏—Å
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#low_resource", "#dataset", "#reasoning", "#hallucinations", "#multilingual", "#benchmark"], "emoji": "üåê", "ru": {"title": "MEENA: –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞", "desc": "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö MEENA –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä—Å–∏–¥—Å–∫–æ-–∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –º
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#reasoning", "#benchmark", "#hallucinations", "#survey", "#multimodal", "#interpretability"], "emoji": "üß†", "ru": {"title": "–ö–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ: –æ—Ç –ø–æ–¥—Å–∫–∞–∑–æ–∫ –∫ –∞–≥–µ–Ω—Ç–∞–º", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –æ–±–∑–æ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ –æ–±–ª–∞—Å—Ç–∏
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#diffusion", "#optimization", "#audio", "#open_source"], "emoji": "üó£Ô∏è", "ru": {"title": "TaDiCodec: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–∏ –∏ —Ç–µ–∫—Å—Ç–∞", "desc": "TaDiCodec - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—é —Ä–µ—á–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ. –û–Ω 
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#dataset", "#benchmark", "#reasoning", "#multimodal", "#data", "#interpretability"], "emoji": "üå≥", "ru": {"title": "ST-Raptor: –î—Ä–µ–≤–æ–≤–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–Ω–∞–ª–∏–∑—É —Å–ª–æ–∂–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "ST-Raptor - —ç—Ç–æ –¥—Ä–µ–≤–æ–≤–∏–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ø–æ–ª—É—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–∞–±–ª
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#benchmark", "#diffusion", "#open_source", "#hallucinations", "#cv"], "emoji": "üñºÔ∏è", "ru": {"title": "SpotEdit: –Ω–æ–≤—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "desc": "SpotEdit ‚Äî —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–µ—Ç–æ–¥–æ–≤ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —É–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏. –û–Ω
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#open_source", "#dataset", "#data", "#training", "#synthetic"], "emoji": "üìö", "ru": {"title": "–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤: German4All –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø–∞—Ä–∞—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω German4All - –ø–µ—Ä–≤—ã–π –º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–µ–º–µ—Ü–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –ø–∞—Ä–∞—Ñ—Ä–∞–∑–æ–≤ —Å –∫–æ–Ω—Ç—Ä–æ–ª–∏
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#optimization", "#training", "#math"], "emoji": "üîç", "ru": {"title": "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–æ—Ñ—Ç–º–∞–∫—Å-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –º–µ—Ö–∞–Ω–∏–∑–º–∞—Ö –≤–Ω–∏–º–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –º–µ—Ö–∞–Ω–∏–∑–º–∞—Ö –≤–Ω–∏–º–∞–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ —Ç–µ–æ—Ä–µ—Ç
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#cv", "#3d"], "emoji": "üî¨", "ru": {"title": "–¢–æ—á–Ω–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è 3D-–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º", "desc": "MeshSplat - —ç—Ç–æ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π –ø–æ –º–∞–ª–æ–º—É —á–∏—Å–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π Gaussian Splatting –∏ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è. –î–ª—è –ø
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#ethics", "#benchmark", "#alignment", "#multimodal", "#interpretability"], "emoji": "‚öñÔ∏è", "ru": {"title": "–ë–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∫–∞–∫ —Å—É–¥—å–∏: –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —ç–Ω—Ç—É–∑–∏–∞–∑–º?", "desc": "–°—Ç–∞—Ç—å—è –∫—Ä–∏—Ç–∏–∫—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å—É–¥–µ–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –≥–µ–Ω–µ—Ä–∞
[26.08.2025 17:10] Using data from previous issue: {"categories": ["#architecture", "#open_source", "#cv", "#games", "#video", "#optimization", "#inference"], "emoji": "üéÆ", "ru": {"title": "–§–æ—Ç–æ—Ä–µ–∞–ª–∏–∑–º –≤ –∏–≥—Ä–∞—Ö –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–≤–µ—Ç–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ –≤ –≤–∏–¥–µ–æ–∏–≥—Ä–∞—Ö —Å –ø–æ–º–æ—â—å—é –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω
[26.08.2025 17:10] Renaming data file.
[26.08.2025 17:10] Renaming previous data. hf_papers.json to ./d/2025-08-26.json
[26.08.2025 17:10] Saving new data file.
[26.08.2025 17:10] Generating page.
[26.08.2025 17:10] Renaming previous page.
[26.08.2025 17:10] Renaming previous data. index.html to ./d/2025-08-26.html
[26.08.2025 17:10] Writing result.
[26.08.2025 17:10] Renaming log file.
[26.08.2025 17:10] Renaming previous data. log.txt to ./logs/2025-08-26_last_log.txt
