[11.11.2024 08:07] Read previous papers.
[11.11.2024 08:07] Generating top page (month).
[11.11.2024 08:07] Writing top page (month).
[11.11.2024 08:16] Read previous papers.
[11.11.2024 08:16] Get feed.
[11.11.2024 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05288
[11.11.2024 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05738
[11.11.2024 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02462
[11.11.2024 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05457
[11.11.2024 08:16] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04425
[11.11.2024 08:16] ********************************************************************************
[11.11.2024 08:16] Abstract 0. Pipeline parallelism is widely used to scale the training of transformer-based large language models, various works have been done to improve its throughput and memory footprint. In this paper, we address a frequently overlooked issue: the vocabulary layers can cause imbalanced computation and memor...
[11.11.2024 08:16] ********************************************************************************
[11.11.2024 08:16] Abstract 1. We present StdGEN, an innovative pipeline for generating semantically decomposed high-quality 3D characters from single images, enabling broad applications in virtual reality, gaming, and filmmaking, etc. Unlike previous methods which struggle with limited decomposability, unsatisfactory quality, an...
[11.11.2024 08:16] ********************************************************************************
[11.11.2024 08:16] Abstract 2. The advent of large language models (LLMs) like GitHub Copilot has significantly enhanced programmers' productivity, particularly in code generation. However, these models often struggle with real-world tasks without fine-tuning. As LLMs grow larger and more performant, fine-tuning for specialized t...
[11.11.2024 08:16] ********************************************************************************
[11.11.2024 08:16] Abstract 3. Technical debt (TD) is a term used to describe the additional work and costs that emerge when developers have opted for a quick and easy solution to a problem, rather than a more effective and well-designed, but time-consuming approach. Self-Admitted Technical Debts (SATDs) are a specific type of te...
[11.11.2024 08:16] ********************************************************************************
[11.11.2024 08:16] Abstract 4. Fine-tuning large language models (LLMs) is essential for enhancing their performance on specific tasks but is often resource-intensive due to redundant or uninformative data. To address this inefficiency, we introduce DELIFT (Data Efficient Language model Instruction Fine-Tuning), a novel algorithm...
[11.11.2024 08:16] Read previous papers.
[11.11.2024 08:16] Generating reviews via LLM API.
[11.11.2024 08:16] Using data from previous issue: {"categories": ["#architecture", "#inference", "#open_source", "#optimization", "#training"], "emoji": "‚ö°", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–Ω—ã—Ö —Å–ª–æ–µ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[11.11.2024 08:16] Using data from previous issue: {"categories": ["#3d", "#diffusion", "#games"], "emoji": "üé≠", "ru": {"title": "StdGEN: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ 3D-–ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º", "desc": "StdGEN - —ç—Ç–æ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –∏–∑–æ–±—Ä
[11.11.2024 08:16] Using data from previous issue: {"categories": ["#optimization", "#training", "#benchmark", "#plp"], "emoji": "üß™", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥—É–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (PEFT) –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∑–∞
[11.11.2024 08:16] Using data from previous issue: {"categories": ["#data", "#training", "#dataset"], "emoji": "üîç", "ru": {"title": "–ù–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–ª–≥: –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ (–¢–î) –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –ø–µ—Ä–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ø—Ä–∏–º–µ—Ä—ã
[11.11.2024 08:16] Using data from previous issue: {"categories": ["#data", "#optimization", "#training"], "emoji": "üîç", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–Ω-—Ç—é–Ω–∏–Ω–≥ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –º–µ–Ω—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º DELIFT –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Ñ–∞–π–Ω-—Ç—é–Ω–∏–Ω–≥–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). DELIFT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ø
[11.11.2024 08:16] Loading Chinese text from previous data.
[11.11.2024 08:16] Renaming data file.
[11.11.2024 08:16] Renaming previous data. hf_papers.json to ./d/2024-11-11.json
[11.11.2024 08:16] Saving new data file.
[11.11.2024 08:16] Generating page.
[11.11.2024 08:16] Renaming previous page.
[11.11.2024 08:16] Renaming previous data. index.html to ./d/2024-11-11.html
[11.11.2024 08:16] [Experimental] Generating Chinese page for reading.
[11.11.2024 08:16] Chinese vocab [{'word': 'ËÆ®ËÆ∫', 'pinyin': 't«éo l√πn', 'trans': 'discuss'}, {'word': 'Â§ßÂûã', 'pinyin': 'd√† x√≠ng', 'trans': 'large-scale'}, {'word': 'ËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'y«î y√°n m√≥ x√≠ng', 'trans': 'language model'}, {'word': '‰ª£Á†ÅÁîüÊàê', 'pinyin': 'd√†i m«é shƒìng ch√©ng', 'trans': 'code generation'}, {'word': 'Êé®ÁêÜ‰ªªÂä°', 'pinyin': 'tuƒ´ l«ê r√®n w√π', 'trans': 'reasoning tasks'}, {'word': '‰ª£ÁêÜÁ≥ªÁªü', 'pinyin': 'd√†i l«ê x√¨ t«íng', 'trans': 'proxy system'}, {'word': 'ÈáçË¶ÅÊÄß', 'pinyin': 'zh√≤ng y√†o x√¨ng', 'trans': 'importance'}, {'word': 'ÂºÄÊîæËÆøÈóÆ', 'pinyin': 'kƒÅi f√†ng f«éng w√®n', 'trans': 'open access'}, {'word': 'ÊÄßËÉΩ', 'pinyin': 'x√¨ng n√©ng', 'trans': 'performance'}, {'word': 'Êé•Ëøë', 'pinyin': 'jiƒì j√¨n', 'trans': 'close to'}, {'word': '‰∏ìÊúâÊ®°Âûã', 'pinyin': 'zhuƒÅn y«íu m√≥ x√≠ng', 'trans': 'proprietary model'}, {'word': 'ÈÄÇÂêà', 'pinyin': 'sh√¨ h√©', 'trans': 'suitable'}, {'word': '‰∏•Ê†º', 'pinyin': 'y√°n g√©', 'trans': 'strict'}, {'word': 'ÁßëÂ≠¶Á†îÁ©∂', 'pinyin': 'kƒì xu√© y√°n ji≈´', 'trans': 'scientific research'}, {'word': 'È´òË¥®Èáè', 'pinyin': 'gƒÅo zh√¨ li√†ng', 'trans': 'high quality'}, {'word': 'ÊúâÈôê', 'pinyin': 'y«íu xi√†n', 'trans': 'limited'}, {'word': 'Â°´Ë°•', 'pinyin': 'ti√°n b«î', 'trans': 'fill'}, {'word': 'Á©∫ÁôΩ', 'pinyin': 'k√≤ng b√°i', 'trans': 'gap'}, {'word': '‰ΩúËÄÖ', 'pinyin': 'zu√≤ zhƒõ', 'trans': 'author'}, {'word': '‰ªãÁªç', 'pinyin': 'ji√® sh√†o', 'trans': 'introduce'}, {'word': 'OpenCoder', 'pinyin': 'OpenCoder', 'trans': 'OpenCoder'}, {'word': 'È°∂Â∞ñ', 'pinyin': 'd«êng jiƒÅn', 'trans': 'top-notch'}, {'word': 'Â™≤Áæé', 'pinyin': 'p√¨ mƒõi', 'trans': 'rival'}, {'word': 'È¢ÜÂÖàÊ®°Âûã', 'pinyin': 'l«êng xiƒÅn m√≥ x√≠ng', 'trans': 'leading model'}, {'word': 'ËØ¶ÁªÜ', 'pinyin': 'xi√°ng x√¨', 'trans': 'detailed'}, {'word': 'ËÆ≠ÁªÉÊï∞ÊçÆ', 'pinyin': 'x√πn li√†n sh√π j√π', 'trans': 'training data'}, {'word': 'ÂçèËÆÆ', 'pinyin': 'xi√© y√¨', 'trans': 'protocol'}, {'word': 'ÂºÄÊîæÊÄß', 'pinyin': 'kƒÅi f√†ng x√¨ng', 'trans': 'openness'}, {'word': 'Âä†ÈÄü', 'pinyin': 'jiƒÅ s√π', 'trans': 'accelerate'}, {'word': 'ÂèØÈáçÂ§ç', 'pinyin': 'kƒõ ch√≥ng f√π', 'trans': 'reproducible'}, {'word': 'ËøõÂ±ï', 'pinyin': 'j√¨n zh«én', 'trans': 'progress'}]
[11.11.2024 08:16] Renaming previous Chinese page.
[11.11.2024 08:16] Renaming previous data. zh.html to ./d/2024-11-10_zh_reading_task.html
[11.11.2024 08:16] Writing Chinese reading task.
[11.11.2024 08:16] Writing result.
[11.11.2024 08:16] Renaming log file.
[11.11.2024 08:16] Renaming previous data. log.txt to ./logs/2024-11-11_last_log.txt
