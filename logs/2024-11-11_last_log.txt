[11.11.2024 20:12] Read previous papers.
[11.11.2024 20:12] Generating top page (month).
[11.11.2024 20:12] Writing top page (month).
[11.11.2024 22:11] Read previous papers.
[11.11.2024 22:11] Get feed.
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05288
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04997
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05738
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04425
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.02462
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04097
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.04986
[11.11.2024 22:11] Get page data from previous paper. URL: https://huggingface.co/papers/2411.05457
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 0. Pipeline parallelism is widely used to scale the training of transformer-based large language models, various works have been done to improve its throughput and memory footprint. In this paper, we address a frequently overlooked issue: the vocabulary layers can cause imbalanced computation and memor...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 1. CLIP is one of the most important multimodal foundational models today. What powers CLIP's capabilities? The rich supervision signals provided by natural language, the carrier of human knowledge, shape a powerful cross-modal representation space. However, with the rapid advancements in large languag...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 2. We present StdGEN, an innovative pipeline for generating semantically decomposed high-quality 3D characters from single images, enabling broad applications in virtual reality, gaming, and filmmaking, etc. Unlike previous methods which struggle with limited decomposability, unsatisfactory quality, an...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 3. Fine-tuning large language models (LLMs) is essential for enhancing their performance on specific tasks but is often resource-intensive due to redundant or uninformative data. To address this inefficiency, we introduce DELIFT (Data Efficient Language model Instruction Fine-Tuning), a novel algorithm...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 4. The advent of large language models (LLMs) like GitHub Copilot has significantly enhanced programmers' productivity, particularly in code generation. However, these models often struggle with real-world tasks without fine-tuning. As LLMs grow larger and more performant, fine-tuning for specialized t...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 5. Fine-tuned vision-language models (VLMs) often capture spurious correlations between image features and textual attributes, resulting in degraded zero-shot performance at test time. Existing approaches for addressing spurious correlations (i) primarily operate at the global image-level rather than i...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 6. Modern language models can process inputs across diverse languages and modalities. We hypothesize that models acquire this capability through learning a shared representation space across heterogeneous data types (e.g., different languages and modalities), which places semantically similar inputs ne...
[11.11.2024 22:11] ********************************************************************************
[11.11.2024 22:11] Abstract 7. Technical debt (TD) is a term used to describe the additional work and costs that emerge when developers have opted for a quick and easy solution to a problem, rather than a more effective and well-designed, but time-consuming approach. Self-Admitted Technical Debts (SATDs) are a specific type of te...
[11.11.2024 22:11] Read previous papers.
[11.11.2024 22:11] Generating reviews via LLM API.
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#architecture", "#inference", "#open_source", "#optimization", "#training"], "emoji": "‚ö°", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–Ω—ã—Ö —Å–ª–æ–µ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#long_context", "#multimodal", "#games", "#training"], "emoji": "üîó", "ru": {"title": "–£—Å–∏–ª–µ–Ω–∏–µ CLIP —Å –ø–æ–º–æ—â—å—é LLM –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Ç–µ–∫—Å—Ç–∞", "desc": "LLM2CLIP - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ CLIP —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ê–≤—Ç–æ—Ä
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#3d", "#diffusion", "#games"], "emoji": "üé≠", "ru": {"title": "StdGEN: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ 3D-–ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º", "desc": "StdGEN - —ç—Ç–æ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –∏–∑–æ–±—Ä
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#data", "#optimization", "#training"], "emoji": "üîç", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–Ω-—Ç—é–Ω–∏–Ω–≥ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –º–µ–Ω—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º DELIFT –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤—ã–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Ñ–∞–π–Ω-—Ç—é–Ω–∏–Ω–≥–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). DELIFT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ø
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#optimization", "#training", "#benchmark", "#plp"], "emoji": "üß™", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥—É–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (PEFT) –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∑–∞
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#optimization", "#multimodal", "#cv", "#training", "#healthcare", "#interpretability"], "emoji": "üîç", "ru": {"title": "–¢–æ—á–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–∂–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ RaVL –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ —Å–º—è–≥—á–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#multilingual", "#multimodal", "#transfer_learning", "#interpretability"], "emoji": "üß†", "ru": {"title": "–ï–¥–∏–Ω–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∫–∞–∫ –∫–ª—é—á –∫ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ –ò–ò", "desc": "–°—Ç–∞—Ç—å—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ö–∞–±–∞ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥
[11.11.2024 22:11] Using data from previous issue: {"categories": ["#data", "#training", "#dataset"], "emoji": "üîç", "ru": {"title": "–ù–æ–≤—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–ª–≥: –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ (–¢–î) –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–ª–∏ –ø–µ—Ä–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ø—Ä–∏–º–µ—Ä—ã
[11.11.2024 22:11] Loading Chinese text from previous data.
[11.11.2024 22:11] Renaming data file.
[11.11.2024 22:11] Renaming previous data. hf_papers.json to ./d/2024-11-11.json
[11.11.2024 22:11] Saving new data file.
[11.11.2024 22:11] Generating page.
[11.11.2024 22:11] Renaming previous page.
[11.11.2024 22:11] Renaming previous data. index.html to ./d/2024-11-11.html
[11.11.2024 22:11] [Experimental] Generating Chinese page for reading.
[11.11.2024 22:11] Chinese vocab [{'word': 'StdGEN', 'pinyin': 'sƒ´tƒ´dƒ´ jƒ´n', 'trans': 'a method for generating high-quality 3D characters from a single image'}, {'word': 'ÂàõÊñ∞', 'pinyin': 'chu√†ngxƒ´n', 'trans': 'innovative'}, {'word': 'ËßíËâ≤', 'pinyin': 'ju√©s√®', 'trans': 'character'}, {'word': 'ËØ≠‰πâ', 'pinyin': 'y«îy√¨', 'trans': 'semantic'}, {'word': 'ÁªÑ‰ª∂', 'pinyin': 'z«îji√†n', 'trans': 'component'}, {'word': 'Âá†‰Ωï', 'pinyin': 'j«êh√©', 'trans': 'geometry'}, {'word': 'ÈáçÂª∫', 'pinyin': 'ch√≥ngji√†n', 'trans': 'reconstruct'}, {'word': 'Â§öËßÜÂõæ', 'pinyin': 'du≈çsh√¨t√∫', 'trans': 'multi-view'}, {'word': 'Ë°®Áé∞', 'pinyin': 'bi«éoxi√†n', 'trans': 'performance'}, {'word': 'Âá∫Ëâ≤', 'pinyin': 'ch≈´s√®', 'trans': 'outstanding'}, {'word': 'Áé∞Êúâ', 'pinyin': 'xi√†ny«íu', 'trans': 'existing'}, {'word': 'ÁÅµÊ¥ª', 'pinyin': 'l√≠nghu√≥', 'trans': 'flexible'}, {'word': 'ÂÆöÂà∂Âåñ', 'pinyin': 'd√¨ngzh√¨hu√†', 'trans': 'customized'}, {'word': 'ËôöÊãüÁé∞ÂÆû', 'pinyin': 'x≈´n«ê xi√†nsh√≠', 'trans': 'virtual reality'}, {'word': 'Ê∏∏Êàè', 'pinyin': 'y√≥ux√¨', 'trans': 'game'}, {'word': 'ÁîµÂΩ±Âà∂‰Ωú', 'pinyin': 'di√†ny«êng zh√¨zu√≤', 'trans': 'film production'}]
[11.11.2024 22:11] Renaming previous Chinese page.
[11.11.2024 22:11] Renaming previous data. zh.html to ./d/2024-11-10_zh_reading_task.html
[11.11.2024 22:11] Writing Chinese reading task.
[11.11.2024 22:11] Writing result.
[11.11.2024 22:11] Renaming log file.
[11.11.2024 22:11] Renaming previous data. log.txt to ./logs/2024-11-11_last_log.txt
