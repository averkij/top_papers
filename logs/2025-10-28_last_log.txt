[28.10.2025 00:52] Read previous papers.
[28.10.2025 00:52] Generating top page (month).
[28.10.2025 00:52] Writing top page (month).
[28.10.2025 02:23] Read previous papers.
[28.10.2025 02:23] Get feed.
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21618
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20888
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21682
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21583
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.19871
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.14901
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.18212
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21270
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20286
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21697
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20479
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20206
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21223
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.13251
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21553
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20535
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21652
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21447
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20780
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.17234
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21581
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21057
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.11370
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21440
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.21111
[28.10.2025 02:23] Get page data from previous paper. URL: https://huggingface.co/papers/2510.20708
[28.10.2025 02:23] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[28.10.2025 02:23] No deleted papers detected.
[28.10.2025 02:23] Downloading and parsing papers (pdf, html). Total: 26.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21618.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21618.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21618.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20888.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20888.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20888.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21682.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21682.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21682.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21583.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21583.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21583.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.19871.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.19871.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.19871.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.14901.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.14901.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.14901.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.18212.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.18212.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.18212.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21270.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21270.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21270.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20286.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20286.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20286.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21697.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21697.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21697.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20479.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20479.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20479.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20206.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20206.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20206.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21223.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21223.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21223.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.13251.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.13251.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.13251.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21553.
[28.10.2025 02:23] Downloading paper 2510.21553 from http://arxiv.org/pdf/2510.21553v1...
[28.10.2025 02:23] Failed to download and parse paper https://huggingface.co/papers/2510.21553: 'LTChar' object is not iterable
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20535.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20535.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20535.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21652.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21652.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21652.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21447.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21447.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21447.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20780.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20780.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20780.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.17234.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.17234.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.17234.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21581.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21581.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21581.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21057.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21057.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21057.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.11370.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.11370.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.11370.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21440.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21440.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21440.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.21111.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.21111.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.21111.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Downloading and parsing paper https://huggingface.co/papers/2510.20708.
[28.10.2025 02:23] Extra JSON file exists (./assets/json/2510.20708.json), skip PDF parsing.
[28.10.2025 02:23] Paper image links file exists (./assets/img_data/2510.20708.json), skip HTML parsing.
[28.10.2025 02:23] Success.
[28.10.2025 02:23] Enriching papers with extra data.
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 0. DeepAgent, an end-to-end deep reasoning agent, autonomously performs thinking, tool discovery, and action execution using memory folding and reinforcement learning, outperforming baselines in various tool-use and application tasks.  					AI-generated summary 				 Large reasoning models have demonstr...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 1. Video-As-Prompt (VAP) uses a reference video to guide a frozen Video Diffusion Transformer via a Mixture-of-Transformers expert, achieving state-of-the-art results in semantic-controlled video generation with strong zero-shot generalization.  					AI-generated summary 				 Unified, generalizable sem...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 2. WorldGrow, a hierarchical framework, generates large, continuous 3D environments with coherent geometry and realistic appearance using pre-trained 3D models and a coarse-to-fine generation strategy.  					AI-generated summary 				 We tackle the challenge of generating the infinitely extendable 3D wo...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 3. Chunk-GRPO, a chunk-level optimization approach for text-to-image generation, improves preference alignment and image quality by addressing inaccurate advantage attribution and neglecting temporal dynamics.  					AI-generated summary 				 Group Relative Policy Optimization (GRPO) has shown strong po...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 4. ReDiff, a refining-enhanced diffusion framework, addresses train-inference discrepancies in discrete diffusion models by enabling the model to identify and correct its own errors, improving coherence and factual accuracy in generated content.  					AI-generated summary 				 Discrete diffusion models...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 5. An iterative sampling algorithm enhances reasoning capabilities in base models without additional training, matching or outperforming reinforcement learning on single-shot tasks.  					AI-generated summary 				 Frontier reasoning models have exhibited incredible capabilities across a wide array of d...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 6. A quantifiable framework based on Cattell-Horn-Carroll theory evaluates AI systems across ten cognitive domains, revealing significant gaps in foundational cognitive abilities like long-term memory.  					AI-generated summary 				 The lack of a concrete definition for Artificial General Intelligence...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 7. Permuted Block-Sparse Attention improves computational efficiency in large language models by enhancing block-level sparsity in the self-attention mechanism, achieving significant speedups without compromising accuracy.  					AI-generated summary 				 Scaling the context length of large language mod...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 8. The Instruction-as-Reasoning paradigm enhances GUI grounding by treating instructions as dynamic pathways, improving performance through multi-perspective reasoning and reinforcement learning.  					AI-generated summary 				 GUI grounding, which maps natural-language instructions to actionable UI el...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 9. Visual diffusion models can solve geometric problems by transforming noisy images into valid solutions, demonstrating a novel approach to geometric reasoning through image generation.  					AI-generated summary 				 In this paper we show that visual diffusion models can serve as effective geometric ...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 10. RECALL is a representation-aware framework for continual learning in large language models that merges models without historical data, preserving domain-general features and adapting to task-specific knowledge.  					AI-generated summary 				 We unveil that internal representations in large language...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 11. RAPO++ enhances text-to-video generation by optimizing user prompts through retrieval, iterative refinement, and LLM fine-tuning, improving semantic alignment, compositionality, and temporal coherence.  					AI-generated summary 				 Prompt design plays a crucial role in text-to-video (T2V) generati...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 12. Functional Dual Anchors (FDAs) enhance model merging by aligning gradients with task vectors in the input-representation space, offering robustness and flexibility compared to parameter-space methods.  					AI-generated summary 				 Model merging is an efficient post-training strategy for integratin...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 13. Video Large Language Models (VideoLLMs) perform video question answering by initiating temporal reasoning through cross-frame interactions, followed by video-language integration, and generate answers using effective information pathways while suppressing unnecessary attention edges.  					AI-genera...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 14. Category theory is used to develop information-theoretic measures, summarization, and self-supervised improvement of large pretrained models through a mathematical framework of question-answer pairs and orthogonalization.  					AI-generated summary 				 We apply category theory to extract multimodal...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 15. An ARC-Encoder compresses context into continuous representations for LLMs, improving inference efficiency and performance across various scenarios.  					AI-generated summary 				 Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and ...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 16. AstaBench provides a comprehensive benchmark suite for evaluating AI agents in scientific research, revealing that while progress has been made, AI still falls short in fully assisting scientific research.  					AI-generated summary 				 AI agents hold the potential to revolutionize scientific produ...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 17. PhysWorld uses a simulator to generate diverse demonstrations for training a GNN-based world model, enabling accurate and fast predictions for deformable objects with competitive performance and faster inference speeds.  					AI-generated summary 				 Interactive world models that simulate object dy...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 18. Calibrating large reasoning models with synthetic human-like thinking trajectories improves their efficiency and performance in machine translation evaluation.  					AI-generated summary 				 Recent advancements in large reasoning models (LRMs) have introduced an intermediate "thinking" process prio...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 19. A novel Continual Audio-Visual Segmentation (CAVS) task addresses challenges in multi-modal continual learning through a Collision-based Multi-modal Rehearsal (CMR) framework, improving performance over single-modal methods.  					AI-generated summary 				 Recently, significant progress has been mad...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 20. Foley Control uses a small cross-attention bridge to synchronize video and audio without retraining, achieving competitive alignment with fewer parameters and maintaining modularity.  					AI-generated summary 				 Foley Control is a lightweight approach to video-guided Foley that keeps pretrained s...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 21. SIC, an iterative prompt sanitization method, enhances the security of tool-augmented LLM agents by repeatedly inspecting and cleaning incoming data to prevent prompt injection attacks.  					AI-generated summary 				 Large Language Models (LLMs) are increasingly deployed in agentic systems that int...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 22. Rollout Routing Replay (R3) stabilizes reinforcement learning training in Mixture-of-Experts models by reducing discrepancies between training and inference routing behaviors.  					AI-generated summary 				 Reinforcement learning (RL) has emerged as a crucial approach for enhancing the capabilities...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 23. A new metric, UDCG, is introduced to better evaluate Retrieval Augmented Generation systems by accounting for both the utility of relevant documents and the distraction of irrelevant ones, improving correlation with end-to-end answer accuracy.  					AI-generated summary 				 Traditional Information ...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 24. Active Visual Reasoning (AVR) extends visual reasoning to interactive, partially observable environments, requiring agents to sequentially gather and integrate information for coherent decision-making, as evaluated by the CLEVR-AVR benchmark.  					AI-generated summary 				 Visual reasoning in multi...
[28.10.2025 02:23] ********************************************************************************
[28.10.2025 02:23] Abstract 25. ALICE-LRI is a sensor-agnostic method that achieves lossless range image generation from spinning LiDAR point clouds, preserving all points and maintaining geometric accuracy in real-time.  					AI-generated summary 				 3D LiDAR sensors are essential for autonomous navigation, environmental monitor...
[28.10.2025 02:23] Read previous papers.
[28.10.2025 02:23] Generating reviews via LLM API.
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#optimization", "#rl", "#agents", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "DeepAgent: –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π AI-–∞–≥–µ–Ω—Ç —Å –≥–ª—É–±–æ–∫–∏–º reasoning –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é", "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω DeepAgent ‚Äî end-to-end –∞–≥–µ–Ω—Ç –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–Ω–æ–º–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, 
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#video", "#open_source", "#dataset", "#architecture", "#diffusion"], "emoji": "üé¨", "ru": {"title": "–í–∏–¥–µ–æ –∫–∞–∫ –ø—Ä–æ–º–ø—Ç: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Video-As-Prompt (VAP) ‚Äî –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ, –≥–¥–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#3d", "#dataset", "#games"], "emoji": "üåç", "ru": {"title": "–ë–µ—Å–∫–æ–Ω–µ—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 3D-–º–∏—Ä–æ–≤ –±–ª–æ–∫ –∑–∞ –±–ª–æ–∫–æ–º", "desc": "WorldGrow - —ç—Ç–æ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ —Ä–∞—Å—à–∏—Ä—è–µ–º—ã—Ö 3D-–º–∏—Ä–æ–≤ —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–µ–π –∏ —Ç–µ–∫—Å—Ç—É—Ä–∞–º–∏. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ 3D-–º–æ–¥–µ–ª–∏
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#training", "#optimization", "#alignment", "#cv", "#rl"], "emoji": "üß©", "ru": {"title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ —á–∞—Å—Ç—è–º: —É–ª—É—á—à–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ Chunk-GRPO ‚Äî –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Ä
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#hallucinations", "#optimization", "#diffusion", "#rl", "#training", "#cv"], "emoji": "üîÑ", "ru": {"title": "–£—á–∏–º –º–æ–¥–µ–ª—å –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å —Å–≤–æ–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏", "desc": "–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å—Ç–∞–ª–∫–∏–≤–∞—é—Ç—Å—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–∂–¥—É –æ–±—É—á–µ–Ω–∏–µ–º –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–æ–º, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∫–∞—Å–∫
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#optimization", "#inference", "#math", "#rl", "#reasoning"], "emoji": "üîÑ", "ru": {"title": "–†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è: —Å–∏–ª–∞ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —É–ª—É—á—à–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–∞–∑–æ–≤—ã—Ö LLM –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –±–µ–∑ –¥
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#agi", "#benchmark", "#long_context", "#reasoning", "#math"], "emoji": "üß†", "ru": {"title": "–ò–∑–º–µ—Ä—è—è —Ä–∞–∑—Ä—ã–≤ –¥–æ AGI —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–º—É —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –ø—Å–∏—Ö–æ–º–µ—Ç—Ä–∏–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –º–µ—Ç–æ–¥–∏–∫—É –æ—Ü–µ–Ω–∫–∏ AI-—Å–∏—Å—Ç–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–æ—Ä–∏–∏ –ö–µ—Ç—Ç–µ–ª–ª–∞-–•–æ—Ä–Ω–∞-–ö—ç—Ä—Ä–æ–ª–ª–∞, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—è –¥–µ—Å—è—Ç
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#optimization", "#long_context", "#training", "#architecture", "#inference"], "emoji": "üîÄ", "ru": {"title": "–ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –≤ LLM", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–µ—Ç–æ–¥ Permuted Block-Sparse Attention (PBS-Attn) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#training", "#rl", "#open_source", "#benchmark", "#agents", "#optimization", "#reasoning"], "emoji": "üéØ", "ru": {"title": "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∫–∞–∫ –ø—É—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É Instruction-as-Reasoning –¥–ª—è GUI grou
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#cv", "#reasoning", "#multimodal", "#diffusion"], "emoji": "üî∑", "ru": {"title": "–ì–µ–æ–º–µ—Ç—Ä–∏—è —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é: –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∫–∞–∫ —Ä–µ—à–∞—Ç–µ–ª–∏ –∑–∞–¥–∞—á", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ—à–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏, —Ä–∞–±–æ—Ç–∞—è –Ω–∞–ø—Ä—è–º—É—é —Å –∏–∑–æ
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#training", "#transfer_learning", "#optimization", "#agents"], "emoji": "üîÑ", "ru": {"title": "–°–ª–∏—è–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –ø–∞–º—è—Ç–∏", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç RECALL ‚Äî –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ continual learning –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—ä–µ–¥
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#video", "#multimodal", "#optimization", "#rag", "#diffusion", "#training"], "emoji": "üé¨", "ru": {"title": "–¢—Ä—ë—Ö—ç—Ç–∞–ø–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è text-to-video –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", "desc": "RAPO++ ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#synthetic", "#architecture", "#training", "#optimization"], "emoji": "‚öì", "ru": {"title": "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —è–∫–æ—Ä—è –¥–ª—è —É–º–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—é fine-tuned –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Functional Dual Anchors (FDA). –í–º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#alignment", "#video", "#reasoning", "#interpretability", "#training", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–ö–∞–∫ –≤–∏–¥–µ–æ-LLM –ø–æ–Ω–∏–º–∞—é—Ç –≤—Ä–µ–º—è: –∫–∞—Ä—Ç–∞ –ø–æ—Ç–æ–∫–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–∑—É—á–∏–ª–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã —Ä–∞–±–æ—Ç—ã –≤–∏–¥–µ–æ-LLM (–±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤–∏–¥–µ–æ) –ø—Ä
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#interpretability", "#training", "#rl", "#multimodal", "#survey", "#data", "#optimization", "#math"], "emoji": "üî∑", "ru": {"title": "–¢–µ–æ—Ä–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–ª–∏ —Ç–µ–æ—Ä–∏—é –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#training", "#open_source", "#dataset", "#long_context", "#architecture", "#optimization", "#inference"], "emoji": "üóúÔ∏è", "ru": {"title": "–°–∂–∞—Ç–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ inference", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç ARC-Encoder ‚Äî —ç–Ω–∫–æ–¥–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Å–∂–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ 
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#benchmark", "#agents", "#science"], "emoji": "üî¨", "ru": {"title": "AI –≤ –Ω–∞—É–∫–µ: –µ—â—ë –Ω–µ –∑–∞–º–µ–Ω–∞ —É—á—ë–Ω—ã–º", "desc": "AstaBench –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π AI –∞–≥–µ–Ω—Ç–æ–≤ –≤ –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö. –û–Ω –≤—ã—è–≤–ª—è–µ—Ç, —á—Ç–æ, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å, AI –ø–æ–∫–∞ –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#dataset", "#agents", "#robotics", "#synthetic", "#graphs", "#inference"], "emoji": "üåä", "ru": {"title": "–§–∏–∑–∏—á–µ—Å–∫–∏–π –º–∏—Ä: —Å–∏–º—É–ª—è—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–µ—Ñ–æ—Ä–º–∏—Ä—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤", "desc": "PhysWorld ‚Äî —ç—Ç–æ framework –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö world models, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–º—É–ª–∏—Ä—É—é—Ç –¥–∏–Ω–∞–º–∏–∫—É –¥
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#benchmark", "#reasoning", "#synthetic", "#training", "#machine_translation", "#multimodal"], "emoji": "üéØ", "ru": {"title": "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–∑—É—á–∏–ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (LRM) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#training", "#multimodal"], "emoji": "üîä", "ru": {"title": "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ –±–µ–∑ –∑–∞–±—ã–≤–∞–Ω–∏—è", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –∞—É–¥–∏–æ-–≤–∏–∑—É–∞–ª—å–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (CAVS), –≥–¥–µ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ–¥ —É–ø—Ä–∞–≤
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#optimization", "#video", "#small_models", "#alignment", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–ú–æ–¥—É–ª—å–Ω—ã–π –º–æ—Å—Ç –º–µ–∂–¥—É –≤–∏–¥–µ–æ –∏ –∑–≤—É–∫–æ–º –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π", "desc": "Foley Control ‚Äî —ç—Ç–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–≤—É–∫–æ–≤–æ–≥–æ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏—è –≤–∏–¥–µ–æ, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–∞–º–æ—Ä
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#agents", "#security", "#data", "#inference"], "emoji": "üõ°Ô∏è", "ru": {"title": "–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –∑–∞—â–∏—Ç—ã LLM-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ SIC (Soft Instruction Control) –¥–ª—è –∑–∞—â–∏—Ç—ã LLM-–∞–≥–µ–Ω—Ç–æ–≤ –æ—Ç prompt injection –∞—Ç–∞–∫ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –≤–Ω–µ—à–Ω–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –ú–µ—Ç–æ–¥
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#rl", "#training", "#optimization", "#reasoning"], "emoji": "üîÑ", "ru": {"title": "–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è MoE —á–µ—Ä–µ–∑ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Ä–æ—É—Ç–∏–Ω–≥–∞", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ Rollout Routing Replay (R3) –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ Mixture-of-Experts –º–æ–¥–µ–ª—è—Ö. –ü—Ä–æ–±–ª–µ–º
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#benchmark", "#optimization", "#rag", "#alignment"], "emoji": "üéØ", "ru": {"title": "–ù–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–∏—Å–∫–∞ –≤ RAG-—Å–∏—Å—Ç–µ–º–∞—Ö —Å —É—á—ë—Ç–æ–º —Ä–∞–±–æ—Ç—ã LLM", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –º–µ—Ç—Ä–∏–∫—É UDCG –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º Retrieval Augmented Generation, –∫–æ—Ç–æ—Ä–∞—è —É—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#dataset", "#cv", "#multimodal", "#agents", "#benchmark", "#reasoning"], "emoji": "üîç", "ru": {"title": "–ù–∞—É—á–∏—Ç–µ AI –∞–∫—Ç–∏–≤–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –∏ –¥—É–º–∞—Ç—å", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É Active Visual Reasoning (AVR), –≥–¥–µ AI-–∞–≥–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –∞–∫—Ç–∏–≤–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω
[28.10.2025 02:23] Using data from previous issue: {"categories": ["#3d", "#dataset"], "emoji": "üì°", "ru": {"title": "–ò–¥–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è LiDAR –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "desc": "ALICE-LRI ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç 2D range-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –æ–±–ª–∞–∫–æ–≤ —Ç–æ—á–µ–∫ –≤—Ä–∞—â–∞—é—â–∏—Ö—Å—è LiDAR-—Å–µ–Ω—Å–æ—Ä–æ–≤ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö. –ê–ª–≥–æ—Ä–∏—Ç–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç
[28.10.2025 02:23] Renaming data file.
[28.10.2025 02:23] Renaming previous data. hf_papers.json to ./d/2025-10-28.json
[28.10.2025 02:23] Saving new data file.
[28.10.2025 02:23] Generating page.
[28.10.2025 02:23] Renaming previous page.
[28.10.2025 02:23] Renaming previous data. index.html to ./d/2025-10-28.html
[28.10.2025 02:23] Writing result.
[28.10.2025 02:23] Renaming log file.
[28.10.2025 02:23] Renaming previous data. log.txt to ./logs/2025-10-28_last_log.txt
