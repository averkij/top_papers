[16.10.2024 10:13] Read previous papers.
[16.10.2024 10:13] Get feed.
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11710
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11779
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11096
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.10816
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2406.15786
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11419
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.10626
[16.10.2024 10:13] Extract page data from URL. URL: https://huggingface.co/papers/2410.10814
[16.10.2024 10:13] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08001
[16.10.2024 10:13] Extract page data from URL. URL: https://huggingface.co/papers/2410.11795
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 0. Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Recently, many tool-use benchmark datasets have been proposed. However, existing datasets have the following limitations: (1). Insufficient evaluati...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 1. Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to reco...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 2. Existing works have established multiple benchmarks to highlight the security risks associated with Code GenAI. These risks are primarily reflected in two areas: a model potential to generate insecure code (insecure coding) and its utility in cyberattacks (cyberattack helpfulness). While these bench...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 3. The efficacy of video generation models heavily depends on the quality of their training datasets. Most previous video generation models are trained on short video clips, while recently there has been increasing interest in training long video generation models directly on longer videos. However, th...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 4. While scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks, it also introduces redundant architectures, posing efficiency challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy ...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 5. We present a spatial and angular Gaussian based representation and a triple splatting process, for real-time, high-quality novel lighting-and-view synthesis from multi-view point-lit input images. To describe complex appearance, we employ a Lambertian plus a mixture of angular Gaussians as an effect...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 6. Adapting medical Large Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensur...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 7. While large language models (LLMs) excel on generation tasks, their decoder-only architecture often limits their potential as embedding models if no further representation finetuning is applied. Does this contradict their claim of generalists? To answer the question, we take a closer look at Mixture...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 8. The increasing demand for versatile robotic systems to operate in diverse and dynamic environments has emphasized the importance of a generalist policy, which leverages a large cross-embodiment data corpus to facilitate broad adaptability and high-level reasoning. However, the generalist would strug...
[16.10.2024 10:13] ********************************************************************************
[16.10.2024 10:13] Abstract 9. As one of the most popular and sought-after generative models in the recent years, diffusion models have sparked the interests of many researchers and steadily shown excellent advantage in various generative tasks such as image synthesis, video generation, molecule design, 3D scene rendering and mul...
[16.10.2024 10:13] Read previous papers.
[16.10.2024 10:13] Generating reviews via LLM API.
[16.10.2024 10:13] Using data from previous issue: {"desc": "В этой статье представлен новый бенчмарк MTU-Bench для оценки навыков использования инструментов большими языковыми моделями (LLM). MTU-Bench охватывает пять сценариев использования инструментов, от простых до сложных и нестандартных задач. Оценка производится без использования API GPT или
[16.10.2024 10:13] Using data from previous issue: {"desc": "Статья исследует проблему галлюцинаций в мультимодальных больших языковых моделях (MLLM). Авторы обнаружили, что MLLM способны распознавать визуальные объекты в промежуточных слоях, но в итоговом выводе могут их некорректно генерировать. Предполагается, что это связано с подавлением визуал
[16.10.2024 10:13] Using data from previous issue: {"desc": "Статья представляет SecCodePLT - новую платформу для оценки рисков безопасности генеративных моделей AI для кода. Авторы разработали методологию создания данных, сочетающую экспертную оценку и автоматическую генерацию, а также внедрили динамические метрики оценки. SecCodePLT позволяет оцен
[16.10.2024 10:13] Using data from previous issue: {"desc": "Статья представляет новый датасет LVD-2M для обучения моделей генерации длинных видео. Датасет содержит 2 миллиона видео длительностью более 10 секунд, снятых одним кадром и сопровождаемых плотными временными подписями. Авторы разработали методику отбора качественных видео и создания аннот
[16.10.2024 10:13] Using data from previous issue: {"desc": "Это исследование посвящено проблеме избыточности в архитектуре больших языковых моделей (LLM) на базе трансформеров. Авторы обнаружили, что значительная часть слоев внимания (attention layers) обладает высокой схожестью и может быть удалена без существенной потери производительности. Напри
[16.10.2024 10:13] Using data from previous issue: {"desc": "Статья представляет новый метод синтеза изображений с изменением освещения и ракурса в реальном времени. Авторы используют представление на основе пространственных и угловых гауссианов, а также процесс тройного сплаттинга. Для описания сложных визуальных эффектов применяется функция отраже
[16.10.2024 10:13] Using data from previous issue: {"desc": "Статья посвящена адаптации больших языковых моделей (LLM) для медицинских целей в различных языках. Авторы создают качественный медицинский датасет и исследуют внутренние механизмы многоязычных LLM с использованием модульности Mixture of Experts (MoE). Они предлагают новый метод маршрутиза
[16.10.2024 10:13] Querying the API.
[16.10.2024 10:13] Got response. {
  "desc": "Исследование показывает, что маршрутизаторы экспертов в моделях Mixture-of-Experts (MoE) LLM могут служить готовой моделью для создания эмбеддингов с многообещающей производительностью на разнообразных задачах, не требуя дополнительной настройки. Анализ демонстрирует, что веса маршрутизации MoE (RW) дополняют скрытое состояние (HS) LLM, широко используемое для эмбеддингов. Предложенный метод MoEE, объединяющий RW и HS, показывает лучшую производительность, чем использование каждого по отдельности. Эксперименты проводились на 6 задачах эмбеддинга с 20 наборами данных из Massive Text Embedding Benchmark (MTEB).",
  "categories": ["#nlp", "#benchmark", "#dataset"],
  "emoji": "🧠",
  "title": "MoE LLM: Скрытый потенциал эмбеддингов без дополнительной настройки"
}
[16.10.2024 10:13] Get embedding for a paper via LLM API.
[16.10.2024 10:13] Using data from previous issue: {"desc": "RoboDual - это синергетическая двойная система, объединяющая преимущества обобщенной и специализированной политик для роботов. Обобщенная политика на основе vision-language-action обеспечивает высокоуровневое понимание задач, а специализированная политика на основе диффузионного трансформе
[16.10.2024 10:13] Querying the API.
[16.10.2024 10:13] Got response. {
  "desc": "Эта статья представляет собой обзор диффузионных моделей, одного из самых популярных и востребованных типов генеративных моделей последних лет. Авторы предоставляют комплексный анализ принципов работы и эффективных практик применения диффузионных моделей в различных задачах, таких как синтез изображений, генерация видео и молекулярный дизайн. Особое внимание уделяется архитектуре моделей, методам обучения, быстрому выводу и надежному развертыванию. Статья призвана помочь исследователям и практикам быстро понять и применить диффузионные модели в новых сценариях.",
  "categories": ["#cv", "#video", "#multimodal", "#benchmark"],
  "emoji": "🌀",
  "title": "Эффективные диффузионные модели: от теории к практике"
}
[16.10.2024 10:13] Get embedding for a paper via LLM API.
[16.10.2024 10:13] Loading Chinese text from previous data.
[16.10.2024 10:13] Renaming data file.
[16.10.2024 10:13] Renaming previous data. hf_papers.json to 2024-10-15_hf_papers.json
[16.10.2024 10:13] Saving new data file.
[16.10.2024 10:13] Generating page.
[16.10.2024 10:13] Generating Chinese page for reading.
[16.10.2024 10:13] Chinese vocab [{'word': '多模态', 'pinyin': 'duō mó shuài', 'trans': 'multimodal'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '幻觉', 'pinyin': 'huàn jué', 'trans': 'hallucination'}, {'word': '现象', 'pinyin': 'xiàn xiàng', 'trans': 'phenomenon'}, {'word': '原因', 'pinyin': 'yuán yīn', 'trans': 'reason'}, {'word': '错误', 'pinyin': 'cuò wù', 'trans': 'error'}, {'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generate'}, {'word': '对象', 'pinyin': 'duì xiàng', 'trans': 'object'}, {'word': '识别', 'pinyin': 'shí bié', 'trans': 'recognize'}, {'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'}, {'word': '强', 'pinyin': 'qiáng', 'trans': 'strong'}, {'word': '知识', 'pinyin': 'zhī shi', 'trans': 'knowledge'}, {'word': '先验', 'pinyin': 'xiān yàn', 'trans': 'prior'}, {'word': '抑制', 'pinyin': 'yì zhì', 'trans': 'suppress'}, {'word': '信息', 'pinyin': 'xìn xī', 'trans': 'information'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '纠正', 'pinyin': 'jiū zhèng', 'trans': 'correct'}, {'word': '解码', 'pinyin': 'jiě mǎ', 'trans': 'decode'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '适应性', 'pinyin': 'shì yìng xìng', 'trans': 'adaptive'}, {'word': '选择', 'pinyin': 'xuǎn zé', 'trans': 'select'}, {'word': '合适', 'pinyin': 'hé shì', 'trans': 'suitable'}, {'word': '整合', 'pinyin': 'zhěng hé', 'trans': 'integrate'}, {'word': '调整', 'pinyin': 'tiáo zhěng', 'trans': 'adjust'}, {'word': '经典', 'pinyin': 'jīng diǎn', 'trans': 'classical'}, {'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'}, {'word': '无缝', 'pinyin': 'wú fēng', 'trans': 'seamless'}, {'word': '结合', 'pinyin': 'jié hé', 'trans': 'combine'}, {'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'apply'}, {'word': '不同', 'pinyin': 'bù tóng', 'trans': 'different'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'}, {'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'}, {'word': '降低', 'pinyin': 'jiàng dī', 'trans': 'reduce'}, {'word': '率', 'pinyin': 'lǜ', 'trans': 'rate'}]
[16.10.2024 10:13] Renaming previous page.
[16.10.2024 10:13] Renaming previous data. index.html to 2024-10-15_hf_papers.html
[16.10.2024 10:13] Renaming previous Chinese page.
[16.10.2024 10:13] Renaming previous data. zh.html to 2024-10-15_zh_reading_task.html
[16.10.2024 10:13] Writing result.
[16.10.2024 10:13] Writing Chinese reading task.
[16.10.2024 10:13] Renaming log file.
[16.10.2024 10:13] Renaming previous data. log.txt to 2024-10-15_last_log.txt
