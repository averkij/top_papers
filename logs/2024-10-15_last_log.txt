[16.10.2024 12:23] Read previous papers.
[16.10.2024 12:23] Get feed.
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11779
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11710
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11096
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.10816
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2406.15786
[16.10.2024 12:23] Extract page data from URL. URL: https://huggingface.co/papers/2410.09342
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11419
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.10814
[16.10.2024 12:23] Extract page data from URL. URL: https://huggingface.co/papers/2410.09754
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.10626
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.08001
[16.10.2024 12:23] Extract page data from URL. URL: https://huggingface.co/papers/2410.09745
[16.10.2024 12:23] Get page data from previous paper. URL: https://huggingface.co/papers/2410.11795
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 0. Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to reco...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 1. Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Recently, many tool-use benchmark datasets have been proposed. However, existing datasets have the following limitations: (1). Insufficient evaluati...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 2. Existing works have established multiple benchmarks to highlight the security risks associated with Code GenAI. These risks are primarily reflected in two areas: a model potential to generate insecure code (insecure coding) and its utility in cyberattacks (cyberattack helpfulness). While these bench...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 3. The efficacy of video generation models heavily depends on the quality of their training datasets. Most previous video generation models are trained on short video clips, while recently there has been increasing interest in training long video generation models directly on longer videos. However, th...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 4. While scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks, it also introduces redundant architectures, posing efficiency challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy ...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 5. Enlarging the context window of large language models (LLMs) has become a crucial research area, particularly for applications involving extremely long texts. In this work, we propose a novel training-free framework for processing long texts, utilizing a divide-and-conquer strategy to achieve compre...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 6. We present a spatial and angular Gaussian based representation and a triple splatting process, for real-time, high-quality novel lighting-and-view synthesis from multi-view point-lit input images. To describe complex appearance, we employ a Lambertian plus a mixture of angular Gaussians as an effect...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 7. While large language models (LLMs) excel on generation tasks, their decoder-only architecture often limits their potential as embedding models if no further representation finetuning is applied. Does this contradict their claim of generalists? To answer the question, we take a closer look at Mixture...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 8. Recent advances in CV and NLP have been largely driven by scaling up the number of network parameters, despite traditional theories suggesting that larger networks are prone to overfitting. These large networks avoid overfitting by integrating components that induce a simplicity bias, guiding models...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 9. Adapting medical Large Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensur...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 10. The increasing demand for versatile robotic systems to operate in diverse and dynamic environments has emphasized the importance of a generalist policy, which leverages a large cross-embodiment data corpus to facilitate broad adaptability and high-level reasoning. However, the generalist would strug...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 11. The Mutual Reinforcement Effect (MRE) investigates the synergistic relationship between word-level and text-level classifications in text classification tasks. It posits that the performance of both classification levels can be mutually enhanced. However, this mechanism has not been adequately demon...
[16.10.2024 12:23] ********************************************************************************
[16.10.2024 12:23] Abstract 12. As one of the most popular and sought-after generative models in the recent years, diffusion models have sparked the interests of many researchers and steadily shown excellent advantage in various generative tasks such as image synthesis, video generation, molecule design, 3D scene rendering and mul...
[16.10.2024 12:23] Read previous papers.
[16.10.2024 12:23] Generating reviews via LLM API.
[16.10.2024 12:23] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (MLLM). –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ MLLM —Å–ø–æ—Å–æ–±–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è—Ö, –Ω–æ –≤ –∏—Ç–æ–≥–æ–≤–æ–º –≤—ã–≤–æ–¥–µ –º–æ–≥—É—Ç –∏—Ö –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ–º –≤–∏–∑—É–∞–ª
[16.10.2024 12:23] Using data from previous issue: {"desc": "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ MTU-Bench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–∞–≤—ã–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (LLM). MTU-Bench –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –ø—è—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö –¥–æ —Å–ª–æ–∂–Ω—ã—Ö –∏ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á. –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API GPT –∏–ª–∏
[16.10.2024 12:23] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SecCodePLT - –Ω–æ–≤—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π AI –¥–ª—è –∫–æ–¥–∞. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, —Å–æ—á–µ—Ç–∞—é—â—É—é —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –∞ —Ç–∞–∫–∂–µ –≤–Ω–µ–¥—Ä–∏–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏. SecCodePLT –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω
[16.10.2024 12:23] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç LVD-2M –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ. –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 2 –º–∏–ª–ª–∏–æ–Ω–∞ –≤–∏–¥–µ–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –±–æ–ª–µ–µ 10 —Å–µ–∫—É–Ω–¥, —Å–Ω—è—Ç—ã—Ö –æ–¥–Ω–∏–º –∫–∞–¥—Ä–æ–º –∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–µ–º—ã—Ö –ø–ª–æ—Ç–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –º–µ—Ç–æ–¥–∏–∫—É –æ—Ç–±–æ—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–Ω–æ—Ç
[16.10.2024 12:23] Using data from previous issue: {"desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –Ω–∞ –±–∞–∑–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è —á–∞—Å—Ç—å —Å–ª–æ–µ–≤ –≤–Ω–∏–º–∞–Ω–∏—è (attention layers) –æ–±–ª–∞–¥–∞–µ—Ç –≤—ã—Å–æ–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç—å—é –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞ –±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–æ—Ç–µ—Ä–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–∞–ø—Ä–∏
[16.10.2024 12:23] Querying the API.
[16.10.2024 12:23] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ LLM√óMapReduce, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–∑–¥–µ–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∞ –∑–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –î–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –ø–æ—Ç–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –ø—Ä–æ—Ç–æ–∫–æ–ª —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –º–µ—Ö–∞–Ω–∏–∑–º –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ LLM√óMapReduce –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –ø—Ä–∏–º–µ–Ω–∏–º –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º LLM.",
  "categories": ["#nlp", "#rag", "#benchmark"],
  "emoji": "üìÑ",
  "title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è LLM"
}
[16.10.2024 12:23] Get embedding for a paper via LLM API.
[16.10.2024 12:23] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –æ—Å–≤–µ—â–µ–Ω–∏—è –∏ —Ä–∞–∫—É—Ä—Å–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ —É–≥–ª–æ–≤—ã—Ö –≥–∞—É—Å—Å–∏–∞–Ω–æ–≤, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ—Ü–µ—Å—Å —Ç—Ä–æ–π–Ω–æ–≥–æ —Å–ø–ª–∞—Ç—Ç–∏–Ω–≥–∞. –î–ª—è –æ–ø–∏—Å–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç—Ä–∞–∂–µ
[16.10.2024 12:23] Using data from previous issue: {"desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –º–æ–¥–µ–ª—è—Ö Mixture-of-Experts (MoE) LLM –º–æ–≥—É—Ç —Å–ª—É–∂–∏—Ç—å –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –º–Ω–æ–≥–æ–æ–±–µ—â–∞—é—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –Ω–µ —Ç—Ä–µ–±—É—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. –ê–Ω–∞–ª–∏–∑ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, —á—Ç–æ –≤–µ—Å–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏
[16.10.2024 12:23] Querying the API.
[16.10.2024 12:23] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É SimBa –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL). SimBa –≤–∫–ª—é—á–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞–±–ª—é–¥–µ–Ω–∏–π, —Ä–µ–∑–∏–¥—É–∞–ª—å–Ω—ã–π –±–ª–æ–∫ –ø—Ä—è–º–æ–π —Å–≤—è–∑–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Å–ª–æ–µ–≤ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Å–º–µ—â–µ–Ω–∏—è –∫ –ø—Ä–æ—Å—Ç–æ—Ç–µ. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ SimBa —É–ª—É—á—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ RL, –≤–∫–ª—é—á–∞—è off-policy, on-policy –∏ unsupervised –º–µ—Ç–æ–¥—ã. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SimBa –≤ –∞–ª–≥–æ—Ä–∏—Ç–º SAC –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ—Å—Ç–∏—á—å –∏–ª–∏ –ø—Ä–µ–≤–∑–æ–π—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã RL –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö —Å –≤—ã—Å–æ–∫–æ–π –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é.",
  "categories": ["#rl", "#deeplearning", "#architecture", "#scalability"],
  "emoji": "ü§ñ",
  "title": "SimBa: –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º"
}
[16.10.2024 12:23] Get embedding for a paper via LLM API.
[16.10.2024 12:23] Using data from previous issue: {"desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ü–µ–ª–µ–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö. –ê–≤—Ç–æ—Ä—ã —Å–æ–∑–¥–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∏ –∏—Å—Å–ª–µ–¥—É—é—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö LLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥—É–ª—å–Ω–æ—Å—Ç–∏ Mixture of Experts (MoE). –û–Ω–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞
[16.10.2024 12:23] Using data from previous issue: {"desc": "RoboDual - —ç—Ç–æ —Å–∏–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –¥–≤–æ–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –æ–±–æ–±—â–µ–Ω–Ω–æ–π –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫ –¥–ª—è —Ä–æ–±–æ—Ç–æ–≤. –û–±–æ–±—â–µ–Ω–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ vision-language-action –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–¥–∞—á, –∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ
[16.10.2024 12:23] Querying the API.
[16.10.2024 12:23] Got response. {
  "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –≤–∑–∞–∏–º–æ—É—Å–∏–ª–∏–≤–∞—é—â–∏–π —ç—Ñ—Ñ–µ–∫—Ç (MRE) –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞ –≤ –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–æ–≤–æ–¥—è—Ç —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ 21 –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö MRE Mix –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ç–µ–æ—Ä–∏–∏ MRE. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ MRE. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ MRE –∫ –æ–±—É—á–µ–Ω–∏—é —Å –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ—Ä–±–∞–ª–∏–∑–∞—Ç–æ—Ä–∞, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–æ F1-–º–µ—Ä—É –Ω–∞ 18 –∏–∑ 21 –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.",
  "categories": ["#nlp", "#classification", "#finetuning", "#promptlearning"],
  "emoji": "üîÑ",
  "title": "–í–∑–∞–∏–º–Ω–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ª–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞ —É–ª—É—á—à–∞–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ —è–∑—ã–∫–∞"
}
[16.10.2024 12:23] Get embedding for a paper via LLM API.
[16.10.2024 12:23] Using data from previous issue: {"desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±–∑–æ—Ä –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–¥–Ω–æ–≥–æ –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∏ –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ª–µ—Ç. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ —Ä–∞–±–æ—Ç—ã –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ —Å–∏–Ω—Ç
[16.10.2024 12:23] Loading Chinese text from previous data.
[16.10.2024 12:23] Renaming data file.
[16.10.2024 12:23] Renaming previous data. hf_papers.json to 2024-10-15_hf_papers.json
[16.10.2024 12:23] Saving new data file.
[16.10.2024 12:23] Generating page.
[16.10.2024 12:23] Generating Chinese page for reading.
[16.10.2024 12:23] Chinese vocab [{'word': 'Â§öÊ®°ÊÄÅ', 'pinyin': 'du≈ç m√≥ shu√†i', 'trans': 'multimodal'}, {'word': 'Â§ßËØ≠Ë®ÄÊ®°Âûã', 'pinyin': 'd√† y«î y√°n m√≥ x√≠ng', 'trans': 'large language model'}, {'word': 'ÂπªËßâ', 'pinyin': 'hu√†n ju√©', 'trans': 'hallucination'}, {'word': 'Áé∞Ë±°', 'pinyin': 'xi√†n xi√†ng', 'trans': 'phenomenon'}, {'word': 'ÂéüÂõ†', 'pinyin': 'yu√°n yƒ´n', 'trans': 'reason'}, {'word': 'ÈîôËØØ', 'pinyin': 'cu√≤ w√π', 'trans': 'error'}, {'word': 'ÁîüÊàê', 'pinyin': 'shƒìng ch√©ng', 'trans': 'generate'}, {'word': 'ÂØπË±°', 'pinyin': 'du√¨ xi√†ng', 'trans': 'object'}, {'word': 'ËØÜÂà´', 'pinyin': 'sh√≠ bi√©', 'trans': 'recognize'}, {'word': 'ËßÜËßâ', 'pinyin': 'sh√¨ ju√©', 'trans': 'visual'}, {'word': 'Âº∫', 'pinyin': 'qi√°ng', 'trans': 'strong'}, {'word': 'Áü•ËØÜ', 'pinyin': 'zhƒ´ shi', 'trans': 'knowledge'}, {'word': 'ÂÖàÈ™å', 'pinyin': 'xiƒÅn y√†n', 'trans': 'prior'}, {'word': 'ÊäëÂà∂', 'pinyin': 'y√¨ zh√¨', 'trans': 'suppress'}, {'word': '‰ø°ÊÅØ', 'pinyin': 'x√¨n xƒ´', 'trans': 'information'}, {'word': 'Âä®ÊÄÅ', 'pinyin': 'd√≤ng t√†i', 'trans': 'dynamic'}, {'word': 'Á∫†Ê≠£', 'pinyin': 'ji≈´ zh√®ng', 'trans': 'correct'}, {'word': 'Ëß£Á†Å', 'pinyin': 'jiƒõ m«é', 'trans': 'decode'}, {'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}, {'word': 'ÈÄÇÂ∫îÊÄß', 'pinyin': 'sh√¨ y√¨ng x√¨ng', 'trans': 'adaptive'}, {'word': 'ÈÄâÊã©', 'pinyin': 'xu«én z√©', 'trans': 'select'}, {'word': 'ÂêàÈÄÇ', 'pinyin': 'h√© sh√¨', 'trans': 'suitable'}, {'word': 'Êï¥Âêà', 'pinyin': 'zhƒõng h√©', 'trans': 'integrate'}, {'word': 'Ë∞ÉÊï¥', 'pinyin': 'ti√°o zhƒõng', 'trans': 'adjust'}, {'word': 'ÁªèÂÖ∏', 'pinyin': 'jƒ´ng di«én', 'trans': 'classical'}, {'word': 'Á≠ñÁï•', 'pinyin': 'c√® l√º√®', 'trans': 'strategy'}, {'word': 'Êó†Áºù', 'pinyin': 'w√∫ fƒìng', 'trans': 'seamless'}, {'word': 'ÁªìÂêà', 'pinyin': 'ji√© h√©', 'trans': 'combine'}, {'word': 'Â∫îÁî®', 'pinyin': 'y√¨ng y√≤ng', 'trans': 'apply'}, {'word': '‰∏çÂêå', 'pinyin': 'b√π t√≥ng', 'trans': 'different'}, {'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠ y√†n', 'trans': 'experiment'}, {'word': 'ÁªìÊûú', 'pinyin': 'ji√© gu«í', 'trans': 'result'}, {'word': 'ÊòæËëó', 'pinyin': 'xi«én zh√π', 'trans': 'significant'}, {'word': 'Èôç‰Ωé', 'pinyin': 'ji√†ng dƒ´', 'trans': 'reduce'}, {'word': 'Áéá', 'pinyin': 'l«ú', 'trans': 'rate'}]
[16.10.2024 12:23] Renaming previous page.
[16.10.2024 12:23] Renaming previous data. index.html to 2024-10-15_hf_papers.html
[16.10.2024 12:23] Renaming previous Chinese page.
[16.10.2024 12:23] Renaming previous data. zh.html to 2024-10-15_zh_reading_task.html
[16.10.2024 12:23] Writing result.
[16.10.2024 12:23] Writing Chinese reading task.
[16.10.2024 12:23] Renaming log file.
[16.10.2024 12:23] Renaming previous data. log.txt to 2024-10-15_last_log.txt
