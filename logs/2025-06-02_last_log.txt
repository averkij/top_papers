[02.06.2025 03:49] Read previous papers.
[02.06.2025 03:49] Generating top page (month).
[02.06.2025 03:49] Writing top page (month).
[02.06.2025 04:23] Read previous papers.
[02.06.2025 04:23] Get feed.
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24863
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.14752
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24878
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24521
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24850
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24417
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.24293
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23009
[02.06.2025 04:23] Get page data from previous paper. URL: https://huggingface.co/papers/2505.23844
[02.06.2025 04:23] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[02.06.2025 04:23] No deleted papers detected.
[02.06.2025 04:23] Downloading and parsing papers (pdf, html). Total: 9.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.24863.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.24863.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.24863.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.14752.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.14752.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.14752.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.24878.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.24878.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.24878.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.24521.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.24521.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.24521.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.24850.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.24850.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.24850.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.24417.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.24417.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.24417.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.24293.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.24293.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.24293.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.23009.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.23009.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.23009.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Downloading and parsing paper https://huggingface.co/papers/2505.23844.
[02.06.2025 04:23] Extra JSON file exists (./assets/json/2505.23844.json), skip PDF parsing.
[02.06.2025 04:23] Paper image links file exists (./assets/img_data/2505.23844.json), skip HTML parsing.
[02.06.2025 04:23] Success.
[02.06.2025 04:23] Enriching papers with extra data.
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 0. This paper presents AlphaOne (alpha1), a universal framework for modulating reasoning progress in large reasoning models (LRMs) at test time. alpha1 first introduces alpha moment, which represents the scaled thinking phase with a universal parameter alpha. Within this scaled pre-alpha moment phase, ...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 1. LLMSynthor enhances LLMs for efficient and statistically accurate data synthesis through distributional feedback and proposal sampling.  					AI-generated summary 				 Generating synthetic data that faithfully captures the statistical structure of real-world distributions is a fundamental challenge ...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 2. CAPTCHAs have been a critical bottleneck for deploying web agents in real-world applications, often blocking them from completing end-to-end automation tasks. While modern multimodal LLM agents have demonstrated impressive performance in static perception tasks, their ability to handle interactive, ...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 3. Recently, methods leveraging diffusion model priors to assist monocular geometric estimation (e.g., depth and normal) have gained significant attention due to their strong generalization ability. However, most existing works focus on estimating geometric properties within the camera coordinate syste...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 4. Recent advances in model distillation demonstrate that data from advanced reasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer complex reasoning abilities to smaller, efficient student models. However, standard practices employ rejection sampling, discarding incorrect reasoning...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 5. Generating accurate multilingual text with diffusion models has long been desired but remains challenging. Recent methods have made progress in rendering text in a single language, but rendering arbitrary languages is still an unexplored area. This paper introduces EasyText, a text rendering framewo...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 6. We demonstrate that the inference operations of several open-weight large language models (LLMs) can be mapped to an exactly equivalent linear system for an input sequence without modifying the model weights or altering output predictions. Extending techniques from image diffusion models that exhibi...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 7. A comprehensive TTS benchmark, EmergentTTS-Eval, automates test-case generation and evaluation using LLMs and LALM to assess nuanced and semantically complex text in speech outputs.  					AI-generated summary 				 Text-to-Speech (TTS) benchmarks often fail to capture how well models handle nuanced a...
[02.06.2025 04:23] ********************************************************************************
[02.06.2025 04:23] Abstract 8. Large language models (LLMs) have shown remarkable promise but remain challenging to continually improve through traditional finetuning, particularly when integrating capabilities from other specialized LLMs. Popular methods like ensemble and weight merging require substantial memory and struggle to...
[02.06.2025 04:23] Read previous papers.
[02.06.2025 04:23] Generating reviews via LLM API.
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#math", "#reasoning", "#training", "#benchmark", "#architecture"], "emoji": "üß†", "ru": {"title": "AlphaOne: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥—É–ª—è—Ü–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –ò–ò", "desc": "AlphaOne (alpha1) - —ç—Ç–æ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º–æ–¥—É–ª—è—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –∫—Ä—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (LRM) –≤–æ –≤—Ä–µ
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#dataset", "#synthetic", "#data"], "emoji": "üß¨", "ru": {"title": "LLMSynthor: –ü—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ç–æ—á–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö", "desc": "LLMSynthor - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –≤ —Å–∏–º—É–ª—è—Ç–æ—Ä—ã, —É—á–∏—Ç—ã–≤–∞—é—â–∏–µ —Å—Ç
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#reasoning"], "emoji": "ü§ñ", "ru": {"title": "Open CaptchaWorld: –≤—ã–∑–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Open CaptchaWorld - –ø–µ—Ä–≤—ã–π –≤–µ–±-–±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM) –≤ —Ä–µ—à–µ–Ω–∏–∏ CAPTCHA.
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#video", "#diffusion", "#optimization", "#cv"], "emoji": "üé•", "ru": {"title": "–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Ü–µ–Ω–∫–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –≤ –≤–∏–¥–µ–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ê–≤—Ç–æ—Ä—ã –ø
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#training", "#optimization", "#reasoning", "#dataset", "#math"], "emoji": "üß†", "ru": {"title": "REDI: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Reinforce
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#synthetic", "#dataset", "#multilingual", "#cv", "#diffusion"], "emoji": "üåê", "ru": {"title": "EasyText: –ø—Ä–æ—Ä—ã–≤ –≤ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–º —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç EasyText - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –º–æ–¥–µ
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#architecture", "#interpretability", "#inference", "#optimization"], "emoji": "üßÆ", "ru": {"title": "–õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –±–æ–ª—å—à–∏–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –º–æ–∂–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤ —ç–∫–≤–∏–≤–∞–ª
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#games", "#benchmark", "#open_source", "#audio"], "emoji": "üó£Ô∏è", "ru": {"title": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò", "desc": "EmergentTTS-Eval - —ç—Ç–æ –Ω–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º Text-to-Speech (TTS). –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (
[02.06.2025 04:23] Using data from previous issue: {"categories": ["#transfer_learning", "#multimodal", "#training", "#optimization"], "emoji": "üß†", "ru": {"title": "–£–º–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø—É—Ç–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞
[02.06.2025 04:23] Loading Chinese text from previous data.
[02.06.2025 04:23] Renaming data file.
[02.06.2025 04:23] Renaming previous data. hf_papers.json to ./d/2025-06-02.json
[02.06.2025 04:23] Saving new data file.
[02.06.2025 04:23] Generating page.
[02.06.2025 04:23] Renaming previous page.
[02.06.2025 04:23] Renaming previous data. index.html to ./d/2025-06-02.html
[02.06.2025 04:23] [Experimental] Generating Chinese page for reading.
[02.06.2025 04:23] Chinese vocab [{'word': 'Ëí∏È¶è', 'pinyin': 'zhƒìngli√∫', 'trans': 'distillation'}, {'word': 'Âº∫ÂåñÂ≠¶‰π†', 'pinyin': 'qi√°ng hu√† xu√© x√≠', 'trans': 'reinforcement learning'}, {'word': 'ÂèØÈ™åËØÅÂ•ñÂä±', 'pinyin': 'kƒõ y√†n zh√®ng ji«éng l√¨', 'trans': 'verifiable reward'}, {'word': 'Ë°®Ê†ºÊé®ÁêÜ', 'pinyin': 'bi«éo g√© tuƒ´ l«ê', 'trans': 'table reasoning'}, {'word': 'Êé®ÁêÜÊó∂Áº©Êîæ', 'pinyin': 'tuƒ´ l«ê sh√≠ su≈ç f√†ng', 'trans': 'inference-time scaling'}, {'word': 'Ê≥õÂåñËÉΩÂäõ', 'pinyin': 'f√†n hu√† n√©ng l√¨', 'trans': 'generalization capability'}, {'word': 'Áü≠Á≠îÈóÆÁ≠î', 'pinyin': 'du«én d√° w√®n d√°', 'trans': 'short answer Q&A'}, {'word': '‰∫ãÂÆûÈ™åËØÅ', 'pinyin': 'sh√¨ sh√≠ y√†n zh√®ng', 'trans': 'fact verification'}, {'word': 'Ëá™Áî±ÂΩ¢ÂºèÈóÆÁ≠î', 'pinyin': 'z√¨ y√≥u x√≠ng sh√¨ w√®n d√°', 'trans': 'free-form Q&A'}]
[02.06.2025 04:23] Renaming previous Chinese page.
[02.06.2025 04:23] Renaming previous data. zh.html to ./d/2025-06-01_zh_reading_task.html
[02.06.2025 04:23] Writing Chinese reading task.
[02.06.2025 04:23] Writing result.
[02.06.2025 04:23] Renaming log file.
[02.06.2025 04:23] Renaming previous data. log.txt to ./logs/2025-06-02_last_log.txt
