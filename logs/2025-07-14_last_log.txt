[14.07.2025 04:34] Read previous papers.
[14.07.2025 04:34] Generating top page (month).
[14.07.2025 04:34] Writing top page (month).
[14.07.2025 05:19] Read previous papers.
[14.07.2025 05:19] Get feed.
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08776
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.01951
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08800
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08801
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08772
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.08794
[14.07.2025 05:19] Extract page data from URL. URL: https://huggingface.co/papers/2507.08771
[14.07.2025 05:19] Get page data from previous paper. URL: https://huggingface.co/papers/2507.07151
[14.07.2025 05:19] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[14.07.2025 05:19] No deleted papers detected.
[14.07.2025 05:19] Downloading and parsing papers (pdf, html). Total: 8.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.08776.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.08776.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.08776.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.01951.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.01951.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.01951.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.08800.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.08800.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.08800.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.08801.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.08801.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.08801.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.08772.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.08772.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.08772.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.08794.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.08794.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.08794.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.08771.
[14.07.2025 05:19] Downloading paper 2507.08771 from http://arxiv.org/pdf/2507.08771v1...
[14.07.2025 05:19] Extracting affiliations from text.
[14.07.2025 05:19] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 1 1 ] . [ 1 1 7 7 8 0 . 7 0 5 2 : r Published as conference paper at COLM 2025 BlockFFN: Towards End-Side Acceleration-Friendly Mixtureof-Experts with Chunk-Level Activation Sparsity Chenyang Song, Weilin Zhao, Xu Han, Chaojun Xiao, Yingfa Chen, Yuxuan Li, Zhiyuan Liu, Maosong Sun Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China {scy22,zwl23}@mails.tsinghua.edu.cn, {han-xu,liuzy}@tsinghua.edu.cn "
[14.07.2025 05:19] Response: ```python
["Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China"]
```
[14.07.2025 05:19] Deleting PDF ./assets/pdf/2507.08771.pdf.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Downloading and parsing paper https://huggingface.co/papers/2507.07151.
[14.07.2025 05:19] Extra JSON file exists (./assets/json/2507.07151.json), skip PDF parsing.
[14.07.2025 05:19] Paper image links file exists (./assets/img_data/2507.07151.json), skip HTML parsing.
[14.07.2025 05:19] Success.
[14.07.2025 05:19] Enriching papers with extra data.
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 0. A neural rendering method uses compressed light-field tokens to efficiently represent scenes and render novel views with varying compute budgets.  					AI-generated summary 				 This paper proposes a neural rendering approach that represents a scene as "compressed light-field tokens (CLiFTs)", retai...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 1. MetaStone-S1, a reflective generative model using a self-supervised process reward model, achieves efficient reasoning and scalable performance with fewer parameters compared to existing models.  					AI-generated summary 				 We introduce our first reflective generative model MetaStone-S1, which ob...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 2. NeuralOS uses a combination of RNNs and diffusion-based rendering to simulate OS GUIs by predicting screen frames from user inputs, demonstrating realistic GUI rendering and state transitions.  					AI-generated summary 				 We introduce NeuralOS, a neural framework that simulates graphical user int...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 3. Lumos-1 is an autoregressive video generator that uses a modified LLM architecture with MM-RoPE and AR-DF to address spatiotemporal correlation and frame-wise loss imbalance, achieving competitive performance with fewer resources.  					AI-generated summary 				 Autoregressive large language models ...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 4. A part-aware diffusion framework, CoPart, enhances 3D generation by decomposing objects into contextual parts, improving complexity handling, relationship modeling, and part-level conditioning.  					AI-generated summary 				 Recent advances in 3D generation have transitioned from multi-view 2D rend...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 5. Generative reward models using LLMs are vulnerable to superficial manipulations but can be improved with data augmentation strategies.  					AI-generated summary 				 Generative reward models (also known as LLMs-as-judges), which use large language models (LLMs) to evaluate answer quality, are incre...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 6. To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while ...
[14.07.2025 05:19] ********************************************************************************
[14.07.2025 05:19] Abstract 7. Investigation of modality conflict in multimodal large language models reveals its role in causing hallucinations, with reinforcement learning emerging as the most effective mitigation strategy.  					AI-generated summary 				 Despite the impressive capabilities of multimodal large language models (...
[14.07.2025 05:19] Read previous papers.
[14.07.2025 05:19] Generating reviews via LLM API.
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#benchmark", "#3d", "#dataset"], "emoji": "üé•", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –Ω–µ–π—Ä–æ—Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ —Å –ø–æ–º–æ—â—å—é —Å–∂–∞—Ç—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Å–≤–µ—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è", "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π —Å–∂–∞—Ç—ã–µ —Ç–æ–∫–µ–Ω—ã —Å–≤–µ—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è (CLiFTs) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—Ü–µ–Ω. –ú
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#training", "#open_source", "#architecture", "#rl", "#small_models", "#reasoning"], "emoji": "üß†", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ —Å –º–µ–Ω—å—à–∏–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏: MetaStone-S1 –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏", "desc": "MetaStone-S1 - —ç—Ç–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—é—â
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#games", "#diffusion", "#dataset", "#agents", "#multimodal", "#cv"], "emoji": "üñ•Ô∏è", "ru": {"title": "–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–∏–º—É–ª—è—Ü–∏—è GUI: —à–∞–≥ –∫ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º –±—É–¥—É—â–µ–≥–æ", "desc": "NeuralOS - —ç—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Å–∏–º—É–ª–∏—Ä—É—é—â–∞—è –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –ø—É—Ç–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#training", "#games", "#architecture", "#video", "#optimization", "#multimodal"], "emoji": "üé¨", "ru": {"title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π", "desc": "Lumos-1 - —ç—Ç–æ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–µ–æ, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#games", "#3d", "#diffusion", "#dataset"], "emoji": "üß©", "ru": {"title": "–†–∞–∑–¥–µ–ª—è–π –∏ –≤–ª–∞—Å—Ç–≤—É–π: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤", "desc": "CoPart - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö. –û–Ω–∞ —Ä–∞–∑–±–∏–≤–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏, 
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#training", "#rl", "#data", "#dataset", "#optimization", "#hallucinations", "#synthetic", "#rlhf"], "emoji": "üõ°Ô∏è", "ru": {"title": "–£–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã—Ö –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π", "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ —É—è–∑–≤–∏–º–æ—Å—Ç—è–º –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥
[14.07.2025 05:19] Querying the API.
[14.07.2025 05:19] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while each token activates only a few parameters, these sparsely-activated architectures exhibit low chunk-level sparsity, indicating that the union of multiple consecutive tokens activates a large ratio of parameters. Such a sparsity pattern is unfriendly for acceleration under low-resource conditions (e.g., end-side devices) and incompatible with mainstream acceleration techniques (e.g., speculative decoding). To address these challenges, we introduce a novel MoE architecture, BlockFFN, as well as its efficient training and deployment techniques. Specifically, we use a router integrating ReLU activation and RMSNorm for differentiable and flexible routing. Next, to promote both token-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training objectives are designed, making BlockFFN more acceleration-friendly. Finally, we implement efficient acceleration kernels, combining activation sparsity and speculative decoding for the first time. The experimental results demonstrate the superior performance of BlockFFN over other MoE baselines, achieving over 80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67times speedup on real end-side devices than dense models. All codes and checkpoints are available publicly (https://github.com/thunlp/BlockFFN).
[14.07.2025 05:19] Response: {
  "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–º–µ—Å–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (MoE) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º BlockFFN –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). BlockFFN –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º—É—é –∏ –≥–∏–±–∫—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é, –æ–±—ä–µ–¥–∏–Ω—è—é—â—É—é –∞–∫—Ç–∏–≤–∞—Ü–∏—é ReLU –∏ RMSNorm. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ —Ü–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—é—â–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —á–∞–Ω–∫–æ–≤, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –º–æ–¥–µ–ª—å –±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ BlockFFN –Ω–∞–¥ –¥—Ä—É–≥–∏–º–∏ –±–∞–∑–æ–≤—ã–º–∏ MoE, –¥–æ—Å—Ç–∏–≥–∞—è –±–æ–ª–µ–µ 80% —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏ 70% –Ω–∞ —É—Ä–æ–≤–Ω–µ 8-—Ç–æ–∫–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.",

  "emoji": "üöÄ",

  "title": "BlockFFN: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–º–µ—Å–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
}
[14.07.2025 05:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

DATASET: Papers that introduce new datasets or make significant modifications to existing ones
DATA: Papers focusing on data processing, cleaning, collection, or curation methodologies
BENCHMARK: Papers proposing or analyzing model evaluation frameworks and benchmarks
AGENTS: Papers exploring autonomous agents, web agents, or agent-based architectures
CV: Papers developing computer vision methods or visual processing systems
RL: Papers investigating reinforcement learning theory or applications
RLHF: Papers specifically about human feedback in RL (PPO, DPO, etc.)
RAG: Papers advancing retrieval-augmented generation techniques
PLP: Papers about Programming Language Processing models or programming benchmarks
INFERENCE: Papers optimizing model deployment (quantization, pruning, etc.)
3D: Papers on 3D content generation, processing, or understanding
AUDIO: Papers advancing speech/audio processing or generation
VIDEO: Papers on video analysis, generation, or understanding
MULTIMODAL: Papers combining multiple input/output modalities
MATH: Papers focused on mathematical theory and algorithms
MULTILINGUAL: Papers addressing multiple languages or cross-lingual capabilities, including all non English models
ARCHITECTURE: Papers proposing novel neural architectures or components
HEALTHCARE: Papers applying ML to medical/healthcare domains
TRAINING: Papers improving model training or fine-tuning methods
ROBOTICS: Papers on robotic systems and embodied AI
SMALL_MODELS: Papers that describe models considering small, below 1 billion parameters or similar 

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while each token activates only a few parameters, these sparsely-activated architectures exhibit low chunk-level sparsity, indicating that the union of multiple consecutive tokens activates a large ratio of parameters. Such a sparsity pattern is unfriendly for acceleration under low-resource conditions (e.g., end-side devices) and incompatible with mainstream acceleration techniques (e.g., speculative decoding). To address these challenges, we introduce a novel MoE architecture, BlockFFN, as well as its efficient training and deployment techniques. Specifically, we use a router integrating ReLU activation and RMSNorm for differentiable and flexible routing. Next, to promote both token-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training objectives are designed, making BlockFFN more acceleration-friendly. Finally, we implement efficient acceleration kernels, combining activation sparsity and speculative decoding for the first time. The experimental results demonstrate the superior performance of BlockFFN over other MoE baselines, achieving over 80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67times speedup on real end-side devices than dense models. All codes and checkpoints are available publicly (https://github.com/thunlp/BlockFFN)."

[14.07.2025 05:19] Response: ```python
['ARCHITECTURE', 'TRAINING', 'INFERENCE']
```
[14.07.2025 05:19] OpenAI request. Model: gpt-4o-mini. Prompt: Analyze the following research paper text and classify it into one or more relevant topics from the list below. Consider only information from the provided text. Don't add a tag if the topic is not directly related to the article.

Topics:

AGI: Papers discussing artificial general intelligence concepts
GAMES: Papers applying ML to games or game development
INTERPRETABILITY: Papers analyzing model behavior and explanations
REASONING: Papers enhancing logical reasoning capabilities
TRANSFER_LEARNING: Papers on knowledge transfer between models/domains
GRAPHS: Papers advancing graph neural networks and applications
ETHICS: Papers addressing AI ethics, fairness, and bias
SECURITY: Papers on model security and adversarial robustness
OPTIMIZATION: Papers advancing training optimization methods
SURVEY: Papers comprehensively reviewing research areas
DIFFUSION: Papers on diffusion-based generative models
ALIGNMENT: Papers about aligning language models with human values, preferences, and intended behavior
STORY_GENERATION: Papers on story generation, including plot generation and author style adaptation
HALLUCINATIONS: Papers about the hallucinations, hallucinations analysis and mitigation
LONG_CONTEXT: Papers about long context handling, including techniques to extend context length
SYNTHETIC: Papers about using synthetic data for training, including methods for generating and leveraging artificial data
TRANSLATION: Papers on machine translation, including techniques, data and applications for translating between languages
LEAKAGE: Papers about data leakage, including issues of unintended data exposure and methods to detect or prevent it
OPEN_SOURCE: Papers that contribute to open-source projects by releasing models, datasets, or frameworks to the public
SCIENCE: Papers on scientific applications of LM including understanding of science articles and research automatization
LOW_RESOURCE: Papers that mention low-resource languages

Return only a Python flat list of topics that match the given text.

Paper text to classify:

"To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while each token activates only a few parameters, these sparsely-activated architectures exhibit low chunk-level sparsity, indicating that the union of multiple consecutive tokens activates a large ratio of parameters. Such a sparsity pattern is unfriendly for acceleration under low-resource conditions (e.g., end-side devices) and incompatible with mainstream acceleration techniques (e.g., speculative decoding). To address these challenges, we introduce a novel MoE architecture, BlockFFN, as well as its efficient training and deployment techniques. Specifically, we use a router integrating ReLU activation and RMSNorm for differentiable and flexible routing. Next, to promote both token-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training objectives are designed, making BlockFFN more acceleration-friendly. Finally, we implement efficient acceleration kernels, combining activation sparsity and speculative decoding for the first time. The experimental results demonstrate the superior performance of BlockFFN over other MoE baselines, achieving over 80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67times speedup on real end-side devices than dense models. All codes and checkpoints are available publicly (https://github.com/thunlp/BlockFFN)."

[14.07.2025 05:19] Response: ```python
['OPTIMIZATION', 'OPEN_SOURCE', 'LOW_RESOURCE']
```
[14.07.2025 05:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"This paper presents a new architecture called BlockFFN that improves the efficiency of mixture-of-experts (MoE) models by addressing issues with routing and sparsity. The authors introduce a router that uses ReLU activation and RMSNorm, allowing for more flexible and differentiable routing of parameters. They also propose training objectives that enhance both token-level and chunk-level sparsity, making the model more suitable for low-resource environments. Experimental results show that BlockFFN outperforms existing MoE models, achieving significant speedups on end-side devices while maintaining high levels of sparsity.","title":"BlockFFN: Efficient Sparsity for Faster Language Models"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='This paper presents a new architecture called BlockFFN that improves the efficiency of mixture-of-experts (MoE) models by addressing issues with routing and sparsity. The authors introduce a router that uses ReLU activation and RMSNorm, allowing for more flexible and differentiable routing of parameters. They also propose training objectives that enhance both token-level and chunk-level sparsity, making the model more suitable for low-resource environments. Experimental results show that BlockFFN outperforms existing MoE models, achieving significant speedups on end-side devices while maintaining high levels of sparsity.', title='BlockFFN: Efficient Sparsity for Faster Language Models'))
[14.07.2025 05:19] Response: ParsedChatCompletionMessage[Article](content='{"desc":"‰∏∫‰∫ÜÂáèËΩªÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ°ÁÆóË¥üÊãÖÔºåÁ®ÄÁñèÊøÄÊ¥ªÊû∂ÊûÑÔºàÂ¶Ç‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãMoEÔºâÂèóÂà∞Ë∂äÊù•Ë∂äÂ§öÁöÑÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºå‰º†ÁªüMoEÁöÑÈùûÂèØÂæÆÂíå‰∏çÁÅµÊ¥ªÁöÑË∑ØÁî±ÊñπÂºè‰ºöÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåËôΩÁÑ∂ÊØè‰∏™tokenÂè™ÊøÄÊ¥ªÂ∞ëÈáèÂèÇÊï∞Ôºå‰ΩÜËøô‰∫õÁ®ÄÁñèÊøÄÊ¥ªÊû∂ÊûÑÂú®ÂùóÁ∫ßÁ®ÄÁñèÊÄß‰∏äË°®Áé∞ËæÉ‰ΩéÔºåËøô‰ΩøÂæóÂú®‰ΩéËµÑÊ∫êÊù°‰ª∂‰∏ãÂä†ÈÄüÂèòÂæóÂõ∞Èöæ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÂûãÁöÑMoEÊû∂ÊûÑBlockFFNÔºåÂπ∂ËÆæËÆ°‰∫ÜÈ´òÊïàÁöÑËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤ÊäÄÊúØ„ÄÇ","title":"ÊèêÂçáÁ®ÄÁñèÊøÄÊ¥ªÊ®°ÂûãÁöÑÊÄßËÉΩ‰∏éÂä†ÈÄü"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=Article(desc='‰∏∫‰∫ÜÂáèËΩªÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ°ÁÆóË¥üÊãÖÔºåÁ®ÄÁñèÊøÄÊ¥ªÊû∂ÊûÑÔºàÂ¶Ç‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãMoEÔºâÂèóÂà∞Ë∂äÊù•Ë∂äÂ§öÁöÑÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºå‰º†ÁªüMoEÁöÑÈùûÂèØÂæÆÂíå‰∏çÁÅµÊ¥ªÁöÑË∑ØÁî±ÊñπÂºè‰ºöÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåËôΩÁÑ∂ÊØè‰∏™tokenÂè™ÊøÄÊ¥ªÂ∞ëÈáèÂèÇÊï∞Ôºå‰ΩÜËøô‰∫õÁ®ÄÁñèÊøÄÊ¥ªÊû∂ÊûÑÂú®ÂùóÁ∫ßÁ®ÄÁñèÊÄß‰∏äË°®Áé∞ËæÉ‰ΩéÔºåËøô‰ΩøÂæóÂú®‰ΩéËµÑÊ∫êÊù°‰ª∂‰∏ãÂä†ÈÄüÂèòÂæóÂõ∞Èöæ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÂûãÁöÑMoEÊû∂ÊûÑBlockFFNÔºåÂπ∂ËÆæËÆ°‰∫ÜÈ´òÊïàÁöÑËÆ≠ÁªÉÂíåÈÉ®ÁΩ≤ÊäÄÊúØ„ÄÇ', title='ÊèêÂçáÁ®ÄÁñèÊøÄÊ¥ªÊ®°ÂûãÁöÑÊÄßËÉΩ‰∏éÂä†ÈÄü'))
[14.07.2025 05:19] Using data from previous issue: {"categories": ["#training", "#interpretability", "#dataset", "#rl", "#hallucinations", "#multimodal"], "emoji": "ü§ñ", "ru": {"title": "–ë–æ—Ä—å–±–∞ —Å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö", "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (MLLM) –∏–∑-–∑–∞ 
[14.07.2025 05:19] Renaming data file.
[14.07.2025 05:19] Renaming previous data. hf_papers.json to ./d/2025-07-14.json
[14.07.2025 05:19] Saving new data file.
[14.07.2025 05:19] Generating page.
[14.07.2025 05:19] Renaming previous page.
[14.07.2025 05:19] Renaming previous data. index.html to ./d/2025-07-14.html
[14.07.2025 05:19] Writing result.
[14.07.2025 05:19] Renaming log file.
[14.07.2025 05:19] Renaming previous data. log.txt to ./logs/2025-07-14_last_log.txt
