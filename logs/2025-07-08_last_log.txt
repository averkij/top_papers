[08.07.2025 14:12] Read previous papers.
[08.07.2025 14:12] Generating top page (month).
[08.07.2025 14:12] Writing top page (month).
[08.07.2025 15:12] Read previous papers.
[08.07.2025 15:12] Get feed.
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.03724
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.00994
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.05163
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04447
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.05197
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.03483
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.02029
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04009
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.03253
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.03745
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.05108
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.02659
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04952
[08.07.2025 15:12] Extract page data from URL. URL: https://huggingface.co/papers/2507.03683
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04590
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04036
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.03607
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.05259
[08.07.2025 15:12] Extract page data from URL. URL: https://huggingface.co/papers/2506.21884
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04562
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04376
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.03336
[08.07.2025 15:12] Get page data from previous paper. URL: https://huggingface.co/papers/2507.04285
[08.07.2025 15:12] Obtaining deleted papers (sometimes HF Daily Papers move some articles from today to past days).
[08.07.2025 15:12] No deleted papers detected.
[08.07.2025 15:12] Downloading and parsing papers (pdf, html). Total: 23.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.03724.
[08.07.2025 15:12] Extra JSON file exists (./assets/json/2507.03724.json), skip PDF parsing.
[08.07.2025 15:12] Paper image links file exists (./assets/img_data/2507.03724.json), skip HTML parsing.
[08.07.2025 15:12] Success.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.00994.
[08.07.2025 15:12] Extra JSON file exists (./assets/json/2507.00994.json), skip PDF parsing.
[08.07.2025 15:12] Paper image links file exists (./assets/img_data/2507.00994.json), skip HTML parsing.
[08.07.2025 15:12] Success.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.05163.
[08.07.2025 15:12] Extra JSON file exists (./assets/json/2507.05163.json), skip PDF parsing.
[08.07.2025 15:12] Paper image links file exists (./assets/img_data/2507.05163.json), skip HTML parsing.
[08.07.2025 15:12] Success.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.04447.
[08.07.2025 15:12] Extra JSON file exists (./assets/json/2507.04447.json), skip PDF parsing.
[08.07.2025 15:12] Paper image links file exists (./assets/img_data/2507.04447.json), skip HTML parsing.
[08.07.2025 15:12] Success.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.05197.
[08.07.2025 15:12] Extra JSON file exists (./assets/json/2507.05197.json), skip PDF parsing.
[08.07.2025 15:12] Paper image links file exists (./assets/img_data/2507.05197.json), skip HTML parsing.
[08.07.2025 15:12] Success.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.03483.
[08.07.2025 15:12] Extra JSON file exists (./assets/json/2507.03483.json), skip PDF parsing.
[08.07.2025 15:12] Paper image links file exists (./assets/img_data/2507.03483.json), skip HTML parsing.
[08.07.2025 15:12] Success.
[08.07.2025 15:12] Downloading and parsing paper https://huggingface.co/papers/2507.02029.
[08.07.2025 15:12] Downloading paper 2507.02029 from http://arxiv.org/pdf/2507.02029v2...
[08.07.2025 15:13] Extracting affiliations from text.
[08.07.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RoboBrain 2.0 Technical Report Please see Contributions and Author List for more author details. "
[08.07.2025 15:13] Response: []
[08.07.2025 15:13] Extracting affiliations from text.
[08.07.2025 15:13] Mistral request. Model: mistral-large-latest. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"RoboBrain 2.0 Technical ReportPlease see Contributions and Author List for more author details.We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, designed to unify perception, reasoning, and planning for complex embodied tasks in physical environments. It comes in two variants: lightweight 7B model and full-scale 32B model, featuring heterogeneous architecture with vision encoder and language model. Despite its compact size, RoboBrain 2.0 achieves strong performance across wide spectrum of embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B variant achieves leading results, surpassing prior open-source and proprietary models. In particular, it supports key real-world embodied AI capabilities, including spatial understanding (e.g., affordance prediction, spatial referring, trajectory forecasting) and temporal decision-making (e.g., closed-loop interaction, multi-agent longhorizon planning, and scene graph updating). This report details the model architecture, data construction, multi-stage training strategies, infrastructure and practical applications. We hope RoboBrain 2.0 advances embodied AI research and serves as practical step toward building generalist embodied agents. The code, checkpoint and benchmark are available at https://superrobobrain.github.io. 5 2 0 2 5 ] . [ 2 9 2 0 2 0 . 7 0 5 2 : r Figure 1 Benchmark comparison across spatial and temporal reasoning. RoboBrain2.0-32B achieves best performance on both spatial and temporal reasoning benchmarks across BLINK-Spatial, RoboSpatial, RefSpatial-Bench, Where2Place, EgoPlan2 and Multi-Robot-Plan, outperforming prior open-source models and proprietary models.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1 Input Modalities and Tokenization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2 Vision Encoder and Projection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.3 LLM Decoder and Output Representations 3 Training Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1 General MLLM VQA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Spatial Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Temporal Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Training Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.1 Stage 1: Foundational Spatiotemporal Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Stage 2: Embodied Spatiotemporal Enhancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Stage 3: Chain-of-Thought Reasoning in Embodied Contexts 5 Infrastructures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1 Large-Scale Training Infrastructure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.1 Multi-Dimensional Hybrid Parallelism . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.2 Pre-Allocate Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.3 Data Pre-Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.4 Distributed Data Loading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1.5 Fault Tolerance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2 Reinforcement Fine-Tuning Infrastructure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Inference Infrastructure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5. 6 Evaluation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.1 Spatial Reasoning Capability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.2 Temporal Reasoning Capability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Conclusion and Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Contributions and Author List . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Qualitative examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.1 Examples for Pointing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.2 Examples for Affordance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.3 Examples for Trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.4 Examples for EgoPlan2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.5 Examples for Close-Loop Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.6 Examples for Multi-Robot Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.7 Examples for Synthetic Benchmarks Prompts Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.1 Spatial Understanding: Coordinates Pointing . . . . . . . . . . . . . . . . . . . . . . . . . . B.2 Spatial Understanding: Coordinates Trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.3 Spatial Understanding: Bounding Box Affordance B.4 Spatial Understanding: Freeform Q&A General Spatial Analysis . . . . . . . . . . . . . . . B.5 Temporal Understanding: Long-horizon Planning . . . . . . . . . . . . . . . . . . . . . . . . . B.6 Temporal Understanding: Closed Loop Conversation . . . . . . . . . . . . . . . . . . . . . . . B.7 Temporal Understanding: Multi-Robot Planning . . . . . . . . . . . . . . . . . . . . . . . . . 4 5 5 6 6 6 7 8 9 9 10 10 11 11 11 11 11 12 12 12 12 13 13 15 22 23 23 40 42 44 47 51 52 54 54 54 54 55 55 55 55In recent years, large language models (LLMs) and vision-language models (VLMs) have emerged as key driving forces in the advancement of general artificial intelligence (AGI). Within digital environments, these models have demonstrated "
[08.07.2025 15:13] Mistral response. {"object": "error", "message": "Service tier capacity exceeded for this model.", "type": "invalid_request_error", "param": null, "code": null}
[08.07.2025 15:13] Failed to download and parse paper https://huggingface.co/papers/2507.02029: 'choices'
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04009.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04009.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04009.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.03253.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.03253.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.03253.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.03745.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.03745.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.03745.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.05108.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.05108.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.05108.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.02659.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.02659.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.02659.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04952.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04952.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04952.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.03683.
[08.07.2025 15:13] Downloading paper 2507.03683 from http://arxiv.org/pdf/2507.03683v1...
[08.07.2025 15:13] Extracting affiliations from text.
[08.07.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"5 2 0 2 4 ] . [ 1 3 8 6 3 0 . 7 0 5 2 : r a Ankit Sonthalia1 Arnas Uselis1 Seong Joon Oh1 1Tübingen AI Center, Universität Tübingen, Germany "
[08.07.2025 15:13] Response: ```python
["Tübingen AI Center, Universität Tübingen, Germany"]
```
[08.07.2025 15:13] Deleting PDF ./assets/pdf/2507.03683.pdf.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04590.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04590.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04590.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04036.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04036.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04036.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.03607.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.03607.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.03607.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.05259.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.05259.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.05259.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2506.21884.
[08.07.2025 15:13] Downloading paper 2506.21884 from http://arxiv.org/pdf/2506.21884v1...
[08.07.2025 15:13] Extracting affiliations from text.
[08.07.2025 15:13] OpenAI request. Model: gpt-4o-mini. Prompt: I give you a contaminated text with start of ML paper. Extract all authors affiliations as a single institute, firm, company, etc. Return items as a Python plain list only with affiliations. Do not provide commentaries. If there are no affiliations return empty list.

Text:"UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields Fabian Perez1,2,, Sara Rojas2, Carlos Hinojosa2,, Hoover Rueda-Chacon1, Bernard Ghanem2 1Universidad Industrial de Santander 2 KAUST 5 2 0 2 J 7 2 ] . e [ 1 4 8 8 1 2 . 6 0 5 2 : r Figure 1. UnMix-NeRF: hyperspectral novel view synthesis framework that leverages spectral unmixing for scene editing and unsupervised material segmentation. By exploiting endmembers and abundances, our approach enables material separation and scene manipulation. "
[08.07.2025 15:13] Response: ```python
["Universidad Industrial de Santander", "KAUST"]
```
[08.07.2025 15:13] Deleting PDF ./assets/pdf/2506.21884.pdf.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04562.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04562.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04562.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04376.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04376.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04376.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.03336.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.03336.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.03336.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Downloading and parsing paper https://huggingface.co/papers/2507.04285.
[08.07.2025 15:13] Extra JSON file exists (./assets/json/2507.04285.json), skip PDF parsing.
[08.07.2025 15:13] Paper image links file exists (./assets/img_data/2507.04285.json), skip HTML parsing.
[08.07.2025 15:13] Success.
[08.07.2025 15:13] Enriching papers with extra data.
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 0. MemOS is proposed as a memory operating system for Large Language Models to enhance memory management, enabling efficient storage and retrieval, and facilitating continual learning and personalized modeling.  					AI-generated summary 				 Large Language Models (LLMs) have become an essential infras...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 1. Learning high-quality text representations is fundamental to a wide range of NLP tasks. While encoder pretraining has traditionally relied on Masked Language Modeling (MLM), recent evidence suggests that decoder models pretrained with Causal Language Modeling (CLM) can be effectively repurposed as e...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 2. A high-speed 4D capturing system using low FPS cameras with asynchronous capture and video-diffusion-based artifact correction enhances reconstruction quality.  					AI-generated summary 				 Reconstructing fast-dynamic scenes from multi-view videos is crucial for high-speed motion analysis and real...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 3. DreamVLA improves robot manipulation through a VLA framework that incorporates world knowledge, dynamic-region guidance, and a diffusion-based transformer to ensure clear, disentangled representations for action planning.  					AI-generated summary 				 Recent advances in vision-language-action (VLA...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 4. A scalable reward modeling method, Policy Discriminative Learning (POLAR), enhances reward model performance and generalizes robustly in reinforcement learning through policy comparison.  					AI-generated summary 				 We offer a novel perspective on reward modeling by formulating it as a policy dis...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 5. A large-scale dataset and verification tool are introduced for assessing and improving cross-disciplinary reasoning capabilities in multimodal models.  					AI-generated summary 				 In this paper, we introduce BMMR, a large-scale bilingual, multimodal, multi-disciplinary reasoning dataset for the c...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 6. RoboBrain 2.0, a vision-language foundation model, achieves top performance in embodied tasks through its heterogeneous architecture and multi-stage training strategies.  					AI-generated summary 				 We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, d...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 7. A unified framework called Easy Dataset synthesizes fine-tuning data from unstructured documents using a GUI and LLMs, improving domain-specific performance of LLMs while maintaining general knowledge.  					AI-generated summary 				 Large language models (LLMs) have shown impressive performance on ...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 8. RefineX is a scalable framework for improving the quality of large language model pre-training data through programmatic editing, yielding better performance than alternative methods across various downstream tasks.  					AI-generated summary 				 The foundational capabilities of large language mode...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 9. A streaming video generation model named StreamDiT, based on transformer-based diffusion models, enables real-time video generation with high content consistency and visual quality.  					AI-generated summary 				 Recently, great progress has been achieved in text-to-video (T2V) generation by scalin...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 10. Historical documents represent an invaluable cultural heritage, yet have undergone significant degradation over time through tears, water erosion, and oxidation. Existing Historical Document Restoration (HDR) methods primarily focus on single modality or limited-size restoration, failing to meet pra...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 11. OmniDraft, a unified framework, addresses cross-vocabulary mismatch and improves decoding speed by allowing a single draft model to interact dynamically with diverse target models in online settings.  					AI-generated summary 				 Speculative decoding generally dictates having a small, efficient dr...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 12. ArtifactsBench, a novel benchmark and evaluation framework, automates the assessment of visual code generation quality using temporal screenshots and a multimodal language model judge.  					AI-generated summary 				 The generative capabilities of Large Language Models (LLMs) are rapidly expanding f...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 13. Visual embedding models often capture continuous, ordinal attributes along specific axes, enabling effective image ranking with minimal supervision.  					AI-generated summary 				 We study whether visual embedding models capture continuous, ordinal attributes along linear directions, which we term ...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 14. A unified framework VLM2Vec-V2 is proposed for learning embeddings across diverse visual forms such as videos and documents, demonstrating strong performance on new tasks and improving upon existing benchmarks for images.  					AI-generated summary 				 Multimodal embedding models have been crucial ...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 15. A multimodal agent transforms documents into detailed presentation videos with audio, evaluated using a comprehensive framework involving vision-language models.  					AI-generated summary 				 We present PresentAgent, a multimodal agent that transforms long-form documents into narrated presentation...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 16. A transformer-based model predicts software vulnerability severity levels directly from text, enhancing triage efficiency and consistency.  					AI-generated summary 				 This paper presents VLAI, a transformer-based model that predicts software vulnerability severity levels directly from text descr...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 17. X-Planner, a planning system utilizing a multimodal large language model, decomposes complex text-guided image editing instructions into precise sub-instructions, ensuring localized, identity-preserving edits and achieving top performance on established benchmarks.  					AI-generated summary 				 Re...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 18. A framework combining NeRF with spectral unmixing yields accurate material segmentation and editing through hyperspectral synthesis.  					AI-generated summary 				 Neural Radiance Field (NeRF)-based segmentation methods focus on object semantics and rely solely on RGB data, lacking intrinsic materi...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 19. State-of-the-art large language models are evaluated on forecasting questions and show lower accuracy compared to human superforecasters.  					AI-generated summary 				 Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but their ability to forecast future ...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 20. As Artificial Intelligence systems evolve from monolithic models to ecosystems of specialized agents, the need for standardized communication protocols becomes increasingly critical. This paper introduces MOD-X (Modular Open Decentralized eXchange), a novel architectural framework proposal for agent...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 21. DiaFORGE is a disambiguation framework that enhances large language models' ability to invoke enterprise APIs accurately through dialogue synthesis, supervised fine-tuning, and real-world evaluation.  					AI-generated summary 				 Large language models (LLMs) are increasingly tasked with invoking e...
[08.07.2025 15:13] ********************************************************************************
[08.07.2025 15:13] Abstract 22. SeqTex leverages pretrained video foundation models to directly generate high-fidelity UV texture maps through a sequence generation approach, enhancing 3D texture generation with superior consistency and alignment.  					AI-generated summary 				 Training native 3D texture generative models remains...
[08.07.2025 15:13] Read previous papers.
[08.07.2025 15:13] Generating reviews via LLM API.
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#training", "#agi", "#rag", "#long_context", "#optimization", "#data"], "emoji": "🧠", "ru": {"title": "MemOS: операционная система памяти для более умных и адаптивных языковых моделей", "desc": "MemOS - это операционная система памяти для больших языковых моделей (LLM), предложенная
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#survey", "#optimization", "#training", "#dataset"], "emoji": "🧠", "ru": {"title": "Оптимизация предобучения энкодеров: синергия CLM и MLM", "desc": "Исследование сравнивает эффективность методов предобучения энкодеров на основе маскированного языкового моделирования (MLM) и каузаль
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#diffusion", "#3d", "#video"], "emoji": "🎥", "ru": {"title": "Высокоскоростная 4D-съемка обычными камерами", "desc": "Предлагается система высокоскоростной 4D-съемки с использованием камер с низкой частотой кадров и асинхронным захватом. Система повышает эффективную
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#robotics", "#reasoning", "#training", "#optimization", "#multimodal", "#diffusion", "#agents", "#games"], "emoji": "🤖", "ru": {"title": "DreamVLA: Интеллектуальное планирование действий робота на основе комплексного анализа окружающего мира", "desc": "DreamVLA - это новая система у
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#rlhf", "#training", "#rl"], "emoji": "🎯", "ru": {"title": "POLAR: Революция в моделировании вознаграждений для обучения с подкреплением", "desc": "В статье представлен новый метод моделирования вознаграждений в обучении с подкреплением, названный Policy Discriminat
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#multimodal", "#reasoning", "#dataset", "#benchmark", "#open_source", "#data"], "emoji": "🧠", "ru": {"title": "Новый инструмент для оценки мультидисциплинарных рассуждений ИИ", "desc": "Статья представляет BMMR - масштабный двуязычный мультимодальный датасет для оценки рассуждений в
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#agi", "#reasoning", "#architecture", "#benchmark", "#training", "#agents", "#open_source"], "emoji": "🤖", "ru": {"title": "RoboBrain 2.0: Универсальный ИИ для воплощенных задач", "desc": "RoboBrain 2.0 - это новая модель искусственного интеллекта для воплощенных задач, объединяющая
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#synthetic", "#data", "#dataset", "#open_source"], "emoji": "🧠", "ru": {"title": "Синтез данных для дообучения LLM с помощью Easy Dataset", "desc": "Easy Dataset - это унифицированный фреймворк для синтеза данных для дообучения больших языковых моделей (LLM) из неструктурированных д
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#training", "#optimization", "#data"], "emoji": "✂️", "ru": {"title": "RefineX: хирургическая точность в улучшении данных для ИИ", "desc": "RefineX - это масштабируемый фреймворк для улучшения качества данных предобучения больших языковых моделей путем программного редактирования. О
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#diffusion", "#video", "#games"], "emoji": "🎬", "ru": {"title": "StreamDiT: Реальновременная генерация видео с помощью ИИ", "desc": "StreamDiT - это модель генерации потокового видео, основанная на трансформерных диффузионных моделях. Она позволяет генерировать видео в реальном врем
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#architecture", "#cv", "#multimodal", "#dataset", "#data"], "emoji": "📜", "ru": {"title": "AutoHDR: Возрождение истории через искусственный интеллект", "desc": "Эта статья представляет новый подход к автоматизированной реставрации исторических документов под названием AutoHDR. Автор
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#games", "#inference", "#training", "#reasoning", "#multimodal"], "emoji": "🚀", "ru": {"title": "Один черновик для всех: ускорение и адаптация языковых моделей", "desc": "OmniDraft - это унифицированная система для ускорения работы языковых моделей. Она решает пробл
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#multimodal", "#benchmark", "#games", "#open_source"], "emoji": "🖥️", "ru": {"title": "Автоматизированная оценка визуального кода с помощью мультимодальных языковых моделей", "desc": "ArtifactsBench - это новый фреймворк для автоматизированной оценки качества генерации визуального к
[08.07.2025 15:13] Querying the API.
[08.07.2025 15:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

Visual embedding models often capture continuous, ordinal attributes along specific axes, enabling effective image ranking with minimal supervision.  					AI-generated summary 				 We study whether visual embedding models capture continuous, ordinal attributes along linear directions, which we term _rank axes_. We define a model as _rankable_ for an attribute if projecting embeddings onto such an axis preserves the attribute's order. Across 7 popular encoders and 9 datasets with attributes like age, crowd count, head pose, aesthetics, and recency, we find that many embeddings are inherently rankable. Surprisingly, a small number of samples, or even just two extreme examples, often suffice to recover meaningful rank axes, without full-scale supervision. These findings open up new use cases for image ranking in vector databases and motivate further study into the structure and learning of rankable embeddings. Our code is available at https://github.com/aktsonthalia/rankable-vision-embeddings.
[08.07.2025 15:13] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#games", "#rag", "#survey", "#benchmark", "#transfer_learning", "#multimodal"], "emoji": "🎥", "ru": {"title": "Единая модель эмбеддингов для всех визуальных форматов", "desc": "VLM2Vec-V2 - это унифицированная система для создания эмбеддингов различных визуальных форматов, включая в
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#cv", "#multimodal", "#agents", "#optimization", "#dataset", "#benchmark", "#games", "#interpretability"], "emoji": "🎥", "ru": {"title": "Искусственный интеллект создает презентации на уровне человека", "desc": "Статья представляет PresentAgent - мультимодального агента, преобразующ
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#security", "#architecture", "#dataset", "#data", "#training", "#open_source"], "emoji": "🛡️", "ru": {"title": "Искусственный интеллект на страже кибербезопасности: автоматическая оценка уязвимостей ПО", "desc": "Представлена модель VLAI на основе трансформера, которая предсказывает
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#dataset", "#reasoning", "#benchmark", "#multimodal", "#diffusion"], "emoji": "🎨", "ru": {"title": "X-Planner: умное планирование для точного редактирования изображений", "desc": "X-Planner - это система планирования на основе мультимодальной большой языковой модели для редактирован
[08.07.2025 15:13] Querying the API.
[08.07.2025 15:13] Claude request. Model: claude-3-5-sonnet-20240620. Prompt: Read an abstract of the ML paper and return a JSON with fields: 'desc': explanation of the paper in Russian (4 sentences), use correct machine learning terms. 'emoji': emoji that will reflect the theme of an article somehow, only one emoji. 'title': a slogan of a main idea of the article in Russian. Return only JSON and nothing else.

A framework combining NeRF with spectral unmixing yields accurate material segmentation and editing through hyperspectral synthesis.  					AI-generated summary 				 Neural Radiance Field (NeRF)-based segmentation methods focus on object semantics and rely solely on RGB data, lacking intrinsic material properties. This limitation restricts accurate material perception, which is crucial for robotics, augmented reality, simulation, and other applications. We introduce UnMix-NeRF, a framework that integrates spectral unmixing into NeRF, enabling joint hyperspectral novel view synthesis and unsupervised material segmentation. Our method models spectral reflectance via diffuse and specular components, where a learned dictionary of global endmembers represents pure material signatures, and per-point abundances capture their distribution. For material segmentation, we use spectral signature predictions along learned endmembers, allowing unsupervised material clustering. Additionally, UnMix-NeRF enables scene editing by modifying learned endmember dictionaries for flexible material-based appearance manipulation. Extensive experiments validate our approach, demonstrating superior spectral reconstruction and material segmentation to existing methods. Project page: https://www.factral.co/UnMix-NeRF.
[08.07.2025 15:13] Error getting data: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#benchmark", "#reasoning"], "emoji": "🔮", "ru": {"title": "Искусственный интеллект vs суперпрогнозисты: битва предсказателей будущего", "desc": "Современные большие языковые модели (LLM) были протестированы на задачах прогнозирования будущих событий. Результаты показали, что LLM дос
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#interpretability", "#agi", "#agents", "#architecture"], "emoji": "🔀", "ru": {"title": "MOD-X: Новый стандарт для взаимодействия ИИ-агентов", "desc": "Статья представляет MOD-X - новую архитектурную концепцию для обеспечения взаимодействия между ИИ-агентами. MOD-X п
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#optimization", "#open_source", "#dataset", "#training", "#data", "#alignment", "#benchmark", "#agents"], "emoji": "🔧", "ru": {"title": "DiaFORGE: точные вызовы API через синтез диалогов и дообучение LLM", "desc": "DiaFORGE - это фреймворк для улучшения способности больших языковых 
[08.07.2025 15:13] Using data from previous issue: {"categories": ["#architecture", "#3d", "#synthetic", "#optimization"], "emoji": "🎨", "ru": {"title": "SeqTex: прямая генерация UV-текстур с помощью видео-моделей", "desc": "SeqTex - это новый метод генерации текстур для 3D-моделей, использующий предобученные видео-модели. Он генерирует UV-развертки
[08.07.2025 15:13] Renaming data file.
[08.07.2025 15:13] Renaming previous data. hf_papers.json to ./d/2025-07-08.json
[08.07.2025 15:13] Saving new data file.
[08.07.2025 15:13] Generating page.
[08.07.2025 15:13] Renaming previous page.
[08.07.2025 15:13] Renaming previous data. index.html to ./d/2025-07-08.html
[08.07.2025 15:13] Writing result.
[08.07.2025 15:13] Renaming log file.
[08.07.2025 15:13] Renaming previous data. log.txt to ./logs/2025-07-08_last_log.txt
