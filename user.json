[
    {
        "id": "2411.10109",
        "title": "Generative Agent Simulations of 1,000 People",
        "url": "https://arxiv.org/abs/2411.10109",
        "abstract": "The promise of human behavioral simulation--general-purpose computational\nagents that replicate human behavior across domains--could enable broad\napplications in policymaking and social science. We present a novel agent\narchitecture that simulates the attitudes and behaviors of 1,052 real\nindividuals--applying large language models to qualitative interviews about\ntheir lives, then measuring how well these agents replicate the attitudes and\nbehaviors of the individuals that they represent. The generative agents\nreplicate participants' responses on the General Social Survey 85% as\naccurately as participants replicate their own answers two weeks later, and\nperform comparably in predicting personality traits and outcomes in\nexperimental replications. Our architecture reduces accuracy biases across\nracial and ideological groups compared to agents given demographic\ndescriptions. This work provides a foundation for new tools that can help\ninvestigate individual and collective behavior.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-15",
        "pub_date_card": {
            "ru": "15 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 15",
            "zh": "11æœˆ15æ—¥"
        },
        "hash": "295021638bf121fb",
        "authors": [
            "Joon Sung Park",
            "Carolyn Q. Zou",
            "Aaron Shaw",
            "Benjamin Mako Hill",
            "Carrie Cai",
            "Meredith Ringel Morris",
            "Robb Willer",
            "Percy Liang",
            "Michael S. Bernstein"
        ],
        "affiliations": [
            "Computer Science Department, Stanford University",
            "Department of Communication Studies, Northwestern University",
            "Department of Communication, University of Washington",
            "Department of Sociology, Stanford University",
            "Google DeepMind"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.10109.jpg",
        "data": {
            "categories": [
                "#agi",
                "#agents",
                "#ethics",
                "#science"
            ],
            "emoji": "ğŸ¤–",
            "ru": {
                "title": "Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¸ĞºĞ¸: Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ»ÑĞ´ĞµĞ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²ÑŒÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ³ĞµĞ½Ñ‚Ñ‹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ğ² ÑĞ¾Ñ†Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°Ñ… Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ğ¾Ğ¹ Ñ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ğ¼Ğ¸ ÑĞ°Ğ¼Ğ¸Ñ… Ğ»ÑĞ´ĞµĞ¹. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµĞ½ÑŒÑˆÑƒÑ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ Ñ€Ğ°ÑĞ¾Ğ²Ñ‹Ğ¼ Ğ¸ Ğ¸Ğ´ĞµĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°Ğ¼ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ´ĞµĞ¼Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°ĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ."
            },
            "en": {
                "title": "Simulating Human Behavior with Generative Agents",
                "desc": "This paper introduces a new type of computational agent designed to simulate human behavior by using large language models. The agents are based on qualitative interviews from 1,052 individuals, allowing them to replicate real human attitudes and behaviors. The study shows that these generative agents can accurately mimic responses from the General Social Survey, achieving an 85% accuracy rate compared to individuals' self-reports. Additionally, the architecture minimizes biases related to race and ideology, paving the way for innovative tools in social science and policymaking."
            },
            "zh": {
                "title": "æ¨¡æ‹Ÿäººç±»è¡Œä¸ºçš„æ–°å·¥å…·",
                "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„ä»£ç†æ¶æ„ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿ1052ä¸ªçœŸå®ä¸ªä½“çš„æ€åº¦å’Œè¡Œä¸ºã€‚é€šè¿‡å¯¹ä»–ä»¬ç”Ÿæ´»çš„å®šæ€§è®¿è°ˆåº”ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç ”ç©¶è€…æµ‹é‡äº†è¿™äº›ä»£ç†åœ¨å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿå¤åˆ¶æ‰€ä»£è¡¨ä¸ªä½“çš„æ€åº¦å’Œè¡Œä¸ºã€‚ç»“æœæ˜¾ç¤ºï¼Œè¿™äº›ç”Ÿæˆä»£ç†åœ¨ç¤¾ä¼šè°ƒæŸ¥ä¸­çš„å›ç­”å‡†ç¡®ç‡è¾¾åˆ°85%ï¼Œä¸å‚ä¸è€…åœ¨ä¸¤å‘¨åè‡ªæˆ‘å›ç­”çš„å‡†ç¡®ç‡ç›¸å½“ã€‚è¯¥æ¶æ„åœ¨å‡å°‘ä¸åŒç§æ—å’Œæ„è¯†å½¢æ€ç¾¤ä½“ä¹‹é—´çš„å‡†ç¡®æ€§åå·®æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä¸ºç ”ç©¶ä¸ªä½“å’Œé›†ä½“è¡Œä¸ºæä¾›äº†æ–°çš„å·¥å…·åŸºç¡€ã€‚"
            }
        }
    },
    {
        "id": "2411.15594",
        "title": "A Survey on LLM-as-a-Judge",
        "url": "https://arxiv.org/abs/2411.15594",
        "abstract": "Accurate and consistent evaluation is crucial for decision-making across\nnumerous fields, yet it remains a challenging task due to inherent\nsubjectivity, variability, and scale. Large Language Models (LLMs) have\nachieved remarkable success across diverse domains, leading to the emergence of\n\"LLM-as-a-Judge,\" where LLMs are employed as evaluators for complex tasks. With\ntheir ability to process diverse data types and provide scalable,\ncost-effective, and consistent assessments, LLMs present a compelling\nalternative to traditional expert-driven evaluations. However, ensuring the\nreliability of LLM-as-a-Judge systems remains a significant challenge that\nrequires careful design and standardization. This paper provides a\ncomprehensive survey of LLM-as-a-Judge, addressing the core question: How can\nreliable LLM-as-a-Judge systems be built? We explore strategies to enhance\nreliability, including improving consistency, mitigating biases, and adapting\nto diverse assessment scenarios. Additionally, we propose methodologies for\nevaluating the reliability of LLM-as-a-Judge systems, supported by a novel\nbenchmark designed for this purpose. To advance the development and real-world\ndeployment of LLM-as-a-Judge systems, we also discussed practical applications,\nchallenges, and future directions. This survey serves as a foundational\nreference for researchers and practitioners in this rapidly evolving field.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-23",
        "pub_date_card": {
            "ru": "23 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 23",
            "zh": "11æœˆ23æ—¥"
        },
        "hash": "5b29ec51248581eb",
        "authors": [
            "Jiawei Gu",
            "Xuhui Jiang",
            "Zhichao Shi",
            "Hexiang Tan",
            "Xuehao Zhai",
            "Chengjin Xu",
            "Wei Li",
            "Yinghan Shen",
            "Shengjie Ma",
            "Honghao Liu",
            "Yuanzhuo Wang",
            "Jian Guo"
        ],
        "affiliations": [
            "Department of Civil and Environmental Engineering, Imperial College London",
            "Gaoling School of Artificial Intelligence, Renmin University of China",
            "IDEA Research, International Digital Economy Academy",
            "Institute of Computing Technology, Chinese Academy of Sciences"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.15594.jpg",
        "data": {
            "categories": [
                "#ethics",
                "#benchmark",
                "#data",
                "#survey"
            ],
            "emoji": "âš–ï¸",
            "ru": {
                "title": "LLM ĞºĞ°Ğº Ğ±ĞµÑĞ¿Ñ€Ğ¸ÑÑ‚Ñ€Ğ°ÑÑ‚Ğ½Ñ‹Ğ¹ ÑÑƒĞ´ÑŒÑ: Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ",
                "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ¾Ğ² Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´ÑƒÑÑ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚Ğ°ĞºĞ¸Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ¸ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸. Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ LLM-as-a-Judge ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ¹ Ñ†ĞµĞ»Ğ¸. Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ‚Ğ°ĞºĞ¶Ğµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ, Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ğ²Ğ°ÑÑ‰ĞµĞ¹ÑÑ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸."
            },
            "en": {
                "title": "Building Reliable LLM-as-a-Judge Systems for Consistent Evaluations",
                "desc": "This paper discusses the use of Large Language Models (LLMs) as evaluators, termed 'LLM-as-a-Judge', which can provide consistent and scalable assessments across various tasks. It highlights the challenges of ensuring the reliability of these systems, including issues of bias and variability in evaluations. The authors propose strategies to enhance the reliability of LLM-as-a-Judge systems and introduce a novel benchmark for evaluating their performance. This comprehensive survey aims to guide researchers and practitioners in developing effective and trustworthy LLM-based evaluation systems."
            },
            "zh": {
                "title": "LLMï¼šè¯„ä¼°çš„æœªæ¥é€‰æ‹©",
                "desc": "æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¯„ä¼°å·¥å…·çš„åº”ç”¨ï¼Œç§°ä¸ºâ€œLLMä½œä¸ºè¯„åˆ¤è€…â€ã€‚LLMèƒ½å¤Ÿå¤„ç†å¤šç§æ•°æ®ç±»å‹ï¼Œæä¾›å¯æ‰©å±•ã€ç»æµä¸”ä¸€è‡´çš„è¯„ä¼°ï¼Œæˆä¸ºä¼ ç»Ÿä¸“å®¶è¯„ä¼°çš„æœ‰åŠ›æ›¿ä»£æ–¹æ¡ˆã€‚å°½ç®¡å¦‚æ­¤ï¼Œç¡®ä¿LLMä½œä¸ºè¯„åˆ¤è€…ç³»ç»Ÿçš„å¯é æ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦ç²¾å¿ƒè®¾è®¡å’Œæ ‡å‡†åŒ–ã€‚æœ¬æ–‡è¿˜æå‡ºäº†æé«˜å¯é æ€§çš„ç­–ç•¥ï¼Œå¹¶ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„åŸºå‡†æµ‹è¯•æ–¹æ³•ï¼Œä»¥è¯„ä¼°è¿™äº›ç³»ç»Ÿçš„å¯é æ€§ã€‚"
            }
        }
    },
    {
        "id": "2411.16489",
        "title": "O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?",
        "url": "https://arxiv.org/abs/2411.16489",
        "abstract": "This paper presents a critical examination of current approaches to\nreplicating OpenAI's O1 model capabilities, with particular focus on the\nwidespread but often undisclosed use of knowledge distillation techniques.\nWhile our previous work explored the fundamental technical path to O1\nreplication, this study reveals how simple distillation from O1's API, combined\nwith supervised fine-tuning, can achieve superior performance on complex\nmathematical reasoning tasks. Through extensive experiments, we show that a\nbase model fine-tuned on simply tens of thousands of samples O1-distilled\nlong-thought chains outperforms O1-preview on the American Invitational\nMathematics Examination (AIME) with minimal technical complexity. Moreover, our\ninvestigation extends beyond mathematical reasoning to explore the\ngeneralization capabilities of O1-distilled models across diverse tasks:\nhallucination, safety and open-domain QA. Notably, despite training only on\nmathematical problem-solving data, our models demonstrated strong\ngeneralization to open-ended QA tasks and became significantly less susceptible\nto sycophancy after fine-tuning. We deliberately make this finding public to\npromote transparency in AI research and to challenge the current trend of\nobscured technical claims in the field. Our work includes: (1) A detailed\ntechnical exposition of the distillation process and its effectiveness, (2) A\ncomprehensive benchmark framework for evaluating and categorizing O1\nreplication attempts based on their technical transparency and reproducibility,\n(3) A critical discussion of the limitations and potential risks of\nover-relying on distillation approaches, our analysis culminates in a crucial\nbitter lesson: while the pursuit of more capable AI systems is important, the\ndevelopment of researchers grounded in first-principles thinking is paramount.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-25",
        "pub_date_card": {
            "ru": "25 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 25",
            "zh": "11æœˆ25æ—¥"
        },
        "hash": "3b22987c1e49b378",
        "authors": [
            "Zhen Huang",
            "Haoyang Zou",
            "Xuefeng Li",
            "Yixiu Liu",
            "Yuxiang Zheng",
            "Ethan Chern",
            "Shijie Xia",
            "Yiwei Qin",
            "Weizhe Yuan",
            "Pengfei Liu"
        ],
        "affiliations": [
            "Generative AI Research Lab (GAIR)",
            "NYU",
            "SII",
            "Shanghai Jiao Tong University"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.16489.jpg",
        "data": {
            "categories": [
                "#interpretability",
                "#data",
                "#benchmark",
                "#open_source",
                "#math",
                "#reasoning",
                "#training",
                "#hallucinations"
            ],
            "emoji": "ğŸ§ ",
            "ru": {
                "title": "Ğ”Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹ ĞºĞ»ÑÑ‡ Ğº Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğº Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ OpenAI O1, ÑƒĞ´ĞµĞ»ÑÑ Ğ¾ÑĞ¾Ğ±Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ğ¾Ğ¼Ñƒ, Ğ½Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ½ĞµÑ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼Ğ¾Ğ¼Ñƒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, ĞºĞ°Ğº Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ Ğ¸Ğ· API O1 Ğ² ÑĞ¾Ñ‡ĞµÑ‚Ğ°Ğ½Ğ¸Ğ¸ Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾Ğ¹Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ O1-preview Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… O1, Ğº Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ… Ğ˜Ğ˜ Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, Ğ¼Ñ‹ÑĞ»ÑÑ‰Ğ¸Ñ… Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ°Ğ¼Ğ¸."
            },
            "en": {
                "title": "Unlocking O1: Transparency and Distillation in AI Replication",
                "desc": "This paper critically analyzes how researchers replicate the capabilities of OpenAI's O1 model, emphasizing the often hidden use of knowledge distillation techniques. It demonstrates that fine-tuning a base model with data distilled from O1's API can lead to better performance on complex mathematical reasoning tasks. The study also shows that models trained on mathematical data can generalize well to other tasks, such as open-domain question answering, while reducing issues like sycophancy. The authors advocate for transparency in AI research and provide a framework for evaluating replication efforts, highlighting the importance of foundational understanding in AI development."
            },
            "zh": {
                "title": "çŸ¥è¯†è’¸é¦ï¼šæå‡AIæ¨¡å‹æ€§èƒ½çš„å…³é”®",
                "desc": "æœ¬æ–‡å¯¹å½“å‰å¤åˆ¶OpenAIçš„O1æ¨¡å‹èƒ½åŠ›çš„æ–¹æ³•è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œç‰¹åˆ«å…³æ³¨çŸ¥è¯†è’¸é¦æŠ€æœ¯çš„å¹¿æ³›ä½¿ç”¨ã€‚ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä»O1çš„APIè¿›è¡Œç®€å•çš„è’¸é¦ï¼Œå¹¶ç»“åˆç›‘ç£å¾®è°ƒï¼Œå¯ä»¥åœ¨å¤æ‚çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å®ç°æ›´ä¼˜çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„åŸºç¡€æ¨¡å‹åœ¨ç¾å›½é‚€è¯·æ•°å­¦è€ƒè¯•ï¼ˆAIMEï¼‰ä¸­è¶…è¶Šäº†O1é¢„è§ˆï¼Œä¸”æŠ€æœ¯å¤æ‚æ€§è¾ƒä½ã€‚æ­¤å¤–ï¼Œå°½ç®¡æ¨¡å‹ä»…åœ¨æ•°å­¦é—®é¢˜è§£å†³æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†åœ¨å¼€æ”¾å¼é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸”åœ¨å¾®è°ƒåæ˜¾è‘—å‡å°‘äº†å¯¹è°„åªšçš„æ•æ„Ÿæ€§ã€‚"
            }
        }
    },
    {
        "id": "2411.00640",
        "title": "Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations",
        "url": "https://arxiv.org/abs/2411.00640",
        "abstract": "Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-01",
        "pub_date_card": {
            "ru": "1 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 1",
            "zh": "11æœˆ1æ—¥"
        },
        "hash": "0bd5a7e6c3e4a303",
        "authors": [
            "Evan Miller"
        ],
        "affiliations": [
            "Anthropic"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.00640.jpg",
        "data": {
            "categories": [
                "#data",
                "#science",
                "#benchmark"
            ],
            "emoji": "ğŸ“Š",
            "ru": {
                "title": "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ¶Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞ°Ñ… LLM. ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ÑÑ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ”Ğ°ÑÑ‚ÑÑ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑˆÑƒĞ¼Ğ°."
            },
            "en": {
                "title": "Enhancing Language Model Evaluations with Statistical Rigor",
                "desc": "This paper emphasizes the importance of proper evaluation methods for large language models (LLMs) by drawing parallels with experimental analysis in other scientific fields. It introduces statistical concepts to help researchers design and analyze their evaluation experiments effectively. The authors propose formulas for comparing model performance and offer guidelines to enhance the clarity and reliability of evaluation results. By minimizing statistical noise and maximizing the informativeness of reports, the paper aims to improve the overall understanding of LLM capabilities."
            },
            "zh": {
                "title": "ä¼˜åŒ–è¯­è¨€æ¨¡å‹è¯„ä¼°çš„å®éªŒæ–¹æ³•",
                "desc": "è¿™ç¯‡è®ºæ–‡å¼ºè°ƒäº†è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½åŠ›çš„é‡è¦æ€§ã€‚ä½œè€…æŒ‡å‡ºï¼Œè¯„ä¼°å®é™…ä¸Šæ˜¯å®éªŒï¼Œä½†ç°æœ‰æ–‡çŒ®å¾€å¾€å¿½è§†äº†å…¶ä»–ç§‘å­¦é¢†åŸŸçš„å®éªŒåˆ†æå’Œè§„åˆ’ã€‚æ–‡ç« ä¸ºå…·å¤‡ä¸€å®šç»Ÿè®¡å­¦åŸºç¡€çš„ç ”ç©¶äººå‘˜æä¾›äº†å¦‚ä½•æ€è€ƒå’Œåˆ†æè¯­è¨€æ¨¡å‹è¯„ä¼°æ•°æ®çš„æ–¹æ³•ã€‚æœ€åï¼Œä½œè€…æå‡ºäº†ä¸€äº›å…·ä½“å»ºè®®ï¼Œä»¥å‡å°‘ç»Ÿè®¡å™ªå£°å¹¶æé«˜è¯„ä¼°ç»“æœçš„ä¿¡æ¯é‡ã€‚"
            }
        }
    },
    {
        "id": "2411.11910",
        "title": "AIGS: Generating Science from AI-Powered Automated Falsification",
        "url": "https://arxiv.org/abs/2411.11910v2",
        "abstract": "Rapid development of artificial intelligence has drastically accelerated the\ndevelopment of scientific discovery. Trained with large-scale observation data,\ndeep neural networks extract the underlying patterns in an end-to-end manner\nand assist human researchers with highly-precised predictions in unseen\nscenarios. The recent rise of Large Language Models (LLMs) and the empowered\nautonomous agents enable scientists to gain help through interaction in\ndifferent stages of their research, including but not limited to literature\nreview, research ideation, idea implementation, and academic writing. However,\nAI researchers instantiated by foundation model empowered agents with\nfull-process autonomy are still in their infancy. In this paper, we study\n$\\textbf{AI-Generated Science}$ (AIGS), where agents independently and\nautonomously complete the entire research process and discover scientific laws.\nBy revisiting the definition of scientific research, we argue that\n$\\textit{falsification}$ is the essence of both human research process and the\ndesign of an AIGS system. Through the lens of falsification, prior systems\nattempting towards AI-Generated Science either lack the part in their design,\nor rely heavily on existing verification engines that narrow the use in\nspecialized domains. In this work, we propose Baby-AIGS as a baby-step\ndemonstration of a full-process AIGS system, which is a multi-agent system with\nagents in roles representing key research process. By introducing\nFalsificationAgent, which identify and then verify possible scientific\ndiscoveries, we empower the system with explicit falsification. Experiments on\nthree tasks preliminarily show that Baby-AIGS could produce meaningful\nscientific discoveries, though not on par with experienced human researchers.\nFinally, we discuss on the limitations of current Baby-AIGS, actionable\ninsights, and related ethical issues in detail.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-17",
        "pub_date_card": {
            "ru": "17 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 17",
            "zh": "11æœˆ17æ—¥"
        },
        "hash": "d10fc69f7972862b",
        "authors": [
            "Zijun Liu",
            "Kaiming Liu",
            "Yiqi Zhu",
            "Xuanyu Lei",
            "Zonghan Yang",
            "Zhenhe Zhang",
            "Peng Li",
            "Yang Liu"
        ],
        "affiliations": [
            "Department of Computer Science & Technology, Tsinghua University",
            "Institute for AI Industry Research (AIR), Tsinghua University"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.11910.jpg",
        "data": {
            "categories": [
                "#agents",
                "#healthcare",
                "#science",
                "#multimodal",
                "#ethics"
            ],
            "emoji": "ğŸ¤–",
            "ru": {
                "title": "ĞĞ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜: Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ ÑˆĞ°Ğ³Ğ¸ Ğº Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ½Ğ°ÑƒĞºĞµ",
                "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Baby-AIGS - ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, Ğ³Ğ´Ğµ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑÑ‚Ğ°Ğ¿Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ¼ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ FalsificationAgent, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Baby-AIGS ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¾ÑĞ¼Ñ‹ÑĞ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹, Ñ…Ğ¾Ñ‚Ñ Ğ¸ ÑƒÑÑ‚ÑƒĞ¿Ğ°ĞµÑ‚ Ğ¾Ğ¿Ñ‹Ñ‚Ğ½Ñ‹Ğ¼ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼-Ğ»ÑĞ´ÑĞ¼."
            },
            "en": {
                "title": "Empowering AI to Independently Discover Science",
                "desc": "This paper explores the concept of AI-Generated Science (AIGS), where autonomous agents conduct the entire research process independently. It emphasizes the importance of falsification, a key aspect of scientific inquiry, in the design of AIGS systems. The authors introduce Baby-AIGS, a multi-agent system that includes a FalsificationAgent to identify and verify potential scientific discoveries. Initial experiments indicate that Baby-AIGS can generate meaningful findings, although it still falls short compared to experienced human researchers."
            },
            "zh": {
                "title": "äººå·¥æ™ºèƒ½åŠ©åŠ›ç§‘å­¦å‘ç°çš„æœªæ¥",
                "desc": "è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½ç”Ÿæˆç§‘å­¦ï¼ˆAIGSï¼‰ï¼Œå³è‡ªä¸»å®Œæˆæ•´ä¸ªç ”ç©¶è¿‡ç¨‹çš„æ™ºèƒ½ä½“ã€‚ç ”ç©¶è€…ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºBaby-AIGSçš„ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥ä¸€ä¸ªä¸“é—¨çš„éªŒè¯æ™ºèƒ½ä½“æ¥å®ç°ç§‘å­¦å‘ç°çš„éªŒè¯ã€‚è®ºæ–‡å¼ºè°ƒäº†åœ¨ç§‘å­¦ç ”ç©¶ä¸­ï¼Œåé©³ï¼ˆfalsificationï¼‰æ˜¯æ ¸å¿ƒè¦ç´ ï¼Œå¹¶æŒ‡å‡ºç°æœ‰çš„AIGSç³»ç»Ÿåœ¨è®¾è®¡ä¸Šå­˜åœ¨ä¸è¶³ã€‚é€šè¿‡å®éªŒï¼ŒBaby-AIGSå±•ç¤ºäº†å…¶åœ¨ç§‘å­¦å‘ç°æ–¹é¢çš„æ½œåŠ›ï¼Œå°½ç®¡ä¸ç»éªŒä¸°å¯Œçš„äººç±»ç ”ç©¶è€…ç›¸æ¯”ä»æœ‰å·®è·ã€‚"
            }
        }
    }
]