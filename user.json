[
    {
        "id": "2411.15129",
        "title": "Measuring Bullshit in the Language Games played by ChatGPT",
        "url": "https://arxiv.org/pdf/2411.15129",
        "abstract": "Generative large language models (LLMs), which create text without direct\ncorrespondence to truth value, are widely understood to resemble the uses of\nlanguage described in Frankfurt's popular monograph On Bullshit. In this paper,\nwe offer a rigorous investigation of this topic, identifying how the phenomenon\nhas arisen, and how it might be analysed. In this paper, we elaborate on this\nargument to propose that LLM-based chatbots play the 'language game of\nbullshit'. We use statistical text analysis to investigate the features of this\nWittgensteinian language game, based on a dataset constructed to contrast the\nlanguage of 1,000 scientific publications with typical pseudo-scientific text\ngenerated by ChatGPT. We then explore whether the same language features can be\ndetected in two well-known contexts of social dysfunction: George Orwell's\ncritique of politics and language, and David Graeber's characterisation of\nbullshit jobs. Using simple hypothesis-testing methods, we demonstrate that a\nstatistical model of the language of bullshit can reliably relate the\nFrankfurtian artificial bullshit of ChatGPT to the political and workplace\nfunctions of bullshit as observed in natural human language.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-22",
        "pub_date_card": {
            "ru": "22 ноября",
            "en": "November 22",
            "zh": "11月22日"
        },
        "hash": "68c8dcdefb2bfe98",
        "authors": [
            "Alessandro Trevisan",
            "Harry Giddens",
            "Sarah Dillon",
            "Alan F. Blackwell"
        ],
        "affiliations": [
            "University of Cambridge"
        ],
        "pdf_title_img": "assets\\pdf\\title_img\\2411.15129.jpg",
        "data": {
            "categories": [
                "#benchmark",
                "#ethics",
                "#interpretability",
                "#dataset",
                "#data",
                "#hallucinations"
            ],
            "emoji": "🗣️",
            "ru": {
                "title": "LLM как мастера 'языковой игры болтовни'",
                "desc": "Это исследование анализирует генеративные языковые модели (LLM) с точки зрения концепции 'болтовни' (bullshit) Франкфурта. Авторы предлагают, что чат-боты на основе LLM участвуют в 'языковой игре болтовни' по Витгенштейну. Используя статистический анализ текста, они сравнивают научные публикации с псевдонаучным текстом, сгенерированным ChatGPT. Исследование также рассматривает, как эти языковые особенности проявляются в контексте политической критики Оруэлла и концепции 'бессмысленных работ' Грэбера."
            },
            "en": {
                "title": "Unveiling the Language Game of Bullshit in LLMs",
                "desc": "This paper investigates how generative large language models (LLMs) like ChatGPT produce text that resembles the concept of 'bullshit' as described by Frankfurt. It analyzes the language features of LLM-generated text compared to genuine scientific publications, using statistical text analysis. The study also connects these findings to broader social issues, such as Orwell's critique of language in politics and Graeber's notion of 'bullshit jobs'. Ultimately, it shows that the language patterns of LLMs can be statistically linked to the characteristics of bullshit in human communication."
            },
            "zh": {
                "title": "大型语言模型与胡说八道的语言游戏",
                "desc": "这篇论文探讨了生成性大型语言模型（LLMs）如何与法兰克福在《胡说八道》一书中描述的语言使用相似。作者通过统计文本分析，比较了1,000篇科学出版物与ChatGPT生成的伪科学文本的语言特征。研究还考察了在乔治·奥威尔的政治语言批评和大卫·格雷伯的胡说八道工作特征中是否存在相似的语言特征。结果表明，ChatGPT生成的人工胡说八道与自然人类语言中的政治和工作功能之间存在可靠的统计关系。"
            }
        }
    }
]