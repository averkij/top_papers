[
    {
        "id": "2411.10109",
        "title": "Generative Agent Simulations of 1,000 People",
        "url": "https://arxiv.org/abs/2411.10109",
        "abstract": "The promise of human behavioral simulation--general-purpose computational\nagents that replicate human behavior across domains--could enable broad\napplications in policymaking and social science. We present a novel agent\narchitecture that simulates the attitudes and behaviors of 1,052 real\nindividuals--applying large language models to qualitative interviews about\ntheir lives, then measuring how well these agents replicate the attitudes and\nbehaviors of the individuals that they represent. The generative agents\nreplicate participants' responses on the General Social Survey 85% as\naccurately as participants replicate their own answers two weeks later, and\nperform comparably in predicting personality traits and outcomes in\nexperimental replications. Our architecture reduces accuracy biases across\nracial and ideological groups compared to agents given demographic\ndescriptions. This work provides a foundation for new tools that can help\ninvestigate individual and collective behavior.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-15",
        "pub_date_card": {
            "ru": "15 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 15",
            "zh": "11æœˆ15æ—¥"
        },
        "hash": "295021638bf121fb",
        "authors": [
            "Joon Sung Park",
            "Carolyn Q. Zou",
            "Aaron Shaw",
            "Benjamin Mako Hill",
            "Carrie Cai",
            "Meredith Ringel Morris",
            "Robb Willer",
            "Percy Liang",
            "Michael S. Bernstein"
        ],
        "affiliations": [
            "Computer Science Department, Stanford University",
            "Department of Communication Studies, Northwestern University",
            "Department of Communication, University of Washington",
            "Department of Sociology, Stanford University",
            "Google DeepMind"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.10109.jpg",
        "data": {
            "categories": [
                "#agi",
                "#agents",
                "#ethics",
                "#science"
            ],
            "emoji": "ğŸ¤–",
            "ru": {
                "title": "Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¸ĞºĞ¸: Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ»ÑĞ´ĞµĞ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²ÑŒÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ³ĞµĞ½Ñ‚Ñ‹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ğ² ÑĞ¾Ñ†Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°Ñ… Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ğ¾Ğ¹ Ñ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ğ¼Ğ¸ ÑĞ°Ğ¼Ğ¸Ñ… Ğ»ÑĞ´ĞµĞ¹. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµĞ½ÑŒÑˆÑƒÑ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ Ñ€Ğ°ÑĞ¾Ğ²Ñ‹Ğ¼ Ğ¸ Ğ¸Ğ´ĞµĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°Ğ¼ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ´ĞµĞ¼Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°ĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ."
            },
            "en": {
                "title": "Simulating Human Behavior with Generative Agents",
                "desc": "This paper introduces a new type of computational agent designed to simulate human behavior by using large language models. The agents are based on qualitative interviews from 1,052 individuals, allowing them to replicate real human attitudes and behaviors. The study shows that these generative agents can accurately mimic responses from the General Social Survey, achieving an 85% accuracy rate compared to individuals' self-reports. Additionally, the architecture minimizes biases related to race and ideology, paving the way for innovative tools in social science and policymaking."
            },
            "zh": {
                "title": "æ¨¡æ‹Ÿäººç±»è¡Œä¸ºçš„æ–°å·¥å…·",
                "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„ä»£ç†æ¶æ„ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿ1052ä¸ªçœŸå®ä¸ªä½“çš„æ€åº¦å’Œè¡Œä¸ºã€‚é€šè¿‡å¯¹ä»–ä»¬ç”Ÿæ´»çš„å®šæ€§è®¿è°ˆåº”ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç ”ç©¶è€…æµ‹é‡äº†è¿™äº›ä»£ç†åœ¨å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿå¤åˆ¶æ‰€ä»£è¡¨ä¸ªä½“çš„æ€åº¦å’Œè¡Œä¸ºã€‚ç»“æœæ˜¾ç¤ºï¼Œè¿™äº›ç”Ÿæˆä»£ç†åœ¨ç¤¾ä¼šè°ƒæŸ¥ä¸­çš„å›ç­”å‡†ç¡®ç‡è¾¾åˆ°85%ï¼Œä¸å‚ä¸è€…åœ¨ä¸¤å‘¨åè‡ªæˆ‘å›ç­”çš„å‡†ç¡®ç‡ç›¸å½“ã€‚è¯¥æ¶æ„åœ¨å‡å°‘ä¸åŒç§æ—å’Œæ„è¯†å½¢æ€ç¾¤ä½“ä¹‹é—´çš„å‡†ç¡®æ€§åå·®æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä¸ºç ”ç©¶ä¸ªä½“å’Œé›†ä½“è¡Œä¸ºæä¾›äº†æ–°çš„å·¥å…·åŸºç¡€ã€‚"
            }
        }
    },
    {
        "id": "2411.15594",
        "title": "A Survey on LLM-as-a-Judge",
        "url": "https://arxiv.org/abs/2411.15594",
        "abstract": "Accurate and consistent evaluation is crucial for decision-making across\nnumerous fields, yet it remains a challenging task due to inherent\nsubjectivity, variability, and scale. Large Language Models (LLMs) have\nachieved remarkable success across diverse domains, leading to the emergence of\n\"LLM-as-a-Judge,\" where LLMs are employed as evaluators for complex tasks. With\ntheir ability to process diverse data types and provide scalable,\ncost-effective, and consistent assessments, LLMs present a compelling\nalternative to traditional expert-driven evaluations. However, ensuring the\nreliability of LLM-as-a-Judge systems remains a significant challenge that\nrequires careful design and standardization. This paper provides a\ncomprehensive survey of LLM-as-a-Judge, addressing the core question: How can\nreliable LLM-as-a-Judge systems be built? We explore strategies to enhance\nreliability, including improving consistency, mitigating biases, and adapting\nto diverse assessment scenarios. Additionally, we propose methodologies for\nevaluating the reliability of LLM-as-a-Judge systems, supported by a novel\nbenchmark designed for this purpose. To advance the development and real-world\ndeployment of LLM-as-a-Judge systems, we also discussed practical applications,\nchallenges, and future directions. This survey serves as a foundational\nreference for researchers and practitioners in this rapidly evolving field.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-23",
        "pub_date_card": {
            "ru": "23 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 23",
            "zh": "11æœˆ23æ—¥"
        },
        "hash": "5b29ec51248581eb",
        "authors": [
            "Jiawei Gu",
            "Xuhui Jiang",
            "Zhichao Shi",
            "Hexiang Tan",
            "Xuehao Zhai",
            "Chengjin Xu",
            "Wei Li",
            "Yinghan Shen",
            "Shengjie Ma",
            "Honghao Liu",
            "Yuanzhuo Wang",
            "Jian Guo"
        ],
        "affiliations": [
            "Department of Civil and Environmental Engineering, Imperial College London",
            "Gaoling School of Artificial Intelligence, Renmin University of China",
            "IDEA Research, International Digital Economy Academy",
            "Institute of Computing Technology, Chinese Academy of Sciences"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.15594.jpg",
        "data": {
            "categories": [
                "#ethics",
                "#benchmark",
                "#data",
                "#survey"
            ],
            "emoji": "âš–ï¸",
            "ru": {
                "title": "LLM ĞºĞ°Ğº Ğ±ĞµÑĞ¿Ñ€Ğ¸ÑÑ‚Ñ€Ğ°ÑÑ‚Ğ½Ñ‹Ğ¹ ÑÑƒĞ´ÑŒÑ: Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ",
                "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ¾Ğ² Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´ÑƒÑÑ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚Ğ°ĞºĞ¸Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ¸ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸. Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ LLM-as-a-Judge ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ¹ Ñ†ĞµĞ»Ğ¸. Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ‚Ğ°ĞºĞ¶Ğµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ, Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ğ²Ğ°ÑÑ‰ĞµĞ¹ÑÑ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸."
            },
            "en": {
                "title": "Building Reliable LLM-as-a-Judge Systems for Consistent Evaluations",
                "desc": "This paper discusses the use of Large Language Models (LLMs) as evaluators, termed 'LLM-as-a-Judge', which can provide consistent and scalable assessments across various tasks. It highlights the challenges of ensuring the reliability of these systems, including issues of bias and variability in evaluations. The authors propose strategies to enhance the reliability of LLM-as-a-Judge systems and introduce a novel benchmark for evaluating their performance. This comprehensive survey aims to guide researchers and practitioners in developing effective and trustworthy LLM-based evaluation systems."
            },
            "zh": {
                "title": "LLMï¼šè¯„ä¼°çš„æœªæ¥é€‰æ‹©",
                "desc": "æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¯„ä¼°å·¥å…·çš„åº”ç”¨ï¼Œç§°ä¸ºâ€œLLMä½œä¸ºè¯„åˆ¤è€…â€ã€‚LLMèƒ½å¤Ÿå¤„ç†å¤šç§æ•°æ®ç±»å‹ï¼Œæä¾›å¯æ‰©å±•ã€ç»æµä¸”ä¸€è‡´çš„è¯„ä¼°ï¼Œæˆä¸ºä¼ ç»Ÿä¸“å®¶è¯„ä¼°çš„æœ‰åŠ›æ›¿ä»£æ–¹æ¡ˆã€‚å°½ç®¡å¦‚æ­¤ï¼Œç¡®ä¿LLMä½œä¸ºè¯„åˆ¤è€…ç³»ç»Ÿçš„å¯é æ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦ç²¾å¿ƒè®¾è®¡å’Œæ ‡å‡†åŒ–ã€‚æœ¬æ–‡è¿˜æå‡ºäº†æé«˜å¯é æ€§çš„ç­–ç•¥ï¼Œå¹¶ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„åŸºå‡†æµ‹è¯•æ–¹æ³•ï¼Œä»¥è¯„ä¼°è¿™äº›ç³»ç»Ÿçš„å¯é æ€§ã€‚"
            }
        }
    },
    {
        "id": "2411.16489",
        "title": "O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?",
        "url": "https://arxiv.org/abs/2411.16489",
        "abstract": "This paper presents a critical examination of current approaches to\nreplicating OpenAI's O1 model capabilities, with particular focus on the\nwidespread but often undisclosed use of knowledge distillation techniques.\nWhile our previous work explored the fundamental technical path to O1\nreplication, this study reveals how simple distillation from O1's API, combined\nwith supervised fine-tuning, can achieve superior performance on complex\nmathematical reasoning tasks. Through extensive experiments, we show that a\nbase model fine-tuned on simply tens of thousands of samples O1-distilled\nlong-thought chains outperforms O1-preview on the American Invitational\nMathematics Examination (AIME) with minimal technical complexity. Moreover, our\ninvestigation extends beyond mathematical reasoning to explore the\ngeneralization capabilities of O1-distilled models across diverse tasks:\nhallucination, safety and open-domain QA. Notably, despite training only on\nmathematical problem-solving data, our models demonstrated strong\ngeneralization to open-ended QA tasks and became significantly less susceptible\nto sycophancy after fine-tuning. We deliberately make this finding public to\npromote transparency in AI research and to challenge the current trend of\nobscured technical claims in the field. Our work includes: (1) A detailed\ntechnical exposition of the distillation process and its effectiveness, (2) A\ncomprehensive benchmark framework for evaluating and categorizing O1\nreplication attempts based on their technical transparency and reproducibility,\n(3) A critical discussion of the limitations and potential risks of\nover-relying on distillation approaches, our analysis culminates in a crucial\nbitter lesson: while the pursuit of more capable AI systems is important, the\ndevelopment of researchers grounded in first-principles thinking is paramount.",
        "score": 1,
        "issue_id": 1,
        "pub_date": "2024-11-25",
        "pub_date_card": {
            "ru": "25 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
            "en": "November 25",
            "zh": "11æœˆ25æ—¥"
        },
        "hash": "3b22987c1e49b378",
        "authors": [
            "Zhen Huang",
            "Haoyang Zou",
            "Xuefeng Li",
            "Yixiu Liu",
            "Yuxiang Zheng",
            "Ethan Chern",
            "Shijie Xia",
            "Yiwei Qin",
            "Weizhe Yuan",
            "Pengfei Liu"
        ],
        "affiliations": [
            "Generative AI Research Lab (GAIR)",
            "NYU",
            "SII",
            "Shanghai Jiao Tong University"
        ],
        "pdf_title_img": "assets/pdf/title_img/2411.16489.jpg",
        "data": {
            "categories": [
                "#interpretability",
                "#data",
                "#benchmark",
                "#open_source",
                "#math",
                "#reasoning",
                "#training",
                "#hallucinations"
            ],
            "emoji": "ğŸ§ ",
            "ru": {
                "title": "Ğ”Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹ ĞºĞ»ÑÑ‡ Ğº Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğº Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ OpenAI O1, ÑƒĞ´ĞµĞ»ÑÑ Ğ¾ÑĞ¾Ğ±Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ğ¾Ğ¼Ñƒ, Ğ½Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ½ĞµÑ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼Ğ¾Ğ¼Ñƒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, ĞºĞ°Ğº Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ñ Ğ¸Ğ· API O1 Ğ² ÑĞ¾Ñ‡ĞµÑ‚Ğ°Ğ½Ğ¸Ğ¸ Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾Ğ¹Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ O1-preview Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… O1, Ğº Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ… Ğ˜Ğ˜ Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, Ğ¼Ñ‹ÑĞ»ÑÑ‰Ğ¸Ñ… Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ°Ğ¼Ğ¸."
            },
            "en": {
                "title": "Unlocking O1: Transparency and Distillation in AI Replication",
                "desc": "This paper critically analyzes how researchers replicate the capabilities of OpenAI's O1 model, emphasizing the often hidden use of knowledge distillation techniques. It demonstrates that fine-tuning a base model with data distilled from O1's API can lead to better performance on complex mathematical reasoning tasks. The study also shows that models trained on mathematical data can generalize well to other tasks, such as open-domain question answering, while reducing issues like sycophancy. The authors advocate for transparency in AI research and provide a framework for evaluating replication efforts, highlighting the importance of foundational understanding in AI development."
            },
            "zh": {
                "title": "çŸ¥è¯†è’¸é¦ï¼šæå‡AIæ¨¡å‹æ€§èƒ½çš„å…³é”®",
                "desc": "æœ¬æ–‡å¯¹å½“å‰å¤åˆ¶OpenAIçš„O1æ¨¡å‹èƒ½åŠ›çš„æ–¹æ³•è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œç‰¹åˆ«å…³æ³¨çŸ¥è¯†è’¸é¦æŠ€æœ¯çš„å¹¿æ³›ä½¿ç”¨ã€‚ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä»O1çš„APIè¿›è¡Œç®€å•çš„è’¸é¦ï¼Œå¹¶ç»“åˆç›‘ç£å¾®è°ƒï¼Œå¯ä»¥åœ¨å¤æ‚çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å®ç°æ›´ä¼˜çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„åŸºç¡€æ¨¡å‹åœ¨ç¾å›½é‚€è¯·æ•°å­¦è€ƒè¯•ï¼ˆAIMEï¼‰ä¸­è¶…è¶Šäº†O1é¢„è§ˆï¼Œä¸”æŠ€æœ¯å¤æ‚æ€§è¾ƒä½ã€‚æ­¤å¤–ï¼Œå°½ç®¡æ¨¡å‹ä»…åœ¨æ•°å­¦é—®é¢˜è§£å†³æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†åœ¨å¼€æ”¾å¼é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸”åœ¨å¾®è°ƒåæ˜¾è‘—å‡å°‘äº†å¯¹è°„åªšçš„æ•æ„Ÿæ€§ã€‚"
            }
        }
    }
]