{
    "date": {
        "ru": "21 ÑĞ½Ğ²Ğ°Ñ€Ñ",
        "en": "January 21",
        "zh": "1æœˆ21æ—¥"
    },
    "time_utc": "2025-01-21 08:13",
    "weekday": 1,
    "issue_id": 1777,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.08325",
            "title": "GameFactory: Creating New Games with Generative Interactive Videos",
            "url": "https://huggingface.co/papers/2501.08325",
            "abstract": "Generative game engines have the potential to revolutionize game development by autonomously creating new content and reducing manual workload. However, existing video-based game generation methods fail to address the critical challenge of scene generalization, limiting their applicability to existing games with fixed styles and scenes. In this paper, we present GameFactory, a framework focused on exploring scene generalization in game video generation. To enable the creation of entirely new and diverse games, we leverage pre-trained video diffusion models trained on open-domain video data. To bridge the domain gap between open-domain priors and small-scale game dataset, we propose a multi-phase training strategy that decouples game style learning from action control, preserving open-domain generalization while achieving action controllability. Using Minecraft as our data source, we release GF-Minecraft, a high-quality and diversity action-annotated video dataset for research. Furthermore, we extend our framework to enable autoregressive action-controllable game video generation, allowing the production of unlimited-length interactive game videos. Experimental results demonstrate that GameFactory effectively generates open-domain, diverse, and action-controllable game videos, representing a significant step forward in AI-driven game generation. Our dataset and project page are publicly available at https://vvictoryuki.github.io/gamefactory/.",
            "score": 37,
            "issue_id": 1773,
            "pub_date": "2025-01-14",
            "pub_date_card": {
                "ru": "14 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 14",
                "zh": "1æœˆ14æ—¥"
            },
            "hash": "0331c9576ced4090",
            "authors": [
                "Jiwen Yu",
                "Yiran Qin",
                "Xintao Wang",
                "Pengfei Wan",
                "Di Zhang",
                "Xihui Liu"
            ],
            "affiliations": [
                "Kuaishou Technology",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.08325.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#video",
                    "#open_source",
                    "#diffusion",
                    "#games",
                    "#training",
                    "#multimodal"
                ],
                "emoji": "ğŸ®",
                "ru": {
                    "title": "GameFactory: Ğ˜Ğ˜-Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¸Ğ³Ñ€",
                    "desc": "GameFactory - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸Ğ³Ñ€ Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑÑ†ĞµĞ½Ñ‹. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ½Ğ° Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ³Ñ€Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¸Ğ»Ñ Ğ¸Ğ³Ñ€Ñ‹ Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸Ğ³Ñ€ Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ĞµĞ¼ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ½ĞµĞ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹."
                },
                "en": {
                    "title": "Revolutionizing Game Development with Scene Generalization",
                    "desc": "This paper introduces GameFactory, a novel framework aimed at enhancing scene generalization in game video generation. It addresses the limitations of current methods that struggle with fixed styles and scenes by utilizing pre-trained video diffusion models on diverse video data. The authors propose a multi-phase training strategy that separates game style learning from action control, allowing for better generalization and controllability. The framework is validated using a new dataset, GF-Minecraft, which supports the generation of diverse and interactive game videos, marking a significant advancement in AI-driven game development."
                },
                "zh": {
                    "title": "GameFactoryï¼šé©å‘½æ€§çš„æ¸¸æˆè§†é¢‘ç”Ÿæˆæ¡†æ¶",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†GameFactoryæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¸¸æˆè§†é¢‘ç”Ÿæˆä¸­çš„åœºæ™¯æ³›åŒ–é—®é¢˜ã€‚ç°æœ‰çš„è§†é¢‘ç”Ÿæˆæ–¹æ³•æ— æ³•é€‚åº”ä¸åŒé£æ ¼å’Œåœºæ™¯çš„æ¸¸æˆï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚æˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå¹¶æå‡ºå¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä»¥å®ç°æ¸¸æˆé£æ ¼å­¦ä¹ ä¸åŠ¨ä½œæ§åˆ¶çš„è§£è€¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGameFactoryèƒ½å¤Ÿæœ‰æ•ˆç”Ÿæˆå¼€æ”¾åŸŸã€å¤šæ ·åŒ–ä¸”å¯æ§çš„æ¸¸æˆè§†é¢‘ï¼Œæ¨åŠ¨äº†AIé©±åŠ¨çš„æ¸¸æˆç”ŸæˆæŠ€æœ¯çš„å‘å±•ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-01-20.html",
    "link_next": "2025-01-22.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "20.01",
        "en": "01/20",
        "zh": "1æœˆ20æ—¥"
    },
    "short_date_next": {
        "ru": "22.01",
        "en": "01/22",
        "zh": "1æœˆ22æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« æ¢è®¨äº†ä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ—¶é—´è®¡ç®—çš„æ¼”åŒ–æœç´¢ç­–ç•¥ã€‚è¯¥æ–¹æ³•ç§°ä¸ºâ€œå¿ƒæ™ºæ¼”åŒ–â€ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆã€é‡ç»„å’Œä¼˜åŒ–å€™é€‰å“åº”ã€‚è¿™ç§æ–¹æ³•é¿å…äº†åœ¨æœ‰è§£å†³æ–¹æ¡ˆè¯„ä¼°å™¨æ—¶æ­£å¼å®šä¹‰åº•å±‚æ¨ç†é—®é¢˜çš„éœ€è¦ã€‚åœ¨æ§åˆ¶æ¨ç†æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œå¿ƒæ™ºæ¼”åŒ–åœ¨è‡ªç„¶è¯­è¨€è§„åˆ’ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºå…¶ä»–æ¨ç†ç­–ç•¥ï¼Œå¦‚Best-of-Nå’ŒSequential Revisionã€‚åœ¨TravelPlannerå’ŒNatural PlanåŸºå‡†æµ‹è¯•ä¸­ï¼Œå¿ƒæ™ºæ¼”åŒ–åœ¨ä¸ä½¿ç”¨æ­£å¼æ±‚è§£å™¨çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨Gemini 1.5 Proè§£å†³äº†è¶…è¿‡98%çš„é—®é¢˜å®ä¾‹ã€‚",
        "title": "Evolving Deeper LLM Thinking",
        "pinyin": "è¿™ç¯‡æ–‡ç« æ¢è®¨äº†ä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ—¶é—´è®¡ç®—çš„æ¼”åŒ–æœç´¢ç­–ç•¥ã€‚è¯¥æ–¹æ³•ç§°ä¸ºâ€œå¿ƒæ™ºæ¼”åŒ–â€ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆã€é‡ç»„å’Œä¼˜åŒ–å€™é€‰å“åº”ã€‚è¿™ç§æ–¹æ³•é¿å…äº†åœ¨æœ‰è§£å†³æ–¹æ¡ˆè¯„ä¼°å™¨æ—¶æ­£å¼å®šä¹‰åº•å±‚æ¨ç†é—®é¢˜çš„éœ€è¦ã€‚åœ¨æ§åˆ¶æ¨ç†æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œå¿ƒæ™ºæ¼”åŒ–åœ¨è‡ªç„¶è¯­è¨€è§„åˆ’ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºå…¶ä»–æ¨ç†ç­–ç•¥ï¼Œå¦‚Best-of-Nå’ŒSequential Revisionã€‚åœ¨TravelPlannerå’ŒNatural PlanåŸºå‡†æµ‹è¯•ä¸­ï¼Œå¿ƒæ™ºæ¼”åŒ–åœ¨ä¸ä½¿ç”¨æ­£å¼æ±‚è§£å™¨çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨Gemini 1.5 Proè§£å†³äº†è¶…è¿‡98%çš„é—®é¢˜å®ä¾‹ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng tÃ ntÃ o le yÄ« zhÇ’ng yÃ²ngyÃº dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng tuÄ«lÇ shÃ­jiÄn jÃ¬suÃ n de yÇnhuÃ  sÅusuÇ’ cÃ¨lÃ¼Ã¨. GÄi fÄngfÇ chÄ“ngwÃ©i â€œxÄ«nzhÃ¬ yÇnhuÃ â€, shÇyÃ²ng yÇ”yÃ¡n mÃ³xÃ­ng shÄ“ngchÃ©ng, chÃ³ngzÇ” hÃ© yÅuhuÃ  hÃ²uxuÇn xÇngyÃ¬ng. ZhÃ¨ zhÇ’ng fÄngfÇ bÃ¬miÇn le zÃ i yÇ’u jiÄ›juÃ© fÄng'Ã n pÃ­ngjiÃ qÃ¬ shÃ­ zhÃ¨ngshÃ¬ dÃ¬ngyÃ¬ dÇcÃ©ng tuÄ«lÇ wÃ¨ntÃ­ de xÅ«yÃ o. ZÃ i kÃ²ngzhÃ¬ tuÄ«lÇ chÃ©ngbÄ›n de qÃ­ngkuÃ ng xiÃ , xÄ«nzhÃ¬ yÇnhuÃ  zÃ i zÃ¬rÃ¡n yÇ”yÃ¡n guÄ«huÃ  rÃ¨nwÃ¹ zhÅng xiÇnzhÃ¹ yÅuqÃ­ qÃ­tÄ tuÄ«lÇ cÃ¨lÃ¼Ã¨, rÃº Best-of-N hÃ© Sequential Revision. ZÃ i TravelPlanner hÃ© Natural Plan jÄ«zhÇ”n cÃ¨shÃ¬ zhÅng, xÄ«nzhÃ¬ yÇnhuÃ  zÃ i bÃ¹ shÇyÃ²ng zhÃ¨ngshÃ¬ qiÃºjiÄ›qÃ¬ de qÃ­ngkuÃ ng xiÃ , shÇyÃ²ng Gemini 1.5 Pro jiÄ›juÃ© le chÄoguÃ² 98% de wÃ¨ntÃ­ shÃ¬lÃ¬.",
        "vocab": "[\n    {\"word\": \"æ¢è®¨\", \"pinyin\": \"tÃ n tÃ o\", \"trans\": \"discuss\"},\n    {\"word\": \"æ¼”åŒ–\", \"pinyin\": \"yÇn huÃ \", \"trans\": \"evolution\"},\n    {\"word\": \"æœç´¢\", \"pinyin\": \"sÅu suÇ’\", \"trans\": \"search\"},\n    {\"word\": \"ç­–ç•¥\", \"pinyin\": \"cÃ¨ lÃ¼Ã¨\", \"trans\": \"strategy\"},\n    {\"word\": \"å¿ƒæ™º\", \"pinyin\": \"xÄ«n zhÃ¬\", \"trans\": \"mind\"},\n    {\"word\": \"ç”Ÿæˆ\", \"pinyin\": \"shÄ“ng chÃ©ng\", \"trans\": \"generate\"},\n    {\"word\": \"é‡ç»„\", \"pinyin\": \"chÃ³ng zÇ”\", \"trans\": \"recombine\"},\n    {\"word\": \"ä¼˜åŒ–\", \"pinyin\": \"yÅu huÃ \", \"trans\": \"optimize\"},\n    {\"word\": \"å€™é€‰\", \"pinyin\": \"hÃ²u xuÇn\", \"trans\": \"candidate\"},\n    {\"word\": \"å“åº”\", \"pinyin\": \"xiÇng yÃ¬ng\", \"trans\": \"response\"},\n    {\"word\": \"é¿å…\", \"pinyin\": \"bÃ¬ miÇn\", \"trans\": \"avoid\"},\n    {\"word\": \"è§£å†³æ–¹æ¡ˆ\", \"pinyin\": \"jiÄ› juÃ© fÄng Ã n\", \"trans\": \"solution\"},\n    {\"word\": \"è¯„ä¼°å™¨\", \"pinyin\": \"pÃ­ng gÅ« qÃ¬\", \"trans\": \"evaluator\"},\n    {\"word\": \"å®šä¹‰\", \"pinyin\": \"dÃ¬ng yÃ¬\", \"trans\": \"define\"},\n    {\"word\": \"åº•å±‚\", \"pinyin\": \"dÇ cÃ©ng\", \"trans\": \"underlying\"},\n    {\"word\": \"æ¨ç†\", \"pinyin\": \"tuÄ« lÇ\", \"trans\": \"reasoning\"},\n    {\"word\": \"æˆæœ¬\", \"pinyin\": \"chÃ©ng bÄ›n\", \"trans\": \"cost\"},\n    {\"word\": \"æ˜¾è‘—\", \"pinyin\": \"xiÇn zhÃ¹\", \"trans\": \"significant\"},\n    {\"word\": \"ä¼˜äº\", \"pinyin\": \"yÅu yÃº\", \"trans\": \"superior to\"},\n    {\"word\": \"è§„åˆ’\", \"pinyin\": \"guÄ« huÃ \", \"trans\": \"planning\"},\n    {\"word\": \"ä»»åŠ¡\", \"pinyin\": \"rÃ¨n wu\", \"trans\": \"task\"},\n    {\"word\": \"åŸºå‡†\", \"pinyin\": \"jÄ« zhÇ”n\", \"trans\": \"benchmark\"},\n    {\"word\": \"æµ‹è¯•\", \"pinyin\": \"cÃ¨ shÃ¬\", \"trans\": \"test\"},\n    {\"word\": \"å®ä¾‹\", \"pinyin\": \"shÃ­ lÃ¬\", \"trans\": \"instance\"},\n    {\"word\": \"æ±‚è§£å™¨\", \"pinyin\": \"qiÃº jiÄ› qÃ¬\", \"trans\": \"solver\"}\n]",
        "trans": "This article discusses an evolutionary search strategy for calculating the inference time of large language models. The method, known as \"Mental Evolution,\" employs language models to generate, recombine, and optimize candidate responses. This approach eliminates the need to formally define underlying inference problems when a solution evaluator is available. Under the constraint of controlling inference costs, Mental Evolution significantly outperforms other inference strategies, such as Best-of-N and Sequential Revision, in natural language planning tasks. In the TravelPlanner and Natural Plan benchmarks, Mental Evolution solved over 98% of problem instances using Gemini 1.5 Pro without the need for a formal solver.",
        "update_ts": "2025-01-20 09:11"
    }
}