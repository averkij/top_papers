{
    "date": {
        "ru": "23 Ğ¼Ğ°Ñ",
        "en": "May 23",
        "zh": "5æœˆ23æ—¥"
    },
    "time_utc": "2025-05-23 02:30",
    "weekday": 4,
    "issue_id": 3914,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.16410",
            "title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement\n  Learning",
            "url": "https://huggingface.co/papers/2505.16410",
            "abstract": "Tool-Star, an RL-based framework, enables LLMs to autonomously use multiple tools for stepwise reasoning, leveraging data synthesis and hierarchical reward design.  \t\t\t\t\tAI-generated summary \t\t\t\t Recently, large language models (LLMs) have shown remarkable reasoning capabilities via large-scale reinforcement learning (RL). However, leveraging the RL algorithm to empower effective multi-tool collaborative reasoning in LLMs remains an open challenge. In this paper, we introduce Tool-Star, an RL-based framework designed to empower LLMs to autonomously invoke multiple external tools during stepwise reasoning. Tool-Star integrates six types of tools and incorporates systematic designs in both data synthesis and training. To address the scarcity of tool-use data, we propose a general tool-integrated reasoning data synthesis pipeline, which combines tool-integrated prompting with hint-based sampling to automatically and scalably generate tool-use trajectories. A subsequent quality normalization and difficulty-aware classification process filters out low-quality samples and organizes the dataset from easy to hard. Furthermore, we propose a two-stage training framework to enhance multi-tool collaborative reasoning by: (1) cold-start fine-tuning, which guides LLMs to explore reasoning patterns via tool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with hierarchical reward design, which reinforces reward understanding and promotes effective tool collaboration. Experimental analyses on over 10 challenging reasoning benchmarks highlight the effectiveness and efficiency of Tool-Star. The code is available at https://github.com/dongguanting/Tool-Star.",
            "score": 6,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "acbe5c0b965cb7af",
            "authors": [
                "Guanting Dong",
                "Yifei Chen",
                "Xiaoxi Li",
                "Jiajie Jin",
                "Hongjin Qian",
                "Yutao Zhu",
                "Hangyu Mao",
                "Guorui Zhou",
                "Zhicheng Dou",
                "Ji-Rong Wen"
            ],
            "affiliations": [
                "BAAI",
                "Kuaishou Technology",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16410.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "ğŸ› ï¸",
                "ru": {
                    "title": "Tool-Star: ĞĞ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Tool-Star - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ ÑˆĞµÑÑ‚ÑŒ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğº ÑĞ¸Ğ½Ñ‚ĞµĞ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñ‹ Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ 10 ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Tool-Star."
                },
                "en": {
                    "title": "Empowering LLMs with Multi-Tool Collaborative Reasoning",
                    "desc": "Tool-Star is a reinforcement learning (RL) framework that enhances large language models (LLMs) by enabling them to autonomously utilize multiple external tools for stepwise reasoning. It addresses the challenge of effective multi-tool collaboration by integrating a systematic approach to data synthesis and hierarchical reward design. The framework includes a novel data synthesis pipeline that generates tool-use trajectories and organizes them by difficulty, ensuring high-quality training data. Tool-Star's two-stage training process improves LLMs' reasoning capabilities through fine-tuning and a self-critic RL algorithm, leading to significant performance gains on various reasoning tasks."
                },
                "zh": {
                    "title": "Tool-Starï¼šèµ‹èƒ½LLMçš„å¤šå·¥å…·åä½œæ¨ç†",
                    "desc": "Tool-Staræ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿè‡ªä¸»ä½¿ç”¨å¤šä¸ªå·¥å…·è¿›è¡Œé€æ­¥æ¨ç†ã€‚è¯¥æ¡†æ¶æ•´åˆäº†å…­ç§å·¥å…·ï¼Œå¹¶åœ¨æ•°æ®åˆæˆå’Œè®­ç»ƒæ–¹é¢è¿›è¡Œäº†ç³»ç»Ÿè®¾è®¡ï¼Œä»¥è§£å†³å·¥å…·ä½¿ç”¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚é€šè¿‡ç»“åˆå·¥å…·é›†æˆæç¤ºå’ŒåŸºäºæç¤ºçš„é‡‡æ ·ï¼ŒTool-Starèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå·¥å…·ä½¿ç”¨è½¨è¿¹ï¼Œå¹¶é€šè¿‡è´¨é‡æ ‡å‡†åŒ–å’Œéš¾åº¦æ„ŸçŸ¥åˆ†ç±»æ¥è¿‡æ»¤ä½è´¨é‡æ ·æœ¬ã€‚æœ€åï¼ŒTool-Staré‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œå¢å¼ºå¤šå·¥å…·åä½œæ¨ç†èƒ½åŠ›ï¼Œæå‡äº†æ¨¡å‹çš„æ¨ç†æ•ˆæœå’Œæ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14625",
            "title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM\n  Reasoning",
            "url": "https://huggingface.co/papers/2505.14625",
            "abstract": "Reinforcement Learning (RL) has become a powerful tool for enhancing the reasoning abilities of large language models (LLMs) by optimizing their policies with reward signals. Yet, RL's success relies on the reliability of rewards, which are provided by verifiers. In this paper, we expose and analyze a widespread problem--false negatives--where verifiers wrongly reject correct model outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals that over 38% of model-generated responses suffer from false negatives, where the verifier fails to recognize correct answers. We show, both empirically and theoretically, that these false negatives severely impair RL training by depriving the model of informative gradient signals and slowing convergence. To mitigate this, we propose tinyV, a lightweight LLM-based verifier that augments existing rule-based methods, which dynamically identifies potential false negatives and recovers valid responses to produce more accurate reward estimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts pass rates by up to 10% and accelerates convergence relative to the baseline. Our findings highlight the critical importance of addressing verifier false negatives and offer a practical approach to improve RL-based fine-tuning of LLMs. Our code is available at https://github.com/uw-nsl/TinyV.",
            "score": 4,
            "issue_id": 3914,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 Ğ¼Ğ°Ñ",
                "en": "May 20",
                "zh": "5æœˆ20æ—¥"
            },
            "hash": "0bcb0b140b7623c3",
            "authors": [
                "Zhangchen Xu",
                "Yuetai Li",
                "Fengqing Jiang",
                "Bhaskar Ramasubramanian",
                "Luyao Niu",
                "Bill Yuchen Lin",
                "Radha Poovendran"
            ],
            "affiliations": [
                "University of Washington",
                "Western Washington University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14625.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#reasoning",
                    "#training",
                    "#dataset",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ‘Ğ¾Ñ€ÑŒĞ±Ğ° Ñ Ğ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ RL-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ñ…, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ 38% Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½ĞµĞ²ĞµÑ€Ğ½Ğ¾ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ÑÑÑ‚ÑÑ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒÑ…ÑƒĞ´ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ»ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½Ñ‹Ğ¹ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ tinyV Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ LLM, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ tinyV Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° 10% Ğ¸ ÑƒÑĞºĞ¾Ñ€ÑĞµÑ‚ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ LLM Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ RL Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…."
                },
                "en": {
                    "title": "Enhancing RL Training by Tackling Verifier False Negatives with TinyV",
                    "desc": "This paper discusses the challenges of using Reinforcement Learning (RL) to improve large language models (LLMs) due to the issue of false negatives from verifiers. False negatives occur when verifiers incorrectly reject correct outputs from the model, which can hinder the RL training process by limiting the feedback the model receives. The authors analyze a dataset and find that a significant portion of model responses are misclassified, leading to slower learning and convergence. To address this, they introduce TinyV, a new verifier that enhances existing methods by identifying and correcting these false negatives, resulting in improved performance on math-reasoning tasks."
                },
                "zh": {
                    "title": "è§£å†³å‡é˜´æ€§ï¼Œæå‡å¼ºåŒ–å­¦ä¹ æ•ˆæœï¼",
                    "desc": "å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ˜¯ä¸€ç§é€šè¿‡å¥–åŠ±ä¿¡å·ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç­–ç•¥çš„å¼ºå¤§å·¥å…·ã€‚ç„¶è€Œï¼ŒRLçš„æˆåŠŸä¾èµ–äºéªŒè¯è€…æä¾›çš„å¯é å¥–åŠ±ï¼Œè€Œæˆ‘ä»¬å‘ç°ä¸€ä¸ªæ™®éå­˜åœ¨çš„é—®é¢˜â€”â€”å‡é˜´æ€§ï¼Œå³éªŒè¯è€…é”™è¯¯åœ°æ‹’ç»æ­£ç¡®çš„æ¨¡å‹è¾“å‡ºã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¶…è¿‡38%çš„æ¨¡å‹ç”Ÿæˆçš„å“åº”å—åˆ°å‡é˜´æ€§çš„å½±å“ï¼Œè¿™ä¸¥é‡æŸå®³äº†RLè®­ç»ƒçš„æ•ˆæœã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†tinyVï¼Œä¸€ä¸ªè½»é‡çº§çš„LLMåŸºç¡€éªŒè¯å™¨ï¼Œå¯ä»¥åŠ¨æ€è¯†åˆ«æ½œåœ¨çš„å‡é˜´æ€§ï¼Œä»è€Œæé«˜å¥–åŠ±ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16839",
            "title": "LaViDa: A Large Diffusion Language Model for Multimodal Understanding",
            "url": "https://huggingface.co/papers/2505.16839",
            "abstract": "LaViDa, a family of vision-language models built on discrete diffusion models, offers competitive performance on multimodal benchmarks with advantages in speed, controllability, and bidirectional reasoning.  \t\t\t\t\tAI-generated summary \t\t\t\t Modern Vision-Language Models (VLMs) can solve a wide range of tasks requiring visual reasoning. In real-world scenarios, desirable properties for VLMs include fast inference and controllable generation (e.g., constraining outputs to adhere to a desired format). However, existing autoregressive (AR) VLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs) offer a promising alternative, enabling parallel decoding for faster inference and bidirectional context for controllable generation through text-infilling. While effective in language-only settings, DMs' potential for multimodal tasks is underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build LaViDa by equipping DMs with a vision encoder and jointly fine-tune the combined parts for multimodal instruction following. To address challenges encountered, LaViDa incorporates novel techniques such as complementary masking for effective training, prefix KV cache for efficient inference, and timestep shifting for high-quality sampling. Experiments show that LaViDa achieves competitive or superior performance to AR VLMs on multi-modal benchmarks such as MMMU, while offering unique advantages of DMs, including flexible speed-quality tradeoff, controllability, and bidirectional reasoning. On COCO captioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x speedup. On bidirectional tasks, it achieves +59% improvement on Constrained Poem Completion. These results demonstrate LaViDa as a strong alternative to AR VLMs. Code and models will be released in the camera-ready version.",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "9e2202389256fc59",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Hritik Bansal",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Jason Kuen",
                "Zhe Lin",
                "Kai-Wei Chang",
                "Aditya Grover"
            ],
            "affiliations": [
                "Adobe Research",
                "Panasonic AI Research",
                "Salesforce Research",
                "UCLA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16839.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#architecture",
                    "#training",
                    "#games",
                    "#cv",
                    "#diffusion"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "LaViDa: Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¸ Ğ³Ğ¸Ğ±ĞºĞ¸Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸",
                    "desc": "LaViDa - ÑÑ‚Ğ¾ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ¾ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞĞ½Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ² ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸, ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ´Ğ²ÑƒĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¸. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, LaViDa Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ¸ Ğ´Ğ²ÑƒĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ LaViDa Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¸Ğ»Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "LaViDa: Fast and Controllable Vision-Language Models",
                    "desc": "LaViDa is a new family of vision-language models that utilize discrete diffusion models to enhance performance on multimodal tasks. It addresses the limitations of traditional autoregressive models by providing faster inference and better control over output generation. By integrating a vision encoder and employing techniques like complementary masking and prefix KV cache, LaViDa achieves high-quality results while maintaining efficiency. Experimental results show that LaViDa outperforms existing models in various benchmarks, demonstrating its potential as a robust alternative in the field of vision-language processing."
                },
                "zh": {
                    "title": "LaViDaï¼šé«˜æ•ˆå¯æ§çš„è§†è§‰-è¯­è¨€æ¨¡å‹",
                    "desc": "LaViDaæ˜¯ä¸€ç§åŸºäºç¦»æ•£æ‰©æ•£æ¨¡å‹çš„è§†è§‰-è¯­è¨€æ¨¡å‹å®¶æ—ï¼Œèƒ½å¤Ÿåœ¨å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚ä¸ç°æœ‰çš„è‡ªå›å½’è§†è§‰-è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼ŒLaViDaåœ¨æ¨ç†é€Ÿåº¦ã€å¯æ§æ€§å’ŒåŒå‘æ¨ç†æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆè§†è§‰ç¼–ç å™¨å’Œè”åˆå¾®è°ƒæŠ€æœ¯ï¼Œæå‡äº†å¤šæ¨¡æ€ä»»åŠ¡çš„å¤„ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLaViDaåœ¨å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿæ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºè‡ªå›å½’æ¨¡å‹å¼ºæœ‰åŠ›æ›¿ä»£å“çš„æ½œåŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16707",
            "title": "KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models",
            "url": "https://huggingface.co/papers/2505.16707",
            "abstract": "Recent advances in multi-modal generative models have enabled significant progress in instruction-based image editing. However, while these models produce visually plausible outputs, their capacity for knowledge-based reasoning editing tasks remains under-explored. In this paper, we introduce KRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a diagnostic benchmark designed to assess models through a cognitively informed lens. Drawing from educational theory, KRIS-Bench categorizes editing tasks across three foundational knowledge types: Factual, Conceptual, and Procedural. Based on this taxonomy, we design 22 representative tasks spanning 7 reasoning dimensions and release 1,267 high-quality annotated editing instances. To support fine-grained evaluation, we propose a comprehensive protocol that incorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints and calibrated through human studies. Empirical results on 10 state-of-the-art models reveal significant gaps in reasoning performance, highlighting the need for knowledge-centric benchmarks to advance the development of intelligent image editing systems.",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "fa1902dc37796b16",
            "authors": [
                "Yongliang Wu",
                "Zonghui Li",
                "Xinting Hu",
                "Xinyu Ye",
                "Xianfang Zeng",
                "Gang Yu",
                "Wenbo Zhu",
                "Bernt Schiele",
                "Ming-Hsuan Yang",
                "Xu Yang"
            ],
            "affiliations": [
                "Max Planck Institute for Informatics",
                "Shanghai Jiao Tong University",
                "Southeast University",
                "StepFun",
                "University of California, Berkeley",
                "University of California, Merced"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16707.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "KRIS-Bench: ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ KRIS-Bench - Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ Ñ‚Ñ€ĞµĞ¼ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼, ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ğ½Ñ‹Ğ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ 22 Ñ€ĞµĞ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾ 7 Ğ°ÑĞ¿ĞµĞºÑ‚Ğ°Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ ÑĞ¾Ğ±Ñ€Ğ°Ğ»Ğ¸ 1267 Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ Ğ¿Ñ€Ğ°Ğ²Ğ´Ğ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Advancing Image Editing with Knowledge-Based Reasoning",
                    "desc": "This paper presents KRIS-Bench, a new benchmark for evaluating multi-modal generative models in the context of instruction-based image editing. It focuses on assessing the models' ability to perform knowledge-based reasoning tasks, which has not been thoroughly investigated before. The benchmark categorizes editing tasks into three knowledge types: Factual, Conceptual, and Procedural, and includes 22 tasks with 1,267 annotated instances. The study reveals that current state-of-the-art models struggle with reasoning tasks, indicating a need for more knowledge-centric evaluation methods in image editing systems."
                },
                "zh": {
                    "title": "çŸ¥è¯†é©±åŠ¨çš„å›¾åƒç¼–è¾‘è¯„ä¼°æ–°åŸºå‡†",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†KRIS-Benchï¼ˆçŸ¥è¯†åŸºç¡€æ¨ç†åœ¨å›¾åƒç¼–è¾‘ç³»ç»ŸåŸºå‡†ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹åœ¨çŸ¥è¯†æ¨ç†ç¼–è¾‘ä»»åŠ¡ä¸­çš„èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚KRIS-Benchæ ¹æ®æ•™è‚²ç†è®ºå°†ç¼–è¾‘ä»»åŠ¡åˆ†ä¸ºä¸‰ç§åŸºç¡€çŸ¥è¯†ç±»å‹ï¼šäº‹å®æ€§ã€æ¦‚å¿µæ€§å’Œç¨‹åºæ€§ï¼Œå¹¶è®¾è®¡äº†22ä¸ªä»£è¡¨æ€§ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»¼åˆè¯„ä¼°åè®®ï¼ŒåŒ…å«æ–°çš„çŸ¥è¯†åˆç†æ€§æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡äººç±»ç ”ç©¶è¿›è¡Œæ ¡å‡†ã€‚å®è¯ç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨æ¨ç†æ€§èƒ½ä¸Šå­˜åœ¨æ˜¾è‘—å·®è·ï¼Œå¼ºè°ƒäº†ä»¥çŸ¥è¯†ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯•åœ¨æ™ºèƒ½å›¾åƒç¼–è¾‘ç³»ç»Ÿå‘å±•ä¸­çš„é‡è¦æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16151",
            "title": "Training-Free Reasoning and Reflection in MLLMs",
            "url": "https://huggingface.co/papers/2505.16151",
            "abstract": "The FRANK Model enhances multimodal LLMs with reasoning and reflection abilities without retraining, using a hierarchical weight merging approach that merges visual-pretrained and reasoning-specialized models.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Reasoning LLMs (e.g., DeepSeek-R1 and OpenAI-o1) have showcased impressive reasoning capabilities via reinforcement learning. However, extending these capabilities to Multimodal LLMs (MLLMs) is hampered by the prohibitive costs of retraining and the scarcity of high-quality, verifiable multimodal reasoning datasets. This paper introduces FRANK Model, a training-FRee ANd r1-liKe MLLM that imbues off-the-shelf MLLMs with reasoning and reflection abilities, without any gradient updates or extra supervision. Our key insight is to decouple perception and reasoning across MLLM decoder layers. Specifically, we observe that compared to the deeper decoder layers, the shallow decoder layers allocate more attention to visual tokens, while the deeper decoder layers concentrate on textual semantics. This observation motivates a hierarchical weight merging approach that combines a visual-pretrained MLLM with a reasoning-specialized LLM. To this end, we propose a layer-wise, Taylor-derived closed-form fusion mechanism that integrates reasoning capacity into deep decoder layers while preserving visual grounding in shallow decoder layers. Extensive experiments on challenging multimodal reasoning benchmarks demonstrate the effectiveness of our approach. On the MMMU benchmark, our model FRANK-38B achieves an accuracy of 69.2, outperforming the strongest baseline InternVL2.5-38B by +5.3, and even surpasses the proprietary GPT-4o model. Our project homepage is at: http://iip.whu.edu.cn/frank/index.html",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "59af0e553fdc317e",
            "authors": [
                "Hongchen Wei",
                "Zhenzhong Chen"
            ],
            "affiliations": [
                "School of Remote Sensing and Information Engineering, Wuhan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16151.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#reasoning",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "FRANK: ĞœÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
                    "desc": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ FRANK ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (MLLM), Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ Ğ¸Ğ¼ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ­Ñ‚Ğ¾ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ÑÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğº Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ½Ğ° Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ, ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ½Ğ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ…. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ¾ÑĞ»Ğ¾Ğ¹Ğ½Ğ¾Ğµ ÑĞ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ¢ĞµĞ¹Ğ»Ğ¾Ñ€Ğ°, Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼ Ğ² Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğµ ÑĞ»Ğ¾Ğ¸ Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€Ğ°, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºÑƒ Ğ² Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚Ğ½Ñ‹Ñ… ÑĞ»Ğ¾ÑÑ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "FRANK Model: Enhancing MLLMs with Reasoning Without Retraining",
                    "desc": "The FRANK Model enhances multimodal large language models (MLLMs) by integrating reasoning and reflection capabilities without the need for retraining. It employs a hierarchical weight merging technique that combines visual-pretrained models with reasoning-specialized models, allowing for effective reasoning in MLLMs. The model strategically decouples perception and reasoning across different layers of the decoder, leveraging shallow layers for visual attention and deeper layers for textual semantics. Experimental results show that FRANK-38B significantly outperforms existing models on multimodal reasoning tasks, achieving a notable accuracy increase on the MMMU benchmark."
                },
                "zh": {
                    "title": "FRANKæ¨¡å‹ï¼šæ— éœ€é‡è®­çš„å¤šæ¨¡æ€æ¨ç†å¢å¼º",
                    "desc": "FRANKæ¨¡å‹é€šè¿‡åˆ†å±‚æƒé‡åˆå¹¶çš„æ–¹æ³•ï¼Œå¢å¼ºäº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ¨ç†å’Œåæ€èƒ½åŠ›ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚è¯¥æ¨¡å‹å°†è§†è§‰é¢„è®­ç»ƒçš„MLLMä¸ä¸“æ³¨äºæ¨ç†çš„LLMç»“åˆï¼Œé¿å…äº†é«˜æ˜‚çš„é‡æ–°è®­ç»ƒæˆæœ¬ã€‚ç ”ç©¶å‘ç°ï¼Œæµ…å±‚è§£ç å™¨å±‚å¯¹è§†è§‰ä¿¡æ¯çš„å…³æ³¨åº¦æ›´é«˜ï¼Œè€Œæ·±å±‚è§£ç å™¨å±‚åˆ™æ›´æ³¨é‡æ–‡æœ¬è¯­ä¹‰ï¼Œè¿™ä¸€è§‚å¯Ÿä¿ƒæˆäº†åˆ†å±‚æƒé‡åˆå¹¶çš„æ–¹æ³•ã€‚é€šè¿‡åœ¨æ·±å±‚è§£ç å™¨ä¸­æ•´åˆæ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒæµ…å±‚è§£ç å™¨çš„è§†è§‰åŸºç¡€ï¼ŒFRANKæ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå‡†ç¡®ç‡è¶…è¿‡äº†å¤šä¸ªå¼ºåŸºçº¿æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14810",
            "title": "Scaling Reasoning, Losing Control: Evaluating Instruction Following in\n  Large Reasoning Models",
            "url": "https://huggingface.co/papers/2505.14810",
            "abstract": "An empirical analysis of MathIF identifies a tension between enhancing reasoning capacity and maintaining instruction adherence in large language models.  \t\t\t\t\tAI-generated summary \t\t\t\t Instruction-following is essential for aligning large language models (LLMs) with user intent. While recent reasoning-oriented models exhibit impressive performance on complex mathematical problems, their ability to adhere to natural language instructions remains underexplored. In this work, we introduce MathIF, a dedicated benchmark for evaluating instruction-following in mathematical reasoning tasks. Our empirical analysis reveals a consistent tension between scaling up reasoning capacity and maintaining controllability, as models that reason more effectively often struggle to comply with user directives. We find that models tuned on distilled long chains-of-thought or trained with reasoning-oriented reinforcement learning often degrade in instruction adherence, especially when generation length increases. Furthermore, we show that even simple interventions can partially recover obedience, though at the cost of reasoning performance. These findings highlight a fundamental tension in current LLM training paradigms and motivate the need for more instruction-aware reasoning models. We release the code and data at https://github.com/TingchenFu/MathIF.",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 Ğ¼Ğ°Ñ",
                "en": "May 20",
                "zh": "5æœˆ20æ—¥"
            },
            "hash": "97ed7c1fde734d7e",
            "authors": [
                "Tingchen Fu",
                "Jiawei Gu",
                "Yafu Li",
                "Xiaoye Qu",
                "Yu Cheng"
            ],
            "affiliations": [
                "Renmin University of China",
                "Shanghai AI Laboratory",
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14810.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#training",
                    "#benchmark",
                    "#optimization",
                    "#alignment"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ¾Ğ¼ Ğ¸ Ğ¿Ğ¾ÑĞ»ÑƒÑˆĞ°Ğ½Ğ¸ĞµĞ¼ Ğ² Ğ˜Ğ˜",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ MathIF Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸ĞµĞ¼ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM). ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ»Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ñ‡Ğ°ÑÑ‚Ğ¾ ÑƒÑ…ÑƒĞ´ÑˆĞ°ÑÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸ÑĞ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ. ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ²Ğ¼ĞµÑˆĞ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ° Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ÑĞ»ÑƒÑˆĞ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ½Ğ¾ Ğ·Ğ° ÑÑ‡ĞµÑ‚ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ­Ñ‚Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğµ Ğ² Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ğ°Ñ… Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM Ğ¸ Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ¸Ñ€ÑƒÑÑ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ±Ğ¾Ğ»ĞµĞµ Ğ¾ÑĞ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼ Ğ¿Ñ€Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Balancing Reasoning and Instruction in Language Models",
                    "desc": "This paper presents MathIF, a benchmark designed to evaluate how well large language models (LLMs) follow instructions while solving mathematical problems. The authors find a conflict between improving reasoning abilities and maintaining adherence to user instructions, as models that excel in reasoning often fail to follow directives accurately. They observe that training methods like reinforcement learning can enhance reasoning but may reduce the model's ability to comply with instructions, especially as the complexity of tasks increases. The study suggests that addressing this tension is crucial for developing more effective instruction-aware reasoning models."
                },
                "zh": {
                    "title": "å¹³è¡¡æ¨ç†èƒ½åŠ›ä¸æŒ‡ä»¤éµå¾ªçš„æŒ‘æˆ˜",
                    "desc": "æœ¬ç ”ç©¶åˆ†æäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ä¸æ¨ç†èƒ½åŠ›ä¹‹é—´çš„çŸ›ç›¾ã€‚æˆ‘ä»¬æå‡ºäº†MathIFåŸºå‡†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä¸­çš„æŒ‡ä»¤éµå¾ªè¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨ç†èƒ½åŠ›æ›´å¼ºçš„æ¨¡å‹å¾€å¾€åœ¨éµå¾ªç”¨æˆ·æŒ‡ä»¤æ—¶è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆå†…å®¹è¾ƒé•¿æ—¶ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå½“å‰çš„è®­ç»ƒæ–¹æ³•éœ€è¦æ›´å¤šå…³æ³¨æŒ‡ä»¤æ„è¯†ï¼Œä»¥å¹³è¡¡æ¨ç†èƒ½åŠ›å’ŒæŒ‡ä»¤éµå¾ªã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16916",
            "title": "Backdoor Cleaning without External Guidance in MLLM Fine-tuning",
            "url": "https://huggingface.co/papers/2505.16916",
            "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in fine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt general-purpose models to downstream tasks. This flexibility, however, introduces serious security risks, as malicious fine-tuning can implant backdoors into MLLMs with minimal effort. In this paper, we observe that backdoor triggers systematically disrupt cross-modal processing by causing abnormal attention concentration on non-semantic regions--a phenomenon we term attention collapse. Based on this insight, we propose Believe Your Eyes (BYE), a data filtering framework that leverages attention entropy patterns as self-supervised signals to identify and filter backdoor samples. BYE operates via a three-stage pipeline: (1) extracting attention maps using the fine-tuned model, (2) computing entropy scores and profiling sensitive layers via bimodal separation, and (3) performing unsupervised clustering to remove suspicious samples. Unlike prior defenses, BYE equires no clean supervision, auxiliary labels, or model modifications. Extensive experiments across various datasets, models, and diverse trigger types validate BYE's effectiveness: it achieves near-zero attack success rates while maintaining clean-task performance, offering a robust and generalizable solution against backdoor threats in MLLMs.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "36dbc47d484f0a53",
            "authors": [
                "Xuankun Rong",
                "Wenke Huang",
                "Jian Liang",
                "Jinhe Bi",
                "Xun Xiao",
                "Yiming Li",
                "Bo Du",
                "Mang Ye"
            ],
            "affiliations": [
                "Huawei Technologies",
                "Munich Research Center",
                "Nanyang Technological University",
                "School of Computer Science, Wuhan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16916.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#data",
                    "#training",
                    "#dataset",
                    "#security"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ˜Ğ˜ Ğ¾Ñ‚ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… ÑƒĞ³Ñ€Ğ¾Ğ·: Ğ´Ğ¾Ğ²ĞµÑ€ÑĞ¹ ÑĞ²Ğ¾Ğ¸Ğ¼ Ğ³Ğ»Ğ°Ğ·Ğ°Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğµ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM) Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ ĞºĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ½ĞµÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ…, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ² ÑÑ‚Ğ¾ ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ 'ĞºĞ¾Ğ»Ğ»Ğ°Ğ¿ÑĞ¾Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ'. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ñ Ğ¾Ğ½Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº BYE Ğ´Ğ»Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ backdoor-Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ², Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ. BYE Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ² Ñ‚Ñ€Ğ¸ ÑÑ‚Ğ°Ğ¿Ğ° Ğ¸ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ñ‡Ğ¸ÑÑ‚Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ»Ğ¸ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñƒ Ğ¾Ñ‚ backdoor-Ğ°Ñ‚Ğ°Ğº Ğ½Ğ° MLLM."
                },
                "en": {
                    "title": "Defending MLLMs: Believe Your Eyes Against Backdoors!",
                    "desc": "This paper addresses the security risks associated with Multimodal Large Language Models (MLLMs) in fine-tuning-as-a-service (FTaaS) environments, where malicious fine-tuning can introduce backdoors. The authors identify a phenomenon called 'attention collapse', where backdoor triggers cause abnormal attention focus on irrelevant areas, disrupting cross-modal processing. To combat this, they propose a framework called Believe Your Eyes (BYE), which uses attention entropy patterns to filter out backdoor samples without needing clean supervision or model changes. BYE demonstrates strong effectiveness in various scenarios, achieving low attack success rates while preserving performance on clean tasks."
                },
                "zh": {
                    "title": "æŠµå¾¡åé—¨å¨èƒçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆ",
                    "desc": "å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¾®è°ƒæœåŠ¡ä¸­è¶Šæ¥è¶Šå¸¸è§ï¼Œä½†è¿™ä¹Ÿå¸¦æ¥äº†å®‰å…¨é£é™©ï¼Œæ¶æ„å¾®è°ƒå¯èƒ½ä¼šåœ¨æ¨¡å‹ä¸­æ¤å…¥åé—¨ã€‚æœ¬æ–‡è§‚å¯Ÿåˆ°ï¼Œåé—¨è§¦å‘å™¨ä¼šå¯¼è‡´è·¨æ¨¡æ€å¤„ç†çš„å¼‚å¸¸æ³¨æ„åŠ›é›†ä¸­ï¼Œå½¢æˆæˆ‘ä»¬ç§°ä¹‹ä¸ºæ³¨æ„åŠ›å´©æºƒçš„ç°è±¡ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†\"ç›¸ä¿¡ä½ çš„çœ¼ç›\"ï¼ˆBYEï¼‰æ•°æ®è¿‡æ»¤æ¡†æ¶ï¼Œé€šè¿‡æ³¨æ„åŠ›ç†µæ¨¡å¼ä½œä¸ºè‡ªç›‘ç£ä¿¡å·æ¥è¯†åˆ«å’Œè¿‡æ»¤åé—¨æ ·æœ¬ã€‚BYEé€šè¿‡ä¸‰ä¸ªé˜¶æ®µçš„æµç¨‹æ“ä½œï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦å¹²å‡€ç›‘ç£æˆ–æ¨¡å‹ä¿®æ”¹çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåœ°æŠµå¾¡MLLMsä¸­çš„åé—¨å¨èƒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16175",
            "title": "QuickVideo: Real-Time Long Video Understanding with System Algorithm\n  Co-Design",
            "url": "https://huggingface.co/papers/2505.16175",
            "abstract": "QuickVideo accelerates long-video understanding by combining a parallelized video decoder, memory-efficient prefilling, and overlapping video decoding with inference, enabling real-time performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-video understanding has emerged as a crucial capability in real-world applications such as video surveillance, meeting summarization, educational lecture analysis, and sports broadcasting. However, it remains computationally prohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential video decoding, the process of converting the raw bit stream to RGB frames can take up to a minute for hour-long video inputs, and 2) costly prefilling of up to several million tokens for LLM inference, resulting in high latency and memory use. To address these challenges, we propose QuickVideo, a system-algorithm co-design that substantially accelerates long-video understanding to support real-time downstream applications. It comprises three key innovations: QuickDecoder, a parallelized CPU-based video decoder that achieves 2-3 times speedup by splitting videos into keyframe-aligned intervals processed concurrently; QuickPrefill, a memory-efficient prefilling method using KV-cache pruning to support more frames with less GPU memory; and an overlapping scheme that overlaps CPU video decoding with GPU inference. Together, these components infernece time reduce by a minute on long video inputs, enabling scalable, high-quality video understanding even on limited hardware. Experiments show that QuickVideo generalizes across durations and sampling rates, making long video processing feasible in practice.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "0bcb5c833bad2340",
            "authors": [
                "Benjamin Schneider",
                "Dongfu Jiang",
                "Chao Du",
                "Tianyu Pang",
                "Wenhu Chen"
            ],
            "affiliations": [
                "University of Waterloo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16175.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#optimization",
                    "#video",
                    "#long_context"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ QuickVideo",
                    "desc": "QuickVideo - ÑÑ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ÑƒÑĞºĞ¾Ñ€ÑÑÑ‰Ğ°Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€ Ğ²Ğ¸Ğ´ĞµĞ¾, ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¿Ğ¾ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¾Ğ¼. QuickVideo Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ QuickDecoder Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ½Ğ° CPU, QuickPrefill Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ GPU Ğ¸ ÑÑ…ĞµĞ¼Ñƒ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ñ CPU-Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ GPU-Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¾Ğ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾."
                },
                "en": {
                    "title": "Accelerating Long-Video Understanding for Real-Time Applications",
                    "desc": "QuickVideo is a novel system designed to enhance the understanding of long videos in real-time applications. It addresses two major challenges: the slow sequential video decoding and the high memory requirements for token prefilling in large language models (LLMs). By introducing a parallelized video decoder, a memory-efficient prefilling method, and an overlapping decoding scheme, QuickVideo significantly reduces inference time. This allows for efficient processing of long videos, making advanced video analysis accessible even on limited hardware."
                },
                "zh": {
                    "title": "QuickVideoï¼šå®æ—¶é•¿è§†é¢‘ç†è§£çš„åŠ é€Ÿåˆ©å™¨",
                    "desc": "QuickVideo æ˜¯ä¸€ç§åŠ é€Ÿé•¿è§†é¢‘ç†è§£çš„ç³»ç»Ÿï¼Œç»“åˆäº†å¹¶è¡Œè§†é¢‘è§£ç ã€å†…å­˜é«˜æ•ˆçš„é¢„å¡«å……å’Œé‡å è§£ç ä¸æ¨ç†ã€‚å®ƒé€šè¿‡å¿«é€Ÿè§£ç å™¨å°†è§†é¢‘åˆ†å‰²æˆå…³é”®å¸§å¯¹é½çš„é—´éš”ï¼Œå¹¶åŒæ—¶å¤„ç†ï¼Œä»è€Œå®ç°äº† 2-3 å€çš„é€Ÿåº¦æå‡ã€‚QuickPrefill æ–¹æ³•é€šè¿‡ KV-cache å‰ªæå‡å°‘äº†å¯¹ GPU å†…å­˜çš„éœ€æ±‚ï¼Œä½¿å¾—å¯ä»¥å¤„ç†æ›´å¤šå¸§ã€‚è¯¥ç³»ç»Ÿæ˜¾è‘—é™ä½äº†é•¿è§†é¢‘è¾“å…¥çš„æ¨ç†æ—¶é—´ï¼Œä½¿å¾—åœ¨æœ‰é™ç¡¬ä»¶ä¸Šä¹Ÿèƒ½å®ç°é«˜è´¨é‡çš„è§†é¢‘ç†è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15270",
            "title": "Scaling Diffusion Transformers Efficiently via Î¼P",
            "url": "https://huggingface.co/papers/2505.15270",
            "abstract": "Maximal Update Parametrization (Î¼P) is extended to diffusion Transformers, demonstrating efficient hyperparameter transferability and reduced tuning costs across various models and tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion Transformers have emerged as the foundation for vision generative models, but their scalability is limited by the high cost of hyperparameter (HP) tuning at large scales. Recently, Maximal Update Parametrization (muP) was proposed for vanilla Transformers, which enables stable HP transfer from small to large language models, and dramatically reduces tuning costs. However, it remains unclear whether muP of vanilla Transformers extends to diffusion Transformers, which differ architecturally and objectively. In this work, we generalize standard muP to diffusion Transformers and validate its effectiveness through large-scale experiments. First, we rigorously prove that muP of mainstream diffusion Transformers, including DiT, U-ViT, PixArt-alpha, and MMDiT, aligns with that of the vanilla Transformer, enabling the direct application of existing muP methodologies. Leveraging this result, we systematically demonstrate that DiT-muP enjoys robust HP transferability. Notably, DiT-XL-2-muP with transferred learning rate achieves 2.9 times faster convergence than the original DiT-XL-2. Finally, we validate the effectiveness of muP on text-to-image generation by scaling PixArt-alpha from 0.04B to 0.61B and MMDiT from 0.18B to 18B. In both cases, models under muP outperform their respective baselines while requiring small tuning cost, only 5.5% of one training run for PixArt-alpha and 3% of consumption by human experts for MMDiT-18B. These results establish muP as a principled and efficient framework for scaling diffusion Transformers.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 Ğ¼Ğ°Ñ",
                "en": "May 21",
                "zh": "5æœˆ21æ—¥"
            },
            "hash": "6c13e0c5ef8ee4a2",
            "authors": [
                "Chenyu Zheng",
                "Xinyu Zhang",
                "Rongzhen Wang",
                "Wei Huang",
                "Zhi Tian",
                "Weilin Huang",
                "Jun Zhu",
                "Chongxuan Li"
            ],
            "affiliations": [
                "Beijing Key Laboratory of Research on Large Models and Intelligent Governance",
                "ByteDance Seed",
                "Engineering Research Center of Next-Generation Intelligent Search and Recommendation, MOE",
                "Gaoling School of AI, Renmin University of China",
                "RIKEN AIP",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15270.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#transfer_learning",
                    "#diffusion",
                    "#optimization"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "Î¼P: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Maximal Update Parametrization (Î¼P) Ğ´Ğ»Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Î¼P Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½ Ğº Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ğ¼ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ², Ñ‚Ğ°ĞºĞ¸Ğ¼ ĞºĞ°Ğº DiT, U-ViT, PixArt-alpha Ğ¸ MMDiT. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Î¼P Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ¸Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, Ñ‡Ñ‚Ğ¾ Î¼P ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ² Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Efficient Hyperparameter Transfer for Diffusion Transformers with Î¼P",
                    "desc": "This paper extends the Maximal Update Parametrization (Î¼P) technique to diffusion Transformers, which are crucial for generative vision models. The authors demonstrate that Î¼P allows for effective hyperparameter transfer from smaller to larger models, significantly reducing the costs associated with hyperparameter tuning. Through extensive experiments, they show that diffusion Transformers like DiT and PixArt-alpha benefit from Î¼P, achieving faster convergence and better performance with minimal tuning effort. Overall, this work establishes Î¼P as a valuable method for enhancing the scalability and efficiency of diffusion Transformers in various tasks."
                },
                "zh": {
                    "title": "æœ€å¤§æ›´æ–°å‚æ•°åŒ–ï¼šæ‰©æ•£å˜æ¢å™¨çš„é«˜æ•ˆè°ƒä¼˜æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æ‰©å±•äº†æœ€å¤§æ›´æ–°å‚æ•°åŒ–ï¼ˆÎ¼Pï¼‰åˆ°æ‰©æ•£å˜æ¢å™¨ï¼Œå±•ç¤ºäº†é«˜æ•ˆçš„è¶…å‚æ•°å¯è½¬ç§»æ€§å’Œé™ä½çš„è°ƒä¼˜æˆæœ¬ã€‚æ‰©æ•£å˜æ¢å™¨åœ¨è§†è§‰ç”Ÿæˆæ¨¡å‹ä¸­å‘æŒ¥äº†åŸºç¡€ä½œç”¨ï¼Œä½†åœ¨å¤§è§„æ¨¡åº”ç”¨ä¸­è¶…å‚æ•°è°ƒä¼˜çš„é«˜æˆæœ¬é™åˆ¶äº†å…¶å¯æ‰©å±•æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒÎ¼På¯ä»¥æœ‰æ•ˆåœ°ä»å°å‹æ¨¡å‹è½¬ç§»åˆ°å¤§å‹æ‰©æ•£å˜æ¢å™¨ï¼Œå¹¶åœ¨å¤§è§„æ¨¡å®éªŒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚é€šè¿‡ç³»ç»Ÿæ€§å®éªŒï¼Œç»“æœæ˜¾ç¤ºåœ¨è°ƒä¼˜æˆæœ¬è¾ƒä½çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨Î¼Pçš„æ¨¡å‹åœ¨æ€§èƒ½ä¸Šä¼˜äºåŸºçº¿æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11711",
            "title": "Reinforcement Learning Finetunes Small Subnetworks in Large Language\n  Models",
            "url": "https://huggingface.co/papers/2505.11711",
            "abstract": "Reinforcement learning improves large language models with minimal parameter updates, affecting only a small subnetwork without explicit sparsity techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement learning (RL) yields substantial improvements in large language models (LLMs) downstream task performance and alignment with human values. Surprisingly, such large gains result from updating only a small subnetwork comprising just 5 percent to 30 percent of the parameters, with the rest effectively unchanged. We refer to this phenomenon as parameter update sparsity induced by RL. It is observed across all 7 widely used RL algorithms (e.g., PPO, GRPO, DPO) and all 10 LLMs from different families in our experiments. This sparsity is intrinsic and occurs without any explicit sparsity promoting regularizations or architectural constraints. Finetuning the subnetwork alone recovers the test accuracy, and, remarkably, produces a model nearly identical to the one obtained via full finetuning. The subnetworks from different random seeds, training data, and even RL algorithms show substantially greater overlap than expected by chance. Our analysis suggests that this sparsity is not due to updating only a subset of layers, instead, nearly all parameter matrices receive similarly sparse updates. Moreover, the updates to almost all parameter matrices are nearly full-rank, suggesting RL updates a small subset of parameters that nevertheless span almost the full subspaces that the parameter matrices can represent. We conjecture that the this update sparsity can be primarily attributed to training on data that is near the policy distribution, techniques that encourage the policy to remain close to the pretrained model, such as the KL regularization and gradient clipping, have limited impact.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 Ğ¼Ğ°Ñ",
                "en": "May 16",
                "zh": "5æœˆ16æ—¥"
            },
            "hash": "e7296e89ef67015f",
            "authors": [
                "Sagnik Mukherjee",
                "Lifan Yuan",
                "Dilek Hakkani-Tur",
                "Hao Peng"
            ],
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11711.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#training",
                    "#rl",
                    "#optimization",
                    "#alignment"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚",
                    "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿Ñ€Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ¸Ñ… ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼ Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑĞ¼. Ğ£Ğ´Ğ¸Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾, Ğ½Ğ¾ Ñ‚Ğ°ĞºĞ¸Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ÑÑ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ğ¿Ğ¾Ğ´ÑĞµÑ‚Ğ¸, ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‰ĞµĞ¹ 5-30% Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ñ„ĞµĞ½Ğ¾Ğ¼ĞµĞ½, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ 'Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²', Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² RL Ğ¸ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ² LLM Ğ±ĞµĞ· Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ÑĞ²Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ñ‚Ñ€Ğ°Ğ³Ğ¸Ğ²Ğ°ÑÑ‚ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¸ Ğ²ÑĞµ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñ‹ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ½Ğ¾ Ğ¾ÑÑ‚Ğ°ÑÑ‚ÑÑ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ€Ğ°Ğ½Ğ³Ğ¾Ğ²Ñ‹Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Efficient Reinforcement Learning: Small Updates, Big Gains!",
                    "desc": "This paper explores how reinforcement learning (RL) can enhance the performance of large language models (LLMs) by making minimal updates to a small subnetwork of parameters. Remarkably, only 5 to 30 percent of the model's parameters are adjusted, while the majority remain unchanged, a phenomenon termed 'parameter update sparsity.' This sparsity occurs across various RL algorithms and LLMs, indicating a consistent pattern in how RL influences model training. The findings suggest that even with limited updates, the subnetwork can achieve performance comparable to full finetuning, highlighting the efficiency of RL in optimizing LLMs."
                },
                "zh": {
                    "title": "å¼ºåŒ–å­¦ä¹ ï¼šå°æ›´æ–°ï¼Œå¤§æå‡",
                    "desc": "å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­é€šè¿‡æœ€å°çš„å‚æ•°æ›´æ–°æ˜¾è‘—æå‡äº†ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°å’Œä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè¿™ç§æ˜¾è‘—çš„æå‡ä»…é€šè¿‡æ›´æ–°å å‚æ•°5%åˆ°30%çš„å°å­ç½‘ç»œå®ç°ï¼Œå…¶ä½™å‚æ•°åŸºæœ¬ä¿æŒä¸å˜ã€‚æˆ‘ä»¬ç§°è¿™ç§ç°è±¡ä¸ºç”±RLå¼•èµ·çš„å‚æ•°æ›´æ–°ç¨€ç–æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§ç¨€ç–æ€§åœ¨ä¸ƒç§å¹¿æ³›ä½¿ç”¨çš„RLç®—æ³•å’Œåç§ä¸åŒå®¶æ—çš„LLMä¸­æ™®éå­˜åœ¨ï¼Œä¸”ä¸éœ€è¦ä»»ä½•æ˜¾å¼çš„ç¨€ç–ä¿ƒè¿›æ­£åˆ™åŒ–æˆ–æ¶æ„çº¦æŸã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15963",
            "title": "OViP: Online Vision-Language Preference Learning",
            "url": "https://huggingface.co/papers/2505.15963",
            "abstract": "Large vision-language models (LVLMs) remain vulnerable to hallucination, often generating content misaligned with visual inputs. While recent approaches advance multi-modal Direct Preference Optimization (DPO) to mitigate hallucination, they typically rely on predefined or randomly edited negative samples that fail to reflect actual model errors, limiting training efficacy. In this work, we propose an Online Vision-language Preference Learning (OViP) framework that dynamically constructs contrastive training data based on the model's own hallucinated outputs. By identifying semantic differences between sampled response pairs and synthesizing negative images using a diffusion model, OViP generates more relevant supervision signals in real time. This failure-driven training enables adaptive alignment of both textual and visual preferences. Moreover, we refine existing evaluation protocols to better capture the trade-off between hallucination suppression and expressiveness. Experiments on hallucination and general benchmarks demonstrate that OViP effectively reduces hallucinations while preserving core multi-modal capabilities.",
            "score": 0,
            "issue_id": 3914,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 Ğ¼Ğ°Ñ",
                "en": "May 21",
                "zh": "5æœˆ21æ—¥"
            },
            "hash": "4476380071b2e936",
            "authors": [
                "Shujun Liu",
                "Siyuan Wang",
                "Zejun Li",
                "Jianxiang Wang",
                "Cheng Zeng",
                "Zhongyu Wei"
            ],
            "affiliations": [
                "ByteDance",
                "Fudan University",
                "University of Southern California"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15963.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#training",
                    "#hallucinations",
                    "#benchmark",
                    "#diffusion",
                    "#rag",
                    "#alignment"
                ],
                "emoji": "ğŸ”®",
                "ru": {
                    "title": "OViP: ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ OViP (Online Vision-language Preference Learning). Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ° ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ğµ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Ğ² ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LVLM) Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. OViP Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ OViP ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Dynamic Learning to Combat Hallucination in Vision-Language Models",
                    "desc": "This paper addresses the issue of hallucination in large vision-language models (LVLMs), where the models generate content that does not match the visual inputs. The authors introduce a new framework called Online Vision-language Preference Learning (OViP), which creates training data based on the model's own incorrect outputs, rather than relying on static negative samples. By using a diffusion model to synthesize negative images, OViP provides more relevant feedback for the model to learn from. The results show that this approach not only reduces hallucinations but also maintains the model's ability to express multi-modal information effectively."
                },
                "zh": {
                    "title": "åŠ¨æ€æ„å»ºå¯¹æ¯”æ•°æ®ï¼Œå‡å°‘å¹»è§‰ï¼",
                    "desc": "å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨ç”Ÿæˆå†…å®¹æ—¶å®¹æ˜“å‡ºç°å¹»è§‰ï¼Œå¸¸å¸¸ä¸è§†è§‰è¾“å…¥ä¸ä¸€è‡´ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶é€šè¿‡å¤šæ¨¡æ€ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ¥å‡è½»å¹»è§‰é—®é¢˜ï¼Œä½†é€šå¸¸ä¾èµ–äºé¢„å®šä¹‰æˆ–éšæœºç¼–è¾‘çš„è´Ÿæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬æ— æ³•çœŸå®åæ˜ æ¨¡å‹çš„é”™è¯¯ï¼Œé™åˆ¶äº†è®­ç»ƒæ•ˆæœã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨çº¿è§†è§‰è¯­è¨€åå¥½å­¦ä¹ ï¼ˆOViPï¼‰æ¡†æ¶ï¼ŒåŠ¨æ€æ„å»ºå¯¹æ¯”è®­ç»ƒæ•°æ®ï¼ŒåŸºäºæ¨¡å‹è‡ªèº«çš„å¹»è§‰è¾“å‡ºã€‚é€šè¿‡è¯†åˆ«å“åº”å¯¹ä¹‹é—´çš„è¯­ä¹‰å·®å¼‚å¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹åˆæˆè´Ÿå›¾åƒï¼ŒOViPå®æ—¶ç”Ÿæˆæ›´ç›¸å…³çš„ç›‘ç£ä¿¡å·ï¼Œæœ‰æ•ˆå‡å°‘å¹»è§‰ï¼ŒåŒæ—¶ä¿æŒå¤šæ¨¡æ€èƒ½åŠ›ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-22.html",
    "link_next": "2025-05-26.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "22.05",
        "en": "05/22",
        "zh": "5æœˆ22æ—¥"
    },
    "short_date_next": {
        "ru": "26.05",
        "en": "05/26",
        "zh": "5æœˆ26æ—¥"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 5,
        "#agents": 0,
        "#cv": 1,
        "#rl": 3,
        "#rlhf": 2,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 5,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 8,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 5,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 3,
        "#alignment": 3,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†ç½‘é¡µå¯¼èˆªçš„è‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚è¿‡å»çš„ç ”ç©¶ä½¿ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä½œä¸ºå¥–åŠ±æ¨¡å‹ï¼Œä½†è¿™å¯¹å®é™…åº”ç”¨æœ‰é™åˆ¶ã€‚ä½œè€…æå‡ºäº†ç¬¬ä¸€ä¸ªè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ï¼Œç§°ä¸ºWeb-Shepherdï¼Œç”¨äºé€æ­¥è¯„ä¼°ç½‘é¡µå¯¼èˆªè·¯å¾„ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†ï¼Œå¹¶åœ¨å®éªŒä¸­è¯æ˜äº†Web-Shepherdçš„æœ‰æ•ˆæ€§å’Œæˆæœ¬æ•ˆç›Šã€‚æ‰€æœ‰æ¨¡å‹ã€æ•°æ®é›†å’Œä»£ç éƒ½å…¬å¼€å¯ç”¨ã€‚",
        "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†ç½‘é¡µå¯¼èˆªçš„è‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚è¿‡å»çš„ç ”ç©¶ä½¿ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä½œä¸ºå¥–åŠ±æ¨¡å‹ï¼Œä½†è¿™å¯¹å®é™…åº”ç”¨æœ‰é™åˆ¶ã€‚ä½œè€…æå‡ºäº†ç¬¬ä¸€ä¸ªè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰ï¼Œç§°ä¸ºWeb-Shepherdï¼Œç”¨äºé€æ­¥è¯„ä¼°ç½‘é¡µå¯¼èˆªè·¯å¾„ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†ï¼Œå¹¶åœ¨å®éªŒä¸­è¯æ˜äº†Web-Shepherdçš„æœ‰æ•ˆæ€§å’Œæˆæœ¬æ•ˆç›Šã€‚æ‰€æœ‰æ¨¡å‹ã€æ•°æ®é›†å’Œä»£ç éƒ½å…¬å¼€å¯ç”¨ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le wÇngyÃ¨ dÇohÃ¡ng de zÃ¬dÃ²nghuÃ  rÃ¨nwÃ¹. GuÃ²qÃ¹ de yÃ¡njiÅ« shÇyÃ²ng duÅ mÃ³shÃ¬ dÃ  yÇ”yÃ¡n mÃ³xÃ­ng (MLLM) zuÃ²wÃ©i jiÇnglÃ¬ mÃ³xÃ­ng, dÃ n zhÃ¨ duÃ¬ shÃ­jÃ¬ yÃ¬ngyÃ²ng yÇ’u xiÃ nzhÃ¬. ZuÃ²zhÄ› tÃ­chÅ« le dÃ¬-yÄ«gÃ¨ guÃ²chÃ©ng jiÇnglÃ¬ mÃ³xÃ­ng (PRM), chÄ“ngwÃ©i Web-Shepherd, yÃ²ngyÃº zhÃºbÃ¹ pÃ­ngjiÃ  wÇngyÃ¨ dÇohÃ¡ng lÃ¹jÃ¬ng. TÄmen chuÃ ngjiÃ n le yÄ«gÃ¨ dÃ  guÄ«mÃ³ shÃ¹jÃ¹jÃ­ hÃ© pÃ­ngjiÃ  jÄ«zhÇ”n, bÃ¬ng zÃ i shÃ¬yÃ n zhÅng zhÃ¨ngmÃ­ng le Web-Shepherd de yÇ’uxiÃ oxÃ¬ng hÃ© chÃ©ngbÄ›n xiÃ oyÃ¬. SuÇ’yÇ’u mÃ³xÃ­ng, shÃ¹jÃ¹jÃ­ hÃ© dÃ imÇ dÅu gÅngkÄi kÄ›yÃ²ng.",
        "vocab": "[\n    {\"word\": \"è®¨è®º\", \"pinyin\": \"tÇo lÃ¹n\", \"trans\": \"discuss\"},\n    {\"word\": \"ç½‘é¡µå¯¼èˆª\", \"pinyin\": \"wÇng yÃ¨ dÇo hÃ¡ng\", \"trans\": \"web navigation\"},\n    {\"word\": \"è‡ªåŠ¨åŒ–\", \"pinyin\": \"zÃ¬ dÃ²ng huÃ \", \"trans\": \"automation\"},\n    {\"word\": \"ä»»åŠ¡\", \"pinyin\": \"rÃ¨n wu\", \"trans\": \"task\"},\n    {\"word\": \"ç ”ç©¶\", \"pinyin\": \"yÃ¡n jiÅ«\", \"trans\": \"research\"},\n    {\"word\": \"å¤šæ¨¡æ€\", \"pinyin\": \"duÅ mÃ³ tÃ i\", \"trans\": \"multimodal\"},\n    {\"word\": \"å¤§è¯­è¨€æ¨¡å‹\", \"pinyin\": \"dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng\", \"trans\": \"large language model\"},\n    {\"word\": \"å¥–åŠ±æ¨¡å‹\", \"pinyin\": \"jiÇng lÃ¬ mÃ³ xÃ­ng\", \"trans\": \"reward model\"},\n    {\"word\": \"é™åˆ¶\", \"pinyin\": \"xiÃ n zhÃ¬\", \"trans\": \"limit\"},\n    {\"word\": \"æå‡º\", \"pinyin\": \"tÃ­ chÅ«\", \"trans\": \"propose\"},\n    {\"word\": \"è¿‡ç¨‹å¥–åŠ±æ¨¡å‹\", \"pinyin\": \"guÃ² chÃ©ng jiÇng lÃ¬ mÃ³ xÃ­ng\", \"trans\": \"process reward model\"},\n    {\"word\": \"é€æ­¥\", \"pinyin\": \"zhuÃ³ bÃ¹\", \"trans\": \"step-by-step\"},\n    {\"word\": \"è¯„ä¼°\", \"pinyin\": \"pÃ­ng gÅ«\", \"trans\": \"evaluate\"},\n    {\"word\": \"è·¯å¾„\", \"pinyin\": \"lÃ¹ jÃ¬ng\", \"trans\": \"path\"},\n    {\"word\": \"åˆ›å»º\", \"pinyin\": \"chuÃ ng jiÃ n\", \"trans\": \"create\"},\n    {\"word\": \"æ•°æ®é›†\", \"pinyin\": \"shÃ¹ jÃ¹ jÃ­\", \"trans\": \"dataset\"},\n    {\"word\": \"è¯„ä¼°åŸºå‡†\", \"pinyin\": \"pÃ­ng gÅ« jÄ« zhÇ”n\", \"trans\": \"evaluation benchmark\"},\n    {\"word\": \"å®éªŒ\", \"pinyin\": \"shÃ­ yÃ n\", \"trans\": \"experiment\"},\n    {\"word\": \"è¯æ˜\", \"pinyin\": \"zhÃ¨ng mÃ­ng\", \"trans\": \"prove\"},\n    {\"word\": \"æœ‰æ•ˆæ€§\", \"pinyin\": \"yÇ’u xiÃ o xÃ¬ng\", \"trans\": \"effectiveness\"},\n    {\"word\": \"æˆæœ¬æ•ˆç›Š\", \"pinyin\": \"chÃ©ng bÄ›n xiÃ o yÃ¬\", \"trans\": \"cost-effectiveness\"},\n    {\"word\": \"å…¬å¼€å¯ç”¨\", \"pinyin\": \"gÅng kÄi kÄ› yÃ²ng\", \"trans\": \"publicly available\"}\n]",
        "trans": "This article discusses the automation of web page navigation tasks. Previous research has used multimodal large language models (MLLMs) as reward models, but this has limitations for practical applications. The authors propose the first process reward model (PRM), called Web-Shepherd, for step-by-step evaluation of web page navigation paths. They created a large-scale dataset and evaluation benchmark, and demonstrated the effectiveness and cost-efficiency of Web-Shepherd in experiments. All models, datasets, and code are publicly available.",
        "update_ts": "2025-05-22 09:12"
    }
}