{
    "date": {
        "ru": "9 Ğ¸ÑĞ»Ñ",
        "en": "July 9",
        "zh": "7æœˆ9æ—¥"
    },
    "time_utc": "2025-07-09 02:49",
    "weekday": 2,
    "issue_id": 4715,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.03112",
            "title": "RLVER: Reinforcement Learning with Verifiable Emotion Rewards for\n  Empathetic Agents",
            "url": "https://huggingface.co/papers/2507.03112",
            "abstract": "An end-to-end reinforcement learning framework using simulated user emotion rewards enhances emotional intelligence in large language models while maintaining cognitive skills.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) excel at logical and algorithmic reasoning, yet their emotional intelligence (EQ) still lags far behind their cognitive prowess. While reinforcement learning from verifiable rewards (RLVR) has advanced in other domains, its application to dialogue-especially for emotional intelligence-remains underexplored. In this work, we introduce RLVER, the first end-to-end reinforcement learning framework that leverages verifiable emotion rewards from simulated users to cultivate higher-order empathetic abilities in LLMs. Within this framework, self-consistent affective simulated users engage in dialogue rollouts and produce deterministic emotion scores during conversations, serving as reward signals to guide the LLM's learning. Fine-tuning publicly available Qwen2.5-7B-Instruct model with PPO boosts its Sentient-Benchmark score from 13.3 to 79.2 while largely preserving mathematical and coding competence. Extensive experiments reveal that: (i) RLVER consistently improves multiple dialogue capabilities; (ii) Thinking and non-thinking models show distinct trends--thinking models excel in empathy and insight, while non-thinking models favor action; (iii) GRPO often yields stable gains, while PPO can push certain capabilities to a higher ceiling; (iv) More challenging environments are not always better-moderate ones can yield stronger outcomes. Our results show that RLVER is a practical route toward emotionally intelligent and broadly capable language agents.",
            "score": 8,
            "issue_id": 4715,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ»Ñ",
                "en": "July 3",
                "zh": "7æœˆ3æ—¥"
            },
            "hash": "c1368a26272d7e57",
            "authors": [
                "Peisong Wang",
                "Ruotian Ma",
                "Bang Zhang",
                "Xingyu Chen",
                "Zhiwei He",
                "Kang Luo",
                "Qingsong Lv",
                "Qingxuan Jiang",
                "Zheng Xie",
                "Shanyi Wang",
                "Yuan Li",
                "Fanghua Ye",
                "Jian Li",
                "Yifan Yang",
                "Zhaopeng Tu",
                "Xiaolong Li"
            ],
            "affiliations": [
                "Hunyuan AI Digital Human, Tencent"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.03112.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#rl",
                    "#alignment",
                    "#agents",
                    "#rlhf",
                    "#training"
                ],
                "emoji": "ğŸ¤–ğŸ’•",
                "ru": {
                    "title": "Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ Ğ˜Ğ˜: Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ RLVER - Ğ¿ĞµÑ€Ğ²ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ñƒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¸Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ RLVER Ğº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Qwen2.5-7B-Instruct Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ğ»Ğ¾ ĞµÑ‘ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ RLVER Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Enhancing Emotional Intelligence in Language Models with RLVER",
                    "desc": "This paper presents RLVER, a novel reinforcement learning framework designed to enhance emotional intelligence in large language models (LLMs) by using simulated user emotion rewards. The framework employs reinforcement learning from verifiable rewards (RLVR) to train LLMs in dialogue settings, focusing on developing empathetic abilities. By fine-tuning the Qwen2.5-7B-Instruct model with Proximal Policy Optimization (PPO), the authors demonstrate significant improvements in emotional understanding while maintaining cognitive skills. The findings indicate that RLVER effectively boosts dialogue capabilities and suggests that moderate training environments can lead to better outcomes than more challenging ones."
                },
                "zh": {
                    "title": "æƒ…æ„Ÿæ™ºèƒ½ä¸è®¤çŸ¥èƒ½åŠ›çš„å®Œç¾ç»“åˆ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶RLVERï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·çš„æƒ…æ„Ÿå¥–åŠ±æ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æƒ…æ„Ÿæ™ºèƒ½ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬çš„æƒ…æ„Ÿæ™ºèƒ½ä»ç„¶ä¸è¶³ã€‚RLVERåˆ©ç”¨å¯éªŒè¯çš„æƒ…æ„Ÿå¥–åŠ±ï¼ŒæŒ‡å¯¼æ¨¡å‹å­¦ä¹ æ›´é«˜å±‚æ¬¡çš„åŒç†å¿ƒèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRLVERæ˜¾è‘—æé«˜äº†å¯¹è¯èƒ½åŠ›ï¼Œå¹¶åœ¨ä¿æŒæ•°å­¦å’Œç¼–ç èƒ½åŠ›çš„åŒæ—¶ï¼Œæå‡äº†æ¨¡å‹çš„æƒ…æ„Ÿç†è§£èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.06223",
            "title": "Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers",
            "url": "https://huggingface.co/papers/2507.06223",
            "abstract": "E\\textsuperscript{2}R-FLOPs evaluates LLM-based rerankers by measuring relevance and throughput per PetaFLOP, providing a hardware-agnostic metric for efficiency and effectiveness.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have recently been applied to reranking tasks in information retrieval, achieving strong performance. However, their high computational demands often hinder practical deployment. Existing studies evaluate the efficiency of LLM-based rerankers using proxy metrics such as latency, the number of forward passes, input tokens, and output tokens. However, these metrics depend on hardware and running-time choices (\\eg parallel or not, batch size, etc), and often fail to account for model size, making it difficult to interpret and obscuring the evaluation of the efficiency-effectiveness tradeoff. To address this issue, we propose E2R-FLOPs, for LLM-based rerankers: ranking metrics per PetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for hardware-agnostic throughput. Companied with the new metrics, an interpretable FLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even without running any experiments. Based on the proposed metrics, we conduct comprehensive experiments to evaluate a wide range of LLM-based rerankers with different architecture, studying the efficiency-effectiveness trade-off and bringing this issue to the attention of the research community.",
            "score": 6,
            "issue_id": 4715,
            "pub_date": "2025-07-08",
            "pub_date_card": {
                "ru": "8 Ğ¸ÑĞ»Ñ",
                "en": "July 8",
                "zh": "7æœˆ8æ—¥"
            },
            "hash": "6073d3ee8c07d225",
            "authors": [
                "Zhiyuan Peng",
                "Ting-ruen Wei",
                "Tingyu Song",
                "Yilun Zhao",
                "Yi Fang"
            ],
            "affiliations": [
                "Independent Researcher, Beijing, China",
                "Santa Clara University, Santa Clara, CA",
                "Yale University, New Haven, CT"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.06223.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#interpretability",
                    "#architecture",
                    "#inference"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "E2R-FLOPs: ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ LLM-Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ E2R-FLOPs Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ¸Ğ·Ğ¼ĞµÑ€ÑĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ½ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° ĞŸĞµÑ‚Ğ°Ğ¤Ğ›ĞĞŸ, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑ Ğ°Ğ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ğ½Ğ¾-Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ñ‹Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸Ğº Ğ¤Ğ›ĞĞŸ Ğ´Ğ»Ñ Ñ€Ğ°ÑÑ‡ĞµÑ‚Ğ° Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ LLM-Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¾Ğ² Ğ±ĞµĞ· Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ±Ñ‹Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ñ‹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… LLM-Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¾Ğ², Ğ¸Ğ·ÑƒÑ‡Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ."
                },
                "en": {
                    "title": "E2R-FLOPs: A New Standard for Evaluating LLM Efficiency",
                    "desc": "The paper introduces E2R-FLOPs, a new metric for evaluating the efficiency of Large Language Model (LLM)-based rerankers in information retrieval. It measures relevance and throughput per PetaFLOP, providing a hardware-agnostic way to assess performance. Traditional metrics like latency and token counts are limited by hardware dependencies and do not adequately reflect model size, making comparisons challenging. By using E2R-FLOPs, researchers can better understand the trade-offs between efficiency and effectiveness in LLM-based reranking tasks."
                },
                "zh": {
                    "title": "E2R-FLOPsï¼šé«˜æ•ˆè¯„ä¼°LLMé‡æ’åºå™¨çš„å·¥å…·",
                    "desc": "E2R-FLOPs æ˜¯ä¸€ç§è¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é‡æ’åºå™¨çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡æ¯ PetaFLOP çš„ç›¸å…³æ€§å’Œååé‡æ¥è¡¡é‡å…¶æ•ˆç‡å’Œæœ‰æ•ˆæ€§ã€‚è¿™ç§æ–¹æ³•è§£å†³äº†ç°æœ‰è¯„ä¼°æŒ‡æ ‡ä¾èµ–äºç¡¬ä»¶å’Œè¿è¡Œæ—¶é—´é€‰æ‹©çš„é—®é¢˜ï¼Œä½¿å¾—è¯„ä¼°æ›´åŠ é€šç”¨å’Œæ˜“äºç†è§£ã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†ä¸€ä¸ªå¯è§£é‡Šçš„ FLOPs ä¼°ç®—å™¨ï¼Œå¯ä»¥åœ¨ä¸è¿›è¡Œå®éªŒçš„æƒ…å†µä¸‹ä¼°ç®— LLM é‡æ’åºå™¨çš„ FLOPsã€‚é€šè¿‡è¿™äº›æ–°æŒ‡æ ‡ï¼Œæˆ‘ä»¬å¯¹å¤šç§ä¸åŒæ¶æ„çš„ LLM é‡æ’åºå™¨è¿›è¡Œäº†å…¨é¢å®éªŒï¼Œç ”ç©¶äº†æ•ˆç‡ä¸æœ‰æ•ˆæ€§ä¹‹é—´çš„æƒè¡¡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.05791",
            "title": "GTA1: GUI Test-time Scaling Agent",
            "url": "https://huggingface.co/papers/2507.05791",
            "abstract": "GTA1 addresses task planning ambiguity and visual grounding in GUI interactions using test-time scaling and reinforcement learning, achieving state-of-the-art performance across benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.   This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.   Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here.",
            "score": 6,
            "issue_id": 4715,
            "pub_date": "2025-07-08",
            "pub_date_card": {
                "ru": "8 Ğ¸ÑĞ»Ñ",
                "en": "July 8",
                "zh": "7æœˆ8æ—¥"
            },
            "hash": "e20f930b7b567221",
            "authors": [
                "Yan Yang",
                "Dongxu Li",
                "Yutong Dai",
                "Yuhao Yang",
                "Ziyang Luo",
                "Zirui Zhao",
                "Zhiyuan Hu",
                "Junzhe Huang",
                "Amrita Saha",
                "Zeyuan Chen",
                "Ran Xu",
                "Liyuan Pan",
                "Caiming Xiong",
                "Junnan Li"
            ],
            "affiliations": [
                "Salesforce AI Research",
                "The Australian National University",
                "University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.05791.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#games",
                    "#rl",
                    "#agents",
                    "#open_source"
                ],
                "emoji": "ğŸ–¥ï¸",
                "ru": {
                    "title": "GTA1: Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°Ğ¼Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ GTA1 - Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼, Ñ€ĞµÑˆĞ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºĞ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸. GTA1 Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ»Ğ¸ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "GTA1: Mastering GUI Interactions with Smart Planning and Learning",
                    "desc": "The paper presents GTA1, a novel approach to enhance task planning and visual grounding in graphical user interface (GUI) interactions using reinforcement learning. It addresses the challenges of ambiguity in action proposals by employing a test-time scaling method that samples multiple candidates and selects the best one through a judge model. Additionally, it improves the accuracy of grounding actions to visual elements by leveraging reinforcement learning, which aligns objectives with successful interactions. The results demonstrate that GTA1 achieves state-of-the-art performance on various benchmarks, showcasing its effectiveness in autonomous GUI task execution."
                },
                "zh": {
                    "title": "GTA1ï¼šæå‡GUIäº¤äº’çš„æ™ºèƒ½å†³ç­–ä¸è§†è§‰å®šä½",
                    "desc": "GTA1æ˜¯ä¸€ç§å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†ï¼Œæ—¨åœ¨è§£å†³ä»»åŠ¡è§„åˆ’ä¸­çš„æ¨¡ç³Šæ€§å’Œè§†è§‰å®šä½é—®é¢˜ã€‚å®ƒé€šè¿‡æµ‹è¯•æ—¶ç¼©æ”¾å’Œå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œä¼˜åŒ–äº†åœ¨å¤æ‚ç•Œé¢ä¸­ä¸è§†è§‰å…ƒç´ çš„äº¤äº’ã€‚è¯¥æ–¹æ³•é€šè¿‡é‡‡æ ·å¤šä¸ªå€™é€‰åŠ¨ä½œææ¡ˆï¼Œå¹¶åˆ©ç”¨è¯„åˆ¤æ¨¡å‹é€‰æ‹©æœ€åˆé€‚çš„ææ¡ˆï¼Œä»è€Œæé«˜å†³ç­–è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGTA1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨ä»»åŠ¡æˆåŠŸç‡å’Œå‡†ç¡®æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.03698",
            "title": "SAMed-2: Selective Memory Enhanced Medical Segment Anything Model",
            "url": "https://huggingface.co/papers/2507.03698",
            "abstract": "SAMed-2, an adaptation of SAM-2 for medical image segmentation, incorporates a temporal adapter and confidence-driven memory to improve performance across diverse medical datasets and tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent \"segment anything\" efforts show promise by learning from large-scale data, but adapting such models directly to medical images remains challenging due to the complexity of medical data, noisy annotations, and continual learning requirements across diverse modalities and anatomical structures. In this work, we propose SAMed-2, a new foundation model for medical image segmentation built upon the SAM-2 architecture. Specifically, we introduce a temporal adapter into the image encoder to capture image correlations and a confidence-driven memory mechanism to store high-certainty features for later retrieval. This memory-based strategy counters the pervasive noise in large-scale medical datasets and mitigates catastrophic forgetting when encountering new tasks or modalities. To train and evaluate SAMed-2, we curate MedBank-100k, a comprehensive dataset spanning seven imaging modalities and 21 medical segmentation tasks. Our experiments on both internal benchmarks and 10 external datasets demonstrate superior performance over state-of-the-art baselines in multi-task scenarios. The code is available at: https://github.com/ZhilingYan/Medical-SAM-Bench.",
            "score": 6,
            "issue_id": 4715,
            "pub_date": "2025-07-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ»Ñ",
                "en": "July 4",
                "zh": "7æœˆ4æ—¥"
            },
            "hash": "6eb9d67bc0e6c585",
            "authors": [
                "Zhiling Yan",
                "Sifan Song",
                "Dingjie Song",
                "Yiwei Li",
                "Rong Zhou",
                "Weixiang Sun",
                "Zhennong Chen",
                "Sekeun Kim",
                "Hui Ren",
                "Tianming Liu",
                "Quanzheng Li",
                "Xiang Li",
                "Lifang He",
                "Lichao Sun"
            ],
            "affiliations": [
                "Lehigh University, Bethlehem, PA, USA",
                "Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA",
                "University of Georgia, Athens, GA, USA",
                "University of Notre Dame, Notre Dame, IN, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.03698.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#benchmark",
                    "#healthcare",
                    "#data",
                    "#dataset",
                    "#training"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "SAMed-2: Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
                    "desc": "SAMed-2 - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ SAM-2. ĞĞ½Ğ° Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚ĞµÑ€ Ğ´Ğ»Ñ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸, ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğ¹ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒÑ, Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ². ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… MedBank-100k, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞ¼ 7 Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ 21 Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ SAMed-2 Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Enhancing Medical Image Segmentation with SAMed-2",
                    "desc": "SAMed-2 is a new model designed for medical image segmentation, enhancing the original SAM-2 framework. It introduces a temporal adapter to the image encoder, which helps in understanding relationships between images over time. Additionally, a confidence-driven memory mechanism is implemented to retain important features, addressing issues like noisy data and preventing loss of knowledge when learning new tasks. The model is trained on a large dataset called MedBank-100k, showing improved performance in various medical imaging tasks compared to existing methods."
                },
                "zh": {
                    "title": "åŒ»å­¦å›¾åƒåˆ†å‰²çš„æ–°çªç ´ï¼šSAMed-2",
                    "desc": "SAMed-2æ˜¯é’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†å‰²çš„SAM-2æ¨¡å‹çš„æ”¹è¿›ç‰ˆæœ¬ã€‚å®ƒå¼•å…¥äº†æ—¶é—´é€‚é…å™¨å’ŒåŸºäºä¿¡å¿ƒçš„è®°å¿†æœºåˆ¶ï¼Œä»¥æé«˜åœ¨ä¸åŒåŒ»å­¦æ•°æ®é›†å’Œä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚æ—¶é—´é€‚é…å™¨å¸®åŠ©æ•æ‰å›¾åƒä¹‹é—´çš„ç›¸å…³æ€§ï¼Œè€Œè®°å¿†æœºåˆ¶åˆ™å­˜å‚¨é«˜ç½®ä¿¡åº¦ç‰¹å¾ï¼Œä»¥åº”å¯¹åŒ»å­¦æ•°æ®ä¸­çš„å™ªå£°å’Œé¿å…ç¾éš¾æ€§é—å¿˜ã€‚é€šè¿‡æ„å»ºMedBank-100kæ•°æ®é›†å¹¶è¿›è¡Œå®éªŒï¼ŒSAMed-2åœ¨å¤šä»»åŠ¡åœºæ™¯ä¸­è¡¨ç°ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.06181",
            "title": "CriticLean: Critic-Guided Reinforcement Learning for Mathematical\n  Formalization",
            "url": "https://huggingface.co/papers/2507.06181",
            "abstract": "CriticLean, a reinforcement learning framework with CriticLeanGPT and CriticLeanBench, enhances semantic evaluation in automated theorem proving by actively learning to distinguish correct from incorrect formalizations.  \t\t\t\t\tAI-generated summary \t\t\t\t Translating natural language mathematical statements into formal, executable code is a fundamental challenge in automated theorem proving. While prior work has focused on generation and compilation success, little attention has been paid to the critic phase-the evaluation of whether generated formalizations truly capture the semantic intent of the original problem. In this paper, we introduce CriticLean, a novel critic-guided reinforcement learning framework that elevates the role of the critic from a passive validator to an active learning component. Specifically, first, we propose the CriticLeanGPT, trained via supervised fine-tuning and reinforcement learning, to rigorously assess the semantic fidelity of Lean 4 formalizations. Then, we introduce CriticLeanBench, a benchmark designed to measure models' ability to distinguish semantically correct from incorrect formalizations, and demonstrate that our trained CriticLeanGPT models can significantly outperform strong open- and closed-source baselines. Building on the CriticLean framework, we construct FineLeanCorpus, a dataset comprising over 285K problems that exhibits rich domain diversity, broad difficulty coverage, and high correctness based on human evaluation. Overall, our findings highlight that optimizing the critic phase is essential for producing reliable formalizations, and we hope our CriticLean will provide valuable insights for future advances in formal mathematical reasoning.",
            "score": 4,
            "issue_id": 4715,
            "pub_date": "2025-07-08",
            "pub_date_card": {
                "ru": "8 Ğ¸ÑĞ»Ñ",
                "en": "July 8",
                "zh": "7æœˆ8æ—¥"
            },
            "hash": "ad86fa3f7ff162ee",
            "pdf_title_img": "assets/pdf/title_img/2507.06181.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#dataset"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšÑ€Ğ¸Ñ‚Ğ¸Ğº ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞ¾Ñ€ĞµĞ¼",
                    "desc": "CriticLean - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğµ Ñ‚ĞµĞ¾Ñ€ĞµĞ¼. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ CriticLeanGPT - Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ¸ CriticLeanBench - Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ‚Ğ°ĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°, Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ ĞµĞ³Ğ¾ Ñ€Ğ¾Ğ»ÑŒ Ğ¸Ğ· Ğ¿Ğ°ÑÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ÑÑ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ·Ñ‹ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ¸ ĞºÑ€Ğ°Ğ¹Ğ½Ğµ Ğ²Ğ°Ğ¶Ğ½Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹ Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Empowering Theorem Proving with Active Semantic Evaluation",
                    "desc": "CriticLean is a reinforcement learning framework designed to improve the evaluation of formalizations in automated theorem proving. It introduces CriticLeanGPT, a model that actively learns to assess the semantic accuracy of mathematical statements translated into formal code. The framework also includes CriticLeanBench, a benchmark for measuring the effectiveness of models in distinguishing correct from incorrect formalizations. By optimizing the critic phase, CriticLean aims to enhance the reliability of formalizations and contribute to advancements in formal mathematical reasoning."
                },
                "zh": {
                    "title": "ä¼˜åŒ–è¯„åˆ¤é˜¶æ®µï¼Œæå‡è‡ªåŠ¨å®šç†è¯æ˜çš„å¯é æ€§",
                    "desc": "CriticLeanæ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜è‡ªåŠ¨å®šç†è¯æ˜ä¸­çš„è¯­ä¹‰è¯„ä¼°ã€‚å®ƒé€šè¿‡CriticLeanGPTå’ŒCriticLeanBenchï¼Œä¸»åŠ¨å­¦ä¹ åŒºåˆ†æ­£ç¡®å’Œé”™è¯¯çš„å½¢å¼åŒ–è¡¨è¾¾ã€‚CriticLeanGPTç»è¿‡ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œèƒ½å¤Ÿä¸¥æ ¼è¯„ä¼°Lean 4å½¢å¼åŒ–çš„è¯­ä¹‰å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œä¼˜åŒ–è¯„åˆ¤é˜¶æ®µå¯¹äºç”Ÿæˆå¯é çš„å½¢å¼åŒ–è¡¨è¾¾è‡³å…³é‡è¦ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.05101",
            "title": "PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to\n  Graphs",
            "url": "https://huggingface.co/papers/2507.05101",
            "abstract": "Deep learning-based computational methods have achieved promising results in predicting protein-protein interactions (PPIs). However, existing benchmarks predominantly focus on isolated pairwise evaluations, overlooking a model's capability to reconstruct biologically meaningful PPI networks, which is crucial for biology research. To address this gap, we introduce PRING, the first comprehensive benchmark that evaluates protein-protein interaction prediction from a graph-level perspective. PRING curates a high-quality, multi-species PPI network dataset comprising 21,484 proteins and 186,818 interactions, with well-designed strategies to address both data redundancy and leakage. Building on this golden-standard dataset, we establish two complementary evaluation paradigms: (1) topology-oriented tasks, which assess intra and cross-species PPI network construction, and (2) function-oriented tasks, including protein complex pathway prediction, GO module analysis, and essential protein justification. These evaluations not only reflect the model's capability to understand the network topology but also facilitate protein function annotation, biological module detection, and even disease mechanism analysis. Extensive experiments on four representative model categories, consisting of sequence similarity-based, naive sequence-based, protein language model-based, and structure-based approaches, demonstrate that current PPI models have potential limitations in recovering both structural and functional properties of PPI networks, highlighting the gap in supporting real-world biological applications. We believe PRING provides a reliable platform to guide the development of more effective PPI prediction models for the community. The dataset and source code of PRING are available at https://github.com/SophieSarceau/PRING.",
            "score": 4,
            "issue_id": 4715,
            "pub_date": "2025-07-07",
            "pub_date_card": {
                "ru": "7 Ğ¸ÑĞ»Ñ",
                "en": "July 7",
                "zh": "7æœˆ7æ—¥"
            },
            "hash": "c987593bed9476c8",
            "authors": [
                "Xinzhe Zheng",
                "Hao Du",
                "Fanding Xu",
                "Jinzhe Li",
                "Zhiyuan Liu",
                "Wenkang Wang",
                "Tao Chen",
                "Wanli Ouyang",
                "Stan Z. Li",
                "Yan Lu",
                "Nanqing Dong",
                "Yang Zhang"
            ],
            "affiliations": [
                "Fudan University",
                "National University of Singapore",
                "Shanghai Artificial Intelligence Laboratory",
                "Shanghai Innovation Institute",
                "The Chinese University of Hong Kong",
                "Westlake University",
                "Xian Jiaotong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.05101.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#data",
                    "#open_source",
                    "#dataset",
                    "#graphs",
                    "#leakage"
                ],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "PRING: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ»ĞºĞ¾Ğ²Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ PRING - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ±ĞµĞ»Ğ¾Ğº-Ğ±ĞµĞ»Ğ¾Ğº (PPI) Ñ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ². PRING Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… PPI-ÑĞµÑ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ²Ğ¸Ğ´Ğ¾Ğ², ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ 21,484 Ğ±ĞµĞ»ĞºĞ° Ğ¸ 186,818 Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ´Ğ²Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñ‹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸: Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ñ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ ÑĞµÑ‚Ğ¸, Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ±ĞµĞ»ĞºĞ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ PPI Ğ¸Ğ¼ĞµÑÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ² Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ñ… Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ² PPI-ÑĞµÑ‚ĞµĞ¹."
                },
                "en": {
                    "title": "Revolutionizing PPI Prediction with PRING: A Graph-Level Benchmark",
                    "desc": "This paper introduces PRING, a new benchmark for evaluating protein-protein interaction (PPI) prediction models from a graph-level perspective. Unlike previous benchmarks that focused on pairwise evaluations, PRING assesses the ability of models to reconstruct meaningful PPI networks, which is essential for biological research. The benchmark includes a comprehensive dataset of 21,484 proteins and 186,818 interactions, addressing issues like data redundancy and leakage. The evaluation framework consists of topology-oriented and function-oriented tasks, revealing limitations in current PPI models and guiding future improvements in PPI prediction."
                },
                "zh": {
                    "title": "PRINGï¼šè›‹ç™½è´¨ç›¸äº’ä½œç”¨é¢„æµ‹çš„æ–°åŸºå‡†",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„åŸºå‡†æµ‹è¯•å·¥å…·PRINGï¼Œç”¨äºè¯„ä¼°è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ï¼ˆPPIï¼‰é¢„æµ‹æ¨¡å‹çš„èƒ½åŠ›ã€‚ä¸ä»¥å¾€çš„è¯„ä¼°æ–¹æ³•ä¸åŒï¼ŒPRINGä»å›¾çº§åˆ«çš„è§’åº¦å‡ºå‘ï¼Œå…³æ³¨æ¨¡å‹é‡å»ºç”Ÿç‰©å­¦æ„ä¹‰çš„PPIç½‘ç»œã€‚è¯¥åŸºå‡†æ•°æ®é›†åŒ…å«21,484ä¸ªè›‹ç™½è´¨å’Œ186,818ä¸ªç›¸äº’ä½œç”¨ï¼Œæ—¨åœ¨è§£å†³æ•°æ®å†—ä½™å’Œæ³„æ¼é—®é¢˜ã€‚é€šè¿‡æ‹“æ‰‘å¯¼å‘å’ŒåŠŸèƒ½å¯¼å‘çš„è¯„ä¼°ä»»åŠ¡ï¼ŒPRINGå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£PPIç½‘ç»œçš„ç»“æ„å’ŒåŠŸèƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.06219",
            "title": "Is Diversity All You Need for Scalable Robotic Manipulation?",
            "url": "https://huggingface.co/papers/2507.06219",
            "abstract": "Investigation into data diversity in robotic manipulation reveals that task diversity is crucial, multi-embodiment data is optional, and expert diversity can be confounding, leading to a distribution debiasing method for improved performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Data scaling has driven remarkable success in foundation models for Natural Language Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of \"more diverse is better\". Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, the yielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively.",
            "score": 2,
            "issue_id": 4715,
            "pub_date": "2025-07-08",
            "pub_date_card": {
                "ru": "8 Ğ¸ÑĞ»Ñ",
                "en": "July 8",
                "zh": "7æœˆ8æ—¥"
            },
            "hash": "d4781dc7e2730cb8",
            "authors": [
                "Modi Shi",
                "Li Chen",
                "Jin Chen",
                "Yuxiang Lu",
                "Chiming Liu",
                "Guanghui Ren",
                "Ping Luo",
                "Di Huang",
                "Maoqing Yao",
                "Hongyang Li"
            ],
            "affiliations": [
                "AgiBot",
                "Beihang University",
                "Shanghai AI Lab",
                "Shanghai Innovation Institute",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.06219.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#transfer_learning",
                    "#robotics",
                    "#data",
                    "#dataset",
                    "#training"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞšĞ»ÑÑ‡ Ğº ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ²: Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ°Ğ¶Ğ½ĞµĞµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸Ğ¼ĞµĞµÑ‚ Ñ€ĞµÑˆĞ°ÑÑ‰ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ, Ğ² Ñ‚Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ ĞºĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² Ğ½ĞµĞ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾. Ğ Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ²Ğ½Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¿ÑƒÑ‚Ğ°Ğ½Ğ¸Ñ†Ñƒ, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ²ĞµĞ»Ğ¾ Ğº Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ´ĞµĞ±Ğ¸Ğ°ÑĞ¸Ğ½Ğ³Ğ° Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞœĞ¾Ğ´ĞµĞ»Ğ¸, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°, Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ñ‚ÑŒÑÑ Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ GO-1-Pro, ÑĞ½Ğ¸Ğ¶Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ½ĞµĞ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ´Ğ¾ÑÑ‚Ğ¸Ñ‡ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² 15%."
                },
                "en": {
                    "title": "Diversity in Data: Key to Better Robot Learning",
                    "desc": "This paper explores the importance of data diversity in robotic manipulation, focusing on three key aspects: task diversity, embodiment diversity, and expert diversity. It finds that having a variety of tasks is more beneficial than simply increasing the number of demonstrations for each task. The study also shows that using data from a single robot can be just as effective as using data from multiple robots for training. Additionally, it highlights that differences in how experts demonstrate tasks can complicate learning, leading to the development of a new method to reduce confusion caused by these variations, resulting in significant performance improvements."
                },
                "zh": {
                    "title": "ä»»åŠ¡å¤šæ ·æ€§æ˜¯æœºå™¨äººæ“ä½œçš„å…³é”®",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†æ•°æ®å¤šæ ·æ€§åœ¨æœºå™¨äººæ“ä½œä¸­çš„é‡è¦æ€§ï¼Œå‘ç°ä»»åŠ¡å¤šæ ·æ€§æ˜¯å…³é”®ï¼Œè€Œå¤šç§æœºå™¨äººå½¢æ€çš„æ•°æ®æ˜¯å¯é€‰çš„ã€‚é€šè¿‡å¯¹ä¸åŒæœºå™¨äººå¹³å°çš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å‘ç°ä»»åŠ¡å¤šæ ·æ€§æ¯”æ¯ä¸ªä»»åŠ¡çš„æ¼”ç¤ºæ•°é‡æ›´ä¸ºé‡è¦ï¼Œæœ‰åŠ©äºä»å¤šæ ·çš„é¢„è®­ç»ƒä»»åŠ¡è½¬ç§»åˆ°æ–°çš„ä¸‹æ¸¸åœºæ™¯ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åˆ†å¸ƒå»åæ–¹æ³•ï¼Œä»¥å‡å°‘é€Ÿåº¦æ¨¡ç³Šï¼Œä»è€Œæ˜¾è‘—æé«˜æ€§èƒ½ã€‚æ•´ä½“è€Œè¨€ï¼Œè¿™äº›å‘ç°ä¸ºæœ‰æ•ˆæ‰©å±•æœºå™¨äººæ“ä½œæ•°æ®é›†æä¾›äº†æ–°çš„è§†è§’å’Œå®ç”¨æŒ‡å¯¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.04610",
            "title": "any4: Learned 4-bit Numeric Representation for LLMs",
            "url": "https://huggingface.co/papers/2507.04610",
            "abstract": "any4 is a learned 4-bit weight quantization method for LLMs that achieves high accuracy without preprocessing and uses a GPU-efficient lookup table strategy.  \t\t\t\t\tAI-generated summary \t\t\t\t We present any4, a learned 4-bit weight quantization solution for large language models (LLMs) providing arbitrary numeric representations without requiring pre-processing of weights or activations. any4 yields higher accuracy compared to other related 4-bit numeric representation types: int4, fp4 and nf4, as evaluated on a range of model sizes, generations and families (Llama 2, Llama 3, Mistral and Mixtral). While any4 does not require preprocessing of weights or activations, it is also competitive with orthogonal techniques that require such preprocessing (e.g., AWQ and GPTQ). We also experiment with any3 and any2 and show competitiveness at lower bits. Additionally, we show that we can calibrate using a single curated diverse sample rather than hundreds of samples from a dataset as done in most quantization approaches. We also open source tinygemm, a latency optimized GPU matrix multiplication library for LLMs, that implements any4 using a GPU-efficient lookup table strategy along with other common quantization methods. We open source our code at https://github.com/facebookresearch/any4 .",
            "score": 2,
            "issue_id": 4715,
            "pub_date": "2025-07-07",
            "pub_date_card": {
                "ru": "7 Ğ¸ÑĞ»Ñ",
                "en": "July 7",
                "zh": "7æœˆ7æ—¥"
            },
            "hash": "677d34e801c63489",
            "authors": [
                "Mostafa Elhoushi",
                "Jeff Johnson"
            ],
            "affiliations": [
                "FAIR at Meta"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.04610.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#optimization",
                    "#inference",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "any4: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ LLM Ğ±ĞµĞ· ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑĞ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ any4 - Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ğ¾Ğ¹ 4-Ğ±Ğ¸Ñ‚Ğ½Ğ¾Ğ¹ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ²ĞµÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²ĞµÑĞ¾Ğ² Ğ¸Ğ»Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¹, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ 4-Ğ±Ğ¸Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ. any4 Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ´Ğ»Ñ GPU ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğµ Ğ¸ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ñ any3 Ğ¸ any2, Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ² Ğ¸Ñ… ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¼ĞµĞ½ÑŒÑˆĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ±Ğ¸Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "any4: Efficient 4-Bit Weight Quantization for High-Accuracy LLMs",
                    "desc": "The paper introduces any4, a novel method for quantizing weights in large language models (LLMs) to 4 bits, which maintains high accuracy without the need for preprocessing. This method outperforms existing 4-bit representations like int4, fp4, and nf4 across various model sizes and families. Additionally, any4 allows for calibration using just one diverse sample, contrasting with traditional methods that require many samples. The authors also provide an open-source GPU-optimized library, tinygemm, to implement this quantization technique efficiently."
                },
                "zh": {
                    "title": "any4ï¼šé«˜æ•ˆçš„4ä½æƒé‡é‡åŒ–æ–¹æ³•",
                    "desc": "any4æ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å­¦ä¹ å‹4ä½æƒé‡é‡åŒ–æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦é¢„å¤„ç†çš„æƒ…å†µä¸‹å®ç°é«˜ç²¾åº¦çš„æ•°å€¼è¡¨ç¤ºã€‚ä¸å…¶ä»–4ä½æ•°å€¼è¡¨ç¤ºæ–¹æ³•ï¼ˆå¦‚int4ã€fp4å’Œnf4ï¼‰ç›¸æ¯”ï¼Œany4åœ¨å¤šç§æ¨¡å‹è§„æ¨¡å’Œç±»å‹ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥ä½¿ç”¨å•ä¸ªå¤šæ ·åŒ–æ ·æœ¬è¿›è¡Œæ ¡å‡†ï¼Œè€Œä¸æ˜¯åƒå¤§å¤šæ•°é‡åŒ–æ–¹æ³•é‚£æ ·éœ€è¦æ•°ç™¾ä¸ªæ ·æœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€æºäº†tinygemmï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹LLMsä¼˜åŒ–çš„GPUçŸ©é˜µä¹˜æ³•åº“ï¼Œé‡‡ç”¨äº†é«˜æ•ˆçš„æŸ¥æ‰¾è¡¨ç­–ç•¥æ¥å®ç°any4ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.05578",
            "title": "The Landscape of Memorization in LLMs: Mechanisms, Measurement, and\n  Mitigation",
            "url": "https://huggingface.co/papers/2507.05578",
            "abstract": "The paper reviews recent studies on memorization in Large Language Models, exploring factors that influence memorization, detection methodologies, and mitigation strategies, while addressing privacy and ethical implications.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet they also exhibit memorization of their training data. This phenomenon raises critical questions about model behavior, privacy risks, and the boundary between learning and memorization. Addressing these concerns, this paper synthesizes recent studies and investigates the landscape of memorization, the factors influencing it, and methods for its detection and mitigation. We explore key drivers, including training data duplication, training dynamics, and fine-tuning procedures that influence data memorization. In addition, we examine methodologies such as prefix-based extraction, membership inference, and adversarial prompting, assessing their effectiveness in detecting and measuring memorized content. Beyond technical analysis, we also explore the broader implications of memorization, including the legal and ethical implications. Finally, we discuss mitigation strategies, including data cleaning, differential privacy, and post-training unlearning, while highlighting open challenges in balancing the minimization of harmful memorization with utility. This paper provides a comprehensive overview of the current state of research on LLM memorization across technical, privacy, and performance dimensions, identifying critical directions for future work.",
            "score": 1,
            "issue_id": 4715,
            "pub_date": "2025-07-08",
            "pub_date_card": {
                "ru": "8 Ğ¸ÑĞ»Ñ",
                "en": "July 8",
                "zh": "7æœˆ8æ—¥"
            },
            "hash": "9fd6f105854c8570",
            "authors": [
                "Alexander Xiong",
                "Xuandong Zhao",
                "Aneesh Pappu",
                "Dawn Song"
            ],
            "affiliations": [
                "Google DeepMind",
                "University of California, Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.05578.jpg",
            "data": {
                "categories": [
                    "#healthcare",
                    "#hallucinations",
                    "#survey",
                    "#data",
                    "#training",
                    "#ethics"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğµ Ğ² LLM: Ğ¾Ñ‚ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ¾Ğ² Ğ´Ğ¾ ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¸Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸Ğ·ÑƒÑ‡Ğ°ÑÑ‚ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹, Ğ²Ğ»Ğ¸ÑÑÑ‰Ğ¸Ğµ Ğ½Ğ° Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğµ, Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ ĞµĞ³Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ÑĞ¼ÑĞ³Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ğ¹. Ğ Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ Ñ‚Ğ°ĞºĞ¸Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹, ĞºĞ°Ğº Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñ‹ Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸. Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ÑÑ‚ÑÑ Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğ²Ñ‹Ğµ Ğ¸ ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ñ Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ Ğ² LLM."
                },
                "en": {
                    "title": "Understanding and Mitigating Memorization in Large Language Models",
                    "desc": "This paper reviews how Large Language Models (LLMs) memorize information from their training data, which can lead to privacy concerns. It discusses factors that contribute to this memorization, such as data duplication and training methods. The paper also evaluates various techniques for detecting memorized data, like membership inference and adversarial prompting. Finally, it suggests strategies to reduce harmful memorization while maintaining model performance, highlighting the need for further research in this area."
                },
                "zh": {
                    "title": "å¤§å‹è¯­è¨€æ¨¡å‹çš„è®°å¿†ç°è±¡ä¸æŒ‘æˆ˜",
                    "desc": "è¿™ç¯‡è®ºæ–‡å›é¡¾äº†å…³äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®°å¿†ç°è±¡çš„æœ€æ–°ç ”ç©¶ï¼Œæ¢è®¨äº†å½±å“è®°å¿†çš„å› ç´ ã€æ£€æµ‹æ–¹æ³•å’Œç¼“è§£ç­–ç•¥ï¼ŒåŒæ—¶å…³æ³¨éšç§å’Œä¼¦ç†é—®é¢˜ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒLLMåœ¨æ‰§è¡Œä»»åŠ¡æ—¶ä¼šè®°ä½è®­ç»ƒæ•°æ®ï¼Œè¿™å¼•å‘äº†å…³äºæ¨¡å‹è¡Œä¸ºå’Œéšç§é£é™©çš„å…³é”®é—®é¢˜ã€‚è®ºæ–‡åˆ†æäº†è®­ç»ƒæ•°æ®é‡å¤ã€è®­ç»ƒåŠ¨æ€å’Œå¾®è°ƒè¿‡ç¨‹ç­‰å…³é”®é©±åŠ¨å› ç´ ï¼Œå¹¶è¯„ä¼°äº†å‰ç¼€æå–ã€æˆå‘˜æ¨æ–­å’Œå¯¹æŠ—æ€§æç¤ºç­‰æ£€æµ‹æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æœ€åï¼Œè®ºæ–‡è®¨è®ºäº†æ•°æ®æ¸…ç†ã€å·®åˆ†éšç§å’Œåè®­ç»ƒé—å¿˜ç­‰ç¼“è§£ç­–ç•¥ï¼Œå¼ºè°ƒåœ¨å‡å°‘æœ‰å®³è®°å¿†ä¸ä¿æŒæ¨¡å‹æ•ˆç”¨ä¹‹é—´çš„æŒ‘æˆ˜ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-07-08.html",
    "link_next": "2025-07-10.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "08.07",
        "en": "07/08",
        "zh": "7æœˆ8æ—¥"
    },
    "short_date_next": {
        "ru": "10.07",
        "en": "07/10",
        "zh": "7æœˆ10æ—¥"
    },
    "categories": {
        "#dataset": 4,
        "#data": 4,
        "#benchmark": 5,
        "#agents": 2,
        "#cv": 1,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 2,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 2,
        "#training": 5,
        "#robotics": 1,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 2,
        "#transfer_learning": 1,
        "#graphs": 1,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 5,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 1,
        "#open_source": 3,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}