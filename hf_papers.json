{
    "date": {
        "ru": "27 декабря",
        "en": "December 27",
        "zh": "12月27日"
    },
    "time_utc": "2024-12-27 03:15",
    "weekday": 4,
    "issue_id": 1350,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.18547",
            "title": "Token-Budget-Aware LLM Reasoning",
            "url": "https://huggingface.co/papers/2412.18547",
            "abstract": "Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We find that the reasoning process of current LLMs is unnecessarily lengthy and it can be compressed by including a reasonable token budget in the prompt, but the choice of token budget plays a crucial role in the actual compression effectiveness. We then propose a token-budget-aware LLM reasoning framework, which dynamically estimates token budgets for different problems based on reasoning complexity and uses the estimated token budgets to guide the reasoning process. Experiments show that our method effectively reduces token costs in CoT reasoning with only a slight performance reduction, offering a practical solution to balance efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.",
            "score": 12,
            "issue_id": 1328,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 декабря",
                "en": "December 24",
                "zh": "12月24日"
            },
            "hash": "9a018cda2c47f064",
            "authors": [
                "Tingxu Han",
                "Chunrong Fang",
                "Shiyu Zhao",
                "Shiqing Ma",
                "Zhenyu Chen",
                "Zhenting Wang"
            ],
            "affiliations": [
                "Nanjing University",
                "Rutgers University",
                "UMass Amherst"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18547.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "💡",
                "ru": {
                    "title": "Эффективные рассуждения ИИ: больше мыслей, меньше токенов",
                    "desc": "Статья описывает новый подход к рассуждениям в больших языковых моделях (LLM), направленный на оптимизацию использования токенов. Авторы предлагают метод, который динамически оценивает бюджет токенов для различных задач на основе сложности рассуждений. Этот подход позволяет значительно сократить расходы на токены при использовании метода цепочки мыслей (CoT), сохраняя при этом высокую точность. Эксперименты показывают эффективность предложенного метода в балансировании эффективности и точности рассуждений LLM."
                },
                "en": {
                    "title": "Optimizing Reasoning Efficiency in LLMs with Token Budgets",
                    "desc": "This paper addresses the reasoning efficiency of large language models (LLMs) by introducing a token-budget-aware framework. It highlights that while Chain-of-Thought (CoT) reasoning improves performance, it also increases token usage and costs. The authors propose a method to dynamically estimate token budgets based on the complexity of reasoning tasks, allowing for more efficient use of tokens. Experimental results demonstrate that this approach reduces token costs with minimal impact on performance, providing a balance between efficiency and accuracy in LLM reasoning."
                },
                "zh": {
                    "title": "优化推理，降低成本！",
                    "desc": "推理对于大型语言模型（LLMs）在多种任务中表现出色至关重要。虽然链式推理（CoT）方法通过将问题分解为中间步骤来提高LLM性能，但这也导致了显著的令牌使用开销，增加了成本。我们发现当前LLM的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对压缩效果至关重要。我们提出了一种基于令牌预算的LLM推理框架，动态估计不同问题的令牌预算，从而在保持效率和准确性之间取得平衡。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.18319",
            "title": "Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search",
            "url": "https://huggingface.co/papers/2412.18319",
            "abstract": "In this work, we aim to develop an MLLM that understands and solves questions by learning to create each intermediate step of the reasoning involved till the final answer. To this end, we propose Collective Monte Carlo Tree Search (CoMCTS), a new learning-to-reason method for MLLMs, which introduces the concept of collective learning into ``tree search'' for effective and efficient reasoning-path searching and learning. The core idea of CoMCTS is to leverage collective knowledge from multiple models to collaboratively conjecture, search and identify effective reasoning paths toward correct answers via four iterative operations including Expansion, Simulation and Error Positioning, Backpropagation, and Selection. Using CoMCTS, we construct Mulberry-260k, a multimodal dataset with a tree of rich, explicit and well-defined reasoning nodes for each question. With Mulberry-260k, we perform collective SFT to train our model, Mulberry, a series of MLLMs with o1-like step-by-step Reasoning and Reflection capabilities. Extensive experiments demonstrate the superiority of our proposed methods on various benchmarks. Code will be available at https://github.com/HJYao00/Mulberry",
            "score": 8,
            "issue_id": 1341,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 декабря",
                "en": "December 24",
                "zh": "12月24日"
            },
            "hash": "cb1baee5756c3113",
            "authors": [
                "Huanjin Yao",
                "Jiaxing Huang",
                "Wenhao Wu",
                "Jingyi Zhang",
                "Yibo Wang",
                "Shunyu Liu",
                "Yingjie Wang",
                "Yuxin Song",
                "Haocheng Feng",
                "Li Shen",
                "Dacheng Tao"
            ],
            "affiliations": [
                "Baidu Inc.",
                "Nanyang Technological University",
                "Sun Yat-sen University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18319.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#agents",
                    "#multimodal",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "🌳",
                "ru": {
                    "title": "Коллективный поиск рассуждений для мультимодальных языковых моделей",
                    "desc": "В этой работе представлен новый метод обучения мультимодальных языковых моделей (MLLM) под названием Collective Monte Carlo Tree Search (CoMCTS). Метод использует коллективные знания нескольких моделей для эффективного поиска путей рассуждения через четыре итеративные операции. На основе CoMCTS был создан набор данных Mulberry-260k с деревом рассуждений для каждого вопроса. С помощью этого набора данных обучена модель Mulberry, демонстрирующая превосходные результаты на различных бенчмарках."
                },
                "en": {
                    "title": "Collaborative Reasoning for Enhanced MLLM Performance",
                    "desc": "This paper introduces a new method called Collective Monte Carlo Tree Search (CoMCTS) for training machine learning language models (MLLMs) to reason through questions step-by-step. CoMCTS enhances traditional tree search techniques by incorporating collective learning from multiple models, allowing them to collaboratively explore and identify effective reasoning paths. The authors create a dataset named Mulberry-260k, which contains structured reasoning nodes for various questions, facilitating the training of their model, Mulberry. Experimental results show that Mulberry outperforms existing models in reasoning tasks, demonstrating the effectiveness of the CoMCTS approach."
                },
                "zh": {
                    "title": "集体学习提升推理能力的创新方法",
                    "desc": "本研究旨在开发一种多模态大语言模型（MLLM），使其能够理解并解决问题，通过学习每个推理步骤直至最终答案。我们提出了一种新的学习推理方法，称为集体蒙特卡洛树搜索（CoMCTS），它将集体学习的概念引入到树搜索中，以实现有效的推理路径搜索和学习。CoMCTS的核心思想是利用多个模型的集体知识，通过扩展、模拟、错误定位、反向传播和选择等四个迭代操作，协同推测、搜索并识别有效的推理路径。通过使用Mulberry-260k数据集，我们训练了Mulberry模型，使其具备逐步推理和反思的能力，实验结果表明我们的方法在多个基准测试中表现优越。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.17726",
            "title": "VidTwin: Video VAE with Decoupled Structure and Dynamics",
            "url": "https://huggingface.co/papers/2412.17726",
            "abstract": "Recent advancements in video autoencoders (Video AEs) have significantly improved the quality and efficiency of video generation. In this paper, we propose a novel and compact video autoencoder, VidTwin, that decouples video into two distinct latent spaces: Structure latent vectors, which capture overall content and global movement, and Dynamics latent vectors, which represent fine-grained details and rapid movements. Specifically, our approach leverages an Encoder-Decoder backbone, augmented with two submodules for extracting these latent spaces, respectively. The first submodule employs a Q-Former to extract low-frequency motion trends, followed by downsampling blocks to remove redundant content details. The second averages the latent vectors along the spatial dimension to capture rapid motion. Extensive experiments show that VidTwin achieves a high compression rate of 0.20% with high reconstruction quality (PSNR of 28.14 on the MCL-JCV dataset), and performs efficiently and effectively in downstream generative tasks. Moreover, our model demonstrates explainability and scalability, paving the way for future research in video latent representation and generation. Our code has been released at https://github.com/microsoft/VidTok/tree/main/vidtwin.",
            "score": 1,
            "issue_id": 1350,
            "pub_date": "2024-12-23",
            "pub_date_card": {
                "ru": "23 декабря",
                "en": "December 23",
                "zh": "12月23日"
            },
            "hash": "df96145ae3273ac6",
            "authors": [
                "Yuchi Wang",
                "Junliang Guo",
                "Xinyi Xie",
                "Tianyu He",
                "Xu Sun",
                "Jiang Bian"
            ],
            "affiliations": [
                "CUHK (SZ)",
                "Microsoft Research Asia",
                "Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.17726.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#architecture"
                ],
                "emoji": "🎞️",
                "ru": {
                    "title": "VidTwin: Компактное представление видео в двух латентных пространствах",
                    "desc": "Статья представляет новый компактный видео автоэнкодер VidTwin, который разделяет видео на два отдельных латентных пространства: структурные и динамические векторы. Модель использует архитектуру энкодер-декодер с дополнительными подмодулями для извлечения этих латентных пространств. VidTwin достигает высокого коэффициента сжатия 0,20% с хорошим качеством реконструкции (PSNR 28,14 на датасете MCL-JCV). Эксперименты показывают эффективность модели в задачах генерации видео, а также её масштабируемость и интерпретируемость."
                },
                "en": {
                    "title": "Decoupling Video for Better Generation with VidTwin",
                    "desc": "This paper introduces VidTwin, a new type of video autoencoder that enhances video generation by separating video data into two different latent spaces. The Structure latent vectors focus on the overall content and global movements, while the Dynamics latent vectors capture detailed and quick movements. The model uses an Encoder-Decoder architecture with specialized submodules to efficiently extract these latent representations. VidTwin achieves impressive compression and reconstruction quality, making it suitable for various generative tasks and future research in video representation."
                },
                "zh": {
                    "title": "VidTwin：高效视频生成的新方法",
                    "desc": "本文提出了一种新型紧凑的视频自编码器VidTwin，能够将视频解耦为两个不同的潜在空间：结构潜在向量和动态潜在向量。结构潜在向量捕捉整体内容和全局运动，而动态潜在向量则表示细微的细节和快速运动。我们的方法使用了编码器-解码器架构，并通过两个子模块分别提取这两个潜在空间。实验结果表明，VidTwin在重建质量和压缩率方面表现优异，适用于后续生成任务，并具有可解释性和可扩展性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.18495",
            "title": "How \"Real\" is Your Real-Time Simultaneous Speech-to-Text Translation System?",
            "url": "https://huggingface.co/papers/2412.18495",
            "abstract": "Simultaneous speech-to-text translation (SimulST) translates source-language speech into target-language text concurrently with the speaker's speech, ensuring low latency for better user comprehension. Despite its intended application to unbounded speech, most research has focused on human pre-segmented speech, simplifying the task and overlooking significant challenges. This narrow focus, coupled with widespread terminological inconsistencies, is limiting the applicability of research outcomes to real-world applications, ultimately hindering progress in the field. Our extensive literature review of 110 papers not only reveals these critical issues in current research but also serves as the foundation for our key contributions. We 1) define the steps and core components of a SimulST system, proposing a standardized terminology and taxonomy; 2) conduct a thorough analysis of community trends, and 3) offer concrete recommendations and future directions to bridge the gaps in existing literature, from evaluation frameworks to system architectures, for advancing the field towards more realistic and effective SimulST solutions.",
            "score": 1,
            "issue_id": 1345,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 декабря",
                "en": "December 24",
                "zh": "12月24日"
            },
            "hash": "40843b43c87690db",
            "authors": [
                "Sara Papi",
                "Peter Polak",
                "Ondřej Bojar",
                "Dominik Macháček"
            ],
            "affiliations": [
                "Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics, Czech Republic",
                "Fondazione Bruno Kessler, Italy"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18495.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#benchmark",
                    "#architecture",
                    "#multimodal",
                    "#audio"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "Стандартизация и реалистичность: путь к эффективным системам одновременного перевода речи",
                    "desc": "Статья посвящена системам одновременного перевода речи в текст (SimulST). Авторы выявляют проблемы в текущих исследованиях, включая фокус на предварительно сегментированной речи и терминологические несоответствия. Они предлагают стандартизированную терминологию и таксономию для SimulST систем. Исследователи также анализируют тенденции в области и дают рекомендации по улучшению оценки и архитектуры систем SimulST."
                },
                "en": {
                    "title": "Advancing Simultaneous Speech-to-Text Translation for Real-World Applications",
                    "desc": "This paper addresses the challenges in simultaneous speech-to-text translation (SimulST), which translates spoken language into text in real-time. It highlights that most research has focused on simplified, pre-segmented speech, neglecting the complexities of unbounded speech scenarios. The authors conducted a literature review of 110 papers to identify critical issues and inconsistencies in terminology that hinder progress in the field. They propose a standardized framework for SimulST systems, analyze current trends, and provide recommendations for future research to improve real-world applications."
                },
                "zh": {
                    "title": "推动同时语音翻译的标准化与发展",
                    "desc": "本文讨论了同时语音翻译（SimulST）的挑战与发展。尽管SimulST旨在实时将源语言语音翻译为目标语言文本，但大多数研究集中于人类预先分段的语音，忽视了实际应用中的复杂性。我们对110篇文献进行了广泛的回顾，揭示了当前研究中的关键问题，并提出了标准化的术语和分类法。最后，我们提供了具体的建议和未来方向，以推动SimulST领域向更现实和有效的解决方案发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.17998",
            "title": "WavePulse: Real-time Content Analytics of Radio Livestreams",
            "url": "https://huggingface.co/papers/2412.17998",
            "abstract": "Radio remains a pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present WavePulse, a framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of WavePulse in a collaborative project with a team of political scientists focusing on the 2024 Presidential Elections. We use WavePulse to monitor livestreams of 396 news radio stations over a period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to track answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate WavePulse's efficacy in capturing and analyzing content from radio livestreams sourced from the Web. Code and dataset can be accessed at https://wave-pulse.io.",
            "score": 1,
            "issue_id": 1342,
            "pub_date": "2024-12-23",
            "pub_date_card": {
                "ru": "23 декабря",
                "en": "December 23",
                "zh": "12月23日"
            },
            "hash": "f1e86c8c69c0a7d6",
            "authors": [
                "Govind Mittal",
                "Sarthak Gupta",
                "Shruti Wagle",
                "Chirag Chopra",
                "Anthony J DeMattee",
                "Nasir Memon",
                "Mustaque Ahamad",
                "Chinmay Hegde"
            ],
            "affiliations": [
                "Georgia Institute of Technology Atlanta, GA, USA",
                "New York University Tandon School of Engineering Brooklyn, NY, USA",
                "The Carter Center Atlanta, GA, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.17998.jpg",
            "data": {
                "categories": [
                    "#audio",
                    "#dataset",
                    "#data"
                ],
                "emoji": "📻",
                "ru": {
                    "title": "WavePulse: Прослушивание пульса нации через радиоэфир",
                    "desc": "WavePulse - это фреймворк для записи, документирования и анализа радиоконтента в реальном времени. Исследователи использовали его для мониторинга 396 новостных радиостанций в течение трех месяцев, обработав почти 500 000 часов аудиопотоков. Система преобразовывала потоки в стенограммы с временными метками и диаризацией, которые затем анализировались для отслеживания ключевых вопросов политологии на национальном и региональном уровнях. Анализ выявил взаимодействие локальных проблем с национальными тенденциями, предоставив insights о потоках информации."
                },
                "en": {
                    "title": "WavePulse: Real-Time Analysis of Radio Content for Political Insights",
                    "desc": "WavePulse is a framework designed to record, document, and analyze radio content in real-time, particularly focusing on online streams. It was applied in a project with political scientists to study the 2024 Presidential Elections by monitoring 396 news radio stations over three months. The framework processed nearly 500,000 hours of audio, converting them into time-stamped, diarized transcripts for analysis. This analysis provided valuable insights into how local issues influenced national trends in political discourse."
                },
                "zh": {
                    "title": "WavePulse：实时分析广播内容的强大工具",
                    "desc": "本文介绍了WavePulse框架，它能够实时记录、记录和分析广播内容。我们在2024年总统选举的项目中展示了WavePulse的有效性，监测了396个新闻电台的直播，处理了近50万小时的音频流。通过将音频流转换为带时间戳的逐字稿，我们能够分析地方问题与国家趋势之间的互动。我们的研究结果表明，WavePulse在捕捉和分析网络广播内容方面具有很高的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.18609",
            "title": "Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models",
            "url": "https://huggingface.co/papers/2412.18609",
            "abstract": "We present an efficient encoder-free approach for video-language understanding that achieves competitive performance while significantly reducing computational overhead. Current video-language models typically rely on heavyweight image encoders (300M-1.1B parameters) or video encoders (1B-1.4B parameters), creating a substantial computational burden when processing multi-frame videos. Our method introduces a novel Spatio-Temporal Alignment Block (STAB) that directly processes video inputs without requiring pre-trained encoders while using only 45M parameters for visual processing - at least a 6.5times reduction compared to traditional approaches. The STAB architecture combines Local Spatio-Temporal Encoding for fine-grained feature extraction, efficient spatial downsampling through learned attention and separate mechanisms for modeling frame-level and video-level relationships. Our model achieves comparable or superior performance to encoder-based approaches for open-ended video question answering on standard benchmarks. The fine-grained video question-answering evaluation demonstrates our model's effectiveness, outperforming the encoder-based approaches Video-ChatGPT and Video-LLaVA in key aspects like correctness and temporal understanding. Extensive ablation studies validate our architectural choices and demonstrate the effectiveness of our spatio-temporal modeling approach while achieving 3-4times faster processing speeds than previous methods. Code is available at https://github.com/jh-yi/Video-Panda.",
            "score": 1,
            "issue_id": 1341,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 декабря",
                "en": "December 24",
                "zh": "12月24日"
            },
            "hash": "2cf82ae4b3c11ce8",
            "authors": [
                "Jinhui Yi",
                "Syed Talal Wasim",
                "Yanan Luo",
                "Muzammal Naseer",
                "Juergen Gall"
            ],
            "affiliations": [
                "Khalifa University",
                "University of Bonn"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18609.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#optimization",
                    "#open_source",
                    "#benchmark",
                    "#architecture"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Эффективное понимание видео без энкодера: революция в обработке видеоданных",
                    "desc": "Исследователи представили эффективный подход к пониманию видео и языка без использования энкодера, который достигает конкурентоспособной производительности при значительном снижении вычислительных затрат. Метод вводит новый блок пространственно-временного выравнивания (STAB), который обрабатывает видеовходы напрямую, используя всего 45 миллионов параметров для визуальной обработки. Модель достигает сопоставимой или превосходящей производительности по сравнению с подходами на основе энкодеров для открытого видео-вопросно-ответного анализа на стандартных тестах. Обширные исследования подтверждают эффективность архитектурных решений и демонстрируют 3-4-кратное ускорение обработки по сравнению с предыдущими методами."
                },
                "en": {
                    "title": "Efficient Video-Language Understanding with STAB",
                    "desc": "This paper introduces a new method for understanding videos in relation to language without using heavy encoders, which are typically resource-intensive. The proposed Spatio-Temporal Alignment Block (STAB) processes video inputs directly and uses only 45 million parameters, significantly less than traditional models. It employs techniques like Local Spatio-Temporal Encoding and learned attention for efficient feature extraction and relationship modeling. The results show that this approach not only matches but often surpasses the performance of existing encoder-based models in video question answering tasks, while also being faster and more efficient."
                },
                "zh": {
                    "title": "高效视频语言理解的新方法",
                    "desc": "我们提出了一种高效的无编码器视频语言理解方法，能够在显著降低计算负担的同时实现竞争力的性能。传统的视频语言模型通常依赖于大型图像编码器或视频编码器，处理多帧视频时会造成巨大的计算压力。我们的方法引入了一种新颖的时空对齐模块（STAB），直接处理视频输入，使用仅45M参数进行视觉处理，减少了至少6.5倍的计算量。我们的模型在开放式视频问答任务中表现出与基于编码器的方法相当或更优的性能，尤其在正确性和时间理解等关键方面超越了现有的编码器方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.17780",
            "title": "PepTune: De Novo Generation of Therapeutic Peptides with Multi-Objective-Guided Discrete Diffusion",
            "url": "https://huggingface.co/papers/2412.17780",
            "abstract": "Peptide therapeutics, a major class of medicines, have achieved remarkable success across diseases such as diabetes and cancer, with landmark examples such as GLP-1 receptor agonists revolutionizing the treatment of type-2 diabetes and obesity. Despite their success, designing peptides that satisfy multiple conflicting objectives, such as target binding affinity, solubility, and membrane permeability, remains a major challenge. Classical drug development and structure-based design are ineffective for such tasks, as they fail to optimize global functional properties critical for therapeutic efficacy. Existing generative frameworks are largely limited to continuous spaces, unconditioned outputs, or single-objective guidance, making them unsuitable for discrete sequence optimization across multiple properties. To address this, we present PepTune, a multi-objective discrete diffusion model for the simultaneous generation and optimization of therapeutic peptide SMILES. Built on the Masked Discrete Language Model (MDLM) framework, PepTune ensures valid peptide structures with state-dependent masking schedules and penalty-based objectives. To guide the diffusion process, we propose a Monte Carlo Tree Search (MCTS)-based strategy that balances exploration and exploitation to iteratively refine Pareto-optimal sequences. MCTS integrates classifier-based rewards with search-tree expansion, overcoming gradient estimation challenges and data sparsity inherent to discrete spaces. Using PepTune, we generate diverse, chemically-modified peptides optimized for multiple therapeutic properties, including target binding affinity, membrane permeability, solubility, hemolysis, and non-fouling characteristics on various disease-relevant targets. In total, our results demonstrate that MCTS-guided discrete diffusion is a powerful and modular approach for multi-objective sequence design in discrete state spaces.",
            "score": 1,
            "issue_id": 1340,
            "pub_date": "2024-12-23",
            "pub_date_card": {
                "ru": "23 декабря",
                "en": "December 23",
                "zh": "12月23日"
            },
            "hash": "9607ccf742aa57fb",
            "authors": [
                "Sophia Tang",
                "Yinuo Zhang",
                "Pranam Chatterjee"
            ],
            "affiliations": [
                "Center of Computational Biology, Duke-NUS Medical School",
                "Department of Biomedical Engineering, Duke University",
                "Department of Biostatistics and Bioinformatics, Duke University",
                "Department of Computer Science, Duke University",
                "Management and Technology Program, University of Pennsylvania"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.17780.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#training",
                    "#dataset",
                    "#architecture",
                    "#data",
                    "#optimization"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "PepTune: Революция в разработке пептидных лекарств с помощью ИИ",
                    "desc": "PepTune - это мультицелевая дискретная диффузионная модель для одновременной генерации и оптимизации терапевтических пептидов в формате SMILES. Модель основана на фреймворке Masked Discrete Language Model (MDLM) и использует стратегию поиска Монте-Карло для итеративного уточнения последовательностей, оптимальных по Парето. PepTune способна генерировать разнообразные химически модифицированные пептиды, оптимизированные по нескольким терапевтическим свойствам. Результаты демонстрируют, что дискретная диффузия с управлением на основе MCTS является мощным и модульным подходом для многоцелевого дизайна последовательностей в дискретных пространствах состояний."
                },
                "en": {
                    "title": "PepTune: Revolutionizing Peptide Design with Multi-Objective Optimization",
                    "desc": "This paper introduces PepTune, a novel multi-objective discrete diffusion model designed to generate and optimize therapeutic peptides. Traditional methods struggle with the complex requirements of peptide design, such as balancing binding affinity and solubility. PepTune utilizes a Masked Discrete Language Model framework and incorporates a Monte Carlo Tree Search strategy to effectively navigate the challenges of discrete optimization. The results show that PepTune can produce diverse peptides that meet multiple therapeutic criteria, showcasing its potential in drug development."
                },
                "zh": {
                    "title": "PepTune：多目标肽设计的新方法",
                    "desc": "本论文介绍了一种名为PepTune的多目标离散扩散模型，用于同时生成和优化治疗性肽的SMILES结构。该模型基于掩蔽离散语言模型（MDLM）框架，确保生成有效的肽结构，并通过状态依赖的掩蔽和惩罚目标来优化多个治疗特性。为了引导扩散过程，论文提出了一种基于蒙特卡洛树搜索（MCTS）的策略，平衡探索与利用，逐步优化Pareto最优序列。实验结果表明，PepTune能够生成多样化的化学修饰肽，优化目标结合亲和力、膜通透性、溶解度等多个特性，展示了其在离散状态空间中进行多目标序列设计的强大能力。"
                }
            }
        }
    ],
    "link_prev": "2024-12-26.html",
    "link_next": "2024-12-30.html",
    "link_month": "2024-12.html",
    "short_date_prev": {
        "ru": "26.12",
        "en": "12/26",
        "zh": "12月26日"
    },
    "short_date_next": {
        "ru": "30.12",
        "en": "12/30",
        "zh": "12月30日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 2,
        "#benchmark": 3,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 2,
        "#video": 2,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 4,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 1,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。",
        "title": "Token-Budget-Aware LLM Reasoning",
        "pinyin": "这篇文章讨论了大语言模型（LLMs）中推理的重要性。虽然Chain-of-Thought（CoT）推理方法通过将问题分解为中间步骤来提高LLM性能，但也增加了令牌使用的开销，导致成本增加。研究发现，当前LLMs的推理过程过于冗长，可以通过在提示中包含合理的令牌预算来压缩，但令牌预算的选择对实际压缩效果至关重要。作者提出了一个令牌预算感知的LLM推理框架，根据推理复杂性动态估算不同问题的令牌预算，并使用估算的令牌预算指导推理过程。实验表明，这种方法在CoT推理中有效地减少了令牌成本，仅略微降低了性能，提供了一种在LLM推理中平衡效率和准确性的实用解决方案。代码：https://github.com/GeniusHTX/TALE。\n\nzhè piān wén zhāng tǎo lùn le dà yǔ yán mó xíng (LLMs) zhōng tuī lǐ de zhòng yào xìng. suī rán Chain-of-Thought (CoT) tuī lǐ fāng fǎ tōng guò jiāng wèn tí fēn jiě wéi zhōng jiān bù zhòu lái tí gāo LLM xìng néng, dàn yě zēng jiā le lìng pái shǐ yòng de kāi xiǎo, dǎo zhì chéng běn zēng jiā. yán jiū fā xiàn, dāng qián LLMs de tuī lǐ guò chéng guò yú rǒng cháng, kě yǐ tōng guò zài tí shì zhōng bāo hán hé lǐ de lìng pái yù suàn lái yā suō, dàn lìng pái yù suàn de xuǎn zé duì shí jì yā suō xiào guǒ zhì guān zhòng yào. zuò zhě tí chū le yī gè lìng pái yù suàn gǎn zhī de LLM tuī lǐ kuàng jià, gēn jù tuī lǐ fú zà xìng dòng tài gū sǔan bù tóng wèn tí de lìng pái yù suàn, bìng shǐ yòng gū sǔan de lìng pái yù suàn zhǐ dǎo tuī lǐ guò chéng. shí yàn biǎo míng, zhè zhǒng fāng fǎ zài CoT tuī lǐ zhōng yǒu xiào de jiǎn shǎo le lìng pái chéng běn, jǐn lüè wēi jīng le xìng néng, tí gōng le yī zhǒng zài LLM tuī lǐ zhōng píng héng xiào yì hé zhǔn què xìng de shí yòng jiě jué fāng àn. dài mǎ: https://github.com/GeniusHTX/TALE.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'}, {'word': '重要性', 'pinyin': 'zhòng yào xìng', 'trans': 'importance'}, {'word': 'Chain-of-Thought', 'pinyin': 'Chain-of-Thought', 'trans': 'Chain-of-Thought'}, {'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'}, {'word': '令牌', 'pinyin': 'lìng pái', 'trans': 'token'}, {'word': '使用', 'pinyin': 'shǐ yòng', 'trans': 'use'}, {'word': '开销', 'pinyin': 'kāi xiāo', 'trans': 'cost'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'}, {'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'}, {'word': '增加', 'pinyin': 'zēng jiā', 'trans': 'increase'}, {'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'}, {'word': '发现', 'pinyin': 'fā xiàn', 'trans': 'discover'}, {'word': '当前', 'pinyin': 'dāng qián', 'trans': 'current'}, {'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'}, {'word': '冗长', 'pinyin': 'rǒng cháng', 'trans': 'tedious'}, {'word': '压缩', 'pinyin': 'yā suō', 'trans': 'compress'}, {'word': '提示', 'pinyin': 'tí shì', 'trans': 'prompt'}, {'word': '包含', 'pinyin': 'bāo hán', 'trans': 'include'}, {'word': '合理', 'pinyin': 'hé lǐ', 'trans': 'reasonable'}, {'word': '预算', 'pinyin': 'yù suàn', 'trans': 'budget'}, {'word': '至关重要', 'pinyin': 'zhì guān zhòng yào', 'trans': 'crucial'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'perceive'}, {'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'}, {'word': '根据', 'pinyin': 'gēn jù', 'trans': 'based on'}, {'word': '复杂性', 'pinyin': 'fù zá xìng', 'trans': 'complexity'}, {'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'}, {'word': '估算', 'pinyin': 'gū suàn', 'trans': 'estimate'}, {'word': '指导', 'pinyin': 'zhǐ dǎo', 'trans': 'guide'}, {'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'}, {'word': '表明', 'pinyin': 'biǎo míng', 'trans': 'indicate'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '有效', 'pinyin': 'yǒu xiào', 'trans': 'effective'}, {'word': '减少', 'pinyin': 'jiǎn shǎo', 'trans': 'reduce'}, {'word': '略微', 'pinyin': 'lüè wēi', 'trans': 'slightly'}, {'word': '降低', 'pinyin': 'jiàng dī', 'trans': 'lower'}, {'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'}, {'word': '提供', 'pinyin': 'tí gōng', 'trans': 'provide'}, {'word': '平衡', 'pinyin': 'píng héng', 'trans': 'balance'}, {'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'}, {'word': '准确性', 'pinyin': 'zhǔn què xìng', 'trans': 'accuracy'}, {'word': '解决方案', 'pinyin': 'jiě jué fāng àn', 'trans': 'solution'}, {'word': '实用', 'pinyin': 'shí yòng', 'trans': 'practical'}, {'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'}]",
        "trans": "This article discusses the importance of reasoning in large language models (LLMs). Although the Chain-of-Thought (CoT) reasoning method improves LLM performance by breaking down problems into intermediate steps, it also increases the overhead of token usage, leading to higher costs. Research has found that the current reasoning process in LLMs is overly lengthy and can be compressed by including a reasonable token budget in the prompts. However, the choice of token budget is crucial for the actual compression effect. The authors propose a token budget-aware LLM reasoning framework that dynamically estimates the token budget for different problems based on reasoning complexity and uses the estimated token budget to guide the reasoning process. Experiments show that this method effectively reduces token costs in CoT reasoning with only a slight decrease in performance, providing a practical solution for balancing efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.",
        "update_ts": "2024-12-26 09:10"
    }
}