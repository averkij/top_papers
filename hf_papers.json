{
    "date": {
        "ru": "30 декабря",
        "en": "December 30",
        "zh": "12月30日"
    },
    "time_utc": "2024-12-30 04:12",
    "weekday": 0,
    "issue_id": 1382,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.18925",
            "title": "HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs",
            "url": "https://huggingface.co/papers/2412.18925",
            "abstract": "The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning to improve LLM. Yet, most research in reasoning has focused on mathematical tasks, leaving domains like medicine underexplored. The medical domain, though distinct from mathematics, also demands robust reasoning to provide reliable answers, given the high standards of healthcare. However, verifying medical reasoning is challenging, unlike those in mathematics. To address this, we propose verifiable medical problems with a medical verifier to check the correctness of model outputs. This verifiable nature enables advancements in medical reasoning through a two-stage approach: (1) using the verifier to guide the search for a complex reasoning trajectory for fine-tuning LLMs, (2) applying reinforcement learning (RL) with verifier-based rewards to enhance complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM capable of complex reasoning, which outperforms general and medical-specific baselines using only 40K verifiable problems. Experiments show complex reasoning improves medical problem-solving and benefits more from RL. We hope our approach inspires advancements in reasoning across medical and other specialized domains.",
            "score": 3,
            "issue_id": 1382,
            "pub_date": "2024-12-25",
            "pub_date_card": {
                "ru": "25 декабря",
                "en": "December 25",
                "zh": "12月25日"
            },
            "hash": "218dd2a8c2ae478f",
            "authors": [
                "Junying Chen",
                "Zhenyang Cai",
                "Ke Ji",
                "Xidong Wang",
                "Wanlong Liu",
                "Rongsheng Wang",
                "Jianye Hou",
                "Benyou Wang"
            ],
            "affiliations": [
                "Shenzhen Research Institute of Big Data",
                "The Chinese University of Hong Kong, Shenzhen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18925.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#healthcare",
                    "#training",
                    "#rl"
                ],
                "emoji": "🩺",
                "ru": {
                    "title": "Улучшение медицинских ИИ-моделей через верифицируемые рассуждения",
                    "desc": "Статья представляет новый подход к улучшению способностей языковых моделей в медицинской сфере. Авторы предлагают использовать верифицируемые медицинские задачи и специальный верификатор для проверки корректности ответов модели. На основе этого подхода разработана двухэтапная методика: сначала используется верификатор для поиска сложной траектории рассуждений при файнтюнинге языковых моделей, затем применяется обучение с подкреплением для дальнейшего улучшения сложных рассуждений. В результате создана модель HuatuoGPT-01, превосходящая базовые модели в решении медицинских задач."
                },
                "en": {
                    "title": "Enhancing Medical Reasoning with HuatuoGPT-o1",
                    "desc": "This paper discusses the development of HuatuoGPT-o1, a medical language model (LLM) that enhances reasoning capabilities specifically for medical tasks. Unlike traditional approaches that focus on mathematical reasoning, this research emphasizes the need for robust reasoning in healthcare, where accuracy is critical. The authors propose a two-stage method that includes a medical verifier to ensure the correctness of model outputs and reinforcement learning (RL) to further improve reasoning skills. The results demonstrate that HuatuoGPT-o1 significantly outperforms existing models by effectively solving complex medical problems using a limited dataset of verifiable problems."
                },
                "zh": {
                    "title": "医学推理的新突破：HuatuoGPT-o1",
                    "desc": "这篇论文介绍了OpenAI的o1在增强推理能力方面的突破，特别是在医学领域的应用。尽管大多数推理研究集中在数学任务上，但医学同样需要强大的推理能力以提供可靠的答案。为了验证医学推理的正确性，作者提出了一种可验证的医学问题和医学验证器，帮助检查模型输出的准确性。最终，论文介绍了HuatuoGPT-o1，这是一种能够进行复杂推理的医学大语言模型，实验表明其在解决医学问题时表现优于其他基线模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.18605",
            "title": "Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models",
            "url": "https://huggingface.co/papers/2412.18605",
            "abstract": "Orientation is a key attribute of objects, crucial for understanding their spatial pose and arrangement in images. However, practical solutions for accurate orientation estimation from a single image remain underexplored. In this work, we introduce Orient Anything, the first expert and foundational model designed to estimate object orientation in a single- and free-view image. Due to the scarcity of labeled data, we propose extracting knowledge from the 3D world. By developing a pipeline to annotate the front face of 3D objects and render images from random views, we collect 2M images with precise orientation annotations. To fully leverage the dataset, we design a robust training objective that models the 3D orientation as probability distributions of three angles and predicts the object orientation by fitting these distributions. Besides, we employ several strategies to improve synthetic-to-real transfer. Our model achieves state-of-the-art orientation estimation accuracy in both rendered and real images and exhibits impressive zero-shot ability in various scenarios. More importantly, our model enhances many applications, such as comprehension and generation of complex spatial concepts and 3D object pose adjustment.",
            "score": 2,
            "issue_id": 1381,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 декабря",
                "en": "December 24",
                "zh": "12月24日"
            },
            "hash": "6bc56feed4022217",
            "authors": [
                "Zehan Wang",
                "Ziang Zhang",
                "Tianyu Pang",
                "Chao Du",
                "Hengshuang Zhao",
                "Zhou Zhao"
            ],
            "affiliations": [
                "Sea AI Lab",
                "The University of Hong Kong",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18605.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#cv",
                    "#training",
                    "#dataset",
                    "#3d",
                    "#transfer_learning"
                ],
                "emoji": "🧭",
                "ru": {
                    "title": "Orient Anything: точное определение ориентации объектов по одному изображению",
                    "desc": "Статья представляет новую модель Orient Anything для оценки ориентации объектов на изображениях. Авторы создали датасет из 2 миллионов синтетических изображений с точными аннотациями ориентации. Модель использует вероятностный подход, моделируя ориентацию как распределения трех углов. Orient Anything достигает наилучших результатов в оценке ориентации на синтетических и реальных изображениях, демонстрируя способность к обобщению."
                },
                "en": {
                    "title": "Revolutionizing Object Orientation Estimation from Images",
                    "desc": "This paper presents 'Orient Anything', a novel model for estimating the orientation of objects from single images. It addresses the challenge of limited labeled data by utilizing 3D object knowledge to create a large dataset of 2 million images with accurate orientation labels. The model employs a training objective that treats object orientation as probability distributions of angles, allowing it to predict orientations effectively. Additionally, it demonstrates strong performance in both synthetic and real-world scenarios, enhancing applications related to spatial understanding and 3D object manipulation."
                },
                "zh": {
                    "title": "单图像方向估计的新突破",
                    "desc": "本文介绍了一种名为Orient Anything的模型，旨在从单张图像中准确估计物体的方向。由于标注数据稀缺，我们通过从3D世界提取知识，收集了200万张带有精确方向标注的图像。该模型通过将3D方向建模为三个角度的概率分布，来预测物体的方向，并采用多种策略提高合成图像到真实图像的迁移效果。最终，我们的模型在渲染和真实图像中都达到了最先进的方向估计精度，并在多种场景中展现了出色的零样本能力。"
                }
            }
        }
    ],
    "link_prev": "2024-12-27.html",
    "link_next": "2024-12-31.html",
    "link_month": "2024-12.html",
    "short_date_prev": {
        "ru": "27.12",
        "en": "12/27",
        "zh": "12月27日"
    },
    "short_date_next": {
        "ru": "31.12",
        "en": "12/31",
        "zh": "12月31日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一个高效的大语言模型YuLan-Mini。该模型有2.42B参数，性能卓越。研究团队通过数据清洗、优化方法和退火技术提高了训练效果。YuLan-Mini在1.08T tokens上训练，性能媲美需要更多数据的行业领先模型。详细信息可以在GitHub上找到。",
        "title": "YuLan-Mini: An Open Data-efficient Language Model",
        "pinyin": "这篇文章介绍了一个高效的大语言模型YuLan-Mini。该模型有2.42B参数，性能卓越。研究团队通过数据清洗、优化方法和退火技术提高了训练效果。YuLan-Mini在1.08T tokens上训练，性能媲美需要更多数据的行业领先模型。详细信息可以在GitHub上找到。\n\nzhè piān wén zhāng jiè shào le yī gè gāo xiào de dà yǔ yán mó xíng YuLan-Mini. gǎi mó xíng yǒu 2.42B cān shǔ, xìng néng zhuó yuè. yán jiū tuán duī tōng guò shù jù qīng xǐ, yōu huà fāng fǎ hé tuì huǒ jì shù tí gāo le xùn liàn xiào guǒ. YuLan-Mini zài 1.08T tokens shàng xùn liàn, xìng néng jì mǐ xū yào gèng duō shù jù de háng yè lǐng xiān mó xíng. xiáng xì xìn xī kě yǐ zài GitHub shàng zhǎo dào.",
        "vocab": "[\n    {\"word\": \"卓越\", \"pinyin\": \"zhuó yuè\", \"trans\": \"outstanding\"},\n    {\"word\": \"清洗\", \"pinyin\": \"qīng xǐ\", \"trans\": \"cleaning\"},\n    {\"word\": \"优化\", \"pinyin\": \"yōu huà\", \"trans\": \"optimization\"},\n    {\"word\": \"退火\", \"pinyin\": \"tuì huǒ\", \"trans\": \"annealing\"},\n    {\"word\": \"媲美\", \"pinyin\": \"pì měi\", \"trans\": \"rival\"},\n    {\"word\": \"领先\", \"pinyin\": \"lǐng xiān\", \"trans\": \"leading\"}\n]",
        "trans": "This article introduces an efficient large language model called YuLan-Mini. The model has 2.42 billion parameters and delivers outstanding performance. The research team enhanced the training effectiveness through data cleaning, optimization methods, and annealing techniques. YuLan-Mini was trained on 1.08 trillion tokens and performs comparably to industry-leading models that require more data. Detailed information can be found on GitHub.",
        "update_ts": "2024-12-29 12:38"
    }
}