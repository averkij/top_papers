{
    "date": {
        "ru": "20 Ğ¼Ğ°Ñ",
        "en": "May 20",
        "zh": "5æœˆ20æ—¥"
    },
    "time_utc": "2025-05-20 04:15",
    "weekday": 1,
    "issue_id": 3847,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.11896",
            "title": "AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.11896",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.",
            "score": 27,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 Ğ¼Ğ°Ñ",
                "en": "May 17",
                "zh": "5æœˆ17æ—¥"
            },
            "hash": "bdc79864df7cbd51",
            "authors": [
                "Chenwei Lou",
                "Zewei Sun",
                "Xinnian Liang",
                "Meng Qu",
                "Wei Shen",
                "Wenqi Wang",
                "Yuntao Li",
                "Qingping Yang",
                "Shuangzhi Wu"
            ],
            "affiliations": [
                "ByteDance Seed"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11896.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "AdaCoT: Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "AdaCoT - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğ¹ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ (LLM) Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (Chain-of-Thought, CoT). Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ² Ñ‡Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Proximal Policy Optimization (PPO), AdaCoT Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ğ°Ğ¼Ğ¸, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼ CoT. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²ĞºĞ»Ğ°Ğ´Ğ¾Ğ¼ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Selective Loss Masking (SLM), Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ÑÑ‰Ğ¸Ğ¹ ĞºĞ¾Ğ»Ğ»Ğ°Ğ¿Ñ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ AdaCoT Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CoT Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…."
                },
                "en": {
                    "title": "Adaptive Reasoning for Efficient Language Models",
                    "desc": "This paper presents AdaCoT, a new framework that improves the efficiency of Large Language Models (LLMs) by adaptively deciding when to use Chain-of-Thought (CoT) prompting. Traditional CoT prompting can be computationally expensive, especially for simpler queries, but AdaCoT optimizes this by framing the decision to use CoT as a Pareto optimization problem. The authors employ reinforcement learning, specifically Proximal Policy Optimization (PPO), to dynamically adjust when CoT is triggered based on the complexity of the input. Their approach includes a technique called Selective Loss Masking (SLM) to ensure stable training, resulting in significant reductions in CoT usage while maintaining high performance on complex tasks."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”é“¾å¼æ¨ç†ï¼Œæå‡æ•ˆç‡ä¸æ€§èƒ½",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†AdaCoTï¼ˆè‡ªé€‚åº”é“¾å¼æ¨ç†ï¼‰ï¼Œå®ƒå…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥çš„å¤æ‚æ€§è‡ªé€‚åº”åœ°å†³å®šæ˜¯å¦ä½¿ç”¨é“¾å¼æ¨ç†ã€‚æˆ‘ä»¬å°†è‡ªé€‚åº”æ¨ç†è§†ä¸ºä¸€ä¸ªå¸•ç´¯æ‰˜ä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨å¹³è¡¡æ¨¡å‹æ€§èƒ½ä¸é“¾å¼æ¨ç†çš„è®¡ç®—æˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaCoTåœ¨ä¸éœ€è¦å¤æ‚æ¨ç†çš„æŸ¥è¯¢ä¸­æ˜¾è‘—å‡å°‘äº†é“¾å¼æ¨ç†çš„ä½¿ç”¨ï¼Œæå‡äº†æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11254",
            "title": "Delta Attention: Fast and Accurate Sparse Attention Inference by Delta\n  Correction",
            "url": "https://huggingface.co/papers/2505.11254",
            "abstract": "The attention mechanism of a transformer has a quadratic complexity, leading to high inference costs and latency for long sequences. However, attention matrices are mostly sparse, which implies that many entries may be omitted from computation for efficient inference. Sparse attention inference methods aim to reduce this computational burden; however, they also come with a troublesome performance degradation. We discover that one reason for this degradation is that the sparse calculation induces a distributional shift in the attention outputs. The distributional shift causes decoding-time queries to fail to align well with the appropriate keys from the prefill stage, leading to a drop in performance. We propose a simple, novel, and effective procedure for correcting this distributional shift, bringing the distribution of sparse attention outputs closer to that of quadratic attention. Our method can be applied on top of any sparse attention method, and results in an average 36%pt performance increase, recovering 88% of quadratic attention accuracy on the 131K RULER benchmark when applied on top of sliding window attention with sink tokens while only adding a small overhead. Our method can maintain approximately 98.5% sparsity over full quadratic attention, making our model 32 times faster than Flash Attention 2 when processing 1M token prefills.",
            "score": 14,
            "issue_id": 3847,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 Ğ¼Ğ°Ñ",
                "en": "May 16",
                "zh": "5æœˆ16æ—¥"
            },
            "hash": "2aba31b686859e82",
            "authors": [
                "Jeffrey Willette",
                "Heejun Lee",
                "Sung Ju Hwang"
            ],
            "affiliations": [
                "DeepAuto.ai",
                "KAIST"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11254.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#long_context",
                    "#architecture",
                    "#inference",
                    "#benchmark"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "ĞšĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ² Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞ´Ğ²Ğ¸Ğ³ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ² Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ° Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ğ¾Ñ‚ ÑĞ´Ğ²Ğ¸Ğ³, Ğ¿Ñ€Ğ¸Ğ±Ğ»Ğ¸Ğ¶Ğ°Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğº ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¼Ñƒ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒÑÑ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ… Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸."
                },
                "en": {
                    "title": "Boosting Sparse Attention: Aligning Outputs for Enhanced Performance",
                    "desc": "This paper addresses the inefficiencies of the attention mechanism in transformers, which typically has a quadratic complexity that increases inference costs for long sequences. It highlights that while sparse attention methods can reduce computation, they often lead to performance degradation due to a distributional shift in attention outputs. The authors propose a novel procedure to correct this shift, aligning sparse attention outputs more closely with those of traditional quadratic attention. Their method significantly improves performance, achieving an average increase of 36 percentage points while maintaining high sparsity and speed, making it much faster than existing methods."
                },
                "zh": {
                    "title": "ç¨€ç–æ³¨æ„åŠ›çš„åˆ†å¸ƒä¿®æ­£ï¼Œæå‡æ€§èƒ½ä¸æ•ˆç‡",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†å˜æ¢å™¨çš„æ³¨æ„åŠ›æœºåˆ¶åœ¨å¤„ç†é•¿åºåˆ—æ—¶çš„è®¡ç®—å¤æ‚åº¦é—®é¢˜ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬é«˜å’Œå»¶è¿Ÿå¤§ã€‚å°½ç®¡æ³¨æ„åŠ›çŸ©é˜µé€šå¸¸æ˜¯ç¨€ç–çš„ï¼Œä½†ç¨€ç–æ³¨æ„åŠ›æ¨ç†æ–¹æ³•åœ¨å‡å°‘è®¡ç®—è´Ÿæ‹…çš„åŒæ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ€§èƒ½ä¸‹é™çš„ä¸€ä¸ªåŸå› æ˜¯ç¨€ç–è®¡ç®—å¼•èµ·äº†æ³¨æ„åŠ›è¾“å‡ºçš„åˆ†å¸ƒåç§»ï¼Œè¿™ä½¿å¾—è§£ç æ—¶çš„æŸ¥è¯¢ä¸é¢„å¡«é˜¶æ®µçš„é”®å¯¹é½ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ä¿®æ­£æ–¹æ³•ï¼Œä½¿ç¨€ç–æ³¨æ„åŠ›è¾“å‡ºçš„åˆ†å¸ƒæ›´æ¥è¿‘äºäºŒæ¬¡æ³¨æ„åŠ›ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13417",
            "title": "AdaptThink: Reasoning Models Can Learn When to Think",
            "url": "https://huggingface.co/papers/2505.13417",
            "abstract": "Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.",
            "score": 12,
            "issue_id": 3845,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "edd33223d8d833a7",
            "authors": [
                "Jiajie Zhang",
                "Nianyi Lin",
                "Lei Hou",
                "Ling Feng",
                "Juanzi Li"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13417.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#inference",
                    "#training",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ˜",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ AdaptThink, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒÑ‡Ğ¸Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½ÑƒÑ Ñ†ĞµĞ»ĞµĞ²ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ¿Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ AdaptThink Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ° Ñ‚Ñ€ĞµÑ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ğ» ÑÑ€ĞµĞ´Ğ½ÑÑ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ DeepSeek-R1-Distill-Qwen-1.5B Ğ½Ğ° 53% Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ğ» ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° 2.4%."
                },
                "en": {
                    "title": "Optimize Reasoning with Adaptive Thinking Modes!",
                    "desc": "This paper introduces AdaptThink, a reinforcement learning algorithm designed to optimize reasoning models by allowing them to choose between two thinking modes: NoThinking and traditional thinking. NoThinking enables models to skip lengthy reasoning processes for simpler tasks, improving efficiency without sacrificing performance. AdaptThink employs a constrained optimization objective to encourage the use of NoThinking while maintaining overall accuracy, and it uses importance sampling to balance training between both modes. The results show that AdaptThink significantly reduces inference costs and enhances performance on math tasks, demonstrating the effectiveness of adaptive thinking-mode selection."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”æ€è€ƒæ¨¡å¼é€‰æ‹©ï¼Œæå‡æ¨ç†æ•ˆç‡ä¸è´¨é‡",
                    "desc": "æœ€è¿‘ï¼Œå¤§å‹æ¨ç†æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å†—é•¿çš„æ€è€ƒè¿‡ç¨‹æ˜¾è‘—å¢åŠ äº†æ¨ç†å¼€é”€ï¼Œå¯¼è‡´æ•ˆç‡æˆä¸ºç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºNoThinkingçš„æ–¹æ³•ï¼Œé¼“åŠ±æ¨ç†æ¨¡å‹è·³è¿‡æ€è€ƒï¼Œç›´æ¥ç”Ÿæˆæœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºç›¸å¯¹ç®€å•çš„ä»»åŠ¡ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†AdaptThinkï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨æ ¹æ®é—®é¢˜éš¾åº¦è‡ªé€‚åº”é€‰æ‹©æœ€ä½³æ€è€ƒæ¨¡å¼ã€‚å®éªŒè¡¨æ˜ï¼ŒAdaptThinkæ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13379",
            "title": "Thinkless: LLM Learns When to Think",
            "url": "https://huggingface.co/papers/2505.13379",
            "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless",
            "score": 12,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "d41117eabc11e5c3",
            "authors": [
                "Gongfan Fang",
                "Xinyin Ma",
                "Xinchao Wang"
            ],
            "affiliations": [
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13379.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼ Ğ¸ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Thinkless - Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰ÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼ Ğ¸ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ´Ğ²Ğ° ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ°: <short> Ğ´Ğ»Ñ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¸ <think> Ğ´Ğ»Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ’ Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ»ĞµĞ¶Ğ¸Ñ‚ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ DeGRPO, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ Ñ†ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Thinkless ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° 50-90%, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Thinkless: Smart Reasoning for Efficient Language Models",
                    "desc": "This paper introduces Thinkless, a framework designed to enhance the efficiency of Reasoning Language Models (RLMs) by enabling them to choose between short-form and long-form reasoning based on task complexity. The framework utilizes reinforcement learning and two control tokens, <short> for brief answers and <think> for detailed reasoning, to guide the model's response strategy. A novel algorithm called Decoupled Group Relative Policy Optimization (DeGRPO) is employed to separate the learning objectives, allowing for better control over reasoning mode selection and response accuracy. The results show that Thinkless can significantly reduce the reliance on long-chain reasoning, improving computational efficiency while maintaining performance on various benchmarks."
                },
                "zh": {
                    "title": "è®©æ¨¡å‹å­¦ä¼šä½•æ—¶æ€è€ƒ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºThinklessçš„å¯å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„æ•ˆç‡ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§å’Œè‡ªèº«èƒ½åŠ›è‡ªé€‚åº”é€‰æ‹©çŸ­æœŸæˆ–é•¿æœŸæ¨ç†ã€‚Thinklessä½¿ç”¨ä¸¤ä¸ªæ§åˆ¶æ ‡è®°<short>å’Œ<think>æ¥åˆ†åˆ«è¡¨ç¤ºç®€æ´å›ç­”å’Œè¯¦ç»†æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒThinklessèƒ½å¤Ÿå°†é•¿æœŸæ¨ç†çš„ä½¿ç”¨å‡å°‘50%è‡³90%ï¼Œæ˜¾è‘—æå‡æ¨ç†è¯­è¨€æ¨¡å‹çš„æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13427",
            "title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable\n  Step-Level Supervision",
            "url": "https://huggingface.co/papers/2505.13427",
            "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.",
            "score": 11,
            "issue_id": 3847,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "22362149c9b7b5ae",
            "authors": [
                "Lingxiao Du",
                "Fanqing Meng",
                "Zongkai Liu",
                "Zhixiang Zhou",
                "Ping Luo",
                "Qiaosheng Zhang",
                "Wenqi Shao"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "Shanghai Jiao Tong University",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13427.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#multimodal",
                    "#math",
                    "#training",
                    "#open_source",
                    "#benchmark",
                    "#data",
                    "#dataset"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ MM-PRM, Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ°ÑÑÑ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ ÑˆĞ°Ğ³Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ MM-K12 Ñ 10 000 Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ 700 Ñ‚Ñ‹ÑÑÑ‡ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ ÑˆĞ°Ğ³Ğ¾Ğ² Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ MM-PRM Ğ² ÑÑ…ĞµĞ¼Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Best-of-N Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ğ»Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ĞºĞ°Ğº Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ MM-K12, Ñ‚Ğ°Ğº Ğ¸ Ğ½Ğ° Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ÑĞ³ĞºĞ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğº, Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ… ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ Ğ¿ÑƒÑ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Enhancing Multimodal Reasoning with Process Supervision",
                    "desc": "This paper introduces MM-PRM, a novel process reward model designed to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs) in solving complex math problems. The authors highlight that MLLMs often struggle with multi-step reasoning due to insufficient supervision of intermediate steps. To overcome this, they create a strong multimodal model called MM-Policy and a new dataset, MM-K12, containing 10,000 multimodal math problems. By employing a Monte Carlo Tree Search method, they generate over 700,000 annotations to train the PRM, which significantly enhances the logical consistency of reasoning in various benchmarks."
                },
                "zh": {
                    "title": "è¿‡ç¨‹ç›‘ç£æå‡å¤šæ¨¡æ€æ¨ç†çš„é€»è¾‘ç¨³å¥æ€§",
                    "desc": "è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆMM-PRMï¼‰ï¼Œæ—¨åœ¨æé«˜å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å¤šæ­¥éª¤æ¨ç†ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç¼ºä¹ç»†ç²’åº¦çš„ç›‘ç£ï¼Œå¯¼è‡´é€»è¾‘ä¸ä¸€è‡´æˆ–éƒ¨åˆ†æ­£ç¡®çš„ç»“æœã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹MM-Policyï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«10,000ä¸ªå¯éªŒè¯ç­”æ¡ˆçš„å¤šæ¨¡æ€æ•°å­¦é—®é¢˜æ•°æ®é›†MM-K12ã€‚é€šè¿‡æ— äººå·¥æ ‡æ³¨çš„æ–¹å¼ç”Ÿæˆè¶…è¿‡70ä¸‡æ¡æ­¥éª¤çº§æ³¨é‡Šï¼ŒMM-PRMåœ¨æ¨ç†è·¯å¾„è¯„åˆ†ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ï¼Œè¯æ˜äº†è¿‡ç¨‹ç›‘ç£åœ¨å¢å¼ºå¤šæ¨¡æ€æ¨ç†ç³»ç»Ÿé€»è¾‘ç¨³å¥æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13215",
            "title": "Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation",
            "url": "https://huggingface.co/papers/2505.13215",
            "abstract": "Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.",
            "score": 11,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "0ab00a261298ad44",
            "authors": [
                "Seungjun Oh",
                "Younggeun Lee",
                "Hyejin Jeon",
                "Eunbyung Park"
            ],
            "affiliations": [
                "Department of Artificial Intelligence, Sungkyunkwan University",
                "Department of Artificial Intelligence, Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13215.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ 3D-4D Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑÑ†ĞµĞ½",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ 3D-4DGS Ğ´Ğ»Ñ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… 3D-ÑÑ†ĞµĞ½. ĞĞ½ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ 3D Ğ³Ğ°ÑƒÑÑĞ¸Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ĞµĞ¹ Ğ¸ 4D Ğ³Ğ°ÑƒÑÑĞ¸Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ 4D Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼. ĞœĞµÑ‚Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°."
                },
                "en": {
                    "title": "Efficient 3D-4D Scene Reconstruction with Hybrid Gaussian Splatting",
                    "desc": "This paper presents a new method called hybrid 3D-4D Gaussian Splatting (3D-4DGS) for dynamic 3D scene reconstruction. It combines 3D and 4D Gaussian representations to efficiently model static and dynamic elements in a scene. By converting static regions to 3D Gaussians, the method reduces computational load and memory usage while preserving the quality of dynamic elements with 4D Gaussians. The results show that 3D-4DGS achieves faster training times and improved visual quality compared to traditional 4D Gaussian Splatting techniques."
                },
                "zh": {
                    "title": "é«˜æ•ˆçš„åŠ¨æ€3Dåœºæ™¯é‡å»ºæ–°æ–¹æ³•",
                    "desc": "æœ€è¿‘åŠ¨æ€3Dåœºæ™¯é‡å»ºçš„è¿›å±•æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ•ˆæœï¼Œèƒ½å¤Ÿå®ç°é«˜ä¿çœŸåº¦çš„3Dæ–°è§†å›¾åˆæˆï¼Œå¹¶æé«˜æ—¶é—´ä¸€è‡´æ€§ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­ï¼Œ4Dé«˜æ–¯ç‚¹äº‘ï¼ˆ4DGSï¼‰å› å…¶èƒ½å¤Ÿå»ºæ¨¡é«˜ä¿çœŸçš„ç©ºé—´å’Œæ—¶é—´å˜åŒ–è€Œå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨é™æ€åŒºåŸŸå†—ä½™åˆ†é…4Dé«˜æ–¯æ—¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼Œå¹¶å¯èƒ½é™ä½å›¾åƒè´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆ3D-4Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3D-4DGSï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°ç”¨3Dé«˜æ–¯è¡¨ç¤ºé™æ€åŒºåŸŸï¼ŒåŒæ—¶ä¸ºåŠ¨æ€å…ƒç´ ä¿ç•™4Dé«˜æ–¯ï¼Œä»è€Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12081",
            "title": "VisionReasoner: Unified Visual Perception and Reasoning via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.12081",
            "abstract": "Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).",
            "score": 11,
            "issue_id": 3845,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 Ğ¼Ğ°Ñ",
                "en": "May 17",
                "zh": "5æœˆ17æ—¥"
            },
            "hash": "9b7953f88ae7653d",
            "authors": [
                "Yuqi Liu",
                "Tianyuan Qu",
                "Zhisheng Zhong",
                "Bohao Peng",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "affiliations": [
                "CUHK",
                "HKUST",
                "SmartMore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12081.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ VisionReasoner - ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸ Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. VisionReasoner Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ²Ñ‹Ğ´Ğ°Ñ‡ĞµĞ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ VisionReasoner Ğ½Ğ°Ğ´ Qwen2.5VL Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ, ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‡ĞµÑ‚Ğ° Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "VisionReasoner: Unifying Visual Perception with Advanced Reasoning",
                    "desc": "This paper presents VisionReasoner, a unified framework designed to enhance visual perception tasks through advanced reasoning capabilities. It employs innovative multi-object cognitive learning strategies and reformulates tasks systematically to improve its performance across various visual challenges. The model processes visual inputs in a structured manner, allowing it to effectively respond to user queries. Evaluation results demonstrate that VisionReasoner significantly outperforms existing models in detection, segmentation, and counting tasks, showcasing its effectiveness as a comprehensive solution for visual perception."
                },
                "zh": {
                    "title": "ç»Ÿä¸€è§†è§‰æ„ŸçŸ¥çš„æ¨ç†èƒ½åŠ›",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºVisionReasonerçš„ç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨å…±äº«æ¨¡å‹ä¸­å¤„ç†å¤šç§è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ã€‚é€šè¿‡è®¾è®¡æ–°é¢–çš„å¤šå¯¹è±¡è®¤çŸ¥å­¦ä¹ ç­–ç•¥å’Œç³»ç»Ÿçš„ä»»åŠ¡é‡æ„ï¼ŒVisionReasonerå¢å¼ºäº†å…¶æ¨ç†èƒ½åŠ›ï¼Œä»¥åˆ†æè§†è§‰è¾“å…¥å¹¶è§£å†³å¤šæ ·çš„æ„ŸçŸ¥ä»»åŠ¡ã€‚è¯¥æ¨¡å‹åœ¨ç”Ÿæˆæ‰€éœ€è¾“å‡ºä¹‹å‰ï¼Œä¼šå…ˆè¿›è¡Œç»“æ„åŒ–çš„æ¨ç†è¿‡ç¨‹ï¼Œä»¥å“åº”ç”¨æˆ·æŸ¥è¯¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVisionReasoneråœ¨æ£€æµ‹ã€åˆ†å‰²å’Œè®¡æ•°ç­‰ä¸‰ä¸ªå…³é”®é¢†åŸŸçš„åä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†Qwen2.5VLã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12504",
            "title": "CPGD: Toward Stable Rule-based Reinforcement Learning for Language\n  Models",
            "url": "https://huggingface.co/papers/2505.12504",
            "abstract": "Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates and improper clipping can lead to training collapse. To address this issue, we propose Clipped Policy Gradient Optimization with Policy Drift (CPGD), a novel algorithm designed to stabilize policy learning in LMs. CPGD introduces a policy drift constraint based on KL divergence to dynamically regularize policy updates, and leverages a clip mechanism on the logarithm of the ratio to prevent excessive policy updates. We provide theoretical justification for CPGD and demonstrate through empirical analysis that it mitigates the instability observed in prior approaches. Furthermore, we show that CPGD significantly improves performance while maintaining training stability. Our implementation balances theoretical rigor with practical usability, offering a robust alternative for RL in the post-training of LMs. We release our code at https://github.com/ModalMinds/MM-EUREKA.",
            "score": 9,
            "issue_id": 3847,
            "pub_date": "2025-05-18",
            "pub_date_card": {
                "ru": "18 Ğ¼Ğ°Ñ",
                "en": "May 18",
                "zh": "5æœˆ18æ—¥"
            },
            "hash": "f8b07da7e5e43f1e",
            "authors": [
                "Zongkai Liu",
                "Fanqing Meng",
                "Lingxiao Du",
                "Zhixiang Zhou",
                "Chao Yu",
                "Wenqi Shao",
                "Qiaosheng Zhang"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "Shanghai Jiao Tong University",
                "Sun Yat-Sen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12504.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ CPGD Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. CPGD Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ´Ñ€ĞµĞ¹Ñ„ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ KL-Ğ´Ğ¸Ğ²ĞµÑ€Ğ³ĞµĞ½Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ¾Ñ‚ÑĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹Ğ²Ğ°ÑÑ‚ CPGD Ğ¸ ÑĞ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ½ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ, Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼ÑƒÑ Ğ² Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°Ñ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Stabilizing Reinforcement Learning with CPGD",
                    "desc": "This paper introduces Clipped Policy Gradient Optimization with Policy Drift (CPGD), a new algorithm aimed at improving the stability of reinforcement learning in language models. Traditional methods often face issues like training collapse due to large policy updates and improper clipping. CPGD addresses these challenges by using a KL divergence-based policy drift constraint to regulate updates and a clipping mechanism to limit excessive changes. The authors provide theoretical support for CPGD and demonstrate its effectiveness in enhancing performance while ensuring stable training."
                },
                "zh": {
                    "title": "ç¨³å®šå¼ºåŒ–å­¦ä¹ ï¼Œæå‡è¯­è¨€æ¨¡å‹æ€§èƒ½",
                    "desc": "æœ€è¿‘ï¼ŒåŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰çš„æ¨ç†èƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰çš„RLæ–¹æ³•å¦‚GRPOã€REINFORCE++å’ŒRLOOå¸¸å¸¸é¢ä¸´è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°ç®—æ³•â€”â€”å¸¦æœ‰ç­–ç•¥æ¼‚ç§»çš„å‰ªåˆ‡ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–ï¼ˆCPGDï¼‰ï¼Œæ—¨åœ¨ç¨³å®šè¯­è¨€æ¨¡å‹ä¸­çš„ç­–ç•¥å­¦ä¹ ã€‚CPGDé€šè¿‡åŸºäºKLæ•£åº¦çš„ç­–ç•¥æ¼‚ç§»çº¦æŸåŠ¨æ€åœ°è§„èŒƒç­–ç•¥æ›´æ–°ï¼Œå¹¶åˆ©ç”¨å¯¹æ•°æ¯”ç‡çš„å‰ªåˆ‡æœºåˆ¶é˜²æ­¢è¿‡å¤§çš„ç­–ç•¥æ›´æ–°ã€‚æˆ‘ä»¬çš„ç†è®ºåˆ†æå’Œå®è¯ç»“æœè¡¨æ˜ï¼ŒCPGDä¸ä»…ç¼“è§£äº†ä¹‹å‰æ–¹æ³•çš„è®­ç»ƒä¸ç¨³å®šæ€§ï¼Œè¿˜æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12849",
            "title": "Accelerate TarFlow Sampling with GS-Jacobi Iteration",
            "url": "https://huggingface.co/papers/2505.12849",
            "abstract": "Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computation, TarFlow's sampling process is extremely slow. In this paper, we demonstrate that through a series of optimization strategies, TarFlow sampling can be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as GS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow model have varying importance: a small number of blocks play a major role in image generation tasks, while other blocks contribute relatively little; some blocks are sensitive to initial values and prone to numerical overflow, while others are relatively robust. Based on these two characteristics, we propose the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM is used to identify whether a TarFlow block is \"simple\" (converges in few iterations) or \"tough\" (requires more iterations); IGM is used to evaluate whether the initial value of the iteration is good. Experiments on four TarFlow models demonstrate that GS-Jacobi sampling can significantly enhance sampling efficiency while maintaining the quality of generated images (measured by FID), achieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in Img64uncond, and 2.51x in Img64cond without degrading FID scores or sample quality. Code and checkpoints are accessible on https://github.com/encoreus/GS-Jacobi_for_TarFlow",
            "score": 5,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "191f5a409cc6b32e",
            "authors": [
                "Ben Liu",
                "Zhen Qin"
            ],
            "affiliations": [
                "TapTap, Shanghai, China",
                "Zhejiang University, Hangzhou, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12849.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#architecture",
                    "#open_source",
                    "#cv",
                    "#training"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² TarFlow Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ TarFlow Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ“Ğ°ÑƒÑÑĞ°-Ğ—ĞµĞ¹Ğ´ĞµĞ»Ñ-Ğ¯ĞºĞ¾Ğ±Ğ¸ Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ´Ğ²Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸: Convergence Ranking Metric (CRM) Ğ¸ Initial Guessing Metric (IGM). CRM Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² TarFlow, Ğ° IGM Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ´Ğ¾ 5.32 Ñ€Ğ°Ğ·) Ğ±ĞµĞ· ÑƒÑ…ÑƒĞ´ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Accelerating TarFlow: Faster Sampling without Quality Loss",
                    "desc": "This paper presents an optimization strategy for the TarFlow model, which combines transformer architecture with Normalizing Flow for image generation. The authors introduce the Gauss-Seidel-Jacobi (GS-Jacobi) iteration method to accelerate the slow sampling process of TarFlow. They identify that certain blocks within the model are more critical for image generation and propose metrics to evaluate their performance: the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM). Experimental results show that the GS-Jacobi method significantly improves sampling speed while preserving image quality, achieving notable speed-ups across various benchmarks."
                },
                "zh": {
                    "title": "åŠ é€ŸTarFlowé‡‡æ ·ï¼Œæå‡å›¾åƒç”Ÿæˆæ•ˆç‡",
                    "desc": "å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨å¤šä¸ªåº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚TarFlowæ¨¡å‹ç»“åˆäº†å˜æ¢å™¨æ¶æ„å’Œå½’ä¸€åŒ–æµæ¨¡å‹ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç„¶è€Œï¼Œç”±äºå› æœæ³¨æ„åŠ›çš„é¡ºåºè®¡ç®—ï¼ŒTarFlowçš„é‡‡æ ·è¿‡ç¨‹éå¸¸ç¼“æ…¢ã€‚æœ¬æ–‡é€šè¿‡ä¼˜åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨é«˜æ–¯-èµ›å¾·å°”-é›…å¯æ¯”è¿­ä»£æ–¹æ³•æ˜¾è‘—åŠ é€Ÿäº†TarFlowçš„é‡‡æ ·è¿‡ç¨‹ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11932",
            "title": "Neuro-Symbolic Query Compiler",
            "url": "https://huggingface.co/papers/2505.11932",
            "abstract": "Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar G[q] to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 Ğ¼Ğ°Ñ",
                "en": "May 17",
                "zh": "5æœˆ17æ—¥"
            },
            "hash": "9445be4eff7e4edc",
            "authors": [
                "Yuyao Zhang",
                "Zhicheng Dou",
                "Xiaoxi Li",
                "Jiajie Jin",
                "Yongkang Wu",
                "Zhonghua Li",
                "Qi Ye",
                "Ji-Rong Wen"
            ],
            "affiliations": [
                "Huawei Poisson Lab",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11932.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rag",
                    "#multimodal"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ†Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² RAG-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ…",
                    "desc": "QCompiler - ÑÑ‚Ğ¾ Ğ½ĞµĞ¹Ñ€Ğ¾-ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² RAG-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ…. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°Ñ‚Ğ¸ĞºÑƒ BNF Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ñ… Ğ² Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµÑ€ĞµĞ²ÑŒÑ. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ñ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸. QCompiler Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‡Ğ¸Ğº Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ»ĞµĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€."
                },
                "en": {
                    "title": "Enhancing Query Understanding in RAG Systems with QCompiler",
                    "desc": "This paper introduces QCompiler, a neuro-symbolic framework designed to enhance the understanding of complex search queries in Retrieval-Augmented Generation (RAG) systems. It utilizes a specially designed Backus-Naur Form (BNF) grammar to formalize these queries, ensuring that they are both complete and free of unnecessary complexity. QCompiler operates through a series of components, including a Query Expression Translator and a Lexical Syntax Parser, which work together to convert queries into Abstract Syntax Trees (ASTs). By focusing on the atomicity of sub-queries, QCompiler improves the accuracy of document retrieval and response generation for intricate queries."
                },
                "zh": {
                    "title": "æå‡RAGç³»ç»Ÿçš„å¤æ‚æŸ¥è¯¢è¯†åˆ«èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºQCompilerçš„ç¥ç»ç¬¦å·æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿå¯¹å¤æ‚æŸ¥è¯¢çš„è¯†åˆ«èƒ½åŠ›ã€‚QCompileråŸºäºè¯­è¨€è¯­æ³•è§„åˆ™å’Œç¼–è¯‘å™¨è®¾è®¡ï¼Œè®¾è®¡äº†ä¸€ç§æœ€å°ä½†è¶³å¤Ÿçš„å·´ç§‘æ–¯-è¯ºå°”å½¢å¼ï¼ˆBNFï¼‰è¯­æ³•G[q]ï¼Œä»¥å½¢å¼åŒ–å¤æ‚æŸ¥è¯¢ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼Œè¿™ç§è¯­æ³•åœ¨ä¿æŒå®Œæ•´æ€§çš„åŒæ—¶ï¼Œå‡å°‘äº†å†—ä½™ã€‚é€šè¿‡å°†æŸ¥è¯¢ç¼–è¯‘æˆæŠ½è±¡è¯­æ³•æ ‘ï¼ˆASTï¼‰ï¼ŒQCompilerèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°æ£€ç´¢æ–‡æ¡£å¹¶ç”Ÿæˆå“åº”ï¼Œä»è€Œæ˜¾è‘—æå‡RAGç³»ç»Ÿå¤„ç†å¤æ‚æŸ¥è¯¢çš„èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13437",
            "title": "FinePhys: Fine-grained Human Action Generation by Explicitly\n  Incorporating Physical Laws for Effective Skeletal Guidance",
            "url": "https://huggingface.co/papers/2505.13437",
            "abstract": "Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as \"switch leap with 0.5 turn\" poses substantial difficulties for current methods, often yielding unsatisfactory results. To bridge this gap, we propose FinePhys, a Fine-grained human action generation framework that incorporates Physics to obtain effective skeletal guidance. Specifically, FinePhys first estimates 2D poses in an online manner and then performs 2D-to-3D dimension lifting via in-context learning. To mitigate the instability and limited interpretability of purely data-driven 3D poses, we further introduce a physics-based motion re-estimation module governed by Euler-Lagrange equations, calculating joint accelerations via bidirectional temporal updating. The physically predicted 3D poses are then fused with data-driven ones, offering multi-scale 2D heatmap guidance for the diffusion process. Evaluated on three fine-grained action subsets from FineGym (FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms competitive baselines. Comprehensive qualitative results further demonstrate FinePhys's ability to generate more natural and plausible fine-grained human actions.",
            "score": 2,
            "issue_id": 3847,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "28a08dbfb09c6639",
            "authors": [
                "Dian Shao",
                "Mingfei Shi",
                "Shengda Xu",
                "Haodong Chen",
                "Yongle Huang",
                "Binglu Wang"
            ],
            "affiliations": [
                "School of Astronautics, Northwestern Polytechnical University, Xian, China",
                "School of Automation, Northwestern Polytechnical University, Xian, China",
                "School of Software, Northwestern Polytechnical University, Xian, China",
                "Unmanned System Research Institute, Northwestern Polytechnical University, Xian, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13437.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#optimization",
                    "#diffusion",
                    "#video"
                ],
                "emoji": "ğŸ¤¸",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ FinePhys - Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ 2D Ğ¿Ğ¾Ğ·Ñ‹, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Ğ¸Ñ… Ğ² 3D Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ. Ğ”Ğ°Ğ»ĞµĞµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑƒÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğ¹ Ğ­Ğ¹Ğ»ĞµÑ€Ğ°-Ğ›Ğ°Ğ³Ñ€Ğ°Ğ½Ğ¶Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ 3D Ğ¿Ğ¾Ğ·. ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ñ‹ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ñ… 2D Ñ‚ĞµĞ¿Ğ»Ğ¾Ğ²Ñ‹Ñ… ĞºĞ°Ñ€Ñ‚, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ñ… Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Bridging Physics and Data for Realistic Human Action Generation",
                    "desc": "This paper presents FinePhys, a framework designed to improve the generation of fine-grained human actions in videos by integrating physics-based modeling. It addresses the challenges of synthesizing complex movements, such as gymnastics routines, by first estimating 2D poses and then converting them to 3D using in-context learning. To enhance the stability and interpretability of the generated poses, FinePhys employs a motion re-estimation module based on Euler-Lagrange equations, which calculates joint accelerations through bidirectional temporal updates. The combination of physics-based predictions with data-driven approaches results in more realistic and coherent human actions, as demonstrated by superior performance on benchmark datasets."
                },
                "zh": {
                    "title": "FinePhysï¼šç‰©ç†é©±åŠ¨çš„ç»†ç²’åº¦äººç±»åŠ¨ä½œç”Ÿæˆæ¡†æ¶",
                    "desc": "å°½ç®¡è§†é¢‘ç”ŸæˆæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åˆæˆç‰©ç†ä¸Šåˆç†çš„äººç±»åŠ¨ä½œä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å»ºæ¨¡ç»†ç²’åº¦è¯­ä¹‰å’Œå¤æ‚æ—¶é—´åŠ¨æ€æ–¹é¢ã€‚æœ¬æ–‡æå‡ºäº†FinePhysï¼Œä¸€ä¸ªç»†ç²’åº¦äººç±»åŠ¨ä½œç”Ÿæˆæ¡†æ¶ï¼Œç»“åˆç‰©ç†å­¦ä»¥è·å¾—æœ‰æ•ˆçš„éª¨éª¼æŒ‡å¯¼ã€‚FinePhysé¦–å…ˆä»¥åœ¨çº¿æ–¹å¼ä¼°è®¡2Då§¿åŠ¿ï¼Œç„¶åé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ è¿›è¡Œ2Dåˆ°3Dçš„ç»´åº¦æå‡ã€‚é€šè¿‡å¼•å…¥åŸºäºç‰©ç†çš„è¿åŠ¨é‡æ–°ä¼°è®¡æ¨¡å—ï¼ŒFinePhysèƒ½å¤Ÿç”Ÿæˆæ›´è‡ªç„¶å’Œåˆç†çš„ç»†ç²’åº¦äººç±»åŠ¨ä½œã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-19.html",
    "link_next": "2025-05-21.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "19.05",
        "en": "05/19",
        "zh": "5æœˆ19æ—¥"
    },
    "short_date_next": {
        "ru": "21.05",
        "en": "05/21",
        "zh": "5æœˆ21æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 4,
        "#agents": 0,
        "#cv": 2,
        "#rl": 4,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 2,
        "#3d": 2,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 3,
        "#math": 2,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 6,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 7,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 9,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†Qwen3ï¼Œè¿™æ˜¯Qwenæ¨¡å‹ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ã€‚Qwen3åŒ…æ‹¬å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜æ€§èƒ½ã€æ•ˆç‡å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚å®ƒåŒ…å«å¯†é›†å’Œæ··åˆä¸“å®¶æ¶æ„ï¼Œå‚æ•°è§„æ¨¡ä»0.6åˆ°2350äº¿ä¸ç­‰ã€‚Qwen3çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æ€è€ƒæ¨¡å¼å’Œéæ€è€ƒæ¨¡å¼ç»“åˆåœ¨ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œæ¶ˆé™¤äº†åˆ‡æ¢æ¨¡å‹çš„éœ€è¦ã€‚å®ƒè¿˜å¼•å…¥äº†æ€è€ƒé¢„ç®—æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºã€‚",
        "title": "Qwen3 Technical Report",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†Qwen3ï¼Œè¿™æ˜¯Qwenæ¨¡å‹ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ã€‚\nZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le Qwen3, zhÃ¨ shÃ¬ Qwen mÃ³xÃ­ng xÃ¬liÃ¨ de zuÃ¬xÄ«n bÇnbÄ›n.\n\nQwen3åŒ…æ‹¬å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜æ€§èƒ½ã€æ•ˆç‡å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚\nQwen3 bÄokuÃ² duÅzhÇ’ng dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng, zhÇ zÃ i tÃ­gÄo xÃ¬ngnÃ©ng, xiÃ olÇœ hÃ© duÅyÇ”yÃ¡n nÃ©nglÃ¬.\n\nå®ƒåŒ…å«å¯†é›†å’Œæ··åˆä¸“å®¶æ¶æ„ï¼Œå‚æ•°è§„æ¨¡ä»0.6åˆ°2350äº¿ä¸ç­‰ã€‚\nTÄ bÄohÃ¡n mÃ¬jÃ­ hÃ© hÃ¹nhÃ© zhuÄnjiÄ jiÃ gÃ²u, cÄnshÃ¹ guÄ«mÃ³ cÃ³ng 0.6 dÃ o 2350 yÃ¬ bÃ¹dÄ›ng.\n\nQwen3çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æ€è€ƒæ¨¡å¼å’Œéæ€è€ƒæ¨¡å¼ç»“åˆåœ¨ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œæ¶ˆé™¤äº†åˆ‡æ¢æ¨¡å‹çš„éœ€è¦ã€‚\nQwen3 de chuÃ ngxÄ«n zhÄ« chÃ¹ zÃ i yÃº jiÄng sÄ«kÇo mÃ³shÃ¬ hÃ© fÄ“i sÄ«kÇo mÃ³shÃ¬ jiÃ©hÃ© zÃ i yÄ«gÃ¨ kuÃ ngjiÃ  zhÅng, xiÄochÃº le qiÄ“huÃ n mÃ³xÃ­ng de xÅ«yÃ o.\n\nå®ƒè¿˜å¼•å…¥äº†æ€è€ƒé¢„ç®—æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºã€‚\nTÄ hÃ¡i yÇnrÃ¹ le sÄ«kÇo yÃ¹suÃ n jÄ«zhÃ¬, yÇ”nxÇ” yÃ²nghÃ¹ gÄ“njÃ¹ rÃ¨nwÃ¹ fÃ¹zÃ¡xÃ¬ng dÃ²ngtÃ i fÄ“npÃ¨i jÃ¬suÃ n zÄ«yuÃ¡n.",
        "vocab": "[\n    {\"word\": \"ç³»åˆ—\", \"pinyin\": \"xÃ¬liÃ¨\", \"trans\": \"series\"},\n    {\"word\": \"ç‰ˆæœ¬\", \"pinyin\": \"bÇnbÄ›n\", \"trans\": \"version\"},\n    {\"word\": \"æ—¨åœ¨\", \"pinyin\": \"zhÇzÃ i\", \"trans\": \"aim to\"},\n    {\"word\": \"æ•ˆç‡\", \"pinyin\": \"xiÃ olÇœ\", \"trans\": \"efficiency\"},\n    {\"word\": \"å¤šè¯­è¨€\", \"pinyin\": \"duÅyÇ”yÃ¡n\", \"trans\": \"multilingual\"},\n    {\"word\": \"èƒ½åŠ›\", \"pinyin\": \"nÃ©nglÃ¬\", \"trans\": \"ability\"},\n    {\"word\": \"åŒ…å«\", \"pinyin\": \"bÄohÃ¡n\", \"trans\": \"contain\"},\n    {\"word\": \"å¯†é›†\", \"pinyin\": \"mÃ¬jÃ­\", \"trans\": \"dense\"},\n    {\"word\": \"æ··åˆ\", \"pinyin\": \"hÃ¹nhÃ©\", \"trans\": \"hybrid\"},\n    {\"word\": \"ä¸“å®¶\", \"pinyin\": \"zhuÄnjiÄ\", \"trans\": \"expert\"},\n    {\"word\": \"æ¶æ„\", \"pinyin\": \"jiÃ gÃ²u\", \"trans\": \"architecture\"},\n    {\"word\": \"å‚æ•°\", \"pinyin\": \"cÄnshÇ”\", \"trans\": \"parameter\"},\n    {\"word\": \"è§„æ¨¡\", \"pinyin\": \"guÄ«mÃ³\", \"trans\": \"scale\"},\n    {\"word\": \"åˆ›æ–°\", \"pinyin\": \"chuÃ ngxÄ«n\", \"trans\": \"innovation\"},\n    {\"word\": \"ä¹‹å¤„\", \"pinyin\": \"zhÄ«chÃ¹\", \"trans\": \"place\"},\n    {\"word\": \"æ€è€ƒ\", \"pinyin\": \"sÄ«kÇo\", \"trans\": \"think\"},\n    {\"word\": \"æ¨¡å¼\", \"pinyin\": \"mÃ³shÃ¬\", \"trans\": \"mode\"},\n    {\"word\": \"ç»“åˆ\", \"pinyin\": \"jiÃ©hÃ©\", \"trans\": \"combine\"},\n    {\"word\": \"æ¡†æ¶\", \"pinyin\": \"kuÃ ngjiÃ \", \"trans\": \"framework\"},\n    {\"word\": \"æ¶ˆé™¤\", \"pinyin\": \"xiÄochÃº\", \"trans\": \"eliminate\"},\n    {\"word\": \"åˆ‡æ¢\", \"pinyin\": \"qiÄ“huÃ n\", \"trans\": \"switch\"},\n    {\"word\": \"éœ€è¦\", \"pinyin\": \"xÅ«yÃ o\", \"trans\": \"need\"},\n    {\"word\": \"å¼•å…¥\", \"pinyin\": \"yÇnrÃ¹\", \"trans\": \"introduce\"},\n    {\"word\": \"é¢„ç®—\", \"pinyin\": \"yÃ¹suÃ n\", \"trans\": \"budget\"},\n    {\"word\": \"æœºåˆ¶\", \"pinyin\": \"jÄ«zhÃ¬\", \"trans\": \"mechanism\"},\n    {\"word\": \"å…è®¸\", \"pinyin\": \"yÇ”nxÇ”\", \"trans\": \"allow\"},\n    {\"word\": \"æ ¹æ®\", \"pinyin\": \"gÄ“njÃ¹\", \"trans\": \"according to\"},\n    {\"word\": \"ä»»åŠ¡\", \"pinyin\": \"rÃ¨nwÃ¹\", \"trans\": \"task\"},\n    {\"word\": \"å¤æ‚æ€§\", \"pinyin\": \"fÃ¹zÃ¡xÃ¬ng\", \"trans\": \"complexity\"},\n    {\"word\": \"åŠ¨æ€\", \"pinyin\": \"dÃ²ngtÃ i\", \"trans\": \"dynamic\"},\n    {\"word\": \"åˆ†é…\", \"pinyin\": \"fÄ“npÃ¨i\", \"trans\": \"allocate\"},\n    {\"word\": \"è®¡ç®—\", \"pinyin\": \"jÃ¬suÃ n\", \"trans\": \"compute\"},\n    {\"word\": \"èµ„æº\", \"pinyin\": \"zÄ«yuÃ¡n\", \"trans\": \"resources\"}\n]",
        "trans": "This article introduces Qwen3, the latest version in the Qwen model series. Qwen3 includes a variety of large language models aimed at enhancing performance, efficiency, and multilingual capabilities. It features dense and mixture-of-experts architectures, with parameter sizes ranging from 0.6 to 2350 billion. The innovation of Qwen3 lies in combining thinking and non-thinking modes within a single framework, eliminating the need to switch models. It also introduces a thinking budget mechanism, allowing users to dynamically allocate computational resources based on the complexity of the task.",
        "update_ts": "2025-05-19 09:13"
    }
}