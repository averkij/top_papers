{
    "date": {
        "ru": "19 мая",
        "en": "May 19",
        "zh": "5月19日"
    },
    "time_utc": "2025-05-19 07:12",
    "weekday": 0,
    "issue_id": 3827,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.09388",
            "title": "Qwen3 Technical Report",
            "url": "https://huggingface.co/papers/2505.09388",
            "abstract": "In this work, we present Qwen3, the latest version of the Qwen model family. Qwen3 comprises a series of large language models (LLMs) designed to advance performance, efficiency, and multilingual capabilities. The Qwen3 series includes models of both dense and Mixture-of-Expert (MoE) architectures, with parameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is the integration of thinking mode (for complex, multi-step reasoning) and non-thinking mode (for rapid, context-driven responses) into a unified framework. This eliminates the need to switch between different models--such as chat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g., QwQ-32B)--and enables dynamic mode switching based on user queries or chat templates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing users to allocate computational resources adaptively during inference, thereby balancing latency and performance based on task complexity. Moreover, by leveraging the knowledge from the flagship models, we significantly reduce the computational resources required to build smaller-scale models, while ensuring their highly competitive performance. Empirical evaluations demonstrate that Qwen3 achieves state-of-the-art results across diverse benchmarks, including tasks in code generation, mathematical reasoning, agent tasks, etc., competitive against larger MoE models and proprietary models. Compared to its predecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119 languages and dialects, enhancing global accessibility through improved cross-lingual understanding and generation capabilities. To facilitate reproducibility and community-driven research and development, all Qwen3 models are publicly accessible under Apache 2.0.",
            "score": 54,
            "issue_id": 3823,
            "pub_date": "2025-05-14",
            "pub_date_card": {
                "ru": "14 мая",
                "en": "May 14",
                "zh": "5月14日"
            },
            "hash": "69a0f87bb5460e8d",
            "authors": [
                "An Yang",
                "Anfeng Li",
                "Baosong Yang",
                "Beichen Zhang",
                "Binyuan Hui",
                "Bo Zheng",
                "Bowen Yu",
                "Chang Gao",
                "Chengen Huang",
                "Chenxu Lv",
                "Chujie Zheng",
                "Dayiheng Liu",
                "Fan Zhou",
                "Fei Huang",
                "Feng Hu",
                "Hao Ge",
                "Haoran Wei",
                "Huan Lin",
                "Jialong Tang",
                "Jian Yang",
                "Jianhong Tu",
                "Jianwei Zhang",
                "Jianxin Yang",
                "Jiaxi Yang",
                "Jing Zhou",
                "Jingren Zhou",
                "Junyang Lin",
                "Kai Dang",
                "Keqin Bao",
                "Kexin Yang",
                "Le Yu",
                "Lianghao Deng",
                "Mei Li",
                "Mingfeng Xue",
                "Mingze Li",
                "Pei Zhang",
                "Peng Wang",
                "Qin Zhu",
                "Rui Men",
                "Ruize Gao",
                "Shixuan Liu",
                "Shuang Luo",
                "Tianhao Li",
                "Tianyi Tang",
                "Wenbiao Yin",
                "Xingzhang Ren",
                "Xinyu Wang",
                "Xinyu Zhang",
                "Xuancheng Ren",
                "Yang Fan",
                "Yang Su",
                "Yichang Zhang",
                "Yinger Zhang",
                "Yu Wan",
                "Yuqiong Liu",
                "Zekun Wang",
                "Zeyu Cui",
                "Zhenru Zhang",
                "Zhipeng Zhou",
                "Zihan Qiu"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2505.09388.jpg",
            "data": {
                "categories": [
                    "#low_resource",
                    "#agi",
                    "#reasoning",
                    "#multilingual",
                    "#benchmark",
                    "#architecture",
                    "#training",
                    "#open_source"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Qwen3: Единая модель для мышления и быстрых ответов",
                    "desc": "Qwen3 - это новое семейство больших языковых моделей (LLM), разработанное для улучшения производительности, эффективности и многоязычных возможностей. Ключевой инновацией Qwen3 является интеграция режима мышления и режима без мышления в единую структуру, что позволяет динамически переключаться между ними. Модель вводит механизм бюджета мышления, позволяющий адаптивно распределять вычислительные ресурсы во время вывода. Qwen3 достигает передовых результатов в различных бенчмарках и поддерживает 119 языков и диалектов."
                },
                "en": {
                    "title": "Qwen3: Unifying Thinking and Efficiency in Language Models",
                    "desc": "Qwen3 is the latest version of the Qwen model family, featuring large language models that enhance performance, efficiency, and multilingual capabilities. It includes both dense and Mixture-of-Expert (MoE) architectures with a wide range of parameters, from 0.6 to 235 billion. A notable innovation is the integration of thinking and non-thinking modes, allowing for seamless dynamic switching based on user needs, which improves response times and reasoning capabilities. Additionally, Qwen3 supports 119 languages, significantly increasing its accessibility and effectiveness in diverse applications, while also providing a thinking budget mechanism for optimized resource allocation during inference."
                },
                "zh": {
                    "title": "Qwen3：统一思维与响应的智能语言模型",
                    "desc": "本文介绍了Qwen3，这是Qwen模型系列的最新版本。Qwen3包含一系列大型语言模型，旨在提高性能、效率和多语言能力。其创新之处在于将思维模式和非思维模式整合到一个统一框架中，实现动态模式切换，适应用户查询。Qwen3还引入了思维预算机制，允许用户在推理过程中自适应分配计算资源，从而在任务复杂性基础上平衡延迟和性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11409",
            "title": "Visual Planning: Let's Think Only with Images",
            "url": "https://huggingface.co/papers/2505.11409",
            "abstract": "Recent advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have substantially enhanced machine reasoning across diverse tasks. However, these models predominantly rely on pure text as the medium for both expressing and structuring reasoning, even when visual information is present. In this work, we argue that language may not always be the most natural or effective modality for reasoning, particularly in tasks involving spatial and geometrical information. Motivated by this, we propose a new paradigm, Visual Planning, which enables planning through purely visual representations, independent of text. In this paradigm, planning is executed via sequences of images that encode step-by-step inference in the visual domain, akin to how humans sketch or visualize future actions. We introduce a novel reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), empowered by GRPO for post-training large vision models, leading to substantial improvements in planning in a selection of representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our visual planning paradigm outperforms all other planning variants that conduct reasoning in the text-only space. Our results establish Visual Planning as a viable and promising alternative to language-based reasoning, opening new avenues for tasks that benefit from intuitive, image-based inference.",
            "score": 8,
            "issue_id": 3825,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "67875b7838a7b7ea",
            "authors": [
                "Yi Xu",
                "Chengzu Li",
                "Han Zhou",
                "Xingchen Wan",
                "Caiqi Zhang",
                "Anna Korhonen",
                "Ivan Vulić"
            ],
            "affiliations": [
                "Google",
                "Language Technology Lab, University of Cambridge",
                "University College London"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11409.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#reasoning",
                    "#multimodal",
                    "#training",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Визуальное планирование: новый подход к машинному рассуждению без слов",
                    "desc": "Статья представляет новую парадигму под названием 'Визуальное планирование', которая позволяет осуществлять планирование с помощью чисто визуальных представлений, без использования текста. Авторы предлагают фреймворк обучения с подкреплением VPRL, усиленный методом GRPO для дообучения больших моделей компьютерного зрения. Эксперименты показывают, что визуальное планирование превосходит текстовые методы рассуждений в задачах визуальной навигации. Результаты открывают новые возможности для задач, требующих интуитивного, основанного на изображениях вывода."
                },
                "en": {
                    "title": "Visual Planning: Reasoning Beyond Text",
                    "desc": "This paper introduces a new approach called Visual Planning, which focuses on using visual representations for reasoning instead of relying solely on text. The authors argue that for tasks involving spatial and geometrical information, visual reasoning can be more effective. They present a reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), which enhances planning capabilities in visual navigation tasks. The results show that this visual approach outperforms traditional text-based reasoning methods, suggesting a shift towards image-based inference in machine learning applications."
                },
                "zh": {
                    "title": "视觉规划：超越文本的推理新范式",
                    "desc": "最近，大型语言模型（LLMs）和多模态扩展（MLLMs）的进展显著提升了机器推理能力。然而，这些模型主要依赖纯文本来表达和构建推理，即使在存在视觉信息的情况下。我们提出了一种新的范式，称为视觉规划，允许通过纯视觉表示进行规划，而不依赖文本。我们的研究表明，视觉规划在处理空间和几何信息的任务中，比基于语言的推理更有效。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.10962",
            "title": "MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective\n  Search and Data Curation",
            "url": "https://huggingface.co/papers/2505.10962",
            "abstract": "Automated Theorem Proving (ATP) in formal languages remains a formidable challenge in AI, demanding rigorous logical deduction and navigating vast search spaces. While large language models (LLMs) have shown promising performance, existing stepwise provers often suffer from biased search guidance, leading to inefficiencies and suboptimal proof strategies. This paper introduces the Multi-Perspective Search Prover (MPS-Prover), a novel stepwise ATP system designed to overcome these limitations. MPS-Prover incorporates two key innovations: a highly effective post-training data curation strategy that prunes approximately 40% of redundant training data without sacrificing performance, and a multi-perspective tree search mechanism. This search integrates a learned critic model with strategically designed heuristic rules to diversify tactic selection, prevent getting trapped in unproductive states, and enhance search robustness. Extensive evaluations demonstrate that MPS-Prover achieves state-of-the-art performance on multiple challenging benchmarks, including miniF2F and ProofNet, outperforming prior 7B parameter models. Furthermore, our analyses reveal that MPS-Prover generates significantly shorter and more diverse proofs compared to existing stepwise and whole-proof methods, highlighting its efficiency and efficacy. Our work advances the capabilities of LLM-based formal reasoning and offers a robust framework and a comprehensive analysis for developing more powerful theorem provers.",
            "score": 5,
            "issue_id": 3825,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "07990204af30ff71",
            "authors": [
                "Zhenwen Liang",
                "Linfeng Song",
                "Yang Li",
                "Tao Yang",
                "Feng Zhang",
                "Haitao Mi",
                "Dong Yu"
            ],
            "affiliations": [
                "Tencent AI Lab",
                "Tencent LLM Department"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.10962.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#benchmark",
                    "#reasoning",
                    "#data",
                    "#optimization",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Многоперспективный поиск для прорыва в автоматическом доказательстве теорем",
                    "desc": "Эта статья представляет инновационную систему автоматического доказательства теорем под названием MPS-Prover. Система использует две ключевые инновации: эффективную стратегию отбора данных после обучения и механизм поиска с множественными перспективами. MPS-Prover достигает наилучших результатов на нескольких сложных эталонных тестах, превосходя предыдущие модели с 7 миллиардами параметров. Анализ показывает, что MPS-Prover генерирует значительно более короткие и разнообразные доказательства по сравнению с существующими методами."
                },
                "en": {
                    "title": "Revolutionizing Theorem Proving with Multi-Perspective Search",
                    "desc": "This paper presents the Multi-Perspective Search Prover (MPS-Prover), a new system for Automated Theorem Proving (ATP) that addresses inefficiencies in existing stepwise provers. MPS-Prover utilizes a post-training data curation strategy to eliminate redundant training data, improving performance without loss of quality. It also features a multi-perspective tree search that combines a learned critic model with heuristic rules to enhance search diversity and prevent unproductive paths. The results show that MPS-Prover not only achieves state-of-the-art performance on various benchmarks but also produces shorter and more diverse proofs than previous models."
                },
                "zh": {
                    "title": "多视角搜索，提升定理证明效率",
                    "desc": "自动定理证明（ATP）在形式语言中仍然是人工智能中的一大挑战，需要严格的逻辑推理和广泛的搜索空间。虽然大型语言模型（LLMs）表现出良好的性能，但现有的逐步证明器常常受到偏见搜索指导的影响，导致效率低下和次优的证明策略。本文介绍了一种新颖的逐步ATP系统——多视角搜索证明器（MPS-Prover），旨在克服这些局限性。MPS-Prover结合了高效的后训练数据整理策略和多视角树搜索机制，显著提高了证明的效率和多样性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11152",
            "title": "Learning Dense Hand Contact Estimation from Imbalanced Data",
            "url": "https://huggingface.co/papers/2505.11152",
            "abstract": "Hands are essential to human interaction, and understanding contact between hands and the world can promote comprehensive understanding of their function. Recently, there have been growing number of hand interaction datasets that cover interaction with object, other hand, scene, and body. Despite the significance of the task and increasing high-quality data, how to effectively learn dense hand contact estimation remains largely underexplored. There are two major challenges for learning dense hand contact estimation. First, there exists class imbalance issue from hand contact datasets where majority of samples are not in contact. Second, hand contact datasets contain spatial imbalance issue with most of hand contact exhibited in finger tips, resulting in challenges for generalization towards contacts in other hand regions. To tackle these issues, we present a framework that learns dense HAnd COntact estimation (HACO) from imbalanced data. To resolve the class imbalance issue, we introduce balanced contact sampling, which builds and samples from multiple sampling groups that fairly represent diverse contact statistics for both contact and non-contact samples. Moreover, to address the spatial imbalance issue, we propose vertex-level class-balanced (VCB) loss, which incorporates spatially varying contact distribution by separately reweighting loss contribution of each vertex based on its contact frequency across dataset. As a result, we effectively learn to predict dense hand contact estimation with large-scale hand contact data without suffering from class and spatial imbalance issue. The codes will be released.",
            "score": 2,
            "issue_id": 3822,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "caa702fa71c24606",
            "authors": [
                "Daniel Sungho Jung",
                "Kyoung Mu Lee"
            ],
            "affiliations": [
                "IPAI, Dept. of ECE & ASRI, Seoul National University, Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11152.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#data"
                ],
                "emoji": "🖐️",
                "ru": {
                    "title": "Точная оценка контактов рук: преодоление дисбаланса данных",
                    "desc": "Эта статья представляет новый подход к оценке плотного контакта рук с окружающей средой, что важно для понимания взаимодействия человека с миром. Авторы разработали фреймворк HACO для обучения на несбалансированных данных, решая проблемы классового и пространственного дисбаланса в наборах данных о контактах рук. Они предложили метод сбалансированной выборки контактов и функцию потерь VCB, учитывающую пространственное распределение контактов на поверхности руки. Результаты показывают эффективность предложенного подхода для точного предсказания плотных контактов рук на основе крупномасштабных данных."
                },
                "en": {
                    "title": "Enhancing Hand Contact Estimation with Balanced Learning Techniques",
                    "desc": "This paper addresses the challenge of estimating dense hand contact in various interactions, which is crucial for understanding hand functionality. It identifies two main issues: class imbalance, where most samples do not involve contact, and spatial imbalance, where contact is primarily at the fingertips. To overcome these challenges, the authors propose a framework called HACO that utilizes balanced contact sampling to ensure diverse representation of contact data. Additionally, they introduce a vertex-level class-balanced loss to adjust the learning process based on the frequency of contact across different hand regions, leading to improved predictions in dense hand contact estimation."
                },
                "zh": {
                    "title": "提升手部接触估计的准确性",
                    "desc": "这篇论文探讨了手部接触估计的重要性，尤其是在与物体、其他手、场景和身体的互动中。尽管已有大量高质量的数据集，但如何有效学习密集的手部接触估计仍然是一个未被充分研究的问题。论文提出了一种新的框架，称为HACO，旨在解决类不平衡和空间不平衡的问题。通过引入平衡接触采样和顶点级类平衡损失，研究者们成功地提高了手部接触估计的准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11140",
            "title": "Scaling Reasoning can Improve Factuality in Large Language Models",
            "url": "https://huggingface.co/papers/2505.11140",
            "abstract": "Recent studies on large language model (LLM) reasoning capabilities have demonstrated promising improvements in model performance by leveraging a lengthy thinking process and additional computational resources during inference, primarily in tasks involving mathematical reasoning (Muennighoff et al., 2025). However, it remains uncertain if longer reasoning chains inherently enhance factual accuracy, particularly beyond mathematical contexts. In this work, we thoroughly examine LLM reasoning within complex open-domain question-answering (QA) scenarios. We initially distill reasoning traces from advanced, large-scale reasoning models (QwQ-32B and DeepSeek-R1-671B), then fine-tune a variety of models ranging from smaller, instruction-tuned variants to larger architectures based on Qwen2.5. To enrich reasoning traces, we introduce factual information from knowledge graphs in the form of paths into our reasoning traces. Our experimental setup includes four baseline approaches and six different instruction-tuned models evaluated across a benchmark of six datasets, encompassing over 22.6K questions. Overall, we carry out 168 experimental runs and analyze approximately 1.7 million reasoning traces. Our findings indicate that, within a single run, smaller reasoning models achieve noticeable improvements in factual accuracy compared to their original instruction-tuned counterparts. Moreover, our analysis demonstrates that adding test-time compute and token budgets factual accuracy consistently improves by 2-8%, further confirming the effectiveness of test-time scaling for enhancing performance and consequently improving reasoning accuracy in open-domain QA tasks. We release all the experimental artifacts for further research.",
            "score": 0,
            "issue_id": 3827,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "29d6b0a8040db2ff",
            "authors": [
                "Mike Zhang",
                "Johannes Bjerva",
                "Russa Biswas"
            ],
            "affiliations": [
                "Department of Computer Science Aalborg University Copenhagen, Denmark"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11140.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#graphs",
                    "#dataset",
                    "#benchmark",
                    "#inference",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Длительные рассуждения улучшают точность ответов языковых моделей",
                    "desc": "Исследование посвящено изучению влияния длительного процесса рассуждений на точность ответов больших языковых моделей (LLM) в задачах открытого вопросно-ответного поиска. Авторы провели эксперименты с различными моделями, обогащая цепочки рассуждений фактической информацией из графов знаний. Результаты показывают, что меньшие модели рассуждений достигают заметных улучшений в фактической точности по сравнению с исходными инструктированными аналогами. Добавление вычислительных ресурсов и увеличение лимита токенов во время тестирования последовательно улучшает фактическую точность на 2-8%."
                },
                "en": {
                    "title": "Enhancing LLM Reasoning with Knowledge and Compute",
                    "desc": "This paper investigates the reasoning capabilities of large language models (LLMs) in open-domain question-answering tasks. It analyzes how longer reasoning processes and additional computational resources can impact factual accuracy, especially beyond mathematical reasoning. The authors fine-tune various models and incorporate knowledge graph information to enhance reasoning traces. Their experiments reveal that smaller models can achieve better factual accuracy than larger, instruction-tuned models, and that increasing computational resources during inference can further improve performance."
                },
                "zh": {
                    "title": "提升推理准确性的关键在于模型与资源的结合",
                    "desc": "本研究探讨了大型语言模型（LLM）在复杂开放领域问答（QA）场景中的推理能力。我们从先进的推理模型中提取推理轨迹，并对多种模型进行微调，以提高其推理准确性。通过引入知识图谱中的事实信息，我们丰富了推理轨迹，并在多个数据集上进行了广泛的实验。结果表明，较小的推理模型在事实准确性上有显著提升，而在测试时增加计算资源和令牌预算也能进一步提高准确性。"
                }
            }
        }
    ],
    "link_prev": "2025-05-16.html",
    "link_next": "2025-05-20.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "16.05",
        "en": "05/16",
        "zh": "5月16日"
    },
    "short_date_next": {
        "ru": "20.05",
        "en": "05/20",
        "zh": "5月20日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 2,
        "#benchmark": 3,
        "#agents": 0,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 5,
        "#robotics": 0,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 4,
        "#transfer_learning": 0,
        "#graphs": 1,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "这篇文章讨论了大型推理模型（LRMs）的潜在长链推理能力。之前的研究表明，结果导向的强化学习（RL）可以偶然引发自我校正、回溯和验证等高级推理行为。然而，这些行为的时间和一致性难以预测和控制，限制了LRMs的推理能力。为了解决这些问题，作者提出了显式地将模型与三种元能力（演绎、归纳和溯因）对齐的方法。通过三阶段流水线，提升了性能，并在数学、编程和科学基准测试中显著提高了表现。代码可在GitHub上找到。",
        "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large\n  Reasoning Models",
        "pinyin": "这篇文章讨论了大型推理模型（LRMs）的潜在长链推理能力。之前的研究表明，结果导向的强化学习（RL）可以偶然引发自我校正、回溯和验证等高级推理行为。然而，这些行为的时间和一致性难以预测和控制，限制了LRMs的推理能力。为了解决这些问题，作者提出了显式地将模型与三种元能力（演绎、归纳和溯因）对齐的方法。通过三阶段流水线，提升了性能，并在数学、编程和科学基准测试中显著提高了表现。代码可在GitHub上找到。\n\nZhè piān wénzhāng tǎolùn le dàxíng tuīlǐ móxíng (LRMs) de qiánzài chánglián tuīlǐ nénglì. Zhīqián de yánjiū biǎomíng, jiéguǒ dǎoxiàng de qiángzhì xuéxí (RL) kěyǐ ǒurán yǐnfā zìwǒ jiàozhèng, huítuì hé yànzhèng děng gāojí tuīlǐ xíngwéi. Rán'ér, zhèxiē xíngwéi de shíjiān hé yīzhìxìng nán yǐ yùcè hé kòngzhì, xiànzhì le LRMs de tuīlǐ nénglì. Wèile jiějué zhèxiē wèntí, zuòzhě tíchū le xiǎnshì de jiāng móxíng yǔ sān zhǒng yuán nénglì (yǎnyì, guīnà hé sùyīn) duìqí de fāngfǎ. Tōngguò sān jiēduàn liúshuǐxiàn, tíshēng le xìngnéng, bìng zài shùxué, biānchéng hé kēxué jīzhǔn cèshì zhōng xiǎnzhù tīgāo le biǎoxiàn. Dàimǎ kě zài GitHub shàng zhǎo dào.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"潜在\", \"pinyin\": \"qián zài\", \"trans\": \"potential\"},\n    {\"word\": \"长链\", \"pinyin\": \"cháng liàn\", \"trans\": \"long-chain\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuī lǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"能力\", \"pinyin\": \"néng lì\", \"trans\": \"ability\"},\n    {\"word\": \"之前\", \"pinyin\": \"zhī qián\", \"trans\": \"before\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"表明\", \"pinyin\": \"biǎo míng\", \"trans\": \"indicate\"},\n    {\"word\": \"结果\", \"pinyin\": \"jié guǒ\", \"trans\": \"result\"},\n    {\"word\": \"导向\", \"pinyin\": \"dǎo xiàng\", \"trans\": \"oriented\"},\n    {\"word\": \"强化\", \"pinyin\": \"qiáng huà\", \"trans\": \"reinforcement\"},\n    {\"word\": \"学习\", \"pinyin\": \"xué xí\", \"trans\": \"learning\"},\n    {\"word\": \"偶然\", \"pinyin\": \"ǒu rán\", \"trans\": \"occasionally\"},\n    {\"word\": \"引发\", \"pinyin\": \"yǐn fā\", \"trans\": \"trigger\"},\n    {\"word\": \"自我\", \"pinyin\": \"zì wǒ\", \"trans\": \"self\"},\n    {\"word\": \"校正\", \"pinyin\": \"jiào zhèng\", \"trans\": \"correct\"},\n    {\"word\": \"回溯\", \"pinyin\": \"huí sù\", \"trans\": \"backtrack\"},\n    {\"word\": \"验证\", \"pinyin\": \"yàn zhèng\", \"trans\": \"verify\"},\n    {\"word\": \"行为\", \"pinyin\": \"xíng wéi\", \"trans\": \"behavior\"},\n    {\"word\": \"一致性\", \"pinyin\": \"yī zhì xìng\", \"trans\": \"consistency\"},\n    {\"word\": \"预测\", \"pinyin\": \"yù cè\", \"trans\": \"predict\"},\n    {\"word\": \"控制\", \"pinyin\": \"kòng zhì\", \"trans\": \"control\"},\n    {\"word\": \"限制\", \"pinyin\": \"xiàn zhì\", \"trans\": \"limit\"},\n    {\"word\": \"提出\", \"pinyin\": \"tí chū\", \"trans\": \"propose\"},\n    {\"word\": \"显式\", \"pinyin\": \"xiǎn shì\", \"trans\": \"explicit\"},\n    {\"word\": \"对齐\", \"pinyin\": \"duì qí\", \"trans\": \"align\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"元\", \"pinyin\": \"yuán\", \"trans\": \"meta\"},\n    {\"word\": \"能力\", \"pinyin\": \"néng lì\", \"trans\": \"ability\"},\n    {\"word\": \"演绎\", \"pinyin\": \"yǎn yì\", \"trans\": \"deduction\"},\n    {\"word\": \"归纳\", \"pinyin\": \"guī nà\", \"trans\": \"induction\"},\n    {\"word\": \"溯因\", \"pinyin\": \"sù yīn\", \"trans\": \"abduction\"},\n    {\"word\": \"三阶段\", \"pinyin\": \"sān jiē duàn\", \"trans\": \"three-stage\"},\n    {\"word\": \"流水线\", \"pinyin\": \"liú shuǐ xiàn\", \"trans\": \"pipeline\"},\n    {\"word\": \"提升\", \"pinyin\": \"tí shēng\", \"trans\": \"enhance\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"提高\", \"pinyin\": \"tí gāo\", \"trans\": \"improve\"},\n    {\"word\": \"表现\", \"pinyin\": \"biǎo xiàn\", \"trans\": \"performance\"},\n    {\"word\": \"代码\", \"pinyin\": \"dài mǎ\", \"trans\": \"code\"},\n    {\"word\": \"GitHub\", \"pinyin\": \"GitHub\", \"trans\": \"GitHub\"}\n]",
        "trans": "This article discusses the potential long-chain reasoning capabilities of Large Reasoning Models (LRMs). Previous research has shown that result-oriented reinforcement learning (RL) can occasionally trigger advanced reasoning behaviors such as self-correction, backtracking, and verification. However, the timing and consistency of these behaviors are difficult to predict and control, limiting the reasoning capabilities of LRMs. To address these issues, the authors propose a method that explicitly aligns the model with three meta-abilities: deduction, induction, and abduction. Through a three-stage pipeline, performance is enhanced, and significant improvements are achieved in mathematical, programming, and scientific benchmark tests. The code can be found on GitHub.",
        "update_ts": "2025-05-18 12:44"
    }
}