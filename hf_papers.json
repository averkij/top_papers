{
    "date": {
        "ru": "29 ноября",
        "en": "November 29",
        "zh": "11月29日"
    },
    "time_utc": "2024-11-29 13:21",
    "weekday": 4,
    "issue_id": 862,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [],
    "link_prev": "2024-11-28.html",
    "link_next": "2024-12-02.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "28.11",
        "en": "11/28",
        "zh": "11月28日"
    },
    "short_date_next": {
        "ru": "02.12",
        "en": "12/02",
        "zh": "12月2日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "视觉-语言模型（VLMs）在多模态推理任务中取得了显著进展。然而，它们仍然常常生成不准确或无关的响应，原因是对图像理解的幻觉或未精炼的推理路径。为解决这些挑战，我们引入了Critic-V，一种受Actor-Critic范式启发的新框架，以提升VLMs的推理能力。该框架通过整合两个独立组件来解耦推理过程和评论过程：Reasoner生成基于视觉和文本输入的推理路径，Critic提供建设性的评论来完善这些路径。评估结果显示，Critic-V框架在5个基准测试中显著优于现有方法，包括GPT-4V，特别是在推理准确性和效率方面。",
        "title": "Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning",
        "pinyin": "视觉-语言模型（VLMs）在多模态推理任务中取得了显著进展。然而，它们仍然常常生成不准确或无关的响应，原因是对图像理解的幻觉或未精炼的推理路径。为解决这些挑战，我们引入了Critic-V，一种受Actor-Critic范式启发的新框架，以提升VLMs的推理能力。该框架通过整合两个独立组件来解耦推理过程和评论过程：Reasoner生成基于视觉和文本输入的推理路径，Critic提供建设性的评论来完善这些路径。评估结果显示，Critic-V框架在5个基准测试中显著优于现有方法，包括GPT-4V，特别是在推理准确性和效率方面。\n\nShìjué-yǔyán móxíng (VLMs) zài duō móshì tuīlǐ rènwù zhōng qǔdéle xiǎnzhù jìnbù. Rán'ér, tāmen réngrán chángcháng shēngchéng bù zhǔnquè huò wúguān de xiǎngyìng, yuányīn shì duì túxiàng lǐjiě de huànjué huò wèi jīngliàn de tuīlǐ lùjìng. Wèi jiějué zhèxiē tiǎozhàn, wǒmen yǐn rùle Critic-V, yīzhǒng shòu Actor-Critic fànshì qǐfā de xīn kuàngjià, yǐ tíshēng VLMs de tuīlǐ nénglì. Gāi kuàngjià tōngguò zhěnghé liǎng gè dúlì zǔjiàn lái jiěchán tuīlǐ guòchéng hé pínglùn guòchéng: Reasoner shēngchéng jīyú shìjué hé wénběn shūrù de tuīlǐ lùjìng, Critic tígōng jiànshèxìng de pínglùn lái wánshàn zhèxiē lùjìng. Píngjià jiéguǒ xiǎnshì, Critic-V kuàngjià zài 5 gè jīzhǔn cèshì zhōng xiǎnzhù yōu xiànzài fāngfǎ, bāokuò GPT-4V, tèbié shì zài tuīlǐ zhǔnquèxìng hé xiàolǜ fāngmiàn.\n\nHere is the pinyin transcription for the given text.",
        "vocab": "[\n    {\"word\": \"视觉-语言模型\", \"pinyin\": \"shìjué-yǔyán móxíng\", \"trans\": \"vision-language model\"},\n    {\"word\": \"多模态\", \"pinyin\": \"duō móshì\", \"trans\": \"multimodal\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuīlǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"任务\", \"pinyin\": \"rènwù\", \"trans\": \"task\"},\n    {\"word\": \"取得\", \"pinyin\": \"qǔdé\", \"trans\": \"achieve\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎnzhù\", \"trans\": \"significant\"},\n    {\"word\": \"进展\", \"pinyin\": \"jìnzhǎn\", \"trans\": \"progress\"},\n    {\"word\": \"然而\", \"pinyin\": \"rán'ér\", \"trans\": \"however\"},\n    {\"word\": \"常常\", \"pinyin\": \"chángcháng\", \"trans\": \"often\"},\n    {\"word\": \"生成\", \"pinyin\": \"shēngchéng\", \"trans\": \"generate\"},\n    {\"word\": \"不准确\", \"pinyin\": \"bù zhǔnquè\", \"trans\": \"inaccurate\"},\n    {\"word\": \"无关\", \"pinyin\": \"wúguān\", \"trans\": \"irrelevant\"},\n    {\"word\": \"响应\", \"pinyin\": \"xiǎngyìng\", \"trans\": \"response\"},\n    {\"word\": \"原因\", \"pinyin\": \"yuányīn\", \"trans\": \"reason\"},\n    {\"word\": \"对\", \"pinyin\": \"duì\", \"trans\": \"towards\"},\n    {\"word\": \"图像\", \"pinyin\": \"túxiàng\", \"trans\": \"image\"},\n    {\"word\": \"理解\", \"pinyin\": \"lǐjiě\", \"trans\": \"understanding\"},\n    {\"word\": \"幻觉\", \"pinyin\": \"huànjué\", \"trans\": \"illusion\"},\n    {\"word\": \"未\", \"pinyin\": \"wèi\", \"trans\": \"not yet\"},\n    {\"word\": \"精炼\", \"pinyin\": \"jīngliàn\", \"trans\": \"refined\"},\n    {\"word\": \"路径\", \"pinyin\": \"lùjìng\", \"trans\": \"path\"},\n    {\"word\": \"解决\", \"pinyin\": \"jiějué\", \"trans\": \"solve\"},\n    {\"word\": \"挑战\", \"pinyin\": \"tiǎozhàn\", \"trans\": \"challenge\"},\n    {\"word\": \"引入\", \"pinyin\": \"yǐnrù\", \"trans\": \"introduce\"},\n    {\"word\": \"Critic-V\", \"pinyin\": \"Critic-V\", \"trans\": \"Critic-V\"},\n    {\"word\": \"受\", \"pinyin\": \"shòu\", \"trans\": \"inspired by\"},\n    {\"word\": \"Actor-Critic\", \"pinyin\": \"Actor-Critic\", \"trans\": \"Actor-Critic\"},\n    {\"word\": \"范式\", \"pinyin\": \"fànshì\", \"trans\": \"paradigm\"},\n    {\"word\": \"启发\", \"pinyin\": \"qǐfā\", \"trans\": \"inspiration\"},\n    {\"word\": \"新\", \"pinyin\": \"xīn\", \"trans\": \"new\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàngjià\", \"trans\": \"framework\"},\n    {\"word\": \"以\", \"pinyin\": \"yǐ\", \"trans\": \"in order to\"},\n    {\"word\": \"提升\", \"pinyin\": \"tíshēng\", \"trans\": \"enhance\"},\n    {\"word\": \"能力\", \"pinyin\": \"nénglì\", \"trans\": \"ability\"},\n    {\"word\": \"该\", \"pinyin\": \"gǎi\", \"trans\": \"this\"},\n    {\"word\": \"通过\", \"pinyin\": \"tōngguò\", \"trans\": \"through\"},\n    {\"word\": \"整合\", \"pinyin\": \"zhěnghé\", \"trans\": \"integrate\"},\n    {\"word\": \"两个\", \"pinyin\": \"liǎng gè\", \"trans\": \"two\"},\n    {\"word\": \"独立\", \"pinyin\": \"dúlì\", \"trans\": \"independent\"},\n    {\"word\": \"组件\", \"pinyin\": \"zǔjiàn\", \"trans\": \"component\"},\n    {\"word\": \"解耦\", \"pinyin\": \"jiě'ǒu\", \"trans\": \"decouple\"},\n    {\"word\": \"过程\", \"pinyin\": \"guòchéng\", \"trans\": \"process\"},\n    {\"word\": \"评论\", \"pinyin\": \"pínglùn\", \"trans\": \"comment\"},\n    {\"word\": \"Reasoner\", \"pinyin\": \"Reasoner\", \"trans\": \"Reasoner\"},\n    {\"word\": \"基于\", \"pinyin\": \"jīyú\", \"trans\": \"based on\"},\n    {\"word\": \"视觉\", \"pinyin\": \"shìjué\", \"trans\": \"visual\"},\n    {\"word\": \"文本\", \"pinyin\": \"wénběn\", \"trans\": \"text\"},\n    {\"word\": \"输入\", \"pinyin\": \"shūrù\", \"trans\": \"input\"},\n    {\"word\": \"Critic\", \"pinyin\": \"Critic\", \"trans\": \"Critic\"},\n    {\"word\": \"提供\", \"pinyin\": \"tígōng\", \"trans\": \"provide\"},\n    {\"word\": \"建设性\", \"pinyin\": \"jiànshèxìng\", \"trans\": \"constructive\"},\n    {\"word\": \"完善\", \"pinyin\": \"wánshàn\", \"trans\": \"improve\"},\n    {\"word\": \"评估\", \"pinyin\": \"pínggū\", \"trans\": \"evaluation\"},\n    {\"word\": \"结果\", \"pinyin\": \"jiéguǒ\", \"trans\": \"result\"},\n    {\"word\": \"显示\", \"pinyin\": \"xiǎnshì\", \"trans\": \"show\"},\n    {\"word\": \"在\", \"pinyin\": \"zài\", \"trans\": \"in\"},\n    {\"word\": \"5个\", \"pinyin\": \"wǔ gè\", \"trans\": \"5\"},\n    {\"word\": \"基准\", \"pinyin\": \"jīzhǔn\", \"trans\": \"benchmark\"},\n    {\"word\": \"测试\", \"pinyin\": \"cèshì\", \"trans\": \"test\"},\n    {\"word\": \"中\", \"pinyin\": \"zhōng\", \"trans\": \"among\"},\n    {\"word\": \"显著优于\", \"pinyin\": \"xiǎnzhù yōuyú\", \"trans\": \"significantly superior to\"},\n    {\"word\": \"现有\", \"pinyin\": \"xiànyǒu\", \"trans\": \"existing\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāngfǎ\", \"trans\": \"method\"},\n    {\"word\": \"包括\", \"pinyin\": \"bāokuò\", \"trans\": \"include\"},\n    {\"word\": \"GPT-4V\", \"pinyin\": \"GPT-4V\", \"trans\": \"GPT-4V\"},\n    {\"word\": \"特别\", \"pinyin\": \"tèbié\", \"trans\": \"especially\"},\n    {\"word\": \"效率\", \"pinyin\": \"xiàolǜ\", \"trans\": \"efficiency\"}\n]",
        "trans": "Vision-language models (VLMs) have made significant progress in multimodal reasoning tasks. However, they often generate inaccurate or irrelevant responses due to illusions in image understanding or unrefined reasoning paths. To address these challenges, we introduce Critic-V, a new framework inspired by the Actor-Critic paradigm to enhance the reasoning capabilities of VLMs. This framework decouples the reasoning process and the critique process by integrating two independent components: the Reasoner, which generates reasoning paths based on visual and textual inputs, and the Critic, which provides constructive critiques to refine these paths. Evaluation results show that the Critic-V framework significantly outperforms existing methods, including GPT-4V, particularly in terms of reasoning accuracy and efficiency, across five benchmark tests.",
        "update_ts": "2024-11-29 09:08"
    }
}