{
    "date": {
        "ru": "11 июня",
        "en": "June 11",
        "zh": "6月11日"
    },
    "time_utc": "2025-06-11 02:42",
    "weekday": 2,
    "issue_id": 4231,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2506.05167",
            "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG",
            "url": "https://huggingface.co/papers/2506.05167",
            "abstract": "ECoRAG framework enhances LLM performance in ODQA by compressing retrieved documents based on evidentiality, reducing latency and token usage.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have shown remarkable performance in Open-Domain Question Answering (ODQA) by leveraging external documents through Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer context, context compression is necessary. However, prior compression methods do not focus on filtering out non-evidential information, which limit the performance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or ECoRAG framework. ECoRAG improves LLM performance by compressing retrieved documents based on evidentiality, ensuring whether answer generation is supported by the correct evidence. As an additional step, ECoRAG reflects whether the compressed content provides sufficient evidence, and if not, retrieves more until sufficient. Experiments show that ECoRAG improves LLM performance on ODQA tasks, outperforming existing compression methods. Furthermore, ECoRAG is highly cost-efficient, as it not only reduces latency but also minimizes token usage by retaining only the necessary information to generate the correct answer. Code is available at https://github.com/ldilab/ECoRAG.",
            "score": 2,
            "issue_id": 4231,
            "pub_date": "2025-06-05",
            "pub_date_card": {
                "ru": "5 июня",
                "en": "June 5",
                "zh": "6月5日"
            },
            "hash": "d979315df3a92206",
            "authors": [
                "Yeonseok Jeong",
                "Jinsu Kim",
                "Dohyeon Lee",
                "Seung-won Hwang"
            ],
            "affiliations": [
                "IPAI, Seoul National University",
                "Korea University",
                "Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.05167.jpg",
            "data": {
                "categories": [
                    "#rag",
                    "#alignment",
                    "#long_context"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "ECoRAG: Умное сжатие для точных ответов",
                    "desc": "ECoRAG - это новый фреймворк для улучшения производительности больших языковых моделей (LLM) в задачах открытого вопросно-ответного поиска (ODQA). Он использует сжатие полученных документов на основе доказательности, что позволяет снизить задержку и использование токенов. ECoRAG превосходит существующие методы сжатия и повышает эффективность LLM в задачах ODQA. Этот подход не только улучшает производительность, но и является экономически эффективным, сохраняя только необходимую информацию для генерации правильного ответа."
                },
                "en": {
                    "title": "ECoRAG: Elevating LLMs with Evidence-Based Compression",
                    "desc": "The ECoRAG framework enhances the performance of Large Language Models (LLMs) in Open-Domain Question Answering (ODQA) by focusing on evidentiality during document retrieval and compression. By filtering out non-evidential information, ECoRAG ensures that the generated answers are supported by relevant evidence, improving the overall accuracy of responses. Additionally, the framework optimizes resource usage by reducing latency and minimizing token consumption, making it more efficient than previous methods. Experiments demonstrate that ECoRAG significantly outperforms existing compression techniques in ODQA tasks."
                },
                "zh": {
                    "title": "ECoRAG：提升问答性能的证据性压缩框架",
                    "desc": "ECoRAG框架通过基于证据性压缩检索到的文档，提升了大型语言模型（LLM）在开放领域问答（ODQA）中的表现。该方法解决了以往压缩技术未能有效过滤非证据性信息的问题，从而提高了生成答案的准确性。ECoRAG确保生成的答案有足够的证据支持，并在必要时进行额外的文档检索。实验结果表明，ECoRAG在ODQA任务中优于现有的压缩方法，同时降低了延迟和令牌使用，具有很高的成本效益。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.05700",
            "title": "RKEFino1: A Regulation Knowledge-Enhanced Large Language Model",
            "url": "https://huggingface.co/papers/2506.05700",
            "abstract": "RKEFino1, a knowledge-enhanced financial reasoning model, addresses accuracy and compliance challenges in Digital Regulatory Reporting through fine-tuning with domain knowledge from XBRL, CDM, and MOF, and introduces a novel Numerical NER task.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in large language models (LLMs) hold great promise for financial applications but introduce critical accuracy and compliance challenges in Digital Regulatory Reporting (DRR). To address these issues, we propose RKEFino1, a regulation knowledge-enhanced financial reasoning model built upon Fino1, fine-tuned with domain knowledge from XBRL, CDM, and MOF. We formulate two QA tasks-knowledge-based and mathematical reasoning-and introduce a novel Numerical NER task covering financial entities in both sentences and tables. Experimental results demonstrate the effectiveness and generalization capacity of RKEFino1 in compliance-critical financial tasks. We have released our model on Hugging Face.",
            "score": 1,
            "issue_id": 4231,
            "pub_date": "2025-06-06",
            "pub_date_card": {
                "ru": "6 июня",
                "en": "June 6",
                "zh": "6月6日"
            },
            "hash": "a23a28bb68811316",
            "authors": [
                "Yan Wang",
                "Yueru He",
                "Ruoyu Xiang",
                "Jeff Zhao"
            ],
            "affiliations": [
                "Columbia University",
                "New York University",
                "The University of Texas at Austin",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.05700.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#multimodal",
                    "#reasoning",
                    "#training",
                    "#healthcare",
                    "#open_source"
                ],
                "emoji": "📊",
                "ru": {
                    "title": "Умная финансовая модель для точной регуляторной отчетности",
                    "desc": "RKEFino1 - это модель финансового рассуждения, улучшенная знаниями о регулировании, построенная на основе Fino1. Она решает проблемы точности и соответствия нормам в цифровой регуляторной отчетности путем дообучения на доменных знаниях из XBRL, CDM и MOF. Модель сформулирована для решения двух задач вопросно-ответной системы: на основе знаний и математических рассуждений. RKEFino1 также вводит новую задачу числового распознавания именованных сущностей (NER) для финансовых объектов в предложениях и таблицах."
                },
                "en": {
                    "title": "Enhancing Financial Compliance with RKEFino1",
                    "desc": "RKEFino1 is a financial reasoning model designed to improve accuracy and compliance in Digital Regulatory Reporting (DRR). It enhances the Fino1 model by incorporating domain knowledge from XBRL, CDM, and MOF, which are essential for understanding financial regulations. The model introduces a new task called Numerical Named Entity Recognition (NER) to identify financial entities in both text and tabular formats. Experimental results show that RKEFino1 effectively addresses compliance challenges and generalizes well to various financial tasks."
                },
                "zh": {
                    "title": "知识增强的金融推理，提升合规性与准确性",
                    "desc": "RKEFino1是一种增强知识的金融推理模型，旨在解决数字监管报告中的准确性和合规性挑战。该模型基于Fino1，并通过XBRL、CDM和MOF等领域知识进行微调。我们提出了两个问答任务——基于知识的问答和数学推理，并引入了一种新的数值命名实体识别任务，涵盖了句子和表格中的金融实体。实验结果表明，RKEFino1在合规性关键的金融任务中表现出色，具有良好的泛化能力。"
                }
            }
        }
    ],
    "link_prev": "2025-06-10.html",
    "link_next": "2025-06-12.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "10.06",
        "en": "06/10",
        "zh": "6月10日"
    },
    "short_date_next": {
        "ru": "12.06",
        "en": "06/12",
        "zh": "6月12日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 1,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种叫做强化预训练（RPT）的新方法。它把下一个词预测当作强化学习任务来训练语言模型。这样可以提高预测的准确性，并为进一步的微调提供坚实基础。RPT利用大量文本数据，不依赖特定领域的标注答案。实验结果显示，增加训练计算量可以提高预测准确性。",
        "title": "Reinforcement Pre-Training",
        "pinyin": "这篇文章介绍了一种叫做强化预训练（RPT）的新方法。\nZhè piān wénzhāng jièshào le yī zhǒng jiàozuò qiáng huà yù xùnliàn (RPT) de xīn fāngfǎ.\n\n它把下一个词预测当作强化学习任务来训练语言模型。\nTā bǎ xià yī gè cí yùcè dāngzuò qiáng huà xuéxí rènwù lái xùnliàn yǔyán móxíng.\n\n这样可以提高预测的准确性，并为进一步的微调提供坚实基础。\nZhèyàng kěyǐ tígāo yùcè de zhǔnquèxìng, bìng wèi jìn yī bù de wēi tiáo tígōng jiānshí jīchǔ.\n\nRPT利用大量文本数据，不依赖特定领域的标注答案。\nRPT lìyòng dàliàng wénběn shùjù, bù yīlài tèdìng lǐngyù de biāozhù dá'àn.\n\n实验结果显示，增加训练计算量可以提高预测准确性。\nShíyàn jiéguǒ xiǎnshì, zēngjiā xùnliàn jìsuàn liàng kěyǐ tígāo yùcè zhǔnquèxìng.",
        "vocab": "[\n    {\"word\": \"强化\", \"pinyin\": \"qiáng huà\", \"trans\": \"reinforcement\"},\n    {\"word\": \"预训练\", \"pinyin\": \"yù xùn liàn\", \"trans\": \"pre-training\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"预测\", \"pinyin\": \"yù cè\", \"trans\": \"prediction\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wu\", \"trans\": \"task\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"准确性\", \"pinyin\": \"zhǔn què xìng\", \"trans\": \"accuracy\"},\n    {\"word\": \"微调\", \"pinyin\": \"wēi tiáo\", \"trans\": \"fine-tuning\"},\n    {\"word\": \"坚实\", \"pinyin\": \"jiān shí\", \"trans\": \"solid\"},\n    {\"word\": \"基础\", \"pinyin\": \"jī chǔ\", \"trans\": \"foundation\"},\n    {\"word\": \"利用\", \"pinyin\": \"lì yòng\", \"trans\": \"utilize\"},\n    {\"word\": \"文本\", \"pinyin\": \"wén běn\", \"trans\": \"text\"},\n    {\"word\": \"数据\", \"pinyin\": \"shù jù\", \"trans\": \"data\"},\n    {\"word\": \"依赖\", \"pinyin\": \"yī lài\", \"trans\": \"depend on\"},\n    {\"word\": \"特定\", \"pinyin\": \"tè dìng\", \"trans\": \"specific\"},\n    {\"word\": \"领域\", \"pinyin\": \"lǐng yù\", \"trans\": \"field\"},\n    {\"word\": \"标注\", \"pinyin\": \"biāo zhù\", \"trans\": \"annotation\"},\n    {\"word\": \"答案\", \"pinyin\": \"dá àn\", \"trans\": \"answer\"},\n    {\"word\": \"实验\", \"pinyin\": \"shí yàn\", \"trans\": \"experiment\"},\n    {\"word\": \"结果\", \"pinyin\": \"jié guǒ\", \"trans\": \"result\"},\n    {\"word\": \"显示\", \"pinyin\": \"xiǎn shì\", \"trans\": \"show\"},\n    {\"word\": \"增加\", \"pinyin\": \"zēng jiā\", \"trans\": \"increase\"},\n    {\"word\": \"计算量\", \"pinyin\": \"jì suàn liàng\", \"trans\": \"computational amount\"}\n]",
        "trans": "This article introduces a new method called Reinforced Pre-Training (RPT). It trains language models by treating next-word prediction as a reinforcement learning task. This approach improves the accuracy of predictions and provides a solid foundation for further fine-tuning. RPT leverages a large amount of text data and does not rely on domain-specific annotated answers. Experimental results show that increasing the amount of training computation can enhance prediction accuracy.",
        "update_ts": "2025-06-10 09:13"
    }
}