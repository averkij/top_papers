{
    "date": {
        "ru": "2 ÑĞ½Ğ²Ğ°Ñ€Ñ",
        "en": "January 2",
        "zh": "1æœˆ2æ—¥"
    },
    "time_utc": "2025-01-02 12:18",
    "weekday": 3,
    "issue_id": 1459,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.19723",
            "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
            "url": "https://huggingface.co/papers/2412.19723",
            "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at https://qiushisun.github.io/OS-Genesis-Home/{OS-Genesis Homepage}.",
            "score": 35,
            "issue_id": 1455,
            "pub_date": "2025-12-27",
            "pub_date_card": {
                "ru": "27 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ",
                "en": "December 27",
                "zh": "12æœˆ27æ—¥"
            },
            "hash": "b331198d09aa8650",
            "authors": [
                "Qiushi Sun",
                "Kanzhi Cheng",
                "Zichen Ding",
                "Chuanyang Jin",
                "Yian Wang",
                "Fangzhi Xu",
                "Zhenyu Wu",
                "Chengyou Jia",
                "Liheng Chen",
                "Zhoumianze Liu",
                "Ben Kao",
                "Guohao Li",
                "Junxian He",
                "Yu Qiao",
                "Zhiyong Wu"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Johns Hopkins University",
                "Shanghai AI Laboratory",
                "Shanghai Jiao Tong University",
                "The University of Hong Kong",
                "University of Oxford"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.19723.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#synthetic",
                    "#dataset",
                    "#optimization",
                    "#training",
                    "#data",
                    "#agents"
                ],
                "emoji": "ğŸ–¥ï¸",
                "ru": {
                    "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: Ğ¾Ñ‚ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğº Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ OS-Genesis - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼. Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¸ÑÑĞ»ĞµĞ´ÑƒÑÑ‚ ÑÑ€ĞµĞ´Ñƒ Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‚ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ, Ğ° Ğ·Ğ°Ñ‚ĞµĞ¼ Ñ€ĞµÑ‚Ñ€Ğ¾ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒÑÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Revolutionizing GUI Agent Training with OS-Genesis",
                    "desc": "This paper introduces OS-Genesis, a new method for generating high-quality trajectory data for training GUI agents using Vision-Language Models (VLMs). Unlike traditional methods that rely on human supervision or predefined tasks, OS-Genesis allows agents to first interact with their environment and then derive tasks retrospectively. This approach enhances data diversity and quality by enabling agents to explore and learn from real-world interactions. The results show that GUI agents trained with OS-Genesis perform significantly better on challenging benchmarks, demonstrating the effectiveness of this novel data synthesis pipeline."
                },
                "zh": {
                    "title": "OS-Genesisï¼šæå‡GUIä»£ç†æ€§èƒ½çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºOS-Genesisçš„æ–°å‹å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ•°æ®åˆæˆç®¡é“ï¼Œæ—¨åœ¨è§£å†³é«˜è´¨é‡è½¨è¿¹æ•°æ®æ”¶é›†çš„ç“¶é¢ˆã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºäººç±»ç›‘ç£æˆ–åˆæˆæ•°æ®ç”Ÿæˆï¼Œå¾€å¾€èµ„æºæ¶ˆè€—å¤§ä¸”æ•°æ®è´¨é‡éš¾ä»¥ä¿è¯ã€‚OS-Genesisé€šè¿‡è®©ä»£ç†å…ˆæ„ŸçŸ¥ç¯å¢ƒå¹¶è¿›è¡Œé€æ­¥äº¤äº’ï¼Œéšåå›æº¯ç”Ÿæˆé«˜è´¨é‡ä»»åŠ¡ï¼Œä»è€Œå®ç°è½¨è¿¹çº§æ¢ç´¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨OS-Genesisè®­ç»ƒçš„GUIä»£ç†åœ¨å¤æ‚çš„åœ¨çº¿åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æ˜¾è‘—æå‡ï¼Œä¸”å…¶æ•°æ®è´¨é‡å’Œå¤šæ ·æ€§ä¼˜äºç°æœ‰åˆæˆæ–¹æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.19638",
            "title": "Xmodel-2 Technical Report",
            "url": "https://huggingface.co/papers/2412.19638",
            "abstract": "Xmodel-2 is a 1.2-billion-parameter large language model designed specifically for reasoning tasks. Its architecture enables different model scales to share a unified set of hyperparameters, allowing for extensive experimentation on smaller models and seamless transfer of optimal configurations to larger models. To maximize training efficiency and stability, Xmodel-2 employs the WSD learning rate scheduler from MiniCPM. Pretrained on 1.5 trillion tokens from diverse sources, Xmodel-2 achieves state-of-the-art performance in complex reasoning and agent-based tasks, while maintaining low training costs. These results highlight the potential of efficient model design and training strategies in advancing reasoning capabilities. Model checkpoints and code are publicly available on GitHub at https://github.com/XiaoduoAILab/Xmodel-2",
            "score": 6,
            "issue_id": 1453,
            "pub_date": "2025-12-27",
            "pub_date_card": {
                "ru": "27 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ",
                "en": "December 27",
                "zh": "12æœˆ27æ—¥"
            },
            "hash": "4707dc8ac5a87e66",
            "authors": [
                "Wang Qun",
                "Liu Yang",
                "Lin Qingquan",
                "Qu Zhijiu",
                "Jiang Ling"
            ],
            "affiliations": [
                "AI Lab, Xiaodu Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.19638.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#small_models",
                    "#reasoning",
                    "#open_source",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ñ Xmodel-2: Ğ¼Ğ¾Ñ‰ÑŒ Ğ² ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸",
                    "desc": "Xmodel-2 - ÑÑ‚Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ 1,2 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰Ğ°ÑÑÑ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ•Ñ‘ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ°Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±Ğ»ĞµĞ³Ñ‡Ğ°ĞµÑ‚ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ¾Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ WSD Ğ¸Ğ· MiniCPM Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞŸÑ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° 1,5 Ñ‚Ñ€Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ°Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Xmodel-2 Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ½Ğ¸Ğ·ĞºĞ¸Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ."
                },
                "en": {
                    "title": "Unlocking Reasoning Power with Efficient Model Design",
                    "desc": "Xmodel-2 is a large language model with 1.2 billion parameters, specifically built for reasoning tasks. It features a flexible architecture that allows different model sizes to use the same hyperparameters, facilitating experimentation and optimization across scales. The model utilizes the WSD learning rate scheduler to enhance training efficiency and stability. With pretraining on 1.5 trillion tokens, Xmodel-2 demonstrates superior performance in complex reasoning tasks while keeping training costs low, showcasing the benefits of efficient model design."
                },
                "zh": {
                    "title": "é«˜æ•ˆæ¨ç†èƒ½åŠ›çš„æ¨¡å‹è®¾è®¡ä¸è®­ç»ƒç­–ç•¥",
                    "desc": "Xmodel-2 æ˜¯ä¸€ä¸ªæ‹¥æœ‰ 12 äº¿å‚æ•°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸“é—¨è®¾è®¡ç”¨äºæ¨ç†ä»»åŠ¡ã€‚å®ƒçš„æ¶æ„å…è®¸ä¸åŒè§„æ¨¡çš„æ¨¡å‹å…±äº«ç»Ÿä¸€çš„è¶…å‚æ•°ï¼Œä»è€Œå¯ä»¥åœ¨è¾ƒå°çš„æ¨¡å‹ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œå¹¶å°†æœ€ä½³é…ç½®æ— ç¼è½¬ç§»åˆ°æ›´å¤§çš„æ¨¡å‹ä¸Šã€‚ä¸ºäº†æœ€å¤§åŒ–è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ï¼ŒXmodel-2 é‡‡ç”¨äº† MiniCPM çš„ WSD å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚ç»è¿‡åœ¨ 1.5 ä¸‡äº¿ä¸ªæ¥è‡ªå¤šæ ·åŒ–æ¥æºçš„æ ‡è®°ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒXmodel-2 åœ¨å¤æ‚æ¨ç†å’ŒåŸºäºä»£ç†çš„ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„è®­ç»ƒæˆæœ¬ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-01-01.html",
    "link_next": "2025-01-03.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "01.01",
        "en": "01/01",
        "zh": "1æœˆ1æ—¥"
    },
    "short_date_next": {
        "ru": "03.01",
        "en": "01/03",
        "zh": "1æœˆ3æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ–°çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ•°æ®åˆæˆæ–¹æ³•ï¼Œç§°ä¸ºOS-Genesisã€‚å®ƒé€šè¿‡è®©ä»£ç†é¦–å…ˆæ„ŸçŸ¥ç¯å¢ƒå¹¶è¿›è¡Œæ­¥è¿›äº¤äº’ï¼Œç„¶åé€†å‘æ¨å¯¼å‡ºé«˜è´¨é‡ä»»åŠ¡ï¼Œä»è€Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­æ•°æ®æ”¶é›†å›°éš¾çš„é—®é¢˜ã€‚OS-Genesis ä½¿ç”¨ä¸€ç§è½¨è¿¹å¥–åŠ±æ¨¡å‹æ¥ç¡®ä¿ç”Ÿæˆè½¨è¿¹çš„è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨OS-Genesisè®­ç»ƒçš„GUIä»£ç†åœ¨æŒ‘æˆ˜æ€§åœ¨çº¿åŸºå‡†ä¸Šè¡¨ç°æ›´å¥½ã€‚è¿›ä¸€æ­¥åˆ†æéªŒè¯äº†OS-Genesisåœ¨æ•°æ®è´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
        "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ–°çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ•°æ®åˆæˆæ–¹æ³•ï¼Œç§°ä¸ºOS-Genesisã€‚å®ƒé€šè¿‡è®©ä»£ç†é¦–å…ˆæ„ŸçŸ¥ç¯å¢ƒå¹¶è¿›è¡Œæ­¥è¿›äº¤äº’ï¼Œç„¶åé€†å‘æ¨å¯¼å‡ºé«˜è´¨é‡ä»»åŠ¡ï¼Œä»è€Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­æ•°æ®æ”¶é›†å›°éš¾çš„é—®é¢˜ã€‚OS-Genesis ä½¿ç”¨ä¸€ç§è½¨è¿¹å¥–åŠ±æ¨¡å‹æ¥ç¡®ä¿ç”Ÿæˆè½¨è¿¹çš„è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨OS-Genesisè®­ç»ƒçš„GUIä»£ç†åœ¨æŒ‘æˆ˜æ€§åœ¨çº¿åŸºå‡†ä¸Šè¡¨ç°æ›´å¥½ã€‚è¿›ä¸€æ­¥åˆ†æéªŒè¯äº†OS-Genesisåœ¨æ•°æ®è´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le yÄ« zhÇ’ng xÄ«n de tÃºxÃ­ng yÃ²nghÃ¹ jiÄ“miÃ n (GUI) shÃ¹jÃ¹ hÃ©chÃ©ng fÄngfÇ, chÄ“ngwÃ©i OS-Genesis. TÄ tÅngguÃ² rÃ ng dÃ ilÇ shÇ’uxiÄn gÇnzhÄ« huÃ¡njÃ¬ng bÃ¬ng jÃ¬nxÃ­ng bÃ¹jÃ¬n jiÄohÃ¹, rÃ¡nhÃ²u nÃ¬xiÃ ng tuÄ«dÇo chÅ« gÄo zhÃ¬liÃ ng rÃ¨nwÃ¹, cÃ³ng'Ã©r jiÄ›juÃ© le chuÃ¡ntÇ’ng fÄngfÇ zhÅng shÃ¹jÃ¹ shÅucuÃ¬ kÃ¹nnÃ¡n de wÃ¨ntÃ­. OS-Genesis shÇyÃ²ng yÄ« zhÇ’ng guÇjÄ« jiÇnglÃ¬ mÃ³xÃ­ng lÃ¡i quÃ¨bÇo shÄ“ngchÃ©ng guÇjÄ« de zhÃ¬liÃ ng. ShÃ­yÃ n jiÃ©guÇ’ biÇomÃ­ng, shÇyÃ²ng OS-Genesis xÃ¹nliÃ n de GUI dÃ ilÇ zÃ i tiÇozhÃ nxÃ¬ng zÃ ixiÃ n jÄ«zhÇ”n shÃ ng biÇoxiÃ n gÃ¨ng hÇo. JÃ¬n yÄ«bÃ¹ fÄ“nxi yÃ nzhÃ¨ng le OS-Genesis zÃ i shÃ¹jÃ¹ zhÃ¬liÃ ng hÃ© duÅyÃ ngxÃ¬ng fÄngmiÃ n de yÅuyuÃ¨xÃ¬ng.",
        "vocab": "[{'word': 'å›¾å½¢ç”¨æˆ·ç•Œé¢', 'pinyin': 'tÃº xÃ­ng yÃ²ng hÃ¹ jiÄ“ miÃ n', 'trans': 'graphical user interface'},\n{'word': 'æ•°æ®åˆæˆ', 'pinyin': 'shÃ¹ jÃ¹ hÃ© chÃ©ng', 'trans': 'data synthesis'},\n{'word': 'ä»£ç†', 'pinyin': 'dÃ i lÇ', 'trans': 'agent'},\n{'word': 'æ„ŸçŸ¥', 'pinyin': 'gÇn zhÄ«', 'trans': 'perceive'},\n{'word': 'æ­¥è¿›', 'pinyin': 'bÃ¹ jÃ¬n', 'trans': 'stepwise'},\n{'word': 'é€†å‘', 'pinyin': 'nÃ¬ xiÃ ng', 'trans': 'reverse'},\n{'word': 'æ¨å¯¼', 'pinyin': 'tuÄ« dÇo', 'trans': 'deduce'},\n{'word': 'é«˜è´¨é‡', 'pinyin': 'gÄo zhÃ¬ liÃ ng', 'trans': 'high quality'},\n{'word': 'è½¨è¿¹', 'pinyin': 'guÇ jÃ¬', 'trans': 'trajectory'},\n{'word': 'å¥–åŠ±', 'pinyin': 'jiÇng lÃ¬', 'trans': 'reward'},\n{'word': 'æ¨¡å‹', 'pinyin': 'mÃ³ xÃ­ng', 'trans': 'model'},\n{'word': 'ç¡®ä¿', 'pinyin': 'quÃ¨ bÇo', 'trans': 'ensure'},\n{'word': 'æŒ‘æˆ˜æ€§', 'pinyin': 'tiÇo zhÃ n xÃ¬ng', 'trans': 'challenging'},\n{'word': 'åŸºå‡†', 'pinyin': 'jÄ« zhÇ”n', 'trans': 'benchmark'},\n{'word': 'å¤šæ ·æ€§', 'pinyin': 'duÅ yÃ ng xÃ¬ng', 'trans': 'diversity'},\n{'word': 'ä¼˜è¶Šæ€§', 'pinyin': 'yÅu yuÃ¨ xÃ¬ng', 'trans': 'superiority'}]",
        "trans": "This article introduces a new method for synthesizing Graphical User Interface (GUI) data, called OS-Genesis. It addresses the challenges of data collection in traditional methods by having agents first perceive the environment and engage in step-by-step interactions, then retroactively deduce high-quality tasks. OS-Genesis employs a trajectory reward model to ensure the quality of the generated trajectories. Experimental results show that GUI agents trained using OS-Genesis perform better on challenging online benchmarks. Further analysis validates the superiority of OS-Genesis in terms of data quality and diversity.",
        "update_ts": "2025-01-02 09:10"
    }
}