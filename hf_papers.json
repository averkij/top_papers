{
    "date": {
        "ru": "5 Ğ¸ÑĞ½Ñ",
        "en": "June 5",
        "zh": "6æœˆ5æ—¥"
    },
    "time_utc": "2025-06-05 04:20",
    "weekday": 3,
    "issue_id": 4135,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2506.03569",
            "title": "MiMo-VL Technical Report",
            "url": "https://huggingface.co/papers/2506.03569",
            "abstract": "We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language models delivering state-of-the-art performance in both general visual understanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B on 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing models with up to 78B parameters. For GUI grounding applications, it sets a new standard with 56.1 on OSWorld-G, even outperforming specialized models such as UI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens) with Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward signals. We identify the importance of incorporating high-quality reasoning data with long Chain-of-Thought into pre-training stages, and the benefits of mixed RL despite challenges in simultaneous multi-domain optimization. We also contribute a comprehensive evaluation suite covering 50+ tasks to promote reproducibility and advance the field. The model checkpoints and full evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.",
            "score": 26,
            "issue_id": 4133,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "cb568276c7e799cb",
            "authors": [
                "Xiaomi LLM-Core Team",
                ":",
                "Zihao Yue",
                "Zhenru Lin",
                "Yifan Song",
                "Weikun Wang",
                "Shuhuai Ren",
                "Shuhao Gu",
                "Shicheng Li",
                "Peidian Li",
                "Liang Zhao",
                "Lei Li",
                "Kainan Bao",
                "Hao Tian",
                "Hailin Zhang",
                "Gang Wang",
                "Dawei Zhu",
                "Cici",
                "Chenhong He",
                "Bowen Ye",
                "Bowen Shen",
                "Zihan Zhang",
                "Zihan Jiang",
                "Zhixian Zheng",
                "Zhichao Song",
                "Zhenbo Luo",
                "Yue Yu",
                "Yudong Wang",
                "Yuanyuan Tian",
                "Yu Tu",
                "Yihan Yan",
                "Yi Huang",
                "Xu Wang",
                "Xinzhe Xu",
                "Xingchen Song",
                "Xing Zhang",
                "Xing Yong",
                "Xin Zhang",
                "Xiangwei Deng",
                "Wenyu Yang",
                "Wenhan Ma",
                "Weiwei Lv",
                "Weiji Zhuang",
                "Wei Liu",
                "Sirui Deng",
                "Shuo Liu",
                "Shimao Chen",
                "Shihua Yu",
                "Shaohui Liu",
                "Shande Wang",
                "Rui Ma",
                "Qiantong Wang",
                "Peng Wang",
                "Nuo Chen",
                "Menghang Zhu",
                "Kangyang Zhou",
                "Kang Zhou",
                "Kai Fang",
                "Jun Shi",
                "Jinhao Dong",
                "Jiebao Xiao",
                "Jiaming Xu",
                "Huaqiu Liu",
                "Hongshen Xu",
                "Heng Qu",
                "Haochen Zhao",
                "Hanglong Lv",
                "Guoan Wang",
                "Duo Zhang",
                "Dong Zhang",
                "Di Zhang",
                "Chong Ma",
                "Chang Liu",
                "Can Cai",
                "Bingquan Xia"
            ],
            "affiliations": [
                "Xiaomi"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.03569.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rl",
                    "#reasoning",
                    "#multimodal",
                    "#rlhf",
                    "#benchmark",
                    "#dataset",
                    "#open_source"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ˜Ğ˜: MiMo-VL ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñ‹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ´Ğ²Ğµ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ MiMo-VL-7B-SFT Ğ¸ MiMo-VL-7B-RL, Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ MiMo-VL-7B-RL Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Qwen2.5-VL-7B Ğ² 35 Ğ¸Ğ· 40 Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ 59.4 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ² Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ OlympiadBench. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²ĞºĞ»ÑÑ‡Ğ°Ğ»Ğ¾ Ñ‡ĞµÑ‚Ñ‹Ñ€ĞµÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° 2.4 Ñ‚Ñ€Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ°Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (MORL). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ¹ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¾Ğ¹ Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ğ² ÑÑ‚Ğ°Ğ¿Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Revolutionizing Vision-Language Models with MiMo-VL",
                    "desc": "The paper introduces two advanced vision-language models, MiMo-VL-7B-SFT and MiMo-VL-7B-RL, which excel in visual understanding and multimodal reasoning tasks. MiMo-VL-7B-RL demonstrates superior performance, outperforming other models on a majority of evaluated tasks and achieving high scores on benchmark datasets. The training methodology involves a four-stage pre-training process using a massive dataset and incorporates Mixed On-policy Reinforcement Learning to enhance model performance through diverse reward signals. Additionally, the authors emphasize the significance of high-quality reasoning data and provide a comprehensive evaluation suite to facilitate reproducibility in future research."
                },
                "zh": {
                    "title": "å¼€åˆ›è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ–°æ ‡å‡†",
                    "desc": "æˆ‘ä»¬å¼€æºäº†MiMo-VL-7B-SFTå’ŒMiMo-VL-7B-RLï¼Œè¿™ä¸¤ä¸ªå¼ºå¤§çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ä¸€èˆ¬è§†è§‰ç†è§£å’Œå¤šæ¨¡æ€æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚MiMo-VL-7B-RLåœ¨40ä¸ªè¯„ä¼°ä»»åŠ¡ä¸­æœ‰35ä¸ªè¶…è¶Šäº†Qwen2.5-VL-7Bï¼Œå¹¶åœ¨OlympiadBenchä¸Šå¾—åˆ†59.4ï¼Œè¶…è¿‡äº†å‚æ•°é«˜è¾¾78Bçš„æ¨¡å‹ã€‚åœ¨GUIå®šä½åº”ç”¨ä¸­ï¼Œå®ƒåœ¨OSWorld-Gä¸Šä»¥56.1çš„åˆ†æ•°è®¾å®šäº†æ–°æ ‡å‡†ï¼Œç”šè‡³è¶…è¶Šäº†ä¸“é—¨æ¨¡å‹UI-TARSã€‚æˆ‘ä»¬çš„è®­ç»ƒç»“åˆäº†å››é˜¶æ®µçš„é¢„è®­ç»ƒï¼ˆ24ä¸‡äº¿ä¸ªæ ‡è®°ï¼‰å’Œæ··åˆåœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆMORLï¼‰ï¼Œå¹¶å¼ºè°ƒäº†åœ¨é¢„è®­ç»ƒé˜¶æ®µèå…¥é«˜è´¨é‡æ¨ç†æ•°æ®å’Œé•¿é“¾æ€ç»´çš„é‡è¦æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.02921",
            "title": "A Controllable Examination for Long-Context Language Models",
            "url": "https://huggingface.co/papers/2506.02921",
            "abstract": "LongBioBench is a new benchmark using artificially generated biographies to evaluate long-context language models across understanding, reasoning, and trustworthiness dimensions, addressing limitations in existing frameworks.  \t\t\t\t\tAI-generated summary \t\t\t\t Existing frameworks for evaluating long-context language models (LCLM) can be broadly categorized into real-world and synthetic tasks. Despite their utility, both approaches are accompanied by certain intrinsic limitations. Real-world tasks are too complex to interpret or characterize and are susceptible to data contamination. In contrast, synthetic tasks often adopt the needle-in-the-haystack (NIAH) format, wherein a lack of coherence between the \"needle\" and the \"haystack\" compromises their validity as proxies for realistic applications. In response to these challenges, we posit that an ideal long-context evaluation framework should be characterized by three essential features: seamless context, controllable setting, and sound evaluation. This study introduces LongBioBench, a novel benchmark that utilizes artificially generated biographies as a controlled environment for assessing LCLMs across dimensions of understanding, reasoning, and trustworthiness. Our experimental evaluation, which includes 18 LCLMs in total, demonstrates that most models still exhibit deficiencies in semantic understanding and elementary reasoning over retrieved results and are less trustworthy as context length increases. Our further analysis indicates some design choices employed by existing synthetic benchmarks, such as contextual non-coherence, numerical needles, and the absence of distractors, rendering them vulnerable to test the model long-context capabilities. Moreover, we also reveal that long-context continual pretraining primarily adjusts RoPE embedding to accommodate extended context lengths. To sum up, compared to previous synthetic benchmarks, LongBioBench achieves a better trade-off between mirroring authentic language tasks and maintaining controllability, and is highly interpretable and configurable.",
            "score": 18,
            "issue_id": 4134,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "073ae66fedf9c141",
            "authors": [
                "Yijun Yang",
                "Zeyu Huang",
                "Wenhao Zhu",
                "Zihan Qiu",
                "Fei Yuan",
                "Jeff Z. Pan",
                "Ivan Titov"
            ],
            "affiliations": [
                "Nanjing University",
                "Qwen Team, Alibaba Group",
                "Shanghai Artificial Intelligence Laboratory",
                "University of Amsterdam",
                "University of Edinburgh"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.02921.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#synthetic",
                    "#long_context",
                    "#reasoning",
                    "#interpretability"
                ],
                "emoji": "ğŸ“Š",
                "ru": {
                    "title": "LongBioBench: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼",
                    "desc": "LongBioBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±Ğ¸Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¸. ĞĞ½ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ñ‚Ñ€ĞµĞ¼ Ğ°ÑĞ¿ĞµĞºÑ‚Ğ°Ğ¼: Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ, Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº ĞºĞ¾Ğ³ĞµÑ€ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²ÑĞµ ĞµÑ‰Ğµ Ğ¸Ğ¼ĞµÑÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ½Ñ‹Ğ¼Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ÑÑ‚ÑÑ Ğ¼ĞµĞ½ĞµĞµ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¸ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ñ‹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°."
                },
                "en": {
                    "title": "LongBioBench: A New Standard for Evaluating Long-Context Language Models",
                    "desc": "LongBioBench is a new benchmark designed to evaluate long-context language models (LCLMs) using artificially generated biographies. It addresses the limitations of existing evaluation frameworks by providing a controlled environment that emphasizes understanding, reasoning, and trustworthiness. The study reveals that many LCLMs struggle with semantic understanding and reasoning as context length increases, highlighting the need for better evaluation methods. LongBioBench offers a more coherent and interpretable approach compared to previous synthetic benchmarks, making it a valuable tool for assessing LCLMs."
                },
                "zh": {
                    "title": "LongBioBenchï¼šè¯„ä¼°é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹çš„æ–°åŸºå‡†",
                    "desc": "LongBioBench æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œåˆ©ç”¨äººå·¥ç”Ÿæˆçš„ä¼ è®°æ¥è¯„ä¼°é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰åœ¨ç†è§£ã€æ¨ç†å’Œå¯ä¿¡åº¦æ–¹é¢çš„è¡¨ç°ï¼Œè§£å†³äº†ç°æœ‰æ¡†æ¶çš„å±€é™æ€§ã€‚ç°æœ‰çš„è¯„ä¼°æ¡†æ¶åˆ†ä¸ºçœŸå®ä¸–ç•Œä»»åŠ¡å’Œåˆæˆä»»åŠ¡ï¼Œä½†ä¸¤è€…éƒ½æœ‰å†…åœ¨çš„ç¼ºé™·ã€‚çœŸå®ä¸–ç•Œä»»åŠ¡å¤æ‚ä¸”æ˜“å—æ•°æ®æ±¡æŸ“ï¼Œè€Œåˆæˆä»»åŠ¡å¸¸å¸¸ç¼ºä¹è¿è´¯æ€§ï¼Œå½±å“å…¶ä½œä¸ºç°å®åº”ç”¨çš„æœ‰æ•ˆæ€§ã€‚LongBioBench æä¾›äº†ä¸€ä¸ªå—æ§ç¯å¢ƒï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼° LCLM çš„èƒ½åŠ›ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå¤§å¤šæ•°æ¨¡å‹åœ¨è¯­ä¹‰ç†è§£å’ŒåŸºæœ¬æ¨ç†ä¸Šä»å­˜åœ¨ä¸è¶³ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04180",
            "title": "SuperWriter: Reflection-Driven Long-Form Generation with Large Language\n  Models",
            "url": "https://huggingface.co/papers/2506.04180",
            "abstract": "Long-form text generation remains a significant challenge for large language models (LLMs), particularly in maintaining coherence, ensuring logical consistency, and preserving text quality as sequence length increases. To address these limitations, we propose SuperWriter-Agent, an agent-based framework designed to enhance the quality and consistency of long-form text generation. SuperWriter-Agent introduces explicit structured thinking-through planning and refinement stages into the generation pipeline, guiding the model to follow a more deliberate and cognitively grounded process akin to that of a professional writer. Based on this framework, we construct a supervised fine-tuning dataset to train a 7B SuperWriter-LM. We further develop a hierarchical Direct Preference Optimization (DPO) procedure that uses Monte Carlo Tree Search (MCTS) to propagate final quality assessments and optimize each generation step accordingly. Empirical results across diverse benchmarks demonstrate that SuperWriter-LM achieves state-of-the-art performance, surpassing even larger-scale baseline models in both automatic evaluation and human evaluation. Furthermore, comprehensive ablation studies demonstrate the effectiveness of hierarchical DPO and underscore the value of incorporating structured thinking steps to improve the quality of long-form text generation.",
            "score": 16,
            "issue_id": 4133,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "3f52b337c5fa3683",
            "authors": [
                "Yuhao Wu",
                "Yushi Bai",
                "Zhiqiang Hu",
                "Juanzi Li",
                "Roy Ka-Wei Lee"
            ],
            "affiliations": [
                "Singapore University of Technology and Design, Singapore",
                "Tsinghua University, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04180.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#agents",
                    "#long_context",
                    "#rlhf",
                    "#benchmark",
                    "#dataset",
                    "#story_generation"
                ],
                "emoji": "âœï¸",
                "ru": {
                    "title": "Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²",
                    "desc": "SuperWriter-Agent - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ½Ğ° Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ÑÑ‚Ğ°Ğ¿Ñ‹ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸, Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒÑ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¸ÑĞ°Ñ‚ĞµĞ»Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ğ»Ğ¸ 7B-Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ SuperWriter-LM Ğ½Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€Ñƒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ (DPO) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ SuperWriter-LM Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼."
                },
                "en": {
                    "title": "Elevating Long-Form Text Generation with Structured Thinking",
                    "desc": "This paper presents SuperWriter-Agent, a novel framework aimed at improving long-form text generation by large language models (LLMs). It introduces structured thinking through planning and refinement stages, which helps the model generate more coherent and logically consistent text. The framework is supported by a supervised fine-tuning dataset for training a 7B parameter model called SuperWriter-LM. Additionally, a hierarchical Direct Preference Optimization (DPO) method is employed, utilizing Monte Carlo Tree Search to enhance the quality of generated text, leading to superior performance on various benchmarks."
                },
                "zh": {
                    "title": "æå‡é•¿æ–‡æœ¬ç”Ÿæˆè´¨é‡çš„æ™ºèƒ½ä»£ç†",
                    "desc": "é•¿æ–‡æœ¬ç”Ÿæˆæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´çš„é‡è¦æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¿æŒè¿è´¯æ€§ã€é€»è¾‘ä¸€è‡´æ€§å’Œæ–‡æœ¬è´¨é‡æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SuperWriter-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºä»£ç†çš„æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜é•¿æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡è§„åˆ’å’Œç²¾ç‚¼é˜¶æ®µå¼•å…¥æ˜ç¡®çš„ç»“æ„åŒ–æ€ç»´ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæ›´æœ‰æ„è¯†å’Œè®¤çŸ¥åŸºç¡€çš„è¿‡ç¨‹ï¼Œç±»ä¼¼äºä¸“ä¸šä½œå®¶çš„å†™ä½œæ–¹å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSuperWriter-LMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†åˆ†å±‚ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å’Œç»“æ„åŒ–æ€ç»´æ­¥éª¤çš„æœ‰æ•ˆæ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24500",
            "title": "TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning\n  for Enhancing LLMs' Social Intelligence",
            "url": "https://huggingface.co/papers/2505.24500",
            "abstract": "Temporal-aware Hierarchical Cognitive Reinforcement Learning enhances LLMs' social intelligence by addressing the distinct cognitive demands of social domains.  \t\t\t\t\tAI-generated summary \t\t\t\t Recently, Large Language Models (LLMs) have made significant progress in IQ-related domains that require careful thinking, such as mathematics and coding. However, enhancing LLMs' cognitive development in social domains, particularly from a post-training perspective, remains underexplored. Recognizing that the social world follows a distinct timeline and requires a richer blend of cognitive modes (from intuitive reactions (System 1) and surface-level thinking to deliberate thinking (System 2)) than mathematics, which primarily relies on System 2 cognition (careful, step-by-step reasoning), we introduce Temporal-aware Hierarchical Cognitive Reinforcement Learning (TimeHC-RL) for enhancing LLMs' social intelligence. In our experiments, we systematically explore improving LLMs' social intelligence and validate the effectiveness of the TimeHC-RL method, through five other post-training paradigms and two test-time intervention paradigms on eight datasets with diverse data patterns. Experimental results reveal the superiority of our proposed TimeHC-RL method compared to the widely adopted System 2 RL method. It gives the 7B backbone model wings, enabling it to rival the performance of advanced models like DeepSeek-R1 and OpenAI-O3. Additionally, the systematic exploration from post-training and test-time interventions perspectives to improve LLMs' social intelligence has uncovered several valuable insights.",
            "score": 10,
            "issue_id": 4133,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "ee580986393d0b7e",
            "authors": [
                "Guiyang Hou",
                "Xing Gao",
                "Yuchuan Wu",
                "Xiang Huang",
                "Wenqi Zhang",
                "Zhe Zheng",
                "Yongliang Shen",
                "Jialu Du",
                "Fei Huang",
                "Yongbin Li",
                "Weiming Lu"
            ],
            "affiliations": [
                "Nanjing University",
                "Tongyi Lab, Alibaba Group",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24500.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#rl",
                    "#reasoning",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ Temporal-aware Hierarchical Cognitive Reinforcement Learning (TimeHC-RL) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‰ÑƒÑ Ğ¸ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ², Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. ĞœĞµÑ‚Ğ¾Ğ´ TimeHC-RL Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ» Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ğ´ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ System 2 RL. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ TimeHC-RL Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ñ 7 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°."
                },
                "en": {
                    "title": "Boosting LLMs' Social Intelligence with TimeHC-RL",
                    "desc": "This paper presents a new approach called Temporal-aware Hierarchical Cognitive Reinforcement Learning (TimeHC-RL) to improve the social intelligence of Large Language Models (LLMs). Unlike traditional methods that focus on logical reasoning, TimeHC-RL incorporates different cognitive processes, including intuitive and deliberate thinking, to better navigate social contexts. The authors conducted experiments across various datasets and compared TimeHC-RL with existing reinforcement learning methods, demonstrating its superior performance. The findings suggest that enhancing LLMs' cognitive abilities in social domains can significantly elevate their overall intelligence and effectiveness."
                },
                "zh": {
                    "title": "æå‡ç¤¾äº¤æ™ºèƒ½çš„æ—¶é—´æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç§°ä¸ºæ—¶é—´æ„ŸçŸ¥å±‚æ¬¡è®¤çŸ¥å¼ºåŒ–å­¦ä¹ ï¼ˆTimeHC-RLï¼‰ï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¤¾äº¤é¢†åŸŸçš„æ™ºèƒ½ã€‚ä¸æ•°å­¦ç­‰ä¾èµ–ç³»ç»Ÿ2è®¤çŸ¥çš„é¢†åŸŸä¸åŒï¼Œç¤¾äº¤é¢†åŸŸéœ€è¦æ›´ä¸°å¯Œçš„è®¤çŸ¥æ¨¡å¼ï¼ŒåŒ…æ‹¬ç›´è§‰ååº”å’Œè¡¨å±‚æ€ç»´ã€‚é€šè¿‡å¯¹å…«ä¸ªä¸åŒæ•°æ®é›†çš„å®éªŒï¼Œæˆ‘ä»¬éªŒè¯äº†TimeHC-RLæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨ç¤¾äº¤æ™ºèƒ½æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„ç³»ç»Ÿ2å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä½¿å¾—7BåŸºç¡€æ¨¡å‹çš„è¡¨ç°æ¥è¿‘äºæ›´å…ˆè¿›çš„æ¨¡å‹ï¼Œå¦‚DeepSeek-R1å’ŒOpenAI-O3ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04228",
            "title": "LayerFlow: A Unified Model for Layer-aware Video Generation",
            "url": "https://huggingface.co/papers/2506.04228",
            "abstract": "LayerFlow is a unified framework for generating layer-aware videos using a text-to-video diffusion transformer and layer embeddings, supporting various video generation tasks with a multi-stage training strategy.  \t\t\t\t\tAI-generated summary \t\t\t\t We present LayerFlow, a unified solution for layer-aware video generation. Given per-layer prompts, LayerFlow generates videos for the transparent foreground, clean background, and blended scene. It also supports versatile variants like decomposing a blended video or generating the background for the given foreground and vice versa. Starting from a text-to-video diffusion transformer, we organize the videos for different layers as sub-clips, and leverage layer embeddings to distinguish each clip and the corresponding layer-wise prompts. In this way, we seamlessly support the aforementioned variants in one unified framework. For the lack of high-quality layer-wise training videos, we design a multi-stage training strategy to accommodate static images with high-quality layer annotations. Specifically, we first train the model with low-quality video data. Then, we tune a motion LoRA to make the model compatible with static frames. Afterward, we train the content LoRA on the mixture of image data with high-quality layered images along with copy-pasted video data. During inference, we remove the motion LoRA thus generating smooth videos with desired layers.",
            "score": 9,
            "issue_id": 4134,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "1e8f6532d8b54b21",
            "authors": [
                "Sihui Ji",
                "Hao Luo",
                "Xi Chen",
                "Yuanpeng Tu",
                "Yiyang Wang",
                "Hengshuang Zhao"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group, China",
                "Hupan Laboratory, China",
                "The University of Hong Kong",
                "The University of Hong Kong, Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04228.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#diffusion",
                    "#synthetic",
                    "#video",
                    "#training"
                ],
                "emoji": "ğŸï¸",
                "ru": {
                    "title": "LayerFlow: Ğ£Ğ¼Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ»Ğ¾Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¼ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ°Ğ¼",
                    "desc": "LayerFlow - ÑÑ‚Ğ¾ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ ÑĞ»Ğ¾ĞµĞ², Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ²ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾ĞµĞ². ĞĞ½Ğ° Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ°, Ñ‡Ğ¸ÑÑ‚Ğ¾Ğ³Ğ¾ Ñ„Ğ¾Ğ½Ğ° Ğ¸ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ğ¾Ğ¹ ÑÑ†ĞµĞ½Ñ‹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğº ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸ ÑĞ»Ğ¾ĞµĞ². LayerFlow Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ LoRA Ğ´Ğ»Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¶ĞµĞ»Ğ°ĞµĞ¼Ñ‹Ğ¼Ğ¸ ÑĞ»Ğ¾ÑĞ¼Ğ¸."
                },
                "en": {
                    "title": "LayerFlow: Unified Layer-Aware Video Generation",
                    "desc": "LayerFlow is a comprehensive framework designed for generating videos that are aware of different layers, such as foreground and background. It utilizes a text-to-video diffusion transformer to create videos based on specific prompts for each layer, allowing for various video generation tasks. The framework can decompose blended videos or generate backgrounds for given foregrounds, making it versatile. To address the challenge of limited high-quality training data, LayerFlow employs a multi-stage training strategy that begins with low-quality videos and progressively incorporates high-quality layered images."
                },
                "zh": {
                    "title": "LayerFlowï¼šç»Ÿä¸€çš„å±‚æ„ŸçŸ¥è§†é¢‘ç”Ÿæˆæ¡†æ¶",
                    "desc": "LayerFlowæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå±‚æ„ŸçŸ¥çš„è§†é¢‘ï¼Œåˆ©ç”¨æ–‡æœ¬åˆ°è§†é¢‘çš„æ‰©æ•£å˜æ¢å™¨å’Œå±‚åµŒå…¥ã€‚è¯¥æ¡†æ¶æ”¯æŒå¤šç§è§†é¢‘ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬é€æ˜å‰æ™¯ã€å¹²å‡€èƒŒæ™¯å’Œæ··åˆåœºæ™¯çš„è§†é¢‘ç”Ÿæˆã€‚é€šè¿‡å°†è§†é¢‘æŒ‰å±‚ç»„ç»‡ä¸ºå­å‰ªè¾‘ï¼Œå¹¶åˆ©ç”¨å±‚åµŒå…¥æ¥åŒºåˆ†æ¯ä¸ªå‰ªè¾‘åŠå…¶å¯¹åº”çš„å±‚çº§æç¤ºï¼ŒLayerFlowå®ç°äº†å¤šç§è§†é¢‘ç”Ÿæˆå˜ä½“ã€‚ä¸ºäº†å…‹æœé«˜è´¨é‡å±‚çº§è®­ç»ƒè§†é¢‘çš„ç¼ºä¹ï¼ŒLayerFlowè®¾è®¡äº†å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œç»“åˆé™æ€å›¾åƒå’Œé«˜è´¨é‡å±‚æ³¨é‡Šè¿›è¡Œè®­ç»ƒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04158",
            "title": "Image Editing As Programs with Diffusion Models",
            "url": "https://huggingface.co/papers/2506.04158",
            "abstract": "While diffusion models have achieved remarkable success in text-to-image generation, they encounter significant challenges with instruction-driven image editing. Our research highlights a key challenge: these models particularly struggle with structurally inconsistent edits that involve substantial layout changes. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a unified image editing framework built upon the Diffusion Transformer (DiT) architecture. At its core, IEAP approaches instructional editing through a reductionist lens, decomposing complex editing instructions into sequences of atomic operations. Each operation is implemented via a lightweight adapter sharing the same DiT backbone and is specialized for a specific type of edit. Programmed by a vision-language model (VLM)-based agent, these operations collaboratively support arbitrary and structurally inconsistent transformations. By modularizing and sequencing edits in this way, IEAP generalizes robustly across a wide range of editing tasks, from simple adjustments to substantial structural changes. Extensive experiments demonstrate that IEAP significantly outperforms state-of-the-art methods on standard benchmarks across various editing scenarios. In these evaluations, our framework delivers superior accuracy and semantic fidelity, particularly for complex, multi-step instructions. Codes are available at https://github.com/YujiaHu1109/IEAP.",
            "score": 5,
            "issue_id": 4133,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "e5a32d484bb427f3",
            "authors": [
                "Yujia Hu",
                "Songhua Liu",
                "Zhenxiong Tan",
                "Xingyi Yang",
                "Xinchao Wang"
            ],
            "affiliations": [
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04158.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#benchmark",
                    "#cv",
                    "#architecture"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "Ğ ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ĞºĞ°Ğº Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ˜Ğ˜-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ IEAP (Image Editing As Programs). Ğ­Ñ‚Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ½Ğ° Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Diffusion Transformer Ğ¸ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹. ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ÑÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ´Ğ°Ğ¿Ñ‚ĞµÑ€Ğ°, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ DiT. IEAP Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Revolutionizing Image Editing with Programmatic Precision",
                    "desc": "This paper addresses the limitations of diffusion models in instruction-driven image editing, particularly when it comes to making significant layout changes. The authors propose a new framework called Image Editing As Programs (IEAP), which utilizes the Diffusion Transformer (DiT) architecture to break down complex editing tasks into simpler, atomic operations. Each operation is executed by a lightweight adapter that specializes in a specific type of edit, allowing for more flexible and accurate transformations. The framework shows improved performance over existing methods, achieving higher accuracy and semantic fidelity in various editing scenarios, especially for complex instructions."
                },
                "zh": {
                    "title": "å›¾åƒç¼–è¾‘çš„æ–°æ–¹æ³•ï¼šå°†å¤æ‚æŒ‡ä»¤è½¬åŒ–ä¸ºç®€å•æ“ä½œ",
                    "desc": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸ºå›¾åƒç¼–è¾‘ä½œä¸ºç¨‹åºï¼ˆIEAPï¼‰ï¼Œæ—¨åœ¨è§£å†³æ‰©æ•£æ¨¡å‹åœ¨æŒ‡ä»¤é©±åŠ¨çš„å›¾åƒç¼–è¾‘ä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚IEAPåŸºäºæ‰©æ•£å˜æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„ï¼Œé€šè¿‡å°†å¤æ‚çš„ç¼–è¾‘æŒ‡ä»¤åˆ†è§£ä¸ºä¸€ç³»åˆ—åŸå­æ“ä½œæ¥å®ç°ã€‚æ¯ä¸ªæ“ä½œç”±è½»é‡çº§é€‚é…å™¨å®ç°ï¼Œä¸“é—¨é’ˆå¯¹ç‰¹å®šç±»å‹çš„ç¼–è¾‘ï¼Œèƒ½å¤Ÿæ”¯æŒä»»æ„å’Œç»“æ„ä¸ä¸€è‡´çš„å˜æ¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIEAPåœ¨å„ç§ç¼–è¾‘åœºæ™¯ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚çš„å¤šæ­¥éª¤æŒ‡ä»¤æ—¶è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œè¯­ä¹‰ä¿çœŸåº¦ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.03295",
            "title": "Unleashing the Reasoning Potential of Pre-trained LLMs by Critique\n  Fine-Tuning on One Problem",
            "url": "https://huggingface.co/papers/2506.03295",
            "abstract": "Critique Fine-Tuning on a single problem can efficiently enhance the reasoning capabilities of large language models with significant performance gains and reduced computational cost compared to reinforcement learning.  \t\t\t\t\tAI-generated summary \t\t\t\t We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess immense reasoning potential inherited from the pre-training stage. With reinforcement learning (RL), these models can improve dramatically on reasoning tasks. Recent studies have shown that even RL on a single problem can unleash these models' reasoning capabilities. However, RL is not only expensive but also unstable. Even one-shot RL requires hundreds of GPU hours. This raises a critical question: Is there a more efficient way to unleash the reasoning potential of these powerful base LLMs? In this work, we demonstrate that Critique Fine-Tuning (CFT) on only one problem can effectively unleash the reasoning potential of LLMs. Our method constructs critique data by collecting diverse model-generated solutions to a single problem and using teacher LLMs to provide detailed critiques. We fine-tune Qwen and Llama family models, ranging from 1.5B to 14B parameters, on the CFT data and observe significant performance gains across diverse reasoning tasks. For example, with just 5 GPU hours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six math benchmarks and 16% on three logic reasoning benchmarks. These results are comparable to or even surpass the results from RL with 20x less compute. Ablation studies reveal the robustness of one-shot CFT across different prompt problems. These results highlight one-shot CFT as a simple, general, and compute-efficient approach to unleashing the reasoning capabilities of modern LLMs.",
            "score": 5,
            "issue_id": 4135,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "03df39687a4bdf5a",
            "authors": [
                "Yubo Wang",
                "Ping Nie",
                "Kai Zou",
                "Lijun Wu",
                "Wenhu Chen"
            ],
            "affiliations": [
                "Independent",
                "Netmind.AI",
                "Shanghai AI Lab",
                "University of Waterloo",
                "Vector Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.03295.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rl",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»Ğ° Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞµ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Critique Fine-Tuning (CFT) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). CFT Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ñ… Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸ÑÑ… Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ-ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ CFT Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ğ°Ñ… Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ CFT ĞºĞ°Ğº Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸ Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğº Ñ€Ğ°ÑĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»Ğ° ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… LLM."
                },
                "en": {
                    "title": "Unlocking Reasoning Power with Efficient Critique Fine-Tuning",
                    "desc": "This paper introduces Critique Fine-Tuning (CFT) as a method to enhance the reasoning abilities of large language models (LLMs) like Qwen and Llama. By focusing on a single problem, CFT generates critique data from various model-generated solutions, which are then used to fine-tune the models. The results show that this approach leads to significant performance improvements on reasoning tasks with much lower computational costs compared to traditional reinforcement learning methods. The findings suggest that CFT is a robust and efficient strategy for maximizing the reasoning potential of LLMs."
                },
                "zh": {
                    "title": "æ‰¹è¯„å¾®è°ƒï¼šé«˜æ•ˆé‡Šæ”¾è¯­è¨€æ¨¡å‹æ¨ç†æ½œåŠ›çš„åˆ©å™¨",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæ‰¹è¯„å¾®è°ƒï¼ˆCritique Fine-Tuning, CFTï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨é«˜æ•ˆæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¯¹å•ä¸€é—®é¢˜è¿›è¡Œå¾®è°ƒï¼ŒCFTèƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼ŒåŒæ—¶å‡å°‘è®¡ç®—æˆæœ¬ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨CFTæ–¹æ³•ï¼Œæ¨¡å‹åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡äº†15%åˆ°16%ã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒCFTåœ¨è®¡ç®—èµ„æºä¸Šæ›´åŠ é«˜æ•ˆï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºä¸€ç§ç®€å•ä¸”é€šç”¨çš„æ¨ç†èƒ½åŠ›æå‡ç­–ç•¥çš„æ½œåŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.02592",
            "title": "Beyond the Surface: Measuring Self-Preference in LLM Judgments",
            "url": "https://huggingface.co/papers/2506.02592",
            "abstract": "The DBG score is introduced to measure self-preference bias in large language models by using gold judgments as proxies for response quality, addressing the confounding effect of response quality.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent studies show that large language models (LLMs) exhibit self-preference bias when serving as judges, meaning they tend to favor their own responses over those generated by other models. Existing methods typically measure this bias by calculating the difference between the scores a judge model assigns to its own responses and those it assigns to responses from other models. However, this approach conflates self-preference bias with response quality, as higher-quality responses from the judge model may also lead to positive score differences, even in the absence of bias. To address this issue, we introduce gold judgments as proxies for the actual quality of responses and propose the DBG score, which measures self-preference bias as the difference between the scores assigned by the judge model to its own responses and the corresponding gold judgments. Since gold judgments reflect true response quality, the DBG score mitigates the confounding effect of response quality on bias measurement. Using the DBG score, we conduct comprehensive experiments to assess self-preference bias across LLMs of varying versions, sizes, and reasoning abilities. Additionally, we investigate two factors that influence and help alleviate self-preference bias: response text style and the post-training data of judge models. Finally, we explore potential underlying mechanisms of self-preference bias from an attention-based perspective. Our code and data are available at https://github.com/zhiyuanc2001/self-preference.",
            "score": 5,
            "issue_id": 4134,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "ccdb2761a23fe0c8",
            "authors": [
                "Zhi-Yuan Chen",
                "Hao Wang",
                "Xinyu Zhang",
                "Enrui Hu",
                "Yankai Lin"
            ],
            "affiliations": [
                "Beijing Key Laboratory of Research on Large Models and Intelligent Governance",
                "Gaoling School of Artificial Intelligence, Renmin University of China",
                "Huawei Poisson Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.02592.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#data",
                    "#hallucinations",
                    "#interpretability",
                    "#ethics",
                    "#training"
                ],
                "emoji": "âš–ï¸",
                "ru": {
                    "title": "DBG: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸ Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸ ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ DBG, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¿Ñ€Ğ¾ĞºÑĞ¸ Ğ´Ğ»Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¾Ñ‚Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¾Ñ‚ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ»Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ LLM Ğ¸ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹, Ğ²Ğ»Ğ¸ÑÑÑ‰Ğ¸Ğµ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ÑŒ ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Measuring Self-Preference Bias with the DBG Score",
                    "desc": "This paper introduces the DBG score, a new metric designed to measure self-preference bias in large language models (LLMs) while accounting for response quality. Traditional methods for assessing this bias often confuse it with the quality of the responses, as higher quality can lead to misleading score differences. By using gold judgments as benchmarks for response quality, the DBG score effectively isolates self-preference bias from quality effects. The authors conduct experiments across various LLMs and examine factors that influence bias, providing insights into the mechanisms behind self-preference in model responses."
                },
                "zh": {
                    "title": "å¼•å…¥DBGè¯„åˆ†ï¼Œç²¾å‡†æµ‹é‡è‡ªæˆ‘åå¥½åå·®",
                    "desc": "æœ¬æ–‡æå‡ºäº†DBGè¯„åˆ†ï¼Œç”¨äºæµ‹é‡å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è‡ªæˆ‘åå¥½åå·®ã€‚é€šè¿‡ä½¿ç”¨é‡‘æ ‡å‡†åˆ¤æ–­ä½œä¸ºå“åº”è´¨é‡çš„ä»£ç†ï¼ŒDBGè¯„åˆ†è§£å†³äº†å“åº”è´¨é‡å¯¹åå·®æµ‹é‡çš„æ··æ·†æ•ˆåº”ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°è‡ªæˆ‘åå¥½åå·®æ—¶ï¼Œå¾€å¾€å°†å…¶ä¸å“åº”è´¨é‡æ··ä¸ºä¸€è°ˆã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¯„ä¼°äº†ä¸åŒç‰ˆæœ¬ã€è§„æ¨¡å’Œæ¨ç†èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘åå¥½åå·®ï¼Œå¹¶æ¢è®¨äº†å½±å“è¯¥åå·®çš„å› ç´ ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.03099",
            "title": "TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via\n  Autoregressive Diffusion Models",
            "url": "https://huggingface.co/papers/2506.03099",
            "abstract": "TalkingMachines transforms a pretrained image-to-video model into an audio-driven avatar generator, supports infinite video streaming, and uses engineering optimizations for real-time performance.  \t\t\t\t\tAI-generated summary \t\t\t\t In this paper, we present TalkingMachines -- an efficient framework that transforms pretrained video generation models into real-time, audio-driven character animators. TalkingMachines enables natural conversational experiences by integrating an audio large language model (LLM) with our video generation foundation model. Our primary contributions include: (1) We adapt a pretrained SOTA image-to-video DiT into an audio-driven avatar generation model of 18 billion parameters; (2) We enable infinite video streaming without error accumulation through asymmetric knowledge distillation from a bidirectional teacher model into a sparse causal, autoregressive student model; (3) We design a high-throughput, low-latency inference pipeline incorporating several key engineering optimizations such as: (a) disaggregation of the DiT and VAE decoder across separate devices, (b) efficient overlap of inter-device communication and computation using CUDA streams, (c) elimination of redundant recomputations to maximize frame-generation throughput. Please see demo videos here - https://aaxwaz.github.io/TalkingMachines/",
            "score": 4,
            "issue_id": 4134,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "eff27ca5fef5cdcf",
            "authors": [
                "Chetwin Low",
                "Weimin Wang"
            ],
            "affiliations": [
                "Character AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.03099.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#multimodal",
                    "#inference",
                    "#games",
                    "#audio",
                    "#video",
                    "#optimization"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "ĞĞ¶Ğ¸Ğ²Ğ»ÑĞµĞ¼ Ğ°Ğ²Ğ°Ñ‚Ğ°Ñ€Ñ‹: Ğ°ÑƒĞ´Ğ¸Ğ¾-ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸",
                    "desc": "TalkingMachines - ÑÑ‚Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒÑÑ‰Ğ°Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ² Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶ĞµĞ¹, ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸. ĞĞ½Ğ° Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ DiT Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ²Ğ°Ñ‚Ğ°Ñ€Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ 18 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ±ĞµÑĞºĞ¾Ğ½ĞµÑ‡Ğ½ÑƒÑ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²ÑƒÑ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ±ĞµĞ· Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ°ÑĞ¸Ğ¼Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. TalkingMachines Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ñ€ÑĞ´ Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ñ‹Ñ… Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ñ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹."
                },
                "en": {
                    "title": "Transforming Audio into Real-Time Avatar Animation",
                    "desc": "TalkingMachines is a novel framework that converts existing image-to-video models into real-time, audio-responsive avatar generators. It combines a large language model (LLM) with a video generation foundation model to create engaging conversational avatars. The framework features a significant adaptation of a state-of-the-art (SOTA) image-to-video model, allowing for efficient infinite video streaming through advanced knowledge distillation techniques. Additionally, it incorporates engineering optimizations to enhance performance, such as distributing processing across devices and minimizing computation delays."
                },
                "zh": {
                    "title": "å®æ—¶éŸ³é¢‘é©±åŠ¨çš„è§’è‰²åŠ¨ç”»ç”Ÿæˆå™¨",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†TalkingMachinesï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„æ¡†æ¶ï¼Œå°†é¢„è®­ç»ƒçš„è§†é¢‘ç”Ÿæˆæ¨¡å‹è½¬å˜ä¸ºå®æ—¶çš„éŸ³é¢‘é©±åŠ¨è§’è‰²åŠ¨ç”»ç”Ÿæˆå™¨ã€‚é€šè¿‡å°†éŸ³é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸è§†é¢‘ç”ŸæˆåŸºç¡€æ¨¡å‹ç»“åˆï¼ŒTalkingMachinesèƒ½å¤Ÿå®ç°è‡ªç„¶çš„å¯¹è¯ä½“éªŒã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šå°†ä¸€ä¸ªé¢„è®­ç»ƒçš„æœ€å…ˆè¿›çš„å›¾åƒåˆ°è§†é¢‘æ¨¡å‹é€‚é…ä¸ºä¸€ä¸ªå…·æœ‰180äº¿å‚æ•°çš„éŸ³é¢‘é©±åŠ¨å¤´åƒç”Ÿæˆæ¨¡å‹ï¼Œä»¥åŠé€šè¿‡ä¸å¯¹ç§°çŸ¥è¯†è’¸é¦å®ç°æ— é™è§†é¢‘æµçš„ç”Ÿæˆã€‚æˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ä¸ªé«˜ååé‡ã€ä½å»¶è¿Ÿçš„æ¨ç†ç®¡é“ï¼Œç»“åˆäº†å¤šé¡¹å…³é”®çš„å·¥ç¨‹ä¼˜åŒ–ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04207",
            "title": "Advancing Multimodal Reasoning: From Optimized Cold Start to Staged\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2506.04207",
            "abstract": "Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex textual tasks, many works attempt to incentivize similar capabilities in Multimodal Large Language Models (MLLMs) by directly applying reinforcement learning (RL). However, they still struggle to activate complex reasoning. In this paper, rather than examining multimodal RL in isolation, we delve into current training pipelines and identify three crucial phenomena: 1) Effective cold start initialization is critical for enhancing MLLM reasoning. Intriguingly, we find that initializing with carefully selected text data alone can lead to performance surpassing many recent multimodal reasoning models, even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers from gradient stagnation, which degrades training stability and performance. 3) Subsequent text-only RL training, following the multimodal RL phase, further enhances multimodal reasoning. This staged training approach effectively balances perceptual grounding and cognitive reasoning development. By incorporating the above insights and addressing multimodal RL issues, we introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath, LogicVista, DynaMath, and challenging AIME2024 and AIME2025.",
            "score": 3,
            "issue_id": 4135,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "61521f9ed974c930",
            "authors": [
                "Shuang Chen",
                "Yue Guo",
                "Zhaochen Su",
                "Yafu Li",
                "Yulun Wu",
                "Jiacheng Chen",
                "Jiayu Chen",
                "Weijie Wang",
                "Xiaoye Qu",
                "Yu Cheng"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai AI Laboratory",
                "Soochow University",
                "The Chinese University of Hong Kong",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04207.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#open_source",
                    "#multimodal",
                    "#training",
                    "#benchmark",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ MLLM: Ğ¾Ñ‚ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ RL",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM) Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ Ñ‚Ñ€Ğ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ñ„ĞµĞ½Ğ¾Ğ¼ĞµĞ½Ğ° Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ÑÑ‚Ğ°Ğ³Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğ¼ GRPO Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ RL. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¸Ñ… Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¹ Ğ±Ñ‹Ğ»Ğ° Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ReVisual-R1, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³ÑˆĞ°Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ ÑÑ€ĞµĞ´Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… 7B MLLM Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Unlocking Reasoning in MLLMs with Smart Training Strategies",
                    "desc": "This paper explores how to improve reasoning in Multimodal Large Language Models (MLLMs) by analyzing their training processes. It identifies that starting with well-chosen text data can significantly boost reasoning capabilities, even before applying multimodal reinforcement learning (RL). The authors also highlight that traditional gradient-based methods in multimodal RL can lead to stagnation, negatively impacting training effectiveness. By implementing a staged training approach that combines text-only RL after multimodal RL, they introduce ReVisual-R1, which sets new performance records on various complex benchmarks."
                },
                "zh": {
                    "title": "æå‡å¤šæ¨¡æ€æ¨ç†çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œè‰¯å¥½çš„å†·å¯åŠ¨åˆå§‹åŒ–å¯¹äºå¢å¼ºMLLMçš„æ¨ç†è‡³å…³é‡è¦ï¼Œå•ç‹¬ä½¿ç”¨ç²¾å¿ƒé€‰æ‹©çš„æ–‡æœ¬æ•°æ®å³å¯è¶…è¶Šè®¸å¤šè¿‘æœŸçš„å¤šæ¨¡æ€æ¨ç†æ¨¡å‹ã€‚æ ‡å‡†çš„GRPOåœ¨å¤šæ¨¡æ€RLä¸­å­˜åœ¨æ¢¯åº¦åœæ»çš„é—®é¢˜ï¼Œå½±å“äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚é€šè¿‡åˆ†é˜¶æ®µçš„è®­ç»ƒæ–¹æ³•ï¼Œç»“åˆæ–‡æœ¬å’Œå¤šæ¨¡æ€RLï¼Œæå‡ºäº†ReVisual-R1ï¼Œè¾¾åˆ°äº†å¼€æº7B MLLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„æ–°çŠ¶æ€ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04108",
            "title": "Rectified Sparse Attention",
            "url": "https://huggingface.co/papers/2506.04108",
            "abstract": "Rectified Sparse Attention (ReSA) improves the efficiency of long-sequence generation in Large Language Models by combining block-sparse attention with periodic dense rectification, maintaining high-quality generation.  \t\t\t\t\tAI-generated summary \t\t\t\t Efficient long-sequence generation is a critical challenge for Large Language Models. While recent sparse decoding methods improve efficiency, they suffer from KV cache misalignment, where approximation errors accumulate and degrade generation quality. In this work, we propose Rectified Sparse Attention (ReSA), a simple yet effective method that combines block-sparse attention with periodic dense rectification. By refreshing the KV cache at fixed intervals using a dense forward pass, ReSA bounds error accumulation and preserves alignment with the pretraining distribution. Experiments across math reasoning, language modeling, and retrieval tasks demonstrate that ReSA achieves near-lossless generation quality with significantly improved efficiency. Notably, ReSA delivers up to 2.42times end-to-end speedup under decoding at 256K sequence length, making it a practical solution for scalable long-context inference. Code is available at https://aka.ms/ReSA-LM.",
            "score": 3,
            "issue_id": 4134,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "ff7222f16cd2bf28",
            "authors": [
                "Yutao Sun",
                "Tianzhu Ye",
                "Li Dong",
                "Yuqing Xia",
                "Jian Chen",
                "Yizhao Gao",
                "Shijie Cao",
                "Jianyong Wang",
                "Furu Wei"
            ],
            "affiliations": [
                "Microsoft Research",
                "The University of Hong Kong",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04108.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#inference",
                    "#long_context",
                    "#optimization",
                    "#training"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°",
                    "desc": "ĞœĞµÑ‚Ğ¾Ğ´ Rectified Sparse Attention (ReSA) ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞĞ½ ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ Ğ±Ğ»Ğ¾Ñ‡Ğ½Ğ¾-Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ñ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ñ€ĞµĞºÑ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº. ReSA Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸, Ğ±Ğ»Ğ¸Ğ·ĞºĞ¾Ğ³Ğ¾ Ğº Ğ±ĞµĞ·Ğ¾ÑˆĞ¸Ğ±Ğ¾Ñ‡Ğ½Ğ¾Ğ¼Ñƒ, Ğ¿Ñ€Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾ 2,42 Ñ€Ğ°Ğ·Ğ° Ğ¿Ñ€Ğ¸ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ´Ğ»Ğ¸Ğ½Ğ¾Ğ¹ 256 Ñ‚Ñ‹ÑÑÑ‡ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²."
                },
                "en": {
                    "title": "Boosting Efficiency in Long-Sequence Generation with ReSA",
                    "desc": "Rectified Sparse Attention (ReSA) enhances the efficiency of generating long sequences in Large Language Models by integrating block-sparse attention with periodic dense rectification. This approach addresses the issue of KV cache misalignment that can lead to errors and reduced quality in generated outputs. By periodically refreshing the KV cache through a dense forward pass, ReSA minimizes error accumulation and maintains alignment with the model's pretraining data. Experimental results show that ReSA not only preserves high-quality generation but also achieves significant speed improvements, making it a viable option for long-context tasks."
                },
                "zh": {
                    "title": "é«˜æ•ˆé•¿åºåˆ—ç”Ÿæˆçš„æ–°æ–¹æ³•ï¼šReSA",
                    "desc": "Rectified Sparse Attentionï¼ˆReSAï¼‰æ˜¯ä¸€ç§æé«˜å¤§å‹è¯­è¨€æ¨¡å‹é•¿åºåˆ—ç”Ÿæˆæ•ˆç‡çš„æ–¹æ³•ã€‚å®ƒç»“åˆäº†å—ç¨€ç–æ³¨æ„åŠ›å’Œå‘¨æœŸæ€§å¯†é›†æ•´æµï¼Œèƒ½å¤Ÿä¿æŒé«˜è´¨é‡çš„ç”Ÿæˆæ•ˆæœã€‚é€šè¿‡åœ¨å›ºå®šé—´éš”å†…ä½¿ç”¨å¯†é›†å‰å‘ä¼ é€’åˆ·æ–°KVç¼“å­˜ï¼ŒReSAé™åˆ¶äº†è¯¯å·®ç´¯ç§¯ï¼Œå¹¶ä¿æŒä¸é¢„è®­ç»ƒåˆ†å¸ƒçš„å¯¹é½ã€‚å®éªŒè¡¨æ˜ï¼ŒReSAåœ¨æ•°å­¦æ¨ç†ã€è¯­è¨€å»ºæ¨¡å’Œæ£€ç´¢ä»»åŠ¡ä¸­å®ç°äº†æ¥è¿‘æ— æŸçš„ç”Ÿæˆè´¨é‡ï¼Œå¹¶åœ¨256Kåºåˆ—é•¿åº¦ä¸‹æä¾›äº†é«˜è¾¾2.42å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.03106",
            "title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and\n  Numerical Feedback",
            "url": "https://huggingface.co/papers/2506.03106",
            "abstract": "Critique-GRPO, an RL framework combining numerical and natural language feedback, enhances LLM reasoning across tasks and outperforms existing methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in reinforcement learning (RL) with numerical feedback, such as scalar rewards, have significantly enhanced the complex reasoning capabilities of large language models (LLMs). Despite this success, we identify three key challenges encountered by RL with solely numerical feedback: performance plateaus, limited effectiveness of self-reflection, and persistent failures. We then demonstrate that RL-finetuned models, even after exhibiting performance plateaus, can generate correct refinements on persistently failed problems by leveraging natural language feedback in the form of critiques. Building on this insight, we propose Critique-GRPO, an online RL framework that integrates both natural language and numerical feedback for effective policy optimization. Critique-GRPO enables LLMs to learn from initial responses and critique-guided refinements simultaneously while maintaining exploration. Extensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that Critique-GRPO consistently outperforms supervised learning-based and RL-based fine-tuning approaches across eight challenging mathematical, STEM, and general reasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%, respectively. Notably, Critique-GRPO surpasses a strong baseline that incorporates expert demonstrations within online RL. Further analysis reveals two critical insights about policy exploration: (1) higher entropy does not always guarantee efficient learning from exploration, and (2) longer responses do not necessarily lead to more effective exploration.",
            "score": 3,
            "issue_id": 4134,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "99f5fb3b08ab4205",
            "authors": [
                "Xiaoying Zhang",
                "Hao Sun",
                "Yipeng Zhang",
                "Kaituo Feng",
                "Chaochao Lu",
                "Chao Yang",
                "Helen Meng"
            ],
            "affiliations": [
                "Shanghai Artificial Intelligence Laboratory",
                "The Chinese University of Hong Kong, HCCL",
                "The Chinese University of Hong Kong, MMLab",
                "University of Cambridge"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.03106.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#rl",
                    "#reasoning",
                    "#optimization",
                    "#rlhf",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Critique-GRPO: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Critique-GRPO - Ğ½Ğ¾Ğ²ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ­Ñ‚Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²ÑƒÑ Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµÑ‚ÑŒ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Critique-GRPO Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Enhancing LLM Reasoning with Critique-GRPO: A Dual Feedback Approach",
                    "desc": "Critique-GRPO is a reinforcement learning (RL) framework that enhances the reasoning abilities of large language models (LLMs) by combining numerical and natural language feedback. It addresses challenges faced by traditional RL methods that rely solely on numerical feedback, such as performance plateaus and ineffective self-reflection. By incorporating critiques in natural language, Critique-GRPO allows models to refine their responses and improve their performance on difficult tasks. Experimental results show that this approach significantly outperforms existing fine-tuning methods, achieving better results in various reasoning tasks."
                },
                "zh": {
                    "title": "Critique-GRPOï¼šè‡ªç„¶è¯­è¨€ä¸æ•°å€¼åé¦ˆçš„å®Œç¾ç»“åˆ",
                    "desc": "Critique-GRPOæ˜¯ä¸€ç§ç»“åˆæ•°å€¼åé¦ˆå’Œè‡ªç„¶è¯­è¨€åé¦ˆçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚è¯¥æ¡†æ¶è§£å†³äº†ä»…ä¾èµ–æ•°å€¼åé¦ˆæ—¶é‡åˆ°çš„æ€§èƒ½åœæ»ã€è‡ªæˆ‘åæ€æ•ˆæœæœ‰é™å’ŒæŒç»­å¤±è´¥ç­‰æŒ‘æˆ˜ã€‚é€šè¿‡åˆ©ç”¨è‡ªç„¶è¯­è¨€åé¦ˆï¼ŒCritique-GRPOèƒ½å¤Ÿåœ¨æ¨¡å‹è¡¨ç°åœæ»æ—¶ï¼Œç”Ÿæˆæ­£ç¡®çš„æ”¹è¿›å»ºè®®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCritique-GRPOåœ¨å¤šä¸ªå¤æ‚ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç°æœ‰çš„ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å¹³å‡é€šè¿‡ç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04133",
            "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management\n  in LLM-based Agentic Multi-Agent Systems",
            "url": "https://huggingface.co/papers/2506.04133",
            "abstract": "A review of trust, risk, and security management in LLM-based agentic multi-agent systems, examining governance, explainability, ModelOps, and privacy/security.  \t\t\t\t\tAI-generated summary \t\t\t\t Agentic AI systems, built on large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligent autonomy, collaboration and decision-making across enterprise and societal domains. This review presents a structured analysis of Trust, Risk, and Security Management (TRiSM) in the context of LLM-based agentic multi-agent systems (AMAS). We begin by examining the conceptual foundations of agentic AI, its architectural differences from traditional AI agents, and the emerging system designs that enable scalable, tool-using autonomy. The TRiSM in the agentic AI framework is then detailed through four pillars governance, explainability, ModelOps, and privacy/security each contextualized for agentic LLMs. We identify unique threat vectors and introduce a comprehensive risk taxonomy for the agentic AI applications, supported by case studies illustrating real-world vulnerabilities. Furthermore, the paper also surveys trust-building mechanisms, transparency and oversight techniques, and state-of-the-art explainability strategies in distributed LLM agent systems. Additionally, metrics for evaluating trust, interpretability, and human-centered performance are reviewed alongside open benchmarking challenges. Security and privacy are addressed through encryption, adversarial defense, and compliance with evolving AI regulations. The paper concludes with a roadmap for responsible agentic AI, proposing research directions to align emerging multi-agent systems with robust TRiSM principles for safe, accountable, and transparent deployment.",
            "score": 2,
            "issue_id": 4133,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "a0a258935ed39508",
            "authors": [
                "Shaina Raza",
                "Ranjan Sapkota",
                "Manoj Karkee",
                "Christos Emmanouilidis"
            ],
            "affiliations": [
                "Cornell University, USA",
                "University of Groningen, Netherlands",
                "Vector Institute, Toronto, Canada"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04133.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#survey",
                    "#agents",
                    "#multimodal",
                    "#security",
                    "#alignment",
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ğµ Ğ² ÑĞ¿Ğ¾Ñ…Ñƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸ĞµĞ¼, Ñ€Ğ¸ÑĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒÑ (TRiSM) Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ°: ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ, Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ, ModelOps Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ/Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒÑÑ‚ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ ÑƒĞ³Ñ€Ğ¾Ğ· Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½ÑƒÑ Ñ‚Ğ°ĞºÑĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ñ€Ğ¸ÑĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜. Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ñ, Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ½Ğ°Ğ´Ğ·Ğ¾Ñ€Ğ°, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ² Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² LLM."
                },
                "en": {
                    "title": "Navigating Trust and Security in Agentic AI Systems",
                    "desc": "This paper reviews the management of trust, risk, and security in multi-agent systems that use large language models (LLMs). It discusses how these agentic AI systems differ from traditional AI, focusing on their ability to operate autonomously and collaboratively. The authors outline four key areas of Trust, Risk, and Security Management (TRiSM): governance, explainability, ModelOps, and privacy/security, providing a framework for understanding the unique challenges these systems face. The paper also highlights the importance of building trust and ensuring transparency in these systems, while proposing future research directions for responsible deployment."
                },
                "zh": {
                    "title": "æ„å»ºå®‰å…¨é€æ˜çš„ä»£ç†äººå·¥æ™ºèƒ½ç³»ç»Ÿ",
                    "desc": "æœ¬æ–‡å›é¡¾äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ä¿¡ä»»ã€é£é™©å’Œå®‰å…¨ç®¡ç†ï¼ˆTRiSMï¼‰ã€‚æˆ‘ä»¬åˆ†æäº†ä»£ç†äººå·¥æ™ºèƒ½çš„æ¦‚å¿µåŸºç¡€åŠå…¶ä¸ä¼ ç»Ÿäººå·¥æ™ºèƒ½ä»£ç†çš„æ¶æ„å·®å¼‚ï¼Œå¹¶æ¢è®¨äº†æ”¯æŒå¯æ‰©å±•è‡ªä¸»æ€§çš„ç³»ç»Ÿè®¾è®¡ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº†TRiSMçš„å››ä¸ªæ”¯æŸ±ï¼šæ²»ç†ã€å¯è§£é‡Šæ€§ã€æ¨¡å‹æ“ä½œå’Œéšç§/å®‰å…¨ï¼Œå¹¶ä¸ºä»£ç†LLMæä¾›äº†å…·ä½“çš„èƒŒæ™¯ã€‚æœ€åï¼Œæå‡ºäº†è´Ÿè´£ä»»çš„ä»£ç†äººå·¥æ™ºèƒ½çš„è·¯çº¿å›¾ï¼Œå»ºè®®ç ”ç©¶æ–¹å‘ä»¥ç¡®ä¿æ–°å…´å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨ã€é€æ˜å’Œè´Ÿè´£ä»»çš„éƒ¨ç½²ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.04034",
            "title": "Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning",
            "url": "https://huggingface.co/papers/2506.04034",
            "abstract": "Object referring aims to detect all objects in an image that match a given natural language description. We argue that a robust object referring model should be grounded, meaning its predictions should be both explainable and faithful to the visual content. Specifically, it should satisfy two key properties: 1) Verifiable, by producing interpretable reasoning that justifies its predictions and clearly links them to visual evidence; and 2) Trustworthy, by learning to abstain when no object in the image satisfies the given expression. However, most methods treat referring as a direct bounding box prediction task, offering limited interpretability and struggling to reject expressions with no matching object. In this work, we propose Rex-Thinker, a model that formulates object referring as an explicit CoT reasoning task. Given a referring expression, we first identify all candidate object instances corresponding to the referred object category. Rex-Thinker then performs step-by-step reasoning over each candidate to assess whether it matches the given expression, before making a final prediction. To support this paradigm, we construct a large-scale CoT-style referring dataset named HumanRef-CoT by prompting GPT-4o on the HumanRef dataset. Each reasoning trace follows a structured planning, action, and summarization format, enabling the model to learn decomposed, interpretable reasoning over object candidates. We then train Rex-Thinker in two stages: a cold-start supervised fine-tuning phase to teach the model how to perform structured reasoning, followed by GRPO-based RL learning to improve accuracy and generalization. Experiments show that our approach outperforms standard baselines in both precision and interpretability on in-domain evaluation, while also demonstrating improved ability to reject hallucinated outputs and strong generalization in out-of-domain settings.",
            "score": 2,
            "issue_id": 4133,
            "pub_date": "2025-06-04",
            "pub_date_card": {
                "ru": "4 Ğ¸ÑĞ½Ñ",
                "en": "June 4",
                "zh": "6æœˆ4æ—¥"
            },
            "hash": "9d3dcbdd5158f101",
            "authors": [
                "Qing Jiang",
                "Xingyu Chen",
                "Zhaoyang Zeng",
                "Junzhi Yu",
                "Lei Zhang"
            ],
            "affiliations": [
                "International Digital Economy Academy (IDEA)",
                "Peking University",
                "South China University of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.04034.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#hallucinations",
                    "#interpretability",
                    "#dataset"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ½Ğ¾Ğµ Ñ€ĞµÑ„ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµÑ„ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ¼ Ğ·Ñ€ĞµĞ½Ğ¸Ğ¸, Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Rex-Thinker. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ HumanRef-CoT Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼. Rex-Thinker Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² Ğ´Ğ²Ğ° ÑÑ‚Ğ°Ğ¿Ğ°: ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ°Ñ Ñ‚Ğ¾Ğ½ĞºĞ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ñ‡Ñ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Rex-Thinker: Grounded Object Referring with Explainable Reasoning",
                    "desc": "This paper introduces Rex-Thinker, a model designed to enhance object referring in images by incorporating explainable and trustworthy reasoning. Unlike traditional methods that focus solely on bounding box predictions, Rex-Thinker employs a Chain of Thought (CoT) reasoning approach to evaluate candidate objects against natural language descriptions. The model is trained on a new dataset, HumanRef-CoT, which facilitates structured reasoning through a systematic planning and summarization process. Results indicate that Rex-Thinker not only improves precision and interpretability but also effectively rejects irrelevant predictions, showcasing its robustness in various scenarios."
                },
                "zh": {
                    "title": "Rex-Thinkerï¼šå¯è§£é‡Šçš„ç‰©ä½“æŒ‡ä»£æ¨¡å‹",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç‰©ä½“æŒ‡ä»£æ¨¡å‹Rex-Thinkerï¼Œæ—¨åœ¨é€šè¿‡æ˜ç¡®çš„é“¾å¼æ¨ç†ä»»åŠ¡æ¥æ£€æµ‹ä¸è‡ªç„¶è¯­è¨€æè¿°åŒ¹é…çš„å›¾åƒä¸­çš„æ‰€æœ‰ç‰©ä½“ã€‚è¯¥æ¨¡å‹å¼ºè°ƒå¯éªŒè¯æ€§å’Œå¯ä¿¡æ€§ï¼Œç¡®ä¿å…¶é¢„æµ‹èƒ½å¤Ÿè§£é‡Šå¹¶ä¸è§†è§‰è¯æ®ç›¸è¿ã€‚Rex-Thinkeré€šè¿‡é€æ­¥æ¨ç†å€™é€‰ç‰©ä½“å®ä¾‹ï¼Œåˆ¤æ–­å…¶æ˜¯å¦ç¬¦åˆç»™å®šçš„æè¿°ï¼Œä»è€Œåšå‡ºæœ€ç»ˆé¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç²¾ç¡®åº¦å’Œå¯è§£é‡Šæ€§æ–¹é¢ä¼˜äºä¼ ç»ŸåŸºçº¿ï¼Œå¹¶åœ¨æ‹’ç»è™šå‡è¾“å‡ºå’Œè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ä¸Šè¡¨ç°å‡ºè‰²ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.03448",
            "title": "RefEdit: A Benchmark and Method for Improving Instruction-based Image\n  Editing Model on Referring Expressions",
            "url": "https://huggingface.co/papers/2506.03448",
            "abstract": "RefEdit, an instruction-based editing model trained on synthetic data, outperforms baselines in complex scene editing and referring expression tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Despite recent advances in inversion and instruction-based image editing, existing approaches primarily excel at editing single, prominent objects but significantly struggle when applied to complex scenes containing multiple entities. To quantify this gap, we first introduce RefEdit-Bench, a rigorous real-world benchmark rooted in RefCOCO, where even baselines trained on millions of samples perform poorly. To overcome this limitation, we introduce RefEdit -- an instruction-based editing model trained on our scalable synthetic data generation pipeline. Our RefEdit, trained on only 20,000 editing triplets, outperforms the Flux/SD3 model-based baselines trained on millions of data. Extensive evaluations across various benchmarks demonstrate that our model not only excels in referring expression tasks but also enhances performance on traditional benchmarks, achieving state-of-the-art results comparable to closed-source methods. We release data \\& checkpoint for reproducibility.",
            "score": 2,
            "issue_id": 4134,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "717f877ff02ce882",
            "authors": [
                "Bimsara Pathiraja",
                "Maitreya Patel",
                "Shivam Singh",
                "Yezhou Yang",
                "Chitta Baral"
            ],
            "affiliations": [
                "Arizona State University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.03448.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#synthetic",
                    "#cv",
                    "#optimization",
                    "#open_source"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "RefEdit: ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                    "desc": "RefEdit - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ½Ğ° Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ñ‹Ğ¼Ğ¸ Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº RefEdit-Bench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ‚Ğ°ĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. RefEdit, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ²ÑĞµĞ³Ğ¾ Ğ½Ğ° 20 000 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ…, Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ°Ñ… Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ²."
                },
                "en": {
                    "title": "Revolutionizing Image Editing with Instruction-Based Learning",
                    "desc": "RefEdit is a new model designed for editing images based on instructions, specifically focusing on complex scenes with multiple objects. Unlike previous models that struggle with such tasks, RefEdit is trained on a unique synthetic data generation pipeline, allowing it to learn effectively from a smaller dataset of 20,000 editing examples. The model significantly outperforms existing baselines, which were trained on millions of samples, in both referring expression tasks and traditional editing benchmarks. This advancement highlights the potential of instruction-based editing in achieving high performance in challenging image editing scenarios."
                },
                "zh": {
                    "title": "RefEditï¼šå¤æ‚åœºæ™¯ç¼–è¾‘çš„æ–°çªç ´",
                    "desc": "RefEditæ˜¯ä¸€ç§åŸºäºæŒ‡ä»¤çš„ç¼–è¾‘æ¨¡å‹ï¼Œä¸“é—¨é’ˆå¯¹å¤æ‚åœºæ™¯ä¸­çš„ç¼–è¾‘ä»»åŠ¡è¿›è¡Œè®­ç»ƒã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒRefEditåœ¨å¤„ç†å¤šä¸ªå®ä½“çš„å¤æ‚åœºæ™¯æ—¶è¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†RefEdit-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºRefCOCOçš„çœŸå®ä¸–ç•ŒåŸºå‡†ï¼Œç”¨äºé‡åŒ–ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚é€šè¿‡ä½¿ç”¨åˆæˆæ•°æ®ç”Ÿæˆç®¡é“ï¼ŒRefEditåœ¨ä»…ä½¿ç”¨20,000ä¸ªç¼–è¾‘ä¸‰å…ƒç»„çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†åŸºäºFlux/SD3æ¨¡å‹çš„åŸºçº¿ï¼Œå±•ç¤ºäº†å…¶åœ¨æŒ‡ä»£è¡¨è¾¾ä»»åŠ¡å’Œä¼ ç»ŸåŸºå‡†ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.02945",
            "title": "Quantitative LLM Judges",
            "url": "https://huggingface.co/papers/2506.02945",
            "abstract": "LLM-as-a-judge is a framework in which a large language model (LLM) automatically evaluates the output of another LLM. We propose quantitative LLM judges, which align evaluation scores of existing LLM judges to human scores in a given domain using regression models. The models are trained to improve the score of the original judge by using the judge's textual evaluation and score. We present four quantitative judges for different types of absolute and relative feedback, which showcases the generality and versatility of our framework. Our framework is more computationally efficient than supervised fine-tuning and can be more statistically efficient when human feedback is limited, which is expected in most applications of our work. We validate these claims empirically on four datasets using two base judges. Our experiments show that quantitative judges can effectively improve the predictive power of existing judges through post-hoc modeling.",
            "score": 2,
            "issue_id": 4133,
            "pub_date": "2025-06-03",
            "pub_date_card": {
                "ru": "3 Ğ¸ÑĞ½Ñ",
                "en": "June 3",
                "zh": "6æœˆ3æ—¥"
            },
            "hash": "de4ea9c8e4abb76a",
            "authors": [
                "Aishwarya Sahoo",
                "Jeevana Kruthi Karnuthala",
                "Tushar Parmanand Budhwani",
                "Pranchal Agarwal",
                "Sankaran Vaidyanathan",
                "Alexa Siu",
                "Franck Dernoncourt",
                "Jennifer Healey",
                "Nedim Lipka",
                "Ryan Rossi",
                "Uttaran Bhattacharya",
                "Branislav Kveton"
            ],
            "affiliations": [
                "Adobe Research",
                "University of Massachusetts Amherst"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.02945.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#alignment",
                    "#rlhf",
                    "#dataset"
                ],
                "emoji": "âš–ï¸",
                "ru": {
                    "title": "LLM-ÑÑƒĞ´ÑŒĞ¸: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº LLM-as-a-judge, Ğ³Ğ´Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… LLM-ÑÑƒĞ´ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑÑƒÑÑ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ÑÑƒĞ´ĞµĞ¹ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼Ğ¸ Ğ² Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… ÑÑƒĞ´ÑŒĞ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ğ¾Ğ¹ Ğ¸ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ÑÑƒĞ´ÑŒĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ ÑĞ¸Ğ»Ñƒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ÑÑƒĞ´ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ."
                },
                "en": {
                    "title": "Enhancing LLM Evaluation with Quantitative Judges",
                    "desc": "The paper introduces a framework called LLM-as-a-judge, where a large language model (LLM) assesses the outputs of another LLM. It focuses on creating quantitative LLM judges that align their evaluation scores with human assessments using regression models. These models enhance the original judge's scoring by leveraging its textual evaluations and scores. The framework is shown to be more computationally and statistically efficient than traditional supervised fine-tuning, especially when human feedback is scarce, and is validated through experiments on multiple datasets."
                },
                "zh": {
                    "title": "åˆ©ç”¨LLMæå‡è¯„ä¼°æ•ˆç‡çš„åˆ›æ–°æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºLLM-as-a-judgeçš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨è¯„ä¼°å¦ä¸€ä¸ªLLMçš„è¾“å‡ºã€‚æˆ‘ä»¬å¼•å…¥äº†å®šé‡LLMè¯„ä¼°è€…ï¼Œé€šè¿‡å›å½’æ¨¡å‹å°†ç°æœ‰è¯„ä¼°è€…çš„è¯„åˆ†ä¸äººç±»è¯„åˆ†å¯¹é½ã€‚è¯¥æ¨¡å‹é€šè¿‡ä½¿ç”¨è¯„ä¼°è€…çš„æ–‡æœ¬è¯„ä»·å’Œè¯„åˆ†æ¥æé«˜åŸå§‹è¯„ä¼°è€…çš„è¯„åˆ†ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äºç›‘ç£å¾®è°ƒï¼Œå¹¶ä¸”åœ¨äººå·¥åé¦ˆæœ‰é™çš„æƒ…å†µä¸‹ï¼Œç»Ÿè®¡æ•ˆç‡æ›´é«˜ï¼Œé€‚ç”¨äºå¤§å¤šæ•°åº”ç”¨åœºæ™¯ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.02294",
            "title": "Improving Knowledge Distillation Under Unknown Covariate Shift Through\n  Confidence-Guided Data Augmentation",
            "url": "https://huggingface.co/papers/2506.02294",
            "abstract": "A diffusion-based data augmentation strategy improves robustness in knowledge distillation by generating challenging samples, enhancing accuracy and spurious feature resilience.  \t\t\t\t\tAI-generated summary \t\t\t\t Large foundation models trained on extensive datasets demonstrate strong zero-shot capabilities in various domains. To replicate their success when data and model size are constrained, knowledge distillation has become an established tool for transferring knowledge from foundation models to small student networks. However, the effectiveness of distillation is critically limited by the available training data. This work addresses the common practical issue of covariate shift in knowledge distillation, where spurious features appear during training but not at test time. We ask the question: when these spurious features are unknown, yet a robust teacher is available, is it possible for a student to also become robust to them? We address this problem by introducing a novel diffusion-based data augmentation strategy that generates images by maximizing the disagreement between the teacher and the student, effectively creating challenging samples that the student struggles with. Experiments demonstrate that our approach significantly improves worst group and mean group accuracy on CelebA and SpuCo Birds as well as the spurious mAUC on spurious ImageNet under covariate shift, outperforming state-of-the-art diffusion-based data augmentation baselines",
            "score": 1,
            "issue_id": 4133,
            "pub_date": "2025-06-02",
            "pub_date_card": {
                "ru": "2 Ğ¸ÑĞ½Ñ",
                "en": "June 2",
                "zh": "6æœˆ2æ—¥"
            },
            "hash": "740d99ccc158d514",
            "authors": [
                "Niclas Popp",
                "Kevin Alexander Laube",
                "Matthias Hein",
                "Lukas Schott"
            ],
            "affiliations": [
                "Bosch Center for Artificial Intelligence",
                "University of TÃ¼bingen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.02294.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#transfer_learning",
                    "#training",
                    "#optimization",
                    "#diffusion",
                    "#dataset"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞŸĞ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. ĞœĞµÑ‚Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ñ‹, Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ»Ğ°ÑĞ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¸ ÑƒÑ‡ĞµĞ½Ğ¸ĞºĞ¾Ğ¼, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ĞºĞ¾Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ´Ğ²Ğ¸Ğ³Ğ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Ğ½Ğ°Ğ¸Ñ…ÑƒĞ´ÑˆĞ¸Ñ… Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ñ… Ğ¸ ÑÑ€ĞµĞ´Ğ½ĞµĞ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼ Ğ½Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ… CelebA Ğ¸ SpuCo Birds. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Boosting Student Robustness with Diffusion Data Augmentation",
                    "desc": "This paper presents a new data augmentation method using diffusion processes to enhance knowledge distillation. The approach generates challenging samples that help student networks learn to be more robust against spurious features that may not appear during testing. By maximizing the disagreement between a robust teacher model and the student model, the method effectively prepares the student for real-world scenarios where data may shift. Experiments show that this strategy improves accuracy and resilience against spurious features in various datasets, outperforming existing methods."
                },
                "zh": {
                    "title": "åŸºäºæ‰©æ•£çš„æ•°æ®å¢å¼ºæå‡çŸ¥è¯†è’¸é¦é²æ£’æ€§",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œä»¥æé«˜çŸ¥è¯†è’¸é¦ä¸­çš„é²æ£’æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æ ·æœ¬ï¼Œå¢å¼ºäº†å­¦ç”Ÿç½‘ç»œå¯¹è™šå‡ç‰¹å¾çš„æŠµæŠ—åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨CelebAå’ŒSpuCo Birdsæ•°æ®é›†ä¸Šï¼Œè¯¥ç­–ç•¥æ˜¾è‘—æé«˜äº†æœ€å·®ç»„å’Œå¹³å‡ç»„çš„å‡†ç¡®ç‡ã€‚é€šè¿‡æœ€å¤§åŒ–æ•™å¸ˆå’Œå­¦ç”Ÿä¹‹é—´çš„åˆ†æ­§ï¼Œæœ¬æ–‡æœ‰æ•ˆåœ°è§£å†³äº†çŸ¥è¯†è’¸é¦ä¸­çš„åå˜é‡åç§»é—®é¢˜ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.01344",
            "title": "Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic\n  Agents",
            "url": "https://huggingface.co/papers/2506.01344",
            "abstract": "Flowcharts are a critical tool for visualizing decision-making processes. However, their non-linear structure and complex visual-textual relationships make it challenging to interpret them using LLMs, as vision-language models frequently hallucinate nonexistent connections and decision paths when analyzing these diagrams. This leads to compromised reliability for automated flowchart processing in critical domains such as logistics, health, and engineering. We introduce the task of Fine-grained Flowchart Attribution, which traces specific components grounding a flowchart referring LLM response. Flowchart Attribution ensures the verifiability of LLM predictions and improves explainability by linking generated responses to the flowchart's structure. We propose FlowPathAgent, a neurosymbolic agent that performs fine-grained post hoc attribution through graph-based reasoning. It first segments the flowchart, then converts it into a structured symbolic graph, and then employs an agentic approach to dynamically interact with the graph, to generate attribution paths. Additionally, we present FlowExplainBench, a novel benchmark for evaluating flowchart attributions across diverse styles, domains, and question types. Experimental results show that FlowPathAgent mitigates visual hallucinations in LLM answers over flowchart QA, outperforming strong baselines by 10-14% on our proposed FlowExplainBench dataset.",
            "score": 1,
            "issue_id": 4133,
            "pub_date": "2025-06-02",
            "pub_date_card": {
                "ru": "2 Ğ¸ÑĞ½Ñ",
                "en": "June 2",
                "zh": "6æœˆ2æ—¥"
            },
            "hash": "788495117e4bf1d7",
            "authors": [
                "Manan Suri",
                "Puneet Mathur",
                "Nedim Lipka",
                "Franck Dernoncourt",
                "Ryan A. Rossi",
                "Vivek Gupta",
                "Dinesh Manocha"
            ],
            "affiliations": [
                "Adobe",
                "University of Maryland"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.01344.jpg",
            "data": {
                "categories": [
                    "#graphs",
                    "#cv",
                    "#reasoning",
                    "#agents",
                    "#hallucinations",
                    "#multimodal",
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "ğŸ”€",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ Ğ±Ğ»Ğ¾Ğº-ÑÑ…ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸ Ğ±Ğ»Ğ¾Ğº-ÑÑ…ĞµĞ¼ Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° FlowPathAgent Ğ´Ğ»Ñ ĞµĞµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ»Ğ¾Ğº-ÑÑ…ĞµĞ¼Ñƒ, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ ĞµĞµ Ğ² ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ³Ñ€Ğ°Ñ„ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ÑƒÑ‚ĞµĞ¹ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸. Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº FlowExplainBench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¹ Ğ±Ğ»Ğ¾Ğº-ÑÑ…ĞµĞ¼. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ FlowPathAgent ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾ Ğ±Ğ»Ğ¾Ğº-ÑÑ…ĞµĞ¼Ğ°Ğ¼, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ½Ğ° 10-14%."
                },
                "en": {
                    "title": "Enhancing Flowchart Interpretation with Fine-grained Attribution",
                    "desc": "This paper addresses the challenges of interpreting flowcharts using large language models (LLMs) due to their complex structures and potential for hallucination. It introduces Fine-grained Flowchart Attribution, a method that links LLM responses to specific components of flowcharts, enhancing the reliability and explainability of automated processing. The authors present FlowPathAgent, a neurosymbolic agent that utilizes graph-based reasoning to segment flowcharts and create structured symbolic graphs for dynamic interaction. Experimental results demonstrate that FlowPathAgent significantly reduces hallucinations in LLM outputs, achieving improved performance on the newly introduced FlowExplainBench benchmark."
                },
                "zh": {
                    "title": "æå‡æµç¨‹å›¾è§£æçš„å¯é æ€§ä¸å¯è§£é‡Šæ€§",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„ä»»åŠ¡ï¼Œç§°ä¸ºç»†ç²’åº¦æµç¨‹å›¾å½’å› ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†æµç¨‹å›¾æ—¶çš„å¯é æ€§å’Œå¯è§£é‡Šæ€§ã€‚æˆ‘ä»¬æå‡ºäº†FlowPathAgentï¼Œè¿™æ˜¯ä¸€ç§ç¥ç»ç¬¦å·ä»£ç†ï¼Œé€šè¿‡å›¾å½¢æ¨ç†è¿›è¡Œç»†ç²’åº¦çš„åæœŸå½’å› ã€‚è¯¥ä»£ç†é¦–å…ˆå¯¹æµç¨‹å›¾è¿›è¡Œåˆ†å‰²ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„ç¬¦å·å›¾ï¼Œå¹¶åŠ¨æ€ä¸å›¾è¿›è¡Œäº¤äº’ï¼Œä»¥ç”Ÿæˆå½’å› è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFlowPathAgentåœ¨æµç¨‹å›¾é—®ç­”ä¸­å‡å°‘äº†è§†è§‰å¹»è§‰ï¼Œç›¸è¾ƒäºå¼ºåŸºçº¿æé«˜äº†10-14%çš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23807",
            "title": "DLP: Dynamic Layerwise Pruning in Large Language Models",
            "url": "https://huggingface.co/papers/2505.23807",
            "abstract": "A dynamic layerwise pruning method adaptively determines layer importance by combining model weights and activation information to maintain performance in large language models at high sparsity.  \t\t\t\t\tAI-generated summary \t\t\t\t Pruning has recently been widely adopted to reduce the parameter scale and improve the inference efficiency of Large Language Models (LLMs). Mainstream pruning techniques often rely on uniform layerwise pruning strategies, which can lead to severe performance degradation at high sparsity levels. Recognizing the varying contributions of different layers in LLMs, recent studies have shifted their focus toward non-uniform layerwise pruning. However, these approaches often rely on pre-defined values, which can result in suboptimal performance. To overcome these limitations, we propose a novel method called Dynamic Layerwise Pruning (DLP). This approach adaptively determines the relative importance of each layer by integrating model weights with input activation information, assigning pruning rates accordingly. Experimental results show that DLP effectively preserves model performance at high sparsity levels across multiple LLMs. Specifically, at 70% sparsity, DLP reduces the perplexity of LLaMA2-7B by 7.79 and improves the average accuracy by 2.7% compared to state-of-the-art methods. Moreover, DLP is compatible with various existing LLM compression techniques and can be seamlessly integrated into Parameter-Efficient Fine-Tuning (PEFT). We release the code at https://github.com/ironartisan/DLP to facilitate future research.",
            "score": 1,
            "issue_id": 4133,
            "pub_date": "2025-05-27",
            "pub_date_card": {
                "ru": "27 Ğ¼Ğ°Ñ",
                "en": "May 27",
                "zh": "5æœˆ27æ—¥"
            },
            "hash": "a817afc0cdd35d8d",
            "authors": [
                "Yuli Chen",
                "Bo Cheng",
                "Jiale Han",
                "Yingying Zhang",
                "Yingting Li",
                "Shuhao Zhang"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology, Hong Kong, China",
                "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23807.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#training"
                ],
                "emoji": "âœ‚ï¸",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ° ÑĞ»Ğ¾ĞµĞ² Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¿Ğ¾ÑĞ»Ğ¾Ğ¹Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ¸ (DLP) Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. DLP Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ñ, ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ²ĞµÑĞ°Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸ÑÑ…. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¼ ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ DLP Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Dynamic Layerwise Pruning: Smart Sparsity for Language Models",
                    "desc": "This paper introduces a new method called Dynamic Layerwise Pruning (DLP) that improves the efficiency of large language models (LLMs) by adaptively determining the importance of each layer. Unlike traditional pruning methods that apply uniform strategies, DLP combines model weights and activation data to assign specific pruning rates to different layers. This approach helps maintain model performance even at high levels of sparsity, which is crucial for effective model compression. Experimental results demonstrate that DLP significantly enhances accuracy and reduces perplexity in LLMs compared to existing techniques."
                },
                "zh": {
                    "title": "åŠ¨æ€å‰ªæï¼Œæ™ºèƒ½ä¿æŒæ€§èƒ½ï¼",
                    "desc": "åŠ¨æ€å±‚çº§å‰ªææ–¹æ³•é€šè¿‡ç»“åˆæ¨¡å‹æƒé‡å’Œæ¿€æ´»ä¿¡æ¯ï¼Œè‡ªé€‚åº”åœ°ç¡®å®šæ¯ä¸€å±‚çš„é‡è¦æ€§ï¼Œä»è€Œåœ¨é«˜ç¨€ç–æ€§ä¸‹ä¿æŒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚ä¼ ç»Ÿçš„å‰ªææŠ€æœ¯é€šå¸¸é‡‡ç”¨å‡åŒ€å±‚çº§å‰ªæç­–ç•¥ï¼Œè¿™å¯èƒ½å¯¼è‡´åœ¨é«˜ç¨€ç–æ€§æ°´å¹³ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚åŠ¨æ€å±‚çº§å‰ªæï¼ˆDLPï¼‰æ–¹æ³•å…‹æœäº†è¿™ä¸€é™åˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥æ¿€æ´»ä¿¡æ¯åŠ¨æ€è°ƒæ•´å‰ªæç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDLPåœ¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸­æœ‰æ•ˆåœ°ä¿æŒäº†é«˜ç¨€ç–æ€§ä¸‹çš„æ¨¡å‹æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.21541",
            "title": "DiffDecompose: Layer-Wise Decomposition of Alpha-Composited Images via\n  Diffusion Transformers",
            "url": "https://huggingface.co/papers/2505.21541",
            "abstract": "DiffDecompose, a diffusion Transformer-based framework, effectively decomposes images into constituent layers with semantic prompts, addressing challenges in transparent layer decomposition.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion models have recently motivated great success in many generation tasks like object removal. Nevertheless, existing image decomposition methods struggle to disentangle semi-transparent or transparent layer occlusions due to mask prior dependencies, static object assumptions, and the lack of datasets. In this paper, we delve into a novel task: Layer-Wise Decomposition of Alpha-Composited Images, aiming to recover constituent layers from single overlapped images under the condition of semi-transparent/transparent alpha layer non-linear occlusion. To address challenges in layer ambiguity, generalization, and data scarcity, we first introduce AlphaBlend, the first large-scale and high-quality dataset for transparent and semi-transparent layer decomposition, supporting six real-world subtasks (e.g., translucent flare removal, semi-transparent cell decomposition, glassware decomposition). Building on this dataset, we present DiffDecompose, a diffusion Transformer-based framework that learns the posterior over possible layer decompositions conditioned on the input image, semantic prompts, and blending type. Rather than regressing alpha mattes directly, DiffDecompose performs In-Context Decomposition, enabling the model to predict one or multiple layers without per-layer supervision, and introduces Layer Position Encoding Cloning to maintain pixel-level correspondence across layers. Extensive experiments on the proposed AlphaBlend dataset and public LOGO dataset verify the effectiveness of DiffDecompose. The code and dataset will be available upon paper acceptance. Our code will be available at: https://github.com/Wangzt1121/DiffDecompose.",
            "score": 1,
            "issue_id": 4133,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "cda6015909393ad0",
            "authors": [
                "Zitong Wang",
                "Hang Zhao",
                "Qianyu Zhou",
                "Xuequan Lu",
                "Xiangtai Li",
                "Yiren Song"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2505.21541.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#open_source",
                    "#cv",
                    "#dataset"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° ÑĞ»Ğ¾Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                    "desc": "DiffDecompose - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° Ğ´Ğ»Ñ Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ»Ğ¾Ğ¸. ĞĞ½Ğ° Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑƒĞ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ñ‹Ñ… Ğ¸ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹, Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼Ğ¸ Ğ½Ğµ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞ»Ğ¸ÑÑŒ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ AlphaBlend Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. DiffDecompose Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑƒÑĞ»Ğ¾Ğ²Ğ½Ğ¾Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ»Ğ¾ĞµĞ² Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Revolutionizing Image Layer Decomposition with DiffDecompose",
                    "desc": "This paper introduces DiffDecompose, a novel framework that uses diffusion Transformers to decompose images into their individual layers, particularly focusing on transparent and semi-transparent layers. The authors highlight the limitations of existing methods in handling complex occlusions and propose a new dataset called AlphaBlend, which is designed to support various real-world image decomposition tasks. DiffDecompose employs In-Context Decomposition to predict multiple layers without needing direct supervision for each layer, enhancing its ability to generalize across different scenarios. The framework's effectiveness is validated through extensive experiments on the AlphaBlend dataset and the public LOGO dataset, showcasing its potential in image processing applications."
                },
                "zh": {
                    "title": "é€æ˜å±‚åˆ†è§£çš„æ–°çªç ´ï¼šDiffDecompose",
                    "desc": "DiffDecompose æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£ Transformer çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†å›¾åƒåˆ†è§£ä¸ºç»„æˆå±‚ï¼Œå¹¶ä½¿ç”¨è¯­ä¹‰æç¤ºæ¥è§£å†³é€æ˜å±‚åˆ†è§£ä¸­çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é’ˆå¯¹åŠé€æ˜å’Œé€æ˜å›¾å±‚çš„éçº¿æ€§é®æŒ¡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡ï¼šé€å±‚åˆ†è§£ alpha åˆæˆå›¾åƒã€‚ä¸ºäº†è§£å†³å±‚æ¨¡ç³Šã€æ³›åŒ–èƒ½åŠ›å’Œæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œç ”ç©¶è€…ä»¬é¦–æ¬¡å¼•å…¥äº† AlphaBlend æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®é™…åº”ç”¨åœºæ™¯ã€‚DiffDecompose é€šè¿‡ä¸Šä¸‹æ–‡åˆ†è§£çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰é€å±‚ç›‘ç£çš„æƒ…å†µä¸‹é¢„æµ‹ä¸€ä¸ªæˆ–å¤šä¸ªå±‚ï¼Œå±•ç¤ºäº†å…¶åœ¨å›¾åƒåˆ†è§£ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-06-04.html",
    "link_next": "2025-06-06.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "04.06",
        "en": "06/04",
        "zh": "6æœˆ4æ—¥"
    },
    "short_date_next": {
        "ru": "06.06",
        "en": "06/06",
        "zh": "6æœˆ6æ—¥"
    },
    "categories": {
        "#dataset": 7,
        "#data": 2,
        "#benchmark": 9,
        "#agents": 3,
        "#cv": 5,
        "#rl": 6,
        "#rlhf": 5,
        "#rag": 0,
        "#plp": 0,
        "#inference": 3,
        "#3d": 0,
        "#audio": 1,
        "#video": 2,
        "#multimodal": 6,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 4,
        "#healthcare": 0,
        "#training": 14,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 5,
        "#reasoning": 8,
        "#transfer_learning": 1,
        "#graphs": 1,
        "#ethics": 1,
        "#security": 1,
        "#optimization": 9,
        "#survey": 1,
        "#diffusion": 4,
        "#alignment": 2,
        "#story_generation": 1,
        "#hallucinations": 3,
        "#long_context": 3,
        "#synthetic": 3,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "VS-Benchæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€åŸºå‡†ï¼Œç”¨äºè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„ç­–ç•¥æ¨ç†å’Œå†³ç­–èƒ½åŠ›ã€‚ç°æœ‰çš„åŸºå‡†å¤§å¤šå±€é™äºå•æ™ºèƒ½ä½“æˆ–ä»…æ–‡æœ¬ç¯å¢ƒï¼Œè€ŒVS-BenchåŒ…å«å…«ä¸ªåŸºäºè§†è§‰çš„ç¯å¢ƒï¼Œæ¶µç›–åˆä½œã€ç«äº‰å’Œæ··åˆåŠ¨æœºçš„äº’åŠ¨ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰æ¨¡å‹åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œå½’ä¸€åŒ–å›æŠ¥æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚VS-Benchæ—¨åœ¨æ ‡å‡†åŒ–è¯„ä¼°å¹¶æŒ‡å‡ºç°æœ‰æ¨¡å‹çš„å±€é™æ€§ï¼Œæ¨åŠ¨æœªæ¥ç ”ç©¶ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨https://vs-bench.github.ioè·å–ã€‚",
        "title": "VS-Bench: Evaluating VLMs for Strategic Reasoning and Decision-Making in\n  Multi-Agent Environments",
        "pinyin": "ä»¥ä¸‹æ˜¯æ‚¨æä¾›çš„æ–‡æœ¬çš„æ‹¼éŸ³è½¬å†™ï¼š\n\nVS-Bench shÃ¬ yÄ«gÃ¨ duÅ mÃ³ tÃ i jÄ«zhÇ”n, yÃ²ngyÃº pÃ­nggÇ” shÃ¬juÃ© yÇ”yÃ¡n mÃ³xÃ­ng zÃ i fÃ¹zÃ¡ dÅu zhÃ¬nÃ©ngtÇ huÃ¡njÃ¬ng zhÅng de cÃ¨lÃ¼Ã¨ tuÄ«lÇ hÃ© juÃ©cÃ¨ nÃ©nglÃ¬. XiÃ n yÇ’u de jÄ«zhÇ”n dÃ duÅ jÃºxÃ¬an zÃ i dÄn zhÃ¬nÃ©ngtÇ huÃ² jÇn wÃ©nbÄ›n huÃ¡njÃ¬ng, Ã©r VS-Bench hÃ¡n yÇ’u bÄ gÃ¨ jÄ«chÇ” shÃ¬juÃ© de huÃ¡njÃ¬ng, hÃ¡nfÃ¹ hÃ©zuÃ², jÃ¬ngzhÄ“ng hÃ© hÃ¹nhÃ© dÃ²ngjÄ« de hÃ¹dÃ²ng. YÃ¡njiÅ« fÄxiÃ n, xiÃ n yÇ’u mÃ³xÃ­ng zÃ i yÃ¹cÃ¨ zhÇ”nquÃ¨xÃ¬ng hÃ© guÄ«yÄ«huÃ  huÃ­bÃ o fÄngmiÃ n cÃºnzÃ i xiÇnzhÃ¹ chÄjÃ¹. VS-Bench zhÇ yÃº biÄozhÇ”nhuÃ  pÃ­nggÇ” Ã©r zhÇchÅ« xiÃ n yÇ’u mÃ³xÃ­ng de jÃºxÃ¬anxÃ¬ng, tuÄ«dÃ²ng wÃ¨ilÃ¡i yÃ¡njiÅ«. DÃ imÇ hÃ© shÃ¹jÃ¹ kÄ› zÃ i https://vs-bench.github.io huÃ²qÇ”.",
        "vocab": "[{'word': 'å¤šæ¨¡æ€', 'pinyin': 'duÅ mÃ³ tÃ i', 'trans': 'multimodal'}, {'word': 'åŸºå‡†', 'pinyin': 'jÄ« zhÇ”n', 'trans': 'benchmark'}, {'word': 'è§†è§‰è¯­è¨€æ¨¡å‹', 'pinyin': 'shÃ¬ juÃ© yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'vision-language model'}, {'word': 'å¤æ‚', 'pinyin': 'fÃ¹ zÃ¡', 'trans': 'complex'}, {'word': 'å¤šæ™ºèƒ½ä½“', 'pinyin': 'duÅ zhÃ¬ nÃ©ng tÇ', 'trans': 'multi-agent'}, {'word': 'ç¯å¢ƒ', 'pinyin': 'huÃ¡n jÃ¬ng', 'trans': 'environment'}, {'word': 'ç­–ç•¥æ¨ç†', 'pinyin': 'cÃ¨ lÃ¼Ã¨ tuÄ« lÇ', 'trans': 'strategic reasoning'}, {'word': 'å†³ç­–', 'pinyin': 'juÃ© cÃ¨', 'trans': 'decision-making'}, {'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©ng lÃ¬', 'trans': 'ability'}, {'word': 'å±€é™äº', 'pinyin': 'jÃº xiÃ n yÃº', 'trans': 'limited to'}, {'word': 'å•æ™ºèƒ½ä½“', 'pinyin': 'dÄn zhÃ¬ nÃ©ng tÇ', 'trans': 'single-agent'}, {'word': 'ä»…', 'pinyin': 'jÇn', 'trans': 'only'}, {'word': 'æ–‡æœ¬', 'pinyin': 'wÃ©n bÄ›n', 'trans': 'text'}, {'word': 'æ¶µç›–', 'pinyin': 'hÃ¡n gÃ i', 'trans': 'cover'}, {'word': 'åˆä½œ', 'pinyin': 'hÃ© zuÃ²', 'trans': 'cooperation'}, {'word': 'ç«äº‰', 'pinyin': 'jÃ¬ng zhÄ“ng', 'trans': 'competition'}, {'word': 'æ··åˆ', 'pinyin': 'hÃ¹n hÃ©', 'trans': 'hybrid'}, {'word': 'åŠ¨æœº', 'pinyin': 'dÃ²ng jÄ«', 'trans': 'motivation'}, {'word': 'äº’åŠ¨', 'pinyin': 'hÃ¹ dÃ²ng', 'trans': 'interaction'}, {'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡n jiÅ«', 'trans': 'research'}, {'word': 'å‘ç°', 'pinyin': 'fÄ xiÃ n', 'trans': 'find'}, {'word': 'é¢„æµ‹', 'pinyin': 'yÃ¹ cÃ¨', 'trans': 'prediction'}, {'word': 'å‡†ç¡®æ€§', 'pinyin': 'zhÇ”n quÃ¨ xÃ¬ng', 'trans': 'accuracy'}, {'word': 'å½’ä¸€åŒ–', 'pinyin': 'guÄ« yÄ« huÃ ', 'trans': 'normalization'}, {'word': 'å›æŠ¥', 'pinyin': 'huÃ­ bÃ o', 'trans': 'reward'}, {'word': 'æ–¹é¢', 'pinyin': 'fÄng miÃ n', 'trans': 'aspect'}, {'word': 'å­˜åœ¨', 'pinyin': 'cÃºn zÃ i', 'trans': 'exist'}, {'word': 'æ˜¾è‘—', 'pinyin': 'xiÇn zhÃ¹', 'trans': 'significant'}, {'word': 'å·®è·', 'pinyin': 'chÄ jÃ¹', 'trans': 'gap'}, {'word': 'æ—¨åœ¨', 'pinyin': 'zhÇ zÃ i', 'trans': 'aim to'}, {'word': 'æ ‡å‡†åŒ–', 'pinyin': 'biÄo zhÇ”n huÃ ', 'trans': 'standardize'}, {'word': 'è¯„ä¼°', 'pinyin': 'pÃ­ng gÅ«', 'trans': 'evaluate'}, {'word': 'æŒ‡å‡º', 'pinyin': 'zhÇ chÅ«', 'trans': 'point out'}, {'word': 'å±€é™æ€§', 'pinyin': 'jÃº xiÃ n xÃ¬ng', 'trans': 'limitation'}, {'word': 'æ¨åŠ¨', 'pinyin': 'tuÄ« dÃ²ng', 'trans': 'promote'}, {'word': 'æœªæ¥', 'pinyin': 'wÃ¨i lÃ¡i', 'trans': 'future'}, {'word': 'ä»£ç ', 'pinyin': 'dÃ i mÇ', 'trans': 'code'}, {'word': 'æ•°æ®', 'pinyin': 'shÃ¹ jÃ¹', 'trans': 'data'}, {'word': 'è·å–', 'pinyin': 'huÃ² qÇ”', 'trans': 'obtain'}]",
        "trans": "VS-Bench is a multimodal benchmark designed to evaluate the strategic reasoning and decision-making capabilities of vision-language models in complex multi-agent environments. Existing benchmarks are largely limited to single-agent or text-only environments, whereas VS-Bench includes eight visually-based environments that encompass cooperative, competitive, and mixed-motive interactions. Research has revealed significant gaps in the predictive accuracy and normalized returns of existing models. VS-Bench aims to standardize evaluations and highlight the limitations of current models, driving future research. The code and data are available at https://vs-bench.github.io.",
        "update_ts": "2025-06-04 09:12"
    }
}