{
    "date": {
        "ru": "30 октября",
        "en": "October 30",
        "zh": "10月30日"
    },
    "time_utc": "2024-10-30 16:15",
    "weekday": 2,
    "issue_id": 342,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2410.18057",
            "title": "CLEAR: Character Unlearning in Textual and Visual Modalities",
            "url": "https://huggingface.co/papers/2410.18057",
            "abstract": "Machine Unlearning (MU) is critical for enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs), by removing specific private or hazardous information. While MU has made significant progress in textual and visual modalities, multimodal unlearning (MMU) remains significantly underexplored, partially due to the absence of a suitable open-source benchmark. To address this, we introduce CLEAR, a new benchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious individuals and 3,700 images linked with corresponding question-answer pairs, enabling a thorough evaluation across modalities. We assess 10 MU methods, adapting them for MMU, and highlight new challenges specific to multimodal forgetting. We also demonstrate that simple ell_1 regularization on LoRA weights significantly mitigates catastrophic forgetting, preserving model performance on retained data. The dataset is available at https://huggingface.co/datasets/therem/CLEAR",
            "score": 163,
            "issue_id": 337,
            "pub_date": "2024-10-23",
            "pub_date_card": {
                "ru": "23 октября",
                "en": "October 23",
                "zh": "10月23日"
            },
            "hash": "ce7b8092b3ce7ef9",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "CLEAR: Новый стандарт для мультимодального разобучения в ИИ",
                    "desc": "Статья представляет новый бенчмарк CLEAR для оценки методов мультимодального разобучения (MMU) в больших мультимодальных языковых моделях (MLLM). CLEAR содержит данные о 200 вымышленных личностях, включая 3700 изображений с соответствующими парами вопрос-ответ. Авторы адаптировали и оценили 10 методов машинного разобучения (MU) для мультимодальных задач. Исследование показало, что простая L1-регуляризация весов LoRA значительно снижает катастрофическое забывание, сохраняя производительность модели на оставшихся данных."
                },
                "en": {
                    "title": "Enhancing Privacy with Multimodal Unlearning: Introducing CLEAR",
                    "desc": "This paper focuses on Machine Unlearning (MU), which is important for protecting privacy in deep learning models, especially in large multimodal language models (MLLMs). The authors identify a gap in multimodal unlearning (MMU) research and introduce CLEAR, a new benchmark that includes 200 fictitious individuals and 3,700 images with question-answer pairs for evaluating MMU methods. They assess 10 existing MU methods adapted for MMU and reveal unique challenges related to forgetting in multimodal contexts. Additionally, they find that applying simple ell_1 regularization on LoRA weights can help reduce catastrophic forgetting, thus maintaining the model's performance on the data that remains."
                },
                "zh": {
                    "title": "CLEAR：多模态遗忘的新基准",
                    "desc": "机器遗忘（MU）在深度学习模型中对于增强隐私和安全性至关重要，尤其是在大型多模态语言模型（MLLMs）中。尽管在文本和视觉模态上，MU已经取得了显著进展，但多模态遗忘（MMU）仍然未被充分探索，部分原因是缺乏合适的开源基准。为了解决这个问题，我们引入了CLEAR，一个新的基准，用于评估MMU方法。CLEAR包含200个虚构个体和3700张与相应问答对相关的图像，能够全面评估不同模态的遗忘效果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.20424",
            "title": "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions",
            "url": "https://huggingface.co/papers/2410.20424",
            "abstract": "Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKaggle implements an iterative development process that combines code execution, debugging, and comprehensive unit testing to ensure code correctness and logic consistency. The framework offers highly customizable workflows, allowing users to intervene at each phase, thus integrating automated intelligence with human expertise. Our universal data science toolkit, comprising validated functions for data cleaning, feature engineering, and modeling, forms the foundation of this solution, enhancing productivity by streamlining common tasks. We selected 8 Kaggle competitions to simulate data processing workflows in real-world application scenarios. Evaluation results demonstrate that AutoKaggle achieves a validation submission rate of 0.85 and a comprehensive score of 0.82 in typical data science pipelines, fully proving its effectiveness and practicality in handling complex data science tasks.",
            "score": 17,
            "issue_id": 335,
            "pub_date": "2024-10-27",
            "pub_date_card": {
                "ru": "27 октября",
                "en": "October 27",
                "zh": "10月27日"
            },
            "hash": "d86977fc81e85089",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#agents"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "AutoKaggle: ИИ-помощник для ускорения работы с данными",
                    "desc": "AutoKaggle - это мощный фреймворк для решения задач с табличными данными с помощью мультиагентной системы. Он использует итеративный процесс разработки, включающий выполнение кода, отладку и модульное тестирование. Фреймворк предлагает настраиваемые рабочие процессы и универсальный набор инструментов для обработки данных. Оценка на 8 соревнованиях Kaggle показала высокую эффективность AutoKaggle в типичных задачах анализа данных."
                },
                "en": {
                    "title": "Empowering Data Science with AutoKaggle: Automation Meets Expertise",
                    "desc": "AutoKaggle is a framework designed to help data scientists manage complex tasks involving tabular data. It uses a collaborative multi-agent system to streamline data pipelines through an iterative process that includes code execution, debugging, and unit testing. The framework allows for customizable workflows, enabling users to integrate their expertise with automated processes. Evaluation on real-world Kaggle competitions shows that AutoKaggle significantly improves productivity and achieves high validation rates in data science tasks."
                },
                "zh": {
                    "title": "AutoKaggle：智能与人类的完美结合",
                    "desc": "本文提出了一个名为AutoKaggle的框架，旨在帮助数据科学家处理复杂的表格数据任务。该框架通过协作的多智能体系统，支持数据管道的自动化和用户干预，结合了代码执行、调试和单元测试的迭代开发过程。AutoKaggle提供了高度可定制的工作流程，允许用户在每个阶段进行干预，从而将自动智能与人类专业知识相结合。通过在8个Kaggle竞赛中进行模拟，评估结果显示AutoKaggle在数据科学管道中具有良好的有效性和实用性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19609",
            "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization",
            "url": "https://huggingface.co/papers/2410.19609",
            "abstract": "The rapid development of large language and multimodal models has sparked significant interest in using proprietary models, such as GPT-4o, to develop autonomous agents capable of handling real-world scenarios like web navigation. Although recent open-source efforts have tried to equip agents with the ability to explore environments and continuously improve over time, they are building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents struggle to generalize to realistic settings that require multimodal perception abilities and lack ground-truth signals. In this paper, we introduce an open-source framework designed to facilitate the development of multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets.",
            "score": 11,
            "issue_id": 336,
            "pub_date": "2024-10-25",
            "pub_date_card": {
                "ru": "25 октября",
                "en": "October 25",
                "zh": "10月25日"
            },
            "hash": "c9775abc4b4ddd0d",
            "data": {
                "categories": [
                    "#agents",
                    "#multimodal",
                    "#rl"
                ],
                "emoji": "🕸️",
                "ru": {
                    "title": "Самообучающиеся мультимодальные веб-агенты для реального мира",
                    "desc": "Эта статья представляет открытую платформу для разработки мультимодальных веб-агентов, способных к автономному исследованию реального мира и самосовершенствованию. Базовая модель обучается с помощью имитационного обучения, затем агент исследует открытый веб и собирает обратную связь. Далее агент улучшает свою стратегию, обучаясь на успешных траекториях, оцененных другой универсальной моделью. Экспериментальные результаты показывают, что веб-агент успешно улучшается после каждой итерации этого цикла."
                },
                "en": {
                    "title": "Empowering Web Agents with Multimodal Learning and Self-Improvement",
                    "desc": "This paper presents an open-source framework for developing multimodal web agents that can autonomously explore real-world environments. Unlike previous text-only agents that operate in synthetic settings, this framework allows agents to learn from real web interactions and improve their performance over time. The approach utilizes imitation learning to establish a baseline capability, followed by an exploration-feedback-optimization cycle where the agent refines its policy based on feedback from its own experiences. Experimental results indicate that the agent effectively enhances its skills through iterative learning, showcasing its ability to adapt and perform well in diverse scenarios."
                },
                "zh": {
                    "title": "自主多模态网络代理的探索与优化",
                    "desc": "本文介绍了一种开源框架，旨在开发能够自主进行真实世界探索的多模态网络代理。我们首先通过模仿学习训练基础模型，使其获得基本能力。然后，代理在开放网络中探索并收集其轨迹的反馈，进一步通过学习表现良好的轨迹来优化其策略。实验结果表明，该网络代理在每次迭代后成功自我改进，在多个测试集上表现出色。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.21411",
            "title": "SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization",
            "url": "https://huggingface.co/papers/2410.21411",
            "abstract": "Social relation reasoning aims to identify relation categories such as friends, spouses, and colleagues from images. While current methods adopt the paradigm of training a dedicated network end-to-end using labeled image data, they are limited in terms of generalizability and interpretability. To address these issues, we first present a simple yet well-crafted framework named {\\name}, which combines the perception capability of Vision Foundation Models (VFMs) and the reasoning capability of Large Language Models (LLMs) within a modular framework, providing a strong baseline for social relation recognition. Specifically, we instruct VFMs to translate image content into a textual social story, and then utilize LLMs for text-based reasoning. {\\name} introduces systematic design principles to adapt VFMs and LLMs separately and bridge their gaps. Without additional model training, it achieves competitive zero-shot results on two databases while offering interpretable answers, as LLMs can generate language-based explanations for the decisions. The manual prompt design process for LLMs at the reasoning phase is tedious and an automated prompt optimization method is desired. As we essentially convert a visual classification task into a generative task of LLMs, automatic prompt optimization encounters a unique long prompt optimization issue. To address this issue, we further propose the Greedy Segment Prompt Optimization (GSPO), which performs a greedy search by utilizing gradient information at the segment level. Experimental results show that GSPO significantly improves performance, and our method also generalizes to different image styles. The code is available at https://github.com/Mengzibin/SocialGPT.",
            "score": 11,
            "issue_id": 335,
            "pub_date": "2024-10-28",
            "pub_date_card": {
                "ru": "28 октября",
                "en": "October 28",
                "zh": "10月28日"
            },
            "hash": "ad99b3e3b4ef165c",
            "data": {
                "categories": [
                    "#cv",
                    "#multimodal",
                    "#interpretability",
                    "#long_context"
                ],
                "emoji": "👥",
                "ru": {
                    "title": "SocialGPT: объединение зрения и языка для интерпретируемого распознавания социальных отношений",
                    "desc": "Эта статья представляет новый подход к распознаванию социальных отношений на изображениях, названный SocialGPT. Метод объединяет возможности восприятия Визуальных Фундаментальных Моделей (VFM) и способности рассуждения Больших Языковых Моделей (LLM) в модульную структуру. SocialGPT переводит содержание изображения в текстовую социальную историю с помощью VFM, а затем использует LLM для рассуждений на основе текста. Авторы также предлагают метод оптимизации промптов под названием Greedy Segment Prompt Optimization (GSPO) для улучшения производительности."
                },
                "en": {
                    "title": "Bridging Vision and Language for Social Relation Recognition",
                    "desc": "This paper introduces a new framework called SocialGPT for social relation reasoning, which identifies relationships like friends or colleagues from images. It combines Vision Foundation Models (VFMs) for image analysis with Large Language Models (LLMs) for reasoning, allowing for better generalization and interpretability. The framework translates visual content into textual narratives and uses LLMs to reason about these narratives, achieving competitive results without additional training. Additionally, it proposes a method called Greedy Segment Prompt Optimization (GSPO) to enhance the performance of LLMs by optimizing prompts effectively, leading to improved outcomes across various image styles."
                },
                "zh": {
                    "title": "社交关系推理的新方法：结合视觉与语言的力量",
                    "desc": "社交关系推理旨在从图像中识别关系类别，如朋友、配偶和同事。当前的方法通常采用端到端的专用网络训练方式，但在泛化能力和可解释性方面存在局限。为了解决这些问题，我们提出了一个名为SocialGPT的框架，结合了视觉基础模型（VFM）和大型语言模型（LLM）的感知能力与推理能力。该方法在不额外训练模型的情况下，在两个数据库上实现了竞争性的零样本结果，并提供了可解释的答案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.22304",
            "title": "Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning",
            "url": "https://huggingface.co/papers/2410.22304",
            "abstract": "Mathematical reasoning is a crucial capability for Large Language Models (LLMs), yet generating detailed and accurate reasoning traces remains a significant challenge. This paper introduces a novel approach to produce high-quality reasoning traces for LLM fine-tuning using online learning Flows. Our method employs an incremental output production Flow, where component LLMs collaboratively construct solutions through iterative communication. We train the Flow using online Direct Preference Optimization (DPO) learning with rollouts, generating DPO pairs for each training example and updating models in real-time. We directly compare the quality of reasoning traces generated by our method with those produced through direct model inference, demonstrating the effectiveness of our approach in improving LLM performance in mathematical reasoning tasks.",
            "score": 8,
            "issue_id": 334,
            "pub_date": "2024-10-29",
            "pub_date_card": {
                "ru": "29 октября",
                "en": "October 29",
                "zh": "10月29日"
            },
            "hash": "ffb1cb8e8855bf5d",
            "data": {
                "categories": [
                    "#math",
                    "#rlhf",
                    "#reasoning"
                ],
                "emoji": "🧮",
                "ru": {
                    "title": "Улучшение математических рассуждений LLM через онлайн-обучение потоков",
                    "desc": "Эта статья представляет новый подход к созданию качественных цепочек рассуждений для дообучения больших языковых моделей (LLM) в задачах математических рассуждений. Метод использует инкрементальный процесс построения решения, где компонентные LLM совместно конструируют решение через итеративное взаимодействие. Обучение происходит с помощью онлайн-оптимизации прямых предпочтений (DPO) с использованием развёртываний, генерируя пары для DPO для каждого обучающего примера и обновляя модели в реальном времени. Авторы напрямую сравнивают качество цепочек рассуждений, созданных их методом, с теми, что получены прямым выводом модели, демонстрируя эффективность подхода в улучшении производительности LLM в задачах математических рассуждений."
                },
                "en": {
                    "title": "Enhancing Mathematical Reasoning in LLMs with Collaborative Learning Flows",
                    "desc": "This paper addresses the challenge of generating accurate reasoning traces for Large Language Models (LLMs) in mathematical tasks. It presents a new method that uses online learning Flows, where multiple LLMs work together to create solutions through iterative communication. The training process involves Direct Preference Optimization (DPO) with rollouts, allowing real-time updates and improvements. The results show that this approach significantly enhances the quality of reasoning traces compared to traditional model inference methods."
                },
                "zh": {
                    "title": "提升大型语言模型的数学推理能力",
                    "desc": "本文探讨了大型语言模型（LLMs）在数学推理中的能力，尤其是生成详细和准确的推理过程的挑战。我们提出了一种新方法，通过在线学习流（Flows）来生成高质量的推理过程，以便对LLM进行微调。该方法采用增量输出生成流，多个组件LLM通过迭代通信共同构建解决方案。我们使用在线直接偏好优化（DPO）学习进行训练，实时更新模型，从而提高LLM在数学推理任务中的表现。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.22325",
            "title": "Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Dataset",
            "url": "https://huggingface.co/papers/2410.22325",
            "abstract": "The pre-training of visual representations has enhanced the efficiency of robot learning. Due to the lack of large-scale in-domain robotic datasets, prior works utilize in-the-wild human videos to pre-train robotic visual representation. Despite their promising results, representations from human videos are inevitably subject to distribution shifts and lack the dynamics information crucial for task completion. We first evaluate various pre-trained representations in terms of their correlation to the downstream robotic manipulation tasks (i.e., manipulation centricity). Interestingly, we find that the \"manipulation centricity\" is a strong indicator of success rates when applied to downstream tasks. Drawing from these findings, we propose Manipulation Centric Representation (MCR), a foundation representation learning framework capturing both visual features and the dynamics information such as actions and proprioceptions of manipulation tasks to improve manipulation centricity. Specifically, we pre-train a visual encoder on the DROID robotic dataset and leverage motion-relevant data such as robot proprioceptive states and actions. We introduce a novel contrastive loss that aligns visual observations with the robot's proprioceptive state-action dynamics, combined with a behavior cloning (BC)-like actor loss to predict actions during pre-training, along with a time contrastive loss. Empirical results across 4 simulation domains with 20 tasks verify that MCR outperforms the strongest baseline method by 14.8%. Moreover, MCR boosts the performance of data-efficient learning with a UR5e arm on 3 real-world tasks by 76.9%. Project website: https://robots-pretrain-robots.github.io/.",
            "score": 5,
            "issue_id": 335,
            "pub_date": "2024-10-29",
            "pub_date_card": {
                "ru": "29 октября",
                "en": "October 29",
                "zh": "10月29日"
            },
            "hash": "b8a6dec29ce881c9",
            "data": {
                "categories": [
                    "#agents",
                    "#robotics",
                    "#dataset"
                ],
                "emoji": "🦾",
                "ru": {
                    "title": "Улучшение роботизированных манипуляций через предобучение с учетом динамики",
                    "desc": "Эта статья представляет новый подход к предобучению визуальных представлений для робототехники под названием Manipulation Centric Representation (MCR). MCR использует датасет DROID и информацию о движениях робота для улучшения эффективности манипуляций. Авторы вводят новую контрастивную функцию потерь, которая сопоставляет визуальные наблюдения с динамикой состояний и действий робота. Эмпирические результаты показывают, что MCR превосходит базовые методы на 14.8% в симуляциях и на 76.9% в реальных задачах."
                },
                "en": {
                    "title": "Enhancing Robot Learning with Manipulation Centric Representation",
                    "desc": "This paper discusses the importance of pre-training visual representations for improving robot learning efficiency. It highlights the challenges posed by using human videos for training, which can lead to distribution shifts and a lack of essential dynamic information. The authors introduce a new framework called Manipulation Centric Representation (MCR) that integrates visual features with dynamic data from robotic tasks to enhance performance. Their empirical results show that MCR significantly outperforms existing methods in both simulation and real-world tasks, demonstrating its effectiveness in robotic manipulation."
                },
                "zh": {
                    "title": "操作中心表示：提升机器人学习效率的关键",
                    "desc": "本论文探讨了视觉表示的预训练如何提高机器人学习的效率。由于缺乏大规模的领域内机器人数据集，之前的研究利用人类视频进行预训练，但这些视频的表示存在分布偏移，并缺乏完成任务所需的动态信息。我们提出了一种新的表示学习框架，称为操作中心表示（MCR），它同时捕捉视觉特征和操作任务的动态信息。实验结果表明，MCR在多个模拟领域和真实任务中显著提高了机器人的操作性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.21845",
            "title": "Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning",
            "url": "https://huggingface.co/papers/2410.21845",
            "abstract": "Reinforcement learning (RL) holds great promise for enabling autonomous acquisition of complex robotic manipulation skills, but realizing this potential in real-world settings has been challenging. We present a human-in-the-loop vision-based RL system that demonstrates impressive performance on a diverse set of dexterous manipulation tasks, including dynamic manipulation, precision assembly, and dual-arm coordination. Our approach integrates demonstrations and human corrections, efficient RL algorithms, and other system-level design choices to learn policies that achieve near-perfect success rates and fast cycle times within just 1 to 2.5 hours of training. We show that our method significantly outperforms imitation learning baselines and prior RL approaches, with an average 2x improvement in success rate and 1.8x faster execution. Through extensive experiments and analysis, we provide insights into the effectiveness of our approach, demonstrating how it learns robust, adaptive policies for both reactive and predictive control strategies. Our results suggest that RL can indeed learn a wide range of complex vision-based manipulation policies directly in the real world within practical training times. We hope this work will inspire a new generation of learned robotic manipulation techniques, benefiting both industrial applications and research advancements. Videos and code are available at our project website https://hil-serl.github.io/.",
            "score": 4,
            "issue_id": 334,
            "pub_date": "2024-10-29",
            "pub_date_card": {
                "ru": "29 октября",
                "en": "October 29",
                "zh": "10月29日"
            },
            "hash": "b8302dbf79e25f7d",
            "data": {
                "categories": [
                    "#rl",
                    "#rlhf",
                    "#robotics"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Человек и ИИ: совместное обучение роботов сложным манипуляциям",
                    "desc": "В этой статье представлена система обучения с подкреплением (RL) для роботизированной манипуляции с участием человека. Система демонстрирует впечатляющие результаты в различных задачах ловкой манипуляции, включая динамическую манипуляцию, точную сборку и координацию двух рук. Подход интегрирует демонстрации и коррекции человека, эффективные алгоритмы RL и другие системные решения для обучения политик с почти идеальным уровнем успеха за 1-2,5 часа тренировки. Результаты показывают значительное превосходство над базовыми методами имитационного обучения и предыдущими подходами RL."
                },
                "en": {
                    "title": "Empowering Robots with Human-guided Reinforcement Learning for Complex Manipulation",
                    "desc": "This paper presents a novel human-in-the-loop reinforcement learning (RL) system designed for robotic manipulation tasks. By combining human demonstrations and corrections with efficient RL algorithms, the system achieves high success rates and quick training times for complex tasks like dynamic manipulation and dual-arm coordination. The results show a significant improvement over traditional imitation learning and previous RL methods, with a twofold increase in success rates and faster execution times. The findings indicate that RL can effectively learn complex manipulation skills in real-world scenarios, paving the way for advancements in robotic applications."
                },
                "zh": {
                    "title": "人机协作强化学习：实现复杂机器人操作的突破",
                    "desc": "强化学习（RL）在自主获取复杂机器人操作技能方面具有很大潜力，但在现实环境中实现这一潜力面临挑战。我们提出了一种人机协作的基于视觉的RL系统，在多种灵巧操作任务中表现出色，包括动态操作、精密组装和双臂协调。该方法结合了演示和人类纠正、有效的RL算法以及其他系统设计选择，使得在仅1到2.5小时的训练内学习到接近完美的成功率和快速的循环时间。我们的实验结果表明，该方法在成功率和执行速度上显著优于模仿学习基线和之前的RL方法，展示了RL在现实世界中学习复杂视觉操作策略的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.21465",
            "title": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference",
            "url": "https://huggingface.co/papers/2410.21465",
            "abstract": "With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each token generation both result in low throughput when serving long-context LLMs. While various dynamic sparse attention methods have been proposed to speed up inference while maintaining generation quality, they either fail to sufficiently reduce GPU memory consumption or introduce significant decoding latency by offloading the KV cache to the CPU. We present ShadowKV, a high-throughput long-context LLM inference system that stores the low-rank key cache and offloads the value cache to reduce the memory footprint for larger batch sizes and longer sequences. To minimize decoding latency, ShadowKV employs an accurate KV selection strategy that reconstructs minimal sparse KV pairs on-the-fly. By evaluating ShadowKV on a broad range of benchmarks, including RULER, LongBench, and Needle In A Haystack, and models like Llama-3.1-8B, Llama-3-8B-1M, GLM-4-9B-1M, Yi-9B-200K, Phi-3-Mini-128K, and Qwen2-7B-128K, we demonstrate that it can support up to 6times larger batch sizes and boost throughput by up to 3.04times on an A100 GPU without sacrificing accuracy, even surpassing the performance achievable with infinite batch size under the assumption of infinite GPU memory. The code is available at https://github.com/bytedance/ShadowKV.",
            "score": 3,
            "issue_id": 334,
            "pub_date": "2024-10-28",
            "pub_date_card": {
                "ru": "28 октября",
                "en": "October 28",
                "zh": "10月28日"
            },
            "hash": "f954b9ea6eb1a3ff",
            "data": {
                "categories": [
                    "#inference",
                    "#long_context",
                    "#benchmark"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "ShadowKV: Ускорение вывода длинноконтекстных LLM без компромиссов",
                    "desc": "Статья представляет ShadowKV - систему для высокопроизводительного вывода длинноконтекстных больших языковых моделей (LLM). ShadowKV хранит кэш ключей низкого ранга и выгружает кэш значений для уменьшения объема памяти, что позволяет обрабатывать большие пакеты и длинные последовательности. Система использует точную стратегию выбора KV, восстанавливая минимальные разреженные пары KV на лету для минимизации задержки декодирования. Эксперименты показали, что ShadowKV может увеличить размер пакета до 6 раз и повысить производительность до 3,04 раз на GPU A100 без потери точности."
                },
                "en": {
                    "title": "Boosting Long-Context LLM Inference with ShadowKV",
                    "desc": "The paper introduces ShadowKV, a system designed to enhance the efficiency of long-context large language model (LLM) inference. It addresses the challenges of high memory usage and low throughput caused by the expanding key-value (KV) cache during token generation. ShadowKV reduces memory consumption by storing a low-rank key cache while offloading the value cache, allowing for larger batch sizes and longer sequences. The system also implements a KV selection strategy that dynamically reconstructs sparse KV pairs, significantly improving throughput without compromising accuracy."
                },
                "zh": {
                    "title": "高效推理，提升长上下文模型性能",
                    "desc": "随着长上下文大语言模型（LLMs）的广泛应用，对高吞吐量推理的需求不断增加。本文提出了ShadowKV，一个高吞吐量的长上下文LLM推理系统，通过存储低秩键缓存并将值缓存卸载，从而减少内存占用。ShadowKV采用准确的KV选择策略，实时重构最小稀疏KV对，以降低解码延迟。实验结果表明，ShadowKV在多个基准测试中表现优异，支持更大的批量大小并显著提高吞吐量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.20088",
            "title": "RARe: Retrieval Augmented Retrieval with In-Context Examples",
            "url": "https://huggingface.co/papers/2410.20088",
            "abstract": "We investigate whether in-context examples, widely used in decoder-only language models (LLMs), can improve embedding model performance in retrieval tasks. Unlike in LLMs, naively prepending in-context examples (query-document pairs) to the target query at inference time does not work out of the box. We introduce a simple approach to enable retrievers to use in-context examples. Our approach, RARe, finetunes a pre-trained model with in-context examples whose query is semantically similar to the target query. This can be applied to adapt various base architectures (i.e., decoder-only language models, retriever models) and consistently achieves performance gains of up to +2.72% nDCG across various open-domain retrieval datasets (BeIR, RAR-b). In particular, we find RARe exhibits stronger out-of-domain generalization compared to models using queries without in-context examples, similar to what is seen for in-context learning in LLMs. We further provide analysis on the design choices of in-context example augmentation and lay the foundation for future work in this space.",
            "score": 1,
            "issue_id": 342,
            "pub_date": "2024-10-26",
            "pub_date_card": {
                "ru": "26 октября",
                "en": "October 26",
                "zh": "10月26日"
            },
            "hash": "03c6d910a07fe4c7",
            "data": {
                "categories": [
                    "#rag",
                    "#training",
                    "#benchmark"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Улучшение поисковых систем с помощью обучения на примерах в контексте",
                    "desc": "Исследователи изучают возможность улучшения работы моделей встраивания в задачах поиска с помощью примеров в контексте, широко используемых в языковых моделях. Предложен метод RARe, который дообучает предварительно обученную модель с использованием семантически схожих примеров в контексте. Этот подход демонстрирует улучшение производительности до 2.72% nDCG на различных наборах данных для поиска в открытом домене. RARe также показывает более сильную обобщающую способность вне домена по сравнению с моделями, не использующими примеры в контексте."
                },
                "en": {
                    "title": "Enhancing Retrieval with In-Context Examples: The RARe Approach",
                    "desc": "This paper explores the use of in-context examples to enhance the performance of embedding models in retrieval tasks. Unlike decoder-only language models, simply adding these examples to queries does not yield immediate benefits. The authors propose a method called RARe, which fine-tunes a pre-trained model using semantically similar in-context examples to the target query. Their approach shows consistent performance improvements, achieving up to +2.72% nDCG across various datasets, and demonstrates better out-of-domain generalization compared to traditional methods."
                },
                "zh": {
                    "title": "利用上下文示例提升检索模型性能",
                    "desc": "本文研究了在检索任务中，使用上下文示例是否能提高嵌入模型的性能。与语言模型不同，简单地将上下文示例添加到目标查询并不能直接奏效。我们提出了一种简单的方法RARe，通过对预训练模型进行微调，使其能够使用与目标查询语义相似的上下文示例。实验结果表明，RARe在多个开放域检索数据集上实现了最高+2.72%的nDCG性能提升，并展现出更强的领域外泛化能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.21333",
            "title": "Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse",
            "url": "https://huggingface.co/papers/2410.21333",
            "abstract": "Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning.",
            "score": 1,
            "issue_id": 341,
            "pub_date": "2024-10-27",
            "pub_date_card": {
                "ru": "27 октября",
                "en": "October 27",
                "zh": "10月27日"
            },
            "hash": "c5caddd15a467732",
            "data": {
                "categories": [
                    "#interpretability",
                    "#reasoning",
                    "#multimodal"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Когда размышления вредят: ограничения CoT в языковых моделях",
                    "desc": "Статья исследует влияние промптинга с цепочкой рассуждений (CoT) на производительность языковых моделей. Авторы выявляют задачи, где CoT снижает эффективность, опираясь на примеры из когнитивной психологии. Эксперименты показывают значительное падение точности современных моделей при использовании CoT в определенных сценариях. Исследование устанавливает связь между литературой о человеческих рассуждениях и оценкой CoT в контексте языковых моделей."
                },
                "en": {
                    "title": "Understanding When Chain-of-Thought Prompting Fails in AI Models",
                    "desc": "This paper investigates the effectiveness of Chain-of-Thought (CoT) prompting in large language and multimodal models, particularly focusing on when it may hinder performance. By drawing parallels from cognitive psychology, the authors explore scenarios where verbal reasoning negatively impacts human performance and whether these scenarios apply to language models. Through extensive experiments, they demonstrate that certain tasks, such as implicit statistical learning and visual recognition, can lead to significant performance drops in models when using CoT prompting. The findings suggest that understanding human cognitive limitations can provide insights into optimizing model performance and prompt design."
                },
                "zh": {
                    "title": "链式思维的影响：何时有益，何时有害",
                    "desc": "链式思维（CoT）提示是一种在大型语言和多模态模型中广泛使用的策略。本文探讨了在何种情况下链式思维会降低模型性能，借鉴了认知心理学的研究。通过对隐性统计学习、视觉识别和包含例外的模式分类等任务的实验，我们发现使用推理时的链式思维会导致模型性能显著下降。我们的研究表明，理解人类思维对模型性能的影响，可以帮助我们更好地选择提示和推理策略。"
                }
            }
        }
    ],
    "link_prev": "2024-10-29.html",
    "link_next": "2024-10-31.html",
    "short_date_prev": {
        "ru": "29.10",
        "en": "10/29",
        "zh": "10月29日"
    },
    "short_date_next": {
        "ru": "31.10",
        "en": "10/31",
        "zh": "10月31日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 3,
        "#agents": 3,
        "#cv": 1,
        "#rl": 2,
        "#rlhf": 2,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 4,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#medicine": 0,
        "#training": 1,
        "#robotics": 2,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 2,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 2
    },
    "zh": {
        "text": "这篇文章讨论了机器取消学习（MU）在深度学习模型中增强隐私和安全的重要性，特别是在大型多模态语言模型（MLLMs）中。虽然MU在文本和视觉模态上取得了显著进展，但多模态取消学习（MMU）仍然没有得到充分研究，部分原因是缺乏合适的开源基准。为了解决这个问题，作者引入了CLEAR，一个新的基准，用于评估MMU方法。CLEAR包含200个虚构个体和3700张图片，并附有相应的问答对，可以进行跨模态的全面评估。作者评估了10种MU方法，并指出了多模态遗忘的新挑战。他们还展示了简单的ell_1正则化可以显著减轻灾难性遗忘，保持模型在保留数据上的性能。数据集可在https://huggingface.co/datasets/therem/CLEAR获取。",
        "title": "CLEAR: Character Unlearning in Textual and Visual Modalities",
        "pinyin": "这篇文章讨论了机器取消学习（MU）在深度学习模型中增强隐私和安全的重要性，特别是在大型多模态语言模型（MLLMs）中。虽然MU在文本和视觉模态上取得了显著进展，但多模态取消学习（MMU）仍然没有得到充分研究，部分原因是缺乏合适的开源基准。为了解决这个问题，作者引入了CLEAR，一个新的基准，用于评估MMU方法。CLEAR包含200个虚构个体和3700张图片，并附有相应的问答对，可以进行跨模态的全面评估。作者评估了10种MU方法，并指出了多模态遗忘的新挑战。他们还展示了简单的ell_1正则化可以显著减轻灾难性遗忘，保持模型在保留数据上的性能。数据集可在https://huggingface.co/datasets/therem/CLEAR获取。\n\nzhè piān wén zhāng tǎo lùn le jī qì qǔ xiāo xué (MU) zài shēn dù xué xí mó xìng zhōng zēng qiáng yǐn sī hé ān quán de zhòng yào xìng, tè bié shì zài dà xíng duō mó shuài yǔ yán mó xìng (MLLMs) zhōng. suī rán MU zài wén běn hé shì jué mó tài shàng qu dé le xiǎn zhù jìn zhǎn, dàn duō mó shuài qǔ xiāo xué (MMU) réng rán méi yǒu dé dào chóng fèn yán jiū, bù fèn yuán yīn shì quē fá hé shì de kāi yuán jī zhǔn. wèi le jiě jué zhè gè wèn tí, zuò zhě yǐn rù le CLEAR, yī gè xīn de jī zhǔn, yòng yú píng guā MMU fāng fǎ. CLEAR bāo hán 200 gè xū gòu gè tǐ hé 3700 zhāng tú piàn, bìng fù yǒu xiāng yìng de wèn dá duì, kě yǐ jìn xíng kuà mó shuài de quán miàn píng guā. zuò zhě píng guā le 10 zhǒng MU fāng fǎ, bìng zhǐ chū le duō mó shuài yí wàng de xīn tiǎo zhàn. tā men hái zhǎn shì le jiǎn dān de ell_1 zhèng guī huà kě yǐ xiǎn zhù jiǎn qīng zāi nàn xìng yí wàng, bǎo chí mó xìng zài bǎo liú shù jù shàng de xiào nèng. shù jù jí kě zài https://huggingface.co/datasets/therem/CLEAR huò qǔ.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"机器取消学习\", \"pinyin\": \"jī qì qǔ xiāo xué xí\", \"trans\": \"machine unlearning\"},\n    {\"word\": \"增强\", \"pinyin\": \"zēng qiáng\", \"trans\": \"enhance\"},\n    {\"word\": \"隐私\", \"pinyin\": \"yǐn sī\", \"trans\": \"privacy\"},\n    {\"word\": \"安全\", \"pinyin\": \"ān quán\", \"trans\": \"security\"},\n    {\"word\": \"深度学习模型\", \"pinyin\": \"shēn dù xué xí mó xíng\", \"trans\": \"deep learning model\"},\n    {\"word\": \"多模态语言模型\", \"pinyin\": \"duō mó shuài yǔ yán mó xíng\", \"trans\": \"multimodal language model\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"进展\", \"pinyin\": \"jìn zhǎn\", \"trans\": \"progress\"},\n    {\"word\": \"多模态取消学习\", \"pinyin\": \"duō mó shuài qǔ xiāo xué xí\", \"trans\": \"multimodal unlearning\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"合适\", \"pinyin\": \"hé shì\", \"trans\": \"suitable\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāi yuán\", \"trans\": \"open-source\"},\n    {\"word\": \"基准\", \"pinyin\": \"jī zhǔn\", \"trans\": \"benchmark\"},\n    {\"word\": \"引入\", \"pinyin\": \"yǐn rù\", \"trans\": \"introduce\"},\n    {\"word\": \"评估\", \"pinyin\": \"píng gū\", \"trans\": \"evaluate\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"虚构\", \"pinyin\": \"xū gòu\", \"trans\": \"fictional\"},\n    {\"word\": \"个体\", \"pinyin\": \"gè tǐ\", \"trans\": \"individual\"},\n    {\"word\": \"图片\", \"pinyin\": \"tú piàn\", \"trans\": \"image\"},\n    {\"word\": \"问答对\", \"pinyin\": \"wèn dá duì\", \"trans\": \"question-answer pair\"},\n    {\"word\": \"跨模态\", \"pinyin\": \"kuà mó shuài\", \"trans\": \"cross-modal\"},\n    {\"word\": \"全面\", \"pinyin\": \"quán miàn\", \"trans\": \"comprehensive\"},\n    {\"word\": \"遗忘\", \"pinyin\": \"yí wàng\", \"trans\": \"forgetting\"},\n    {\"word\": \"挑战\", \"pinyin\": \"tiǎo zhàn\", \"trans\": \"challenge\"},\n    {\"word\": \"正则化\", \"pinyin\": \"zhèng zé huà\", \"trans\": \"regularization\"},\n    {\"word\": \"减轻\", \"pinyin\": \"jiǎn qīng\", \"trans\": \"alleviate\"},\n    {\"word\": \"灾难性\", \"pinyin\": \"zāi nàn xìng\", \"trans\": \"catastrophic\"},\n    {\"word\": \"保持\", \"pinyin\": \"bǎo chí\", \"trans\": \"maintain\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shù jù jí\", \"trans\": \"dataset\"}\n]",
        "trans": "This article discusses the importance of machine unlearning (MU) in enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs). Although MU has made significant progress in text and visual modalities, multimodal unlearning (MMU) remains under-researched, partly due to the lack of suitable open-source benchmarks. To address this issue, the authors introduce CLEAR, a new benchmark for evaluating MMU methods. CLEAR contains 200 fictional individuals and 3,700 images, along with corresponding question-answer pairs, allowing for comprehensive cross-modal evaluation. The authors evaluated 10 MU methods and highlighted new challenges in multimodal forgetting. They also demonstrated that simple ell_1 regularization can significantly mitigate catastrophic forgetting, maintaining the model's performance on retained data. The dataset is available at https://huggingface.co/datasets/therem/CLEAR.",
        "update_ts": "2024-10-30 10:13"
    }
}