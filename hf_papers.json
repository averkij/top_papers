{
    "date": {
        "ru": "31 марта",
        "en": "March 31",
        "zh": "3月31日"
    },
    "time_utc": "2025-03-31 02:26",
    "weekday": 0,
    "issue_id": 2971,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.22675",
            "title": "Think Before Recommend: Unleashing the Latent Reasoning Power for\n  Sequential Recommendation",
            "url": "https://huggingface.co/papers/2503.22675",
            "abstract": "Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose ReaRec, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\\%-50\\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",
            "score": 7,
            "issue_id": 2971,
            "pub_date": "2025-03-28",
            "pub_date_card": {
                "ru": "28 марта",
                "en": "March 28",
                "zh": "3月28日"
            },
            "hash": "092ab2fa75277891",
            "authors": [
                "Jiakai Tang",
                "Sunhao Dai",
                "Teng Shi",
                "Jun Xu",
                "Xu Chen",
                "Wen Chen",
                "Wu Jian",
                "Yuning Jiang"
            ],
            "affiliations": [
                "Alibaba Group, Beijing, China",
                "Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.22675.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#reasoning",
                    "#dataset",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Многошаговое рассуждение для улучшения рекомендаций",
                    "desc": "ReaRec - это новый фреймворк для систем рекомендаций, использующий многошаговое рассуждение во время вывода для улучшения представления пользователей. Он применяет авторегрессивную подачу последнего скрытого состояния последовательности в рекомендательную систему, используя специальные эмбеддинги позиций рассуждения. Авторы также предлагают два метода обучения на основе рассуждений: Ensemble Reasoning Learning (ERL) и Progressive Reasoning Learning (PRL). Эксперименты показывают, что ReaRec значительно повышает эффективность различных архитектур последовательных рекомендательных систем."
                },
                "en": {
                    "title": "ReaRec: Elevating Sequential Recommendations with Multi-Step Reasoning",
                    "desc": "This paper introduces ReaRec, a novel framework for Sequential Recommendation (SeqRec) that enhances user representation through multi-step reasoning. Traditional methods often rely on a single forward computation, which limits their ability to capture the evolving nature of user preferences and understand less popular items. ReaRec addresses these limitations by using autoregressive techniques and special embeddings to improve the inference process. The proposed framework, along with two learning methods, shows significant performance improvements across various datasets, suggesting a new direction for research in recommendation systems."
                },
                "zh": {
                    "title": "ReaRec：提升顺序推荐的推理能力",
                    "desc": "顺序推荐（SeqRec）旨在通过捕捉用户历史交互中的顺序模式来预测下一个项目，这在许多现实世界的推荐系统中起着关键作用。现有方法主要采用直接的前向计算范式，最终的隐藏状态作为用户表示，但这种方法在建模用户偏好的复杂演变方面存在局限。为了解决这个问题，我们提出了ReaRec，这是第一个用于推荐系统的推理时计算框架，通过隐式多步推理增强用户表示。我们的实验表明，ReaRec显著提高了多个顺序推荐模型的性能，开辟了推理时计算的新研究方向。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.22194",
            "title": "ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation",
            "url": "https://huggingface.co/papers/2503.22194",
            "abstract": "We introduce ORIGEN, the first zero-shot method for 3D orientation grounding in text-to-image generation across multiple objects and diverse categories. While previous work on spatial grounding in image generation has mainly focused on 2D positioning, it lacks control over 3D orientation. To address this, we propose a reward-guided sampling approach using a pretrained discriminative model for 3D orientation estimation and a one-step text-to-image generative flow model. While gradient-ascent-based optimization is a natural choice for reward-based guidance, it struggles to maintain image realism. Instead, we adopt a sampling-based approach using Langevin dynamics, which extends gradient ascent by simply injecting random noise--requiring just a single additional line of code. Additionally, we introduce adaptive time rescaling based on the reward function to accelerate convergence. Our experiments show that ORIGEN outperforms both training-based and test-time guidance methods across quantitative metrics and user studies.",
            "score": 2,
            "issue_id": 2971,
            "pub_date": "2025-03-28",
            "pub_date_card": {
                "ru": "28 марта",
                "en": "March 28",
                "zh": "3月28日"
            },
            "hash": "6d93cc886c16f9b0",
            "authors": [
                "Yunhong Min",
                "Daehyeon Choi",
                "Kyeongmin Yeo",
                "Jihyun Lee",
                "Minhyuk Sung"
            ],
            "affiliations": [
                "KAIST"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.22194.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#optimization",
                    "#3d"
                ],
                "emoji": "🧭",
                "ru": {
                    "title": "Точное управление 3D ориентацией объектов при генерации изображений",
                    "desc": "ORIGEN - это первый метод для определения 3D ориентации объектов при генерации изображений из текста без предварительного обучения. Он использует предобученную дискриминативную модель для оценки 3D ориентации и одношаговую генеративную модель текст-изображение. Вместо градиентного спуска применяется семплирование на основе динамики Ланжевена с добавлением случайного шума. Эксперименты показывают превосходство ORIGEN над другими методами по количественным метрикам и оценкам пользователей."
                },
                "en": {
                    "title": "Revolutionizing 3D Orientation in Text-to-Image Generation with ORIGEN",
                    "desc": "ORIGEN is a novel method that enables zero-shot 3D orientation grounding in text-to-image generation, allowing for better control over how objects are oriented in three-dimensional space. Unlike previous methods that focused on 2D positioning, ORIGEN utilizes a reward-guided sampling approach that leverages a pretrained model for estimating 3D orientations. This method incorporates Langevin dynamics to enhance image realism while maintaining effective sampling, requiring minimal code changes. Experimental results demonstrate that ORIGEN surpasses existing training-based and test-time guidance techniques in both quantitative metrics and user evaluations."
                },
                "zh": {
                    "title": "ORIGEN：文本到图像生成中的3D方向定位新方法",
                    "desc": "我们介绍了ORIGEN，这是首个用于文本到图像生成中实现3D方向定位的零样本方法。以往的研究主要集中在2D定位上，缺乏对3D方向的控制。为了解决这个问题，我们提出了一种基于奖励引导的采样方法，利用预训练的判别模型进行3D方向估计，并结合一步文本到图像生成流模型。实验结果表明，ORIGEN在定量指标和用户研究中均优于基于训练和测试时引导的方法。"
                }
            }
        }
    ],
    "link_prev": "2025-03-28.html",
    "link_next": "2025-04-01.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "28.03",
        "en": "03/28",
        "zh": "3月28日"
    },
    "short_date_next": {
        "ru": "01.04",
        "en": "04/01",
        "zh": "4月1日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种名为Video-R1的新方法，用于在多模态大语言模型中激发视频推理能力。受DeepSeek-R1成功的启发，作者提出了T-GRPO算法，以解决直接应用RL训练中的时间建模和高质量数据缺乏的问题。他们还创建了两个包含图像和视频数据的数据集，并展示了Video-R1在多个视频推理基准上的显著改进。特别是，Video-R1-7B在VSI-bench上的准确率达到了35.8%，超越了商业模型GPT-4o。所有代码、模型和数据都已公开。",
        "title": "Video-R1: Reinforcing Video Reasoning in MLLMs",
        "pinyin": "这篇文章介绍了一种名为Video-R1的新方法，用于在多模态大语言模型中激发视频推理能力。受DeepSeek-R1成功的启发，作者提出了T-GRPO算法，以解决直接应用RL训练中的时间建模和高质量数据缺乏的问题。他们还创建了两个包含图像和视频数据的数据集，并展示了Video-R1在多个视频推理基准上的显著改进。特别是，Video-R1-7B在VSI-bench上的准确率达到了35.8%，超越了商业模型GPT-4o。所有代码、模型和数据都已公开。\n\nzhè piān wén zhāng jiè shào le yī zhǒng míng wéi Video-R1 de xīn fāng fǎ, yòng yú zài duō mó tài dà yǔ yán mó xíng zhōng jī fā shì pǐn tuī lǐ néng lì. shòu DeepSeek-R1 chéng gōng de qǐ fǎ, zuò zhě tí chū le T-GRPO suàn fǎ, yǐ jiě jué zhí jiē yòng RL xùn liàn zhōng de shí jiān jiàn mó hé gāo zhì liàng shù jué de quē fá de wèn tí. tā men hái chuàng jiàn le liǎng gè bāo hán tú xiàng hé shì pǐn shù jué de shù ju ji, bìng zhàn shì le Video-R1 zài duō gè shì pǐn tuī lǐ jī zhǔn shàng de xiǎn zhù gǎi jìn. tè bié shì, Video-R1-7B zài VSI-bench shàng de zhǔn què lǜ dá dào le 35.8%, chāo yuè le shāng yè mó xíng GPT-4o. suǒ yǒu dài mǎ, mó xíng hé shù ju dōu yǐ gōng kāi.",
        "vocab": "[\n    {\"word\": \"多模态\", \"pinyin\": \"duō mó tài\", \"trans\": \"multimodal\"},\n    {\"word\": \"激发\", \"pinyin\": \"jī fā\", \"trans\": \"stimulate\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuī lǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"启发\", \"pinyin\": \"qǐ fā\", \"trans\": \"inspire\"},\n    {\"word\": \"提出\", \"pinyin\": \"tí chū\", \"trans\": \"propose\"},\n    {\"word\": \"算法\", \"pinyin\": \"suàn fǎ\", \"trans\": \"algorithm\"},\n    {\"word\": \"解决\", \"pinyin\": \"jiě jué\", \"trans\": \"solve\"},\n    {\"word\": \"直接\", \"pinyin\": \"zhí jiē\", \"trans\": \"direct\"},\n    {\"word\": \"应用\", \"pinyin\": \"yìng yòng\", \"trans\": \"application\"},\n    {\"word\": \"训练\", \"pinyin\": \"xùn liàn\", \"trans\": \"training\"},\n    {\"word\": \"时间\", \"pinyin\": \"shí jiān\", \"trans\": \"time\"},\n    {\"word\": \"建模\", \"pinyin\": \"jiàn mó\", \"trans\": \"modeling\"},\n    {\"word\": \"高质量\", \"pinyin\": \"gāo zhì liàng\", \"trans\": \"high quality\"},\n    {\"word\": \"缺乏\", \"pinyin\": \"quē fá\", \"trans\": \"lack\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shù jù jí\", \"trans\": \"dataset\"},\n    {\"word\": \"展示\", \"pinyin\": \"zhǎn shì\", \"trans\": \"demonstrate\"},\n    {\"word\": \"基准\", \"pinyin\": \"jī zhǔn\", \"trans\": \"benchmark\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"改进\", \"pinyin\": \"gǎi jìn\", \"trans\": \"improvement\"},\n    {\"word\": \"准确率\", \"pinyin\": \"zhǔn què lǜ\", \"trans\": \"accuracy\"},\n    {\"word\": \"超越\", \"pinyin\": \"chāo yuè\", \"trans\": \"surpass\"},\n    {\"word\": \"商业\", \"pinyin\": \"shāng yè\", \"trans\": \"commercial\"},\n    {\"word\": \"公开\", \"pinyin\": \"gōng kāi\", \"trans\": \"public\"}\n]",
        "trans": "This article introduces a new method called Video-R1 for eliciting video reasoning capabilities in multimodal large language models. Inspired by the success of DeepSeek-R1, the authors propose the T-GRPO algorithm to address the issues of temporal modeling in direct RL training and the lack of high-quality data. They also created two datasets containing image and video data and demonstrated significant improvements of Video-R1 on multiple video reasoning benchmarks. Notably, Video-R1-7B achieved an accuracy of 35.8% on the VSI-bench, surpassing the commercial model GPT-4o. All code, models, and data have been made publicly available.",
        "update_ts": "2025-03-30 12:41"
    }
}