{
    "date": {
        "ru": "7 июля",
        "en": "July 7",
        "zh": "7月7日"
    },
    "time_utc": "2025-07-07 05:15",
    "weekday": 0,
    "issue_id": 4672,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.01853",
            "title": "Eka-Eval : A Comprehensive Evaluation Framework for Large Language\n  Models in Indian Languages",
            "url": "https://huggingface.co/papers/2507.01853",
            "abstract": "EKA-EVAL is a comprehensive multilingual evaluation framework for large language models, supporting diverse benchmarks and features for efficient distributed inference and GPU usage.  \t\t\t\t\tAI-generated summary \t\t\t\t The rapid advancement of Large Language Models (LLMs) has intensified the need for evaluation frameworks that go beyond English centric benchmarks and address the requirements of linguistically diverse regions such as India. We present EKA-EVAL, a unified and production-ready evaluation framework that integrates over 35 benchmarks, including 10 Indic-specific datasets, spanning categories like reasoning, mathematics, tool use, long-context understanding, and reading comprehension. Compared to existing Indian language evaluation tools, EKA-EVAL offers broader benchmark coverage, with built-in support for distributed inference, quantization, and multi-GPU usage. Our systematic comparison positions EKA-EVAL as the first end-to-end, extensible evaluation suite tailored for both global and Indic LLMs, significantly lowering the barrier to multilingual benchmarking. The framework is open-source and publicly available at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA initiative (https://eka.soket.ai), which aims to scale up to over 100 benchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.",
            "score": 1,
            "issue_id": 4672,
            "pub_date": "2025-07-02",
            "pub_date_card": {
                "ru": "2 июля",
                "en": "July 2",
                "zh": "7月2日"
            },
            "hash": "a397a0d71f721623",
            "authors": [
                "Samridhi Raj Sinha",
                "Rajvee Sheth",
                "Abhishek Upperwal",
                "Mayank Singh"
            ],
            "affiliations": [
                "Indian Institute of Technology Gandhinagar",
                "LINGO Research Group",
                "NMIMS",
                "Soket AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.01853.jpg",
            "data": {
                "categories": [
                    "#low_resource",
                    "#multilingual",
                    "#open_source",
                    "#benchmark"
                ],
                "emoji": "🌏",
                "ru": {
                    "title": "EKA-EVAL: Универсальная платформа для оценки многоязычных языковых моделей",
                    "desc": "EKA-EVAL - это комплексная многоязычная система оценки больших языковых моделей (LLM), поддерживающая разнообразные бенчмарки. Она включает более 35 тестов, в том числе 10 наборов данных для индийских языков, охватывающих такие категории, как рассуждение, математика, использование инструментов и понимание длинного контекста. EKA-EVAL предлагает встроенную поддержку распределенного вывода, квантизации и использования нескольких GPU. Эта система позиционируется как первый комплексный инструмент оценки, адаптированный как для глобальных, так и для индийских LLM."
                },
                "en": {
                    "title": "Empowering Multilingual Evaluation for Large Language Models",
                    "desc": "EKA-EVAL is a multilingual evaluation framework designed for large language models (LLMs), focusing on diverse linguistic needs, particularly in regions like India. It includes over 35 benchmarks, with specific datasets for Indic languages, covering various tasks such as reasoning and reading comprehension. The framework supports efficient distributed inference and multi-GPU usage, making it suitable for production environments. EKA-EVAL aims to lower the barriers for multilingual benchmarking and is part of a larger initiative to expand its benchmark offerings."
                },
                "zh": {
                    "title": "EKA-EVAL：多语言模型评估的新标准",
                    "desc": "EKA-EVAL是一个全面的多语言评估框架，专为大型语言模型设计。它支持多种基准测试和功能，能够高效地进行分布式推理和GPU使用。该框架整合了超过35个基准，包括10个特定于印度的数据库，涵盖推理、数学、工具使用、长文本理解和阅读理解等类别。EKA-EVAL是首个为全球和印度语言模型量身定制的端到端可扩展评估套件，显著降低了多语言基准测试的门槛。"
                }
            }
        }
    ],
    "link_prev": "2025-07-04.html",
    "link_next": "2025-07-08.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "04.07",
        "en": "07/04",
        "zh": "7月4日"
    },
    "short_date_next": {
        "ru": "08.07",
        "en": "07/08",
        "zh": "7月8日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    }
}