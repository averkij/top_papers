{
    "date": {
        "ru": "12 мая",
        "en": "May 12",
        "zh": "5月12日"
    },
    "time_utc": "2025-05-12 12:21",
    "weekday": 0,
    "issue_id": 3709,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.02550",
            "title": "Bielik v3 Small: Technical Report",
            "url": "https://huggingface.co/papers/2505.02550",
            "abstract": "We introduce Bielik v3, a series of parameter-efficient generative text models (1.5B and 4.5B) optimized for Polish language processing. These models demonstrate that smaller, well-optimized architectures can achieve performance comparable to much larger counterparts while requiring substantially fewer computational resources. Our approach incorporates several key innovations: a custom Polish tokenizer (APT4) that significantly improves token efficiency, Weighted Instruction Cross-Entropy Loss to balance learning across instruction types, and Adaptive Learning Rate that dynamically adjusts based on training progress. Trained on a meticulously curated corpus of 292 billion tokens spanning 303 million documents, these models excel across multiple benchmarks, including the Open PL LLM Leaderboard, Complex Polish Text Understanding Benchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter model achieves results competitive with models 2-3 times its size, while the 1.5B model delivers strong performance despite its extremely compact profile. These advances establish new benchmarks for parameter-efficient language modeling in less-represented languages, making high-quality Polish language AI more accessible for resource-constrained applications.",
            "score": 28,
            "issue_id": 3707,
            "pub_date": "2025-05-05",
            "pub_date_card": {
                "ru": "5 мая",
                "en": "May 5",
                "zh": "5月5日"
            },
            "hash": "a7c9d183be6447dd",
            "authors": [
                "Krzysztof Ociepa",
                "Łukasz Flis",
                "Remigiusz Kinas",
                "Krzysztof Wróbel",
                "Adrian Gwoździej"
            ],
            "affiliations": [
                "ACK Cyfronet AGH",
                "Azurro",
                "Enelpol",
                "Jagiellonian University",
                "SpeakLeash"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.02550.jpg",
            "data": {
                "categories": [
                    "#small_models",
                    "#plp",
                    "#multilingual",
                    "#low_resource",
                    "#dataset",
                    "#benchmark"
                ],
                "emoji": "🇵🇱",
                "ru": {
                    "title": "Эффективные языковые модели делают ИИ на польском языке доступнее",
                    "desc": "Представлена серия Bielik v3 - эффективные генеративные текстовые модели для польского языка. Модели демонстрируют, что меньшие оптимизированные архитектуры могут достигать производительности сравнимой с гораздо более крупными аналогами. Ключевые инновации включают специальный польский токенизатор, взвешенную функцию потерь и адаптивную скорость обучения. Модели показывают отличные результаты в различных тестах, устанавливая новые стандарты для эффективного моделирования языка для менее распространенных языков."
                },
                "en": {
                    "title": "Efficient Polish Language Models: Big Performance from Small Sizes",
                    "desc": "Bielik v3 introduces efficient generative text models specifically designed for the Polish language, with sizes of 1.5B and 4.5B parameters. These models show that smaller architectures can perform as well as larger ones while using less computational power. Key innovations include a custom tokenizer for better token efficiency, a specialized loss function to balance learning, and an adaptive learning rate that adjusts during training. With training on a vast dataset, these models set new standards for language processing in Polish, making advanced AI more accessible for various applications."
                },
                "zh": {
                    "title": "高效波兰语生成模型的创新之路",
                    "desc": "我们介绍了Bielik v3，这是一系列针对波兰语处理的高效生成文本模型（1.5B和4.5B参数）。这些模型表明，较小且经过优化的架构可以在计算资源大幅减少的情况下，达到与更大模型相当的性能。我们的创新包括定制的波兰语分词器（APT4），显著提高了标记效率，以及加权指令交叉熵损失，平衡不同指令类型的学习。此外，动态调整的学习率根据训练进度进行调整，使得模型在多个基准测试中表现优异。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.02410",
            "title": "Bielik 11B v2 Technical Report",
            "url": "https://huggingface.co/papers/2505.02410",
            "abstract": "We present Bielik 11B v2, a state-of-the-art language model optimized for Polish text processing. Built on the Mistral 7B v0.2 architecture and scaled to 11B parameters using depth up-scaling, this model demonstrates exceptional performance across Polish language benchmarks while maintaining strong cross-lingual capabilities. We introduce two key technical innovations: Weighted Instruction Cross-Entropy Loss, which optimizes learning across diverse instruction types by assigning quality-based weights to training examples, and Adaptive Learning Rate, which dynamically adjusts based on context length. Comprehensive evaluation across multiple benchmarks demonstrates that Bielik 11B v2 outperforms many larger models, including those with 2-6 times more parameters, and significantly surpasses other specialized Polish language models on tasks ranging from linguistic understanding to complex reasoning. The model's parameter efficiency and extensive quantization options enable deployment across various hardware configurations, advancing Polish language AI capabilities and establishing new benchmarks for resource-efficient language modeling in less-represented languages.",
            "score": 25,
            "issue_id": 3707,
            "pub_date": "2025-05-05",
            "pub_date_card": {
                "ru": "5 мая",
                "en": "May 5",
                "zh": "5月5日"
            },
            "hash": "e9cb82cbeaac24ed",
            "authors": [
                "Krzysztof Ociepa",
                "Łukasz Flis",
                "Krzysztof Wróbel",
                "Adrian Gwoździej",
                "Remigiusz Kinas"
            ],
            "affiliations": [
                "ACK Cyfronet AGH",
                "Azurro",
                "Enelpol",
                "Jagiellonian University",
                "SpeakLeash"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.02410.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#multilingual",
                    "#low_resource",
                    "#training",
                    "#benchmark",
                    "#architecture",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "🇵🇱",
                "ru": {
                    "title": "Революция в обработке польского языка: Bielik 11B v2 устанавливает новые стандарты эффективности",
                    "desc": "Представлена модель Bielik 11B v2 - усовершенствованная языковая модель для обработки польских текстов. Основанная на архитектуре Mistral 7B v0.2 и масштабированная до 11 миллиардов параметров, она демонстрирует исключительную производительность на польских языковых бенчмарках. В модели применены две ключевые инновации: взвешенная функция потерь для инструкций и адаптивная скорость обучения. Bielik 11B v2 превосходит более крупные модели и устанавливает новые стандарты для эффективного моделирования языка с ограниченными ресурсами."
                },
                "en": {
                    "title": "Revolutionizing Polish Language Processing with Bielik 11B v2",
                    "desc": "Bielik 11B v2 is a cutting-edge language model specifically designed for processing Polish text. It utilizes the Mistral 7B v0.2 architecture and has been enhanced to 11 billion parameters, achieving remarkable results on Polish language tasks while also performing well in cross-lingual scenarios. The model introduces innovative techniques like Weighted Instruction Cross-Entropy Loss for better learning from diverse instructions and an Adaptive Learning Rate that adjusts based on the context length. Its efficiency and quantization options allow it to run on various hardware, making it a significant advancement in AI for Polish language applications."
                },
                "zh": {
                    "title": "波兰语处理的新标杆：Bielik 11B v2",
                    "desc": "Bielik 11B v2 是一个针对波兰语文本处理的先进语言模型，基于 Mistral 7B v0.2 架构，参数规模达到 11B。该模型在波兰语基准测试中表现出色，同时具备强大的跨语言能力。我们引入了两项关键技术创新：加权指令交叉熵损失，通过为训练样本分配基于质量的权重来优化不同指令类型的学习，以及自适应学习率，根据上下文长度动态调整。综合评估显示，Bielik 11B v2 超越了许多更大模型的表现，尤其在语言理解和复杂推理等任务上显著优于其他专门的波兰语言模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.06046",
            "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health\n  Information",
            "url": "https://huggingface.co/papers/2505.06046",
            "abstract": "As Large Language Models (LLMs) become widely accessible, a detailed understanding of their knowledge within specific domains becomes necessary for successful real world use. This is particularly critical in public health, where failure to retrieve relevant, accurate, and current information could significantly impact UK residents. However, currently little is known about LLM knowledge of UK Government public health information. To address this issue, this paper introduces a new benchmark, PubHealthBench, with over 8000 questions for evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form responses to public health queries, created via an automated pipeline. We also release a new dataset of the extracted UK Government public health guidance documents used as source text for PubHealthBench. Assessing 24 LLMs on PubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a high degree of knowledge, achieving >90% in the MCQA setup, and outperform humans with cursory search engine use. However, in the free form setup we see lower performance with no model scoring >75%. Therefore, whilst there are promising signs that state of the art (SOTA) LLMs are an increasingly accurate source of public health information, additional safeguards or tools may still be needed when providing free form responses on public health topics.",
            "score": 8,
            "issue_id": 3707,
            "pub_date": "2025-05-09",
            "pub_date_card": {
                "ru": "9 мая",
                "en": "May 9",
                "zh": "5月9日"
            },
            "hash": "c671de3a9e8ff4de",
            "authors": [
                "Joshua Harris",
                "Fan Grayson",
                "Felix Feldman",
                "Timothy Laurence",
                "Toby Nonnenmacher",
                "Oliver Higgins",
                "Leo Loman",
                "Selina Patel",
                "Thomas Finnie",
                "Samuel Collins",
                "Michael Borowitz"
            ],
            "affiliations": [
                "UK Health Security Agency (UKHSA)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.06046.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#science",
                    "#dataset",
                    "#healthcare",
                    "#benchmark"
                ],
                "emoji": "🏥",
                "ru": {
                    "title": "Оценка знаний LLM в сфере общественного здравоохранения: прогресс и ограничения",
                    "desc": "Статья представляет новый бенчмарк PubHealthBench для оценки знаний больших языковых моделей (LLM) в области общественного здравоохранения Великобритании. Бенчмарк содержит более 8000 вопросов для оценки ответов моделей на вопросы с множественным выбором и свободной формой. Исследование показало, что новейшие частные LLM достигают более 90% точности в задачах с множественным выбором, превосходя людей с поверхностным использованием поисковых систем. Однако в задачах со свободной формой ответа производительность моделей ниже, что указывает на необходимость дополнительных мер безопасности при использовании LLM для предоставления информации о здравоохранении."
                },
                "en": {
                    "title": "Evaluating LLMs for Public Health: Promising Yet Cautious",
                    "desc": "This paper investigates the knowledge of Large Language Models (LLMs) in the domain of UK public health information. It introduces a benchmark called PubHealthBench, which consists of over 8000 questions designed to evaluate LLMs' performance in Multiple Choice Question Answering (MCQA) and free form responses. The study assesses 24 different LLMs, revealing that the latest models perform well in MCQA tasks, achieving over 90% accuracy, but struggle with free form responses, none scoring above 75%. The findings suggest that while LLMs show promise as reliable sources of public health information, caution is needed when interpreting their free form outputs."
                },
                "zh": {
                    "title": "提升公共卫生信息的准确性",
                    "desc": "随着大型语言模型（LLMs）的广泛应用，了解它们在特定领域的知识变得至关重要，尤其是在公共卫生领域。本文提出了一个新的基准测试PubHealthBench，包含超过8000个问题，用于评估LLMs在公共卫生查询中的多项选择问答（MCQA）和自由形式回答的能力。研究发现，最新的私有LLMs（如GPT-4.5和GPT-4.1）在MCQA测试中表现优异，准确率超过90%，甚至超越了人类的搜索引擎使用。然而，在自由形式回答中，模型的表现较低，没有一个模型得分超过75%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.06111",
            "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
            "url": "https://huggingface.co/papers/2505.06111",
            "abstract": "A generalist robot should perform effectively across various environments. However, most existing approaches heavily rely on scaling action-annotated data to enhance their capabilities. Consequently, they are often limited to single physical specification and struggle to learn transferable knowledge across different embodiments and environments. To confront these limitations, we propose UniVLA, a new framework for learning cross-embodiment vision-language-action (VLA) policies. Our key innovation is to derive task-centric action representations from videos with a latent action model. This enables us to exploit extensive data across a wide spectrum of embodiments and perspectives. To mitigate the effect of task-irrelevant dynamics, we incorporate language instructions and establish a latent action model within the DINO feature space. Learned from internet-scale videos, the generalist policy can be deployed to various robots through efficient latent action decoding. We obtain state-of-the-art results across multiple manipulation and navigation benchmarks, as well as real-robot deployments. UniVLA achieves superior performance over OpenVLA with less than 1/20 of pretraining compute and 1/10 of downstream data. Continuous performance improvements are observed as heterogeneous data, even including human videos, are incorporated into the training pipeline. The results underscore UniVLA's potential to facilitate scalable and efficient robot policy learning.",
            "score": 6,
            "issue_id": 3704,
            "pub_date": "2025-05-09",
            "pub_date_card": {
                "ru": "9 мая",
                "en": "May 9",
                "zh": "5月9日"
            },
            "hash": "bf19981dd100b8fb",
            "authors": [
                "Qingwen Bu",
                "Yanting Yang",
                "Jisong Cai",
                "Shenyuan Gao",
                "Guanghui Ren",
                "Maoqing Yao",
                "Ping Luo",
                "Hongyang Li"
            ],
            "affiliations": [
                "AgiBot",
                "OpenDriveLab",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.06111.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#robotics",
                    "#training",
                    "#benchmark",
                    "#agents",
                    "#transfer_learning"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Универсальное обучение роботов через видео и язык",
                    "desc": "UniVLA - это новый фреймворк для обучения универсальных политик взаимодействия робота с окружающей средой на основе зрения, языка и действий. Ключевая инновация заключается в использовании скрытой модели действий для извлечения представлений из видео, что позволяет использовать разнородные данные из различных воплощений и перспектив. Фреймворк демонстрирует превосходные результаты на нескольких бенчмарках по манипуляции и навигации, а также в реальных роботизированных системах. UniVLA достигает лучшей производительности по сравнению с OpenVLA, используя при этом значительно меньше вычислительных ресурсов и данных."
                },
                "en": {
                    "title": "UniVLA: Empowering Robots with Cross-Embodiment Learning",
                    "desc": "The paper introduces UniVLA, a framework designed to enhance the capabilities of generalist robots by learning cross-embodiment vision-language-action (VLA) policies. It addresses the limitations of existing methods that depend on large amounts of action-annotated data and are restricted to specific physical forms. By utilizing a latent action model derived from videos, UniVLA can leverage diverse data sources and improve knowledge transfer across different robot embodiments and environments. The framework demonstrates state-of-the-art performance in various tasks while requiring significantly less computational resources and data compared to previous approaches."
                },
                "zh": {
                    "title": "UniVLA：提升通用机器人学习效率的新框架",
                    "desc": "本文提出了一种新的框架UniVLA，用于学习跨体现的视觉-语言-动作（VLA）策略，以提高通用机器人在不同环境中的表现。我们通过视频中的潜在动作模型提取以任务为中心的动作表示，从而利用广泛的多样化数据。为了减少与任务无关的动态影响，我们结合了语言指令，并在DINO特征空间中建立了潜在动作模型。实验结果表明，UniVLA在多个操作和导航基准测试中表现优异，且在预训练计算和下游数据方面的需求显著低于现有方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.05026",
            "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness",
            "url": "https://huggingface.co/papers/2505.05026",
            "abstract": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While recent Vision-Language Models (VLMs) can process automated UI analysis, current approaches focus on isolated design attributes rather than comparative persuasiveness-the key factor in optimizing user interactions. To address this, we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales. Additionally, we propose G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy. Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation. Through promoting VLM-driven evaluation of UI persuasiveness, our work offers an approach to complement A/B testing, propelling progress in scalable UI preference modeling and design optimization. Code and data will be released publicly.",
            "score": 5,
            "issue_id": 3705,
            "pub_date": "2025-05-08",
            "pub_date_card": {
                "ru": "8 мая",
                "en": "May 8",
                "zh": "5月8日"
            },
            "hash": "41e61eccd430ea55",
            "authors": [
                "Jaehyun Jeon",
                "Jang Han Yoon",
                "Min Soo Kim",
                "Sumin Shim",
                "Yejin Choi",
                "Hanbin Kim",
                "Youngjae Yu"
            ],
            "affiliations": [
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.05026.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#cv",
                    "#benchmark",
                    "#optimization",
                    "#inference"
                ],
                "emoji": "🖥️",
                "ru": {
                    "title": "Оценка убедительности UI без A/B-тестов",
                    "desc": "Авторы статьи представляют новый подход к оценке эффективности пользовательских интерфейсов с точки зрения их убедительности. Они вводят бенчмарк WiserUI-Bench для сравнительной оценки дизайна интерфейсов, содержащий 300 пар реальных UI-изображений с результатами A/B-тестов. Исследователи также предлагают стратегию G-FOCUS для улучшения оценки убедительности интерфейсов с помощью мультимодальных языковых моделей. Эксперименты показывают, что G-FOCUS превосходит существующие методы по согласованности и точности оценки пользовательских интерфейсов."
                },
                "en": {
                    "title": "Revolutionizing UI Evaluation with G-FOCUS and WiserUI-Bench",
                    "desc": "This paper discusses the importance of evaluating user interface (UI) design not just for its visual appeal but for its ability to influence user behavior, a concept known as Design Persuasiveness. The authors highlight the limitations of traditional A/B testing, which is often expensive and slow, and propose a new benchmark called WiserUI-Bench for assessing UI design effectiveness through pairwise comparisons. They introduce G-FOCUS, an innovative reasoning strategy that improves the accuracy of Vision-Language Models (VLMs) in evaluating UI persuasiveness by minimizing biases. The results demonstrate that G-FOCUS outperforms existing methods, paving the way for more efficient and scalable UI design optimization."
                },
                "zh": {
                    "title": "提升用户界面设计的说服力评估",
                    "desc": "本论文探讨了用户界面（UI）设计的有效性评估，强调设计的说服力对用户行为的影响。传统的A/B测试方法虽然常用，但成本高且耗时。我们提出了WiserUI-Bench，这是一个用于成对UI设计说服力评估的基准，包含300对真实的UI图像及其A/B测试结果和专家理由。此外，我们还提出了G-FOCUS，这是一种新颖的推理策略，能够提高基于视觉语言模型的说服力评估的准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.02686",
            "title": "Sailing AI by the Stars: A Survey of Learning from Rewards in\n  Post-Training and Test-Time Scaling of Large Language Models",
            "url": "https://huggingface.co/papers/2505.02686",
            "abstract": "Recent developments in Large Language Models (LLMs) have shifted from pre-training scaling to post-training and test-time scaling. Across these developments, a key unified paradigm has arisen: Learning from Rewards, where reward signals act as the guiding stars to steer LLM behavior. It has underpinned a wide range of prevalent techniques, such as reinforcement learning (in RLHF, DPO, and GRPO), reward-guided decoding, and post-hoc correction. Crucially, this paradigm enables the transition from passive learning from static data to active learning from dynamic feedback. This endows LLMs with aligned preferences and deep reasoning capabilities. In this survey, we present a comprehensive overview of the paradigm of learning from rewards. We categorize and analyze the strategies under this paradigm across training, inference, and post-inference stages. We further discuss the benchmarks for reward models and the primary applications. Finally we highlight the challenges and future directions. We maintain a paper collection at https://github.com/bobxwu/learning-from-rewards-llm-papers.",
            "score": 4,
            "issue_id": 3706,
            "pub_date": "2025-05-05",
            "pub_date_card": {
                "ru": "5 мая",
                "en": "May 5",
                "zh": "5月5日"
            },
            "hash": "22b290e68229e62f",
            "authors": [
                "Xiaobao Wu"
            ],
            "affiliations": [
                "Nanyang Technological University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.02686.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#training",
                    "#rlhf",
                    "#alignment",
                    "#benchmark",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Обучение с вознаграждением: ключ к совершенствованию больших языковых моделей",
                    "desc": "Данная статья представляет обзор парадигмы обучения с вознаграждением в контексте больших языковых моделей (LLM). Авторы анализируют различные стратегии применения этой парадигмы на этапах обучения, вывода и пост-обработки. Обсуждаются методы, такие как обучение с подкреплением, декодирование с учетом вознаграждения и постобработка, которые позволяют LLM переходить от пассивного обучения на статических данных к активному обучению с динамической обратной связью. В статье также рассматриваются бенчмарки для моделей вознаграждения, основные приложения и будущие направления исследований в этой области."
                },
                "en": {
                    "title": "Harnessing Rewards: The Future of Learning in LLMs",
                    "desc": "This paper discusses the evolution of Large Language Models (LLMs) focusing on the shift from pre-training to learning from rewards. It highlights how reward signals guide LLM behavior through techniques like reinforcement learning, reward-guided decoding, and post-hoc correction. The authors categorize various strategies used in training, inference, and post-inference stages, emphasizing the importance of dynamic feedback for improving model alignment and reasoning. Additionally, the paper addresses benchmarks for reward models and outlines future challenges and directions in this area."
                },
                "zh": {
                    "title": "从奖励中学习，赋能大型语言模型",
                    "desc": "最近，大型语言模型（LLMs）的发展从预训练扩展到后训练和测试时扩展。一个关键的统一范式出现了：从奖励中学习，其中奖励信号作为指导星，引导LLM的行为。这个范式支持了许多流行的技术，如强化学习（在RLHF、DPO和GRPO中）、奖励引导解码和事后修正。通过这个范式，LLMs能够从静态数据的被动学习转向从动态反馈的主动学习，赋予它们对齐的偏好和深度推理能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.05621",
            "title": "A Preliminary Study for GPT-4o on Image Restoration",
            "url": "https://huggingface.co/papers/2505.05621",
            "abstract": "OpenAI's GPT-4o model, integrating multi-modal inputs and outputs within an autoregressive architecture, has demonstrated unprecedented performance in image generation. In this work, we investigate its potential impact on the image restoration community. We present the first systematic evaluation of GPT-4o across diverse restoration tasks. Our experiments reveal that, although restoration outputs from GPT-4o are visually appealing, they often suffer from pixel-level structural fidelity when compared to ground-truth images. Common issues are variations in image proportions, shifts in object positions and quantities, and changes in viewpoint.To address it, taking image dehazing, derainning, and low-light enhancement as representative case studies, we show that GPT-4o's outputs can serve as powerful visual priors, substantially enhancing the performance of existing dehazing networks. It offers practical guidelines and a baseline framework to facilitate the integration of GPT-4o into future image restoration pipelines. We hope the study on GPT-4o image restoration will accelerate innovation in the broader field of image generation areas. To support further research, we will release GPT-4o-restored images from over 10 widely used image restoration datasets.",
            "score": 0,
            "issue_id": 3709,
            "pub_date": "2025-05-08",
            "pub_date_card": {
                "ru": "8 мая",
                "en": "May 8",
                "zh": "5月8日"
            },
            "hash": "4fd37a23cd5db52f",
            "authors": [
                "Hao Yang",
                "Yan Yang",
                "Ruikun Zhang",
                "Liyuan Pan"
            ],
            "affiliations": [
                "Australian National University",
                "Beijing Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.05621.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#dataset",
                    "#cv",
                    "#multimodal",
                    "#open_source",
                    "#games"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "GPT-4o: Новый рубеж в восстановлении изображений",
                    "desc": "Модель GPT-4o от OpenAI показала беспрецедентную производительность в генерации изображений. Исследователи провели систематическую оценку GPT-4o в различных задачах восстановления изображений. Хотя результаты визуально привлекательны, они часто страдают от структурной точности на уровне пикселей по сравнению с эталонными изображениями. Тем не менее, выходные данные GPT-4o могут служить мощными визуальными приорами, значительно улучшая производительность существующих сетей для удаления дымки, дождя и улучшения изображений при низкой освещенности."
                },
                "en": {
                    "title": "Harnessing GPT-4o for Enhanced Image Restoration",
                    "desc": "The paper explores the capabilities of OpenAI's GPT-4o model in the field of image restoration, highlighting its ability to generate visually appealing images. Despite its impressive outputs, the model struggles with maintaining pixel-level accuracy, leading to issues like incorrect object positioning and altered image proportions. The authors demonstrate that GPT-4o can enhance existing image restoration techniques, particularly in tasks like dehazing and deraining, by providing valuable visual priors. This work aims to establish a foundation for integrating GPT-4o into future restoration workflows and encourages further research in image generation."
                },
                "zh": {
                    "title": "GPT-4o：图像修复的新动力",
                    "desc": "OpenAI的GPT-4o模型结合了多模态输入和输出，展现了在图像生成方面的卓越性能。本文系统评估了GPT-4o在图像修复任务中的潜在影响，尽管其生成的修复图像在视觉上吸引人，但在像素级结构保真度上与真实图像相比存在问题。我们通过图像去雾、去雨和低光增强等案例研究，展示了GPT-4o的输出可以作为强大的视觉先验，显著提升现有去雾网络的性能。希望本研究能加速图像生成领域的创新，并将发布来自10个广泛使用的图像修复数据集的GPT-4o修复图像以支持进一步研究。"
                }
            }
        }
    ],
    "link_prev": "2025-05-09.html",
    "link_next": "2025-05-13.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "09.05",
        "en": "05/09",
        "zh": "5月9日"
    },
    "short_date_next": {
        "ru": "13.05",
        "en": "05/13",
        "zh": "5月13日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 0,
        "#benchmark": 6,
        "#agents": 1,
        "#cv": 2,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 1,
        "#inference": 2,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 2,
        "#architecture": 1,
        "#healthcare": 1,
        "#training": 3,
        "#robotics": 1,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 3,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 4,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 1,
        "#science": 1,
        "#low_resource": 2
    },
    "zh": {
        "text": "我们介绍了 Bielik v3，这是一系列专为波兰语处理优化的参数高效生成文本模型（1.5B 和 4.5B）。这些模型展示了较小但优化良好的架构可以实现与大得多模型相当的性能，同时需要更少的计算资源。我们的方法包括自定义波兰语分词器（APT4）、平衡不同指令类型学习的加权指令交叉熵损失和根据训练进度动态调整的自适应学习率。经过精心策划的 292 亿个标记和 303 百万文档的训练，这些模型在多个基准测试中表现出色。4.5B 参数模型的结果与其 2-3 倍大小的模型竞争力相当，而 1.5B 模型则在其极其紧凑的配置下表现出强大的性能。",
        "title": "Bielik v3 Small: Technical Report",
        "pinyin": "Wǒmen jièshào le Bielik v3, zhè shì yī xìliè zhuān wèi Bōlán yǔ chǔlǐ yōuhuà de cānshù gāoxiào shēngchéng wénběn móxíng (1.5B hé 4.5B). Zhèxiē móxíng zhǎnshì le jiào xiǎo dàn yōuhuà liáng hǎo de jiàgòu kěyǐ shíxiàn yǔ dà dé duō móxíng xiàngdāng de xíngnéng, tóngshí xūyào gèng shǎo de jìsuàn zīyuán. Wǒmen de fāngfǎ bāokuò zìdìngyì Bōlán yǔ fēncíqì (APT4), píng héng bùtóng zhǐlìng lèixíng xuéxí de jiāquán zhǐlìng jiāochā shāngsǔn yǔ gēnjù xùnliàn jìndù dòngtài tiáojié de zìshìyìng xuéxí lǜ. Jīngxīn cèhuà de 292 yì gè biāojì hé 303 bǎi wàn wénjiàn de xùnliàn, zhèxiē móxíng zài duōgè jīzhǔn cèshì zhōng biǎoxiàn chūsè. 4.5B cānshù móxíng de jiéguǒ yǔ qí 2-3 bèi dàxìao de móxíng jìngzhēnglì xiàngdāng, ér 1.5B móxíng zé zài qí qí tè jǐnkǒu de pèizhì xià biǎoxiàn chū qiángdà de xíngnéng.",
        "vocab": "[\n    {\"word\": \"介绍\", \"pinyin\": \"jiè shào\", \"trans\": \"introduce\"},\n    {\"word\": \"系列\", \"pinyin\": \"xì liè\", \"trans\": \"series\"},\n    {\"word\": \"专为\", \"pinyin\": \"zhuān wèi\", \"trans\": \"specially for\"},\n    {\"word\": \"优化\", \"pinyin\": \"yōu huà\", \"trans\": \"optimize\"},\n    {\"word\": \"参数\", \"pinyin\": \"cān shù\", \"trans\": \"parameters\"},\n    {\"word\": \"高效\", \"pinyin\": \"gāo xiào\", \"trans\": \"efficient\"},\n    {\"word\": \"生成\", \"pinyin\": \"shēng chéng\", \"trans\": \"generate\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"展示\", \"pinyin\": \"zhǎn shì\", \"trans\": \"demonstrate\"},\n    {\"word\": \"架构\", \"pinyin\": \"jià gòu\", \"trans\": \"architecture\"},\n    {\"word\": \"相当\", \"pinyin\": \"xiāng dāng\", \"trans\": \"equivalent\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"计算\", \"pinyin\": \"jì suàn\", \"trans\": \"compute\"},\n    {\"word\": \"资源\", \"pinyin\": \"zī yuán\", \"trans\": \"resources\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"自定义\", \"pinyin\": \"zì dìng yì\", \"trans\": \"customize\"},\n    {\"word\": \"分词器\", \"pinyin\": \"fēn cí qì\", \"trans\": \"tokenizer\"},\n    {\"word\": \"平衡\", \"pinyin\": \"píng héng\", \"trans\": \"balance\"},\n    {\"word\": \"指令\", \"pinyin\": \"zhǐ lìng\", \"trans\": \"instruction\"},\n    {\"word\": \"类型\", \"pinyin\": \"lèi xíng\", \"trans\": \"type\"},\n    {\"word\": \"学习\", \"pinyin\": \"xué xí\", \"trans\": \"learn\"},\n    {\"word\": \"加权\", \"pinyin\": \"jiā quán\", \"trans\": \"weighted\"},\n    {\"word\": \"交叉熵\", \"pinyin\": \"jiāo chā shāng\", \"trans\": \"cross-entropy\"},\n    {\"word\": \"损失\", \"pinyin\": \"sǔn shī\", \"trans\": \"loss\"},\n    {\"word\": \"自适应\", \"pinyin\": \"zì shì yìng\", \"trans\": \"adaptive\"},\n    {\"word\": \"学习率\", \"pinyin\": \"xué xí lǜ\", \"trans\": \"learning rate\"},\n    {\"word\": \"策划\", \"pinyin\": \"cè huà\", \"trans\": \"plan\"},\n    {\"word\": \"标记\", \"pinyin\": \"biāo jì\", \"trans\": \"token\"},\n    {\"word\": \"文档\", \"pinyin\": \"wén dàng\", \"trans\": \"document\"},\n    {\"word\": \"训练\", \"pinyin\": \"xùn liàn\", \"trans\": \"train\"},\n    {\"word\": \"基准\", \"pinyin\": \"jī zhǔn\", \"trans\": \"benchmark\"},\n    {\"word\": \"测试\", \"pinyin\": \"cè shì\", \"trans\": \"test\"},\n    {\"word\": \"表现\", \"pinyin\": \"biǎo xiàn\", \"trans\": \"perform\"},\n    {\"word\": \"出色\", \"pinyin\": \"chū sè\", \"trans\": \"outstanding\"},\n    {\"word\": \"结果\", \"pinyin\": \"jié guǒ\", \"trans\": \"result\"},\n    {\"word\": \"竞争力\", \"pinyin\": \"jìng zhēng lì\", \"trans\": \"competitiveness\"},\n    {\"word\": \"配置\", \"pinyin\": \"pèi zhì\", \"trans\": \"configuration\"},\n    {\"word\": \"紧凑\", \"pinyin\": \"jǐn còu\", \"trans\": \"compact\"},\n    {\"word\": \"强大\", \"pinyin\": \"qiáng dà\", \"trans\": \"powerful\"}\n]",
        "trans": "We introduced Bielik v3, a series of parameter-efficient text generation models optimized specifically for Polish language processing (1.5B and 4.5B). These models demonstrate that smaller but well-optimized architectures can achieve performance comparable to much larger models while requiring fewer computational resources. Our approach includes a custom Polish tokenizer (APT4), weighted instruction cross-entropy loss to balance learning across different instruction types, and adaptive learning rates dynamically adjusted according to training progress. With meticulously planned training on 292 billion tokens and 303 million documents, these models perform excellently on multiple benchmarks. The 4.5B parameter model's results are competitive with models 2-3 times its size, while the 1.5B model shows strong performance in its extremely compact configuration.",
        "update_ts": "2025-05-12 10:13"
    }
}