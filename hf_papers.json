{
    "date": {
        "ru": "20 мая",
        "en": "May 20",
        "zh": "5月20日"
    },
    "time_utc": "2025-05-20 05:12",
    "weekday": 1,
    "issue_id": 3848,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.11896",
            "title": "AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.11896",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.",
            "score": 30,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 мая",
                "en": "May 17",
                "zh": "5月17日"
            },
            "hash": "bdc79864df7cbd51",
            "authors": [
                "Chenwei Lou",
                "Zewei Sun",
                "Xinnian Liang",
                "Meng Qu",
                "Wei Shen",
                "Wenqi Wang",
                "Yuntao Li",
                "Qingping Yang",
                "Shuangzhi Wu"
            ],
            "affiliations": [
                "ByteDance Seed"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11896.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "AdaCoT: Умное рассуждение для языковых моделей",
                    "desc": "AdaCoT - это новый фреймворк, позволяющий крупным языковым моделям (LLM) адаптивно решать, когда использовать метод цепочки рассуждений (Chain-of-Thought, CoT). Используя обучение с подкреплением, в частности Proximal Policy Optimization (PPO), AdaCoT оптимизирует баланс между производительностью модели и вычислительными затратами, связанными с применением CoT. Ключевым техническим вкладом является метод Selective Loss Masking (SLM), предотвращающий коллапс границы принятия решений во время многоэтапного обучения с подкреплением. Эксперименты показывают, что AdaCoT значительно снижает использование CoT для запросов, не требующих сложных рассуждений, сохраняя при этом высокую производительность на сложных задачах."
                },
                "en": {
                    "title": "Adaptive Reasoning for Efficient Language Models",
                    "desc": "This paper presents AdaCoT, a new framework that improves the efficiency of Large Language Models (LLMs) by adaptively deciding when to use Chain-of-Thought (CoT) prompting. Traditional CoT prompting can be computationally expensive, especially for simpler queries, but AdaCoT optimizes this by framing the decision to use CoT as a Pareto optimization problem. The authors employ reinforcement learning, specifically Proximal Policy Optimization (PPO), to dynamically adjust when CoT is triggered based on the complexity of the input. Their approach includes a technique called Selective Loss Masking (SLM) to ensure stable training, resulting in significant reductions in CoT usage while maintaining high performance on complex tasks."
                },
                "zh": {
                    "title": "自适应链式推理，提升效率与性能",
                    "desc": "大型语言模型（LLMs）在处理复杂推理任务时表现出色，但在某些情况下面临挑战。为了解决这一问题，本文提出了AdaCoT（自适应链式推理），它允许模型根据输入的复杂性自适应地决定是否使用链式推理。我们将自适应推理视为一个帕累托优化问题，旨在平衡模型性能与链式推理的计算成本。实验结果表明，AdaCoT在不需要复杂推理的查询中显著减少了链式推理的使用，提升了效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11820",
            "title": "Chain-of-Model Learning for Language Model",
            "url": "https://huggingface.co/papers/2505.11820",
            "abstract": "In this paper, we propose a novel learning paradigm, termed Chain-of-Model (CoM), which incorporates the causal relationship into the hidden states of each layer as a chain style, thereby introducing great scaling efficiency in model training and inference flexibility in deployment. We introduce the concept of Chain-of-Representation (CoR), which formulates the hidden states at each layer as a combination of multiple sub-representations (i.e., chains) at the hidden dimension level. In each layer, each chain from the output representations can only view all of its preceding chains in the input representations. Consequently, the model built upon CoM framework can progressively scale up the model size by increasing the chains based on the previous models (i.e., chains), and offer multiple sub-models at varying sizes for elastic inference by using different chain numbers. Based on this principle, we devise Chain-of-Language-Model (CoLM), which incorporates the idea of CoM into each layer of Transformer architecture. Based on CoLM, we further introduce CoLM-Air by introducing a KV sharing mechanism, that computes all keys and values within the first chain and then shares across all chains. This design demonstrates additional extensibility, such as enabling seamless LM switching, prefilling acceleration and so on. Experimental results demonstrate our CoLM family can achieve comparable performance to the standard Transformer, while simultaneously enabling greater flexiblity, such as progressive scaling to improve training efficiency and offer multiple varying model sizes for elastic inference, paving a a new way toward building language models. Our code will be released in the future at: https://github.com/microsoft/CoLM.",
            "score": 21,
            "issue_id": 3848,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 мая",
                "en": "May 17",
                "zh": "5月17日"
            },
            "hash": "2e8115f0fe78856b",
            "authors": [
                "Kaitao Song",
                "Xiaohua Wang",
                "Xu Tan",
                "Huiqiang Jiang",
                "Chengruidong Zhang",
                "Yongliang Shen",
                "Cen LU",
                "Zihao Li",
                "Zifan Song",
                "Caihua Shan",
                "Yansen Wang",
                "Kan Ren",
                "Xiaoqing Zheng",
                "Tao Qin",
                "Yuqing Yang",
                "Dongsheng Li",
                "Lili Qiu"
            ],
            "affiliations": [
                "Fudan University",
                "Microsoft Research",
                "ShanghaiTech University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11820.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#open_source",
                    "#inference",
                    "#agi",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "🔗",
                "ru": {
                    "title": "Цепная революция в языковых моделях: гибкость и эффективность",
                    "desc": "В этой статье представлена новая парадигма обучения под названием Chain-of-Model (CoM), которая внедряет причинно-следственные связи в скрытые состояния каждого слоя модели в виде цепочки. Авторы вводят концепцию Chain-of-Representation (CoR), формулирующую скрытые состояния на каждом уровне как комбинацию нескольких под-представлений на уровне скрытых измерений. На основе этого принципа разработана архитектура Chain-of-Language-Model (CoLM), которая внедряет идею CoM в каждый слой Transformer. Экспериментальные результаты показывают, что семейство моделей CoLM достигает сопоставимой производительности со стандартным Transformer, одновременно обеспечивая большую гибкость в масштабировании и развертывании."
                },
                "en": {
                    "title": "Scaling Language Models with Chain-of-Model Efficiency",
                    "desc": "This paper introduces a new learning approach called Chain-of-Model (CoM), which enhances model training efficiency by incorporating causal relationships into the hidden states of each layer. It presents the Chain-of-Representation (CoR) concept, where hidden states are formed from multiple sub-representations, allowing each layer to only access its preceding chains. The CoM framework enables models to scale up by adding more chains, providing flexibility in deploying various sub-models of different sizes. The Chain-of-Language-Model (CoLM) and its variant CoLM-Air further optimize Transformer architectures by sharing key-value pairs across chains, resulting in improved performance and adaptability for language models."
                },
                "zh": {
                    "title": "链式模型：灵活高效的语言模型新范式",
                    "desc": "本文提出了一种新颖的学习范式，称为链式模型（CoM），它将因果关系融入每一层的隐藏状态，以链式结构提高模型训练的效率和推理的灵活性。我们引入了链式表示（CoR）的概念，将每一层的隐藏状态表示为多个子表示的组合（即链）。在每一层中，输出表示的每个链只能查看输入表示中所有前面的链，从而使得基于CoM框架构建的模型能够通过增加链的数量逐步扩大模型规模，并提供不同大小的子模型以实现灵活推理。基于这一原理，我们设计了链式语言模型（CoLM），并进一步引入了CoLM-Air，通过引入键值共享机制，计算第一个链中的所有键和值，然后在所有链之间共享，从而展示了额外的可扩展性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11254",
            "title": "Delta Attention: Fast and Accurate Sparse Attention Inference by Delta\n  Correction",
            "url": "https://huggingface.co/papers/2505.11254",
            "abstract": "The attention mechanism of a transformer has a quadratic complexity, leading to high inference costs and latency for long sequences. However, attention matrices are mostly sparse, which implies that many entries may be omitted from computation for efficient inference. Sparse attention inference methods aim to reduce this computational burden; however, they also come with a troublesome performance degradation. We discover that one reason for this degradation is that the sparse calculation induces a distributional shift in the attention outputs. The distributional shift causes decoding-time queries to fail to align well with the appropriate keys from the prefill stage, leading to a drop in performance. We propose a simple, novel, and effective procedure for correcting this distributional shift, bringing the distribution of sparse attention outputs closer to that of quadratic attention. Our method can be applied on top of any sparse attention method, and results in an average 36%pt performance increase, recovering 88% of quadratic attention accuracy on the 131K RULER benchmark when applied on top of sliding window attention with sink tokens while only adding a small overhead. Our method can maintain approximately 98.5% sparsity over full quadratic attention, making our model 32 times faster than Flash Attention 2 when processing 1M token prefills.",
            "score": 18,
            "issue_id": 3847,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "2aba31b686859e82",
            "authors": [
                "Jeffrey Willette",
                "Heejun Lee",
                "Sung Ju Hwang"
            ],
            "affiliations": [
                "DeepAuto.ai",
                "KAIST"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11254.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#long_context",
                    "#architecture",
                    "#inference",
                    "#benchmark"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Коррекция распределения для эффективного разреженного внимания",
                    "desc": "Статья предлагает новый метод для повышения эффективности разреженного внимания в трансформерах. Авторы обнаружили, что разреженное вычисление вызывает сдвиг распределения в выходных данных механизма внимания, что приводит к снижению производительности. Предложенная процедура корректирует этот сдвиг, приближая распределение выходных данных разреженного внимания к квадратичному. Метод может применяться поверх любого алгоритма разреженного внимания, значительно повышая точность при сохранении высокой разреженности и скорости обработки."
                },
                "en": {
                    "title": "Boosting Sparse Attention: Aligning Outputs for Enhanced Performance",
                    "desc": "This paper addresses the inefficiencies of the attention mechanism in transformers, which typically has a quadratic complexity that increases inference costs for long sequences. It highlights that while sparse attention methods can reduce computation, they often lead to performance degradation due to a distributional shift in attention outputs. The authors propose a novel procedure to correct this shift, aligning sparse attention outputs more closely with those of traditional quadratic attention. Their method significantly improves performance, achieving an average increase of 36 percentage points while maintaining high sparsity and speed, making it much faster than existing methods."
                },
                "zh": {
                    "title": "稀疏注意力的分布修正，提升性能与效率",
                    "desc": "本文探讨了变换器的注意力机制在处理长序列时的计算复杂度问题，导致推理成本高和延迟大。尽管注意力矩阵通常是稀疏的，但稀疏注意力推理方法在减少计算负担的同时，可能会导致性能下降。我们发现，性能下降的一个原因是稀疏计算引起了注意力输出的分布偏移，这使得解码时的查询与预填阶段的键对齐不佳。为了解决这个问题，我们提出了一种简单而有效的修正方法，使稀疏注意力输出的分布更接近于二次注意力，从而显著提高了性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13417",
            "title": "AdaptThink: Reasoning Models Can Learn When to Think",
            "url": "https://huggingface.co/papers/2505.13417",
            "abstract": "Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.",
            "score": 17,
            "issue_id": 3845,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "edd33223d8d833a7",
            "authors": [
                "Jiajie Zhang",
                "Nianyi Lin",
                "Lei Hou",
                "Ling Feng",
                "Juanzi Li"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13417.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#inference",
                    "#training",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Адаптивное мышление для оптимизации рассуждений ИИ",
                    "desc": "Исследователи представили новый алгоритм AdaptThink, который учит модели рассуждения адаптивно выбирать оптимальный режим мышления в зависимости от сложности задачи. Алгоритм использует метод обучения с подкреплением и включает в себя ограниченную целевую функцию оптимизации и стратегию выборки по важности. Эксперименты показали, что AdaptThink значительно сокращает вычислительные затраты при одновременном повышении производительности моделей. На трех наборах математических данных алгоритм сократил среднюю длину ответа модели DeepSeek-R1-Distill-Qwen-1.5B на 53% и повысил ее точность на 2.4%."
                },
                "en": {
                    "title": "Optimize Reasoning with Adaptive Thinking Modes!",
                    "desc": "This paper introduces AdaptThink, a reinforcement learning algorithm designed to optimize reasoning models by allowing them to choose between two thinking modes: NoThinking and traditional thinking. NoThinking enables models to skip lengthy reasoning processes for simpler tasks, improving efficiency without sacrificing performance. AdaptThink employs a constrained optimization objective to encourage the use of NoThinking while maintaining overall accuracy, and it uses importance sampling to balance training between both modes. The results show that AdaptThink significantly reduces inference costs and enhances performance on math tasks, demonstrating the effectiveness of adaptive thinking-mode selection."
                },
                "zh": {
                    "title": "自适应思考模式选择，提升推理效率与质量",
                    "desc": "最近，大型推理模型在各种任务上表现出色，但其冗长的思考过程显著增加了推理开销，导致效率成为瓶颈。本文提出了一种名为NoThinking的方法，鼓励推理模型跳过思考，直接生成最终解决方案，适用于相对简单的任务。基于此，我们提出了AdaptThink，这是一种新颖的强化学习算法，旨在根据问题难度自适应选择最佳思考模式。实验表明，AdaptThink显著降低了推理成本，同时提高了模型的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13427",
            "title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable\n  Step-Level Supervision",
            "url": "https://huggingface.co/papers/2505.13427",
            "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.",
            "score": 14,
            "issue_id": 3847,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "22362149c9b7b5ae",
            "authors": [
                "Lingxiao Du",
                "Fanqing Meng",
                "Zongkai Liu",
                "Zhixiang Zhou",
                "Ping Luo",
                "Qiaosheng Zhang",
                "Wenqi Shao"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "Shanghai Jiao Tong University",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13427.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#multimodal",
                    "#math",
                    "#training",
                    "#open_source",
                    "#benchmark",
                    "#data",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Автоматизированное обучение мультимодальных моделей пошаговым рассуждениям",
                    "desc": "В статье представлена модель MM-PRM, обучающаяся оценивать промежуточные шаги рассуждений в мультимодальных задачах. Авторы создали датасет MM-K12 с 10 000 мультимодальных математических задач и использовали метод Монте-Карло для генерации более 700 тысяч аннотаций шагов решения без участия человека. Применение MM-PRM в схеме вывода Best-of-N значительно улучшило результаты как на тестовом наборе MM-K12, так и на внешних бенчмарках. Исследование показывает эффективность использования мягких меток, меньших скоростей обучения и разнообразия путей для оптимизации производительности модели."
                },
                "en": {
                    "title": "Enhancing Multimodal Reasoning with Process Supervision",
                    "desc": "This paper introduces MM-PRM, a novel process reward model designed to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs) in solving complex math problems. The authors highlight that MLLMs often struggle with multi-step reasoning due to insufficient supervision of intermediate steps. To overcome this, they create a strong multimodal model called MM-Policy and a new dataset, MM-K12, containing 10,000 multimodal math problems. By employing a Monte Carlo Tree Search method, they generate over 700,000 annotations to train the PRM, which significantly enhances the logical consistency of reasoning in various benchmarks."
                },
                "zh": {
                    "title": "过程监督提升多模态推理的逻辑稳健性",
                    "desc": "这篇论文介绍了一种新的多模态过程奖励模型（MM-PRM），旨在提高多模态大语言模型在复杂多步骤推理中的表现。研究发现，现有模型在推理过程中缺乏细粒度的监督，导致逻辑不一致或部分正确的结果。为了解决这个问题，作者构建了一个强大的多模态模型MM-Policy，并创建了一个包含10,000个可验证答案的多模态数学问题数据集MM-K12。通过无人工标注的方式生成超过70万条步骤级注释，MM-PRM在推理路径评分中表现出显著的改进，证明了过程监督在增强多模态推理系统逻辑稳健性方面的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13379",
            "title": "Thinkless: LLM Learns When to Think",
            "url": "https://huggingface.co/papers/2505.13379",
            "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless",
            "score": 14,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "d41117eabc11e5c3",
            "authors": [
                "Gongfan Fang",
                "Xinyin Ma",
                "Xinchao Wang"
            ],
            "affiliations": [
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13379.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Умное переключение между кратким и развернутым мышлением в языковых моделях",
                    "desc": "Статья представляет Thinkless - обучаемую систему, позволяющую языковым моделям адаптивно выбирать между кратким и развернутым рассуждением в зависимости от сложности задачи. Система использует обучение с подкреплением и два управляющих токена: <short> для кратких ответов и <think> для детального рассуждения. В основе метода лежит алгоритм DeGRPO, который разделяет цель обучения на выбор режима рассуждения и улучшение точности ответов. Эмпирические результаты показывают, что Thinkless способен сократить использование длинных цепочек рассуждений на 50-90%, значительно повышая эффективность моделей."
                },
                "en": {
                    "title": "Thinkless: Smart Reasoning for Efficient Language Models",
                    "desc": "This paper introduces Thinkless, a framework designed to enhance the efficiency of Reasoning Language Models (RLMs) by enabling them to choose between short-form and long-form reasoning based on task complexity. The framework utilizes reinforcement learning and two control tokens, <short> for brief answers and <think> for detailed reasoning, to guide the model's response strategy. A novel algorithm called Decoupled Group Relative Policy Optimization (DeGRPO) is employed to separate the learning objectives, allowing for better control over reasoning mode selection and response accuracy. The results show that Thinkless can significantly reduce the reliance on long-chain reasoning, improving computational efficiency while maintaining performance on various benchmarks."
                },
                "zh": {
                    "title": "让模型学会何时思考",
                    "desc": "本文提出了一种名为Thinkless的可学习框架，旨在提高大型语言模型（LLM）在推理任务中的效率。该框架通过强化学习训练，使模型能够根据任务复杂性和自身能力自适应选择短期或长期推理。Thinkless使用两个控制标记<short>和<think>来分别表示简洁回答和详细推理。实验结果表明，Thinkless能够将长期推理的使用减少50%至90%，显著提升推理语言模型的效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13215",
            "title": "Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation",
            "url": "https://huggingface.co/papers/2505.13215",
            "abstract": "Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.",
            "score": 13,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "0ab00a261298ad44",
            "authors": [
                "Seungjun Oh",
                "Younggeun Lee",
                "Hyejin Jeon",
                "Eunbyung Park"
            ],
            "affiliations": [
                "Department of Artificial Intelligence, Sungkyunkwan University",
                "Department of Artificial Intelligence, Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13215.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Гибридный 3D-4D подход для эффективной реконструкции динамических сцен",
                    "desc": "Статья представляет новый метод 3D-4DGS для реконструкции динамических 3D-сцен. Он комбинирует 3D гауссианы для статичных областей и 4D гауссианы для динамических элементов. Это позволяет значительно сократить вычислительные затраты и память по сравнению с полностью 4D подходом. Метод демонстрирует более быстрое обучение при сохранении или улучшении визуального качества."
                },
                "en": {
                    "title": "Efficient 3D-4D Scene Reconstruction with Hybrid Gaussian Splatting",
                    "desc": "This paper presents a new method called hybrid 3D-4D Gaussian Splatting (3D-4DGS) for dynamic 3D scene reconstruction. It combines 3D and 4D Gaussian representations to efficiently model static and dynamic elements in a scene. By converting static regions to 3D Gaussians, the method reduces computational load and memory usage while preserving the quality of dynamic elements with 4D Gaussians. The results show that 3D-4DGS achieves faster training times and improved visual quality compared to traditional 4D Gaussian Splatting techniques."
                },
                "zh": {
                    "title": "高效的动态3D场景重建新方法",
                    "desc": "最近动态3D场景重建的进展显示出良好的效果，能够实现高保真度的3D新视图合成，并提高时间一致性。在这些方法中，4D高斯点云（4DGS）因其能够建模高保真的空间和时间变化而受到关注。然而，现有方法在静态区域冗余分配4D高斯时，导致了显著的计算和内存开销，并可能降低图像质量。我们提出了一种混合3D-4D高斯点云（3D-4DGS）框架，能够自适应地用3D高斯表示静态区域，同时为动态元素保留4D高斯，从而显著提高计算效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12805",
            "title": "FedSVD: Adaptive Orthogonalization for Private Federated Learning with\n  LoRA",
            "url": "https://huggingface.co/papers/2505.12805",
            "abstract": "Low-Rank Adaptation (LoRA), which introduces a product of two trainable low-rank matrices into frozen pre-trained weights, is widely used for efficient fine-tuning of language models in federated learning (FL). However, when combined with differentially private stochastic gradient descent (DP-SGD), LoRA faces substantial noise amplification: DP-SGD perturbs per-sample gradients, and the matrix multiplication of the LoRA update (BA) intensifies this effect. Freezing one matrix (e.g., A) reduces the noise but restricts model expressiveness, often resulting in suboptimal adaptation. To address this, we propose FedSVD, a simple yet effective method that introduces a global reparameterization based on singular value decomposition (SVD). In our approach, each client optimizes only the B matrix and transmits it to the server. The server aggregates the B matrices, computes the product BA using the previous A, and refactorizes the result via SVD. This yields a new adaptive A composed of the orthonormal right singular vectors of BA, and an updated B containing the remaining SVD components. This reparameterization avoids quadratic noise amplification, while allowing A to better capture the principal directions of the aggregate updates. Moreover, the orthonormal structure of A bounds the gradient norms of B and preserves more signal under DP-SGD, as confirmed by our theoretical analysis. As a result, FedSVD consistently improves stability and performance across a variety of privacy settings and benchmarks, outperforming relevant baselines under both private and non-private regimes.",
            "score": 12,
            "issue_id": 3848,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "41ef4fd84db0c7fb",
            "authors": [
                "Seanie Lee",
                "Sangwoo Park",
                "Dong Bok Lee",
                "Dominik Wagner",
                "Haebin Seong",
                "Tobias Bocklet",
                "Juho Lee",
                "Sung Ju Hwang"
            ],
            "affiliations": [
                "DeepAuto.ai",
                "KAIST",
                "Technische Hochschule Nürnberg Georg Simon Ohm"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12805.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#data",
                    "#benchmark",
                    "#security",
                    "#optimization"
                ],
                "emoji": "🔒",
                "ru": {
                    "title": "FedSVD: Защищенное федеративное обучение языковых моделей с сохранением эффективности",
                    "desc": "Статья представляет новый метод FedSVD для эффективного федеративного обучения языковых моделей с дифференциальной приватностью. FedSVD решает проблему усиления шума в методе Low-Rank Adaptation (LoRA) при использовании DP-SGD. Метод использует сингулярное разложение (SVD) для глобальной репараметризации, что позволяет избежать квадратичного усиления шума. FedSVD показывает улучшенную стабильность и производительность по сравнению с базовыми методами в различных настройках приватности."
                },
                "en": {
                    "title": "Enhancing Federated Learning with FedSVD: A Noise-Resilient Approach",
                    "desc": "This paper presents FedSVD, a novel method that enhances the fine-tuning of language models in federated learning while addressing the challenges posed by noise amplification in differentially private stochastic gradient descent (DP-SGD). By utilizing singular value decomposition (SVD), FedSVD allows clients to optimize only one matrix (B) and send it to a central server, which then aggregates these updates to improve model adaptation. This approach mitigates the noise amplification that occurs when combining LoRA with DP-SGD, ensuring that the model remains expressive without compromising privacy. The results demonstrate that FedSVD improves both stability and performance across various privacy settings, outperforming existing methods."
                },
                "zh": {
                    "title": "FedSVD：优化联邦学习中的低秩适应",
                    "desc": "本文提出了一种名为FedSVD的方法，旨在解决低秩适应（LoRA）在联邦学习中与差分隐私随机梯度下降（DP-SGD）结合时的噪声放大问题。通过引入基于奇异值分解（SVD）的全局重参数化，FedSVD允许每个客户端仅优化B矩阵并将其传输到服务器。服务器聚合B矩阵，计算BA的乘积，并通过SVD重新因式分解，从而生成新的适应性A和更新后的B。该方法有效减少了噪声放大，同时提高了模型的稳定性和性能，尤其在隐私设置下表现优异。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12504",
            "title": "CPGD: Toward Stable Rule-based Reinforcement Learning for Language\n  Models",
            "url": "https://huggingface.co/papers/2505.12504",
            "abstract": "Recent advances in rule-based reinforcement learning (RL) have significantly improved the reasoning capability of language models (LMs) with rule-based rewards. However, existing RL methods -- such as GRPO, REINFORCE++, and RLOO -- often suffer from training instability, where large policy updates and improper clipping can lead to training collapse. To address this issue, we propose Clipped Policy Gradient Optimization with Policy Drift (CPGD), a novel algorithm designed to stabilize policy learning in LMs. CPGD introduces a policy drift constraint based on KL divergence to dynamically regularize policy updates, and leverages a clip mechanism on the logarithm of the ratio to prevent excessive policy updates. We provide theoretical justification for CPGD and demonstrate through empirical analysis that it mitigates the instability observed in prior approaches. Furthermore, we show that CPGD significantly improves performance while maintaining training stability. Our implementation balances theoretical rigor with practical usability, offering a robust alternative for RL in the post-training of LMs. We release our code at https://github.com/ModalMinds/MM-EUREKA.",
            "score": 12,
            "issue_id": 3847,
            "pub_date": "2025-05-18",
            "pub_date_card": {
                "ru": "18 мая",
                "en": "May 18",
                "zh": "5月18日"
            },
            "hash": "f8b07da7e5e43f1e",
            "authors": [
                "Zongkai Liu",
                "Fanqing Meng",
                "Lingxiao Du",
                "Zhixiang Zhou",
                "Chao Yu",
                "Wenqi Shao",
                "Qiaosheng Zhang"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "Shanghai Jiao Tong University",
                "Sun Yat-Sen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12504.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Стабильное обучение с подкреплением для языковых моделей",
                    "desc": "Статья представляет новый алгоритм CPGD для стабилизации обучения с подкреплением языковых моделей. CPGD вводит ограничение на дрейф политики на основе KL-дивергенции и использует механизм отсечения для предотвращения чрезмерных обновлений политики. Авторы теоретически обосновывают CPGD и эмпирически демонстрируют, что он уменьшает нестабильность, наблюдаемую в предыдущих подходах. Результаты показывают значительное улучшение производительности при сохранении стабильности обучения."
                },
                "en": {
                    "title": "Stabilizing Reinforcement Learning with CPGD",
                    "desc": "This paper introduces Clipped Policy Gradient Optimization with Policy Drift (CPGD), a new algorithm aimed at improving the stability of reinforcement learning in language models. Traditional methods often face issues like training collapse due to large policy updates and improper clipping. CPGD addresses these challenges by using a KL divergence-based policy drift constraint to regulate updates and a clipping mechanism to limit excessive changes. The authors provide theoretical support for CPGD and demonstrate its effectiveness in enhancing performance while ensuring stable training."
                },
                "zh": {
                    "title": "稳定强化学习，提升语言模型性能",
                    "desc": "最近，基于规则的强化学习（RL）在语言模型（LM）的推理能力上取得了显著进展，但现有的RL方法如GRPO、REINFORCE++和RLOO常常面临训练不稳定的问题。为了解决这个问题，我们提出了一种新算法——带有策略漂移的剪切策略梯度优化（CPGD），旨在稳定语言模型中的策略学习。CPGD通过基于KL散度的策略漂移约束动态地规范策略更新，并利用对数比率的剪切机制防止过大的策略更新。我们的理论分析和实证结果表明，CPGD不仅缓解了之前方法的训练不稳定性，还显著提高了性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12081",
            "title": "VisionReasoner: Unified Visual Perception and Reasoning via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.12081",
            "abstract": "Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).",
            "score": 11,
            "issue_id": 3845,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 мая",
                "en": "May 17",
                "zh": "5月17日"
            },
            "hash": "9b7953f88ae7653d",
            "authors": [
                "Yuqi Liu",
                "Tianyuan Qu",
                "Zhisheng Zhong",
                "Bohao Peng",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "affiliations": [
                "CUHK",
                "HKUST",
                "SmartMore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12081.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Единая модель для многозадачного визуального восприятия",
                    "desc": "В статье представлен VisionReasoner - унифицированная модель для решения различных задач визуального восприятия. Модель использует новые стратегии когнитивного обучения с несколькими объектами и систематическое переформулирование задач для улучшения способностей к рассуждению. VisionReasoner генерирует структурированный процесс рассуждений перед выдачей ответов на запросы пользователей. Экспериментальные результаты показывают превосходство VisionReasoner над Qwen2.5VL в задачах обнаружения, сегментации и подсчета объектов."
                },
                "en": {
                    "title": "VisionReasoner: Unifying Visual Perception with Advanced Reasoning",
                    "desc": "This paper presents VisionReasoner, a unified framework designed to enhance visual perception tasks through advanced reasoning capabilities. It employs innovative multi-object cognitive learning strategies and reformulates tasks systematically to improve its performance across various visual challenges. The model processes visual inputs in a structured manner, allowing it to effectively respond to user queries. Evaluation results demonstrate that VisionReasoner significantly outperforms existing models in detection, segmentation, and counting tasks, showcasing its effectiveness as a comprehensive solution for visual perception."
                },
                "zh": {
                    "title": "统一视觉感知的推理能力",
                    "desc": "本文介绍了一种名为VisionReasoner的统一框架，能够在共享模型中处理多种视觉感知任务。通过设计新颖的多对象认知学习策略和系统的任务重构，VisionReasoner增强了其推理能力，以分析视觉输入并解决多样的感知任务。该模型在生成所需输出之前，会先进行结构化的推理过程，以响应用户查询。实验结果表明，VisionReasoner在检测、分割和计数等三个关键领域的十个任务上表现优异，超越了Qwen2.5VL。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12849",
            "title": "Accelerate TarFlow Sampling with GS-Jacobi Iteration",
            "url": "https://huggingface.co/papers/2505.12849",
            "abstract": "Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computation, TarFlow's sampling process is extremely slow. In this paper, we demonstrate that through a series of optimization strategies, TarFlow sampling can be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as GS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow model have varying importance: a small number of blocks play a major role in image generation tasks, while other blocks contribute relatively little; some blocks are sensitive to initial values and prone to numerical overflow, while others are relatively robust. Based on these two characteristics, we propose the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM is used to identify whether a TarFlow block is \"simple\" (converges in few iterations) or \"tough\" (requires more iterations); IGM is used to evaluate whether the initial value of the iteration is good. Experiments on four TarFlow models demonstrate that GS-Jacobi sampling can significantly enhance sampling efficiency while maintaining the quality of generated images (measured by FID), achieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in Img64uncond, and 2.51x in Img64cond without degrading FID scores or sample quality. Code and checkpoints are accessible on https://github.com/encoreus/GS-Jacobi_for_TarFlow",
            "score": 6,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "191f5a409cc6b32e",
            "authors": [
                "Ben Liu",
                "Zhen Qin"
            ],
            "affiliations": [
                "TapTap, Shanghai, China",
                "Zhejiang University, Hangzhou, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12849.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#architecture",
                    "#open_source",
                    "#cv",
                    "#training"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Ускорение генерации изображений в TarFlow с помощью оптимизированных итераций",
                    "desc": "Данная статья представляет метод ускорения процесса сэмплирования в модели TarFlow для генерации изображений. Авторы применяют итерационный метод Гаусса-Зейделя-Якоби и вводят две метрики: Convergence Ranking Metric (CRM) и Initial Guessing Metric (IGM). CRM используется для определения сложности блоков TarFlow, а IGM оценивает качество начальных значений для итераций. Эксперименты показали значительное ускорение сэмплирования (до 5.32 раз) без ухудшения качества генерируемых изображений."
                },
                "en": {
                    "title": "Accelerating TarFlow: Faster Sampling without Quality Loss",
                    "desc": "This paper presents an optimization strategy for the TarFlow model, which combines transformer architecture with Normalizing Flow for image generation. The authors introduce the Gauss-Seidel-Jacobi (GS-Jacobi) iteration method to accelerate the slow sampling process of TarFlow. They identify that certain blocks within the model are more critical for image generation and propose metrics to evaluate their performance: the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM). Experimental results show that the GS-Jacobi method significantly improves sampling speed while preserving image quality, achieving notable speed-ups across various benchmarks."
                },
                "zh": {
                    "title": "加速TarFlow采样，提升图像生成效率",
                    "desc": "图像生成模型在多个应用中取得了显著进展。TarFlow模型结合了变换器架构和归一化流模型，在多个基准测试中达到了最先进的结果。然而，由于因果注意力的顺序计算，TarFlow的采样过程非常缓慢。本文通过优化策略，利用高斯-赛德尔-雅可比迭代方法显著加速了TarFlow的采样过程，同时保持生成图像的质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11932",
            "title": "Neuro-Symbolic Query Compiler",
            "url": "https://huggingface.co/papers/2505.11932",
            "abstract": "Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar G[q] to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.",
            "score": 5,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 мая",
                "en": "May 17",
                "zh": "5月17日"
            },
            "hash": "9445be4eff7e4edc",
            "authors": [
                "Yuyao Zhang",
                "Zhicheng Dou",
                "Xiaoxi Li",
                "Jiajie Jin",
                "Yongkang Wu",
                "Zhonghua Li",
                "Qi Ye",
                "Ji-Rong Wen"
            ],
            "affiliations": [
                "Huawei Poisson Lab",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11932.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rag",
                    "#multimodal"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Компиляция запросов для точного поиска в RAG-системах",
                    "desc": "QCompiler - это нейро-символическая система для улучшения понимания сложных запросов в RAG-системах. Она использует минимальную грамматику BNF для формализации запросов и компилирует их в абстрактные синтаксические деревья. Это позволяет более точно извлекать документы и генерировать ответы на сложные запросы с вложенными структурами. QCompiler включает в себя переводчик выражений запросов, лексический синтаксический анализатор и рекурсивный процессор."
                },
                "en": {
                    "title": "Enhancing Query Understanding in RAG Systems with QCompiler",
                    "desc": "This paper introduces QCompiler, a neuro-symbolic framework designed to enhance the understanding of complex search queries in Retrieval-Augmented Generation (RAG) systems. It utilizes a specially designed Backus-Naur Form (BNF) grammar to formalize these queries, ensuring that they are both complete and free of unnecessary complexity. QCompiler operates through a series of components, including a Query Expression Translator and a Lexical Syntax Parser, which work together to convert queries into Abstract Syntax Trees (ASTs). By focusing on the atomicity of sub-queries, QCompiler improves the accuracy of document retrieval and response generation for intricate queries."
                },
                "zh": {
                    "title": "提升RAG系统的复杂查询识别能力",
                    "desc": "本文提出了一种名为QCompiler的神经符号框架，旨在提高检索增强生成（RAG）系统对复杂查询的识别能力。QCompiler基于语言语法规则和编译器设计，设计了一种最小但足够的巴科斯-诺尔形式（BNF）语法G[q]，以形式化复杂查询。与以往方法不同，这种语法在保持完整性的同时，减少了冗余。通过将查询编译成抽象语法树（AST），QCompiler能够更精确地检索文档并生成响应，从而显著提升RAG系统处理复杂查询的能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13437",
            "title": "FinePhys: Fine-grained Human Action Generation by Explicitly\n  Incorporating Physical Laws for Effective Skeletal Guidance",
            "url": "https://huggingface.co/papers/2505.13437",
            "abstract": "Despite significant advances in video generation, synthesizing physically plausible human actions remains a persistent challenge, particularly in modeling fine-grained semantics and complex temporal dynamics. For instance, generating gymnastics routines such as \"switch leap with 0.5 turn\" poses substantial difficulties for current methods, often yielding unsatisfactory results. To bridge this gap, we propose FinePhys, a Fine-grained human action generation framework that incorporates Physics to obtain effective skeletal guidance. Specifically, FinePhys first estimates 2D poses in an online manner and then performs 2D-to-3D dimension lifting via in-context learning. To mitigate the instability and limited interpretability of purely data-driven 3D poses, we further introduce a physics-based motion re-estimation module governed by Euler-Lagrange equations, calculating joint accelerations via bidirectional temporal updating. The physically predicted 3D poses are then fused with data-driven ones, offering multi-scale 2D heatmap guidance for the diffusion process. Evaluated on three fine-grained action subsets from FineGym (FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms competitive baselines. Comprehensive qualitative results further demonstrate FinePhys's ability to generate more natural and plausible fine-grained human actions.",
            "score": 2,
            "issue_id": 3847,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "28a08dbfb09c6639",
            "authors": [
                "Dian Shao",
                "Mingfei Shi",
                "Shengda Xu",
                "Haodong Chen",
                "Yongle Huang",
                "Binglu Wang"
            ],
            "affiliations": [
                "School of Astronautics, Northwestern Polytechnical University, Xian, China",
                "School of Automation, Northwestern Polytechnical University, Xian, China",
                "School of Software, Northwestern Polytechnical University, Xian, China",
                "Unmanned System Research Institute, Northwestern Polytechnical University, Xian, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13437.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#optimization",
                    "#diffusion",
                    "#video"
                ],
                "emoji": "🤸",
                "ru": {
                    "title": "Точная генерация движений человека с помощью физического моделирования",
                    "desc": "Статья представляет FinePhys - фреймворк для генерации точных движений человека с использованием физических моделей. Система сначала оценивает 2D позы, затем преобразует их в 3D с помощью обучения в контексте. Далее применяется физическое моделирование на основе уравнений Эйлера-Лагранжа для улучшения 3D поз. Полученные физически корректные позы комбинируются с данными для создания многомасштабных 2D тепловых карт, используемых в процессе диффузии."
                },
                "en": {
                    "title": "Bridging Physics and Data for Realistic Human Action Generation",
                    "desc": "This paper presents FinePhys, a framework designed to improve the generation of fine-grained human actions in videos by integrating physics-based modeling. It addresses the challenges of synthesizing complex movements, such as gymnastics routines, by first estimating 2D poses and then converting them to 3D using in-context learning. To enhance the stability and interpretability of the generated poses, FinePhys employs a motion re-estimation module based on Euler-Lagrange equations, which calculates joint accelerations through bidirectional temporal updates. The combination of physics-based predictions with data-driven approaches results in more realistic and coherent human actions, as demonstrated by superior performance on benchmark datasets."
                },
                "zh": {
                    "title": "FinePhys：物理驱动的细粒度人类动作生成框架",
                    "desc": "尽管视频生成技术取得了显著进展，但合成物理上合理的人类动作仍然是一个持续的挑战，尤其是在建模细粒度语义和复杂时间动态方面。本文提出了FinePhys，一个细粒度人类动作生成框架，结合物理学以获得有效的骨骼指导。FinePhys首先以在线方式估计2D姿势，然后通过上下文学习进行2D到3D的维度提升。通过引入基于物理的运动重新估计模块，FinePhys能够生成更自然和合理的细粒度人类动作。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13444",
            "title": "ChartMuseum: Testing Visual Reasoning Capabilities of Large\n  Vision-Language Models",
            "url": "https://huggingface.co/papers/2505.13444",
            "abstract": "Chart understanding presents a unique challenge for large vision-language models (LVLMs), as it requires the integration of sophisticated textual and visual reasoning capabilities. However, current LVLMs exhibit a notable imbalance between these skills, falling short on visual reasoning that is difficult to perform in text. We conduct a case study using a synthetic dataset solvable only through visual reasoning and show that model performance degrades significantly with increasing visual complexity, while human performance remains robust. We then introduce ChartMuseum, a new Chart Question Answering (QA) benchmark containing 1,162 expert-annotated questions spanning multiple reasoning types, curated from real-world charts across 184 sources, specifically built to evaluate complex visual and textual reasoning. Unlike prior chart understanding benchmarks -- where frontier models perform similarly and near saturation -- our benchmark exposes a substantial gap between model and human performance, while effectively differentiating model capabilities: although humans achieve 93% accuracy, the best-performing model Gemini-2.5-Pro attains only 63.0%, and the leading open-source LVLM Qwen2.5-VL-72B-Instruct achieves only 38.5%. Moreover, on questions requiring primarily visual reasoning, all models experience a 35%-55% performance drop from text-reasoning-heavy question performance. Lastly, our qualitative error analysis reveals specific categories of visual reasoning that are challenging for current LVLMs.",
            "score": 1,
            "issue_id": 3848,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "7bd36c8068fb640c",
            "authors": [
                "Liyan Tang",
                "Grace Kim",
                "Xinyu Zhao",
                "Thom Lake",
                "Wenxuan Ding",
                "Fangcong Yin",
                "Prasann Singhal",
                "Manya Wadhwa",
                "Zeyu Leo Liu",
                "Zayne Sprague",
                "Ramya Namuduri",
                "Bodun Hu",
                "Juan Diego Rodriguez",
                "Puyuan Peng",
                "Greg Durrett"
            ],
            "affiliations": [
                "The University of Texas at Austin"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13444.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#interpretability",
                    "#cv",
                    "#benchmark",
                    "#synthetic",
                    "#reasoning",
                    "#dataset"
                ],
                "emoji": "📊",
                "ru": {
                    "title": "Раскрывая пробелы в визуальном мышлении ИИ при анализе диаграмм",
                    "desc": "Статья представляет новый тестовый набор данных ChartMuseum для оценки понимания диаграмм моделями компьютерного зрения и обработки естественного языка. Исследование показывает, что современные мультимодальные модели значительно уступают людям в задачах, требующих сложного визуального анализа диаграмм. Авторы обнаружили существенное снижение производительности моделей при увеличении визуальной сложности задач. ChartMuseum эффективно выявляет разрыв между возможностями моделей и людей в понимании диаграмм, особенно в задачах, требующих преимущественно визуального рассуждения."
                },
                "en": {
                    "title": "Bridging the Gap in Chart Understanding: Visual vs. Textual Reasoning",
                    "desc": "This paper addresses the challenges faced by large vision-language models (LVLMs) in understanding charts, highlighting their struggle with visual reasoning compared to textual reasoning. The authors present a case study using a synthetic dataset that shows a significant drop in model performance as visual complexity increases, while human performance remains stable. They introduce ChartMuseum, a new benchmark for Chart Question Answering (QA) that includes 1,162 expert-annotated questions designed to test both visual and textual reasoning. The results reveal a substantial performance gap between humans and models, with the best model achieving only 63% accuracy compared to 93% for humans, particularly struggling with questions that require visual reasoning."
                },
                "zh": {
                    "title": "图表理解：人类与模型的差距",
                    "desc": "图表理解对大型视觉语言模型（LVLMs）提出了独特的挑战，因为它需要复杂的文本和视觉推理能力的结合。当前的LVLM在这些技能之间存在显著的不平衡，尤其是在视觉推理方面表现不佳。我们通过一个合成数据集进行案例研究，发现随着视觉复杂性的增加，模型性能显著下降，而人类的表现则保持稳定。我们引入了ChartMuseum，这是一个新的图表问答基准，包含1162个专家注释的问题，旨在评估复杂的视觉和文本推理能力。"
                }
            }
        }
    ],
    "link_prev": "2025-05-19.html",
    "link_next": "2025-05-21.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "19.05",
        "en": "05/19",
        "zh": "5月19日"
    },
    "short_date_next": {
        "ru": "21.05",
        "en": "05/21",
        "zh": "5月21日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 2,
        "#benchmark": 6,
        "#agents": 0,
        "#cv": 3,
        "#rl": 4,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 3,
        "#3d": 2,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 3,
        "#math": 2,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 8,
        "#robotics": 0,
        "#agi": 1,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 8,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 11,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了Qwen3，这是Qwen模型系列的最新版本。Qwen3包括多种大型语言模型，旨在提高性能、效率和多语言能力。它包含密集和混合专家架构，参数规模从0.6到2350亿不等。Qwen3的创新之处在于将思考模式和非思考模式结合在一个框架中，消除了切换模型的需要。它还引入了思考预算机制，允许用户根据任务复杂性动态分配计算资源。",
        "title": "Qwen3 Technical Report",
        "pinyin": "这篇文章介绍了Qwen3，这是Qwen模型系列的最新版本。\nZhè piān wénzhāng jièshào le Qwen3, zhè shì Qwen móxíng xìliè de zuìxīn bǎnběn.\n\nQwen3包括多种大型语言模型，旨在提高性能、效率和多语言能力。\nQwen3 bāokuò duōzhǒng dàxíng yǔyán móxíng, zhǐ zài tígāo xìngnéng, xiàolǜ hé duōyǔyán nénglì.\n\n它包含密集和混合专家架构，参数规模从0.6到2350亿不等。\nTā bāohán mìjí hé hùnhé zhuānjiā jiàgòu, cānshù guīmó cóng 0.6 dào 2350 yì bùděng.\n\nQwen3的创新之处在于将思考模式和非思考模式结合在一个框架中，消除了切换模型的需要。\nQwen3 de chuàngxīn zhī chù zài yú jiāng sīkǎo móshì hé fēi sīkǎo móshì jiéhé zài yīgè kuàngjià zhōng, xiāochú le qiēhuàn móxíng de xūyào.\n\n它还引入了思考预算机制，允许用户根据任务复杂性动态分配计算资源。\nTā hái yǐnrù le sīkǎo yùsuàn jīzhì, yǔnxǔ yònghù gēnjù rènwù fùzáxìng dòngtài fēnpèi jìsuàn zīyuán.",
        "vocab": "[\n    {\"word\": \"系列\", \"pinyin\": \"xìliè\", \"trans\": \"series\"},\n    {\"word\": \"版本\", \"pinyin\": \"bǎnběn\", \"trans\": \"version\"},\n    {\"word\": \"旨在\", \"pinyin\": \"zhǐzài\", \"trans\": \"aim to\"},\n    {\"word\": \"效率\", \"pinyin\": \"xiàolǜ\", \"trans\": \"efficiency\"},\n    {\"word\": \"多语言\", \"pinyin\": \"duōyǔyán\", \"trans\": \"multilingual\"},\n    {\"word\": \"能力\", \"pinyin\": \"nénglì\", \"trans\": \"ability\"},\n    {\"word\": \"包含\", \"pinyin\": \"bāohán\", \"trans\": \"contain\"},\n    {\"word\": \"密集\", \"pinyin\": \"mìjí\", \"trans\": \"dense\"},\n    {\"word\": \"混合\", \"pinyin\": \"hùnhé\", \"trans\": \"hybrid\"},\n    {\"word\": \"专家\", \"pinyin\": \"zhuānjiā\", \"trans\": \"expert\"},\n    {\"word\": \"架构\", \"pinyin\": \"jiàgòu\", \"trans\": \"architecture\"},\n    {\"word\": \"参数\", \"pinyin\": \"cānshǔ\", \"trans\": \"parameter\"},\n    {\"word\": \"规模\", \"pinyin\": \"guīmó\", \"trans\": \"scale\"},\n    {\"word\": \"创新\", \"pinyin\": \"chuàngxīn\", \"trans\": \"innovation\"},\n    {\"word\": \"之处\", \"pinyin\": \"zhīchù\", \"trans\": \"place\"},\n    {\"word\": \"思考\", \"pinyin\": \"sīkǎo\", \"trans\": \"think\"},\n    {\"word\": \"模式\", \"pinyin\": \"móshì\", \"trans\": \"mode\"},\n    {\"word\": \"结合\", \"pinyin\": \"jiéhé\", \"trans\": \"combine\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàngjià\", \"trans\": \"framework\"},\n    {\"word\": \"消除\", \"pinyin\": \"xiāochú\", \"trans\": \"eliminate\"},\n    {\"word\": \"切换\", \"pinyin\": \"qiēhuàn\", \"trans\": \"switch\"},\n    {\"word\": \"需要\", \"pinyin\": \"xūyào\", \"trans\": \"need\"},\n    {\"word\": \"引入\", \"pinyin\": \"yǐnrù\", \"trans\": \"introduce\"},\n    {\"word\": \"预算\", \"pinyin\": \"yùsuàn\", \"trans\": \"budget\"},\n    {\"word\": \"机制\", \"pinyin\": \"jīzhì\", \"trans\": \"mechanism\"},\n    {\"word\": \"允许\", \"pinyin\": \"yǔnxǔ\", \"trans\": \"allow\"},\n    {\"word\": \"根据\", \"pinyin\": \"gēnjù\", \"trans\": \"according to\"},\n    {\"word\": \"任务\", \"pinyin\": \"rènwù\", \"trans\": \"task\"},\n    {\"word\": \"复杂性\", \"pinyin\": \"fùzáxìng\", \"trans\": \"complexity\"},\n    {\"word\": \"动态\", \"pinyin\": \"dòngtài\", \"trans\": \"dynamic\"},\n    {\"word\": \"分配\", \"pinyin\": \"fēnpèi\", \"trans\": \"allocate\"},\n    {\"word\": \"计算\", \"pinyin\": \"jìsuàn\", \"trans\": \"compute\"},\n    {\"word\": \"资源\", \"pinyin\": \"zīyuán\", \"trans\": \"resources\"}\n]",
        "trans": "This article introduces Qwen3, the latest version in the Qwen model series. Qwen3 includes a variety of large language models aimed at enhancing performance, efficiency, and multilingual capabilities. It features dense and mixture-of-experts architectures, with parameter sizes ranging from 0.6 to 2350 billion. The innovation of Qwen3 lies in combining thinking and non-thinking modes within a single framework, eliminating the need to switch models. It also introduces a thinking budget mechanism, allowing users to dynamically allocate computational resources based on the complexity of the task.",
        "update_ts": "2025-05-19 09:13"
    }
}