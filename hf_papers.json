{
    "date": {
        "ru": "26 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ",
        "en": "December 26",
        "zh": "12æœˆ26æ—¥"
    },
    "time_utc": "2024-12-26 07:10",
    "weekday": 3,
    "issue_id": 1331,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.18547",
            "title": "Token-Budget-Aware LLM Reasoning",
            "url": "https://huggingface.co/papers/2412.18547",
            "abstract": "Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We find that the reasoning process of current LLMs is unnecessarily lengthy and it can be compressed by including a reasonable token budget in the prompt, but the choice of token budget plays a crucial role in the actual compression effectiveness. We then propose a token-budget-aware LLM reasoning framework, which dynamically estimates token budgets for different problems based on reasoning complexity and uses the estimated token budgets to guide the reasoning process. Experiments show that our method effectively reduces token costs in CoT reasoning with only a slight performance reduction, offering a practical solution to balance efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.",
            "score": 3,
            "issue_id": 1328,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ",
                "en": "December 24",
                "zh": "12æœˆ24æ—¥"
            },
            "hash": "9a018cda2c47f064",
            "authors": [
                "Tingxu Han",
                "Chunrong Fang",
                "Shiyu Zhao",
                "Shiqing Ma",
                "Zhenyu Chen",
                "Zhenting Wang"
            ],
            "affiliations": [
                "Nanjing University",
                "Rutgers University",
                "UMass Amherst"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18547.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "ğŸ’¡",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ˜Ğ˜: Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¼Ñ‹ÑĞ»ĞµĞ¹, Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM), Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ±ÑĞ´Ğ¶ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ñ‹ Ğ½Ğ° Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ğ¼Ñ‹ÑĞ»ĞµĞ¹ (CoT), ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ² Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ LLM."
                },
                "en": {
                    "title": "Optimizing Reasoning Efficiency in LLMs with Token Budgets",
                    "desc": "This paper addresses the reasoning efficiency of large language models (LLMs) by introducing a token-budget-aware framework. It highlights that while Chain-of-Thought (CoT) reasoning improves performance, it also increases token usage and costs. The authors propose a method to dynamically estimate token budgets based on the complexity of reasoning tasks, allowing for more efficient use of tokens. Experimental results demonstrate that this approach reduces token costs with minimal impact on performance, providing a balance between efficiency and accuracy in LLM reasoning."
                },
                "zh": {
                    "title": "ä¼˜åŒ–æ¨ç†ï¼Œé™ä½æˆæœ¬ï¼",
                    "desc": "æ¨ç†å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²è‡³å…³é‡è¦ã€‚è™½ç„¶é“¾å¼æ¨ç†ï¼ˆCoTï¼‰æ–¹æ³•é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜LLMæ€§èƒ½ï¼Œä½†è¿™ä¹Ÿå¯¼è‡´äº†æ˜¾è‘—çš„ä»¤ç‰Œä½¿ç”¨å¼€é”€ï¼Œå¢åŠ äº†æˆæœ¬ã€‚æˆ‘ä»¬å‘ç°å½“å‰LLMçš„æ¨ç†è¿‡ç¨‹è¿‡äºå†—é•¿ï¼Œå¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­åŒ…å«åˆç†çš„ä»¤ç‰Œé¢„ç®—æ¥å‹ç¼©ï¼Œä½†ä»¤ç‰Œé¢„ç®—çš„é€‰æ‹©å¯¹å‹ç¼©æ•ˆæœè‡³å…³é‡è¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä»¤ç‰Œé¢„ç®—çš„LLMæ¨ç†æ¡†æ¶ï¼ŒåŠ¨æ€ä¼°è®¡ä¸åŒé—®é¢˜çš„ä»¤ç‰Œé¢„ç®—ï¼Œä»è€Œåœ¨ä¿æŒæ•ˆç‡å’Œå‡†ç¡®æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚"
                }
            }
        }
    ],
    "link_prev": "2024-12-25.html",
    "link_next": "2024-12-27.html",
    "link_month": "2024-12.html",
    "short_date_prev": {
        "ru": "25.12",
        "en": "12/25",
        "zh": "12æœˆ25æ—¥"
    },
    "short_date_next": {
        "ru": "27.12",
        "en": "12/27",
        "zh": "12æœˆ27æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†æ·±åº¦æ•°æ®ä¸­ç¼ºå¤±å€¼çš„æŒ‘æˆ˜ã€‚DepthLab æ˜¯ä¸€ä¸ªåŸºäºå›¾åƒæ‰©æ•£å…ˆéªŒçš„æ·±åº¦ä¿®å¤æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ç¼ºå¤±åŒºåŸŸã€‚å®ƒå…·æœ‰ä¸¤ä¸ªä¼˜ç‚¹ï¼šå¯¹è¿ç»­åŒºåŸŸå’Œå­¤ç«‹ç‚¹éƒ½èƒ½æä¾›å¯é çš„å¡«è¡¥ï¼Œå¹¶ä¿æŒå·²çŸ¥æ·±åº¦çš„å°ºåº¦ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•åœ¨3Dåœºæ™¯ä¿®å¤ã€æ–‡æœ¬åˆ°3Dåœºæ™¯ç”Ÿæˆç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½å’Œè§†è§‰è´¨é‡éƒ½è¶…è¿‡ç°æœ‰è§£å†³æ–¹æ¡ˆã€‚é¡¹ç›®é¡µé¢å’Œæºä»£ç å¯ä»¥åœ¨ https://johanan528.github.io/depthlab_web/ æ‰¾åˆ°ã€‚",
        "title": "DepthLab: From Partial to Complete",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†æ·±åº¦æ•°æ®ä¸­ç¼ºå¤±å€¼çš„æŒ‘æˆ˜ã€‚\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le shÄ“ndÃ¹ shÃ¹jÃ¹ zhÅng quÄ“shÄ«zhÃ­ de tiÇozhÃ n.\n\nDepthLab æ˜¯ä¸€ä¸ªåŸºäºå›¾åƒæ‰©æ•£å…ˆéªŒçš„æ·±åº¦ä¿®å¤æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ç¼ºå¤±åŒºåŸŸã€‚\nDepthLab shÃ¬ yÄ«gÃ¨ jÄ«yÃº tÃºxiÃ ng kuÃ²sÃ n xiÄnyÃ¡n de shÄ“ndÃ¹ xiÅ«fÃ¹ mÃ³xÃ­ng, nÃ©nggÃ²u chÇ”lÇ quÄ“shÄ« qÅ«yÃ¹.\n\nå®ƒå…·æœ‰ä¸¤ä¸ªä¼˜ç‚¹ï¼šå¯¹è¿ç»­åŒºåŸŸå’Œå­¤ç«‹ç‚¹éƒ½èƒ½æä¾›å¯é çš„å¡«è¡¥ï¼Œå¹¶ä¿æŒå·²çŸ¥æ·±åº¦çš„å°ºåº¦ä¸€è‡´æ€§ã€‚\nTÄ jÃ¹yÇ’u liÇng gÃ¨ yÅudiÇn: duÃ¬ liÃ¡nxÃ¹ qÅ«yÃ¹ hÃ© gÅ«lÃ¬diÇn dÅu nÃ©ng tÃ­gÅng kÄ›kÃ o de tiÃ¡nbÇ”, bÃ¬ng bÇochÃ­ yÇzhÄ« shÄ“ndÃ¹ de chÇdÃ¹ yÄ«zhÃ¬xÃ¬ng.\n\nè¯¥æ–¹æ³•åœ¨3Dåœºæ™¯ä¿®å¤ã€æ–‡æœ¬åˆ°3Dåœºæ™¯ç”Ÿæˆç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½å’Œè§†è§‰è´¨é‡éƒ½è¶…è¿‡ç°æœ‰è§£å†³æ–¹æ¡ˆã€‚\nGÇi fÄngfÇ zÃ i 3D chÇngjÇng xiÅ«fÃ¹, wÃ©nbÄ›n dÃ o 3D chÇngjÇng shÄ“ngchÃ©ng dÄ›ng rÃ¨nwÃ¹ zhÅng biÇoxiÃ n chÅ«sÃ¨, xÃ¬ngnÃ©ng hÃ© shÃ¬juÃ© zhÃ¬liÃ ng dÅu chÄoguÃ² xiÃ nyÇ’u jiÄ›juÃ© fÄng'Ã n.\n\né¡¹ç›®é¡µé¢å’Œæºä»£ç å¯ä»¥åœ¨ https://johanan528.github.io/depthlab_web/ æ‰¾åˆ°ã€‚\nXiÃ ngmÃ¹ yÃ¨miÃ n hÃ© yuÃ¡n dÃ imÇ kÄ›yÇ zÃ i https://johanan528.github.io/depthlab_web/ zhÇo dÃ o.",
        "vocab": "[{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'}, {'word': 'æ·±åº¦', 'pinyin': 'shÄ“n dÃ¹', 'trans': 'depth'}, {'word': 'ç¼ºå¤±å€¼', 'pinyin': 'quÄ“ shÄ« zhÃ­', 'trans': 'missing value'}, {'word': 'æŒ‘æˆ˜', 'pinyin': 'tiÇo zhÃ n', 'trans': 'challenge'}, {'word': 'åŸºäº', 'pinyin': 'jÄ« yÃº', 'trans': 'based on'}, {'word': 'å›¾åƒ', 'pinyin': 'tÃº xiÃ ng', 'trans': 'image'}, {'word': 'æ‰©æ•£', 'pinyin': 'kuÃ² sÃ n', 'trans': 'diffusion'}, {'word': 'å…ˆéªŒ', 'pinyin': 'xiÄn yÃ n', 'trans': 'prior'}, {'word': 'ä¿®å¤', 'pinyin': 'xiÅ« fÃ¹', 'trans': 'repair'}, {'word': 'æ¨¡å‹', 'pinyin': 'mÃ³ xÃ­ng', 'trans': 'model'}, {'word': 'å¤„ç†', 'pinyin': 'chÇ” lÇ', 'trans': 'handle'}, {'word': 'åŒºåŸŸ', 'pinyin': 'qÅ« yÃ¹', 'trans': 'region'}, {'word': 'è¿ç»­', 'pinyin': 'liÃ¡n xÃ¹', 'trans': 'continuous'}, {'word': 'å­¤ç«‹ç‚¹', 'pinyin': 'gÅ« lÃ¬ diÇn', 'trans': 'isolated point'}, {'word': 'å¯é ', 'pinyin': 'kÄ› kÃ o', 'trans': 'reliable'}, {'word': 'å¡«è¡¥', 'pinyin': 'tiÃ¡n bÇ”', 'trans': 'fill in'}, {'word': 'ä¿æŒ', 'pinyin': 'bÇo chÃ­', 'trans': 'maintain'}, {'word': 'å°ºåº¦', 'pinyin': 'chÇ dÃ¹', 'trans': 'scale'}, {'word': 'ä¸€è‡´æ€§', 'pinyin': 'yÄ« zhÃ¬ xÃ¬ng', 'trans': 'consistency'}, {'word': '3D', 'pinyin': '3D', 'trans': '3D'}, {'word': 'åœºæ™¯', 'pinyin': 'chÇng jÇng', 'trans': 'scene'}, {'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ng chÃ©ng', 'trans': 'generate'}, {'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨n wÃ¹', 'trans': 'task'}, {'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'}, {'word': 'å‡ºè‰²', 'pinyin': 'chÅ« sÃ¨', 'trans': 'outstanding'}, {'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ng nÃ©ng', 'trans': 'performance'}, {'word': 'è§†è§‰', 'pinyin': 'shÃ¬ juÃ©', 'trans': 'visual'}, {'word': 'è´¨é‡', 'pinyin': 'zhÃ¬ liÃ ng', 'trans': 'quality'}, {'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ› juÃ© fÄng Ã n', 'trans': 'solution'}, {'word': 'é¡¹ç›®', 'pinyin': 'xiÃ ng mÃ¹', 'trans': 'project'}, {'word': 'é¡µé¢', 'pinyin': 'yÃ¨ miÃ n', 'trans': 'page'}, {'word': 'æºä»£ç ', 'pinyin': 'yuÃ¡n dÃ i mÇ', 'trans': 'source code'}, {'word': 'æ‰¾åˆ°', 'pinyin': 'zhÇo dÃ o', 'trans': 'find'}]",
        "trans": "This article discusses the challenges of missing values in depth data. DepthLab is a depth inpainting model based on image diffusion priors that can handle missing regions. It has two advantages: it provides reliable filling for both continuous regions and isolated points, and maintains the scale consistency of known depths. This method performs exceptionally well in tasks such as 3D scene repair and text-to-3D scene generation, outperforming existing solutions in both performance and visual quality. The project page and source code can be found at https://johanan528.github.io/depthlab_web/.",
        "update_ts": "2024-12-25 09:10"
    }
}