{
    "date": {
        "ru": "11 августа",
        "en": "August 11",
        "zh": "8月11日"
    },
    "time_utc": "2025-08-11 03:27",
    "weekday": 0,
    "issue_id": 5272,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2508.05731",
            "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy\n  Optimization",
            "url": "https://huggingface.co/papers/2508.05731",
            "abstract": "Adaptive Exploration Policy Optimization (AEPO) enhances semantic alignment in Multimodal Large Language Models (MLLMs) for GUI interaction, improving performance on benchmarks by up to 9.0% compared to RLVR.  \t\t\t\t\tAI-generated summary \t\t\t\t The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at https://github.com/InfiXAI/InfiGUI-G1.",
            "score": 8,
            "issue_id": 5272,
            "pub_date": "2025-08-07",
            "pub_date_card": {
                "ru": "7 августа",
                "en": "August 7",
                "zh": "8月7日"
            },
            "hash": "31f17f5fb142d3e8",
            "authors": [
                "Yuhang Liu",
                "Zeyu Liu",
                "Shuanghe Zhu",
                "Pengxiang Li",
                "Congkai Xie",
                "Jiasheng Wang",
                "Xueyu Hu",
                "Xiaotian Han",
                "Jianbo Yuan",
                "Xinyao Wang",
                "Shengyu Zhang",
                "Hongxia Yang",
                "Fei Wu"
            ],
            "affiliations": [
                "Amazon",
                "InfiX.ai",
                "The Hong Kong Polytechnic University",
                "The University of Chicago",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.05731.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#alignment",
                    "#training",
                    "#rl",
                    "#benchmark",
                    "#agents",
                    "#multimodal"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "AEPO: Прорыв в семантическом выравнивании для мультимодальных ИИ-агентов",
                    "desc": "Статья представляет новый метод оптимизации политики адаптивного исследования (AEPO) для улучшения семантического выравнивания в мультимодальных больших языковых моделях (MLLM) при взаимодействии с графическим интерфейсом пользователя. AEPO использует стратегию генерации множественных ответов для обеспечения более широкого исследования, которое затем направляется теоретически обоснованной функцией вознаграждения адаптивного исследования (AER). Модели, обученные с помощью AEPO, достигают значительных улучшений до 9.0% по сравнению с базовым методом RLVR на тестах, оценивающих обобщение и семантическое понимание. Этот подход решает проблему неэффективного исследования, которая ограничивает семантическое выравнивание в существующих методах."
                },
                "en": {
                    "title": "Enhancing GUI Interaction with Adaptive Exploration in MLLMs",
                    "desc": "Adaptive Exploration Policy Optimization (AEPO) is a novel framework designed to enhance semantic alignment in Multimodal Large Language Models (MLLMs) for effective interaction with Graphical User Interfaces (GUIs). The paper identifies that while existing methods like Reinforcement Learning with Verifiable Rewards (RLVR) improve spatial alignment, they struggle with semantic alignment due to inefficient exploration strategies. AEPO addresses this by implementing a multi-answer generation approach that encourages broader exploration, guided by an Adaptive Exploration Reward (AER) function. As a result, models trained with AEPO demonstrate significant performance improvements, achieving state-of-the-art results on various GUI grounding benchmarks."
                },
                "zh": {
                    "title": "自适应探索，提升语义对齐！",
                    "desc": "自适应探索策略优化（AEPO）通过增强多模态大型语言模型（MLLMs）在图形用户界面（GUI）交互中的语义对齐，显著提升了模型的性能。该方法解决了自然语言指令与UI元素之间的语义对齐问题，克服了传统强化学习方法在探索效率上的瓶颈。AEPO采用多答案生成策略，结合理论基础的自适应探索奖励函数，促进了更广泛的探索。经过AEPO训练的模型在多个GUI基准测试中取得了最高9.0%的相对提升，展示了其在语义理解和泛化能力上的优势。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.05988",
            "title": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token\n  Surprisal",
            "url": "https://huggingface.co/papers/2508.05988",
            "abstract": "ASAP, a novel coarse-to-fine framework, compresses Chain-of-Thought in code reasoning by preserving core structure and essential steps, reducing costs and improving efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code reasoning by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces introduce substantial challenges in terms of training cost, inference latency, and deployment feasibility. While various CoT compression approaches have emerged to address this challenge, they face inherent trade-offs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps. In this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. It then enables a logic-aware pruning by selecting logically essential reasoning steps based on a novel first-token surprisal metric. Finally, ASAP teaches models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning in coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy across multiple code generation benchmarks while substantially reducing training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark, our approach reduces token generation by 23.5% and inference latency by 43.5% compared to the strongest baseline, while achieving a competitive accuracy of 36.19% in Pass@1. Our results highlight a promising direction for building powerful and efficient LRMs.",
            "score": 7,
            "issue_id": 5272,
            "pub_date": "2025-08-08",
            "pub_date_card": {
                "ru": "8 августа",
                "en": "August 8",
                "zh": "8月8日"
            },
            "hash": "82ad3c225d1615aa",
            "authors": [
                "Wenhao Zeng",
                "Yaoning Wang",
                "Chao Hu",
                "Yuling Shi",
                "Chengcheng Wan",
                "Hongyu Zhang",
                "Xiaodong Gu"
            ],
            "affiliations": [
                "Chongqing University",
                "East China Normal University",
                "Fudan University",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.05988.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#training",
                    "#architecture",
                    "#data",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное сжатие рассуждений для улучшения работы с кодом",
                    "desc": "ASAP - это новый фреймворк для сжатия цепочек рассуждений (Chain-of-Thought) в задачах рассуждения о коде. Он использует двухэтапный подход: сначала сохраняет основную структуру рассуждений, а затем выбирает логически важные шаги на основе метрики неожиданности первого токена. ASAP позволяет моделям автономно генерировать и использовать сжатые цепочки рассуждений во время вывода. Эксперименты показывают, что ASAP достигает современного уровня точности при значительном снижении затрат на обучение и вывод."
                },
                "en": {
                    "title": "Efficient Code Reasoning with ASAP: Smart Compression for Better Performance",
                    "desc": "The paper introduces ASAP, a new framework designed to compress Chain-of-Thought (CoT) in code reasoning while maintaining essential logical structures. It addresses the challenges posed by long reasoning traces, which can increase training costs and slow down inference. ASAP uses anchor-guided pruning to focus on core reasoning elements and applies a novel first-token surprisal metric to identify critical reasoning steps. The results demonstrate that ASAP not only improves efficiency by reducing token generation and inference latency but also maintains high accuracy in code generation tasks."
                },
                "zh": {
                    "title": "ASAP：高效的代码推理思维链压缩框架",
                    "desc": "本文提出了一种名为ASAP的新的粗到细框架，用于压缩代码推理中的思维链（CoT），旨在保留核心结构和关键步骤，从而降低成本并提高效率。ASAP首先通过锚点引导修剪来保留核心推理结构，减少后续处理的搜索空间。接着，它基于新颖的首个令牌惊讶度指标，选择逻辑上重要的推理步骤进行逻辑感知修剪。实验结果表明，ASAP在多个代码生成基准上实现了最先进的准确性，同时显著降低了训练和推理成本。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.04825",
            "title": "Voost: A Unified and Scalable Diffusion Transformer for Bidirectional\n  Virtual Try-On and Try-Off",
            "url": "https://huggingface.co/papers/2508.04825",
            "abstract": "Voost, a unified diffusion transformer framework, jointly learns virtual try-on and try-off, enhancing garment-body correspondence and achieving state-of-the-art results across benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Virtual try-on aims to synthesize a realistic image of a person wearing a target garment, but accurately modeling garment-body correspondence remains a persistent challenge, especially under pose and appearance variation. In this paper, we propose Voost - a unified and scalable framework that jointly learns virtual try-on and try-off with a single diffusion transformer. By modeling both tasks jointly, Voost enables each garment-person pair to supervise both directions and supports flexible conditioning over generation direction and garment category, enhancing garment-body relational reasoning without task-specific networks, auxiliary losses, or additional labels. In addition, we introduce two inference-time techniques: attention temperature scaling for robustness to resolution or mask variation, and self-corrective sampling that leverages bidirectional consistency between tasks. Extensive experiments demonstrate that Voost achieves state-of-the-art results on both try-on and try-off benchmarks, consistently outperforming strong baselines in alignment accuracy, visual fidelity, and generalization.",
            "score": 7,
            "issue_id": 5272,
            "pub_date": "2025-08-06",
            "pub_date_card": {
                "ru": "6 августа",
                "en": "August 6",
                "zh": "8月6日"
            },
            "hash": "085e45094380ed54",
            "authors": [
                "Seungyong Lee",
                "Jeong-gi Kwak"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2508.04825.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#cv",
                    "#optimization",
                    "#inference",
                    "#architecture",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "👚",
                "ru": {
                    "title": "Voost: революция в виртуальной примерке одежды",
                    "desc": "Voost - это унифицированная система на основе диффузионного трансформера, которая совместно обучается виртуальной примерке одежды и ее снятию. Она улучшает соответствие между одеждой и телом человека, используя двунаправленную согласованность между задачами. Voost поддерживает гибкое управление направлением генерации и категорией одежды без специфичных для задачи сетей. Система достигает лучших результатов на различных тестовых наборах данных, превосходя существующие методы по точности сопоставления и визуальному качеству."
                },
                "en": {
                    "title": "Voost: Revolutionizing Virtual Try-On with Unified Learning",
                    "desc": "Voost is a new framework that uses a diffusion transformer to improve virtual try-on and try-off tasks in fashion technology. It learns to create realistic images of people wearing clothes by understanding how garments fit the body, even when poses and appearances change. By training both tasks together, Voost enhances the relationship between garments and bodies without needing extra networks or labels. The framework also includes innovative techniques to improve performance during image generation, leading to top results in accuracy and visual quality across various benchmarks."
                },
                "zh": {
                    "title": "Voost：虚拟试穿与试脱的统一框架",
                    "desc": "Voost是一个统一的扩散变换器框架，能够同时学习虚拟试穿和试脱。它通过联合建模这两个任务，增强了服装与身体之间的对应关系，解决了在姿势和外观变化下的挑战。该框架支持灵活的生成方向和服装类别，避免了特定任务的网络和额外标签。实验结果表明，Voost在试穿和试脱的基准测试中均取得了最先进的成果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.05502",
            "title": "MELLA: Bridging Linguistic Capability and Cultural Groundedness for\n  Low-Resource Language MLLMs",
            "url": "https://huggingface.co/papers/2508.05502",
            "abstract": "MELLA, a multimodal, multilingual dataset, enhances MLLMs in low-resource languages by improving linguistic capability and cultural groundedness through native web alt-text and MLLM-generated captions.  \t\t\t\t\tAI-generated summary \t\t\t\t Multimodal Large Language Models (MLLMs) have shown remarkable performance in high-resource languages. However, their effectiveness diminishes significantly in the contexts of low-resource languages. Current multilingual enhancement methods are often limited to text modality or rely solely on machine translation. While such approaches help models acquire basic linguistic capabilities and produce \"thin descriptions\", they neglect the importance of multimodal informativeness and cultural groundedness, both of which are crucial for serving low-resource language users effectively. To bridge this gap, in this study, we identify two significant objectives for a truly effective MLLM in low-resource language settings, namely 1) linguistic capability and 2) cultural groundedness, placing special emphasis on cultural awareness. To achieve these dual objectives, we propose a dual-source strategy that guides the collection of data tailored to each goal, sourcing native web alt-text for culture and MLLM-generated captions for linguistics. As a concrete implementation, we introduce MELLA, a multimodal, multilingual dataset. Experiment results show that after fine-tuning on MELLA, there is a general performance improvement for the eight languages on various MLLM backbones, with models producing \"thick descriptions\". We verify that the performance gains are from both cultural knowledge enhancement and linguistic capability enhancement. Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.",
            "score": 0,
            "issue_id": 5272,
            "pub_date": "2025-08-07",
            "pub_date_card": {
                "ru": "7 августа",
                "en": "August 7",
                "zh": "8月7日"
            },
            "hash": "b7b633c31ed6e35e",
            "authors": [
                "Yufei Gao",
                "Jiaying Fei",
                "Nuo Chen",
                "Ruirui Chen",
                "Guohang Yan",
                "Yunshi Lan",
                "Botian Shi"
            ],
            "affiliations": [
                "East China Normal University",
                "Institute of High Performance Computing, A*STAR",
                "Shanghai Artificial Intelligence Laboratory",
                "The Chinese University of Hong Kong, Shenzhen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.05502.jpg",
            "data": {
                "categories": [
                    "#low_resource",
                    "#dataset",
                    "#multilingual",
                    "#training",
                    "#data",
                    "#multimodal"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "MELLA: Расширение горизонтов MLLM для низкоресурсных языков",
                    "desc": "Датасет MELLA представляет собой многомодальный многоязычный набор данных, направленный на улучшение работы мультимодальных больших языковых моделей (MLLM) для низкоресурсных языков. MELLA использует двойной подход, сочетая альтернативный текст с веб-страниц и подписи, сгенерированные MLLM, для улучшения лингвистических возможностей и культурной осведомленности моделей. Эксперименты показали общее улучшение производительности для восьми языков на различных архитектурах MLLM после дообучения на MELLA. Результаты подтверждают, что улучшения связаны как с расширением культурных знаний, так и с повышением лингвистических способностей моделей."
                },
                "en": {
                    "title": "Enhancing MLLMs for Low-Resource Languages with MELLA",
                    "desc": "This paper introduces MELLA, a new dataset designed to improve Multimodal Large Language Models (MLLMs) for low-resource languages. It focuses on enhancing both linguistic capabilities and cultural groundedness by using native web alt-text and MLLM-generated captions. The study highlights the limitations of existing methods that rely solely on text or machine translation, which often fail to provide rich, informative content. By fine-tuning MLLMs on MELLA, the results show significant performance improvements across multiple languages, enabling models to generate more detailed and culturally aware descriptions."
                },
                "zh": {
                    "title": "提升低资源语言的多模态语言模型",
                    "desc": "MELLA是一个多模态、多语言的数据集，旨在提升低资源语言中的多模态大型语言模型（MLLM）的语言能力和文化基础。该研究提出了一种双源策略，通过收集本地网页的替代文本和MLLM生成的标题，来实现语言能力和文化基础的双重目标。实验结果表明，在MELLA上进行微调后，八种语言的模型在多种MLLM基础上普遍提高了性能，能够生成更丰富的描述。我们的数据集强调了文化知识和语言能力的增强，适用于低资源语言用户。"
                }
            }
        }
    ],
    "link_prev": "2025-08-08.html",
    "link_next": "2025-08-12.html",
    "link_month": "2025-08.html",
    "short_date_prev": {
        "ru": "08.08",
        "en": "08/08",
        "zh": "8月8日"
    },
    "short_date_next": {
        "ru": "12.08",
        "en": "08/12",
        "zh": "8月12日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 2,
        "#benchmark": 3,
        "#agents": 1,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    }
}