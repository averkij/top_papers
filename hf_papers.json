{
    "date": {
        "ru": "25 июля",
        "en": "July 25",
        "zh": "7月25日"
    },
    "time_utc": "2025-07-25 02:57",
    "weekday": 4,
    "issue_id": 5005,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.18537",
            "title": "TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive\n  Generation",
            "url": "https://huggingface.co/papers/2507.18537",
            "abstract": "TTS-VAR, a test-time scaling framework for visual auto-regressive models, improves generation quality by dynamically adjusting batch sizes and using clustering and resampling techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Scaling visual generation models is essential for real-world content creation, yet requires substantial training and computational expenses. Alternatively, test-time scaling has garnered growing attention due to resource efficiency and promising performance. In this work, we present TTS-VAR, the first general test-time scaling framework for visual auto-regressive (VAR) models, modeling the generation process as a path searching problem. To dynamically balance computational efficiency with exploration capacity, we first introduce an adaptive descending batch size schedule throughout the causal generation process. Besides, inspired by VAR's hierarchical coarse-to-fine multi-scale generation, our framework integrates two key components: (i) At coarse scales, we observe that generated tokens are hard for evaluation, possibly leading to erroneous acceptance of inferior samples or rejection of superior samples. Noticing that the coarse scales contain sufficient structural information, we propose clustering-based diversity search. It preserves structural variety through semantic feature clustering, enabling later selection on samples with higher potential. (ii) In fine scales, resampling-based potential selection prioritizes promising candidates using potential scores, which are defined as reward functions incorporating multi-scale generation history. Experiments on the powerful VAR model Infinity show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights reveal that early-stage structural features effectively influence final quality, and resampling efficacy varies across generation scales. Code is available at https://github.com/ali-vilab/TTS-VAR.",
            "score": 1,
            "issue_id": 5005,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 июля",
                "en": "July 24",
                "zh": "7月24日"
            },
            "hash": "acf3b32f27e7342b",
            "authors": [
                "Zhekai Chen",
                "Ruihang Chu",
                "Yukang Chen",
                "Shiwei Zhang",
                "Yujie Wei",
                "Yingya Zhang",
                "Xihui Liu"
            ],
            "affiliations": [
                "CUHK",
                "HKU MMLab",
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18537.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Умное масштабирование для лучшей генерации изображений",
                    "desc": "TTS-VAR - это новая система масштабирования визуальных авторегрессионных моделей во время тестирования. Она улучшает качество генерации изображений, динамически регулируя размеры батчей и применяя методы кластеризации и ресэмплинга. TTS-VAR моделирует процесс генерации как задачу поиска пути, балансируя вычислительную эффективность и способность к исследованию. Эксперименты показали значительное улучшение оценки GenEval на 8.7% для модели Infinity."
                },
                "en": {
                    "title": "Dynamic Scaling for Enhanced Visual Generation Quality",
                    "desc": "TTS-VAR is a novel framework designed to enhance the quality of visual auto-regressive (VAR) models during the generation process. It introduces a dynamic batch size adjustment strategy that balances computational efficiency with the ability to explore diverse outputs. The framework employs clustering techniques at coarse scales to maintain structural diversity and resampling methods at fine scales to prioritize high-potential candidates based on their generation history. Experiments demonstrate a significant improvement in generation quality, highlighting the importance of early-stage features in the overall output."
                },
                "zh": {
                    "title": "动态调整，提升生成质量的创新框架",
                    "desc": "TTS-VAR是一个用于视觉自回归模型的测试时间缩放框架，通过动态调整批量大小和使用聚类与重采样技术来提高生成质量。该框架将生成过程建模为路径搜索问题，旨在平衡计算效率与探索能力。它在粗尺度上采用基于聚类的多样性搜索，以保留结构多样性，并在细尺度上通过重采样优先选择潜在的优质样本。实验结果表明，TTS-VAR在强大的VAR模型Infinity上实现了8.7%的GenEval分数提升，显示出早期结构特征对最终质量的有效影响。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.16535",
            "title": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent\n  Diffusion",
            "url": "https://huggingface.co/papers/2507.16535",
            "abstract": "Despite the remarkable developments achieved by recent 3D generation works, scaling these methods to geographic extents, such as modeling thousands of square kilometers of Earth's surface, remains an open challenge. We address this through a dual innovation in data infrastructure and model architecture. First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date, consisting of 50k curated scenes (each measuring 600m x 600m) captured across the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene provides pose-annotated multi-view images, depth maps, normals, semantic segmentation, and camera poses, with explicit quality control to ensure terrain diversity. Building on this foundation, we propose EarthCrafter, a tailored framework for large-scale 3D Earth generation via sparse-decoupled latent diffusion. Our architecture separates structural and textural generation: 1) Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the costly computation suffering from vast geographic scales while preserving critical information. 2) We propose condition-aware flow matching models trained on mixed inputs (semantics, images, or neither) to flexibly model latent geometry and texture features independently. Extensive experiments demonstrate that EarthCrafter performs substantially better in extremely large-scale generation. The framework further supports versatile applications, from semantic-guided urban layout generation to unconditional terrain synthesis, while maintaining geographic plausibility through our rich data priors from Aerial-Earth3D. Our project page is available at https://whiteinblue.github.io/earthcrafter/",
            "score": 1,
            "issue_id": 5005,
            "pub_date": "2025-07-22",
            "pub_date_card": {
                "ru": "22 июля",
                "en": "July 22",
                "zh": "7月22日"
            },
            "hash": "7ee137161bbe047e",
            "authors": [
                "Shang Liu",
                "Chenjie Cao",
                "Chaohui Yu",
                "Wen Qian",
                "Jing Wang",
                "Fan Wang"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group",
                "Fudan University",
                "Hupan Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.16535.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#architecture",
                    "#synthetic",
                    "#3d",
                    "#dataset"
                ],
                "emoji": "🌎",
                "ru": {
                    "title": "EarthCrafter: революция в широкомасштабном 3D-моделировании Земли",
                    "desc": "Статья представляет Aerial-Earth3D - крупнейший набор данных 3D аэросъемки, охватывающий 50 тысяч сцен по всей территории США. На основе этих данных разработан фреймворк EarthCrafter для широкомасштабной генерации 3D-моделей земной поверхности с использованием разреженной латентной диффузии. Архитектура EarthCrafter разделяет генерацию структуры и текстуры, применяя сжатие геометрии и текстур в компактные латентные пространства. Модель демонстрирует превосходные результаты в генерации крупномасштабных 3D-сцен и поддерживает различные приложения, сохраняя географическую достоверность."
                },
                "en": {
                    "title": "Revolutionizing Large-Scale 3D Earth Generation",
                    "desc": "This paper presents a solution to the challenge of generating large-scale 3D models of Earth's surface by introducing a new dataset and a novel model architecture. The Aerial-Earth3D dataset is the largest of its kind, containing 50,000 scenes with detailed annotations that support diverse terrain representation. The EarthCrafter framework utilizes a dual approach with sparse-decoupled latent diffusion, allowing for efficient generation of 3D structures and textures while managing computational costs. The results show significant improvements in generating realistic and plausible large-scale 3D environments, with applications in urban planning and terrain synthesis."
                },
                "zh": {
                    "title": "大规模3D地球生成的新突破",
                    "desc": "尽管最近的3D生成技术取得了显著进展，但将这些方法扩展到大规模地理范围仍然是一个挑战。我们通过数据基础设施和模型架构的双重创新来解决这个问题。我们介绍了Aerial-Earth3D，这是迄今为止最大的3D航空数据集，包含50,000个场景，支持大规模的3D地球生成。基于此，我们提出了EarthCrafter框架，通过稀疏解耦的潜在扩散技术，实现了高效的地形生成。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.14988",
            "title": "DMOSpeech 2: Reinforcement Learning for Duration Prediction in\n  Metric-Optimized Speech Synthesis",
            "url": "https://huggingface.co/papers/2507.14988",
            "abstract": "DMOSpeech 2 optimizes duration prediction and introduces teacher-guided sampling to enhance speech synthesis performance and diversity.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion-based text-to-speech (TTS) systems have made remarkable progress in zero-shot speech synthesis, yet optimizing all components for perceptual metrics remains challenging. Prior work with DMOSpeech demonstrated direct metric optimization for speech generation components, but duration prediction remained unoptimized. This paper presents DMOSpeech 2, which extends metric optimization to the duration predictor through a reinforcement learning approach. The proposed system implements a novel duration policy framework using group relative preference optimization (GRPO) with speaker similarity and word error rate as reward signals. By optimizing this previously unoptimized component, DMOSpeech 2 creates a more complete metric-optimized synthesis pipeline. Additionally, this paper introduces teacher-guided sampling, a hybrid approach leveraging a teacher model for initial denoising steps before transitioning to the student model, significantly improving output diversity while maintaining efficiency. Comprehensive evaluations demonstrate superior performance across all metrics compared to previous systems, while reducing sampling steps by half without quality degradation. These advances represent a significant step toward speech synthesis systems with metric optimization across multiple components. The audio samples, code and pre-trained models are available at https://dmospeech2.github.io/.",
            "score": 0,
            "issue_id": 5005,
            "pub_date": "2025-07-20",
            "pub_date_card": {
                "ru": "20 июля",
                "en": "July 20",
                "zh": "7月20日"
            },
            "hash": "27df664b6cc093b4",
            "authors": [
                "Yinghao Aaron Li",
                "Xilin Jiang",
                "Fei Tao",
                "Cheng Niu",
                "Kaifeng Xu",
                "Juntong Song",
                "Nima Mesgarani"
            ],
            "affiliations": [
                "Columbia University",
                "NewsBreak"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.14988.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#training",
                    "#rl",
                    "#audio",
                    "#optimization"
                ],
                "emoji": "🎙️",
                "ru": {
                    "title": "Оптимизация синтеза речи на всех уровнях",
                    "desc": "DMOSpeech 2 - это улучшенная система синтеза речи, оптимизирующая предсказание длительности звуков с помощью обучения с подкреплением. Система использует новый подход к политике длительности, основанный на групповой оптимизации относительных предпочтений (GRPO) с использованием схожести голоса диктора и уровня ошибок распознавания слов в качестве сигналов вознаграждения. DMOSpeech 2 также вводит метод выборки с учительским руководством, что улучшает разнообразие выходных данных при сохранении эффективности. Комплексные оценки показывают превосходную производительность по всем метрикам по сравнению с предыдущими системами."
                },
                "en": {
                    "title": "Optimizing Duration for Diverse Speech Synthesis",
                    "desc": "DMOSpeech 2 enhances speech synthesis by optimizing duration prediction, which was previously unaddressed. It employs a reinforcement learning strategy with group relative preference optimization (GRPO) to improve the duration predictor using metrics like speaker similarity and word error rate. Additionally, the paper introduces teacher-guided sampling, which combines a teacher model for initial processing with a student model for efficiency, leading to greater output diversity. Overall, DMOSpeech 2 achieves superior performance in speech synthesis while reducing the number of sampling steps needed, marking a significant advancement in metric-optimized TTS systems."
                },
                "zh": {
                    "title": "优化语音合成，提升多样性与效率",
                    "desc": "DMOSpeech 2 是一种优化语音合成中持续时间预测的新方法，采用了强化学习的策略来提升合成效果。该系统引入了基于组相对偏好的优化框架，利用说话者相似性和词错误率作为奖励信号，从而优化了之前未优化的持续时间预测组件。除此之外，DMOSpeech 2 还采用了教师引导采样的方法，通过教师模型进行初步去噪，再转向学生模型，从而显著提高了输出的多样性。综合评估结果显示，该系统在各项指标上均优于之前的系统，同时将采样步骤减少了一半，且没有降低质量。"
                }
            }
        }
    ],
    "link_prev": "2025-07-24.html",
    "link_next": "2025-07-28.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "24.07",
        "en": "07/24",
        "zh": "7月24日"
    },
    "short_date_next": {
        "ru": "28.07",
        "en": "07/28",
        "zh": "7月28日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 1,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}