{
    "date": {
        "ru": "28 Ğ¸ÑĞ»Ñ",
        "en": "July 28",
        "zh": "7æœˆ28æ—¥"
    },
    "time_utc": "2025-07-28 05:22",
    "weekday": 0,
    "issue_id": 5038,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.10510",
            "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from\n  Human to AI",
            "url": "https://huggingface.co/papers/2507.10510",
            "abstract": "Artic addresses latency issues in AI Video Chat by optimizing video streaming and frame rate adaptation to enhance MLLM accuracy and reduce bitrate.  \t\t\t\t\tAI-generated summary \t\t\t\t AI Video Chat emerges as a new paradigm for Real-time Communication (RTC), where one peer is not a human, but a Multimodal Large Language Model (MLLM). This makes interaction between humans and AI more intuitive, as if chatting face-to-face with a real person. However, this poses significant challenges to latency, because the MLLM inference takes up most of the response time, leaving very little time for video streaming. Due to network uncertainty and instability, transmission latency becomes a critical bottleneck preventing AI from being like a real person. To address this, we propose Artic, an AI-oriented Real-time Communication framework, exploring the network requirement shift from \"humans watching video\" to \"AI understanding video\". To reduce bitrate dramatically while maintaining MLLM accuracy, we propose Context-Aware Video Streaming that recognizes the importance of each video region for chat and allocates bitrate almost exclusively to chat-important regions. To avoid packet retransmission, we propose Loss-Resilient Adaptive Frame Rate that leverages previous frames to substitute for lost/delayed frames while avoiding bitrate waste. To evaluate the impact of video streaming quality on MLLM accuracy, we build the first benchmark, named Degraded Video Understanding Benchmark (DeViBench). Finally, we discuss some open questions and ongoing solutions for AI Video Chat.",
            "score": 1,
            "issue_id": 5037,
            "pub_date": "2025-07-14",
            "pub_date_card": {
                "ru": "14 Ğ¸ÑĞ»Ñ",
                "en": "July 14",
                "zh": "7æœˆ14æ—¥"
            },
            "hash": "d931480372d88084",
            "authors": [
                "Jiangkai Wu",
                "Zhiyuan Ren",
                "Liming Liu",
                "Xinggong Zhang"
            ],
            "affiliations": [
                "Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.10510.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#survey",
                    "#multimodal",
                    "#video"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Artic: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾Ñ‡Ğ°Ñ‚Ğµ Ñ Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Artic - Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ‡Ğ°Ñ‚Ğ° Ñ Ğ˜Ğ˜. ĞĞ½ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼ÑƒÑ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²ÑƒÑ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ Ğ²Ğ¸Ğ´ĞµĞ¾, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ²Ñ‹Ğ´ĞµĞ»ÑĞµÑ‚ Ğ±Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğ¼ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑĞ¼. Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° ĞºĞ°Ğ´Ñ€Ğ¾Ğ², ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ°Ñ Ğº Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ¼, Ğ´Ğ»Ñ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº DeViBench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ½Ğ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Optimizing AI Video Chat for Real-Time Interaction",
                    "desc": "The paper presents Artic, a framework designed to improve latency in AI Video Chat by optimizing video streaming and frame rate adaptation. It focuses on enhancing the accuracy of Multimodal Large Language Models (MLLMs) while minimizing the bitrate required for video transmission. By implementing Context-Aware Video Streaming, Artic prioritizes important video regions for chat, ensuring efficient bitrate allocation. Additionally, the Loss-Resilient Adaptive Frame Rate technique helps maintain video quality by using previous frames to compensate for lost or delayed ones, thus addressing the challenges posed by network instability."
                },
                "zh": {
                    "title": "ä¼˜åŒ–AIè§†é¢‘èŠå¤©ï¼Œæå‡å®æ—¶æ²Ÿé€šä½“éªŒ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºArticçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³AIè§†é¢‘èŠå¤©ä¸­çš„å»¶è¿Ÿé—®é¢˜ã€‚é€šè¿‡ä¼˜åŒ–è§†é¢‘æµå’Œå¸§ç‡é€‚åº”ï¼ŒArticèƒ½å¤Ÿæé«˜å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶å‡å°‘æ¯”ç‰¹ç‡ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†é¢‘æµæŠ€æœ¯ï¼Œä¼˜å…ˆåˆ†é…æ¯”ç‰¹ç‡ç»™å¯¹èŠå¤©é‡è¦çš„è§†é¢‘åŒºåŸŸï¼Œä»è€Œæ˜¾è‘—é™ä½æ¯”ç‰¹ç‡ã€‚ä¸ºäº†é¿å…æ•°æ®åŒ…é‡ä¼ ï¼ŒArticè¿˜å¼•å…¥äº†æŠ—ä¸¢åŒ…è‡ªé€‚åº”å¸§ç‡æŠ€æœ¯ï¼Œåˆ©ç”¨ä¹‹å‰çš„å¸§æ¥æ›¿ä»£ä¸¢å¤±æˆ–å»¶è¿Ÿçš„å¸§ï¼Œè¿›ä¸€æ­¥æå‡äº†è§†é¢‘èŠå¤©çš„æµç•…æ€§ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-07-25.html",
    "link_next": "2025-07-29.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "25.07",
        "en": "07/25",
        "zh": "7æœˆ25æ—¥"
    },
    "short_date_next": {
        "ru": "29.07",
        "en": "07/29",
        "zh": "7æœˆ29æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}