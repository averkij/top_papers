{
    "date": {
        "ru": "20 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
        "en": "November 20",
        "zh": "11æœˆ20æ—¥"
    },
    "time_utc": "2024-11-20 03:22",
    "weekday": 2,
    "issue_id": 674,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.11925",
            "title": "Continuous Speculative Decoding for Autoregressive Image Generation",
            "url": "https://huggingface.co/papers/2411.11925",
            "abstract": "Continuous-valued Autoregressive (AR) image generation models have demonstrated notable superiority over their discrete-token counterparts, showcasing considerable reconstruction quality and higher generation fidelity. However, the computational demands of the autoregressive framework result in significant inference overhead. While speculative decoding has proven effective in accelerating Large Language Models (LLMs), their adaptation to continuous-valued visual autoregressive models remains unexplored. This work generalizes the speculative decoding algorithm from discrete tokens to continuous space. By analyzing the intrinsic properties of output distribution, we establish a tailored acceptance criterion for the diffusion distributions prevalent in such models. To overcome the inconsistency that occurred in speculative decoding output distributions, we introduce denoising trajectory alignment and token pre-filling methods. Additionally, we identify the hard-to-sample distribution in the rejection phase. To mitigate this issue, we propose a meticulous acceptance-rejection sampling method with a proper upper bound, thereby circumventing complex integration. Experimental results show that our continuous speculative decoding achieves a remarkable 2.33times speed-up on off-the-shelf models while maintaining the output distribution. Codes will be available at https://github.com/MarkXCloud/CSpD",
            "score": 0,
            "issue_id": 674,
            "pub_date": "2024-11-18",
            "pub_date_card": {
                "ru": "18 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
                "en": "November 18",
                "zh": "11æœˆ18æ—¥"
            },
            "hash": "17049106ecc06192",
            "authors": [
                "Zili Wang",
                "Robert Zhang",
                "Kun Ding",
                "Qi Yang",
                "Fei Li",
                "Shiming Xiang"
            ],
            "affiliations": [
                "China Tower Corporation Limited",
                "Institute of Automation, Chinese Academy of Sciences, China",
                "University of Chinese Academy of Sciences, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.11925.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#diffusion",
                    "#cv"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹: Ğ¾Ñ‚ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğº Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğ¼Ñƒ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€ÑƒÑÑ‚ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ ÑĞ¿ĞµĞºÑƒĞ»ÑÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ€Ğ°Ğ½ĞµĞµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞ²ÑˆĞ¸Ğ¹ÑÑ Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğº Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ñƒ. ĞĞ½Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ğ´Ğ»Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ 2.33-ĞºÑ€Ğ°Ñ‚Ğ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· ÑƒÑ…ÑƒĞ´ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "Speeding Up Image Generation with Continuous Speculative Decoding",
                    "desc": "This paper presents a new approach to improve the speed of continuous-valued autoregressive image generation models. It adapts speculative decoding, a technique previously used in large language models, to work with continuous data. The authors introduce methods to align denoising trajectories and pre-fill tokens to enhance the output quality during the decoding process. Their experiments demonstrate that this new method can significantly speed up the generation process by over two times while preserving the quality of the generated images."
                },
                "zh": {
                    "title": "åŠ é€Ÿè¿ç»­å€¼è‡ªå›å½’å›¾åƒç”Ÿæˆçš„æ¨æµ‹è§£ç ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹è¿ç»­å€¼è‡ªå›å½’å›¾åƒç”Ÿæˆæ¨¡å‹çš„æ¨æµ‹è§£ç ç®—æ³•ï¼Œæ—¨åœ¨æé«˜ç”Ÿæˆé€Ÿåº¦ã€‚é€šè¿‡åˆ†æè¾“å‡ºåˆ†å¸ƒçš„å†…åœ¨ç‰¹æ€§ï¼Œå»ºç«‹äº†é€‚åˆæ‰©æ•£åˆ†å¸ƒçš„æ¥å—æ ‡å‡†ã€‚ä¸ºäº†è§£å†³æ¨æµ‹è§£ç è¾“å‡ºåˆ†å¸ƒçš„ä¸ä¸€è‡´æ€§ï¼Œæœ¬æ–‡å¼•å…¥äº†å»å™ªè½¨è¿¹å¯¹é½å’Œä»¤ç‰Œé¢„å¡«å……æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè¾“å‡ºåˆ†å¸ƒçš„åŒæ—¶ï¼Œå®ç°äº†2.33å€çš„é€Ÿåº¦æå‡ã€‚"
                }
            }
        }
    ],
    "link_prev": "2024-11-19.html",
    "link_next": "2024-11-21.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "19.11",
        "en": "11/19",
        "zh": "11æœˆ19æ—¥"
    },
    "short_date_next": {
        "ru": "21.11",
        "en": "11/21",
        "zh": "11æœˆ21æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å…´èµ·åŠå…¶åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„æ½œåŠ›ã€‚æ‰‹æœºæ˜¯éƒ¨ç½²MLLMsçš„æœ€ä½³å¹³å°ï¼Œä½†ç”±äºå†…å­˜å’Œè®¡ç®—èƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥å®ç°æµç•…çš„å®æ—¶å¤„ç†ã€‚æ–‡ç« æå‡ºäº†BlueLM-V-3Bï¼Œä¸€ç§ä¸“ä¸ºç§»åŠ¨å¹³å°è®¾è®¡çš„ç®—æ³•å’Œç³»ç»Ÿã€‚å®ƒé€šè¿‡é‡æ–°è®¾è®¡åŠ¨æ€åˆ†è¾¨ç‡æ–¹æ¡ˆå’Œç¡¬ä»¶æ„ŸçŸ¥éƒ¨ç½²ä¼˜åŒ–ï¼Œå®ç°äº†å°å°ºå¯¸ã€å¿«é€Ÿåº¦å’Œå¼ºæ€§èƒ½ã€‚\n\nTranslation:\nThis article discusses the rise of multimodal large language models (MLLMs) and their potential in daily life. Mobile phones are the best platform for deploying MLLMs, but due to memory and computational limitations, real-time processing is challenging. The article presents BlueLM-V-3B, an algorithm and system designed for mobile platforms. It achieves small size, fast speed, and strong performance through dynamic resolution scheme redesign and hardware-aware deployment optimization.",
        "title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices",
        "pinyin": "Sure, here is the pinyin transcription for the given text:\n\nZhÃ¨ piÄn wÃ©n zhÄng jiÃ¨ shÃ o le duÅ mÃ³ tÃ i dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng (MLLMs) de xÄ«ng qÇ jÃ­ qÃ­ zÃ i rÃ¬ chÃ¡ng shÄ“ng huÃ³ zhÅng de qiÃ¡n lÃ¬. ShÇ’u jÄ« shÃ¬ bÃ¹ shÇ” MLLMs de zuÃ¬ jiÄ pÃ­ng tÃ i, dÃ n yÃ³u yÃº nÃ¨i cÃ¹n hÃ© suÃ n jÃ¬ nÃ©ng lÃ¬ yÇ’u xiÃ n, nÃ¡n yÇ shÃ­ xiÃ n liÃº chÃ ng de shÃ­ shÃ­ chÇ” lÇ. WÃ©n zhÄng tÃ­ chÅ« le BlueLM-V-3B, yÄ« zhÇ’ng zhuÄn wÃ¨i yÃ­ dÃ²ng pÃ­ng tÃ i shÃ¨ jÃ¬ de suÃ n fÇ hÃ© xÃ¬ tÇ’ng. TÄ tÅng guÃ² chÃ³ng xÄ«n shÃ¨ jÃ¬ dÃ²ng tÃ i fÄ“n biÃ© lÇœ fÄng Än hÃ© yÃ¬ng jiÃ n gÇn zhÄ« bÃ¹ shÇ” yÅu huÃ , shÃ­ xiÃ n le xiÇo chÇ cÃ¹, kuÃ i sÃ¹ dÃ¹ hÃ© qiÃ¡ng xÃ¬ng nÃ©ng.\n\nTranslation:\nThis article discusses the rise of multimodal large language models (MLLMs) and their potential in daily life. Mobile phones are the best platform for deploying MLLMs, but due to memory and computational limitations, real-time processing is challenging. The article presents BlueLM-V-3B, an algorithm and system designed for mobile platforms. It achieves small size, fast speed, and strong performance through dynamic resolution scheme redesign and hardware-aware deployment optimization.",
        "vocab": "[{'word': 'å¤šæ¨¡æ€', 'pinyin': 'duÅ mÃ³ tÃ i', 'trans': 'multimodal'},\n{'word': 'å¤§è¯­è¨€æ¨¡å‹', 'pinyin': 'dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'large language models'},\n{'word': 'å…´èµ·', 'pinyin': 'xÄ«ng qÇ', 'trans': 'rise'},\n{'word': 'æ½œåŠ›', 'pinyin': 'qiÃ¡n lÃ¬', 'trans': 'potential'},\n{'word': 'éƒ¨ç½²', 'pinyin': 'bÃ¹ shÇ”', 'trans': 'deploy'},\n{'word': 'å¹³å°', 'pinyin': 'pÃ­ng tÃ¡i', 'trans': 'platform'},\n{'word': 'å†…å­˜', 'pinyin': 'nÃ¨i cÃºn', 'trans': 'memory'},\n{'word': 'è®¡ç®—', 'pinyin': 'jÃ¬ suÃ n', 'trans': 'computational'},\n{'word': 'æµç•…', 'pinyin': 'liÃº chÃ ng', 'trans': 'smooth'},\n{'word': 'å®æ—¶', 'pinyin': 'shÃ­ shÃ­', 'trans': 'real-time'},\n{'word': 'å¤„ç†', 'pinyin': 'chÇ” lÇ', 'trans': 'processing'},\n{'word': 'ç®—æ³•', 'pinyin': 'suÃ n fÇ', 'trans': 'algorithm'},\n{'word': 'åŠ¨æ€', 'pinyin': 'dÃ²ng tÃ i', 'trans': 'dynamic'},\n{'word': 'åˆ†è¾¨ç‡', 'pinyin': 'fÄ“n biÃ n lÇœ', 'trans': 'resolution'},\n{'word': 'æ–¹æ¡ˆ', 'pinyin': 'fÄng Ã n', 'trans': 'scheme'},\n{'word': 'ç¡¬ä»¶', 'pinyin': 'yÃ¬ng jiÃ n', 'trans': 'hardware'},\n{'word': 'æ„ŸçŸ¥', 'pinyin': 'gÇn zhÄ«', 'trans': 'aware'},\n{'word': 'ä¼˜åŒ–', 'pinyin': 'yÅu huÃ ', 'trans': 'optimization'}]",
        "trans": "Here's a refined translation of the text:\n\n\"This article explores the emergence of multimodal large language models (MLLMs) and their potential applications in everyday life. While mobile phones serve as an ideal platform for deploying MLLMs, their limited memory and computational power present challenges for smooth real-time processing. To address these issues, the article introduces BlueLM-V-3B, an algorithm and system tailored for mobile platforms. By employing a redesigned dynamic resolution scheme and hardware-aware deployment optimizations, BlueLM-V-3B achieves a compact size, high speed, and robust performance.\"\n\nChanges made:\n1. Used \"explores the emergence\" instead of \"discusses the rise\" for a more formal tone.\n2. Added \"applications in\" for better flow.\n3. Changed \"difficult to achieve\" to \"present challenges for\" to improve phrasing.\n4. Used \"to address these issues\" to create a stronger connection between sentences.\n5. Changed \"it achieves\" to \"By employing... BlueLM-V-3B achieves\" for clarity.\n6. Used \"robust performance\" instead of \"strong performance\" for more natural English.",
        "update_ts": "2024-11-19 09:11"
    }
}