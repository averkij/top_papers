{
    "date": {
        "ru": "18 —Ñ–µ–≤—Ä–∞–ª—è",
        "en": "February 18",
        "zh": "2Êúà18Êó•"
    },
    "time_utc": "2025-02-18 09:11",
    "weekday": 1,
    "issue_id": 2269,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.12152",
            "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
            "url": "https://huggingface.co/papers/2502.12152",
            "abstract": "Automatic fall recovery is a crucial prerequisite before humanoid robots can be reliably deployed. Hand-designing controllers for getting up is difficult because of the varied configurations a humanoid can end up in after a fall and the challenging terrains humanoid robots are expected to operate on. This paper develops a learning framework to produce controllers that enable humanoid robots to get up from varying configurations on varying terrains. Unlike previous successful applications of humanoid locomotion learning, the getting-up task involves complex contact patterns, which necessitates accurately modeling the collision geometry and sparser rewards. We address these challenges through a two-phase approach that follows a curriculum. The first stage focuses on discovering a good getting-up trajectory under minimal constraints on smoothness or speed / torque limits. The second stage then refines the discovered motions into deployable (i.e. smooth and slow) motions that are robust to variations in initial configuration and terrains. We find these innovations enable a real-world G1 humanoid robot to get up from two main situations that we considered: a) lying face up and b) lying face down, both tested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grass and snowfield). To the best of our knowledge, this is the first successful demonstration of learned getting-up policies for human-sized humanoid robots in the real world. Project page: https://humanoid-getup.github.io/",
            "score": 22,
            "issue_id": 2266,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "c87382b187d7b745",
            "authors": [
                "Xialin He",
                "Runpei Dong",
                "Zixuan Chen",
                "Saurabh Gupta"
            ],
            "affiliations": [
                "Simon Fraser University",
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.12152.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#games",
                    "#robotics",
                    "#optimization"
                ],
                "emoji": "ü§ñ",
                "ru": {
                    "title": "–†–æ–±–æ—Ç—ã —É—á–∞—Ç—Å—è –≤—Å—Ç–∞–≤–∞—Ç—å: –ø—Ä–æ—Ä—ã–≤ –≤ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –≥—É–º–∞–Ω–æ–∏–¥–∞–º–∏",
                    "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É —Å–∏—Å—Ç–µ–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–æ–≤, –ø–æ–∑–≤–æ–ª—è—é—â–∏—Ö –≥—É–º–∞–Ω–æ–∏–¥–Ω—ã–º —Ä–æ–±–æ—Ç–∞–º –≤—Å—Ç–∞–≤–∞—Ç—å –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–π –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—è—Ö. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—É—Ä—Ä–∏–∫—É–ª—É–º–∞: —Å–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –ø–æ–¥—ä–µ–º–∞, –∞ –∑–∞—Ç–µ–º –æ–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏. –°–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –≥—É–º–∞–Ω–æ–∏–¥–Ω–æ–º —Ä–æ–±–æ—Ç–µ G1 –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö, –≤–∫–ª—é—á–∞—è —Å–∫–æ–ª—å–∑–∫–∏–µ –∏ –Ω–∞–∫–ª–æ–Ω–Ω—ã–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏. –≠—Ç–æ –ø–µ—Ä–≤–∞—è —É—Å–ø–µ—à–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø–æ–¥—ä–µ–º–∞ –¥–ª—è –≥—É–º–∞–Ω–æ–∏–¥–Ω—ã—Ö —Ä–æ–±–æ—Ç–æ–≤ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ."
                },
                "en": {
                    "title": "Learning to Get Up: Humanoid Robots Rise to the Challenge!",
                    "desc": "This paper presents a novel learning framework for enabling humanoid robots to recover from falls by getting up from various positions and terrains. The approach consists of a two-phase curriculum where the first phase focuses on discovering effective getting-up trajectories with minimal constraints, while the second phase refines these motions to ensure they are smooth and robust. The framework addresses the complexities of contact patterns and collision geometry, which are critical for the getting-up task. The results demonstrate successful real-world applications, allowing a humanoid robot to rise from both face-up and face-down positions on challenging surfaces."
                },
                "zh": {
                    "title": "‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ëá™‰∏ªËµ∑Ë∫´ÁöÑÂàõÊñ∞Â≠¶‰π†Ê°ÜÊû∂",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ≠¶‰π†Ê°ÜÊû∂Ôºå‰Ωø‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËÉΩÂ§ü‰ªé‰∏çÂêåÁöÑÂßøÂäøÂíåÂú∞ÂΩ¢‰∏≠Ëá™Ë°åÁ´ôËµ∑„ÄÇÁî±‰∫é‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Ë∑åÂÄíÂêéÂèØËÉΩÂ§Ñ‰∫éÂ§öÁßçÂ§çÊùÇÁöÑÂßøÂäøÔºåËÆæËÆ°ÊéßÂà∂Âô®ÈùûÂ∏∏Âõ∞Èöæ„ÄÇÊàë‰ª¨ÈááÁî®‰∫Ü‰∏§Èò∂ÊÆµÁöÑÊñπÊ≥ïÔºåÁ¨¨‰∏ÄÈò∂ÊÆµÂèëÁé∞ÈÄÇÂêàÁöÑËµ∑Ë∫´ËΩ®ËøπÔºåÁ¨¨‰∫åÈò∂ÊÆµÂàôÂ∞ÜËøô‰∫õËΩ®Ëøπ‰ºòÂåñ‰∏∫Âπ≥Êªë‰∏îÁ®≥ÂÅ•ÁöÑÂä®‰Ωú„ÄÇÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ï‰ΩøÂæó‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ËÉΩÂ§üÂú®Â§öÁßçÁúüÂÆûÁéØÂ¢É‰∏≠ÊàêÂäüÁ´ôËµ∑„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11190",
            "title": "ReLearn: Unlearning via Learning for Large Language Models",
            "url": "https://huggingface.co/papers/2502.11190",
            "abstract": "Current unlearning methods for large language models usually rely on reverse optimization to reduce target token probabilities. However, this paradigm disrupts the subsequent tokens prediction, degrading model performance and linguistic coherence. Moreover, existing evaluation metrics overemphasize contextual forgetting while inadequately assessing response fluency and relevance. To address these challenges, we propose ReLearn, a data augmentation and fine-tuning pipeline for effective unlearning, along with a comprehensive evaluation framework. This framework introduces Knowledge Forgetting Rate (KFR) and Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and Linguistic Score (LS) to evaluate generation quality. Our experiments show that ReLearn successfully achieves targeted forgetting while preserving high-quality output. Through mechanistic analysis, we further demonstrate how reverse optimization disrupts coherent text generation, while ReLearn preserves this essential capability. Code is available at https://github.com/zjunlp/unlearn.",
            "score": 11,
            "issue_id": 2266,
            "pub_date": "2025-02-16",
            "pub_date_card": {
                "ru": "16 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 16",
                "zh": "2Êúà16Êó•"
            },
            "hash": "83a57c7c971f5060",
            "authors": [
                "Haoming Xu",
                "Ningyuan Zhao",
                "Liming Yang",
                "Sendong Zhao",
                "Shumin Deng",
                "Mengru Wang",
                "Bryan Hooi",
                "Nay Oo",
                "Huajun Chen",
                "Ningyu Zhang"
            ],
            "affiliations": [
                "Harbin Institute of Technology",
                "National University of Singapore",
                "Tsinghua University",
                "Xiamen University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11190.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#training",
                    "#hallucinations",
                    "#open_source",
                    "#benchmark",
                    "#optimization"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "ReLearn: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞",
                    "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ ReLearn –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑–æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤, ReLearn –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏—è –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏: KFR, KRR –∏ LS. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ ReLearn —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª—è–µ—Ç —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞."
                },
                "en": {
                    "title": "ReLearn: Effective Unlearning Without Sacrificing Coherence",
                    "desc": "This paper introduces ReLearn, a novel approach for unlearning in large language models that avoids the pitfalls of reverse optimization, which can harm the model's ability to predict subsequent tokens. ReLearn employs a data augmentation and fine-tuning pipeline that effectively targets specific knowledge for removal while maintaining the fluency and relevance of generated text. The authors propose new evaluation metrics, including Knowledge Forgetting Rate (KFR) and Knowledge Retention Rate (KRR), to assess the balance between forgetting and retaining knowledge, alongside a Linguistic Score (LS) for output quality. Experimental results demonstrate that ReLearn achieves its unlearning goals without sacrificing the coherence of the model's text generation capabilities."
                },
                "zh": {
                    "title": "ReLearnÔºöÈ´òÊïàÂéªÂ≠¶‰π†‰∏éËØ≠Ë®ÄÁîüÊàêÁöÑÂÆåÁæéÁªìÂêà",
                    "desc": "ÂΩìÂâçÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂéªÂ≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂèçÂêë‰ºòÂåñÊù•Èôç‰ΩéÁõÆÊ†áËØçÁöÑÊ¶ÇÁéá„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÊñπÊ≥ï‰ºöÂπ≤Êâ∞ÂêéÁª≠ËØçÁöÑÈ¢ÑÊµãÔºåÂØºËá¥Ê®°ÂûãÊÄßËÉΩÂíåËØ≠Ë®ÄËøûË¥ØÊÄß‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÁöÑËØÑ‰º∞ÊåáÊ†áËøá‰∫éÂº∫Ë∞É‰∏ä‰∏ãÊñáÈÅóÂøòÔºåËÄåÂØπÂìçÂ∫îÁöÑÊµÅÁïÖÊÄßÂíåÁõ∏ÂÖ≥ÊÄßËØÑ‰º∞‰∏çË∂≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜReLearnÔºå‰∏Ä‰∏™ÊúâÊïàÁöÑÂéªÂ≠¶‰π†ÁöÑÊï∞ÊçÆÂ¢ûÂº∫ÂíåÂæÆË∞ÉÊµÅÁ®ãÔºåÂπ∂ÂºïÂÖ•‰∫ÜÂÖ®Èù¢ÁöÑËØÑ‰º∞Ê°ÜÊû∂„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.12148",
            "title": "HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation",
            "url": "https://huggingface.co/papers/2502.12148",
            "abstract": "The remarkable success of the autoregressive paradigm has made significant advancement in Multimodal Large Language Models (MLLMs), with powerful models like Show-o, Transfusion and Emu3 achieving notable progress in unified image understanding and generation. For the first time, we uncover a common phenomenon: the understanding capabilities of MLLMs are typically stronger than their generative capabilities, with a significant gap between the two. Building on this insight, we propose HermesFlow, a simple yet general framework designed to seamlessly bridge the gap between understanding and generation in MLLMs. Specifically, we take the homologous data as input to curate homologous preference data of both understanding and generation. Through Pair-DPO and self-play iterative optimization, HermesFlow effectively aligns multimodal understanding and generation using homologous preference data. Extensive experiments demonstrate the significant superiority of our approach over prior methods, particularly in narrowing the gap between multimodal understanding and generation. These findings highlight the potential of HermesFlow as a general alignment framework for next-generation multimodal foundation models. Code: https://github.com/Gen-Verse/HermesFlow",
            "score": 9,
            "issue_id": 2265,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "09e80125d90fd3df",
            "authors": [
                "Ling Yang",
                "Xinchen Zhang",
                "Ye Tian",
                "Chenming Shang",
                "Minghao Xu",
                "Wentao Zhang",
                "Bin Cui"
            ],
            "affiliations": [
                "Mila - Quebec AI Institute",
                "Peking University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.12148.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#multimodal",
                    "#dataset",
                    "#alignment"
                ],
                "emoji": "üåâ",
                "ru": {
                    "title": "HermesFlow: –º–æ—Å—Ç –º–µ–∂–¥—É –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ HermesFlow –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM). –ê–≤—Ç–æ—Ä—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ MLLM –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é –æ–±—ã—á–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç –∏—Ö –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏. HermesFlow –ø—Ä–∏–∑–≤–∞–Ω —É—Å—Ç—Ä–∞–Ω–∏—Ç—å —ç—Ç–æ—Ç —Ä–∞–∑—Ä—ã–≤, –∏—Å–ø–æ–ª—å–∑—É—è –≥–æ–º–æ–ª–æ–≥–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –§—Ä–µ–π–º–≤–æ—Ä–∫ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –º–µ—Ç–æ–¥—ã Pair-DPO –∏ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ HermesFlow –Ω–∞–¥ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –≤ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–∏ —Ä–∞–∑—Ä—ã–≤–∞ –º–µ–∂–¥—É –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –≤ MLLM."
                },
                "en": {
                    "title": "Bridging the Gap: Enhancing Understanding and Generation in MLLMs with HermesFlow",
                    "desc": "This paper discusses the advancements in Multimodal Large Language Models (MLLMs) and identifies a key issue: these models often understand information better than they can generate it. The authors introduce HermesFlow, a new framework that aims to improve the balance between understanding and generation in MLLMs. By using homologous data to create preference data for both tasks, HermesFlow employs Pair-DPO and self-play optimization to align these capabilities more effectively. Experimental results show that HermesFlow significantly reduces the performance gap between understanding and generation, suggesting its potential as a foundational model for future multimodal applications."
                },
                "zh": {
                    "title": "HermesFlowÔºöÁº©Â∞èÁêÜËß£‰∏éÁîüÊàêÁöÑÂ∑ÆË∑ù",
                    "desc": "ËøôÁØáËÆ∫ÊñáÊé¢ËÆ®‰∫ÜËá™ÂõûÂΩíËåÉÂºèÂú®Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâ‰∏≠ÁöÑÊàêÂäüÔºåÁâπÂà´ÊòØÂÉèShow-o„ÄÅTransfusionÂíåEmu3ËøôÊ†∑ÁöÑÊ®°ÂûãÂú®ÂõæÂÉèÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢ÁöÑËøõÂ±ï„ÄÇÁ†îÁ©∂ÂèëÁé∞ÔºåMLLMsÁöÑÁêÜËß£ËÉΩÂäõÈÄöÂ∏∏Âº∫‰∫éÁîüÊàêËÉΩÂäõÔºå‰∏§ËÄÖ‰πãÈó¥Â≠òÂú®ÊòæËëóÂ∑ÆË∑ù„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåËÆ∫ÊñáÊèêÂá∫‰∫ÜHermesFlowÊ°ÜÊû∂ÔºåÈÄöËøá‰ΩøÁî®ÂêåÊ∫êÊï∞ÊçÆÊù•‰ºòÂåñÁêÜËß£ÂíåÁîüÊàê‰πãÈó¥ÁöÑÂØπÈΩê„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåHermesFlowÂú®Áº©Â∞èÂ§öÊ®°ÊÄÅÁêÜËß£‰∏éÁîüÊàê‰πãÈó¥ÁöÑÂ∑ÆË∑ùÊñπÈù¢‰ºò‰∫é‰πãÂâçÁöÑÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂‰Ωú‰∏∫‰∏ã‰∏Ä‰ª£Â§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÂØπÈΩêÊ°ÜÊû∂ÁöÑÊΩúÂäõ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11167",
            "title": "SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors",
            "url": "https://huggingface.co/papers/2502.11167",
            "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in code-related tasks, such as code understanding and code generation. However, an equally important yet underexplored question is whether LLMs can serve as general-purpose surrogate code executors, to predict the output and behavior of a program without actually running it. To systematically investigate this capability, we introduce SURGE, a comprehensive benchmark covering eight key aspects: multi-language programming tasks, competition-level programming problems, repository-level code analysis, high-cost scientific computing, time-complexity-intensive algorithms, buggy code analysis, programs dependent on specific compilers or execution environments, and formal mathematical proof verification. We evaluate multiple open-source and proprietary LLMs on SURGE and conduct a scaling study to analyze the impact of model size and training data scale on surrogate execution accuracy. Additionally, we categorize model prediction errors and explore potential areas for improvement. Our findings indicate that while LLMs can predict code execution results in certain cases, they exhibit limitations in general-purpose surrogate execution. This study provides empirical insights into the feasibility of using LLMs as surrogate code executors. Code and dataset are released at https://github.com/Imbernoulli/SURGE.",
            "score": 6,
            "issue_id": 2266,
            "pub_date": "2025-02-16",
            "pub_date_card": {
                "ru": "16 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 16",
                "zh": "2Êúà16Êó•"
            },
            "hash": "99e183fd31de3be0",
            "authors": [
                "Bohan Lyu",
                "Siqiao Huang",
                "Zichen Liang"
            ],
            "affiliations": [
                "Department of Computer Science and Technology, Tsinghua",
                "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11167.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#plp",
                    "#dataset",
                    "#agi",
                    "#open_source",
                    "#benchmark",
                    "#optimization"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "LLM –∫–∞–∫ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–∏ –∫–æ–¥–∞: –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è",
                    "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ SURGE - –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞ –±–µ–∑ –µ–≥–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—É—Å–∫–∞. –ë–µ–Ω—á–º–∞—Ä–∫ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –≤–æ—Å–µ–º—å –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤, –≤–∫–ª—é—á–∞—è –∑–∞–¥–∞—á–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∞–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –∏ –Ω–∞—É—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è. –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö LLM –Ω–∞ SURGE –ø–æ–∫–∞–∑–∞–ª–∞, —á—Ç–æ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞ –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö, –Ω–æ –∏–º–µ—é—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–µ—Ç —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π –∫–æ–¥–∞."
                },
                "en": {
                    "title": "Exploring LLMs as Surrogate Code Executors with SURGE",
                    "desc": "This paper explores the potential of large language models (LLMs) to act as surrogate code executors, which means predicting the output of code without actually running it. The authors introduce a benchmark called SURGE, which tests LLMs on various programming tasks, including multi-language support and analysis of complex algorithms. They evaluate different LLMs to see how well they can predict code execution results and identify common errors in their predictions. The results show that while LLMs can succeed in some scenarios, they still have significant limitations in general-purpose code execution prediction."
                },
                "zh": {
                    "title": "Êé¢Á¥¢Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫‰ª£Á†ÅÊâßË°åÂô®ÁöÑÊΩúÂäõ",
                    "desc": "Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®‰ª£Á†ÅÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÆÉ‰ª¨ËÉΩÂê¶‰Ωú‰∏∫ÈÄöÁî®ÁöÑÊõø‰ª£‰ª£Á†ÅÊâßË°åÂô®Êù•È¢ÑÊµãÁ®ãÂ∫èÁöÑËæìÂá∫ÂíåË°å‰∏∫‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÈáçË¶ÅÈóÆÈ¢ò„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜSURGEÔºå‰∏Ä‰∏™Ê∂µÁõñÂÖ´‰∏™ÂÖ≥ÈîÆÊñπÈù¢ÁöÑÁªºÂêàÂü∫ÂáÜÔºåÂåÖÊã¨Â§öËØ≠Ë®ÄÁºñÁ®ã‰ªªÂä°ÂíåÈ´òÊàêÊú¨ÁßëÂ≠¶ËÆ°ÁÆóÁ≠â„ÄÇÊàë‰ª¨ÂØπÂ§öÁßçÂºÄÊ∫êÂíå‰∏ìÊúâÁöÑLLMsËøõË°å‰∫ÜËØÑ‰º∞ÔºåÂπ∂Á†îÁ©∂‰∫ÜÊ®°ÂûãËßÑÊ®°ÂíåËÆ≠ÁªÉÊï∞ÊçÆËßÑÊ®°ÂØπÊõø‰ª£ÊâßË°åÂáÜÁ°ÆÊÄßÁöÑÂΩ±Âìç„ÄÇÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÂ∞ΩÁÆ°LLMsÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãËÉΩÂ§üÈ¢ÑÊµã‰ª£Á†ÅÊâßË°åÁªìÊûúÔºå‰ΩÜÂú®ÈÄöÁî®Êõø‰ª£ÊâßË°åÊñπÈù¢‰ªçÂ≠òÂú®Â±ÄÈôêÊÄß„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.12115",
            "title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?",
            "url": "https://huggingface.co/papers/2502.12115",
            "abstract": "We introduce SWE-Lancer, a benchmark of over 1,400 freelance software engineering tasks from Upwork, valued at \\1 million USD total in real-world payouts. SWE-Lancer encompasses both independent engineering tasks--ranging from 50 bug fixes to \\$32,000 feature implementations--and managerial tasks, where models choose between technical implementation proposals. Independent tasks are graded with end-to-end tests triple-verified by experienced software engineers, while managerial decisions are assessed against the choices of the original hired engineering managers. We evaluate model performance and find that frontier models are still unable to solve the majority of tasks. To facilitate future research, we open-source a unified Docker image and a public evaluation split, SWE-Lancer Diamond (https://github.com/openai/SWELancer-Benchmark). By mapping model performance to monetary value, we hope SWE-Lancer enables greater research into the economic impact of AI model development.",
            "score": 6,
            "issue_id": 2266,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "0b2638455d4393b0",
            "authors": [
                "Samuel Miserendino",
                "Michele Wang",
                "Tejal Patwardhan",
                "Johannes Heidecke"
            ],
            "affiliations": [
                "OpenAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.12115.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#science",
                    "#benchmark",
                    "#open_source"
                ],
                "emoji": "üíª",
                "ru": {
                    "title": "SWE-Lancer: –ò–∑–º–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ò–ò –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ü–û",
                    "desc": "SWE-Lancer - —ç—Ç–æ –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –±–æ–ª–µ–µ 1400 —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã Upwork –æ–±—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é 1 –º–∏–ª–ª–∏–æ–Ω –¥–æ–ª–ª–∞—Ä–æ–≤. –ó–∞–¥–∞—á–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ (–æ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –¥–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∫—Ä—É–ø–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π) –∏ —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–µ. –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —Ä–µ—à–µ–Ω–∏—è–º–∏ –æ–ø—ã—Ç–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤."
                },
                "en": {
                    "title": "Unlocking AI's Potential in Freelance Software Engineering",
                    "desc": "SWE-Lancer is a new benchmark that includes over 1,400 freelance software engineering tasks sourced from Upwork, with a total value of $1 million. It features both independent tasks, like bug fixes and large feature implementations, and managerial tasks that require decision-making between different technical proposals. The tasks are rigorously evaluated, with independent tasks tested by experienced engineers and managerial decisions compared to those made by original engineering managers. Despite the evaluation, current advanced models struggle to complete most tasks, highlighting the need for further research in AI's economic implications."
                },
                "zh": {
                    "title": "SWE-LancerÔºöÊé®Âä®AIÊ®°ÂûãÁªèÊµéÂΩ±ÂìçÁ†îÁ©∂ÁöÑÂü∫ÂáÜ",
                    "desc": "Êàë‰ª¨‰ªãÁªç‰∫ÜSWE-LancerÔºåËøôÊòØ‰∏Ä‰∏™ÂåÖÂê´1400Â§ö‰∏™Êù•Ëá™UpworkÁöÑËá™Áî±ËΩØ‰ª∂Â∑•Á®ã‰ªªÂä°ÁöÑÂü∫ÂáÜÔºå‰ªªÂä°ÊÄª‰ª∑ÂÄºËææÂà∞100‰∏áÁæéÂÖÉ„ÄÇSWE-LancerÂåÖÊã¨Áã¨Á´ãÁöÑÂ∑•Á®ã‰ªªÂä°ÔºåÂ¶Ç50‰∏™bug‰øÆÂ§çÂíå‰ª∑ÂÄº32000ÁæéÂÖÉÁöÑÂäüËÉΩÂÆûÁé∞Ôºå‰ª•ÂèäÁÆ°ÁêÜ‰ªªÂä°ÔºåÊ®°ÂûãÈúÄË¶ÅÂú®ÊäÄÊúØÂÆûÊñΩÊèêÊ°à‰∏≠ËøõË°åÈÄâÊã©„ÄÇÁã¨Á´ã‰ªªÂä°ÈÄöËøáÁªèÈ™å‰∏∞ÂØåÁöÑËΩØ‰ª∂Â∑•Á®ãÂ∏àËøõË°å‰∏âÈáçÈ™åËØÅÁöÑÁ´ØÂà∞Á´ØÊµãËØïÊù•ËØÑÂàÜÔºåËÄåÁÆ°ÁêÜÂÜ≥Á≠ñÂàô‰∏éÂéüÈõá‰Ω£ÁöÑÂ∑•Á®ãÁªèÁêÜÁöÑÈÄâÊã©ËøõË°åÊØîËæÉ„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫ÜÊ®°ÂûãÁöÑË°®Áé∞ÔºåÂèëÁé∞ÂâçÊ≤øÊ®°Âûã‰ªçÁÑ∂Êó†Ê≥ïËß£ÂÜ≥Â§ßÂ§öÊï∞‰ªªÂä°ÔºåSWE-LancerÁöÑÂºÄÊ∫êÂ∞Ü‰øÉËøõÊú™Êù•ÁöÑÁ†îÁ©∂„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.12146",
            "title": "Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening",
            "url": "https://huggingface.co/papers/2502.12146",
            "abstract": "We propose Diffusion-Sharpening, a fine-tuning approach that enhances downstream alignment by optimizing sampling trajectories. Existing RL-based fine-tuning methods focus on single training timesteps and neglect trajectory-level alignment, while recent sampling trajectory optimization methods incur significant inference NFE costs. Diffusion-Sharpening overcomes this by using a path integral framework to select optimal trajectories during training, leveraging reward feedback, and amortizing inference costs. Our method demonstrates superior training efficiency with faster convergence, and best inference efficiency without requiring additional NFEs. Extensive experiments show that Diffusion-Sharpening outperforms RL-based fine-tuning methods (e.g., Diffusion-DPO) and sampling trajectory optimization methods (e.g., Inference Scaling) across diverse metrics including text alignment, compositional capabilities, and human preferences, offering a scalable and efficient solution for future diffusion model fine-tuning. Code: https://github.com/Gen-Verse/Diffusion-Sharpening",
            "score": 6,
            "issue_id": 2265,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "25a69f8cf847067e",
            "authors": [
                "Ye Tian",
                "Ling Yang",
                "Xinchen Zhang",
                "Yunhai Tong",
                "Mengdi Wang",
                "Bin Cui"
            ],
            "affiliations": [
                "Peking University",
                "Princeton University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.12146.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rlhf",
                    "#optimization",
                    "#diffusion",
                    "#alignment",
                    "#rl"
                ],
                "emoji": "üéØ",
                "ru": {
                    "title": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π",
                    "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç–æ–¥ Diffusion-Sharpening –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ç–µ–≥—Ä–∞–ª—ã –ø–æ –ø—É—Ç—è–º –∏ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—é. Diffusion-Sharpening –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –¥—Ä—É–≥–∏–µ –ø–æ–¥—Ö–æ–¥—ã –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º, –≤–∫–ª—é—á–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ª—é–¥–µ–π."
                },
                "en": {
                    "title": "Optimize Sampling Paths for Better Model Alignment!",
                    "desc": "The paper introduces Diffusion-Sharpening, a novel fine-tuning method that improves the alignment of machine learning models by optimizing the paths taken during sampling. Unlike traditional reinforcement learning (RL) methods that focus on individual training steps, this approach considers the entire trajectory, which enhances overall performance. By employing a path integral framework, Diffusion-Sharpening efficiently selects the best trajectories while minimizing inference costs. Experimental results show that this method not only converges faster but also achieves better performance than existing RL-based and trajectory optimization techniques across various evaluation metrics."
                },
                "zh": {
                    "title": "Êâ©Êï£ÈîêÂåñÔºöÈ´òÊïàÁöÑÂæÆË∞ÉÊñ∞ÊñπÊ≥ï",
                    "desc": "Êàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫Êâ©Êï£ÈîêÂåñÔºàDiffusion-SharpeningÔºâÁöÑÂæÆË∞ÉÊñπÊ≥ïÔºåÈÄöËøá‰ºòÂåñÈááÊ†∑ËΩ®ËøπÊù•Â¢ûÂº∫‰∏ãÊ∏∏ÂØπÈΩê„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÂæÆË∞ÉÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®Âçï‰∏™ËÆ≠ÁªÉÊó∂Èó¥Ê≠•ÔºåÂøΩËßÜ‰∫ÜËΩ®ËøπÁ∫ßÂà´ÁöÑÂØπÈΩêÔºåËÄåÊúÄËøëÁöÑÈááÊ†∑ËΩ®Ëøπ‰ºòÂåñÊñπÊ≥ïÂàôÂ∏¶Êù•‰∫ÜÊòæËëóÁöÑÊé®ÁêÜÊàêÊú¨„ÄÇÊâ©Êï£ÈîêÂåñÈÄöËøá‰ΩøÁî®Ë∑ØÂæÑÁßØÂàÜÊ°ÜÊû∂Âú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÈÄâÊã©ÊúÄ‰Ω≥ËΩ®ËøπÔºåÂà©Áî®Â•ñÂä±ÂèçÈ¶àÂπ∂ÊëäÈîÄÊé®ÁêÜÊàêÊú¨Ôºå‰ªéËÄåÂÖãÊúç‰∫ÜËøô‰∫õÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºåÊâ©Êï£ÈîêÂåñÂú®ËÆ≠ÁªÉÊïàÁéáÂíåÊé®ÁêÜÊïàÁéá‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÁöÑÂæÆË∞ÉÊñπÊ≥ïÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßçÂèØÊâ©Â±ï‰∏îÈ´òÊïàÁöÑÊú™Êù•Êâ©Êï£Ê®°ÂûãÂæÆË∞ÉËß£ÂÜ≥ÊñπÊ°à„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11196",
            "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
            "url": "https://huggingface.co/papers/2502.11196",
            "abstract": "Despite exceptional capabilities in knowledge-intensive tasks, Large Language Models (LLMs) face a critical gap in understanding how they internalize new knowledge, particularly how to structurally embed acquired knowledge in their neural computations. We address this issue through the lens of knowledge circuit evolution, identifying computational subgraphs that facilitate knowledge storage and processing. Our systematic analysis of circuit evolution throughout continual pre-training reveals several key findings: (1) the acquisition of new knowledge is influenced by its relevance to pre-existing knowledge; (2) the evolution of knowledge circuits exhibits a distinct phase shift from formation to optimization; (3) the evolution of knowledge circuits follows a deep-to-shallow pattern. These insights not only advance our theoretical understanding of the mechanisms of new knowledge acquisition in LLMs, but also provide potential implications for improving continual pre-training strategies to enhance model performance. Code and data will be available at https://github.com/zjunlp/DynamicKnowledgeCircuits.",
            "score": 5,
            "issue_id": 2266,
            "pub_date": "2025-02-16",
            "pub_date_card": {
                "ru": "16 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 16",
                "zh": "2Êúà16Êó•"
            },
            "hash": "d97eafe0888b9da4",
            "authors": [
                "Yixin Ou",
                "Yunzhi Yao",
                "Ningyu Zhang",
                "Hui Jin",
                "Jiacheng Sun",
                "Shumin Deng",
                "Zhenguo Li",
                "Huajun Chen"
            ],
            "affiliations": [
                "Huawei Noahs Ark Lab",
                "National University of Singapore, NUS-NCS Joint Lab, Singapore",
                "Zhejiang Key Laboratory of Big Data Intelligent Computing",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11196.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#training",
                    "#architecture",
                    "#transfer_learning",
                    "#optimization"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–†–∞—Å–∫—Ä—ã–≤–∞—è —Ç–∞–π–Ω—ã –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π: —ç–≤–æ–ª—é—Ü–∏—è —Ü–µ–ø–µ–π –∑–Ω–∞–Ω–∏–π –≤ LLM",
                    "desc": "–≠—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ –∏–∑—É—á–µ–Ω–∏—é –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ —É—Å–≤–æ–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –∑–Ω–∞–Ω–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM). –ê–≤—Ç–æ—Ä—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç —ç–≤–æ–ª—é—Ü–∏—é '—Ü–µ–ø–µ–π –∑–Ω–∞–Ω–∏–π' - –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–¥–≥—Ä–∞—Ñ–æ–≤, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –û–Ω–∏ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ —É—Å–≤–æ–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∑–Ω–∞–Ω–∏–π –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∏—Ö —Å–≤—è–∑–∏ —Å —É–∂–µ –∏–º–µ—é—â–∏–º–∏—Å—è, –∞ —ç–≤–æ–ª—é—Ü–∏—è —Ü–µ–ø–µ–π –∑–Ω–∞–Ω–∏–π –ø—Ä–æ—Ö–æ–¥–∏—Ç —Ñ–∞–∑—ã —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –ø–æ–º–æ—á—å —É–ª—É—á—à–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π."
                },
                "en": {
                    "title": "Understanding Knowledge Integration in Large Language Models",
                    "desc": "This paper explores how Large Language Models (LLMs) learn and store new knowledge within their neural networks. It introduces the concept of knowledge circuit evolution, which refers to the computational pathways that help LLMs process and retain information. The study finds that new knowledge is better integrated when it relates to what the model already knows, and that the process of knowledge circuit evolution shifts from forming new connections to optimizing existing ones. Additionally, the research reveals that this evolution tends to move from deeper to shallower layers of the model, offering insights that could improve continual pre-training methods for LLMs."
                },
                "zh": {
                    "title": "ÁêÜËß£Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÁü•ËØÜÂÜÖÂåñ",
                    "desc": "Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Áü•ËØÜÂØÜÈõÜÂûã‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÁêÜËß£Â¶Ç‰ΩïÂÜÖÂåñÊñ∞Áü•ËØÜÊñπÈù¢Â≠òÂú®ÈáçË¶ÅÁº∫Âè£„ÄÇÊú¨ÊñáÈÄöËøáÁü•ËØÜÁîµË∑ØÊºîÂåñÁöÑËßÜËßíÔºåËØÜÂà´Âá∫‰øÉËøõÁü•ËØÜÂ≠òÂÇ®ÂíåÂ§ÑÁêÜÁöÑËÆ°ÁÆóÂ≠êÂõæ„ÄÇÊàë‰ª¨ÁöÑÁ≥ªÁªüÂàÜÊûêË°®ÊòéÔºåÊñ∞Áü•ËØÜÁöÑËé∑ÂèñÂèóÂ∑≤ÊúâÁü•ËØÜÁõ∏ÂÖ≥ÊÄßÁöÑÂΩ±ÂìçÔºåÁü•ËØÜÁîµË∑ØÁöÑÊºîÂåñÁªèÂéÜ‰ªéÂΩ¢ÊàêÂà∞‰ºòÂåñÁöÑÊòéÊòæÈò∂ÊÆµËΩ¨ÂèòÔºåÂπ∂‰∏îÊºîÂåñÊ®°ÂºèÂëàÁé∞Áî±Ê∑±Âà∞ÊµÖÁöÑÁâπÂæÅ„ÄÇËøô‰∫õÂèëÁé∞‰∏ç‰ªÖÊé®Âä®‰∫ÜÊàë‰ª¨ÂØπLLMs‰∏≠Êñ∞Áü•ËØÜËé∑ÂèñÊú∫Âà∂ÁöÑÁêÜËÆ∫ÁêÜËß£ÔºåËøòÊúâÂä©‰∫éÊîπËøõÊåÅÁª≠È¢ÑËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰ªéËÄåÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11438",
            "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL",
            "url": "https://huggingface.co/papers/2502.11438",
            "abstract": "Text-to-SQL aims to convert natural language questions into executable SQL queries. While previous approaches, such as skeleton-masked selection, have demonstrated strong performance by retrieving similar training examples to guide large language models (LLMs), they struggle in real-world scenarios where such examples are unavailable. To overcome this limitation, we propose Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by generating and filtering self-augmented examples. SAFE-SQL first prompts an LLM to generate multiple Text-to-SQL examples relevant to the test input. Then SAFE-SQL filters these examples through three relevance assessments, constructing high-quality in-context learning examples. Using self-generated examples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL frameworks, achieving higher execution accuracy. Notably, our approach provides additional performance gains in extra hard and unseen scenarios, where conventional methods often fail.",
            "score": 5,
            "issue_id": 2264,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "93b545df707b1538",
            "authors": [
                "Jimin Lee",
                "Ingeol Baek",
                "Byeongjeong Kim",
                "Hwanhee Lee"
            ],
            "affiliations": [
                "Department of Artificial Intelligence, Chung-Ang University, Seoul, Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11438.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#dataset",
                    "#transfer_learning",
                    "#optimization",
                    "#training"
                ],
                "emoji": "üîç",
                "ru": {
                    "title": "–°–∞–º–æ—É—Å–∏–ª–µ–Ω–∏–µ –ò–ò –≤ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –≤ SQL",
                    "desc": "SAFE-SQL - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –≤ SQL-–∑–∞–ø—Ä–æ—Å—ã. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, —É–ª—É—á—à–∞—è –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. SAFE-SQL –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –º–µ—Ç–æ–¥—ã –≤ –∑–∞–¥–∞—á–∞—Ö zero-shot –∏ few-shot, –¥–æ—Å—Ç–∏–≥–∞—è –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤. –û—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –≤ —Å–ª–æ–∂–Ω—ã—Ö –∏ —Ä–∞–Ω–µ–µ –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–≤—à–∏—Ö—Å—è —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö, –≥–¥–µ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —á–∞—Å—Ç–æ –Ω–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è."
                },
                "en": {
                    "title": "Transforming Language to SQL with Self-Augmented Learning",
                    "desc": "This paper introduces SAFE-SQL, a new framework for converting natural language questions into SQL queries. It addresses the limitations of previous methods that rely on existing training examples, which may not be available in real-world situations. SAFE-SQL enhances SQL generation by creating and filtering self-generated examples using a large language model (LLM). The framework demonstrates improved execution accuracy, especially in challenging and unseen scenarios, outperforming traditional zero-shot and few-shot approaches."
                },
                "zh": {
                    "title": "Ëá™ÊàëÂ¢ûÂº∫ÔºåÊèêÂçáText-to-SQLÁöÑÂáÜÁ°ÆÊÄß",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊ°ÜÊû∂SAFE-SQLÔºåÁî®‰∫éÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÈóÆÈ¢òËΩ¨Êç¢‰∏∫ÂèØÊâßË°åÁöÑSQLÊü•ËØ¢„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáËá™ÊàëÂ¢ûÂº∫ÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ÂíåÁªÜÁ≤íÂ∫¶Á§∫‰æãÈÄâÊã©Êù•ÊèêÈ´òSQLÁîüÊàêÁöÑË¥®Èáè„ÄÇSAFE-SQLÈ¶ñÂÖàÁîüÊàêÂ§ö‰∏™‰∏éÊµãËØïËæìÂÖ•Áõ∏ÂÖ≥ÁöÑText-to-SQLÁ§∫‰æãÔºåÁÑ∂ÂêéÈÄöËøá‰∏âÁßçÁõ∏ÂÖ≥ÊÄßËØÑ‰º∞ÂØπËøô‰∫õÁ§∫‰æãËøõË°åËøáÊª§Ôºå‰ªéËÄåÊûÑÂª∫È´òË¥®ÈáèÁöÑÂ≠¶‰π†Á§∫‰æã„ÄÇ‰∏é‰º†ÁªüÁöÑÈõ∂Ê†∑Êú¨ÂíåÂ∞ëÊ†∑Êú¨ÊñπÊ≥ïÁõ∏ÊØîÔºåSAFE-SQLÂú®ÊâßË°åÂáÜÁ°ÆÊÄß‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÂ∞§ÂÖ∂Âú®Âõ∞ÈöæÂíåÊú™ËßÅËøáÁöÑÂú∫ÊôØ‰∏≠Ë°®Áé∞Êõ¥‰Ω≥„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.09061",
            "title": "CRANE: Reasoning with constrained LLM generation",
            "url": "https://huggingface.co/papers/2502.09061",
            "abstract": "Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide a theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose a reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-art constrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO.",
            "score": 4,
            "issue_id": 2264,
            "pub_date": "2025-02-13",
            "pub_date_card": {
                "ru": "13 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 13",
                "zh": "2Êúà13Êó•"
            },
            "hash": "4a44947deeb14cf4",
            "authors": [
                "Debangshu Banerjee",
                "Tarun Suresh",
                "Shubham Ugare",
                "Sasa Misailovic",
                "Gagandeep Singh"
            ],
            "affiliations": [
                "Department of Computer Science, University of Illinois Urbana-Champaign, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.09061.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#optimization",
                    "#benchmark",
                    "#reasoning",
                    "#training",
                    "#architecture"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö",
                    "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏ –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (LLM) –¥–ª—è –∑–∞–¥–∞—á, —Ç—Ä–µ–±—É—é—â–∏—Ö —Ñ–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, –ø–æ—á–µ–º—É —Å—Ç—Ä–æ–≥–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö LLM –º–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å –∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é. –û–Ω–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º CRANE, –∫–æ—Ç–æ—Ä—ã–π –±–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –º–µ–∂–¥—É –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å—é –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –≥–∏–±–∫–æ—Å—Ç—å—é –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ CRANE –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –∏ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö —Å–∏–º–≤–æ–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è."
                },
                "en": {
                    "title": "Balancing Correctness and Reasoning in LLM Outputs with CRANE",
                    "desc": "This paper discusses the challenges of generating outputs from large language models (LLMs) that are both correct in form and meaning, especially in tasks like code generation and symbolic reasoning. It explains that overly strict constraints on the grammar can hinder the model's reasoning abilities. The authors propose a new approach called CRANE, which enhances the output grammar with additional rules to maintain reasoning capabilities while ensuring syntactic and semantic correctness. Their experiments show that CRANE outperforms existing methods, achieving significant accuracy improvements on difficult reasoning tasks."
                },
                "zh": {
                    "title": "Âπ≥Ë°°Êé®ÁêÜËÉΩÂäõ‰∏éÁîüÊàêÊ≠£Á°ÆÊÄßÁöÑÂàõÊñ∞Ëß£Á†ÅÁÆóÊ≥ï",
                    "desc": "Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÂú®ÁîüÊàê‰ª£Á†ÅÂíåÁ¨¶Âè∑Êï∞Â≠¶Êé®ÁêÜÁ≠â‰ªªÂä°‰∏≠ÔºåÁ°Æ‰øùÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâËæìÂá∫ÁöÑËØ≠Ê≥ïÂíåËØ≠‰πâÊ≠£Á°ÆÊÄß„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåËøá‰∫é‰∏•Ê†ºÁöÑËØ≠Ê≥ïÁ∫¶Êùü‰ºöÈôç‰ΩéÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËß£Á†ÅÁÆóÊ≥ïCRANEÔºåÈÄöËøáÂ¢ûÂä†Á≤æÂøÉËÆæËÆ°ÁöÑÈ¢ùÂ§ñËßÑÂàôÔºåÊó¢ËÉΩ‰øùÊåÅËæìÂá∫ÁöÑÊ≠£Á°ÆÊÄßÔºåÂèàËÉΩÂ¢ûÂº∫Êé®ÁêÜËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCRANEÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑËß£Á†ÅÁ≠ñÁï•ÔºåÊèêÂçá‰∫ÜÁ¨¶Âè∑Êé®ÁêÜ‰ªªÂä°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11275",
            "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
            "url": "https://huggingface.co/papers/2502.11275",
            "abstract": "Massive high-quality data, both pre-training raw texts and post-training annotations, have been carefully prepared to incubate advanced large language models (LLMs). In contrast, for information extraction (IE), pre-training data, such as BIO-tagged sequences, are hard to scale up. We show that IE models can act as free riders on LLM resources by reframing next-token prediction into extraction for tokens already present in the context. Specifically, our proposed next tokens extraction (NTE) paradigm learns a versatile IE model, Cuckoo, with 102.6M extractive data converted from LLM's pre-training and post-training data. Under the few-shot setting, Cuckoo adapts effectively to traditional and complex instruction-following IE with better performance than existing pre-trained IE models. As a free rider, Cuckoo can naturally evolve with the ongoing advancements in LLM data preparation, benefiting from improvements in LLM training pipelines without additional manual effort.",
            "score": 4,
            "issue_id": 2263,
            "pub_date": "2025-02-16",
            "pub_date_card": {
                "ru": "16 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 16",
                "zh": "2Êúà16Êó•"
            },
            "hash": "6444052efad6f8be",
            "authors": [
                "Letian Peng",
                "Zilong Wang",
                "Feng Yao",
                "Jingbo Shang"
            ],
            "affiliations": [
                "University of California, San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11275.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#dataset",
                    "#data",
                    "#transfer_learning"
                ],
                "emoji": "üê£",
                "ru": {
                    "title": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –ø–ª–µ—á–∞—Ö –≥–∏–≥–∞–Ω—Ç–æ–≤: –∫–∞–∫ IE –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã LLM",
                    "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (IE) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ—Å—É—Ä—Å–æ–≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ú–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º '–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤' (NTE) –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤ –∑–∞–¥–∞—á—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–æ–∫–µ–Ω–æ–≤. –ú–æ–¥–µ–ª—å Cuckoo, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ 102,6 –º–ª–Ω –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —É—Å–ª–æ–≤–∏—è—Ö –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ IE –º–æ–¥–µ–ª—è–º–∏. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç IE –º–æ–¥–µ–ª—è–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è –≤–º–µ—Å—Ç–µ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –≤ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LLM –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä—É—á–Ω—ã—Ö —É—Å–∏–ª–∏–π."
                },
                "en": {
                    "title": "Leveraging LLMs for Enhanced Information Extraction",
                    "desc": "This paper introduces a new approach for information extraction (IE) using large language models (LLMs) as a resource. The authors propose a method called next tokens extraction (NTE), which allows IE models to leverage existing LLM data for training. They present a model named Cuckoo, which is trained on 102.6 million extractive data points derived from LLMs, showing superior performance in few-shot scenarios. Cuckoo's design enables it to adapt to various IE tasks while benefiting from ongoing improvements in LLM training without requiring extra manual data preparation."
                },
                "zh": {
                    "title": "Âà©Áî®LLMÊèêÂçá‰ø°ÊÅØÊèêÂèñÊ®°ÂûãÁöÑÊÄßËÉΩ",
                    "desc": "Êú¨ÊñáÊé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊù•ÊèêÂçá‰ø°ÊÅØÊèêÂèñÔºàIEÔºâÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊèêÂèñÊñπÊ≥ïÔºåÁß∞‰∏∫‰∏ã‰∏ÄÊ†áËÆ∞ÊèêÂèñÔºàNTEÔºâÔºåÈÄöËøáÂ∞Ü‰∏ã‰∏Ä‰∏™Ê†áËÆ∞È¢ÑÊµãËΩ¨Âåñ‰∏∫ÂØπ‰∏ä‰∏ãÊñá‰∏≠Â∑≤Â≠òÂú®Ê†áËÆ∞ÁöÑÊèêÂèñÔºå‰ªéËÄå‰ΩøIEÊ®°ÂûãËÉΩÂ§üÂà©Áî®LLMÁöÑËµÑÊ∫ê„ÄÇÊàë‰ª¨ÂºÄÂèëÁöÑCuckooÊ®°ÂûãÂú®Â∞ëÈáèÊ†∑Êú¨ÁöÑÊÉÖÂÜµ‰∏ãÔºåËÉΩÂ§üÊúâÊïàÈÄÇÂ∫î‰º†ÁªüÂíåÂ§çÊùÇÁöÑÊåá‰ª§Ë∑üÈöèIE‰ªªÂä°ÔºåÂπ∂‰∏îË°®Áé∞‰ºò‰∫éÁé∞ÊúâÁöÑÈ¢ÑËÆ≠ÁªÉIEÊ®°Âûã„ÄÇCuckoo‰Ωú‰∏∫‰∏Ä‰∏™‚ÄúÊê≠‰æøËΩ¶ËÄÖ‚ÄùÔºåËÉΩÂ§üÈöèÁùÄLLMÊï∞ÊçÆÂáÜÂ§áÁöÑËøõÊ≠•ËÄåËá™ÁÑ∂ÊºîÂèòÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑ‰∫∫Â∑•Âä™Âäõ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11901",
            "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity",
            "url": "https://huggingface.co/papers/2502.11901",
            "abstract": "Existing LMs struggle with proof-oriented programming due to data scarcity, which manifest in two key ways: (1) a lack of sufficient corpora for proof-oriented programming languages such as F*, and (2) the absence of large-scale, project-level proof-oriented implementations that can teach the model the intricate reasoning process when performing proof-oriented programming. We present the first on synthetic data augmentation for project level proof oriented programming for both generation and repair. Our method addresses data scarcity by synthesizing basic proof-oriented programming problems for proficiency in that language; incorporating diverse coding data for reasoning capability elicitation and creating new proofs and repair data within existing repositories. This approach enables language models to both synthesize and repair proofs for function- and repository-level code. We show that our fine-tuned 14B parameter model, PoPilot, can exceed the performance of the models that outperforms GPT-4o in project-level proof-oriented programming by 64% relative margin, and can improve GPT-4o's performance by 54% by repairing its outputs over GPT-4o's self-repair.",
            "score": 3,
            "issue_id": 2263,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "9451c99877c67e4d",
            "authors": [
                "Dylan Zhang",
                "Justin Wang",
                "Tianran Sun"
            ],
            "affiliations": [
                "Shanghai Jiaotong University",
                "University of Chicago",
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11901.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#dataset",
                    "#data",
                    "#plp",
                    "#transfer_learning",
                    "#synthetic"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç–∫—Ä—ã–≤–∞—é—Ç –Ω–æ–≤—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã –≤ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏",
                    "desc": "–°—Ç–∞—Ç—å—è –ø–æ—Å–≤—è—â–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –Ω–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –Ω–µ—Ö–≤–∞—Ç–∫–∏ –∫–æ—Ä–ø—É—Å–æ–≤ –Ω–∞ —è–∑—ã–∫–∞—Ö –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω–∏ —Å–æ–∑–¥–∞—é—Ç –º–æ–¥–µ–ª—å PoPilot, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç GPT-4 –Ω–∞ 64% –≤ –∑–∞–¥–∞—á–∞—Ö –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è. –ú–µ—Ç–æ–¥ —Ç–∞–∫–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ª—É—á—à–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã GPT-4 –Ω–∞ 54% –ø—É—Ç–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –µ–≥–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
                },
                "en": {
                    "title": "Enhancing Proof-Oriented Programming with Synthetic Data Augmentation",
                    "desc": "This paper addresses the challenges faced by language models (LMs) in proof-oriented programming due to limited data availability. It introduces a novel approach of synthetic data augmentation to enhance the training of LMs for generating and repairing proofs in programming languages like F*. The method involves creating basic proof-oriented programming problems and utilizing diverse coding data to improve reasoning capabilities. The results demonstrate that the fine-tuned 14B parameter model, PoPilot, significantly outperforms existing models, including GPT-4o, in project-level proof-oriented programming tasks."
                },
                "zh": {
                    "title": "ÂêàÊàêÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèêÂçáËØÅÊòéÁºñÁ®ãËÉΩÂäõÔºÅ",
                    "desc": "Áé∞ÊúâÁöÑËØ≠Ë®ÄÊ®°ÂûãÂú®Èù¢ÂêëËØÅÊòéÁöÑÁºñÁ®ã‰∏≠Èù¢‰∏¥Êï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢òÔºå‰∏ªË¶Å‰ΩìÁé∞Âú®‰∏§‰∏™ÊñπÈù¢ÔºöÁº∫‰πèË∂≥Â§üÁöÑÈù¢ÂêëËØÅÊòéÁºñÁ®ãËØ≠Ë®ÄÔºàÂ¶ÇF*ÔºâÁöÑËØ≠ÊñôÂ∫ìÔºå‰ª•ÂèäÁº∫Â∞ëÂ§ßËßÑÊ®°ÁöÑÈ°πÁõÆÁ∫ßËØÅÊòéÂÆûÁé∞ÔºåÊó†Ê≥ïÊïô‰ºöÊ®°ÂûãÂ§çÊùÇÁöÑÊé®ÁêÜËøáÁ®ã„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂêàÊàêÊï∞ÊçÆÂ¢ûÂº∫ÁöÑÊñπÊ≥ïÔºå‰∏ìÊ≥®‰∫éÈ°πÁõÆÁ∫ßÁöÑÈù¢ÂêëËØÅÊòéÁºñÁ®ãÔºåÊó¢Áî®‰∫éÁîüÊàê‰πüÁî®‰∫é‰øÆÂ§ç„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÂêàÊàêÂü∫Êú¨ÁöÑÈù¢ÂêëËØÅÊòéÁºñÁ®ãÈóÆÈ¢òÊù•Ëß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢òÔºåÂπ∂ÁªìÂêàÂ§öÊ†∑ÂåñÁöÑÁºñÁ†ÅÊï∞ÊçÆ‰ª•ÊèêÈ´òÊé®ÁêÜËÉΩÂäõÔºåÂêåÊó∂Âú®Áé∞Êúâ‰ª£Á†ÅÂ∫ì‰∏≠ÂàõÂª∫Êñ∞ÁöÑËØÅÊòéÂíå‰øÆÂ§çÊï∞ÊçÆ„ÄÇÊàë‰ª¨ÁöÑ14BÂèÇÊï∞Ê®°ÂûãPoPilotÁªèËøáÂæÆË∞ÉÂêéÔºåÂú®È°πÁõÆÁ∫ßÈù¢ÂêëËØÅÊòéÁºñÁ®ã‰∏≠Ë∂ÖË∂ä‰∫ÜGPT-4oÊ®°Âûã64%ÁöÑÊÄßËÉΩÔºåÂπ∂ÈÄöËøá‰øÆÂ§çÂÖ∂ËæìÂá∫ÊèêÈ´ò‰∫Ü54%ÁöÑÊÄßËÉΩ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.12054",
            "title": "PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning",
            "url": "https://huggingface.co/papers/2502.12054",
            "abstract": "Large language models demonstrate remarkable capabilities across various domains, especially mathematics and logic reasoning. However, current evaluations overlook physics-based reasoning - a complex task requiring physics theorems and constraints. We present PhysReason, a 1,200-problem benchmark comprising knowledge-based (25%) and reasoning-based (75%) problems, where the latter are divided into three difficulty levels (easy, medium, hard). Notably, problems require an average of 8.1 solution steps, with hard requiring 15.6, reflecting the complexity of physics-based reasoning. We propose the Physics Solution Auto Scoring Framework, incorporating efficient answer-level and comprehensive step-level evaluations. Top-performing models like Deepseek-R1, Gemini-2.0-Flash-Thinking, and o3-mini-high achieve less than 60% on answer-level evaluation, with performance dropping from knowledge questions (75.11%) to hard problems (31.95%). Through step-level evaluation, we identified four key bottlenecks: Physics Theorem Application, Physics Process Understanding, Calculation, and Physics Condition Analysis. These findings position PhysReason as a novel and comprehensive benchmark for evaluating physics-based reasoning capabilities in large language models. Our code and data will be published at https:/dxzxy12138.github.io/PhysReason.",
            "score": 2,
            "issue_id": 2269,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "4aaf92e2d2fd9766",
            "authors": [
                "Xinyu Zhang",
                "Yuxuan Dong",
                "Yanrui Wu",
                "Jiaxing Huang",
                "Chengyou Jia",
                "Basura Fernando",
                "Mike Zheng Shou",
                "Lingling Zhang",
                "Jun Liu"
            ],
            "affiliations": [
                "Institute of High-Performance Computing, A*STAR",
                "Show Lab, National University of Singapore",
                "Xian Jiaotong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.12054.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "PhysReason: –∏—Å–ø—ã—Ç–∞–Ω–∏–µ —Ñ–∏–∑–∏–∫–æ–π –¥–ª—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç PhysReason - –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–º—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é. –ë–µ–Ω—á–º–∞—Ä–∫ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 1200 –∑–∞–¥–∞—á —Ä–∞–∑–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, —Ç—Ä–µ–±—É—é—â–∏—Ö –≤ —Å—Ä–µ–¥–Ω–µ–º 8.1 —à–∞–≥–æ–≤ —Ä–µ—à–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏ —Ä–µ—à–µ–Ω–∏–π –∏ –≤—ã—è–≤–ª—è—é—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Ç–µ–æ—Ä–µ–º, –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –≤—ã—á–∏—Å–ª–µ–Ω–∏—è—Ö –∏ –∞–Ω–∞–ª–∏–∑–µ —É—Å–ª–æ–≤–∏–π. –î–∞–∂–µ –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∏–∂–µ 60% –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö."
                },
                "en": {
                    "title": "PhysReason: A New Benchmark for Physics-Based Reasoning in AI",
                    "desc": "This paper introduces PhysReason, a new benchmark designed to evaluate the physics-based reasoning abilities of large language models. It consists of 1,200 problems, with a mix of knowledge-based and reasoning-based tasks, categorized into three difficulty levels. The benchmark highlights the complexity of physics reasoning, requiring multiple solution steps, with hard problems demanding an average of 15.6 steps. The study also identifies key challenges in physics reasoning, such as theorem application and process understanding, providing insights into the limitations of current models."
                },
                "zh": {
                    "title": "Áâ©ÁêÜÊé®ÁêÜËÉΩÂäõÁöÑÊñ∞Âü∫ÂáÜ",
                    "desc": "Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Êï∞Â≠¶ÂíåÈÄªËæëÊé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®Áâ©ÁêÜÊé®ÁêÜÊñπÈù¢ÁöÑËØÑ‰º∞‰ªçÁÑ∂‰∏çË∂≥„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜPhysReasonÔºåËøôÊòØ‰∏Ä‰∏™ÂåÖÂê´1200‰∏™ÈóÆÈ¢òÁöÑÂü∫ÂáÜÊµãËØïÔºåÂÖ∂‰∏≠75%ÊòØÊé®ÁêÜÁ±ªÈóÆÈ¢òÔºåÂàÜ‰∏∫ÁÆÄÂçï„ÄÅ‰∏≠Á≠âÂíåÂõ∞Èöæ‰∏â‰∏™ÈöæÂ∫¶Á∫ßÂà´„ÄÇÈÄöËøáÂºïÂÖ•Áâ©ÁêÜËß£È¢òËá™Âä®ËØÑÂàÜÊ°ÜÊû∂ÔºåÊàë‰ª¨ËÉΩÂ§üÊúâÊïàËØÑ‰º∞Ê®°ÂûãÂú®Áâ©ÁêÜÂÆöÁêÜÂ∫îÁî®„ÄÅËøáÁ®ãÁêÜËß£„ÄÅËÆ°ÁÆóÂíåÊù°‰ª∂ÂàÜÊûêÁ≠âÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂΩìÂâçÈ°∂Â∞ñÊ®°ÂûãÂú®Áâ©ÁêÜÊé®ÁêÜ‰ªªÂä°‰∏äÁöÑË°®Áé∞‰ªçÊúâÂæÖÊèêÈ´òÔºåÂ∞§ÂÖ∂ÊòØÂú®Âõ∞ÈöæÈóÆÈ¢ò‰∏ä„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11330",
            "title": "System Message Generation for User Preferences using Open-Source Models",
            "url": "https://huggingface.co/papers/2502.11330",
            "abstract": "System messages play a crucial role in interactions with large language models (LLMs), often serving as prompts to initiate conversations. Through system messages, users can assign specific roles, perform intended tasks, incorporate background information, specify various output formats and communication styles. Despite such versatility, publicly available data are often lack system messages and subject to strict license constraints in the industry field. Manual labeling of publicly available data with system messages that align with user instructions demands significant resources. In view of such challenges, our work introduces SysGen, a pipeline for generating system messages with better aligned assistant responses from the supervised fine-tuning dataset without system messages. Training on SysGen data has demonstrated substantial improvements in the alignment of model responses with system messages and user instructions, as demonstrated across various open-source models on the Multifacet benchmark, while maintaining minimal impact on other unseen benchmarks such as Open LLM Leaderboard 2. Our qualitative analysis highlights the importance of diverse system messages to ensure better adaptability across different contexts.",
            "score": 1,
            "issue_id": 2267,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "36ca5a9ceb25e7fa",
            "authors": [
                "Minbyul Jeong",
                "Jungho Cho",
                "Minsoo Khang",
                "Dawoon Jung",
                "Teakgyu Hong"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2502.11330.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#alignment",
                    "#training",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "ü§ñ",
                "ru": {
                    "title": "SysGen: —É–ª—É—á—à–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ—Ç–≤–µ—Ç–æ–≤ LLM —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π",
                    "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç SysGen - –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). SysGen —Å–æ–∑–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ª—É—á—à–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ—Ç–≤–µ—Ç–∞–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º –±–µ–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö SysGen –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–¥–µ–ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏—è–º –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ –±—ã–ª–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º. –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ª—É—á—à–µ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º."
                },
                "en": {
                    "title": "Enhancing LLM Responses with SysGen: Better System Messages for Better Alignment",
                    "desc": "This paper presents SysGen, a new method for generating system messages that help large language models (LLMs) respond more accurately to user instructions. System messages are crucial for guiding LLMs in their interactions, but there is a lack of publicly available data that includes these messages. SysGen addresses this issue by creating a pipeline that generates system messages from existing supervised fine-tuning datasets, leading to improved alignment of model responses. The results show that training with SysGen data enhances the performance of various open-source models while keeping their effectiveness on other benchmarks largely unchanged."
                },
                "zh": {
                    "title": "SysGenÔºöÊèêÂçáËØ≠Ë®ÄÊ®°ÂûãÂìçÂ∫îÂØπÈΩêÊÄßÁöÑÁ≥ªÁªüÊ∂àÊÅØÁîüÊàê",
                    "desc": "Êú¨ËÆ∫Êñá‰ªãÁªç‰∫ÜSysGenÔºå‰∏Ä‰∏™Áî®‰∫éÁîüÊàêÁ≥ªÁªüÊ∂àÊÅØÁöÑÁÆ°ÈÅìÔºåÊó®Âú®ÊèêÈ´òÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ‰∏éÁî®Êà∑Êåá‰ª§ÁöÑÂØπÈΩêÂ∫¶„ÄÇÁ≥ªÁªüÊ∂àÊÅØÂú®‰∏éLLMsÁöÑ‰∫§‰∫í‰∏≠Ëµ∑ÁùÄÈáçË¶Å‰ΩúÁî®ÔºåËÉΩÂ§üÂ∏ÆÂä©Áî®Êà∑ÊåáÂÆöËßíËâ≤Âíå‰ªªÂä°„ÄÇÈÄöËøáÂú®Ê≤°ÊúâÁ≥ªÁªüÊ∂àÊÅØÁöÑÁõëÁù£ÂæÆË∞ÉÊï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉÔºåSysGenÊòæËëóÊîπÂñÑ‰∫ÜÊ®°ÂûãÂìçÂ∫îÁöÑÂØπÈΩêÊÄß„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêË°®ÊòéÔºåÂ§öÊ†∑ÂåñÁöÑÁ≥ªÁªüÊ∂àÊÅØÂØπ‰∫éÂú®‰∏çÂêå‰∏ä‰∏ãÊñá‰∏≠ÂÆûÁé∞Êõ¥Â•ΩÁöÑÈÄÇÂ∫îÊÄßËá≥ÂÖ≥ÈáçË¶Å„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11775",
            "title": "video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model",
            "url": "https://huggingface.co/papers/2502.11775",
            "abstract": "While recent advancements in reasoning optimization have significantly enhanced the capabilities of large language models (LLMs), existing efforts to improve reasoning have been limited to solving mathematical problems and focusing on visual graphical inputs, neglecting broader applications in general video understanding.This paper proposes video-SALMONN-o1, the first open-source reasoning-enhanced audio-visual LLM designed for general video understanding tasks. To enhance its reasoning abilities, we develop a reasoning-intensive dataset featuring challenging audio-visual questions with step-by-step solutions. We also propose process direct preference optimization (pDPO), which leverages contrastive step selection to achieve efficient step-level reward modelling tailored for multimodal inputs. Additionally, we introduce RivaBench, the first reasoning-intensive video understanding benchmark, featuring over 4,000 high-quality, expert-curated question-answer pairs across scenarios such as standup comedy, academic presentations, and synthetic video detection. video-SALMONN-o1 achieves 3-8% accuracy improvements over the LLaVA-OneVision baseline across different video reasoning benchmarks. Besides, pDPO achieves 6-8% improvements compared to the supervised fine-tuning model on RivaBench. Enhanced reasoning enables video-SALMONN-o1 zero-shot synthetic video detection capabilities.",
            "score": 1,
            "issue_id": 2265,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "ff6f52de37532ca7",
            "authors": [
                "Guangzhi Sun",
                "Yudong Yang",
                "Jimin Zhuang",
                "Changli Tang",
                "Yixuan Li",
                "Wei Li",
                "Zejun MA",
                "Chao Zhang"
            ],
            "affiliations": [
                "ByteDance",
                "Tsinghua university",
                "Univeristy of Cambridge"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11775.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#video",
                    "#training",
                    "#open_source",
                    "#optimization",
                    "#benchmark",
                    "#multimodal",
                    "#dataset"
                ],
                "emoji": "üé•",
                "ru": {
                    "title": "–£–ª—É—á—à–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç video-SALMONN-o1 - –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã—Ç—É—é –∞—É–¥–∏–æ–≤–∏–∑—É–∞–ª—å–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è –æ–±—â–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ –∏ –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ü–µ—Å—Å–∞ (pDPO) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –¢–∞–∫–∂–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω –±–µ–Ω—á–º–∞—Ä–∫ RivaBench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–µ–π –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤–∏–¥–µ–æ. video-SALMONN-o1 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∏–¥–µ–æ."
                },
                "en": {
                    "title": "Revolutionizing Video Understanding with Enhanced Reasoning",
                    "desc": "This paper introduces video-SALMONN-o1, an innovative open-source audio-visual large language model (LLM) aimed at improving general video understanding. It addresses the gap in reasoning capabilities for video content by creating a specialized dataset with complex audio-visual questions and detailed solutions. The authors also present process direct preference optimization (pDPO), a method that enhances reward modeling for multimodal inputs through contrastive step selection. The model demonstrates significant accuracy improvements over existing benchmarks, showcasing its effectiveness in tasks like synthetic video detection without prior training."
                },
                "zh": {
                    "title": "ËßÜÈ¢ëÁêÜËß£ÁöÑÊñ∞Á™ÅÁ†¥Ôºövideo-SALMONN-o1",
                    "desc": "ËøôÁØáËÆ∫ÊñáÊèêÂá∫‰∫Üvideo-SALMONN-o1ÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÂ¢ûÂº∫Êé®ÁêÜÈü≥ËßÜÈ¢ëÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®Ëß£ÂÜ≥‰∏ÄËà¨ËßÜÈ¢ëÁêÜËß£‰ªªÂä°„ÄÇ‰∏∫‰∫ÜÊèêÂçáÂÖ∂Êé®ÁêÜËÉΩÂäõÔºåÁ†îÁ©∂Âõ¢ÈòüÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈü≥ËßÜÈ¢ëÈóÆÈ¢òÂíåÈÄêÊ≠•Ëß£ÂÜ≥ÊñπÊ°àÁöÑÊé®ÁêÜÂØÜÈõÜÂûãÊï∞ÊçÆÈõÜ„ÄÇËÆ∫ÊñáËøòÊèêÂá∫‰∫ÜËøáÁ®ãÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàpDPOÔºâÔºåÂà©Áî®ÂØπÊØîÊ≠•È™§ÈÄâÊã©ÂÆûÁé∞ÈíàÂØπÂ§öÊ®°ÊÄÅËæìÂÖ•ÁöÑÈ´òÊïàÊ≠•È™§Á∫ßÂ•ñÂä±Âª∫Ê®°„ÄÇÊ≠§Â§ñÔºåRivaBench‰Ωú‰∏∫Á¨¨‰∏Ä‰∏™Êé®ÁêÜÂØÜÈõÜÂûãËßÜÈ¢ëÁêÜËß£Âü∫ÂáÜÔºåÊèê‰æõ‰∫ÜË∂ÖËøá4000‰∏™È´òË¥®ÈáèÁöÑÈóÆÈ¢ò-Á≠îÊ°àÂØπÔºåÊ∂µÁõñ‰∫ÜÂ§öÁßçÂú∫ÊôØ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11098",
            "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
            "url": "https://huggingface.co/papers/2502.11098",
            "abstract": "Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown promise, yet significant challenges remain in managing communication and refinement when agents collaborate on complex tasks. In this paper, we propose Talk Structurally, Act Hierarchically (TalkHier), a novel framework that introduces a structured communication protocol for context-rich exchanges and a hierarchical refinement system to address issues such as incorrect outputs, falsehoods, and biases. TalkHier surpasses various types of SoTA, including inference scaling model (OpenAI-o1), open-source multi-agent models (e.g., AgentVerse), and majority voting strategies on current LLM and single-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including open-domain question answering, domain-specific selective questioning, and practical advertisement text generation. These results highlight its potential to set a new standard for LLM-MA systems, paving the way for more effective, adaptable, and collaborative multi-agent frameworks. The code is available https://github.com/sony/talkhier.",
            "score": 1,
            "issue_id": 2265,
            "pub_date": "2025-02-16",
            "pub_date_card": {
                "ru": "16 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 16",
                "zh": "2Êúà16Êó•"
            },
            "hash": "9aaac2e7c7b495a4",
            "authors": [
                "Zhao Wang",
                "Sota Moriyama",
                "Wei-Yao Wang",
                "Briti Gangopadhyay",
                "Shingo Takamatsu"
            ],
            "affiliations": [
                "Sony Group Corporation, Japan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11098.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#optimization",
                    "#agents",
                    "#multimodal",
                    "#alignment"
                ],
                "emoji": "ü§ñ",
                "ru": {
                    "title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ –∏ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤",
                    "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ TalkHier –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). TalkHier –≤–≤–æ–¥–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –∏ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É —É—Ç–æ—á–Ω–µ–Ω–∏—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –Ω–µ–≤–µ—Ä–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤ –∏ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏. –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –≤–∫–ª—é—á–∞—è –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ä–µ–∫–ª–∞–º–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. TalkHier –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –≤ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM."
                },
                "en": {
                    "title": "Enhancing Multi-Agent Collaboration with TalkHier Framework",
                    "desc": "This paper introduces Talk Hierarchically, Act Structurally (TalkHier), a new framework designed to improve communication and collaboration among multi-agent systems using large language models (LLMs). It features a structured communication protocol that enhances context understanding and a hierarchical refinement system to correct errors and biases in agent outputs. The framework outperforms existing state-of-the-art models in various tasks, demonstrating its effectiveness in open-domain question answering and targeted text generation. Overall, TalkHier aims to establish a new benchmark for LLM-based multi-agent systems, promoting better teamwork and adaptability among agents."
                },
                "zh": {
                    "title": "ÁªìÊûÑÂåñ‰∫§ÊµÅÔºåÂàÜÂ±ÇË°åÂä®ÁöÑÊô∫ËÉΩ‰ΩìÂçè‰ΩúÊñ∞Ê†áÂáÜ",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÁß∞‰∏∫Talk Structurally, Act HierarchicallyÔºàTalkHierÔºâÔºåÊó®Âú®ÊîπÂñÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü‰∏≠ÁöÑÈÄö‰ø°ÂíåÂçè‰Ωú„ÄÇËØ•Ê°ÜÊû∂ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÁªìÊûÑÂåñÁöÑÈÄö‰ø°ÂçèËÆÆÔºå‰ª•‰æøÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ËøõË°å‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñá‰∫§ÊµÅÔºåÂπ∂Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂàÜÂ±ÇÁöÑÁ≤æÁÇºÁ≥ªÁªüÔºå‰ª•Ëß£ÂÜ≥ÈîôËØØËæìÂá∫„ÄÅËôöÂÅá‰ø°ÊÅØÂíåÂÅèËßÅÁ≠âÈóÆÈ¢ò„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTalkHierÂú®Â§ö‰∏™‰ªªÂä°‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊäÄÊúØÔºåÂåÖÊã¨ÂºÄÊîæÈ¢ÜÂüüÈóÆÁ≠îÂíåÁâπÂÆöÈ¢ÜÂüüÈÄâÊã©ÊÄßÊèêÈóÆÁ≠â„ÄÇËØ•Á†îÁ©∂‰∏∫LLM-MAÁ≥ªÁªüËÆæÂÆö‰∫ÜÊñ∞ÁöÑÊ†áÂáÜÔºåÊé®Âä®‰∫ÜÊõ¥ÊúâÊïà„ÄÅÁÅµÊ¥ªÂíåÂçè‰ΩúÁöÑÂ§öÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÁöÑÂèëÂ±ï„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.10454",
            "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs",
            "url": "https://huggingface.co/papers/2502.10454",
            "abstract": "Leveraging mathematical Large Language Models (LLMs) for proof generation is a fundamental topic in LLMs research. We argue that the ability of current LLMs to prove statements largely depends on whether they have encountered the relevant proof process during training. This reliance limits their deeper understanding of mathematical theorems and related concepts. Inspired by the pedagogical method of \"proof by counterexamples\" commonly used in human mathematics education, our work aims to enhance LLMs' ability to conduct mathematical reasoning and proof through counterexamples. Specifically, we manually create a high-quality, university-level mathematical benchmark, CounterMATH, which requires LLMs to prove mathematical statements by providing counterexamples, thereby assessing their grasp of mathematical concepts. Additionally, we develop a data engineering framework to automatically obtain training data for further model improvement. Extensive experiments and detailed analyses demonstrate that CounterMATH is challenging, indicating that LLMs, such as OpenAI o1, have insufficient counterexample-driven proof capabilities. Moreover, our exploration into model training reveals that strengthening LLMs' counterexample-driven conceptual reasoning abilities is crucial for improving their overall mathematical capabilities. We believe that our work offers new perspectives on the community of mathematical LLMs.",
            "score": 1,
            "issue_id": 2265,
            "pub_date": "2025-02-12",
            "pub_date_card": {
                "ru": "12 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 12",
                "zh": "2Êúà12Êó•"
            },
            "hash": "1821254437fc158d",
            "authors": [
                "Yinghui Li",
                "Jiayi Kuang",
                "Haojing Huang",
                "Zhikun Xu",
                "Xinnian Liang",
                "Yi Yu",
                "Wenlian Lu",
                "Yangning Li",
                "Xiaoyu Tan",
                "Chao Qu",
                "Ying Shen",
                "Hai-Tao Zheng",
                "Philip S. Yu"
            ],
            "affiliations": [
                "ARC Lab, Arizona State University",
                "Bytedance Inc.",
                "INFLY TECH (Shanghai) Co., Ltd.",
                "Peng Cheng Laboratory",
                "School of Mathematical Science, Fudan University",
                "Sun-Yat Sen University",
                "Tsinghua University",
                "University of Illinois Chicago"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.10454.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#math",
                    "#optimization",
                    "#dataset"
                ],
                "emoji": "üßÆ",
                "ru": {
                    "title": "–ö–æ–Ω—Ç—Ä–ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ –∫–ª—é—á –∫ —É–ª—É—á—à–µ–Ω–∏—é –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –ò–ò",
                    "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞. –ê–≤—Ç–æ—Ä—ã —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ —Ç–µ–∫—É—â–∏–µ LLM –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –≤ –≥–ª—É–±–æ–∫–æ–º –ø–æ–Ω–∏–º–∞–Ω–∏–∏ —Ç–µ–æ—Ä–µ–º –∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∫–æ–Ω—Ç—Ä–ø—Ä–∏–º–µ—Ä–∞—Ö. –û–Ω–∏ —Å–æ–∑–¥–∞–ª–∏ –±–µ–Ω—á–º–∞—Ä–∫ CounterMATH –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ LLM –¥–æ–∫–∞–∑—ã–≤–∞—Ç—å —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç—Ä–ø—Ä–∏–º–µ—Ä—ã. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç—Ä–ø—Ä–∏–º–µ—Ä–æ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –æ–±—â–∏—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π LLM."
                },
                "en": {
                    "title": "Enhancing LLMs' Mathematical Proofs through Counterexamples",
                    "desc": "This paper discusses the limitations of current Large Language Models (LLMs) in generating mathematical proofs, emphasizing their dependence on prior exposure to proof processes during training. The authors introduce a new benchmark called CounterMATH, which challenges LLMs to prove mathematical statements by providing counterexamples, thereby testing their understanding of mathematical concepts. They also present a data engineering framework to enhance the training data for LLMs, aiming to improve their reasoning capabilities. The findings suggest that enhancing counterexample-driven reasoning is essential for advancing the mathematical proficiency of LLMs."
                },
                "zh": {
                    "title": "ÈÄöËøáÂèç‰æãÊèêÂçáÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ",
                    "desc": "Êú¨ËÆ∫ÊñáÊé¢ËÆ®‰∫ÜÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËøõË°åÊï∞Â≠¶ËØÅÊòéÁîüÊàêÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåÂΩìÂâçLLMsÁöÑËØÅÊòéËÉΩÂäõ‰∏ªË¶Å‰æùËµñ‰∫éÂÖ∂Âú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÊòØÂê¶Êé•Ëß¶ËøáÁõ∏ÂÖ≥ÁöÑËØÅÊòéËøáÁ®ãÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÂØπÊï∞Â≠¶ÂÆöÁêÜÂíåÁõ∏ÂÖ≥Ê¶ÇÂøµÁöÑÊ∑±ÂÖ•ÁêÜËß£„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂèç‰æãÁöÑËØÅÊòéÊñπÊ≥ïÔºåÊó®Âú®ÈÄöËøáÂèç‰æãÂ¢ûÂº∫LLMsÁöÑÊï∞Â≠¶Êé®ÁêÜÂíåËØÅÊòéËÉΩÂäõ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊâãÂä®ÂàõÂª∫‰∫Ü‰∏Ä‰∏™È´òË¥®ÈáèÁöÑÊï∞Â≠¶Âü∫ÂáÜCounterMATHÔºå‰ª•ËØÑ‰º∞LLMsÂú®Êèê‰æõÂèç‰æãÊó∂ÁöÑÊï∞Â≠¶Ê¶ÇÂøµÊéåÊè°ÊÉÖÂÜµ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11574",
            "title": "Large Language Models and Mathematical Reasoning Failures",
            "url": "https://huggingface.co/papers/2502.11574",
            "abstract": "This paper investigates the mathematical reasoning capabilities of large language models (LLMs) using 50 newly constructed high-school-level word problems. Unlike prior studies that focus solely on answer correctness, we rigorously analyze both final answers and solution steps to identify reasoning failures. Evaluating eight state-of-the-art models - including Mixtral, Llama, Gemini, GPT-4o, and OpenAI's o1 variants - we find that while newer models (e.g., o3-mini, deepseek-r1) achieve higher accuracy, all models exhibit errors in spatial reasoning, strategic planning, and arithmetic, sometimes producing correct answers through flawed logic. Common failure modes include unwarranted assumptions, over-reliance on numerical patterns, and difficulty translating physical intuition into mathematical steps. Manual analysis reveals that models struggle with problems requiring multi-step deduction or real-world knowledge, despite possessing broad mathematical knowledge. Our results underscore the importance of evaluating reasoning processes, not just answers, and caution against overestimating LLMs' problem-solving proficiency. The study highlights persistent gaps in LLMs' generalization abilities, emphasizing the need for targeted improvements in structured reasoning and constraint handling.",
            "score": 0,
            "issue_id": 2268,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "478a2c4575e67b28",
            "authors": [
                "Johan Boye",
                "Birger Moell"
            ],
            "affiliations": [
                "KTH Royal Institute of Technology, Stockholm, Sweden"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11574.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#reasoning",
                    "#math"
                ],
                "emoji": "üßÆ",
                "ru": {
                    "title": "–†–∞—Å–∫—Ä—ã–≤–∞—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è –ò–ò",
                    "desc": "–í —Å—Ç–∞—Ç—å–µ –∏—Å—Å–ª–µ–¥—É—é—Ç—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ 50 –Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á —É—Ä–æ–≤–Ω—è —Å—Ç–∞—Ä—à–µ–π —à–∫–æ–ª—ã. –ê–≤—Ç–æ—Ä—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤, –Ω–æ –∏ —Ö–æ–¥ —Ä–µ—à–µ–Ω–∏—è, –≤—ã—è–≤–ª—è—è –æ—à–∏–±–∫–∏ –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö. –û—Ü–µ–Ω–∫–∞ –≤–æ—Å—å–º–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–∫–∞–∑–∞–ª–∞, —á—Ç–æ –¥–∞–∂–µ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤, –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –æ—à–∏–±–∫–∏ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–º –º—ã—à–ª–µ–Ω–∏–∏, —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏ –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–µ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—é—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç–æ–≤, –∏ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π LLM –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –º—ã—à–ª–µ–Ω–∏—é –∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π."
                },
                "en": {
                    "title": "Evaluating Reasoning, Not Just Answers in LLMs",
                    "desc": "This paper examines how well large language models (LLMs) can solve high-school-level math word problems by focusing on their reasoning abilities. It evaluates eight advanced models, revealing that while some newer models show better accuracy, they still struggle with spatial reasoning, strategic planning, and arithmetic. The analysis identifies common reasoning failures, such as making incorrect assumptions and having difficulty with multi-step deductions. The findings stress the importance of assessing the reasoning process in addition to the final answers, highlighting the need for improvements in LLMs' structured reasoning skills."
                },
                "zh": {
                    "title": "ËØÑ‰º∞Êé®ÁêÜËøáÁ®ãÔºåË∂ÖË∂äÁ≠îÊ°àÊ≠£Á°ÆÊÄß",
                    "desc": "Êú¨ËÆ∫ÊñáÁ†îÁ©∂‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Êï∞Â≠¶Êé®ÁêÜÊñπÈù¢ÁöÑËÉΩÂäõÔºå‰ΩøÁî®‰∫Ü50‰∏™Êñ∞ÊûÑÂª∫ÁöÑÈ´ò‰∏≠Ê∞¥Âπ≥ÁöÑÊñáÂ≠óÈóÆÈ¢ò„ÄÇ‰∏é‰ª•ÂæÄÂè™ÂÖ≥Ê≥®Á≠îÊ°àÊ≠£Á°ÆÊÄßÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàë‰ª¨‰∏•Ê†ºÂàÜÊûê‰∫ÜÊúÄÁªàÁ≠îÊ°àÂíåËß£ÂÜ≥Ê≠•È™§Ôºå‰ª•ËØÜÂà´Êé®ÁêÜÂ§±Ë¥•„ÄÇËØÑ‰º∞‰∫ÜÂåÖÊã¨Mixtral„ÄÅLlama„ÄÅGemini„ÄÅGPT-4oÂíåOpenAIÁöÑo1Âèò‰ΩìÂú®ÂÜÖÁöÑÂÖ´‰∏™ÊúÄÂÖàËøõÊ®°ÂûãÔºåÂèëÁé∞Â∞ΩÁÆ°Êñ∞Ê®°ÂûãÔºàÂ¶Ço3-mini„ÄÅdeepseek-r1ÔºâÂú®ÂáÜÁ°ÆÊÄß‰∏äÊõ¥È´òÔºå‰ΩÜÊâÄÊúâÊ®°ÂûãÂú®Á©∫Èó¥Êé®ÁêÜ„ÄÅÊàòÁï•ËßÑÂàíÂíåÁÆóÊúØÊñπÈù¢ÈÉΩÂ≠òÂú®ÈîôËØØ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÂº∫Ë∞É‰∫ÜËØÑ‰º∞Êé®ÁêÜËøáÁ®ãÁöÑÈáçË¶ÅÊÄßÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÁ≠îÊ°àÔºåÂπ∂Ë≠¶Âëä‰∏çË¶ÅÈ´ò‰º∞LLMsÁöÑËß£ÂÜ≥ÈóÆÈ¢òËÉΩÂäõ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.11578",
            "title": "Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance",
            "url": "https://huggingface.co/papers/2502.11578",
            "abstract": "Large Language Models (LLMs) have made significant strides in natural language generation but often face challenges in tasks requiring precise calculations and structural analysis. This paper investigates the performance of state-of-the-art LLMs on language complexity measurement tasks, through the computation of the LIX readability metric and Average Dependency Distance (ADD). Using Swedish high school and university-level essays, we evaluate the models' abilities to compute LIX scores and perform dependency parsing, comparing their results to established ground truths. Our findings reveal that while all models demonstrate some capacity for these tasks, ChatGPT-o1-mini performs most consistently, achieving the highest accuracy in both LIX computation and dependency parsing. Additionally, we observe a strong significant correlation -0.875 p 0.026 (N=6) between the models' accuracy in computing LIX and their overall performance on the Massive Multitask Language Understanding (MMLU) benchmark. These results suggest that language complexity measurement abilities can serve as a noisy zero-shot proxies for assessing the general capabilities of LLMs, providing a practical method for model evaluation without the need for extensive benchmarking datasets.",
            "score": 0,
            "issue_id": 2268,
            "pub_date": "2025-02-17",
            "pub_date_card": {
                "ru": "17 —Ñ–µ–≤—Ä–∞–ª—è",
                "en": "February 17",
                "zh": "2Êúà17Êó•"
            },
            "hash": "039b4ffb618ff3b1",
            "authors": [
                "Birger Moell",
                "Johan Boye"
            ],
            "affiliations": [
                "KTH Royal Institute of Technology, Stockholm, Sweden"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.11578.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#interpretability",
                    "#science"
                ],
                "emoji": "üìä",
                "ru": {
                    "title": "–ò–∑–º–µ—Ä–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–∞ –∫–∞–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π",
                    "desc": "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–∞, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ LIX –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (ADD). –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø—Ä–æ–≤–æ–¥–∏–ª–∏—Å—å –Ω–∞ —à–≤–µ–¥—Å–∫–∏—Ö —ç—Å—Å–µ —É—Ä–æ–≤–Ω—è —Å—Ç–∞—Ä—à–µ–π —à–∫–æ–ª—ã –∏ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å ChatGPT-o1-mini –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–∏–ª—É—á—à—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ–±–µ–∏—Ö –∑–∞–¥–∞—á–∞—Ö. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –≤—ã—á–∏—Å–ª–µ–Ω–∏—è LIX –∏ –æ–±—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –º–æ–¥–µ–ª–µ–π –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ MMLU, —á—Ç–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∑–∞–¥–∞—á –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —è–∑—ã–∫–∞ –∫–∞–∫ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ–±—â–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π LLM."
                },
                "en": {
                    "title": "Evaluating Language Complexity as a Proxy for LLM Performance",
                    "desc": "This paper explores how well large language models (LLMs) can measure language complexity using specific metrics like the LIX readability score and Average Dependency Distance (ADD). The authors tested these models on Swedish essays from high school and university students to see how accurately they could compute LIX scores and perform dependency parsing. The results showed that while all models had some success, ChatGPT-o1-mini was the most reliable, achieving the best accuracy in both tasks. Furthermore, a strong correlation was found between the models' LIX computation accuracy and their performance on the MMLU benchmark, indicating that language complexity measurements can be useful for evaluating LLM capabilities without needing extensive datasets."
                },
                "zh": {
                    "title": "ËØ≠Ë®ÄÂ§çÊùÇÊÄßÊµãÈáèÔºöËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊñ∞ÊñπÊ≥ï",
                    "desc": "Êú¨ÊñáÁ†îÁ©∂‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®ËØ≠Ë®ÄÂ§çÊùÇÊÄßÊµãÈáè‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÁâπÂà´ÊòØËÆ°ÁÆóLIXÂèØËØªÊÄßÊåáÊ†áÂíåÂπ≥Âùá‰æùËµñË∑ùÁ¶ªÔºàADDÔºâ„ÄÇÊàë‰ª¨‰ΩøÁî®ÁëûÂÖ∏È´ò‰∏≠ÂíåÂ§ßÂ≠¶ÁöÑËÆ∫ÊñáÊù•ËØÑ‰º∞Ê®°ÂûãËÆ°ÁÆóLIXÂàÜÊï∞ÂíåËøõË°å‰æùËµñËß£ÊûêÁöÑËÉΩÂäõÔºåÂπ∂Â∞ÜÁªìÊûú‰∏éÂ∑≤Âª∫Á´ãÁöÑÂü∫ÂáÜËøõË°åÊØîËæÉ„ÄÇÁ†îÁ©∂ÂèëÁé∞ÔºåÂ∞ΩÁÆ°ÊâÄÊúâÊ®°ÂûãÂú®Ëøô‰∫õ‰ªªÂä°‰∏äÈÉΩÊúâ‰∏ÄÂÆöËÉΩÂäõÔºå‰ΩÜChatGPT-o1-miniÂú®LIXËÆ°ÁÆóÂíå‰æùËµñËß£Êûê‰∏≠Ë°®Áé∞ÊúÄ‰∏∫‰∏ÄËá¥ÔºåÂáÜÁ°ÆÁéáÊúÄÈ´ò„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËßÇÂØüÂà∞Ê®°ÂûãÂú®ËÆ°ÁÆóLIXÊó∂ÁöÑÂáÜÁ°ÆÊÄß‰∏éÂÖ∂Âú®Â§ßËßÑÊ®°Â§ö‰ªªÂä°ËØ≠Ë®ÄÁêÜËß£ÔºàMMLUÔºâÂü∫ÂáÜ‰∏äÁöÑÊï¥‰ΩìË°®Áé∞‰πãÈó¥Â≠òÂú®ÊòæËëóÁöÑË¥üÁõ∏ÂÖ≥ÂÖ≥Á≥ª„ÄÇ"
                }
            }
        }
    ],
    "link_prev": "2025-02-17.html",
    "link_next": "2025-02-19.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "17.02",
        "en": "02/17",
        "zh": "2Êúà17Êó•"
    },
    "short_date_next": {
        "ru": "19.02",
        "en": "02/19",
        "zh": "2Êúà19Êó•"
    },
    "categories": {
        "#dataset": 12,
        "#data": 5,
        "#benchmark": 8,
        "#agents": 1,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 2,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 3,
        "#math": 3,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 14,
        "#robotics": 1,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 6,
        "#transfer_learning": 4,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 11,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 4,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 6,
        "#small_models": 0,
        "#science": 2,
        "#low_resource": 0
    },
    "zh": {
        "text": "ËøôÁØáÊñáÁ´†ËÆ®ËÆ∫‰∫Ü‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ëá™Âä®Ë∑åÂÄíÊÅ¢Â§çÁöÑÈáçË¶ÅÊÄß„ÄÇËÆæËÆ°ÊéßÂà∂Âô®ËÆ©Êú∫Âô®‰∫∫Á´ôËµ∑Êù•ÂæàÈöæÔºåÂõ†‰∏∫Ë∑åÂÄíÂêéÊú∫Âô®‰∫∫ÂèØËÉΩÂ§Ñ‰∫éÂêÑÁßçÂßøÊÄÅÔºå‰∏îÂú∞ÂΩ¢Â§çÊùÇ„ÄÇÊñáÁ´†ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â≠¶‰π†Ê°ÜÊû∂ÔºåËÆ©Êú∫Âô®‰∫∫Âú®‰∏çÂêåÂßøÊÄÅÂíåÂú∞ÂΩ¢‰∏ãÁ´ôËµ∑Êù•„ÄÇÊ°ÜÊû∂ÂàÜ‰∏§Èò∂ÊÆµÔºåÂÖàÊâæÂà∞Á´ôËµ∑Êù•ÁöÑË∑ØÂæÑÔºåÂÜç‰ºòÂåñÂä®‰Ωú‰ΩøÂÖ∂Âπ≥Á®≥ÂèØÈù†„ÄÇÂÆûÈ™å‰∏≠ÔºåÊú∫Âô®‰∫∫Âú®‰∏çÂêåÂú∞Èù¢ÂíåÂßøÊÄÅ‰∏ãÊàêÂäüÁ´ôËµ∑Êù•ÔºåËøôÊòØÈ¶ñÊ¨°Âú®ÁúüÂÆûÁéØÂ¢É‰∏≠ÊàêÂäüÂ∫îÁî®ÁöÑÂ≠¶‰π†ÊñπÊ≥ï„ÄÇ",
        "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
        "pinyin": "ËøôÁØáÊñáÁ´†ËÆ®ËÆ∫‰∫Ü‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ëá™Âä®Ë∑åÂÄíÊÅ¢Â§çÁöÑÈáçË¶ÅÊÄß„ÄÇ\nZh√® piƒÅn w√©nzhƒÅng t«éol√πn le r√©nx√≠ng jƒ´q√¨r√©n z√¨d√≤ng diƒìd«éo huƒ´f√π de zh√≤ngy√†ox√¨ng.\n\nËÆæËÆ°ÊéßÂà∂Âô®ËÆ©Êú∫Âô®‰∫∫Á´ôËµ∑Êù•ÂæàÈöæÔºåÂõ†‰∏∫Ë∑åÂÄíÂêéÊú∫Âô®‰∫∫ÂèØËÉΩÂ§Ñ‰∫éÂêÑÁßçÂßøÊÄÅÔºå‰∏îÂú∞ÂΩ¢Â§çÊùÇ„ÄÇ\nSh√®j√¨ k√≤ngzh√¨q√¨ r√†ng jƒ´q√¨r√©n zh√†n q«êl√°i hƒõn n√°n, yƒ´nw√®i diƒìd«éo h√≤u jƒ´q√¨r√©n kƒõn√©ng ch«îy√∫ g√®zh«íng zƒ´t√†i, qiƒõ d√¨x√≠ng f√πz√°.\n\nÊñáÁ´†ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Â≠¶‰π†Ê°ÜÊû∂ÔºåËÆ©Êú∫Âô®‰∫∫Âú®‰∏çÂêåÂßøÊÄÅÂíåÂú∞ÂΩ¢‰∏ãÁ´ôËµ∑Êù•„ÄÇ\nW√©nzhƒÅng t√≠ch≈´ le yƒ´g√® xu√©x√≠ ku√†ngji√†, r√†ng jƒ´q√¨r√©n z√†i b√πt√≥ng zƒ´t√†i h√© d√¨x√≠ng xi√† zh√†n q«êl√°i.\n\nÊ°ÜÊû∂ÂàÜ‰∏§Èò∂ÊÆµÔºåÂÖàÊâæÂà∞Á´ôËµ∑Êù•ÁöÑË∑ØÂæÑÔºåÂÜç‰ºòÂåñÂä®‰Ωú‰ΩøÂÖ∂Âπ≥Á®≥ÂèØÈù†„ÄÇ\nKu√†ngji√† fƒìn li«éng jiƒìdu√†n, xiƒÅn zh«éo d√†o zh√†n q«êl√°i de l√πj√¨ng, z√†i y≈çuhu√† d√≤ngzu√≤ sh«ê q√≠ p√≠ngwƒõn kƒõk√†o.\n\nÂÆûÈ™å‰∏≠ÔºåÊú∫Âô®‰∫∫Âú®‰∏çÂêåÂú∞Èù¢ÂíåÂßøÊÄÅ‰∏ãÊàêÂäüÁ´ôËµ∑Êù•ÔºåËøôÊòØÈ¶ñÊ¨°Âú®ÁúüÂÆûÁéØÂ¢É‰∏≠ÊàêÂäüÂ∫îÁî®ÁöÑÂ≠¶‰π†ÊñπÊ≥ï„ÄÇ\nSh√≠y√†n zh≈çng, jƒ´q√¨r√©n z√†i b√πt√≥ng d√¨mi√†n h√© zƒ´t√†i xi√† ch√©ngg≈çng zh√†n q«êl√°i, zh√® sh√¨ sh«íuc√¨ z√†i zhƒìnsh√≠ hu√°nj√¨ng zh≈çng ch√©ngg≈çng y√¨ngy√≤ng de xu√©x√≠ fƒÅngf«é.",
        "vocab": "[{'word': 'ËÆ®ËÆ∫', 'pinyin': 't«éo l√πn', 'trans': 'discuss'},\n{'word': '‰∫∫ÂΩ¢Êú∫Âô®‰∫∫', 'pinyin': 'r√©n x√≠ng jƒ´ q√¨ r√©n', 'trans': 'humanoid robot'},\n{'word': 'Ëá™Âä®', 'pinyin': 'z√¨ d√≤ng', 'trans': 'automatic'},\n{'word': 'Ë∑åÂÄí', 'pinyin': 'diƒì d«éo', 'trans': 'fall down'},\n{'word': 'ÊÅ¢Â§ç', 'pinyin': 'huƒ´ f√π', 'trans': 'recover'},\n{'word': 'ÈáçË¶ÅÊÄß', 'pinyin': 'zh√≤ng y√†o x√¨ng', 'trans': 'importance'},\n{'word': 'ËÆæËÆ°', 'pinyin': 'sh√® j√¨', 'trans': 'design'},\n{'word': 'ÊéßÂà∂Âô®', 'pinyin': 'k√≤ng zh√¨ q√¨', 'trans': 'controller'},\n{'word': 'Á´ôËµ∑Êù•', 'pinyin': 'zh√†n q«ê l√°i', 'trans': 'stand up'},\n{'word': 'ÂßøÊÄÅ', 'pinyin': 'zƒ´ t√†i', 'trans': 'posture'},\n{'word': 'Âú∞ÂΩ¢', 'pinyin': 'd√¨ x√≠ng', 'trans': 'terrain'},\n{'word': 'Â§çÊùÇ', 'pinyin': 'f√π z√°', 'trans': 'complex'},\n{'word': 'ÊèêÂá∫', 'pinyin': 't√≠ ch≈´', 'trans': 'propose'},\n{'word': 'Â≠¶‰π†', 'pinyin': 'xu√© x√≠', 'trans': 'learn'},\n{'word': 'Ê°ÜÊû∂', 'pinyin': 'ku√†ng ji√†', 'trans': 'framework'},\n{'word': 'Èò∂ÊÆµ', 'pinyin': 'jiƒì du√†n', 'trans': 'stage'},\n{'word': 'Ë∑ØÂæÑ', 'pinyin': 'l√π j√¨ng', 'trans': 'path'},\n{'word': '‰ºòÂåñ', 'pinyin': 'y≈çu hu√†', 'trans': 'optimize'},\n{'word': 'Âä®‰Ωú', 'pinyin': 'd√≤ng zu√≤', 'trans': 'action'},\n{'word': 'Âπ≥Á®≥', 'pinyin': 'p√≠ng wƒõn', 'trans': 'stable'},\n{'word': 'ÂèØÈù†', 'pinyin': 'kƒõ k√†o', 'trans': 'reliable'},\n{'word': 'ÂÆûÈ™å', 'pinyin': 'sh√≠ y√†n', 'trans': 'experiment'},\n{'word': 'Âú∞Èù¢', 'pinyin': 'd√¨ mi√†n', 'trans': 'ground'},\n{'word': 'ÊàêÂäü', 'pinyin': 'ch√©ng g≈çng', 'trans': 'success'},\n{'word': 'È¶ñÊ¨°', 'pinyin': 'sh«íu c√¨', 'trans': 'first time'},\n{'word': 'ÁúüÂÆû', 'pinyin': 'zhƒìn sh√≠', 'trans': 'real'},\n{'word': 'ÁéØÂ¢É', 'pinyin': 'hu√°n j√¨ng', 'trans': 'environment'},\n{'word': 'Â∫îÁî®', 'pinyin': 'y√¨ng y√≤ng', 'trans': 'apply'},\n{'word': 'ÊñπÊ≥ï', 'pinyin': 'fƒÅng f«é', 'trans': 'method'}]",
        "trans": "This article discusses the importance of automatic fall recovery for humanoid robots. Designing a controller to make a robot stand up after a fall is challenging because the robot may be in various postures and the terrain can be complex. The article proposes a learning framework that enables the robot to stand up from different postures and terrains. The framework consists of two stages: first, finding a path to stand up, and then optimizing the actions to make them smooth and reliable. In experiments, the robot successfully stood up from various surfaces and postures, marking the first successful application of a learning method in a real-world environment.",
        "update_ts": "2025-02-18 09:11"
    }
}