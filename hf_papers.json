{
    "date": {
        "ru": "20 января",
        "en": "January 20",
        "zh": "1月20日"
    },
    "time_utc": "2025-01-20 03:13",
    "weekday": 0,
    "issue_id": 1749,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.10132",
            "title": "ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling under Long-Context Scenario",
            "url": "https://huggingface.co/papers/2501.10132",
            "abstract": "Enhancing large language models (LLMs) with real-time APIs can help generate more accurate and up-to-date responses. However, evaluating the function calling abilities of LLMs in real-world scenarios remains under-explored due to the complexity of data collection and evaluation. In this work, we introduce ComplexFuncBench, a benchmark for complex function calling across five real-world scenarios. Compared to existing benchmarks, ComplexFuncBench encompasses multi-step and constrained function calling, which requires long-parameter filing, parameter value reasoning, and 128k long context. Additionally, we propose an automatic framework, ComplexEval, for quantitatively evaluating complex function calling tasks. Through comprehensive experiments, we demonstrate the deficiencies of state-of-the-art LLMs in function calling and suggest future directions for optimizing these capabilities. The data and code are available at https://github.com/THUDM/ComplexFuncBench.",
            "score": 0,
            "issue_id": 1749,
            "pub_date": "2025-01-17",
            "pub_date_card": {
                "ru": "17 января",
                "en": "January 17",
                "zh": "1月17日"
            },
            "hash": "de405dcc4bfc8efc",
            "authors": [
                "Lucen Zhong",
                "Zhengxiao Du",
                "Xiaohan Zhang",
                "Haiyi Hu",
                "Jie Tang"
            ],
            "affiliations": [
                "Tsinghua University",
                "Zhipu AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.10132.jpg",
            "data": {
                "categories": [
                    "#long_context",
                    "#optimization",
                    "#data",
                    "#benchmark"
                ],
                "emoji": "🧪",
                "ru": {
                    "title": "Новый бенчмарк для оценки сложных вызовов функций в больших языковых моделях",
                    "desc": "Данная статья представляет новый бенчмарк ComplexFuncBench для оценки способностей больших языковых моделей (LLM) вызывать сложные функции в реальных сценариях. Бенчмарк включает в себя многошаговые и ограниченные вызовы функций, требующие заполнения длинных параметров и рассуждений о значениях параметров. Авторы также предлагают автоматическую систему ComplexEval для количественной оценки задач сложного вызова функций. Эксперименты показывают недостатки современных LLM в вызове функций и предлагают направления для оптимизации этих возможностей."
                },
                "en": {
                    "title": "Benchmarking Complex Function Calling in LLMs",
                    "desc": "This paper presents ComplexFuncBench, a new benchmark designed to evaluate the function calling abilities of large language models (LLMs) in real-world scenarios. It focuses on complex tasks that involve multi-step and constrained function calling, which require advanced reasoning and handling of long contexts. The authors also introduce ComplexEval, an automatic framework for quantitatively assessing these complex function calling tasks. Through their experiments, they highlight the limitations of current state-of-the-art LLMs and propose directions for improving their performance in this area."
                },
                "zh": {
                    "title": "提升LLMs函数调用能力的基准与评估",
                    "desc": "本论文提出了ComplexFuncBench，这是一个用于评估大型语言模型（LLMs）在复杂函数调用方面的基准测试。该基准涵盖了五种真实场景，涉及多步骤和受限的函数调用，要求模型进行长参数填写和参数值推理。我们还提出了ComplexEval，一个自动化框架，用于定量评估复杂函数调用任务的能力。通过实验，我们展示了当前最先进的LLMs在函数调用方面的不足，并提出了未来优化的方向。"
                }
            }
        }
    ],
    "link_prev": "2025-01-17.html",
    "link_next": "2025-01-21.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "17.01",
        "en": "01/17",
        "zh": "1月17日"
    },
    "short_date_next": {
        "ru": "21.01",
        "en": "01/21",
        "zh": "1月21日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了生成模型在各个领域的影响。研究发现，大语言模型在推理时增加计算量可以提高性能。扩散模型也可以通过增加去噪步骤来调整计算量，但收益通常在几十步后趋于平缓。作者探讨了扩散模型在推理时的计算行为，并通过实验发现，增加计算量可以显著提高生成图像的质量。不同的组件组合可以适应不同的应用场景。",
        "title": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps",
        "pinyin": "这篇文章讨论了生成模型在各个领域的影响。\nZhè piān wénzhāng tǎolùn le shēngchéng móxíng zài gègè lǐngyù de yǐngxiǎng.\n\n研究发现，大语言模型在推理时增加计算量可以提高性能。\nYánjiū fāxiàn, dà yǔyán móxíng zài tuīlǐ shí zēngjiā jìsuàn liàng kěyǐ tígāo xìngnéng.\n\n扩散模型也可以通过增加去噪步骤来调整计算量，但收益通常在几十步后趋于平缓。\nKuòsàn móxíng yě kěyǐ tōngguò zēngjiā qùzào bùzhòu lái tiáozhěng jìsuàn liàng, dàn shōuyì tōngcháng zài jǐshí bù hòu qūyú píngchuǎn.\n\n作者探讨了扩散模型在推理时的计算行为，并通过实验发现，增加计算量可以显著提高生成图像的质量。\nZuòzhě tàntǎo le kuòsàn móxíng zài tuīlǐ shí de jìsuàn xíngwéi, bìng tōngguò shíyàn fāxiàn, zēngjiā jìsuàn liàng kěyǐ xiǎnzhù tígāo shēngchéng túxiàng de zhìliàng.\n\n不同的组件组合可以适应不同的应用场景。\nBùtóng de zǔjiàn zǔhé kěyǐ shìyìng bùtóng de yìngyòng chǎngjǐng.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"生成\", \"pinyin\": \"shēng chéng\", \"trans\": \"generate\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"领域\", \"pinyin\": \"lǐng yù\", \"trans\": \"field\"},\n    {\"word\": \"影响\", \"pinyin\": \"yǐng xiǎng\", \"trans\": \"influence\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"发现\", \"pinyin\": \"fā xiàn\", \"trans\": \"discover\"},\n    {\"word\": \"大语言模型\", \"pinyin\": \"dà yǔ yán mó xíng\", \"trans\": \"large language model\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuī lǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"增加\", \"pinyin\": \"zēng jiā\", \"trans\": \"increase\"},\n    {\"word\": \"计算量\", \"pinyin\": \"jì suàn liàng\", \"trans\": \"computational load\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"扩散\", \"pinyin\": \"kuò sàn\", \"trans\": \"diffusion\"},\n    {\"word\": \"去噪\", \"pinyin\": \"qù zào\", \"trans\": \"denoise\"},\n    {\"word\": \"步骤\", \"pinyin\": \"bù zhòu\", \"trans\": \"step\"},\n    {\"word\": \"调整\", \"pinyin\": \"tiáo zhěng\", \"trans\": \"adjust\"},\n    {\"word\": \"收益\", \"pinyin\": \"shōu yì\", \"trans\": \"benefit\"},\n    {\"word\": \"趋于\", \"pinyin\": \"qū yú\", \"trans\": \"tend towards\"},\n    {\"word\": \"平缓\", \"pinyin\": \"píng huǎn\", \"trans\": \"gentle\"},\n    {\"word\": \"作者\", \"pinyin\": \"zuò zhě\", \"trans\": \"author\"},\n    {\"word\": \"探讨\", \"pinyin\": \"tàn tǎo\", \"trans\": \"explore\"},\n    {\"word\": \"行为\", \"pinyin\": \"xíng wéi\", \"trans\": \"behavior\"},\n    {\"word\": \"实验\", \"pinyin\": \"shí yàn\", \"trans\": \"experiment\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"图像\", \"pinyin\": \"tú xiàng\", \"trans\": \"image\"},\n    {\"word\": \"质量\", \"pinyin\": \"zhì liàng\", \"trans\": \"quality\"},\n    {\"word\": \"组件\", \"pinyin\": \"zǔ jiàn\", \"trans\": \"component\"},\n    {\"word\": \"组合\", \"pinyin\": \"zǔ hé\", \"trans\": \"combination\"},\n    {\"word\": \"适应\", \"pinyin\": \"shì yìng\", \"trans\": \"adapt\"},\n    {\"word\": \"应用\", \"pinyin\": \"yìng yòng\", \"trans\": \"application\"},\n    {\"word\": \"场景\", \"pinyin\": \"chǎng jǐng\", \"trans\": \"scenario\"}\n]",
        "trans": "This article discusses the impact of generative models across various domains. Research has found that increasing the computational load during inference can enhance the performance of large language models. Diffusion models can also adjust their computational load by increasing the number of denoising steps, although the benefits typically plateau after a few dozen steps. The authors explore the computational behavior of diffusion models during inference and, through experiments, discover that increasing the computational load can significantly improve the quality of generated images. Different combinations of components can be adapted to suit different application scenarios.",
        "update_ts": "2025-01-19 12:36"
    }
}