{
    "date": {
        "ru": "19 Ğ¼Ğ°Ñ",
        "en": "May 19",
        "zh": "5æœˆ19æ—¥"
    },
    "time_utc": "2025-05-19 04:20",
    "weekday": 0,
    "issue_id": 3824,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.09388",
            "title": "Qwen3 Technical Report",
            "url": "https://huggingface.co/papers/2505.09388",
            "abstract": "In this work, we present Qwen3, the latest version of the Qwen model family. Qwen3 comprises a series of large language models (LLMs) designed to advance performance, efficiency, and multilingual capabilities. The Qwen3 series includes models of both dense and Mixture-of-Expert (MoE) architectures, with parameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is the integration of thinking mode (for complex, multi-step reasoning) and non-thinking mode (for rapid, context-driven responses) into a unified framework. This eliminates the need to switch between different models--such as chat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g., QwQ-32B)--and enables dynamic mode switching based on user queries or chat templates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing users to allocate computational resources adaptively during inference, thereby balancing latency and performance based on task complexity. Moreover, by leveraging the knowledge from the flagship models, we significantly reduce the computational resources required to build smaller-scale models, while ensuring their highly competitive performance. Empirical evaluations demonstrate that Qwen3 achieves state-of-the-art results across diverse benchmarks, including tasks in code generation, mathematical reasoning, agent tasks, etc., competitive against larger MoE models and proprietary models. Compared to its predecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119 languages and dialects, enhancing global accessibility through improved cross-lingual understanding and generation capabilities. To facilitate reproducibility and community-driven research and development, all Qwen3 models are publicly accessible under Apache 2.0.",
            "score": 36,
            "issue_id": 3823,
            "pub_date": "2025-05-14",
            "pub_date_card": {
                "ru": "14 Ğ¼Ğ°Ñ",
                "en": "May 14",
                "zh": "5æœˆ14æ—¥"
            },
            "hash": "69a0f87bb5460e8d",
            "authors": [
                "An Yang",
                "Anfeng Li",
                "Baosong Yang",
                "Beichen Zhang",
                "Binyuan Hui",
                "Bo Zheng",
                "Bowen Yu",
                "Chang Gao",
                "Chengen Huang",
                "Chenxu Lv",
                "Chujie Zheng",
                "Dayiheng Liu",
                "Fan Zhou",
                "Fei Huang",
                "Feng Hu",
                "Hao Ge",
                "Haoran Wei",
                "Huan Lin",
                "Jialong Tang",
                "Jian Yang",
                "Jianhong Tu",
                "Jianwei Zhang",
                "Jianxin Yang",
                "Jiaxi Yang",
                "Jing Zhou",
                "Jingren Zhou",
                "Junyang Lin",
                "Kai Dang",
                "Keqin Bao",
                "Kexin Yang",
                "Le Yu",
                "Lianghao Deng",
                "Mei Li",
                "Mingfeng Xue",
                "Mingze Li",
                "Pei Zhang",
                "Peng Wang",
                "Qin Zhu",
                "Rui Men",
                "Ruize Gao",
                "Shixuan Liu",
                "Shuang Luo",
                "Tianhao Li",
                "Tianyi Tang",
                "Wenbiao Yin",
                "Xingzhang Ren",
                "Xinyu Wang",
                "Xinyu Zhang",
                "Xuancheng Ren",
                "Yang Fan",
                "Yang Su",
                "Yichang Zhang",
                "Yinger Zhang",
                "Yu Wan",
                "Yuqiong Liu",
                "Zekun Wang",
                "Zeyu Cui",
                "Zhenru Zhang",
                "Zhipeng Zhou",
                "Zihan Qiu"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2505.09388.jpg",
            "data": {
                "categories": [
                    "#low_resource",
                    "#agi",
                    "#reasoning",
                    "#multilingual",
                    "#benchmark",
                    "#architecture",
                    "#training",
                    "#open_source"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Qwen3: Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²",
                    "desc": "Qwen3 - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğµ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM), Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹. ĞšĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ¹ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸ĞµĞ¹ Qwen3 ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¸ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ğ±ĞµĞ· Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ² ĞµĞ´Ğ¸Ğ½ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¸Ğ¼Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ±ÑĞ´Ğ¶ĞµÑ‚Ğ° Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑÑ‚ÑŒ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°. Qwen3 Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ 119 ÑĞ·Ñ‹ĞºĞ¾Ğ² Ğ¸ Ğ´Ğ¸Ğ°Ğ»ĞµĞºÑ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Qwen3: Unifying Thinking and Efficiency in Language Models",
                    "desc": "Qwen3 is the latest version of the Qwen model family, featuring large language models that enhance performance, efficiency, and multilingual capabilities. It includes both dense and Mixture-of-Expert (MoE) architectures with a wide range of parameters, from 0.6 to 235 billion. A notable innovation is the integration of thinking and non-thinking modes, allowing for seamless dynamic switching based on user needs, which improves response times and reasoning capabilities. Additionally, Qwen3 supports 119 languages, significantly increasing its accessibility and effectiveness in diverse applications, while also providing a thinking budget mechanism for optimized resource allocation during inference."
                },
                "zh": {
                    "title": "Qwen3ï¼šç»Ÿä¸€æ€ç»´ä¸å“åº”çš„æ™ºèƒ½è¯­è¨€æ¨¡å‹",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†Qwen3ï¼Œè¿™æ˜¯Qwenæ¨¡å‹ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ã€‚Qwen3åŒ…å«ä¸€ç³»åˆ—å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜æ€§èƒ½ã€æ•ˆç‡å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚å…¶åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æ€ç»´æ¨¡å¼å’Œéæ€ç»´æ¨¡å¼æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­ï¼Œå®ç°åŠ¨æ€æ¨¡å¼åˆ‡æ¢ï¼Œé€‚åº”ç”¨æˆ·æŸ¥è¯¢ã€‚Qwen3è¿˜å¼•å…¥äº†æ€ç»´é¢„ç®—æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·åœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªé€‚åº”åˆ†é…è®¡ç®—èµ„æºï¼Œä»è€Œåœ¨ä»»åŠ¡å¤æ‚æ€§åŸºç¡€ä¸Šå¹³è¡¡å»¶è¿Ÿå’Œæ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11152",
            "title": "Learning Dense Hand Contact Estimation from Imbalanced Data",
            "url": "https://huggingface.co/papers/2505.11152",
            "abstract": "Hands are essential to human interaction, and understanding contact between hands and the world can promote comprehensive understanding of their function. Recently, there have been growing number of hand interaction datasets that cover interaction with object, other hand, scene, and body. Despite the significance of the task and increasing high-quality data, how to effectively learn dense hand contact estimation remains largely underexplored. There are two major challenges for learning dense hand contact estimation. First, there exists class imbalance issue from hand contact datasets where majority of samples are not in contact. Second, hand contact datasets contain spatial imbalance issue with most of hand contact exhibited in finger tips, resulting in challenges for generalization towards contacts in other hand regions. To tackle these issues, we present a framework that learns dense HAnd COntact estimation (HACO) from imbalanced data. To resolve the class imbalance issue, we introduce balanced contact sampling, which builds and samples from multiple sampling groups that fairly represent diverse contact statistics for both contact and non-contact samples. Moreover, to address the spatial imbalance issue, we propose vertex-level class-balanced (VCB) loss, which incorporates spatially varying contact distribution by separately reweighting loss contribution of each vertex based on its contact frequency across dataset. As a result, we effectively learn to predict dense hand contact estimation with large-scale hand contact data without suffering from class and spatial imbalance issue. The codes will be released.",
            "score": 2,
            "issue_id": 3822,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 Ğ¼Ğ°Ñ",
                "en": "May 16",
                "zh": "5æœˆ16æ—¥"
            },
            "hash": "caa702fa71c24606",
            "authors": [
                "Daniel Sungho Jung",
                "Kyoung Mu Lee"
            ],
            "affiliations": [
                "IPAI, Dept. of ECE & ASRI, Seoul National University, Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11152.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#data"
                ],
                "emoji": "ğŸ–ï¸",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ¾Ğ² Ñ€ÑƒĞº: Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ¸ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ° Ñ€ÑƒĞº Ñ Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰ĞµĞ¹ ÑÑ€ĞµĞ´Ğ¾Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ñ Ğ¼Ğ¸Ñ€Ğ¾Ğ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº HACO Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ½ĞµÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ñ€ĞµÑˆĞ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ ĞºĞ»Ğ°ÑÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¸ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Ğ² Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ°Ñ… Ñ€ÑƒĞº. ĞĞ½Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ¾Ğ² Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ VCB, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰ÑƒÑ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ¾Ğ² Ğ½Ğ° Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€ÑƒĞºĞ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ¾Ğ² Ñ€ÑƒĞº Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞºÑ€ÑƒĞ¿Ğ½Ğ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "Enhancing Hand Contact Estimation with Balanced Learning Techniques",
                    "desc": "This paper addresses the challenge of estimating dense hand contact in various interactions, which is crucial for understanding hand functionality. It identifies two main issues: class imbalance, where most samples do not involve contact, and spatial imbalance, where contact is primarily at the fingertips. To overcome these challenges, the authors propose a framework called HACO that utilizes balanced contact sampling to ensure diverse representation of contact data. Additionally, they introduce a vertex-level class-balanced loss to adjust the learning process based on the frequency of contact across different hand regions, leading to improved predictions in dense hand contact estimation."
                },
                "zh": {
                    "title": "æå‡æ‰‹éƒ¨æ¥è§¦ä¼°è®¡çš„å‡†ç¡®æ€§",
                    "desc": "è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†æ‰‹éƒ¨æ¥è§¦ä¼°è®¡çš„é‡è¦æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä¸ç‰©ä½“ã€å…¶ä»–æ‰‹ã€åœºæ™¯å’Œèº«ä½“çš„äº’åŠ¨ä¸­ã€‚å°½ç®¡å·²æœ‰å¤§é‡é«˜è´¨é‡çš„æ•°æ®é›†ï¼Œä½†å¦‚ä½•æœ‰æ•ˆå­¦ä¹ å¯†é›†çš„æ‰‹éƒ¨æ¥è§¦ä¼°è®¡ä»ç„¶æ˜¯ä¸€ä¸ªæœªè¢«å……åˆ†ç ”ç©¶çš„é—®é¢˜ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç§°ä¸ºHACOï¼Œæ—¨åœ¨è§£å†³ç±»ä¸å¹³è¡¡å’Œç©ºé—´ä¸å¹³è¡¡çš„é—®é¢˜ã€‚é€šè¿‡å¼•å…¥å¹³è¡¡æ¥è§¦é‡‡æ ·å’Œé¡¶ç‚¹çº§ç±»å¹³è¡¡æŸå¤±ï¼Œç ”ç©¶è€…ä»¬æˆåŠŸåœ°æé«˜äº†æ‰‹éƒ¨æ¥è§¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-16.html",
    "link_next": "2025-05-20.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "16.05",
        "en": "05/16",
        "zh": "5æœˆ16æ—¥"
    },
    "short_date_next": {
        "ru": "20.05",
        "en": "05/20",
        "zh": "5æœˆ20æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 1,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰çš„æ½œåœ¨é•¿é“¾æ¨ç†èƒ½åŠ›ã€‚ä¹‹å‰çš„ç ”ç©¶è¡¨æ˜ï¼Œç»“æœå¯¼å‘çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯ä»¥å¶ç„¶å¼•å‘è‡ªæˆ‘æ ¡æ­£ã€å›æº¯å’ŒéªŒè¯ç­‰é«˜çº§æ¨ç†è¡Œä¸ºã€‚ç„¶è€Œï¼Œè¿™äº›è¡Œä¸ºçš„æ—¶é—´å’Œä¸€è‡´æ€§éš¾ä»¥é¢„æµ‹å’Œæ§åˆ¶ï¼Œé™åˆ¶äº†LRMsçš„æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œä½œè€…æå‡ºäº†æ˜¾å¼åœ°å°†æ¨¡å‹ä¸ä¸‰ç§å…ƒèƒ½åŠ›ï¼ˆæ¼”ç»ã€å½’çº³å’Œæº¯å› ï¼‰å¯¹é½çš„æ–¹æ³•ã€‚é€šè¿‡ä¸‰é˜¶æ®µæµæ°´çº¿ï¼Œæå‡äº†æ€§èƒ½ï¼Œå¹¶åœ¨æ•°å­¦ã€ç¼–ç¨‹å’Œç§‘å­¦åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è¡¨ç°ã€‚ä»£ç å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚",
        "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large\n  Reasoning Models",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰çš„æ½œåœ¨é•¿é“¾æ¨ç†èƒ½åŠ›ã€‚ä¹‹å‰çš„ç ”ç©¶è¡¨æ˜ï¼Œç»“æœå¯¼å‘çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯ä»¥å¶ç„¶å¼•å‘è‡ªæˆ‘æ ¡æ­£ã€å›æº¯å’ŒéªŒè¯ç­‰é«˜çº§æ¨ç†è¡Œä¸ºã€‚ç„¶è€Œï¼Œè¿™äº›è¡Œä¸ºçš„æ—¶é—´å’Œä¸€è‡´æ€§éš¾ä»¥é¢„æµ‹å’Œæ§åˆ¶ï¼Œé™åˆ¶äº†LRMsçš„æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œä½œè€…æå‡ºäº†æ˜¾å¼åœ°å°†æ¨¡å‹ä¸ä¸‰ç§å…ƒèƒ½åŠ›ï¼ˆæ¼”ç»ã€å½’çº³å’Œæº¯å› ï¼‰å¯¹é½çš„æ–¹æ³•ã€‚é€šè¿‡ä¸‰é˜¶æ®µæµæ°´çº¿ï¼Œæå‡äº†æ€§èƒ½ï¼Œå¹¶åœ¨æ•°å­¦ã€ç¼–ç¨‹å’Œç§‘å­¦åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è¡¨ç°ã€‚ä»£ç å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le dÃ xÃ­ng tuÄ«lÇ mÃ³xÃ­ng (LRMs) de qiÃ¡nzÃ i chÃ¡ngliÃ¡n tuÄ«lÇ nÃ©nglÃ¬. ZhÄ«qiÃ¡n de yÃ¡njiÅ« biÇomÃ­ng, jiÃ©guÇ’ dÇoxiÃ ng de qiÃ¡ngzhÃ¬ xuÃ©xÃ­ (RL) kÄ›yÇ Ç’urÃ¡n yÇnfÄ zÃ¬wÇ’ jiÃ ozhÃ¨ng, huÃ­tuÃ¬ hÃ© yÃ nzhÃ¨ng dÄ›ng gÄojÃ­ tuÄ«lÇ xÃ­ngwÃ©i. RÃ¡n'Ã©r, zhÃ¨xiÄ“ xÃ­ngwÃ©i de shÃ­jiÄn hÃ© yÄ«zhÃ¬xÃ¬ng nÃ¡n yÇ yÃ¹cÃ¨ hÃ© kÃ²ngzhÃ¬, xiÃ nzhÃ¬ le LRMs de tuÄ«lÇ nÃ©nglÃ¬. WÃ¨ile jiÄ›juÃ© zhÃ¨xiÄ“ wÃ¨ntÃ­, zuÃ²zhÄ› tÃ­chÅ« le xiÇnshÃ¬ de jiÄng mÃ³xÃ­ng yÇ” sÄn zhÇ’ng yuÃ¡n nÃ©nglÃ¬ (yÇnyÃ¬, guÄ«nÃ  hÃ© sÃ¹yÄ«n) duÃ¬qÃ­ de fÄngfÇ. TÅngguÃ² sÄn jiÄ“duÃ n liÃºshuÇxiÃ n, tÃ­shÄ“ng le xÃ¬ngnÃ©ng, bÃ¬ng zÃ i shÃ¹xuÃ©, biÄnchÃ©ng hÃ© kÄ“xuÃ© jÄ«zhÇ”n cÃ¨shÃ¬ zhÅng xiÇnzhÃ¹ tÄ«gÄo le biÇoxiÃ n. DÃ imÇ kÄ› zÃ i GitHub shÃ ng zhÇo dÃ o.",
        "vocab": "[\n    {\"word\": \"è®¨è®º\", \"pinyin\": \"tÇo lÃ¹n\", \"trans\": \"discuss\"},\n    {\"word\": \"æ½œåœ¨\", \"pinyin\": \"qiÃ¡n zÃ i\", \"trans\": \"potential\"},\n    {\"word\": \"é•¿é“¾\", \"pinyin\": \"chÃ¡ng liÃ n\", \"trans\": \"long-chain\"},\n    {\"word\": \"æ¨ç†\", \"pinyin\": \"tuÄ« lÇ\", \"trans\": \"reasoning\"},\n    {\"word\": \"èƒ½åŠ›\", \"pinyin\": \"nÃ©ng lÃ¬\", \"trans\": \"ability\"},\n    {\"word\": \"ä¹‹å‰\", \"pinyin\": \"zhÄ« qiÃ¡n\", \"trans\": \"before\"},\n    {\"word\": \"ç ”ç©¶\", \"pinyin\": \"yÃ¡n jiÅ«\", \"trans\": \"research\"},\n    {\"word\": \"è¡¨æ˜\", \"pinyin\": \"biÇo mÃ­ng\", \"trans\": \"indicate\"},\n    {\"word\": \"ç»“æœ\", \"pinyin\": \"jiÃ© guÇ’\", \"trans\": \"result\"},\n    {\"word\": \"å¯¼å‘\", \"pinyin\": \"dÇo xiÃ ng\", \"trans\": \"oriented\"},\n    {\"word\": \"å¼ºåŒ–\", \"pinyin\": \"qiÃ¡ng huÃ \", \"trans\": \"reinforcement\"},\n    {\"word\": \"å­¦ä¹ \", \"pinyin\": \"xuÃ© xÃ­\", \"trans\": \"learning\"},\n    {\"word\": \"å¶ç„¶\", \"pinyin\": \"Ç’u rÃ¡n\", \"trans\": \"occasionally\"},\n    {\"word\": \"å¼•å‘\", \"pinyin\": \"yÇn fÄ\", \"trans\": \"trigger\"},\n    {\"word\": \"è‡ªæˆ‘\", \"pinyin\": \"zÃ¬ wÇ’\", \"trans\": \"self\"},\n    {\"word\": \"æ ¡æ­£\", \"pinyin\": \"jiÃ o zhÃ¨ng\", \"trans\": \"correct\"},\n    {\"word\": \"å›æº¯\", \"pinyin\": \"huÃ­ sÃ¹\", \"trans\": \"backtrack\"},\n    {\"word\": \"éªŒè¯\", \"pinyin\": \"yÃ n zhÃ¨ng\", \"trans\": \"verify\"},\n    {\"word\": \"è¡Œä¸º\", \"pinyin\": \"xÃ­ng wÃ©i\", \"trans\": \"behavior\"},\n    {\"word\": \"ä¸€è‡´æ€§\", \"pinyin\": \"yÄ« zhÃ¬ xÃ¬ng\", \"trans\": \"consistency\"},\n    {\"word\": \"é¢„æµ‹\", \"pinyin\": \"yÃ¹ cÃ¨\", \"trans\": \"predict\"},\n    {\"word\": \"æ§åˆ¶\", \"pinyin\": \"kÃ²ng zhÃ¬\", \"trans\": \"control\"},\n    {\"word\": \"é™åˆ¶\", \"pinyin\": \"xiÃ n zhÃ¬\", \"trans\": \"limit\"},\n    {\"word\": \"æå‡º\", \"pinyin\": \"tÃ­ chÅ«\", \"trans\": \"propose\"},\n    {\"word\": \"æ˜¾å¼\", \"pinyin\": \"xiÇn shÃ¬\", \"trans\": \"explicit\"},\n    {\"word\": \"å¯¹é½\", \"pinyin\": \"duÃ¬ qÃ­\", \"trans\": \"align\"},\n    {\"word\": \"æ–¹æ³•\", \"pinyin\": \"fÄng fÇ\", \"trans\": \"method\"},\n    {\"word\": \"å…ƒ\", \"pinyin\": \"yuÃ¡n\", \"trans\": \"meta\"},\n    {\"word\": \"èƒ½åŠ›\", \"pinyin\": \"nÃ©ng lÃ¬\", \"trans\": \"ability\"},\n    {\"word\": \"æ¼”ç»\", \"pinyin\": \"yÇn yÃ¬\", \"trans\": \"deduction\"},\n    {\"word\": \"å½’çº³\", \"pinyin\": \"guÄ« nÃ \", \"trans\": \"induction\"},\n    {\"word\": \"æº¯å› \", \"pinyin\": \"sÃ¹ yÄ«n\", \"trans\": \"abduction\"},\n    {\"word\": \"ä¸‰é˜¶æ®µ\", \"pinyin\": \"sÄn jiÄ“ duÃ n\", \"trans\": \"three-stage\"},\n    {\"word\": \"æµæ°´çº¿\", \"pinyin\": \"liÃº shuÇ xiÃ n\", \"trans\": \"pipeline\"},\n    {\"word\": \"æå‡\", \"pinyin\": \"tÃ­ shÄ“ng\", \"trans\": \"enhance\"},\n    {\"word\": \"æ€§èƒ½\", \"pinyin\": \"xÃ¬ng nÃ©ng\", \"trans\": \"performance\"},\n    {\"word\": \"æ˜¾è‘—\", \"pinyin\": \"xiÇn zhÃ¹\", \"trans\": \"significant\"},\n    {\"word\": \"æé«˜\", \"pinyin\": \"tÃ­ gÄo\", \"trans\": \"improve\"},\n    {\"word\": \"è¡¨ç°\", \"pinyin\": \"biÇo xiÃ n\", \"trans\": \"performance\"},\n    {\"word\": \"ä»£ç \", \"pinyin\": \"dÃ i mÇ\", \"trans\": \"code\"},\n    {\"word\": \"GitHub\", \"pinyin\": \"GitHub\", \"trans\": \"GitHub\"}\n]",
        "trans": "This article discusses the potential long-chain reasoning capabilities of Large Reasoning Models (LRMs). Previous research has shown that result-oriented reinforcement learning (RL) can occasionally trigger advanced reasoning behaviors such as self-correction, backtracking, and verification. However, the timing and consistency of these behaviors are difficult to predict and control, limiting the reasoning capabilities of LRMs. To address these issues, the authors propose a method that explicitly aligns the model with three meta-abilities: deduction, induction, and abduction. Through a three-stage pipeline, performance is enhanced, and significant improvements are achieved in mathematical, programming, and scientific benchmark tests. The code can be found on GitHub.",
        "update_ts": "2025-05-18 12:44"
    }
}