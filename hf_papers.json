{
    "date": {
        "ru": "22 мая",
        "en": "May 22",
        "zh": "5月22日"
    },
    "time_utc": "2025-05-22 19:09",
    "weekday": 3,
    "issue_id": 3908,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.15277",
            "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
            "url": "https://huggingface.co/papers/2505.15277",
            "abstract": "Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks. Yet, specialized reward models for web navigation that can be utilized during both training and test-time have been absent until now. Despite the importance of speed and cost-effectiveness, prior works have utilized MLLMs as reward models, which poses significant constraints for real-world deployment. To address this, in this work, we propose the first process reward model (PRM) called Web-Shepherd which could assess web navigation trajectories in a step-level. To achieve this, we first construct the WebPRM Collection, a large-scale dataset with 40K step-level preference pairs and annotated checklists spanning diverse domains and difficulty levels. Next, we also introduce the WebRewardBench, the first meta-evaluation benchmark for evaluating PRMs. In our experiments, we observe that our Web-Shepherd achieves about 30 points better accuracy compared to using GPT-4o on WebRewardBench. Furthermore, when testing on WebArena-lite by using GPT-4o-mini as the policy and Web-Shepherd as the verifier, we achieve 10.9 points better performance, in 10 less cost compared to using GPT-4o-mini as the verifier. Our model, dataset, and code are publicly available at LINK.",
            "score": 77,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "8209bc2f2e5e6119",
            "authors": [
                "Hyungjoo Chae",
                "Sunghwan Kim",
                "Junhee Cho",
                "Seungone Kim",
                "Seungjun Moon",
                "Gyeom Hwangbo",
                "Dongha Lim",
                "Minjin Kim",
                "Yeonjun Hwang",
                "Minju Gwak",
                "Dongwook Choi",
                "Minseok Kang",
                "Gwanhoon Im",
                "ByeongUng Cho",
                "Hyojun Kim",
                "Jun Hee Han",
                "Taeyoon Kwon",
                "Minju Kim",
                "Beong-woo Kwak",
                "Dongjin Kang",
                "Jinyoung Yeo"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15277.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#open_source",
                    "#survey",
                    "#benchmark",
                    "#rl",
                    "#dataset"
                ],
                "emoji": "🧭",
                "ru": {
                    "title": "Web-Shepherd: эффективная модель вознаграждения для автоматизации веб-навигации",
                    "desc": "Статья представляет Web-Shepherd - первую модель вознаграждения процесса (PRM) для веб-навигации. Авторы создали набор данных WebPRM Collection с 40 тысячами пар предпочтений на уровне шагов и аннотированными чек-листами. Они также разработали бенчмарк WebRewardBench для оценки PRM моделей. Web-Shepherd показывает значительно лучшую точность по сравнению с GPT-4o и позволяет достичь более высокой производительности при меньших затратах в задачах веб-навигации."
                },
                "en": {
                    "title": "Web-Shepherd: Revolutionizing Web Navigation with Process Reward Models",
                    "desc": "This paper introduces Web-Shepherd, a novel process reward model (PRM) designed specifically for web navigation tasks that require long-term decision making. The authors highlight the limitations of using multimodal large language models (MLLMs) as reward models, which can hinder practical applications due to speed and cost issues. They present the WebPRM Collection, a comprehensive dataset containing 40,000 step-level preference pairs to train the PRM effectively. Experimental results demonstrate that Web-Shepherd significantly outperforms existing models, achieving higher accuracy and lower costs in web navigation tasks."
                },
                "zh": {
                    "title": "网页导航的智能评估新方法",
                    "desc": "本论文提出了一种新的过程奖励模型（PRM），名为Web-Shepherd，旨在评估网页导航的决策过程。我们构建了一个名为WebPRM Collection的大规模数据集，包含4万对步骤级偏好对和注释清单，涵盖多种领域和难度级别。通过实验，我们发现Web-Shepherd在WebRewardBench上比使用GPT-4o的准确率提高了约30个百分点，并且在WebArena-lite测试中，使用Web-Shepherd作为验证器时，性能提升了10.9点，且成本降低了10。我们的模型、数据集和代码均已公开。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14302",
            "title": "Scaling Law for Quantization-Aware Training",
            "url": "https://huggingface.co/papers/2505.14302",
            "abstract": "Large language models (LLMs) demand substantial computational and memory resources, creating deployment challenges. Quantization-aware training (QAT) addresses these challenges by reducing model precision while maintaining performance. However, the scaling behavior of QAT, especially at 4-bit precision (W4A4), is not well understood. Existing QAT scaling laws often ignore key factors such as the number of training tokens and quantization granularity, which limits their applicability. This paper proposes a unified scaling law for QAT that models quantization error as a function of model size, training data volume, and quantization group size. Through 268 QAT experiments, we show that quantization error decreases as model size increases, but rises with more training tokens and coarser quantization granularity. To identify the sources of W4A4 quantization error, we decompose it into weight and activation components. Both components follow the overall trend of W4A4 quantization error, but with different sensitivities. Specifically, weight quantization error increases more rapidly with more training tokens. Further analysis shows that the activation quantization error in the FC2 layer, caused by outliers, is the primary bottleneck of W4A4 QAT quantization error. By applying mixed-precision quantization to address this bottleneck, we demonstrate that weight and activation quantization errors can converge to similar levels. Additionally, with more training data, weight quantization error eventually exceeds activation quantization error, suggesting that reducing weight quantization error is also important in such scenarios. These findings offer key insights for improving QAT research and development.",
            "score": 54,
            "issue_id": 3891,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "ecea48e2af693a28",
            "authors": [
                "Mengzhao Chen",
                "Chaoyi Zhang",
                "Jing Liu",
                "Yutao Zeng",
                "Zeyue Xue",
                "Zhiheng Liu",
                "Yunshui Li",
                "Jin Ma",
                "Jie Huang",
                "Xun Zhou",
                "Ping Luo"
            ],
            "affiliations": [
                "ByteDance",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14302.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#inference"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "Масштабирование квантизации в больших языковых моделях: новые горизонты эффективности",
                    "desc": "Статья исследует масштабируемость квантизации с учетом обучения (QAT) для больших языковых моделей (LLM). Авторы предлагают единый закон масштабирования для QAT, моделирующий ошибку квантизации как функцию размера модели, объема обучающих данных и размера группы квантизации. Исследование показывает, что ошибка квантизации уменьшается с увеличением размера модели, но растет с увеличением количества обучающих токенов и более грубой грануляцией квантизации. Анализ выявляет, что ошибка квантизации активаций в слое FC2 является основным узким местом в 4-битной QAT."
                },
                "en": {
                    "title": "Optimizing Quantization-Aware Training for Large Language Models",
                    "desc": "This paper investigates the challenges of deploying large language models (LLMs) due to their high computational and memory requirements. It introduces quantization-aware training (QAT) as a solution to reduce model precision while preserving performance, particularly focusing on 4-bit precision (W4A4). The authors propose a new scaling law for QAT that considers factors like model size, training data volume, and quantization granularity, revealing how quantization error behaves under these conditions. Their experiments show that while increasing model size reduces quantization error, more training tokens and coarser quantization lead to higher errors, highlighting the need for mixed-precision quantization to optimize performance."
                },
                "zh": {
                    "title": "量化感知训练的统一扩展法则",
                    "desc": "大型语言模型（LLMs）需要大量的计算和内存资源，这给部署带来了挑战。量化感知训练（QAT）通过降低模型精度来应对这些挑战，同时保持性能。然而，QAT在4位精度（W4A4）下的扩展行为尚不清楚。本文提出了一种统一的QAT扩展法则，模型化量化误差与模型大小、训练数据量和量化组大小之间的关系。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15809",
            "title": "MMaDA: Multimodal Large Diffusion Language Models",
            "url": "https://huggingface.co/papers/2505.15809",
            "abstract": "We introduce MMaDA, a novel class of multimodal diffusion foundation models designed to achieve superior performance across diverse domains such as textual reasoning, multimodal understanding, and text-to-image generation. The approach is distinguished by three key innovations: (i) MMaDA adopts a unified diffusion architecture with a shared probabilistic formulation and a modality-agnostic design, eliminating the need for modality-specific components. This architecture ensures seamless integration and processing across different data types. (ii) We implement a mixed long chain-of-thought (CoT) fine-tuning strategy that curates a unified CoT format across modalities. By aligning reasoning processes between textual and visual domains, this strategy facilitates cold-start training for the final reinforcement learning (RL) stage, thereby enhancing the model's ability to handle complex tasks from the outset. (iii) We propose UniGRPO, a unified policy-gradient-based RL algorithm specifically tailored for diffusion foundation models. Utilizing diversified reward modeling, UniGRPO unifies post-training across both reasoning and generation tasks, ensuring consistent performance improvements. Experimental results demonstrate that MMaDA-8B exhibits strong generalization capabilities as a unified multimodal foundation model. It surpasses powerful models like LLaMA-3-7B and Qwen2-7B in textual reasoning, outperforms Show-o and SEED-X in multimodal understanding, and excels over SDXL and Janus in text-to-image generation. These achievements highlight MMaDA's effectiveness in bridging the gap between pretraining and post-training within unified diffusion architectures, providing a comprehensive framework for future research and development. We open-source our code and trained models at: https://github.com/Gen-Verse/MMaDA",
            "score": 51,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "ff99ceb93709180d",
            "authors": [
                "Ling Yang",
                "Ye Tian",
                "Bowen Li",
                "Xinchen Zhang",
                "Ke Shen",
                "Yunhai Tong",
                "Mengdi Wang"
            ],
            "affiliations": [
                "ByteDance",
                "Peking University",
                "Princeton University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15809.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#multimodal",
                    "#open_source",
                    "#architecture",
                    "#reasoning",
                    "#diffusion",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "MMaDA: Унифицированная мультимодальная диффузионная модель для рассуждений и генерации",
                    "desc": "MMaDA - это новый класс мультимодальных диффузионных фундаментальных моделей, разработанный для достижения превосходной производительности в различных областях, включая текстовые рассуждения, мультимодальное понимание и генерацию изображений по тексту. Модель использует унифицированную диффузионную архитектуру с общей вероятностной формулировкой и модально-агностическим дизайном, устраняя необходимость в компонентах, специфичных для конкретных модальностей. MMaDA применяет смешанную стратегию дообучения с длинной цепочкой рассуждений (CoT) и унифицированный алгоритм обучения с подкреплением UniGRPO, специально разработанный для диффузионных фундаментальных моделей. Экспериментальные результаты показывают, что MMaDA-8B демонстрирует сильные возможности обобщения как унифицированная мультимодальная фундаментальная модель, превосходя мощные модели в различных задачах."
                },
                "en": {
                    "title": "MMaDA: Unifying Multimodal Learning for Superior Performance",
                    "desc": "MMaDA is a new type of multimodal diffusion model that excels in various tasks like understanding text and images, and generating images from text. It features a unified architecture that processes different data types without needing separate components for each type. The model uses a special training method that aligns reasoning across text and visuals, making it easier to learn complex tasks. Additionally, it includes a unique reinforcement learning algorithm that improves performance in both reasoning and generation tasks, showing strong results compared to other leading models."
                },
                "zh": {
                    "title": "MMaDA：多模态扩散模型的创新之路",
                    "desc": "MMaDA是一种新型的多模态扩散基础模型，旨在在文本推理、多模态理解和文本到图像生成等多个领域实现卓越性能。该方法的三个关键创新包括：首先，MMaDA采用统一的扩散架构，消除了对特定模态组件的需求，从而实现不同数据类型的无缝集成和处理。其次，实施混合的长链思维（CoT）微调策略，统一不同模态的推理过程，增强模型处理复杂任务的能力。最后，提出了UniGRPO，这是一种专门为扩散基础模型设计的统一策略梯度强化学习算法，确保在推理和生成任务中实现一致的性能提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14231",
            "title": "UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement\n  Learning",
            "url": "https://huggingface.co/papers/2505.14231",
            "abstract": "Traditional visual grounding methods primarily focus on single-image scenarios with simple textual references. However, extending these methods to real-world scenarios that involve implicit and complex instructions, particularly in conjunction with multiple images, poses significant challenges, which is mainly due to the lack of advanced reasoning ability across diverse multi-modal contexts. In this work, we aim to address the more practical universal grounding task, and propose UniVG-R1, a reasoning guided multimodal large language model (MLLM) for universal visual grounding, which enhances reasoning capabilities through reinforcement learning (RL) combined with cold-start data. Specifically, we first construct a high-quality Chain-of-Thought (CoT) grounding dataset, annotated with detailed reasoning chains, to guide the model towards correct reasoning paths via supervised fine-tuning. Subsequently, we perform rule-based reinforcement learning to encourage the model to identify correct reasoning chains, thereby incentivizing its reasoning capabilities. In addition, we identify a difficulty bias arising from the prevalence of easy samples as RL training progresses, and we propose a difficulty-aware weight adjustment strategy to further strengthen the performance. Experimental results demonstrate the effectiveness of UniVG-R1, which achieves state-of-the-art performance on MIG-Bench with a 9.1% improvement over the previous method. Furthermore, our model exhibits strong generalizability, achieving an average improvement of 23.4% in zero-shot performance across four image and video reasoning grounding benchmarks. The project page can be accessed at https://amap-ml.github.io/UniVG-R1-page/.",
            "score": 42,
            "issue_id": 3891,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "cd98eb52e95427f4",
            "authors": [
                "Sule Bai",
                "Mingxing Li",
                "Yong Liu",
                "Jing Tang",
                "Haoji Zhang",
                "Lei Sun",
                "Xiangxiang Chu",
                "Yansong Tang"
            ],
            "affiliations": [
                "AMAP, Alibaba Group",
                "Tsinghua Shenzhen International Graduate School, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14231.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#multimodal",
                    "#reasoning",
                    "#rl",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Улучшение визуальной привязки через обучение с подкреплением и рассуждения",
                    "desc": "Статья представляет UniVG-R1 - мультимодальную большую языковую модель для универсальной визуальной привязки, улучшенную с помощью обучения с подкреплением. Модель обучается на наборе данных с аннотированными цепочками рассуждений, что позволяет ей следовать правильным путям рассуждений. Авторы применяют обучение с подкреплением на основе правил и стратегию корректировки весов с учетом сложности для повышения производительности. UniVG-R1 достигает лучших результатов на бенчмарке MIG-Bench и демонстрирует сильную обобщающую способность на других задачах визуального обоснования."
                },
                "en": {
                    "title": "Enhancing Visual Grounding with Advanced Reasoning",
                    "desc": "This paper introduces UniVG-R1, a multimodal large language model designed for universal visual grounding, which is the task of linking images to complex textual instructions. The model enhances its reasoning abilities through a combination of supervised fine-tuning on a newly created Chain-of-Thought dataset and reinforcement learning techniques. To address challenges in training, the authors implement a difficulty-aware weight adjustment strategy that helps the model focus on more complex reasoning tasks as it learns. Experimental results show that UniVG-R1 outperforms previous methods, demonstrating significant improvements in both general performance and zero-shot capabilities across various benchmarks."
                },
                "zh": {
                    "title": "提升视觉定位的推理能力",
                    "desc": "传统的视觉定位方法主要集中在单图像场景和简单文本引用上。然而，将这些方法扩展到涉及隐含和复杂指令的真实场景，尤其是多图像的情况下，面临着重大挑战，主要是由于缺乏在多模态上下文中进行高级推理的能力。本文提出了UniVG-R1，这是一种基于推理的多模态大型语言模型，通过结合强化学习和冷启动数据来增强推理能力。实验结果表明，UniVG-R1在MIG-Bench上实现了最先进的性能，相较于之前的方法提高了9.1%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15045",
            "title": "Diffusion vs. Autoregressive Language Models: A Text Embedding\n  Perspective",
            "url": "https://huggingface.co/papers/2505.15045",
            "abstract": "Large language model (LLM)-based embedding models, benefiting from large scale pre-training and post-training, have begun to surpass BERT and T5-based models on general-purpose text embedding tasks such as document retrieval. However, a fundamental limitation of LLM embeddings lies in the unidirectional attention used during autoregressive pre-training, which misaligns with the bidirectional nature of text embedding tasks. To this end, We propose adopting diffusion language models for text embeddings, motivated by their inherent bidirectional architecture and recent success in matching or surpassing LLMs especially on reasoning tasks. We present the first systematic study of the diffusion language embedding model, which outperforms the LLM-based embedding model by 20% on long-document retrieval, 8% on reasoning-intensive retrieval, 2% on instruction-following retrieval, and achieve competitive performance on traditional text embedding benchmarks. Our analysis verifies that bidirectional attention is crucial for encoding global context in long and complex text.",
            "score": 36,
            "issue_id": 3892,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "57c6eb57eddeebcc",
            "authors": [
                "Siyue Zhang",
                "Yilun Zhao",
                "Liyuan Geng",
                "Arman Cohan",
                "Anh Tuan Luu",
                "Chen Zhao"
            ],
            "affiliations": [
                "Alibaba-NTU Singapore Joint Research Institute",
                "Center for Data Science, New York University",
                "NYU Shanghai",
                "Nanyang Technological University",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15045.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#reasoning",
                    "#benchmark",
                    "#training",
                    "#long_context",
                    "#architecture",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Диффузионные модели: новый подход к текстовым эмбеддингам",
                    "desc": "В этой статье представлено исследование применения диффузионных языковых моделей для создания текстовых эмбеддингов. Авторы предлагают использовать двунаправленную архитектуру диффузионных моделей для преодоления ограничений однонаправленного внимания в автореггрессивных LLM. Результаты показывают значительное улучшение производительности по сравнению с эмбеддингами на основе LLM, особенно в задачах поиска длинных документов и рассуждений. Исследование подтверждает важность двунаправленного внимания для кодирования глобального контекста в длинных и сложных текстах."
                },
                "en": {
                    "title": "Harnessing Bidirectional Attention for Superior Text Embeddings",
                    "desc": "This paper discusses the limitations of large language model (LLM) embeddings, particularly their unidirectional attention which does not align well with the needs of text embedding tasks. The authors propose using diffusion language models, which have a bidirectional architecture, to improve text embeddings. Their systematic study shows that these diffusion models outperform LLM-based embeddings in various retrieval tasks, especially in long-document and reasoning-intensive scenarios. The findings highlight the importance of bidirectional attention for capturing the global context in complex texts."
                },
                "zh": {
                    "title": "扩散语言模型：双向嵌入的未来",
                    "desc": "基于大型语言模型（LLM）的嵌入模型在文档检索等通用文本嵌入任务中表现优于BERT和T5模型。然而，LLM嵌入的一个基本限制是其在自回归预训练中使用的单向注意力，这与文本嵌入任务的双向特性不符。为此，我们提出采用扩散语言模型进行文本嵌入，因其固有的双向架构在推理任务中表现出色。我们的研究表明，扩散语言嵌入模型在长文档检索等任务中优于LLM嵌入模型，验证了双向注意力在编码长文本全局上下文中的重要性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13909",
            "title": "Efficient Agent Training for Computer Use",
            "url": "https://huggingface.co/papers/2505.13909",
            "abstract": "Scaling up high-quality trajectory data has long been a critical bottleneck for developing human-like computer use agents. We introduce PC Agent-E, an efficient agent training framework that significantly reduces reliance on large-scale human demonstrations. Starting with just 312 human-annotated computer use trajectories, we further improved data quality by synthesizing diverse action decisions with Claude 3.7 Sonnet. Trained on these enriched trajectories, our PC Agent-E model achieved a remarkable 141% relative improvement, surpassing the strong Claude 3.7 Sonnet with extended thinking on WindowsAgentArena-V2, an improved benchmark we also released. Furthermore, PC Agent-E demonstrates strong generalizability to different operating systems on OSWorld. Our findings suggest that strong computer use capabilities can be stimulated from a small amount of high-quality trajectory data.",
            "score": 31,
            "issue_id": 3891,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "6614c6f1cb4338a5",
            "authors": [
                "Yanheng He",
                "Jiahe Jin",
                "Pengfei Liu"
            ],
            "affiliations": [
                "Generative AI Research Lab (GAIR)",
                "SII",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13909.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#benchmark",
                    "#transfer_learning",
                    "#training",
                    "#dataset",
                    "#agents"
                ],
                "emoji": "🖥️",
                "ru": {
                    "title": "Эффективное обучение компьютерных агентов на малых данных",
                    "desc": "Статья представляет PC Agent-E - эффективную систему обучения агентов для использования компьютера. Авторы разработали метод, позволяющий значительно сократить потребность в большом количестве демонстраций от людей. Используя всего 312 аннотированных человеком траекторий и синтезируя разнообразные решения с помощью языковой модели Claude 3.7 Sonnet, им удалось создать агента, превосходящего базовую модель на 141%. PC Agent-E также демонстрирует хорошую обобщаемость на различные операционные системы."
                },
                "en": {
                    "title": "Empowering Agents with Minimal Data: The PC Agent-E Revolution",
                    "desc": "The paper presents PC Agent-E, a new framework for training computer use agents that minimizes the need for extensive human demonstrations. By starting with only 312 human-annotated trajectories, the authors enhanced the data quality through the synthesis of diverse action decisions using Claude 3.7 Sonnet. This approach led to a significant performance boost, with the PC Agent-E model achieving a 141% relative improvement over previous models on the WindowsAgentArena-V2 benchmark. Additionally, the model shows strong adaptability across different operating systems, indicating that effective computer use skills can be developed from a limited set of high-quality data."
                },
                "zh": {
                    "title": "少量高质量数据，激发强大计算机能力",
                    "desc": "PC Agent-E 是一个高效的代理训练框架，旨在减少对大规模人类示范的依赖。我们从仅有的312个人工标注的计算机使用轨迹开始，通过合成多样的行动决策来提高数据质量。经过这些丰富轨迹的训练，PC Agent-E 模型在 WindowsAgentArena-V2 基准测试中实现了141%的相对提升，超越了强大的 Claude 3.7 Sonnet。我们的研究表明，少量高质量的轨迹数据可以激发出强大的计算机使用能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14766",
            "title": "This Time is Different: An Observability Perspective on Time Series\n  Foundation Models",
            "url": "https://huggingface.co/papers/2505.14766",
            "abstract": "We introduce Toto, a time series forecasting foundation model with 151 million parameters. Toto uses a modern decoder-only architecture coupled with architectural innovations designed to account for specific challenges found in multivariate observability time series data. Toto's pre-training corpus is a mixture of observability data, open datasets, and synthetic data, and is 4-10times larger than those of leading time series foundation models. Additionally, we introduce BOOM, a large-scale benchmark consisting of 350 million observations across 2,807 real-world time series. For both Toto and BOOM, we source observability data exclusively from Datadog's own telemetry and internal observability metrics. Extensive evaluations demonstrate that Toto achieves state-of-the-art performance on both BOOM and on established general purpose time series forecasting benchmarks. Toto's model weights, inference code, and evaluation scripts, as well as BOOM's data and evaluation code, are all available as open source under the Apache 2.0 License available at https://huggingface.co/Datadog/Toto-Open-Base-1.0 and https://github.com/DataDog/toto.",
            "score": 27,
            "issue_id": 3900,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "c77892c45c8f389d",
            "authors": [
                "Ben Cohen",
                "Emaad Khwaja",
                "Youssef Doubli",
                "Salahidine Lemaachi",
                "Chris Lettieri",
                "Charles Masson",
                "Hugo Miccinilli",
                "Elise Ramé",
                "Qiqi Ren",
                "Afshin Rostamizadeh",
                "Jean Ogier du Terrail",
                "Anna-Monica Toon",
                "Kan Wang",
                "Stephan Xie",
                "David Asker",
                "Ameet Talwalkar",
                "Othmane Abou-Amal"
            ],
            "affiliations": [
                "datadoghq.com"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14766.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#open_source",
                    "#small_models",
                    "#synthetic",
                    "#architecture"
                ],
                "emoji": "📈",
                "ru": {
                    "title": "Toto: революция в прогнозировании временных рядов",
                    "desc": "Представлена модель Toto - фундаментальная модель прогнозирования временных рядов с 151 миллионом параметров. Toto использует современную архитектуру декодера с инновациями для решения проблем многомерных данных наблюдаемости. Модель обучена на корпусе данных наблюдаемости, открытых датасетов и синтетических данных, который в 4-10 раз больше, чем у ведущих моделей временных рядов. Toto достигает передовых результатов как на новом бенчмарке BOOM, так и на существующих бенчмарках прогнозирования временных рядов."
                },
                "en": {
                    "title": "Toto: Revolutionizing Time Series Forecasting with State-of-the-Art Performance",
                    "desc": "Toto is a new foundation model designed for time series forecasting, featuring 151 million parameters and a decoder-only architecture. It addresses challenges in multivariate observability time series data through innovative design choices. The model is trained on a diverse dataset that is significantly larger than those used by existing models, combining real and synthetic observability data. Evaluations show that Toto outperforms other models on both a new benchmark called BOOM and established forecasting tasks, with all resources made available as open source."
                },
                "zh": {
                    "title": "Toto：时间序列预测的新基准",
                    "desc": "本文介绍了Toto，一个具有1.51亿参数的时间序列预测基础模型。Toto采用现代的解码器架构，并针对多变量可观测时间序列数据的特定挑战进行了架构创新。其预训练数据集由可观测数据、开放数据集和合成数据混合而成，规模是领先时间序列基础模型的4到10倍。此外，本文还介绍了BOOM，一个包含2,807个真实世界时间序列的350百万观测值的大规模基准。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15612",
            "title": "Learn to Reason Efficiently with Adaptive Length-based Reward Shaping",
            "url": "https://huggingface.co/papers/2505.15612",
            "abstract": "Large Reasoning Models (LRMs) have shown remarkable capabilities in solving complex problems through reinforcement learning (RL), particularly by generating long reasoning traces. However, these extended outputs often exhibit substantial redundancy, which limits the efficiency of LRMs. In this paper, we investigate RL-based approaches to promote reasoning efficiency. Specifically, we first present a unified framework that formulates various efficient reasoning methods through the lens of length-based reward shaping. Building on this perspective, we propose a novel Length-bAsed StEp Reward shaping method (LASER), which employs a step function as the reward, controlled by a target length. LASER surpasses previous methods, achieving a superior Pareto-optimal balance between performance and efficiency. Next, we further extend LASER based on two key intuitions: (1) The reasoning behavior of the model evolves during training, necessitating reward specifications that are also adaptive and dynamic; (2) Rather than uniformly encouraging shorter or longer chains of thought (CoT), we posit that length-based reward shaping should be difficulty-aware i.e., it should penalize lengthy CoTs more for easy queries. This approach is expected to facilitate a combination of fast and slow thinking, leading to a better overall tradeoff. The resulting method is termed LASER-D (Dynamic and Difficulty-aware). Experiments on DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, and DeepSeek-R1-Distill-Qwen-32B show that our approach significantly enhances both reasoning performance and response length efficiency. For instance, LASER-D and its variant achieve a +6.1 improvement on AIME2024 while reducing token usage by 63%. Further analysis reveals our RL-based compression produces more concise reasoning patterns with less redundant \"self-reflections\". Resources are at https://github.com/hkust-nlp/Laser.",
            "score": 23,
            "issue_id": 3892,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "145c2f1bfcaa0c1e",
            "authors": [
                "Wei Liu",
                "Ruochen Zhou",
                "Yiyun Deng",
                "Yuzhen Huang",
                "Junteng Liu",
                "Yuntian Deng",
                "Yizhe Zhang",
                "Junxian He"
            ],
            "affiliations": [
                "Apple",
                "City University of Hong Kong",
                "The Hong Kong University of Science and Technology",
                "University of Waterloo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15612.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#reasoning",
                    "#training",
                    "#optimization"
                ],
                "emoji": "💡",
                "ru": {
                    "title": "Эффективное рассуждение: оптимизация цепочек мыслей в крупных языковых моделях",
                    "desc": "Статья представляет новый метод LASER для повышения эффективности рассуждений в крупных моделях машинного обучения. LASER использует функцию вознаграждения на основе длины для оптимизации баланса между производительностью и эффективностью. Авторы также предлагают улучшенную версию LASER-D, которая адаптивно настраивает вознаграждение в зависимости от сложности задачи. Эксперименты показывают значительное улучшение эффективности рассуждений и сокращение использования токенов в различных моделях."
                },
                "en": {
                    "title": "Enhancing Reasoning Efficiency with Dynamic Length-Based Rewards",
                    "desc": "This paper explores how Large Reasoning Models (LRMs) can improve their problem-solving efficiency using reinforcement learning (RL). It introduces a new method called Length-bAsed StEp Reward shaping (LASER), which optimizes reasoning outputs by shaping rewards based on the length of reasoning traces. LASER-D, an extension of LASER, adapts the reward system to be dynamic and difficulty-aware, penalizing longer reasoning for easier queries. The results show that this approach significantly enhances reasoning performance while reducing redundancy and token usage in outputs."
                },
                "zh": {
                    "title": "提升推理效率的动态奖励机制",
                    "desc": "大型推理模型（LRMs）在通过强化学习（RL）解决复杂问题方面表现出色，尤其是在生成长推理链时。然而，这些冗长的输出往往存在显著的冗余，限制了LRMs的效率。本文探讨了基于RL的方法以提高推理效率，提出了一种新的长度基础步骤奖励塑形方法（LASER），通过目标长度控制奖励，超越了之前的方法，实现了性能与效率的优越平衡。此外，我们还提出了动态和难度感知的LASER-D方法，以适应模型在训练过程中的推理行为变化。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15400",
            "title": "When to Continue Thinking: Adaptive Thinking Mode Switching for\n  Efficient Reasoning",
            "url": "https://huggingface.co/papers/2505.15400",
            "abstract": "Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking modes, and uncover the phenomenon of \"Internal Self-Recovery Mechanism\" where models implicitly supplement reasoning during answer generation. Building on this insight, we propose Adaptive Self-Recovery Reasoning (ASRR), a framework that suppresses unnecessary reasoning and enables implicit recovery. By introducing accuracy-aware length reward regulation, ASRR adaptively allocates reasoning effort according to problem difficulty, achieving high efficiency with negligible performance sacrifice. Experiments across multiple benchmarks and models show that, compared with GRPO, ASRR reduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal accuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates on safety benchmarks (up to +21.7%). Our results highlight the potential of ASRR for enabling efficient, adaptive, and safer reasoning in LRMs.",
            "score": 17,
            "issue_id": 3896,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "93ea3ac7fa19dc07",
            "authors": [
                "Xiaoyun Zhang",
                "Jingqing Ruan",
                "Xing Ma",
                "Yawen Zhu",
                "Haodong Zhao",
                "Hao Li",
                "Jiansong Chen",
                "Ke Zeng",
                "Xunliang Cai"
            ],
            "affiliations": [
                "Meituan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15400.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#architecture",
                    "#training",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное рассуждение: меньше думай, больше делай",
                    "desc": "Эта статья представляет новый подход к оптимизации работы больших моделей рассуждений (LRM). Авторы предлагают метод Адаптивного Самовосстанавливающегося Рассуждения (ASRR), который уменьшает избыточные вычисления при сохранении высокой точности. ASRR основан на обнаруженном феномене 'Внутреннего механизма самовосстановления', когда модели неявно дополняют рассуждения во время генерации ответа. Эксперименты показывают, что ASRR значительно сокращает вычислительные затраты и повышает безопасность моделей на различных тестах."
                },
                "en": {
                    "title": "Efficient Reasoning with Adaptive Self-Recovery",
                    "desc": "This paper discusses the challenges of large reasoning models (LRMs) that often perform redundant reasoning, leading to high computational costs, especially on simpler tasks. The authors introduce a concept called the 'Internal Self-Recovery Mechanism', which allows models to enhance their reasoning during answer generation without additional effort. They propose a new framework called Adaptive Self-Recovery Reasoning (ASRR) that minimizes unnecessary reasoning while still allowing for implicit recovery based on the task's complexity. Experimental results demonstrate that ASRR can significantly reduce the reasoning budget while maintaining accuracy and improving safety metrics across various benchmarks."
                },
                "zh": {
                    "title": "自适应推理，提升效率与安全性",
                    "desc": "大型推理模型（LRMs）在长推理链上表现出色，但在简单任务中常常导致过高的计算开销。本文系统量化了LRMs在长思考和无思考模式下的上限，并揭示了模型在生成答案时隐式补充推理的“内部自我恢复机制”。基于这一发现，我们提出了自适应自我恢复推理（ASRR）框架，能够抑制不必要的推理并实现隐式恢复。实验结果表明，ASRR在多个基准测试中显著提高了推理效率，同时保持了较小的准确性损失。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14357",
            "title": "Vid2World: Crafting Video Diffusion Models to Interactive World Models",
            "url": "https://huggingface.co/papers/2505.14357",
            "abstract": "World models, which predict transitions based on history observation and action sequences, have shown great promise in improving data efficiency for sequential decision making. However, existing world models often require extensive domain-specific training and still produce low-fidelity, coarse predictions, limiting their applicability in complex environments. In contrast, video diffusion models trained on large, internet-scale datasets have demonstrated impressive capabilities in generating high-quality videos that capture diverse real-world dynamics. In this work, we present Vid2World, a general approach for leveraging and transferring pre-trained video diffusion models into interactive world models. To bridge the gap, Vid2World performs casualization of a pre-trained video diffusion model by crafting its architecture and training objective to enable autoregressive generation. Furthermore, it introduces a causal action guidance mechanism to enhance action controllability in the resulting interactive world model. Extensive experiments in robot manipulation and game simulation domains show that our method offers a scalable and effective approach for repurposing highly capable video diffusion models to interactive world models.",
            "score": 17,
            "issue_id": 3891,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "de65ad0f3c9cf5c2",
            "authors": [
                "Siqiao Huang",
                "Jialong Wu",
                "Qixing Zhou",
                "Shangchen Miao",
                "Mingsheng Long"
            ],
            "affiliations": [
                "Chongqing University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14357.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#games",
                    "#robotics",
                    "#diffusion",
                    "#transfer_learning",
                    "#rl",
                    "#agents",
                    "#video"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Превращение моделей диффузии видео в интерактивные модели мира",
                    "desc": "В статье представлен метод Vid2World, позволяющий использовать предобученные модели диффузии видео в качестве интерактивных моделей мира. Авторы предлагают каузализацию архитектуры и целевой функции модели диффузии для обеспечения авторегрессивной генерации. Также вводится механизм каузального управления действиями для улучшения контролируемости в получаемой интерактивной модели мира. Эксперименты в области робототехники и игровых симуляций показывают эффективность подхода для адаптации мощных моделей диффузии видео к задачам интерактивного моделирования мира."
                },
                "en": {
                    "title": "Transforming Video Models into Interactive World Models",
                    "desc": "This paper introduces Vid2World, a novel method that enhances world models by utilizing pre-trained video diffusion models. Traditional world models struggle with low-quality predictions and require extensive training, limiting their use in complex scenarios. Vid2World addresses these issues by adapting the architecture and training objectives of video diffusion models for autoregressive generation. The approach also incorporates a causal action guidance mechanism, improving the controllability of actions in interactive environments, as demonstrated through experiments in robot manipulation and game simulations."
                },
                "zh": {
                    "title": "将视频扩散模型转化为交互式世界模型的创新方法",
                    "desc": "本论文介绍了一种名为Vid2World的方法，它将预训练的视频扩散模型转化为交互式世界模型，以提高数据效率。现有的世界模型通常需要大量特定领域的训练，并且预测精度较低，限制了其在复杂环境中的应用。Vid2World通过调整视频扩散模型的架构和训练目标，实现了自回归生成，并引入了因果动作引导机制，以增强交互式世界模型中的动作可控性。实验结果表明，该方法在机器人操作和游戏模拟领域表现出色，提供了一种可扩展且有效的解决方案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15146",
            "title": "lmgame-Bench: How Good are LLMs at Playing Games?",
            "url": "https://huggingface.co/papers/2505.15146",
            "abstract": "Playing video games requires perception, memory, and planning, exactly the faculties modern large language model (LLM) agents are expected to master. We study the major challenges in using popular video games to evaluate modern LLMs and find that directly dropping LLMs into games cannot make an effective evaluation, for three reasons -- brittle vision perception, prompt sensitivity, and potential data contamination. We introduce lmgame-Bench to turn games into reliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and narrative games delivered through a unified Gym-style API and paired with lightweight perception and memory scaffolds, and is designed to stabilize prompt variance and remove contamination. Across 13 leading models, we show lmgame-Bench is challenging while still separating models well. Correlation analysis shows that every game probes a unique blend of capabilities often tested in isolation elsewhere. More interestingly, performing reinforcement learning on a single game from lmgame-Bench transfers both to unseen games and to external planning tasks. Our evaluation code is available at https://github.com/lmgame-org/GamingAgent/lmgame-bench.",
            "score": 15,
            "issue_id": 3892,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "96b324d85a6c0d83",
            "authors": [
                "Lanxiang Hu",
                "Mingjia Huo",
                "Yuxuan Zhang",
                "Haoyang Yu",
                "Eric P. Xing",
                "Ion Stoica",
                "Tajana Rosing",
                "Haojian Jin",
                "Hao Zhang"
            ],
            "affiliations": [
                "MBZUAI",
                "UC Berkeley",
                "UC San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15146.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#benchmark",
                    "#games",
                    "#agents",
                    "#transfer_learning"
                ],
                "emoji": "🎮",
                "ru": {
                    "title": "Видеоигры как полигон для оценки и обучения языковых моделей",
                    "desc": "Исследователи изучают возможности использования видеоигр для оценки современных больших языковых моделей (LLM). Они выявили проблемы с восприятием, чувствительностью к промптам и потенциальным загрязнением данных при прямом применении LLM в играх. Для решения этих проблем авторы представляют lmgame-Bench - набор игр с унифицированным API и вспомогательными структурами для восприятия и памяти. Результаты показывают, что lmgame-Bench эффективно оценивает и разделяет модели, а также позволяет переносить навыки между играми и задачами планирования."
                },
                "en": {
                    "title": "Evaluating LLMs with lmgame-Bench: A Game-Changer!",
                    "desc": "This paper addresses the challenges of evaluating large language models (LLMs) using video games, highlighting issues like poor visual perception, sensitivity to prompts, and data contamination. The authors propose lmgame-Bench, a framework that standardizes game evaluations through a unified API and incorporates tools for perception and memory. This framework allows for a more reliable assessment of LLMs across various game types, including platformers and puzzles. The results demonstrate that lmgame-Bench effectively distinguishes between models and shows that training on one game can enhance performance on others and on planning tasks."
                },
                "zh": {
                    "title": "游戏评估：提升大型语言模型的能力",
                    "desc": "本论文探讨了如何使用视频游戏来评估现代大型语言模型（LLM）。研究发现，直接将LLM应用于游戏中进行评估存在视觉感知脆弱、提示敏感性和数据污染等问题。为了解决这些挑战，作者提出了lmgame-Bench，这是一个通过统一的Gym风格API提供的平台游戏、解谜游戏和叙事游戏的评估工具。通过对13个领先模型的测试，lmgame-Bench能够有效区分模型的能力，并且在单一游戏上进行强化学习可以转移到未见过的游戏和外部规划任务。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15765",
            "title": "Constructing a 3D Town from a Single Image",
            "url": "https://huggingface.co/papers/2505.15765",
            "abstract": "Acquiring detailed 3D scenes typically demands costly equipment, multi-view data, or labor-intensive modeling. Therefore, a lightweight alternative, generating complex 3D scenes from a single top-down image, plays an essential role in real-world applications. While recent 3D generative models have achieved remarkable results at the object level, their extension to full-scene generation often leads to inconsistent geometry, layout hallucinations, and low-quality meshes. In this work, we introduce 3DTown, a training-free framework designed to synthesize realistic and coherent 3D scenes from a single top-down view. Our method is grounded in two principles: region-based generation to improve image-to-3D alignment and resolution, and spatial-aware 3D inpainting to ensure global scene coherence and high-quality geometry generation. Specifically, we decompose the input image into overlapping regions and generate each using a pretrained 3D object generator, followed by a masked rectified flow inpainting process that fills in missing geometry while maintaining structural continuity. This modular design allows us to overcome resolution bottlenecks and preserve spatial structure without requiring 3D supervision or fine-tuning. Extensive experiments across diverse scenes show that 3DTown outperforms state-of-the-art baselines, including Trellis, Hunyuan3D-2, and TripoSG, in terms of geometry quality, spatial coherence, and texture fidelity. Our results demonstrate that high-quality 3D town generation is achievable from a single image using a principled, training-free approach.",
            "score": 14,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "c8acf46d639df2bb",
            "authors": [
                "Kaizhi Zheng",
                "Ruijian Zhang",
                "Jing Gu",
                "Jie Yang",
                "Xin Eric Wang"
            ],
            "affiliations": [
                "Columbia University",
                "Cybever AI",
                "UC Santa Cruz"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15765.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#3d"
                ],
                "emoji": "🏙️",
                "ru": {
                    "title": "Реалистичные 3D-города из одного изображения без обучения",
                    "desc": "3DTown - это новый подход к генерации реалистичных трехмерных сцен на основе единственного вида сверху, не требующий дополнительного обучения. Метод основан на генерации по регионам для улучшения соответствия изображению и разрешения, а также на пространственно-осведомленном 3D-инпейнтинге для обеспечения глобальной согласованности сцены. 3DTown разбивает входное изображение на перекрывающиеся области, генерирует каждую с помощью предобученного генератора 3D-объектов, а затем применяет маскированный инпейнтинг потока для заполнения недостающей геометрии. Эксперименты показывают, что 3DTown превосходит современные методы по качеству геометрии, пространственной согласованности и точности текстур."
                },
                "en": {
                    "title": "Transforming Top-Down Images into Stunning 3D Towns!",
                    "desc": "This paper presents 3DTown, a novel framework for generating realistic 3D scenes from a single top-down image without the need for extensive training. The method utilizes region-based generation to enhance the alignment between the 2D image and the 3D output, while also employing spatial-aware inpainting to ensure the overall coherence and quality of the generated geometry. By breaking down the image into overlapping regions and using a pretrained 3D object generator, the framework effectively fills in missing parts of the scene, maintaining structural integrity. The results indicate that 3DTown surpasses existing models in producing high-quality, coherent 3D scenes, demonstrating the potential of training-free approaches in 3D scene synthesis."
                },
                "zh": {
                    "title": "从单张图像生成高质量3D场景的创新方法",
                    "desc": "本论文提出了一种名为3DTown的框架，可以从单张俯视图生成逼真的3D场景，而无需复杂的训练过程。该方法基于区域生成和空间感知的3D修复技术，确保生成的场景在几何形状和布局上保持一致性。通过将输入图像分解为重叠区域，并利用预训练的3D物体生成器生成每个区域，最后进行几何填充，保持结构连续性。实验结果表明，3DTown在几何质量、空间一致性和纹理保真度方面优于现有的最先进方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15210",
            "title": "Deliberation on Priors: Trustworthy Reasoning of Large Language Models\n  on Knowledge Graphs",
            "url": "https://huggingface.co/papers/2505.15210",
            "abstract": "Knowledge graph-based retrieval-augmented generation seeks to mitigate hallucinations in Large Language Models (LLMs) caused by insufficient or outdated knowledge. However, existing methods often fail to fully exploit the prior knowledge embedded in knowledge graphs (KGs), particularly their structural information and explicit or implicit constraints. The former can enhance the faithfulness of LLMs' reasoning, while the latter can improve the reliability of response generation. Motivated by these, we propose a trustworthy reasoning framework, termed Deliberation over Priors (DP), which sufficiently utilizes the priors contained in KGs. Specifically, DP adopts a progressive knowledge distillation strategy that integrates structural priors into LLMs through a combination of supervised fine-tuning and Kahneman-Tversky optimization, thereby improving the faithfulness of relation path generation. Furthermore, our framework employs a reasoning-introspection strategy, which guides LLMs to perform refined reasoning verification based on extracted constraint priors, ensuring the reliability of response generation. Extensive experiments on three benchmark datasets demonstrate that DP achieves new state-of-the-art performance, especially a Hit@1 improvement of 13% on the ComplexWebQuestions dataset, and generates highly trustworthy responses. We also conduct various analyses to verify its flexibility and practicality. The code is available at https://github.com/reml-group/Deliberation-on-Priors.",
            "score": 14,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "acf62275d75af161",
            "authors": [
                "Jie Ma",
                "Ning Qu",
                "Zhitao Gao",
                "Rui Xing",
                "Jun Liu",
                "Hongbin Pei",
                "Jiang Xie",
                "Linyun Song",
                "Pinghui Wang",
                "Jing Tao",
                "Zhou Su"
            ],
            "affiliations": [
                "MOE KLINNS Lab, Xian Jiaotong University",
                "School of Artificial Intelligence, Chongqing University of Post and Telecommunications",
                "School of Computer Science and Technology, Xian Jiaotong University",
                "School of Computer Science, Northwestern Polytechnical University",
                "Shaanxi Province Key Laboratory of Big Data Knowledge Engineering"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15210.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rag",
                    "#benchmark",
                    "#hallucinations"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Повышение надежности языковых моделей через осмысление априорных знаний",
                    "desc": "Статья представляет новый метод под названием 'Deliberation over Priors' (DP) для улучшения работы больших языковых моделей (LLM) с использованием графов знаний. DP использует прогрессивную стратегию дистилляции знаний, интегрируя структурные априорные данные в LLM для повышения достоверности генерации путей отношений. Метод также применяет стратегию рассуждения и самоанализа, основанную на извлеченных ограничениях, для обеспечения надежности генерации ответов. Эксперименты показывают, что DP достигает нового уровня производительности, особенно улучшая показатель Hit@1 на 13% для набора данных ComplexWebQuestions."
                },
                "en": {
                    "title": "Enhancing LLM Trustworthiness with Knowledge Graphs",
                    "desc": "This paper introduces a new framework called Deliberation over Priors (DP) to enhance the reliability of Large Language Models (LLMs) by leveraging knowledge graphs (KGs). DP utilizes a progressive knowledge distillation strategy that incorporates the structural information and constraints from KGs into LLMs, improving the accuracy of reasoning and response generation. The framework also includes a reasoning-introspection strategy that allows LLMs to verify their reasoning based on extracted constraints, leading to more trustworthy outputs. Experimental results show that DP significantly outperforms existing methods, achieving a notable improvement in performance on benchmark datasets."
                },
                "zh": {
                    "title": "提升大型语言模型的可信推理能力",
                    "desc": "本论文提出了一种基于知识图谱的检索增强生成框架，旨在减少大型语言模型（LLMs）中的幻觉现象。我们提出的框架称为“先验推理深思”（Deliberation over Priors, DP），充分利用知识图谱中的结构信息和约束条件。DP通过逐步知识蒸馏策略，将结构先验整合到LLMs中，从而提高关系路径生成的可信度。此外，框架还采用推理自省策略，确保生成响应的可靠性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15779",
            "title": "IA-T2I: Internet-Augmented Text-to-Image Generation",
            "url": "https://huggingface.co/papers/2505.15779",
            "abstract": "Current text-to-image (T2I) generation models achieve promising results, but they fail on the scenarios where the knowledge implied in the text prompt is uncertain. For example, a T2I model released in February would struggle to generate a suitable poster for a movie premiering in April, because the character designs and styles are uncertain to the model. To solve this problem, we propose an Internet-Augmented text-to-image generation (IA-T2I) framework to compel T2I models clear about such uncertain knowledge by providing them with reference images. Specifically, an active retrieval module is designed to determine whether a reference image is needed based on the given text prompt; a hierarchical image selection module is introduced to find the most suitable image returned by an image search engine to enhance the T2I model; a self-reflection mechanism is presented to continuously evaluate and refine the generated image to ensure faithful alignment with the text prompt. To evaluate the proposed framework's performance, we collect a dataset named Img-Ref-T2I, where text prompts include three types of uncertain knowledge: (1) known but rare. (2) unknown. (3) ambiguous. Moreover, we carefully craft a complex prompt to guide GPT-4o in making preference evaluation, which has been shown to have an evaluation accuracy similar to that of human preference evaluation. Experimental results demonstrate the effectiveness of our framework, outperforming GPT-4o by about 30% in human evaluation.",
            "score": 13,
            "issue_id": 3893,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "97c03041dc8579a8",
            "authors": [
                "Chuanhao Li",
                "Jianwen Sun",
                "Yukang Feng",
                "Mingliang Zhai",
                "Yifan Chang",
                "Kaipeng Zhang"
            ],
            "affiliations": [
                "Beijing Institute of Technology",
                "Nankai University",
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15779.jpg",
            "data": {
                "categories": [
                    "#rag",
                    "#alignment",
                    "#dataset",
                    "#multimodal",
                    "#diffusion"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Интернет-augmented T2I: преодоление неопределенности в генерации изображений",
                    "desc": "Статья представляет новый подход к генерации изображений по текстовому описанию (T2I) с использованием интернет-ресурсов. Авторы предлагают фреймворк IA-T2I, который решает проблему неопределенности знаний в промптах путем добавления референсных изображений. Система включает модуль активного поиска, иерархический выбор изображений и механизм самоанализа для улучшения результатов. Эффективность метода подтверждена экспериментами на специально созданном датасете Img-Ref-T2I и оценкой с помощью GPT-4."
                },
                "en": {
                    "title": "Enhancing T2I Models with Internet-Augmented Knowledge",
                    "desc": "This paper introduces the Internet-Augmented text-to-image generation (IA-T2I) framework, which enhances traditional text-to-image (T2I) models by addressing uncertainties in text prompts. The framework includes an active retrieval module to assess the need for reference images, a hierarchical image selection module to find the best matching images, and a self-reflection mechanism for continuous improvement of generated images. A new dataset, Img-Ref-T2I, is created to test the framework, featuring prompts with various types of uncertain knowledge. Experimental results show that IA-T2I significantly improves the quality of generated images, outperforming existing models in human evaluations."
                },
                "zh": {
                    "title": "互联网增强的文本到图像生成框架",
                    "desc": "当前的文本到图像生成模型在处理文本提示中隐含的不确定知识时表现不佳。为了解决这个问题，我们提出了一种互联网增强的文本到图像生成框架（IA-T2I），通过提供参考图像来帮助模型理解不确定的知识。该框架包括主动检索模块、分层图像选择模块和自我反思机制，以提高生成图像的质量和与文本提示的一致性。实验结果表明，我们的框架在性能上优于现有模型，特别是在处理复杂和不确定的文本提示时。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15404",
            "title": "How Should We Enhance the Safety of Large Reasoning Models: An Empirical\n  Study",
            "url": "https://huggingface.co/papers/2505.15404",
            "abstract": "Large Reasoning Models (LRMs) have achieved remarkable success on reasoning-intensive tasks such as mathematics and programming. However, their enhanced reasoning capabilities do not necessarily translate to improved safety performance-and in some cases, may even degrade it. This raises an important research question: how can we enhance the safety of LRMs? In this paper, we present a comprehensive empirical study on how to enhance the safety of LRMs through Supervised Fine-Tuning (SFT). Our investigation begins with an unexpected observation: directly distilling safe responses from DeepSeek-R1 fails to significantly enhance safety. We analyze this phenomenon and identify three key failure patterns that contribute to it. We then demonstrate that explicitly addressing these issues during the data distillation process can lead to substantial safety improvements. Next, we explore whether a long and complex reasoning process is necessary for achieving safety. Interestingly, we find that simply using short or template-based reasoning process can attain comparable safety performance-and are significantly easier for models to learn than more intricate reasoning chains. These findings prompt a deeper reflection on the role of reasoning in ensuring safety. Finally, we find that mixing math reasoning data during safety fine-tuning is helpful to balance safety and over-refusal. Overall, we hope our empirical study could provide a more holistic picture on enhancing the safety of LRMs. The code and data used in our experiments are released in https://github.com/thu-coai/LRM-Safety-Study.",
            "score": 11,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "d681b198a7360d3b",
            "authors": [
                "Zhexin Zhang",
                "Xian Qi Loye",
                "Victor Shea-Jay Huang",
                "Junxiao Yang",
                "Qi Zhu",
                "Shiyao Cui",
                "Fei Mi",
                "Lifeng Shang",
                "Yingkang Wang",
                "Hongning Wang",
                "Minlie Huang"
            ],
            "affiliations": [
                "Huawei Noahs Ark Lab",
                "The Conversational AI (CoAI) group, DCST, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15404.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#math",
                    "#reasoning",
                    "#training",
                    "#safety"
                ],
                "emoji": "🛡️",
                "ru": {
                    "title": "Повышение безопасности LRM: простота может быть ключом",
                    "desc": "Эта статья исследует способы повышения безопасности Моделей Крупномасштабного Рассуждения (LRM) с помощью Контролируемой Тонкой Настройки (SFT). Авторы обнаружили, что прямая дистилляция безопасных ответов не всегда эффективна, и выявили три ключевых паттерна неудач. Исследование показало, что короткие или шаблонные процессы рассуждения могут быть столь же эффективны для обеспечения безопасности, как и сложные цепочки рассуждений. Кроме того, было установлено, что включение данных по математическим рассуждениям в процесс тонкой настройки помогает сбалансировать безопасность и чрезмерный отказ."
                },
                "en": {
                    "title": "Enhancing Safety in Large Reasoning Models through Simplified Reasoning",
                    "desc": "This paper investigates how to improve the safety of Large Reasoning Models (LRMs) while maintaining their reasoning capabilities. The authors find that directly distilling safe responses does not significantly enhance safety and identify three failure patterns that contribute to this issue. They demonstrate that addressing these patterns during data distillation can lead to better safety outcomes. Additionally, the study reveals that simpler reasoning processes can achieve similar safety performance as complex ones, suggesting a reevaluation of reasoning's role in safety enhancement."
                },
                "zh": {
                    "title": "提升大型推理模型安全性的研究",
                    "desc": "大型推理模型（LRMs）在数学和编程等推理密集型任务中取得了显著成功。然而，它们的推理能力增强并不一定能提高安全性能，甚至在某些情况下可能会降低安全性。本文通过监督微调（SFT）对如何增强LRMs的安全性进行了全面的实证研究，发现直接从DeepSeek-R1提取安全响应并未显著提升安全性，并识别出三种关键的失败模式。研究表明，使用简单的短推理过程可以实现与复杂推理过程相当的安全性能，且更易于模型学习，这促使我们重新思考推理在确保安全性中的作用。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15817",
            "title": "Learning to Reason via Mixture-of-Thought for Logical Reasoning",
            "url": "https://huggingface.co/papers/2505.15817",
            "abstract": "Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typically natural language. Although some methods explored modality selection or augmentation at inference time, the training process remains modality-blind, limiting synergy among modalities. To fill in this gap, we propose Mixture-of-Thought (MoT), a framework that enables LLMs to reason across three complementary modalities: natural language, code, and a newly introduced symbolic modality, truth-table, which systematically enumerates logical cases and partially mitigates key failure modes in natural language reasoning. MoT adopts a two-phase design: (1) self-evolving MoT training, which jointly learns from filtered, self-generated rationales across modalities; and (2) MoT inference, which fully leverages the synergy of three modalities to produce better predictions. Experiments on logical reasoning benchmarks including FOLIO and ProofWriter demonstrate that our MoT framework consistently and significantly outperforms strong LLM baselines with single-modality chain-of-thought approaches, achieving up to +11.7pp average accuracy gain. Further analyses show that our MoT framework benefits both training and inference stages; that it is particularly effective on harder logical reasoning problems; and that different modalities contribute complementary strengths, with truth-table reasoning helping to overcome key bottlenecks in natural language inference.",
            "score": 10,
            "issue_id": 3897,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "a9b89bfbce1c417a",
            "authors": [
                "Tong Zheng",
                "Lichang Chen",
                "Simeng Han",
                "R. Thomas McCoy",
                "Heng Huang"
            ],
            "affiliations": [
                "Dept. of Computer Science, UMD, College Park, MD 20742",
                "Dept. of Computer Science, Yale University, New Haven, CT 06520",
                "Dept. of Linguistics, Yale University, New Haven, CT"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15817.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#multimodal",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Смешение модальностей для улучшения логических рассуждений ИИ",
                    "desc": "Статья представляет новый подход к обучению языковых моделей - Mixture-of-Thought (MoT). MoT позволяет большим языковым моделям (LLM) рассуждать, используя три модальности: естественный язык, код и новую символическую модальность - таблицу истинности. Метод включает двухфазовый дизайн: самоэволюционирующее обучение MoT и вывод MoT. Эксперименты показывают, что MoT значительно превосходит базовые LLM с подходом цепочки рассуждений в одной модальности, особенно на сложных задачах логического вывода."
                },
                "en": {
                    "title": "Empowering LLMs with Multi-Modal Reasoning for Enhanced Logic Solving",
                    "desc": "This paper introduces the Mixture-of-Thought (MoT) framework, which enhances large language models (LLMs) by enabling them to reason across three different modalities: natural language, code, and a new symbolic modality called truth-table. Unlike traditional methods that rely on a single reasoning modality during training, MoT allows for a more integrated approach, improving the model's ability to tackle logical reasoning tasks. The framework consists of two phases: a self-evolving training phase that learns from generated rationales across modalities, and an inference phase that utilizes the strengths of all three modalities for better predictions. Experimental results show that MoT significantly outperforms existing single-modality approaches, particularly on challenging logical reasoning problems, achieving notable accuracy improvements."
                },
                "zh": {
                    "title": "多模态推理，提升逻辑思维能力",
                    "desc": "本文提出了一种名为混合思维（Mixture-of-Thought, MoT）的框架，旨在提升大型语言模型（LLM）在逻辑推理中的表现。与传统方法只使用自然语言作为推理模式不同，MoT结合了自然语言、代码和一种新引入的符号模式——真值表，以增强推理能力。该框架采用两阶段设计：自我演化的MoT训练和MoT推理，能够在训练和推理阶段充分利用三种模式的协同效应。实验结果表明，MoT在逻辑推理基准测试中显著超越了单一模式的LLM基线，尤其在处理更复杂的逻辑问题时表现优异。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15781",
            "title": "dKV-Cache: The Cache for Diffusion Language Models",
            "url": "https://huggingface.co/papers/2505.15781",
            "abstract": "Diffusion Language Models (DLMs) have been seen as a promising competitor for autoregressive language models. However, diffusion language models have long been constrained by slow inference. A core challenge is that their non-autoregressive architecture and bidirectional attention preclude the key-value cache that accelerates decoding. We address this bottleneck by proposing a KV-cache-like mechanism, delayed KV-Cache, for the denoising process of DLMs. Our approach is motivated by the observation that different tokens have distinct representation dynamics throughout the diffusion process. Accordingly, we propose a delayed and conditioned caching strategy for key and value states. We design two complementary variants to cache key and value step-by-step: (1) dKV-Cache-Decode, which provides almost lossless acceleration, and even improves performance on long sequences, suggesting that existing DLMs may under-utilise contextual information during inference. (2) dKV-Cache-Greedy, which has aggressive caching with reduced lifespan, achieving higher speed-ups with quadratic time complexity at the cost of some performance degradation. dKV-Cache, in final, achieves from 2-10x speedup in inference, largely narrowing the gap between ARs and DLMs. We evaluate our dKV-Cache on several benchmarks, delivering acceleration across general language understanding, mathematical, and code-generation benchmarks. Experiments demonstrate that cache can also be used in DLMs, even in a training-free manner from current DLMs.",
            "score": 10,
            "issue_id": 3893,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "516300496b94028a",
            "authors": [
                "Xinyin Ma",
                "Runpeng Yu",
                "Gongfan Fang",
                "Xinchao Wang"
            ],
            "affiliations": [
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15781.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#inference",
                    "#optimization",
                    "#diffusion",
                    "#benchmark"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Ускорение диффузионных языковых моделей с помощью умного кэширования",
                    "desc": "Статья представляет новый механизм ускорения вывода для диффузионных языковых моделей (DLM) - отложенное KV-кэширование (dKV-Cache). Авторы предлагают два варианта: dKV-Cache-Decode, который улучшает производительность на длинных последовательностях, и dKV-Cache-Greedy для более агрессивного кэширования. Метод позволяет достичь 2-10-кратного ускорения вывода DLM, сокращая разрыв с авторегрессионными моделями. Эксперименты показывают эффективность подхода на различных задачах, включая понимание языка, математику и генерацию кода."
                },
                "en": {
                    "title": "Accelerating Diffusion Language Models with Delayed KV-Cache",
                    "desc": "This paper introduces a new mechanism called delayed KV-Cache to improve the inference speed of Diffusion Language Models (DLMs), which traditionally suffer from slow decoding due to their non-autoregressive nature. The authors identify that different tokens exhibit unique representation dynamics during the diffusion process, leading to the development of a caching strategy that optimizes key and value states. They propose two variants of the caching mechanism: dKV-Cache-Decode, which enhances performance on long sequences, and dKV-Cache-Greedy, which prioritizes speed at the expense of some accuracy. Overall, the proposed dKV-Cache achieves a significant speedup of 2-10x in inference, making DLMs more competitive with autoregressive models."
                },
                "zh": {
                    "title": "加速扩散语言模型的推理速度",
                    "desc": "扩散语言模型（DLMs）被视为自回归语言模型的有力竞争者，但其推理速度较慢是一个主要问题。本文提出了一种延迟键值缓存（dKV-Cache）机制，以解决DLMs在去噪过程中的瓶颈。我们设计了两种互补的缓存变体，分别为dKV-Cache-Decode和dKV-Cache-Greedy，前者在长序列上几乎无损加速，后者则以更高的速度实现了二次时间复杂度的加速。实验结果表明，dKV-Cache在多个基准测试中显著提高了推理速度，缩小了自回归模型与扩散语言模型之间的差距。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15656",
            "title": "Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data\n  Could Be Secretly Stolen!",
            "url": "https://huggingface.co/papers/2505.15656",
            "abstract": "Fine-tuning on open-source Large Language Models (LLMs) with proprietary data is now a standard practice for downstream developers to obtain task-specific LLMs. Surprisingly, we reveal a new and concerning risk along with the practice: the creator of the open-source LLMs can later extract the private downstream fine-tuning data through simple backdoor training, only requiring black-box access to the fine-tuned downstream model. Our comprehensive experiments, across 4 popularly used open-source models with 3B to 32B parameters and 2 downstream datasets, suggest that the extraction performance can be strikingly high: in practical settings, as much as 76.3% downstream fine-tuning data (queries) out of a total 5,000 samples can be perfectly extracted, and the success rate can increase to 94.9% in more ideal settings. We also explore a detection-based defense strategy but find it can be bypassed with improved attack. Overall, we highlight the emergency of this newly identified data breaching risk in fine-tuning, and we hope that more follow-up research could push the progress of addressing this concerning risk. The code and data used in our experiments are released at https://github.com/thu-coai/Backdoor-Data-Extraction.",
            "score": 10,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "eed97ed4c1582120",
            "authors": [
                "Zhexin Zhang",
                "Yuhao Sun",
                "Junxiao Yang",
                "Shiyao Cui",
                "Hongning Wang",
                "Minlie Huang"
            ],
            "affiliations": [
                "The Conversational AI (CoAI) group, DCST, Tsinghua University",
                "The University of Melbourne"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15656.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#security",
                    "#open_source",
                    "#training",
                    "#leakage"
                ],
                "emoji": "🕵️",
                "ru": {
                    "title": "Скрытая угроза: как открытые языковые модели могут раскрыть ваши секретные данные",
                    "desc": "Эта статья раскрывает новый риск безопасности при дообучении открытых языковых моделей (LLM) на проприетарных данных. Исследователи показали, что создатель исходной модели может извлечь частные данные дообучения, имея только доступ к конечной модели. Эксперименты на популярных моделях от 3 до 32 миллиардов параметров показали высокую эффективность извлечения - до 76.3% данных в практических условиях. Авторы подчеркивают срочность решения этой проблемы утечки данных при дообучении LLM."
                },
                "en": {
                    "title": "Exposing the Hidden Risks of Fine-Tuning LLMs with Proprietary Data",
                    "desc": "This paper discusses a significant risk associated with fine-tuning open-source Large Language Models (LLMs) using proprietary data. The authors demonstrate that creators of these LLMs can exploit backdoor training techniques to extract sensitive fine-tuning data from the models, even with only black-box access. Their experiments reveal that up to 76.3% of the fine-tuning data can be successfully extracted, with even higher rates in optimal conditions. The study emphasizes the urgent need for further research to address this data security issue in the context of LLM fine-tuning."
                },
                "zh": {
                    "title": "微调中的数据泄露风险警示",
                    "desc": "本论文揭示了在开源大型语言模型（LLMs）上进行微调时可能存在的隐私风险。研究表明，开源模型的创建者可以通过简单的后门训练提取私有的微调数据，即使只通过黑箱访问微调后的模型。实验结果显示，在实际情况下，最多可提取76.3%的微调数据，而在理想情况下成功率可达94.9%。我们还探讨了一种基于检测的防御策略，但发现该策略可以被改进的攻击绕过，因此强调了这一新识别的数据泄露风险的紧迫性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13934",
            "title": "RLVR-World: Training World Models with Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.13934",
            "abstract": "World models predict state transitions in response to actions and are increasingly developed across diverse modalities. However, standard training objectives such as maximum likelihood estimation (MLE) often misalign with task-specific goals of world models, i.e., transition prediction metrics like accuracy or perceptual quality. In this paper, we present RLVR-World, a unified framework that leverages reinforcement learning with verifiable rewards (RLVR) to directly optimize world models for such metrics. Despite formulating world modeling as autoregressive prediction of tokenized sequences, RLVR-World evaluates metrics of decoded predictions as verifiable rewards. We demonstrate substantial performance gains on both language- and video-based world models across domains, including text games, web navigation, and robot manipulation. Our work indicates that, beyond recent advances in reasoning language models, RLVR offers a promising post-training paradigm for enhancing the utility of generative models more broadly.",
            "score": 9,
            "issue_id": 3891,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "bb3f20501a24c607",
            "authors": [
                "Jialong Wu",
                "Shaofeng Yin",
                "Ningya Feng",
                "Mingsheng Long"
            ],
            "affiliations": [
                "School of Software, BNRist, Tsinghua University",
                "Zhili College, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13934.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#training",
                    "#multimodal",
                    "#optimization",
                    "#reasoning",
                    "#games",
                    "#rl",
                    "#agents",
                    "#video"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "RLVR-World: Революция в обучении мировых моделей",
                    "desc": "RLVR-World - это новый подход к обучению мировых моделей, использующий обучение с подкреплением с проверяемыми наградами. В отличие от стандартных методов, таких как оценка максимального правдоподобия, RLVR-World оптимизирует модели непосредственно для специфических метрик задачи. Этот метод применим к различным модальностям, включая языковые и видео-модели. Эксперименты показали значительное улучшение производительности в таких областях, как текстовые игры, веб-навигация и робототехника."
                },
                "en": {
                    "title": "Optimizing World Models with Reinforcement Learning for Better Predictions",
                    "desc": "This paper introduces RLVR-World, a new framework that improves world models by using reinforcement learning with verifiable rewards. Traditional training methods like maximum likelihood estimation often do not align well with the specific goals of these models, such as accuracy in predicting state transitions. RLVR-World addresses this by optimizing world models directly for metrics that matter, like perceptual quality and accuracy. The authors show that this approach leads to significant improvements in performance for both language and video-based models across various tasks, including text games and robot manipulation."
                },
                "zh": {
                    "title": "通过可验证奖励优化世界模型的创新框架",
                    "desc": "本论文提出了一种名为RLVR-World的统一框架，旨在通过可验证奖励的强化学习来优化世界模型。传统的训练目标如最大似然估计（MLE）往往与特定任务的目标不一致，而RLVR-World直接针对过渡预测的准确性和感知质量进行优化。我们将世界建模视为对标记序列的自回归预测，并通过解码预测的度量作为可验证奖励进行评估。实验结果表明，RLVR-World在语言和视频基础的世界模型上均取得了显著的性能提升，适用于文本游戏、网页导航和机器人操作等多个领域。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13529",
            "title": "BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs",
            "url": "https://huggingface.co/papers/2505.13529",
            "abstract": "Recent advances in Large Reasoning Models (LRMs) have shown impressive capabilities in mathematical and logical reasoning. However, current LRMs rarely admit ignorance or respond with \"I don't know\". Instead, they often produce incorrect answers while showing undue confidence, raising concerns about their factual reliability. In this work, we identify two pathological reasoning patterns characterized by overthinking that contribute to the overconfident and incorrect answers: last-minute guessing and second-thought spiraling. To address these issues, we propose BARREL-a novel framework that promotes concise and boundary-aware factual reasoning. Our experiments show that BARREL-training increases the reliability of DeepSeek-R1-Distill-Llama-8B from 39.33% to 61.48%, while still achieving accuracy comparable to models finetuned on reasoning data generated by R1. These results demonstrate that our pilot study is inspiring to build more reliable and factual System 2 LRMs.",
            "score": 9,
            "issue_id": 3892,
            "pub_date": "2025-05-18",
            "pub_date_card": {
                "ru": "18 мая",
                "en": "May 18",
                "zh": "5月18日"
            },
            "hash": "b0175ab5c60ceaee",
            "authors": [
                "Junxiao Yang",
                "Jinzhe Tu",
                "Haoran Liu",
                "Xiaoce Wang",
                "Chujie Zheng",
                "Zhexin Zhang",
                "Shiyao Cui",
                "Caishun Chen",
                "Tiantian He",
                "Hongning Wang",
                "Yew-Soon Ong",
                "Minlie Huang"
            ],
            "affiliations": [
                "Centre for Frontier AI Research, Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore",
                "The College of Computing and Data Science, Nanyang Technological University",
                "The Conversational AI (CoAI) group, DCST, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13529.jpg",
            "data": {
                "categories": [
                    "#hallucinations",
                    "#reasoning",
                    "#training",
                    "#math"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Повышение надежности ИИ-рассуждений через осознание границ знаний",
                    "desc": "Это исследование посвящено проблеме чрезмерной уверенности и неточности ответов больших моделей рассуждений (LRM) в математических и логических задачах. Авторы выявили два паттерна неправильных рассуждений: поспешные догадки в последний момент и спиральное overthinking. Для решения этих проблем предложен новый фреймворк BARREL, который способствует лаконичному и ограниченному фактическому рассуждению. Эксперименты показали, что BARREL повышает надежность модели DeepSeek-R1-Distill-Llama-8B с 39.33% до 61.48%, сохраняя при этом точность на уровне моделей, дообученных на данных рассуждений R1."
                },
                "en": {
                    "title": "Enhancing Confidence and Reliability in Large Reasoning Models with BARREL",
                    "desc": "This paper discusses the limitations of Large Reasoning Models (LRMs) in handling mathematical and logical reasoning, particularly their tendency to provide incorrect answers with excessive confidence. The authors identify two problematic reasoning behaviors: last-minute guessing and second-thought spiraling, which lead to these overconfident mistakes. To combat this, they introduce BARREL, a new framework designed to enhance factual reasoning by encouraging models to be more concise and aware of their boundaries. Their experiments show that training with BARREL significantly improves the reliability of a specific LRM, DeepSeek-R1-Distill-Llama-8B, while maintaining competitive accuracy levels."
                },
                "zh": {
                    "title": "提升推理模型的可靠性与准确性",
                    "desc": "最近，大型推理模型（LRMs）在数学和逻辑推理方面展现了令人印象深刻的能力。然而，目前的LRMs很少承认自己的无知，通常会在错误的情况下表现出过度自信，这引发了对其事实可靠性的担忧。本文识别了两种病态推理模式，导致了过度自信和错误答案的产生：临时猜测和反复思考。为了解决这些问题，我们提出了BARREL框架，促进简洁且边界意识强的事实推理。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15778",
            "title": "Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous\n  Concept Space",
            "url": "https://huggingface.co/papers/2505.15778",
            "abstract": "Human cognition typically involves thinking through abstract, fluid concepts rather than strictly using discrete linguistic tokens. Current reasoning models, however, are constrained to reasoning within the boundaries of human language, processing discrete token embeddings that represent fixed points in the semantic space. This discrete constraint restricts the expressive power and upper potential of such reasoning models, often causing incomplete exploration of reasoning paths, as standard Chain-of-Thought (CoT) methods rely on sampling one token per step. In this work, we introduce Soft Thinking, a training-free method that emulates human-like \"soft\" reasoning by generating soft, abstract concept tokens in a continuous concept space. These concept tokens are created by the probability-weighted mixture of token embeddings, which form the continuous concept space, enabling smooth transitions and richer representations that transcend traditional discrete boundaries. In essence, each generated concept token encapsulates multiple meanings from related discrete tokens, implicitly exploring various reasoning paths to converge effectively toward the correct answer. Empirical evaluations on diverse mathematical and coding benchmarks consistently demonstrate the effectiveness and efficiency of Soft Thinking, improving pass@1 accuracy by up to 2.48 points while simultaneously reducing token usage by up to 22.4% compared to standard CoT. Qualitative analysis further reveals that Soft Thinking outputs remain highly interpretable and readable, highlighting the potential of Soft Thinking to break the inherent bottleneck of discrete language-based reasoning. Code is available at https://github.com/eric-ai-lab/Soft-Thinking.",
            "score": 8,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "96715f0b3118eceb",
            "authors": [
                "Zhen Zhang",
                "Xuehai He",
                "Weixiang Yan",
                "Ao Shen",
                "Chenyang Zhao",
                "Shuohang Wang",
                "Yelong Shen",
                "Xin Eric Wang"
            ],
            "affiliations": [
                "LMSYS Org",
                "Microsoft",
                "Purdue University",
                "University of California, Los Angeles",
                "University of California, Santa Barbara",
                "University of California, Santa Cruz"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15778.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#interpretability",
                    "#reasoning",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Мягкое мышление: преодоление границ дискретного языкового рассуждения в ИИ",
                    "desc": "Эта статья представляет новый метод машинного обучения под названием 'Soft Thinking', который имитирует человеческое мышление в непрерывном пространстве концепций. В отличие от стандартных моделей рассуждений, ограниченных дискретными языковыми токенами, 'Soft Thinking' генерирует мягкие, абстрактные токены концепций. Этот подход позволяет исследовать более богатые представления и плавные переходы между концепциями, что приводит к улучшению точности и эффективности в задачах математики и программирования. Эмпирические результаты показывают повышение точности до 2.48 пунктов при одновременном снижении использования токенов до 22.4% по сравнению со стандартным методом Chain-of-Thought."
                },
                "en": {
                    "title": "Soft Thinking: Beyond Discrete Boundaries in Reasoning",
                    "desc": "This paper presents Soft Thinking, a novel approach to reasoning that mimics human cognitive processes by utilizing continuous concept spaces instead of discrete token embeddings. Traditional reasoning models are limited by their reliance on fixed linguistic tokens, which restricts their ability to explore diverse reasoning paths. Soft Thinking generates abstract concept tokens through a probability-weighted mixture of existing token embeddings, allowing for smoother transitions and richer representations. Empirical results show that this method improves accuracy and reduces token usage, while maintaining interpretability, thus addressing the limitations of conventional Chain-of-Thought reasoning."
                },
                "zh": {
                    "title": "突破离散限制，拥抱软思维！",
                    "desc": "人类的认知通常涉及抽象和流动的概念，而不是仅仅依赖于离散的语言符号。当前的推理模型受限于人类语言的边界，只能处理代表固定语义点的离散标记嵌入。这种离散限制降低了推理模型的表达能力，导致推理路径的探索不够全面。本文提出了一种名为“软思维”的方法，通过在连续概念空间中生成软的抽象概念标记，模拟人类的“软”推理，从而提高推理的有效性和效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15776",
            "title": "ConvSearch-R1: Enhancing Query Reformulation for Conversational Search\n  with Reasoning via Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.15776",
            "abstract": "Conversational search systems require effective handling of context-dependent queries that often contain ambiguity, omission, and coreference. Conversational Query Reformulation (CQR) addresses this challenge by transforming these queries into self-contained forms suitable for off-the-shelf retrievers. However, existing CQR approaches suffer from two critical constraints: high dependency on costly external supervision from human annotations or large language models, and insufficient alignment between the rewriting model and downstream retrievers. We present ConvSearch-R1, the first self-driven framework that completely eliminates dependency on external rewrite supervision by leveraging reinforcement learning to optimize reformulation directly through retrieval signals. Our novel two-stage approach combines Self-Driven Policy Warm-Up to address the cold-start problem through retrieval-guided self-distillation, followed by Retrieval-Guided Reinforcement Learning with a specially designed rank-incentive reward shaping mechanism that addresses the sparsity issue in conventional retrieval metrics. Extensive experiments on TopiOCQA and QReCC datasets demonstrate that ConvSearch-R1 significantly outperforms previous state-of-the-art methods, achieving over 10% improvement on the challenging TopiOCQA dataset while using smaller 3B parameter models without any external supervision.",
            "score": 8,
            "issue_id": 3896,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "d52cdaf90c573017",
            "authors": [
                "Changtai Zhu",
                "Siyin Wang",
                "Ruijun Feng",
                "Kai Song",
                "Xipeng Qiu"
            ],
            "affiliations": [
                "ByteDance Inc",
                "Fudan University",
                "University of New South Wales"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15776.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#dataset",
                    "#rag",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Самообучающаяся система переформулировки запросов для диалогового поиска",
                    "desc": "Статья представляет ConvSearch-R1 - первую самоуправляемую систему для переформулировки контекстно-зависимых запросов в поисковых диалоговых системах. В отличие от существующих подходов, ConvSearch-R1 не требует внешнего обучения, используя вместо этого обучение с подкреплением на основе сигналов поиска. Система применяет двухэтапный подход: самоуправляемый разогрев политики и обучение с подкреплением на основе поиска. Эксперименты показывают значительное улучшение производительности по сравнению с современными методами, особенно на сложном наборе данных TopiOCQA."
                },
                "en": {
                    "title": "Revolutionizing Conversational Query Reformulation with Self-Driven Learning",
                    "desc": "This paper introduces ConvSearch-R1, a novel framework for Conversational Query Reformulation (CQR) that eliminates the need for external supervision in query rewriting. It utilizes reinforcement learning to optimize the reformulation process based on retrieval signals, making it self-driven. The approach consists of a two-stage method that first addresses the cold-start problem and then employs a rank-incentive reward mechanism to improve retrieval performance. Experiments show that ConvSearch-R1 outperforms existing methods, achieving significant improvements on benchmark datasets with smaller models."
                },
                "zh": {
                    "title": "对话查询重构的新突破",
                    "desc": "本论文提出了一种新的对话查询重构框架ConvSearch-R1，旨在有效处理上下文相关的模糊查询。该方法通过强化学习直接利用检索信号优化查询重构，完全消除了对外部监督的依赖。我们采用了两阶段的方法，首先通过检索引导的自蒸馏解决冷启动问题，然后通过特别设计的奖励机制进行强化学习，以应对传统检索指标的稀疏性问题。实验结果表明，ConvSearch-R1在TopiOCQA和QReCC数据集上显著优于现有的最先进方法，尤其在TopiOCQA数据集上实现了超过10%的提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14827",
            "title": "Text Generation Beyond Discrete Token Sampling",
            "url": "https://huggingface.co/papers/2505.14827",
            "abstract": "In standard autoregressive generation, an LLM predicts the next-token distribution, samples a discrete token, and then discards the distribution, passing only the sampled token as new input. To preserve this distribution's rich information, we propose Mixture of Inputs (MoI), a training-free method for autoregressive generation. After generating a token following the standard paradigm, we construct a new input that blends the generated discrete token with the previously discarded token distribution. Specifically, we employ a Bayesian estimation method that treats the token distribution as the prior, the sampled token as the observation, and replaces the conventional one-hot vector with the continuous posterior expectation as the new model input. MoI allows the model to maintain a richer internal representation throughout the generation process, resulting in improved text quality and reasoning capabilities. On mathematical reasoning, code generation, and PhD-level QA tasks, MoI consistently improves performance across multiple models including QwQ-32B, Nemotron-Super-49B, Gemma-3-27B, and DAPO-Qwen-32B, with no additional training and negligible computational overhead.",
            "score": 7,
            "issue_id": 3893,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "c5866f38a43da092",
            "authors": [
                "Yufan Zhuang",
                "Liyuan Liu",
                "Chandan Singh",
                "Jingbo Shang",
                "Jianfeng Gao"
            ],
            "affiliations": [
                "Microsoft Research",
                "UC San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14827.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#training",
                    "#reasoning",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Смешивание входов для улучшения генерации языковых моделей",
                    "desc": "Исследователи предложили новый метод автореградивной генерации текста под названием Mixture of Inputs (MoI). В отличие от стандартного подхода, MoI сохраняет информацию о распределении вероятностей токенов, а не только выбранный токен. Метод использует байесовскую оценку для создания нового входа модели, объединяющего дискретный токен и распределение вероятностей. MoI позволяет модели поддерживать более богатое внутреннее представление в процессе генерации, что улучшает качество текста и способности к рассуждению."
                },
                "en": {
                    "title": "Enhancing Autoregressive Generation with Mixture of Inputs",
                    "desc": "This paper introduces a novel method called Mixture of Inputs (MoI) for enhancing autoregressive generation in large language models (LLMs). Instead of discarding the token distribution after sampling a token, MoI combines the generated token with the previously discarded distribution to create a richer input representation. By using Bayesian estimation, MoI treats the token distribution as a prior and the sampled token as an observation, allowing for a continuous posterior expectation to be used as input. This approach leads to improved performance in tasks such as mathematical reasoning, code generation, and PhD-level question answering without requiring additional training."
                },
                "zh": {
                    "title": "混合输入：提升自回归生成的质量与推理能力",
                    "desc": "在标准的自回归生成中，语言模型预测下一个标记的分布，采样一个离散标记，然后丢弃该分布，仅将采样的标记作为新输入。为了保留这个分布的丰富信息，我们提出了一种名为混合输入（MoI）的方法，它不需要额外的训练。该方法在生成标记后，构建一个新的输入，将生成的离散标记与之前丢弃的标记分布混合。MoI使模型在生成过程中保持更丰富的内部表示，从而提高文本质量和推理能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12650",
            "title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from\n  Microscopy via Agentic Tool Use",
            "url": "https://huggingface.co/papers/2505.12650",
            "abstract": "Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, converting these images into simulation-ready formats remains labor-intensive and error-prone, creating a bottleneck for model training and validation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that automatically transforms scanning transmission electron microscopy (STEM) images into atomic crystal structures and predicts their physical properties. AutoMat combines pattern-adaptive denoising, physics-guided template retrieval, symmetry-aware atomic reconstruction, fast relaxation and property prediction via MatterSim, and coordinated orchestration across all stages. We propose the first dedicated STEM2Mat-Bench for this task and evaluate performance using lattice RMSD, formation energy MAE, and structure-matching success rate. By orchestrating external tool calls, AutoMat enables a text-only LLM to outperform vision-language models in this domain, achieving closed-loop reasoning throughout the pipeline. In large-scale experiments over 450 structure samples, AutoMat substantially outperforms existing multimodal large language models and tools. These results validate both AutoMat and STEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic simulation in materials science.The code and dataset are publicly available at https://github.com/yyt-2378/AutoMat and https://huggingface.co/datasets/yaotianvector/STEM2Mat.",
            "score": 6,
            "issue_id": 3891,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "b02918769ea5f226",
            "authors": [
                "Yaotian Yang",
                "Yiwen Tang",
                "Yizhe Chen",
                "Xiao Chen",
                "Jiangjie Qiu",
                "Hao Xiong",
                "Haoyu Yin",
                "Zhiyao Luo",
                "Yifei Zhang",
                "Sijia Tao",
                "Wentao Li",
                "Qinghua Zhang",
                "Yuqiang Li",
                "Wanli Ouyang",
                "Bin Zhao",
                "Xiaonan Wang",
                "Fei Wei"
            ],
            "affiliations": [
                "Department of Chemical Engineering, Tsinghua University, Beijing, China",
                "School of Computer Science, Northwestern Polytechnical University, Xian, China",
                "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12650.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#multimodal",
                    "#open_source",
                    "#benchmark",
                    "#dataset",
                    "#agents",
                    "#science"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "AutoMat: от микроскопических изображений к атомным структурам",
                    "desc": "AutoMat - это новый конвейер для автоматического преобразования изображений сканирующей просвечивающей электронной микроскопии (STEM) в атомные кристаллические структуры и предсказания их физических свойств. Он объединяет адаптивное шумоподавление, физически обоснованный поиск шаблонов, реконструкцию атомов с учетом симметрии и быстрое предсказание свойств с помощью MatterSim. AutoMat превосходит существующие мультимодальные большие языковые модели и инструменты в задаче преобразования STEM-изображений в атомные структуры. Это важный шаг на пути к объединению микроскопии и атомистического моделирования в материаловедении."
                },
                "en": {
                    "title": "Automating Atomic Structure Extraction from STEM Images with AutoMat",
                    "desc": "This paper presents AutoMat, a machine learning pipeline designed to convert scanning transmission electron microscopy (STEM) images into atomic crystal structures efficiently. It addresses the challenge of limited experimental data by automating the transformation process, which traditionally requires significant manual effort. AutoMat integrates various techniques such as denoising, template retrieval, and property prediction to streamline the workflow and enhance model training. The authors also introduce the STEM2Mat-Bench for evaluating performance, demonstrating that AutoMat significantly outperforms existing models in this domain."
                },
                "zh": {
                    "title": "AutoMat：显微镜与原子模拟的桥梁",
                    "desc": "本论文介绍了一种名为AutoMat的自动化管道，旨在将扫描透射电子显微镜（STEM）图像转换为原子晶体结构，并预测其物理性质。该方法结合了多种技术，包括自适应去噪、物理引导的模板检索和对称感知的原子重建，能够高效地处理数据。通过引入STEM2Mat-Bench进行性能评估，AutoMat在多个指标上显著优于现有的多模态大语言模型。此研究为材料科学中显微镜与原子级模拟之间的桥梁建设提供了重要进展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15801",
            "title": "VerifyBench: Benchmarking Reference-based Reward Systems for Large\n  Language Models",
            "url": "https://huggingface.co/papers/2505.15801",
            "abstract": "Large reasoning models such as OpenAI o1 and DeepSeek-R1 have achieved remarkable performance in the domain of reasoning. A key component of their training is the incorporation of verifiable rewards within reinforcement learning (RL). However, existing reward benchmarks do not evaluate reference-based reward systems, leaving researchers with limited understanding of the accuracy of verifiers used in RL. In this paper, we introduce two benchmarks, VerifyBench and VerifyBench-Hard, designed to assess the performance of reference-based reward systems. These benchmarks are constructed through meticulous data collection and curation, followed by careful human annotation to ensure high quality. Current models still show considerable room for improvement on both VerifyBench and VerifyBench-Hard, especially smaller-scale models. Furthermore, we conduct a thorough and comprehensive analysis of evaluation results, offering insights for understanding and developing reference-based reward systems. Our proposed benchmarks serve as effective tools for guiding the development of verifier accuracy and the reasoning capabilities of models trained via RL in reasoning tasks.",
            "score": 4,
            "issue_id": 3905,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "45285c81d23cba37",
            "authors": [
                "Yuchen Yan",
                "Jin Jiang",
                "Zhenbang Ren",
                "Yijun Li",
                "Xudong Cai",
                "Yang Liu",
                "Xin Xu",
                "Mengdi Zhang",
                "Jian Shao",
                "Yongliang Shen",
                "Jun Xiao",
                "Yueting Zhuang"
            ],
            "affiliations": [
                "Beijing University of Posts and Telecommunications",
                "Meituan Group",
                "Peking University",
                "The Hong Kong University of Science and Technology",
                "University of Electronic Science and Technology of China",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15801.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#dataset",
                    "#optimization",
                    "#rl",
                    "#data",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Новые бенчмарки для улучшения точности верификаторов в обучении с подкреплением",
                    "desc": "Статья представляет два новых бенчмарка для оценки систем вознаграждения на основе эталонов в обучении с подкреплением (RL) для моделей рассуждений. VerifyBench и VerifyBench-Hard разработаны для измерения точности верификаторов, используемых в RL. Исследование показывает, что современные модели, особенно небольшого масштаба, имеют значительный потенциал для улучшения на этих бенчмарках. Авторы проводят подробный анализ результатов оценки, предоставляя ценные выводы для разработки систем вознаграждения на основе эталонов."
                },
                "en": {
                    "title": "Enhancing Reasoning Models with New Reward Benchmarks",
                    "desc": "This paper discusses the development of two new benchmarks, VerifyBench and VerifyBench-Hard, aimed at evaluating reference-based reward systems in reinforcement learning (RL). These benchmarks are created through careful data collection and human annotation to ensure their quality and effectiveness. The authors highlight that current reasoning models, including smaller-scale ones, still have significant room for improvement when tested against these benchmarks. The paper provides insights into enhancing verifier accuracy and the reasoning abilities of models trained with RL, ultimately guiding future research in this area."
                },
                "zh": {
                    "title": "提升推理模型的奖励系统评估",
                    "desc": "本文介绍了大型推理模型在推理领域的出色表现，特别是OpenAI o1和DeepSeek-R1。我们提出了两个基准测试，VerifyBench和VerifyBench-Hard，用于评估基于参考的奖励系统的性能。通过精心的数据收集和人工标注，这些基准确保了高质量的评估。我们的研究表明，当前模型在这两个基准上仍有很大的改进空间，尤其是小规模模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15524",
            "title": "Evaluate Bias without Manual Test Sets: A Concept Representation\n  Perspective for LLMs",
            "url": "https://huggingface.co/papers/2505.15524",
            "abstract": "Bias in Large Language Models (LLMs) significantly undermines their reliability and fairness. We focus on a common form of bias: when two reference concepts in the model's concept space, such as sentiment polarities (e.g., \"positive\" and \"negative\"), are asymmetrically correlated with a third, target concept, such as a reviewing aspect, the model exhibits unintended bias. For instance, the understanding of \"food\" should not skew toward any particular sentiment. Existing bias evaluation methods assess behavioral differences of LLMs by constructing labeled data for different social groups and measuring model responses across them, a process that requires substantial human effort and captures only a limited set of social concepts. To overcome these limitations, we propose BiasLens, a test-set-free bias analysis framework based on the structure of the model's vector space. BiasLens combines Concept Activation Vectors (CAVs) with Sparse Autoencoders (SAEs) to extract interpretable concept representations, and quantifies bias by measuring the variation in representational similarity between the target concept and each of the reference concepts. Even without labeled data, BiasLens shows strong agreement with traditional bias evaluation metrics (Spearman correlation r > 0.85). Moreover, BiasLens reveals forms of bias that are difficult to detect using existing methods. For example, in simulated clinical scenarios, a patient's insurance status can cause the LLM to produce biased diagnostic assessments. Overall, BiasLens offers a scalable, interpretable, and efficient paradigm for bias discovery, paving the way for improving fairness and transparency in LLMs.",
            "score": 4,
            "issue_id": 3900,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "79c358dbadeae017",
            "authors": [
                "Lang Gao",
                "Kaiyang Wan",
                "Wei Liu",
                "Chenxi Wang",
                "Zirui Song",
                "Zixiang Xu",
                "Yanbo Wang",
                "Veselin Stoyanov",
                "Xiuying Chen"
            ],
            "affiliations": [
                "Huazhong University of Science and Technology",
                "MBZUAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15524.jpg",
            "data": {
                "categories": [
                    "#ethics",
                    "#multimodal",
                    "#benchmark",
                    "#interpretability",
                    "#data"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "BiasLens: Новый взгляд на предвзятость в языковых моделях",
                    "desc": "Статья представляет BiasLens - новый метод анализа предвзятости в больших языковых моделях (LLM) без использования тестовых наборов данных. BiasLens использует векторы активации концепций (CAV) и разреженные автоэнкодеры (SAE) для извлечения интерпретируемых представлений концепций и количественной оценки предвзятости. Метод показывает сильную корреляцию с традиционными метриками оценки предвзятости и способен выявлять формы предвзятости, трудно обнаруживаемые существующими методами. BiasLens предлагает масштабируемую и эффективную парадигму для обнаружения предвзятости в LLM, способствуя улучшению их справедливости и прозрачности."
                },
                "en": {
                    "title": "Uncovering Bias in Language Models with BiasLens",
                    "desc": "This paper addresses the issue of bias in Large Language Models (LLMs), particularly focusing on how certain concepts can be unfairly correlated with others, leading to skewed outputs. The authors introduce BiasLens, a novel framework that analyzes bias without the need for labeled data, using the model's vector space structure. By employing Concept Activation Vectors (CAVs) and Sparse Autoencoders (SAEs), BiasLens quantifies bias through representational similarity, demonstrating strong alignment with traditional evaluation methods. This approach not only enhances the detection of subtle biases but also promotes fairness and transparency in LLMs."
                },
                "zh": {
                    "title": "揭示大型语言模型中的偏见新方法",
                    "desc": "本文探讨了大型语言模型（LLMs）中的偏见问题，指出这种偏见会影响模型的可靠性和公平性。我们关注一种常见的偏见形式，即模型概念空间中两个参考概念（如情感极性）与目标概念（如评论方面）之间的不对称相关性。为了解决现有偏见评估方法的局限性，本文提出了BiasLens框架，它结合了概念激活向量（CAVs）和稀疏自编码器（SAEs），无需标注数据即可进行偏见分析。BiasLens能够有效量化偏见，并揭示传统方法难以检测的偏见形式，从而为提高LLMs的公平性和透明性提供了新的思路。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15791",
            "title": "VARD: Efficient and Dense Fine-Tuning for Diffusion Models with\n  Value-based RL",
            "url": "https://huggingface.co/papers/2505.15791",
            "abstract": "Diffusion models have emerged as powerful generative tools across various domains, yet tailoring pre-trained models to exhibit specific desirable properties remains challenging. While reinforcement learning (RL) offers a promising solution,current methods struggle to simultaneously achieve stable, efficient fine-tuning and support non-differentiable rewards. Furthermore, their reliance on sparse rewards provides inadequate supervision during intermediate steps, often resulting in suboptimal generation quality. To address these limitations, dense and differentiable signals are required throughout the diffusion process. Hence, we propose VAlue-based Reinforced Diffusion (VARD): a novel approach that first learns a value function predicting expection of rewards from intermediate states, and subsequently uses this value function with KL regularization to provide dense supervision throughout the generation process. Our method maintains proximity to the pretrained model while enabling effective and stable training via backpropagation. Experimental results demonstrate that our approach facilitates better trajectory guidance, improves training efficiency and extends the applicability of RL to diffusion models optimized for complex, non-differentiable reward functions.",
            "score": 3,
            "issue_id": 3892,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "48280e44cc4e905f",
            "authors": [
                "Fengyuan Dai",
                "Zifeng Zhuang",
                "Yufei Huang",
                "Siteng Huang",
                "Bangyan Liao",
                "Donglin Wang",
                "Fajie Yuan"
            ],
            "affiliations": [
                "Westlake University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15791.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#rl",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "VARD: Усиление диффузионных моделей с помощью обучения с подкреплением",
                    "desc": "Статья представляет новый метод под названием VARD (Value-based Reinforced Diffusion) для улучшения диффузионных моделей с помощью обучения с подкреплением. VARD использует функцию ценности для предсказания ожидаемых наград из промежуточных состояний и применяет ее вместе с KL-регуляризацией для плотного обучения на протяжении всего процесса генерации. Этот подход позволяет сохранять близость к предобученной модели, обеспечивая при этом эффективное и стабильное обучение. Экспериментальные результаты показывают, что VARD улучшает управление траекторией, повышает эффективность обучения и расширяет применимость обучения с подкреплением для диффузионных моделей."
                },
                "en": {
                    "title": "Enhancing Diffusion Models with Value-Based Reinforcement Learning",
                    "desc": "This paper introduces VAlue-based Reinforced Diffusion (VARD), a new method for fine-tuning diffusion models using reinforcement learning. The approach addresses the challenges of stable and efficient training while dealing with non-differentiable rewards by incorporating a value function that predicts expected rewards from intermediate states. By applying KL regularization, VARD provides dense supervision throughout the generation process, enhancing the model's performance. Experimental results show that VARD improves trajectory guidance and training efficiency, making it suitable for complex reward functions in diffusion models."
                },
                "zh": {
                    "title": "基于价值的强化扩散：提升生成质量的新方法",
                    "desc": "扩散模型在多个领域中成为强大的生成工具，但将预训练模型调整为具有特定期望属性仍然具有挑战性。强化学习（RL）提供了一种有前景的解决方案，但当前方法在实现稳定、高效的微调和支持非可微分奖励方面存在困难。此外，稀疏奖励在中间步骤提供的监督不足，常常导致生成质量不佳。为了解决这些问题，我们提出了基于价值的强化扩散（VARD）方法，通过学习价值函数来预测中间状态的奖励期望，并使用KL正则化提供密集监督，从而提高生成过程的质量和效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15406",
            "title": "Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large\n  Audio-Language Models",
            "url": "https://huggingface.co/papers/2505.15406",
            "abstract": "The rise of Large Audio Language Models (LAMs) brings both potential and risks, as their audio outputs may contain harmful or unethical content. However, current research lacks a systematic, quantitative evaluation of LAM safety especially against jailbreak attacks, which are challenging due to the temporal and semantic nature of speech. To bridge this gap, we introduce AJailBench, the first benchmark specifically designed to evaluate jailbreak vulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of 1,495 adversarial audio prompts spanning 10 policy-violating categories, converted from textual jailbreak attacks using realistic text to speech synthesis. Using this dataset, we evaluate several state-of-the-art LAMs and reveal that none exhibit consistent robustness across attacks. To further strengthen jailbreak testing and simulate more realistic attack conditions, we propose a method to generate dynamic adversarial variants. Our Audio Perturbation Toolkit (APT) applies targeted distortions across time, frequency, and amplitude domains. To preserve the original jailbreak intent, we enforce a semantic consistency constraint and employ Bayesian optimization to efficiently search for perturbations that are both subtle and highly effective. This results in AJailBench-APT, an extended dataset of optimized adversarial audio samples. Our findings demonstrate that even small, semantically preserved perturbations can significantly reduce the safety performance of leading LAMs, underscoring the need for more robust and semantically aware defense mechanisms.",
            "score": 3,
            "issue_id": 3900,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "2d6a5f87ed813485",
            "authors": [
                "Zirui Song",
                "Qian Jiang",
                "Mingxuan Cui",
                "Mingzhe Li",
                "Lang Gao",
                "Zeyu Zhang",
                "Zixiang Xu",
                "Yanbo Wang",
                "Chenxi Wang",
                "Guangxian Ouyang",
                "Zhenhao Chen",
                "Xiuying Chen"
            ],
            "affiliations": [
                "Australia National University",
                "ByteDance",
                "Mohamed bin Zayed University of Artificial Intelligence"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15406.jpg",
            "data": {
                "categories": [
                    "#ethics",
                    "#dataset",
                    "#benchmark",
                    "#security",
                    "#audio"
                ],
                "emoji": "🎙️",
                "ru": {
                    "title": "AJailBench: Новый рубеж в оценке безопасности аудио-ИИ",
                    "desc": "Статья представляет AJailBench - первый бенчмарк для оценки уязвимостей к атакам джейлбрейка в больших аудио-языковых моделях (LAM). Авторы создали набор данных AJailBench-Base из 1495 вредоносных аудио-запросов и оценили на нем несколько современных LAM. Также был разработан инструментарий Audio Perturbation Toolkit для генерации динамических вариантов атак с сохранением семантики. Результаты показывают, что даже небольшие семантически сохраненные возмущения могут значительно снизить безопасность ведущих LAM."
                },
                "en": {
                    "title": "Evaluating and Enhancing Safety in Large Audio Language Models",
                    "desc": "This paper addresses the safety concerns associated with Large Audio Language Models (LAMs), particularly their vulnerability to jailbreak attacks. It introduces AJailBench, a benchmark designed to systematically evaluate these vulnerabilities using a dataset of adversarial audio prompts. The study reveals that current LAMs lack consistent robustness against various attacks, highlighting the need for improved defenses. Additionally, the authors propose an Audio Perturbation Toolkit (APT) to create subtle yet effective adversarial audio samples that maintain semantic integrity, demonstrating the significant impact of small perturbations on LAM safety."
                },
                "zh": {
                    "title": "评估大型音频语言模型的安全性与漏洞",
                    "desc": "大型音频语言模型（LAMs）的兴起带来了潜力和风险，因为它们的音频输出可能包含有害或不道德的内容。目前的研究缺乏对LAM安全性的系统性定量评估，尤其是在针对越狱攻击方面。为了解决这个问题，我们提出了AJailBench，这是第一个专门设计用于评估LAM越狱漏洞的基准测试。我们的研究表明，即使是微小的、保持语义一致的扰动也能显著降低领先LAM的安全性能，强调了需要更强大和更具语义意识的防御机制。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15047",
            "title": "PiFlow: Principle-aware Scientific Discovery with Multi-Agent\n  Collaboration",
            "url": "https://huggingface.co/papers/2505.15047",
            "abstract": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering systematic uncertainty reduction. Overcoming these limitations fundamentally requires systematic uncertainty reduction. We introduce PiFlow, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains -- discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -- our method significantly improves discovery efficiency, reflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06\\% compared to a vanilla agent system. Overall, PiFlow serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our https://github.com/amair-lab/PiFlow{GitHub}.",
            "score": 3,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "12f9a805fafedcf5",
            "authors": [
                "Yingming Pu",
                "Tao Lin",
                "Hongyu Chen"
            ],
            "affiliations": [
                "Westlake University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15047.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#open_source",
                    "#rl",
                    "#agents",
                    "#science"
                ],
                "emoji": "🧪",
                "ru": {
                    "title": "PiFlow: Революция в автоматизированном научном открытии",
                    "desc": "PiFlow - это информационно-теоретическая система для автоматизированного научного открытия на основе многоагентных систем с использованием больших языковых моделей. Она рассматривает научное открытие как структурированную задачу уменьшения неопределенности, основанную на научных принципах. PiFlow значительно повышает эффективность открытий в различных научных областях, таких как наноматериалы, биомолекулы и сверхпроводники. По сравнению с обычными агентными системами, PiFlow демонстрирует улучшение качества решений на 94.06% и увеличение площади под кривой значений свойств на 73.55%."
                },
                "en": {
                    "title": "PiFlow: Revolutionizing Automated Scientific Discovery through Uncertainty Reduction",
                    "desc": "This paper presents PiFlow, a new framework for improving automated scientific discovery using Large Language Model (LLM)-based multi-agent systems. It addresses the limitations of existing methods that often lack rationality and fail to connect hypotheses with evidence, leading to inefficient exploration. By framing the discovery process as a structured uncertainty reduction problem, PiFlow enhances the efficiency and quality of scientific discoveries across various domains. The results show significant improvements in discovery efficiency and solution quality, marking a shift towards more effective AI-driven research."
                },
                "zh": {
                    "title": "PiFlow：高效的自动化科学发现新范式",
                    "desc": "基于大型语言模型（LLM）的多智能体系统（MAS）在科学发现中展现出显著潜力。然而，现有方法通常使用预定义的工作流程来自动化科学发现，这些流程缺乏合理性约束，导致假设无目的且无法有效链接假设与证据，从而阻碍系统性的不确定性减少。为了解决这些问题，我们提出了PiFlow，一个信息理论框架，将自动化科学发现视为一个结构化的不确定性减少问题，并以科学原则为指导。在三个不同的科学领域中进行评估时，我们的方法显著提高了发现效率，并且解决方案质量也得到了显著提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15034",
            "title": "RL Tango: Reinforcing Generator and Verifier Together for Language\n  Reasoning",
            "url": "https://huggingface.co/papers/2505.15034",
            "abstract": "Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifiers that are fixed (rule-based or frozen pretrained) or trained discriminatively via supervised fine-tuning (SFT). Such designs are susceptible to reward hacking and generalize poorly beyond their training distributions. To overcome these limitations, we propose Tango, a novel framework that uses RL to concurrently train both an LLM generator and a verifier in an interleaved manner. A central innovation of Tango is its generative, process-level LLM verifier, which is trained via RL and co-evolves with the generator. Importantly, the verifier is trained solely based on outcome-level verification correctness rewards without requiring explicit process-level annotations. This generative RL-trained verifier exhibits improved robustness and superior generalization compared to deterministic or SFT-trained verifiers, fostering effective mutual reinforcement with the generator. Extensive experiments demonstrate that both components of Tango achieve state-of-the-art results among 7B/8B-scale models: the generator attains best-in-class performance across five competition-level math benchmarks and four challenging out-of-domain reasoning tasks, while the verifier leads on the ProcessBench dataset. Remarkably, both components exhibit particularly substantial improvements on the most difficult mathematical reasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.",
            "score": 3,
            "issue_id": 3897,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "35041556b54ed6d4",
            "authors": [
                "Kaiwen Zha",
                "Zhengqi Gao",
                "Maohao Shen",
                "Zhang-Wei Hong",
                "Duane S. Boning",
                "Dina Katabi"
            ],
            "affiliations": [
                "MIT",
                "MIT-IBM Watson AI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15034.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#rlhf",
                    "#reasoning",
                    "#rl",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🕺",
                "ru": {
                    "title": "Tango: Танец обучения с подкреплением для улучшения рассуждений LLM",
                    "desc": "Статья представляет новый метод Tango для улучшения способностей больших языковых моделей (LLM) к рассуждению с помощью обучения с подкреплением. В отличие от существующих подходов, Tango обучает одновременно и генеративную модель, и верификатор, используя обучение с подкреплением. Генеративный верификатор на основе LLM, обученный с помощью RL, демонстрирует улучшенную устойчивость и обобщение по сравнению с детерминированными верификаторами или обученными с помощью SFT. Эксперименты показывают, что обе компоненты Tango достигают наилучших результатов среди моделей масштаба 7B/8B на различных тестах по математическим рассуждениям и задачам вне обучающего распределения."
                },
                "en": {
                    "title": "Tango: Reinforcing Language Models with Generative Verifiers",
                    "desc": "This paper introduces Tango, a new framework that enhances large language models (LLMs) using reinforcement learning (RL). Unlike traditional methods that rely on fixed or supervised verifiers, Tango trains both the LLM generator and the verifier together, allowing them to improve each other through mutual reinforcement. The verifier in Tango is generative and learns from outcome-level rewards, making it more robust and capable of generalizing better to new tasks. Experiments show that Tango achieves state-of-the-art performance on various reasoning benchmarks, especially in challenging mathematical problems."
                },
                "zh": {
                    "title": "Tango：强化学习提升语言模型推理能力的创新框架",
                    "desc": "强化学习（RL）最近成为提升大型语言模型（LLM）推理能力的一种有效方法。在现有的RL后训练方法中，通常使用固定的验证器，这可能导致奖励黑客行为和泛化能力差。为了解决这些问题，我们提出了Tango框架，它通过交替训练LLM生成器和验证器来实现更好的性能。Tango的创新在于其生成式的过程级验证器，能够在没有明确过程级注释的情况下，仅基于结果级验证奖励进行训练，从而提高了鲁棒性和泛化能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15816",
            "title": "Streamline Without Sacrifice - Squeeze out Computation Redundancy in LMM",
            "url": "https://huggingface.co/papers/2505.15816",
            "abstract": "Large multimodal models excel in multimodal tasks but face significant computational challenges due to excessive computation on visual tokens. Unlike token reduction methods that focus on token-level redundancy, we identify and study the computation-level redundancy on vision tokens to ensure no information loss. Our key insight is that vision tokens from the pretrained vision encoder do not necessarily require all the heavy operations (e.g., self-attention, FFNs) in decoder-only LMMs and could be processed more lightly with proper designs. We designed a series of experiments to discover and progressively squeeze out the vision-related computation redundancy. Based on our findings, we propose ProxyV, a novel approach that utilizes proxy vision tokens to alleviate the computational burden on original vision tokens. ProxyV enhances efficiency without compromising performance and can even yield notable performance gains in scenarios with more moderate efficiency improvements. Furthermore, the flexibility of ProxyV is demonstrated through its combination with token reduction methods to boost efficiency further. The code will be made public at this https://github.com/penghao-wu/ProxyV URL.",
            "score": 2,
            "issue_id": 3891,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "96ff09e995e7c437",
            "authors": [
                "Penghao Wu",
                "Lewei Lu",
                "Ziwei Liu"
            ],
            "affiliations": [
                "1S-Lab, Nanyang Technological University",
                "SenseTime"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15816.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#optimization",
                    "#open_source",
                    "#architecture",
                    "#inference"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "ProxyV: Оптимизация вычислений для визуальных токенов в мультимодальных моделях",
                    "desc": "Статья представляет новый подход ProxyV для повышения эффективности мультимодальных моделей машинного обучения. Авторы обнаружили избыточность вычислений для визуальных токенов в декодер-ориентированных моделях. ProxyV использует прокси-токены для снижения вычислительной нагрузки без потери производительности. Метод показывает гибкость и совместимость с другими методами сокращения токенов."
                },
                "en": {
                    "title": "Enhancing Efficiency in Multimodal Models with Proxy Vision Tokens",
                    "desc": "This paper addresses the computational challenges faced by large multimodal models, particularly in processing visual tokens. Instead of focusing on reducing the number of tokens, the authors explore computation-level redundancy, revealing that not all heavy operations are necessary for vision tokens in decoder-only models. They introduce ProxyV, a method that uses proxy vision tokens to reduce the computational load while maintaining or even improving performance. The study shows that ProxyV can be combined with existing token reduction techniques for even greater efficiency gains."
                },
                "zh": {
                    "title": "ProxyV：减轻视觉计算负担的创新方法",
                    "desc": "本文研究了大型多模态模型在处理视觉标记时的计算冗余问题。我们发现，预训练视觉编码器生成的视觉标记并不需要在解码器中执行所有重计算操作。通过设计一系列实验，我们提出了ProxyV方法，利用代理视觉标记来减轻原始视觉标记的计算负担。ProxyV在提高效率的同时不影响性能，甚至在适度提高效率的情况下还能显著提升性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14818",
            "title": "WebNovelBench: Placing LLM Novelists on the Web Novel Distribution",
            "url": "https://huggingface.co/papers/2505.14818",
            "abstract": "Robustly evaluating the long-form storytelling capabilities of Large Language Models (LLMs) remains a significant challenge, as existing benchmarks often lack the necessary scale, diversity, or objective measures. To address this, we introduce WebNovelBench, a novel benchmark specifically designed for evaluating long-form novel generation. WebNovelBench leverages a large-scale dataset of over 4,000 Chinese web novels, framing evaluation as a synopsis-to-story generation task. We propose a multi-faceted framework encompassing eight narrative quality dimensions, assessed automatically via an LLM-as-Judge approach. Scores are aggregated using Principal Component Analysis and mapped to a percentile rank against human-authored works. Our experiments demonstrate that WebNovelBench effectively differentiates between human-written masterpieces, popular web novels, and LLM-generated content. We provide a comprehensive analysis of 24 state-of-the-art LLMs, ranking their storytelling abilities and offering insights for future development. This benchmark provides a scalable, replicable, and data-driven methodology for assessing and advancing LLM-driven narrative generation.",
            "score": 2,
            "issue_id": 3900,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "54fde916bc0c7b6f",
            "authors": [
                "Leon Lin",
                "Jun Zheng",
                "Haidong Wang"
            ],
            "affiliations": [
                "Nanyang Technological University",
                "Sun Yat-Sen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14818.jpg",
            "data": {
                "categories": [
                    "#story_generation",
                    "#long_context",
                    "#dataset",
                    "#benchmark"
                ],
                "emoji": "📚",
                "ru": {
                    "title": "WebNovelBench: новый стандарт оценки генерации длинных текстов языковыми моделями",
                    "desc": "WebNovelBench - это новый бенчмарк для оценки способностей больших языковых моделей (LLM) генерировать длинные романы. Он использует набор данных из более чем 4000 китайских веб-новелл и оценивает качество генерации по восьми повествовательным измерениям. Оценка производится автоматически с помощью подхода LLM-as-Judge, а результаты агрегируются методом анализа главных компонент. Бенчмарк успешно различает шедевры, написанные людьми, популярные веб-новеллы и контент, сгенерированный LLM."
                },
                "en": {
                    "title": "WebNovelBench: A New Standard for Evaluating LLM Storytelling",
                    "desc": "This paper presents WebNovelBench, a new benchmark for evaluating the storytelling abilities of Large Language Models (LLMs) in generating long-form narratives. It utilizes a dataset of over 4,000 Chinese web novels and frames the evaluation as a task of generating stories from synopses. The framework assesses narrative quality across eight dimensions using an LLM-as-Judge approach, with results analyzed through Principal Component Analysis. The findings show that WebNovelBench can effectively distinguish between human-written and LLM-generated stories, providing valuable insights for improving LLM storytelling capabilities."
                },
                "zh": {
                    "title": "评估长篇小说生成的新基准",
                    "desc": "本论文介绍了WebNovelBench，这是一个专门用于评估大型语言模型（LLMs）长篇小说生成能力的新基准。该基准利用了超过4000部中文网络小说的大规模数据集，将评估框架设定为从摘要到故事生成的任务。我们提出了一个多维度的框架，涵盖八个叙事质量维度，通过LLM作为评判者的方式进行自动评估。实验结果表明，WebNovelBench能够有效区分人类创作的杰作、受欢迎的网络小说和LLM生成的内容。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14157",
            "title": "Prior Prompt Engineering for Reinforcement Fine-Tuning",
            "url": "https://huggingface.co/papers/2505.14157",
            "abstract": "This paper investigates prior prompt engineering (pPE) in the context of reinforcement fine-tuning (RFT), where language models (LMs) are incentivized to exhibit behaviors that maximize performance through reward signals. While existing RFT research has primarily focused on algorithms, reward shaping, and data curation, the design of the prior prompt--the instructions prepended to queries during training to elicit behaviors such as step-by-step reasoning--remains underexplored. We investigate whether different pPE approaches can guide LMs to internalize distinct behaviors after RFT. Inspired by inference-time prompt engineering (iPE), we translate five representative iPE strategies--reasoning, planning, code-based reasoning, knowledge recall, and null-example utilization--into corresponding pPE approaches. We experiment with Qwen2.5-7B using each of the pPE approaches, then evaluate performance on in-domain and out-of-domain benchmarks (e.g., AIME2024, HumanEval+, and GPQA-Diamond). Our results show that all pPE-trained models surpass their iPE-prompted counterparts, with the null-example pPE approach achieving the largest average performance gain and the highest improvement on AIME2024 and GPQA-Diamond, surpassing the commonly used reasoning approach. Furthermore, by adapting a behavior-classification framework, we demonstrate that different pPE strategies instill distinct behavioral styles in the resulting models. These findings position pPE as a powerful yet understudied axis for RFT.",
            "score": 2,
            "issue_id": 3898,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "bb33e698375153d7",
            "authors": [
                "Pittawat Taveekitworachai",
                "Potsawee Manakul",
                "Sarana Nutanong",
                "Kunat Pipatanakul"
            ],
            "affiliations": [
                "SCB 10X R&D, SCB 10X, SCBX Group, Thailand",
                "School of Information Science and Technology, Vidyasirimedhi Institute of Science and Technology, Thailand"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14157.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Предварительная инженерия промптов: новый рубеж в обучении языковых моделей с подкреплением",
                    "desc": "Это исследование рассматривает влияние предварительной инженерии промптов (pPE) на обучение с подкреплением языковых моделей. Авторы адаптировали пять стратегий инженерии промптов во время вывода для использования в pPE. Эксперименты показали, что все модели, обученные с pPE, превзошли свои аналоги с промптами во время вывода, причем подход с нулевым примером показал наибольший прирост производительности. Исследование также продемонстрировало, что различные стратегии pPE формируют у моделей различные поведенческие стили."
                },
                "en": {
                    "title": "Unlocking Performance: The Power of Prior Prompt Engineering in Language Models",
                    "desc": "This paper explores the concept of prior prompt engineering (pPE) in reinforcement fine-tuning (RFT) for language models (LMs). It highlights how the design of prompts, which guide the model's behavior during training, can significantly influence performance. The authors translate various inference-time prompt engineering strategies into prior prompt engineering methods and test them on a model called Qwen2.5-7B. The results indicate that models trained with pPE outperform those using traditional methods, particularly showing notable improvements in specific benchmarks."
                },
                "zh": {
                    "title": "先前提示工程：强化微调的新方向",
                    "desc": "本文研究了在强化微调（RFT）背景下的先前提示工程（pPE），旨在通过奖励信号引导语言模型（LM）表现出最大化性能的行为。尽管现有的RFT研究主要集中在算法、奖励塑造和数据整理上，但先前提示的设计仍然未被充分探讨。我们将五种代表性的推理时间提示工程（iPE）策略转化为相应的pPE方法，并在Qwen2.5-7B模型上进行实验。结果表明，所有pPE训练的模型在性能上均优于iPE提示的模型，尤其是null-example pPE方法在AIME2024和GPQA-Diamond上取得了显著的性能提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14336",
            "title": "Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors\n  Approach",
            "url": "https://huggingface.co/papers/2505.14336",
            "abstract": "Llama-SMoP, an efficient multimodal LLM incorporating Sparse Mixture of Projectors, enhances AVSR performance without increasing inference costs through modality-specific routers and experts.  \t\t\t\t\tAI-generated summary \t\t\t\t Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy environments by integrating visual cues. While recent advances integrate Large Language Models (LLMs) into AVSR, their high computational cost hinders deployment in resource-constrained settings. To address this, we propose Llama-SMoP, an efficient Multimodal LLM that employs a Sparse Mixture of Projectors (SMoP) module to scale model capacity without increasing inference costs. By incorporating sparsely-gated mixture-of-experts (MoE) projectors, Llama-SMoP enables the use of smaller LLMs while maintaining strong performance. We explore three SMoP configurations and show that Llama-SMoP DEDR (Disjoint-Experts, Disjoint-Routers), which uses modality-specific routers and experts, achieves superior performance on ASR, VSR, and AVSR tasks. Ablation studies confirm its effectiveness in expert activation, scalability, and noise robustness.",
            "score": 1,
            "issue_id": 3903,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "d5c843866931f713",
            "authors": [
                "Umberto Cappellazzo",
                "Minsu Kim",
                "Stavros Petridis",
                "Daniele Falavigna",
                "Alessio Brutti"
            ],
            "affiliations": [
                "Fondazione Bruno Kessler, Italy",
                "Imperial College London, UK",
                "Meta AI, UK"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14336.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#audio",
                    "#multimodal",
                    "#inference",
                    "#architecture",
                    "#low_resource"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "Эффективное мультимодальное распознавание речи с помощью разреженных экспертов",
                    "desc": "Llama-SMoP - это эффективная мультимодальная языковая модель, использующая разреженную смесь проекторов для улучшения аудиовизуального распознавания речи. Модель применяет модально-специфичные маршрутизаторы и экспертов для повышения производительности без увеличения вычислительных затрат. Llama-SMoP позволяет использовать меньшие языковые модели при сохранении высокой эффективности. Эксперименты показывают превосходство конфигурации DEDR с раздельными экспертами и маршрутизаторами для каждой модальности."
                },
                "en": {
                    "title": "Efficient AVSR with Llama-SMoP: Smart Scaling for Strong Performance",
                    "desc": "Llama-SMoP is a novel multimodal large language model designed to improve audio-visual speech recognition (AVSR) while keeping inference costs low. It utilizes a Sparse Mixture of Projectors (SMoP) to enhance model capacity without the need for larger models. By implementing modality-specific routers and experts, Llama-SMoP effectively manages resources and maintains high performance in challenging environments. The model's configurations, particularly the DEDR setup, demonstrate significant advancements in ASR, VSR, and AVSR tasks, proving its efficiency and robustness against noise."
                },
                "zh": {
                    "title": "高效多模态模型，提升语音识别性能",
                    "desc": "Llama-SMoP是一种高效的多模态大语言模型，采用稀疏混合投影器(SMoP)模块，旨在提高音视频语音识别(AVSR)的性能，同时不增加推理成本。该模型通过使用特定模态的路由器和专家，能够在资源受限的环境中有效运行。Llama-SMoP通过稀疏门控的专家混合(MoE)投影器，允许使用较小的语言模型，同时保持强大的性能。实验结果表明，Llama-SMoP在语音识别(ASR)、视觉识别(VSR)和音视频语音识别(AVSR)任务中表现优越，具有良好的可扩展性和抗噪声能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14101",
            "title": "MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation\n  of LLM Hallucinations",
            "url": "https://huggingface.co/papers/2505.14101",
            "abstract": "A multilingual, multihop benchmark using knowledge graphs for evaluating and mitigating hallucinations in large language models.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have inherent limitations of faithfulness and factuality, commonly referred to as hallucinations. Several benchmarks have been developed that provide a test bed for factuality evaluation within the context of English-centric datasets, while relying on supplementary informative context like web links or text passages but ignoring the available structured factual resources. To this end, Knowledge Graphs (KGs) have been identified as a useful aid for hallucination mitigation, as they provide a structured way to represent the facts about entities and their relations with minimal linguistic overhead. We bridge the lack of KG paths and multilinguality for factual language modeling within the existing hallucination evaluation benchmarks and propose a KG-based multilingual, multihop benchmark called MultiHal framed for generative text evaluation. As part of our data collection pipeline, we mined 140k KG-paths from open-domain KGs, from which we pruned noisy KG-paths, curating a high-quality subset of 25.9k. Our baseline evaluation shows an absolute scale increase by approximately 0.12 to 0.36 points for the semantic similarity score in KG-RAG over vanilla QA across multiple languages and multiple models, demonstrating the potential of KG integration. We anticipate MultiHal will foster future research towards several graph-based hallucination mitigation and fact-checking tasks.",
            "score": 1,
            "issue_id": 3901,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "a89e20d6ea8c5a4b",
            "authors": [
                "Ernests Lavrinovics",
                "Russa Biswas",
                "Katja Hose",
                "Johannes Bjerva"
            ],
            "affiliations": [
                "Department of Computer Science Aalborg University Copenhagen, Denmark",
                "Institute of Logic and Computation TU Wien Vienna, Austria"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14101.jpg",
            "data": {
                "categories": [
                    "#hallucinations",
                    "#benchmark",
                    "#dataset",
                    "#graphs",
                    "#multilingual",
                    "#data",
                    "#rag"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Графы знаний против галлюцинаций ИИ",
                    "desc": "Статья представляет новый многоязычный бенчмарк MultiHal для оценки и снижения галлюцинаций в больших языковых моделях (LLM). Бенчмарк основан на использовании графов знаний (KG) и предназначен для генеративной оценки текста. Авторы создали набор данных из 25,9 тысяч высококачественных KG-путей, извлеченных из открытых графов знаний. Базовая оценка показала увеличение семантического сходства на 0,12-0,36 пункта при использовании KG-RAG по сравнению с обычными вопросно-ответными системами для разных языков и моделей."
                },
                "en": {
                    "title": "Enhancing Language Models with Knowledge Graphs to Combat Hallucinations",
                    "desc": "This paper introduces a new benchmark called MultiHal, designed to evaluate and reduce hallucinations in large language models (LLMs) using knowledge graphs (KGs). Hallucinations refer to inaccuracies in the generated text, and existing benchmarks often focus on English datasets without utilizing structured factual resources. MultiHal incorporates multilingual and multihop capabilities by leveraging KGs, which represent facts and relationships in a structured format. The authors demonstrate that integrating KGs improves the semantic similarity scores in generative text evaluation across various languages and models, highlighting the benchmark's potential for advancing research in fact-checking and hallucination mitigation."
                },
                "zh": {
                    "title": "利用知识图谱减轻语言模型幻觉的多语言基准测试",
                    "desc": "这篇论文提出了一种新的多语言、多跳基准测试，旨在评估和减轻大型语言模型中的幻觉现象。研究表明，知识图谱（KG）可以有效地帮助解决语言模型在事实性和可信度方面的局限性。通过挖掘和筛选140,000条KG路径，最终构建了25,900条高质量的KG路径，以支持多语言的事实语言建模。实验结果显示，整合KG后，语义相似度评分在多个语言和模型中有显著提升，表明KG在减轻幻觉方面的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11454",
            "title": "HumaniBench: A Human-Centric Framework for Large Multimodal Models\n  Evaluation",
            "url": "https://huggingface.co/papers/2505.11454",
            "abstract": "HumaniBench evaluates state-of-the-art LMMs on seven human-centered AI principles using 32K real-world image-question pairs to ensure fairness, ethics, empathy, and inclusivity.  \t\t\t\t\tAI-generated summary \t\t\t\t Large multimodal models (LMMs) now excel on many vision language benchmarks, however, they still struggle with human centered criteria such as fairness, ethics, empathy, and inclusivity, key to aligning with human values. We introduce HumaniBench, a holistic benchmark of 32K real-world image question pairs, annotated via a scalable GPT4o assisted pipeline and exhaustively verified by domain experts. HumaniBench evaluates seven Human Centered AI (HCAI) principles: fairness, ethics, understanding, reasoning, language inclusivity, empathy, and robustness, across seven diverse tasks, including open and closed ended visual question answering (VQA), multilingual QA, visual grounding, empathetic captioning, and robustness tests. Benchmarking 15 state of the art LMMs (open and closed source) reveals that proprietary models generally lead, though robustness and visual grounding remain weak points. Some open-source models also struggle to balance accuracy with adherence to human-aligned principles. HumaniBench is the first benchmark purpose built around HCAI principles. It provides a rigorous testbed for diagnosing alignment gaps and guiding LMMs toward behavior that is both accurate and socially responsible. Dataset, annotation prompts, and evaluation code are available at: https://vectorinstitute.github.io/HumaniBench",
            "score": 1,
            "issue_id": 3900,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "3ca34ea5393b883b",
            "authors": [
                "Shaina Raza",
                "Aravind Narayanan",
                "Vahid Reza Khazaie",
                "Ashmal Vayani",
                "Mukund S. Chettiar",
                "Amandeep Singh",
                "Mubarak Shah",
                "Deval Pandya"
            ],
            "affiliations": [
                "University of Central Florida, Orlando, USA",
                "Vector Institute, Toronto, Canada"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11454.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#ethics",
                    "#multimodal",
                    "#dataset",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Оценка ИИ по человеческим меркам",
                    "desc": "HumaniBench - это новый комплексный бенчмарк для оценки больших мультимодальных моделей (LMM) по семи принципам человекоцентричного ИИ. Он включает 32 тысячи пар изображение-вопрос из реального мира, охватывающих задачи визуального ответа на вопросы, многоязычного QA, визуальной локализации и эмпатического описания изображений. Тестирование 15 современных LMM показало, что проприетарные модели в целом лидируют, хотя устойчивость и визуальная локализация остаются слабыми местами. HumaniBench предоставляет строгую тестовую среду для диагностики пробелов в выравнивании и направления LMM к поведению, которое является как точным, так и социально ответственным."
                },
                "en": {
                    "title": "HumaniBench: Aligning AI with Human Values",
                    "desc": "HumaniBench is a new benchmark designed to evaluate large multimodal models (LMMs) based on seven human-centered AI principles, including fairness and empathy. It uses a dataset of 32,000 real-world image-question pairs, which are annotated with the help of a scalable GPT-4 assisted pipeline and verified by experts. The benchmark assesses LMMs across various tasks such as visual question answering and empathetic captioning, revealing that while proprietary models often perform better, they still have weaknesses in robustness and visual grounding. HumaniBench aims to identify alignment gaps in LMMs and promote their development towards more socially responsible and human-aligned behaviors."
                },
                "zh": {
                    "title": "以人为本的人工智能评估基准",
                    "desc": "HumaniBench 是一个评估大型多模态模型（LMMs）的基准，专注于七个以人为本的人工智能原则，包括公平性、伦理、理解、推理、语言包容性、同理心和鲁棒性。该基准使用32,000个真实世界的图像-问题对，通过可扩展的GPT4o辅助管道进行注释，并由领域专家进行全面验证。尽管一些专有模型在性能上表现较好，但在鲁棒性和视觉定位方面仍存在不足，而一些开源模型在准确性与遵循人类对齐原则之间也难以平衡。HumaniBench 是首个专门围绕以人为本的人工智能原则构建的基准，为诊断对齐差距和引导LMMs朝向准确且社会责任感强的行为提供了严格的测试平台。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15141",
            "title": "BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms",
            "url": "https://huggingface.co/papers/2505.15141",
            "abstract": "Speculative decoding has emerged as a popular method to accelerate the inference of Large Language Models (LLMs) while retaining their superior text generation performance. Previous methods either adopt a fixed speculative decoding configuration regardless of the prefix tokens, or train draft models in an offline or online manner to align them with the context. This paper proposes a training-free online learning framework to adaptively choose the configuration of the hyperparameters for speculative decoding as text is being generated. We first formulate this hyperparameter selection problem as a Multi-Armed Bandit problem and provide a general speculative decoding framework BanditSpec. Furthermore, two bandit-based hyperparameter selection algorithms, UCBSpec and EXP3Spec, are designed and analyzed in terms of a novel quantity, the stopping time regret. We upper bound this regret under both stochastic and adversarial reward settings. By deriving an information-theoretic impossibility result, it is shown that the regret performance of UCBSpec is optimal up to universal constants. Finally, extensive empirical experiments with LLaMA3 and Qwen2 demonstrate that our algorithms are effective compared to existing methods, and the throughput is close to the oracle best hyperparameter in simulated real-life LLM serving scenarios with diverse input prompts.",
            "score": 0,
            "issue_id": 3905,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "32711fd3625843fd",
            "authors": [
                "Yunlong Hou",
                "Fengzhuo Zhang",
                "Cunxiao Du",
                "Xuan Zhang",
                "Jiachun Pan",
                "Tianyu Pang",
                "Chao Du",
                "Vincent Y. F. Tan",
                "Zhuoran Yang"
            ],
            "affiliations": [
                "National University of Singapore",
                "Sea AI Lab",
                "Singapore Management University",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15141.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#inference",
                    "#math"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Адаптивное спекулятивное декодирование: ускорение LLM с помощью многоруких бандитов",
                    "desc": "Эта статья представляет новый подход к улучшению спекулятивного декодирования для ускорения работы больших языковых моделей (LLM). Авторы предлагают адаптивный метод выбора гиперпараметров для спекулятивного декодирования, основанный на алгоритмах многоруких бандитов. Разработаны два алгоритма - UCBSpec и EXP3Spec, для которых проведен теоретический анализ и доказана оптимальность UCBSpec. Эксперименты на моделях LLaMA3 и Qwen2 показали эффективность предложенного подхода по сравнению с существующими методами."
                },
                "en": {
                    "title": "Dynamic Hyperparameter Selection for Efficient Text Generation",
                    "desc": "This paper introduces a new method called BanditSpec for improving the efficiency of Large Language Models (LLMs) during text generation. Instead of using a fixed approach for speculative decoding, it dynamically selects hyperparameters based on the context of the text being generated. The authors frame this selection process as a Multi-Armed Bandit problem and propose two algorithms, UCBSpec and EXP3Spec, to optimize performance. Their experiments show that these algorithms significantly enhance throughput and adapt well to various input prompts, achieving results close to the best possible configurations."
                },
                "zh": {
                    "title": "自适应超参数选择，加速大语言模型推理",
                    "desc": "本文提出了一种新的在线学习框架，用于自适应选择大语言模型（LLM）推理过程中的超参数配置，以加速推理速度。我们将超参数选择问题建模为多臂赌博机问题，并提出了BanditSpec框架。文中设计了两种基于赌博机的超参数选择算法UCBSpec和EXP3Spec，并分析了它们在随机和对抗奖励设置下的停止时间遗憾。通过实验证明，这些算法在处理多样化输入提示时，能够有效提高推理效率，接近最佳超参数的表现。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14990",
            "title": "Language Specific Knowledge: Do Models Know Better in X than in English?",
            "url": "https://huggingface.co/papers/2505.14990",
            "abstract": "Code-switching is a common phenomenon of alternating between different languages in the same utterance, thought, or conversation. We posit that humans code-switch because they feel more comfortable talking about certain topics and domains in one language than another. With the rise of knowledge-intensive language models, we ask ourselves the next, natural question: Could models hold more knowledge on some topics in some language X? More importantly, could we improve reasoning by changing the language that reasoning is performed in? We coin the term Language Specific Knowledge (LSK) to represent this phenomenon. As ethnic cultures tend to develop alongside different languages, we employ culture-specific datasets (that contain knowledge about cultural and social behavioral norms). We find that language models can perform better when using chain-of-thought reasoning in some languages other than English, sometimes even better in low-resource languages. Paired with previous works showing that semantic similarity does not equate to representational similarity, we hypothesize that culturally specific texts occur more abundantly in corresponding languages, enabling specific knowledge to occur only in specific \"expert\" languages. Motivated by our initial results, we design a simple methodology called LSKExtractor to benchmark the language-specific knowledge present in a language model and, then, exploit it during inference. We show our results on various models and datasets, showing an average relative improvement of 10% in accuracy. Our research contributes to the open-source development of language models that are inclusive and more aligned with the cultural and linguistic contexts in which they are deployed.",
            "score": 0,
            "issue_id": 3895,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "543b5a3ff8ff6a01",
            "authors": [
                "Ishika Agarwal",
                "Nimet Beyza Bozdag",
                "Dilek Hakkani-Tür"
            ],
            "affiliations": [
                "Department of Computer Science University of Illinois, Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14990.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#dataset",
                    "#alignment",
                    "#benchmark",
                    "#open_source",
                    "#inference",
                    "#low_resource",
                    "#multilingual"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "Раскрытие потенциала многоязычности в искусственном интеллекте",
                    "desc": "Исследователи изучают феномен языково-специфичных знаний (LSK) в языковых моделях. Они обнаружили, что модели могут лучше выполнять рассуждения на некоторых языках, отличных от английского, даже на малоресурсных языках. Авторы разработали методологию LSKExtractor для оценки и использования языково-специфичных знаний в языковых моделях. Эксперименты показали среднее относительное улучшение точности на 10% при применении этого подхода."
                },
                "en": {
                    "title": "Unlocking Knowledge: Language Matters in Machine Learning!",
                    "desc": "This paper explores the concept of Language Specific Knowledge (LSK), which suggests that language models may possess more knowledge about certain topics when reasoning in specific languages. The authors argue that humans often code-switch between languages based on comfort with cultural contexts, and this can be leveraged in machine learning. They introduce a methodology called LSKExtractor to evaluate and utilize this language-specific knowledge during model inference. Their findings indicate that language models can achieve improved reasoning accuracy, particularly in low-resource languages, by aligning with culturally relevant datasets."
                },
                "zh": {
                    "title": "语言特定知识提升模型推理能力",
                    "desc": "本文探讨了代码切换现象，即在同一对话中交替使用不同语言的情况。我们提出人们在某些话题上更倾向于使用特定语言，因为他们在这些语言中感到更舒适。研究表明，语言模型在某些语言中使用链式推理时表现更好，尤其是在低资源语言中。我们设计了一种名为LSKExtractor的方法来评估语言模型中的语言特定知识，并在推理过程中加以利用，最终实现了平均10%的准确率提升。"
                }
            }
        }
    ],
    "link_prev": "2025-05-21.html",
    "link_next": "2025-05-23.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "21.05",
        "en": "05/21",
        "zh": "5月21日"
    },
    "short_date_next": {
        "ru": "23.05",
        "en": "05/23",
        "zh": "5月23日"
    },
    "categories": {
        "#dataset": 14,
        "#data": 6,
        "#benchmark": 19,
        "#agents": 6,
        "#cv": 0,
        "#rl": 13,
        "#rlhf": 2,
        "#rag": 4,
        "#plp": 0,
        "#inference": 6,
        "#3d": 1,
        "#audio": 2,
        "#video": 2,
        "#multimodal": 11,
        "#math": 6,
        "#multilingual": 2,
        "#architecture": 8,
        "#healthcare": 0,
        "#training": 19,
        "#robotics": 1,
        "#agi": 0,
        "#games": 3,
        "#interpretability": 2,
        "#reasoning": 17,
        "#transfer_learning": 3,
        "#graphs": 1,
        "#ethics": 3,
        "#security": 2,
        "#optimization": 16,
        "#survey": 1,
        "#diffusion": 6,
        "#alignment": 3,
        "#story_generation": 1,
        "#hallucinations": 3,
        "#long_context": 2,
        "#synthetic": 3,
        "#machine_translation": 0,
        "#leakage": 1,
        "#open_source": 8,
        "#small_models": 1,
        "#science": 2,
        "#low_resource": 2,
        "#safety": 1
    },
    "zh": {
        "text": "这篇文章讨论了网页导航的自动化任务。过去的研究使用多模态大语言模型（MLLM）作为奖励模型，但这对实际应用有限制。作者提出了第一个过程奖励模型（PRM），称为Web-Shepherd，用于逐步评估网页导航路径。他们创建了一个大规模数据集和评估基准，并在实验中证明了Web-Shepherd的有效性和成本效益。所有模型、数据集和代码都公开可用。",
        "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
        "pinyin": "这篇文章讨论了网页导航的自动化任务。过去的研究使用多模态大语言模型（MLLM）作为奖励模型，但这对实际应用有限制。作者提出了第一个过程奖励模型（PRM），称为Web-Shepherd，用于逐步评估网页导航路径。他们创建了一个大规模数据集和评估基准，并在实验中证明了Web-Shepherd的有效性和成本效益。所有模型、数据集和代码都公开可用。\n\nZhè piān wénzhāng tǎolùn le wǎngyè dǎoháng de zìdònghuà rènwù. Guòqù de yánjiū shǐyòng duō móshì dà yǔyán móxíng (MLLM) zuòwéi jiǎnglì móxíng, dàn zhè duì shíjì yìngyòng yǒu xiànzhì. Zuòzhě tíchū le dì-yīgè guòchéng jiǎnglì móxíng (PRM), chēngwéi Web-Shepherd, yòngyú zhúbù píngjià wǎngyè dǎoháng lùjìng. Tāmen chuàngjiàn le yīgè dà guīmó shùjùjí hé píngjià jīzhǔn, bìng zài shìyàn zhōng zhèngmíng le Web-Shepherd de yǒuxiàoxìng hé chéngběn xiàoyì. Suǒyǒu móxíng, shùjùjí hé dàimǎ dōu gōngkāi kěyòng.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"网页导航\", \"pinyin\": \"wǎng yè dǎo háng\", \"trans\": \"web navigation\"},\n    {\"word\": \"自动化\", \"pinyin\": \"zì dòng huà\", \"trans\": \"automation\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wu\", \"trans\": \"task\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"多模态\", \"pinyin\": \"duō mó tài\", \"trans\": \"multimodal\"},\n    {\"word\": \"大语言模型\", \"pinyin\": \"dà yǔ yán mó xíng\", \"trans\": \"large language model\"},\n    {\"word\": \"奖励模型\", \"pinyin\": \"jiǎng lì mó xíng\", \"trans\": \"reward model\"},\n    {\"word\": \"限制\", \"pinyin\": \"xiàn zhì\", \"trans\": \"limit\"},\n    {\"word\": \"提出\", \"pinyin\": \"tí chū\", \"trans\": \"propose\"},\n    {\"word\": \"过程奖励模型\", \"pinyin\": \"guò chéng jiǎng lì mó xíng\", \"trans\": \"process reward model\"},\n    {\"word\": \"逐步\", \"pinyin\": \"zhuó bù\", \"trans\": \"step-by-step\"},\n    {\"word\": \"评估\", \"pinyin\": \"píng gū\", \"trans\": \"evaluate\"},\n    {\"word\": \"路径\", \"pinyin\": \"lù jìng\", \"trans\": \"path\"},\n    {\"word\": \"创建\", \"pinyin\": \"chuàng jiàn\", \"trans\": \"create\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shù jù jí\", \"trans\": \"dataset\"},\n    {\"word\": \"评估基准\", \"pinyin\": \"píng gū jī zhǔn\", \"trans\": \"evaluation benchmark\"},\n    {\"word\": \"实验\", \"pinyin\": \"shí yàn\", \"trans\": \"experiment\"},\n    {\"word\": \"证明\", \"pinyin\": \"zhèng míng\", \"trans\": \"prove\"},\n    {\"word\": \"有效性\", \"pinyin\": \"yǒu xiào xìng\", \"trans\": \"effectiveness\"},\n    {\"word\": \"成本效益\", \"pinyin\": \"chéng běn xiào yì\", \"trans\": \"cost-effectiveness\"},\n    {\"word\": \"公开可用\", \"pinyin\": \"gōng kāi kě yòng\", \"trans\": \"publicly available\"}\n]",
        "trans": "This article discusses the automation of web page navigation tasks. Previous research has used multimodal large language models (MLLMs) as reward models, but this has limitations for practical applications. The authors propose the first process reward model (PRM), called Web-Shepherd, for step-by-step evaluation of web page navigation paths. They created a large-scale dataset and evaluation benchmark, and demonstrated the effectiveness and cost-efficiency of Web-Shepherd in experiments. All models, datasets, and code are publicly available.",
        "update_ts": "2025-05-22 09:12"
    }
}