{
    "date": {
        "ru": "10 ÑĞ½Ğ²Ğ°Ñ€Ñ",
        "en": "January 10",
        "zh": "1æœˆ10æ—¥"
    },
    "time_utc": "2025-01-10 04:12",
    "weekday": 4,
    "issue_id": 1596,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.05441",
            "title": "The GAN is dead; long live the GAN! A Modern GAN Baseline",
            "url": "https://huggingface.co/papers/2501.05441",
            "abstract": "There is a widely-spread claim that GANs are difficult to train, and GAN architectures in the literature are littered with empirical tricks. We provide evidence against this claim and build a modern GAN baseline in a more principled manner. First, we derive a well-behaved regularized relativistic GAN loss that addresses issues of mode dropping and non-convergence that were previously tackled via a bag of ad-hoc tricks. We analyze our loss mathematically and prove that it admits local convergence guarantees, unlike most existing relativistic losses. Second, our new loss allows us to discard all ad-hoc tricks and replace outdated backbones used in common GANs with modern architectures. Using StyleGAN2 as an example, we present a roadmap of simplification and modernization that results in a new minimalist baseline -- R3GAN. Despite being simple, our approach surpasses StyleGAN2 on FFHQ, ImageNet, CIFAR, and Stacked MNIST datasets, and compares favorably against state-of-the-art GANs and diffusion models.",
            "score": 4,
            "issue_id": 1596,
            "pub_date": "2025-01-09",
            "pub_date_card": {
                "ru": "9 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 9",
                "zh": "1æœˆ9æ—¥"
            },
            "hash": "eb1cd90c4d5cb0ef",
            "authors": [
                "Yiwen Huang",
                "Aaron Gokaslan",
                "Volodymyr Kuleshov",
                "James Tompkin"
            ],
            "affiliations": [
                "Brown University",
                "Cornell University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.05441.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#diffusion",
                    "#optimization",
                    "#cv"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "Ğ£Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¼Ğ¾Ğ´ĞµÑ€Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ GAN: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¾Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ³Ğ°ÑÑ‚ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ğ¾Ğµ Ğ¼Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾-ÑĞ¾ÑÑ‚ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹ (GAN). ĞĞ½Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ»ÑÑ‚Ğ¸Ğ²Ğ¸ÑÑ‚ÑĞºĞ¸Ğ¹ GAN-Ğ»Ğ¾ÑÑ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ¼Ğ¾Ğ´ Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ñ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¸Ñ… Ğ»Ğ¾ÑÑ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ, Ğ² Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ñ€ĞµĞ»ÑÑ‚Ğ¸Ğ²Ğ¸ÑÑ‚ÑĞºĞ¸Ñ… Ğ»Ğ¾ÑÑĞ¾Ğ². ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ¾Ğ½Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½ÑƒÑ Ğ±Ğ°Ğ·Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ R3GAN, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ StyleGAN2 Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ GAN Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "Simplifying GAN Training with R3GAN: A New Era of Efficiency",
                    "desc": "This paper challenges the common belief that Generative Adversarial Networks (GANs) are inherently difficult to train. It introduces a new GAN loss function called the regularized relativistic GAN loss, which effectively addresses issues like mode dropping and non-convergence without relying on numerous empirical tricks. The authors provide mathematical analysis showing that their loss function guarantees local convergence, which is a significant improvement over existing methods. By applying this new loss to modern architectures like StyleGAN2, they create a simplified and efficient GAN model named R3GAN, which outperforms previous models on several benchmark datasets."
                },
                "zh": {
                    "title": "ç®€åŒ–GANè®­ç»ƒï¼Œè¶…è¶Šä¼ ç»Ÿæ¶æ„",
                    "desc": "è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰è®­ç»ƒçš„éš¾ç‚¹ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥ç®€åŒ–è¿™ä¸€è¿‡ç¨‹ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ­£åˆ™åŒ–çš„ç›¸å¯¹GANæŸå¤±å‡½æ•°ï¼Œè§£å†³äº†æ¨¡å¼ä¸¢å¤±å’Œéæ”¶æ•›çš„é—®é¢˜ã€‚é€šè¿‡æ•°å­¦åˆ†æï¼Œè¯æ˜äº†è¿™ç§æŸå¤±å‡½æ•°å…·æœ‰å±€éƒ¨æ”¶æ•›çš„ä¿è¯ï¼Œä¼˜äºç°æœ‰çš„ç›¸å¯¹æŸå¤±å‡½æ•°ã€‚æœ€ç»ˆï¼Œä½œè€…å±•ç¤ºäº†ä¸€ä¸ªæ–°çš„ç®€çº¦åŸºçº¿R3GANï¼Œå…¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°è¶…è¿‡äº†StyleGAN2ï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„GANå’Œæ‰©æ•£æ¨¡å‹ç›¸åª²ç¾ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.05453",
            "title": "An Empirical Study of Autoregressive Pre-training from Videos",
            "url": "https://huggingface.co/papers/2501.05453",
            "abstract": "We empirically study autoregressive pre-training from videos. To perform our study, we construct a series of autoregressive video models, called Toto. We treat videos as sequences of visual tokens and train transformer models to autoregressively predict future tokens. Our models are pre-trained on a diverse dataset of videos and images comprising over 1 trillion visual tokens. We explore different architectural, training, and inference design choices. We evaluate the learned visual representations on a range of downstream tasks including image recognition, video classification, object tracking, and robotics. Our results demonstrate that, despite minimal inductive biases, autoregressive pre-training leads to competitive performance across all benchmarks. Finally, we find that scaling our video models results in similar scaling curves to those seen in language models, albeit with a different rate. More details at https://brjathu.github.io/toto/",
            "score": 3,
            "issue_id": 1596,
            "pub_date": "2025-01-09",
            "pub_date_card": {
                "ru": "9 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 9",
                "zh": "1æœˆ9æ—¥"
            },
            "hash": "3846ea8507d046be",
            "authors": [
                "Jathushan Rajasegaran",
                "Ilija Radosavovic",
                "Rahul Ravishankar",
                "Yossi Gandelsman",
                "Christoph Feichtenhofer",
                "Jitendra Malik"
            ],
            "affiliations": [
                "Meta FAIR",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.05453.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#architecture",
                    "#robotics",
                    "#video",
                    "#cv"
                ],
                "emoji": "ğŸ¬",
                "ru": {
                    "title": "ĞĞ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾: Ğ¿ÑƒÑ‚ÑŒ Ğº ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ¼Ñƒ Ğ·Ñ€ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Toto. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ Ğ²Ğ¸Ğ´ĞµĞ¾ ĞºĞ°Ğº Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ÑÑ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ Ñ‚Ñ€Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ° Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ². Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ°ĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Unlocking Video Understanding with Autoregressive Models",
                    "desc": "This paper investigates the use of autoregressive pre-training for video data through a series of models named Toto. The authors treat videos as sequences of visual tokens and employ transformer architectures to predict future tokens in these sequences. They pre-train their models on a massive dataset containing over 1 trillion visual tokens, exploring various design choices in architecture and training. The results show that these autoregressive models achieve strong performance on tasks like image recognition and video classification, indicating that scaling video models can yield similar benefits as seen in language models."
                },
                "zh": {
                    "title": "è‡ªå›å½’é¢„è®­ç»ƒï¼šè§†é¢‘æ¨¡å‹çš„æ–°çªç ´",
                    "desc": "æœ¬æ–‡ç ”ç©¶äº†è§†é¢‘çš„è‡ªå›å½’é¢„è®­ç»ƒã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ç³»åˆ—åä¸ºTotoçš„è‡ªå›å½’è§†é¢‘æ¨¡å‹ï¼Œå°†è§†é¢‘è§†ä¸ºè§†è§‰æ ‡è®°çš„åºåˆ—ï¼Œå¹¶è®­ç»ƒå˜æ¢å™¨æ¨¡å‹ä»¥è‡ªå›å½’æ–¹å¼é¢„æµ‹æœªæ¥çš„æ ‡è®°ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸€ä¸ªåŒ…å«è¶…è¿‡1ä¸‡äº¿è§†è§‰æ ‡è®°çš„å¤šæ ·åŒ–è§†é¢‘å’Œå›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šè¯„ä¼°å­¦ä¹ åˆ°çš„è§†è§‰è¡¨ç¤ºã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡è¯±å¯¼åå·®è¾ƒå°ï¼Œè‡ªå›å½’é¢„è®­ç»ƒåœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºç«äº‰åŠ›çš„æ€§èƒ½ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-01-09.html",
    "link_next": "2025-01-13.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "09.01",
        "en": "01/09",
        "zh": "1æœˆ9æ—¥"
    },
    "short_date_next": {
        "ru": "13.01",
        "en": "01/13",
        "zh": "1æœˆ13æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 2,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 1,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº† rStar-Mathï¼Œå±•ç¤ºäº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å¯ä»¥é€šè¿‡è’™ç‰¹å¡ç½—æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œâ€œæ·±åº¦æ€è€ƒâ€ï¼Œä»è€Œåª²ç¾æˆ–è¶…è¶Š OpenAI o1 çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚rStar-Math é€šè¿‡ä¸‰é¡¹åˆ›æ–°è®­ç»ƒä¸¤ä¸ª SLMsï¼šä»£ç å¢å¼ºçš„æ€ç»´é“¾æ•°æ®åˆæˆæ–¹æ³•ã€æ›´æœ‰æ•ˆçš„è¿‡ç¨‹åå¥½æ¨¡å‹ï¼ˆPPMï¼‰è®­ç»ƒæ–¹æ³•å’Œè‡ªæˆ‘è¿›åŒ–é…æ–¹ã€‚ç»è¿‡å››è½®è‡ªæˆ‘è¿›åŒ–ï¼ŒrStar-Math å°† SLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›æå‡åˆ°æœ€å…ˆè¿›çš„æ°´å¹³ã€‚",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº† rStar-Mathï¼Œå±•ç¤ºäº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å¯ä»¥é€šè¿‡è’™ç‰¹å¡ç½—æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œâ€œæ·±åº¦æ€è€ƒâ€ï¼Œä»è€Œåª²ç¾æˆ–è¶…è¶Š OpenAI o1 çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚rStar-Math é€šè¿‡ä¸‰é¡¹åˆ›æ–°è®­ç»ƒä¸¤ä¸ª SLMsï¼šä»£ç å¢å¼ºçš„æ€ç»´é“¾æ•°æ®åˆæˆæ–¹æ³•ã€æ›´æœ‰æ•ˆçš„è¿‡ç¨‹åå¥½æ¨¡å‹ï¼ˆPPMï¼‰è®­ç»ƒæ–¹æ³•å’Œè‡ªæˆ‘è¿›åŒ–é…æ–¹ã€‚ç»è¿‡å››è½®è‡ªæˆ‘è¿›åŒ–ï¼ŒrStar-Math å°† SLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›æå‡åˆ°æœ€å…ˆè¿›çš„æ°´å¹³ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le rStar-Math, zhÇnshÃ¬ le xiÇoxÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng (SLMs) kÄ›yÇ tÅngguÃ² mÃ©ngtÃ¨kÇluÃ³ shÃ¹ sÅusuÇ’ (MCTS) jÃ¬nxÃ­ng â€œshÄ“ndÃ¹ sÄ«kÇoâ€, cÃ³ng'Ã©r qÃ­bÇ huÃ² chÄoyuÃ¨ OpenAI o1 de shÃ¹xuÃ© tuÄ«lÇ nÃ©nglÃ¬. rStar-Math tÅngguÃ² sÄn xiÃ ng chuÃ ngxÄ«n xÃ¹nliÃ n liÇng gÃ¨ SLMs: dÃ imÇ zÄ“ngqiÃ¡ng de sÄ«wÃ©i liÃ n shÃ¹jÃ¹ hÃ©chÃ©ng fÄngfÇ, gÃ¨ng yÇ’uxiÃ o de guÃ²chÃ©ng qiÄnhuÃ² mÃ³xÃ­ng (PPM) xÃ¹nliÃ n fÄngfÇ hÃ© zÃ¬wÇ’ jÃ¬nhuÃ  pÃ¨ifÃ¡ng. JÄ«ngguÃ² sÃ¬ lÃºn zÃ¬wÇ’ jÃ¬nhuÃ , rStar-Math jiÄng SLMs de shÃ¹xuÃ© tuÄ«lÇ nÃ©nglÃ¬ tÃ­shÄ“ng dÃ o zuÃ¬ xiÄnjÃ¬n de shuÇpÃ­ng.",
        "vocab": "[\n    {\"word\": \"å±•ç¤º\", \"pinyin\": \"zhÇnshÃ¬\", \"trans\": \"display, show\"},\n    {\"word\": \"å°å‹\", \"pinyin\": \"xiÇoxÃ­ng\", \"trans\": \"small, mini\"},\n    {\"word\": \"è¯­è¨€æ¨¡å‹\", \"pinyin\": \"yÇ”yÃ¡n mÃ³xÃ­ng\", \"trans\": \"language model\"},\n    {\"word\": \"è’™ç‰¹å¡ç½—æ ‘æœç´¢\", \"pinyin\": \"MÃ©ngtÃ¨kÇluÃ³ shÃ¹ sÅusuÇ’\", \"trans\": \"Monte Carlo Tree Search\"},\n    {\"word\": \"æ·±åº¦æ€è€ƒ\", \"pinyin\": \"shÄ“ndÃ¹ sÄ«kÇo\", \"trans\": \"deep thinking\"},\n    {\"word\": \"åª²ç¾\", \"pinyin\": \"pÃ¬mÄ›i\", \"trans\": \"rival, match\"},\n    {\"word\": \"è¶…è¶Š\", \"pinyin\": \"chÄoyuÃ¨\", \"trans\": \"surpass, exceed\"},\n    {\"word\": \"æ¨ç†\", \"pinyin\": \"tuÄ«lÇ\", \"trans\": \"reasoning\"},\n    {\"word\": \"èƒ½åŠ›\", \"pinyin\": \"nÃ©nglÃ¬\", \"trans\": \"ability, capability\"},\n    {\"word\": \"åˆ›æ–°\", \"pinyin\": \"chuÃ ngxÄ«n\", \"trans\": \"innovation\"},\n    {\"word\": \"è®­ç»ƒ\", \"pinyin\": \"xÃ¹nliÃ n\", \"trans\": \"train, training\"},\n    {\"word\": \"ä»£ç \", \"pinyin\": \"dÃ imÇ\", \"trans\": \"code\"},\n    {\"word\": \"å¢å¼º\", \"pinyin\": \"zÄ“ngqiÃ¡ng\", \"trans\": \"enhance, strengthen\"},\n    {\"word\": \"æ€ç»´é“¾\", \"pinyin\": \"sÄ«wÃ©i liÃ¡n\", \"trans\": \"chain of thought\"},\n    {\"word\": \"æ•°æ®åˆæˆ\", \"pinyin\": \"shÃ¹jÃ¹ hÃ©chÃ©ng\", \"trans\": \"data synthesis\"},\n    {\"word\": \"æ–¹æ³•\", \"pinyin\": \"fÄngfÇ\", \"trans\": \"method\"},\n    {\"word\": \"è¿‡ç¨‹\", \"pinyin\": \"guÃ²chÃ©ng\", \"trans\": \"process\"},\n    {\"word\": \"åå¥½\", \"pinyin\": \"piÄnhÃ o\", \"trans\": \"preference\"},\n    {\"word\": \"æ¨¡å‹\", \"pinyin\": \"mÃ³xÃ­ng\", \"trans\": \"model\"},\n    {\"word\": \"è‡ªæˆ‘è¿›åŒ–\", \"pinyin\": \"zÃ¬wÇ’ jÃ¬nhuÃ \", \"trans\": \"self-evolution\"},\n    {\"word\": \"é…æ–¹\", \"pinyin\": \"pÃ¨ifÄng\", \"trans\": \"formula, recipe\"},\n    {\"word\": \"å››è½®\", \"pinyin\": \"sÃ¬ lÃºn\", \"trans\": \"four rounds\"},\n    {\"word\": \"æœ€å…ˆè¿›\", \"pinyin\": \"zuÃ¬ xiÄnjÃ¬n\", \"trans\": \"most advanced\"}\n]",
        "trans": "This article introduces rStar-Math, demonstrating that Small Language Models (SLMs) can engage in \"deep thinking\" through Monte Carlo Tree Search (MCTS), thereby matching or surpassing the mathematical reasoning capabilities of OpenAI o1. rStar-Math achieves this through three innovative approaches to train two SLMs: a code-enhanced chain-of-thought data synthesis method, a more effective Process Preference Model (PPM) training method, and a self-evolutionary recipe. After four rounds of self-evolution, rStar-Math elevates the mathematical reasoning abilities of SLMs to the most advanced level.",
        "update_ts": "2025-01-09 09:11"
    }
}