{
    "date": {
        "ru": "20 –º–∞—è",
        "en": "May 20",
        "zh": "5Êúà20Êó•"
    },
    "time_utc": "2025-05-20 03:38",
    "weekday": 1,
    "issue_id": 3846,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.12081",
            "title": "VisionReasoner: Unified Visual Perception and Reasoning via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.12081",
            "abstract": "Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).",
            "score": 11,
            "issue_id": 3845,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 –º–∞—è",
                "en": "May 17",
                "zh": "5Êúà17Êó•"
            },
            "hash": "9b7953f88ae7653d",
            "authors": [
                "Yuqi Liu",
                "Tianyuan Qu",
                "Zhisheng Zhong",
                "Bohao Peng",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "affiliations": [
                "CUHK",
                "HKUST",
                "SmartMore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12081.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è",
                    "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω VisionReasoner - —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é. VisionReasoner –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ø–µ—Ä–µ–¥ –≤—ã–¥–∞—á–µ–π –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ VisionReasoner –Ω–∞–¥ Qwen2.5VL –≤ –∑–∞–¥–∞—á–∞—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—ä–µ–∫—Ç–æ–≤."
                },
                "en": {
                    "title": "VisionReasoner: Unifying Visual Perception with Advanced Reasoning",
                    "desc": "This paper presents VisionReasoner, a unified framework designed to enhance visual perception tasks through advanced reasoning capabilities. It employs innovative multi-object cognitive learning strategies and reformulates tasks systematically to improve its performance across various visual challenges. The model processes visual inputs in a structured manner, allowing it to effectively respond to user queries. Evaluation results demonstrate that VisionReasoner significantly outperforms existing models in detection, segmentation, and counting tasks, showcasing its effectiveness as a comprehensive solution for visual perception."
                },
                "zh": {
                    "title": "Áªü‰∏ÄËßÜËßâÊÑüÁü•ÁöÑÊé®ÁêÜËÉΩÂäõ",
                    "desc": "Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÂêç‰∏∫VisionReasonerÁöÑÁªü‰∏ÄÊ°ÜÊû∂ÔºåËÉΩÂ§üÂú®ÂÖ±‰∫´Ê®°Âûã‰∏≠Â§ÑÁêÜÂ§öÁßçËßÜËßâÊÑüÁü•‰ªªÂä°„ÄÇÈÄöËøáËÆæËÆ°Êñ∞È¢ñÁöÑÂ§öÂØπË±°ËÆ§Áü•Â≠¶‰π†Á≠ñÁï•ÂíåÁ≥ªÁªüÁöÑ‰ªªÂä°ÈáçÊûÑÔºåVisionReasonerÂ¢ûÂº∫‰∫ÜÂÖ∂Êé®ÁêÜËÉΩÂäõÔºå‰ª•ÂàÜÊûêËßÜËßâËæìÂÖ•Âπ∂Ëß£ÂÜ≥Â§öÊ†∑ÁöÑÊÑüÁü•‰ªªÂä°„ÄÇËØ•Ê®°ÂûãÂú®ÁîüÊàêÊâÄÈúÄËæìÂá∫‰πãÂâçÔºå‰ºöÂÖàËøõË°åÁªìÊûÑÂåñÁöÑÊé®ÁêÜËøáÁ®ãÔºå‰ª•ÂìçÂ∫îÁî®Êà∑Êü•ËØ¢„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåVisionReasonerÂú®Ê£ÄÊµã„ÄÅÂàÜÂâ≤ÂíåËÆ°Êï∞Á≠â‰∏â‰∏™ÂÖ≥ÈîÆÈ¢ÜÂüüÁöÑÂçÅ‰∏™‰ªªÂä°‰∏äË°®Áé∞‰ºòÂºÇÔºåË∂ÖË∂ä‰∫ÜQwen2.5VL„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13417",
            "title": "AdaptThink: Reasoning Models Can Learn When to Think",
            "url": "https://huggingface.co/papers/2505.13417",
            "abstract": "Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.",
            "score": 9,
            "issue_id": 3845,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 –º–∞—è",
                "en": "May 19",
                "zh": "5Êúà19Êó•"
            },
            "hash": "edd33223d8d833a7",
            "authors": [
                "Jiajie Zhang",
                "Nianyi Lin",
                "Lei Hou",
                "Ling Feng",
                "Juanzi Li"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13417.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#inference",
                    "#training",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –ò–ò",
                    "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º AdaptThink, –∫–æ—Ç–æ—Ä—ã–π —É—á–∏—Ç –º–æ–¥–µ–ª–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –º—ã—à–ª–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏. –ê–ª–≥–æ—Ä–∏—Ç–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—É—é —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∫–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏, —á—Ç–æ AdaptThink –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã –ø—Ä–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –ø–æ–≤—ã—à–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π. –ù–∞ —Ç—Ä–µ—Ö –Ω–∞–±–æ—Ä–∞—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º —Å–æ–∫—Ä–∞—Ç–∏–ª —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ DeepSeek-R1-Distill-Qwen-1.5B –Ω–∞ 53% –∏ –ø–æ–≤—ã—Å–∏–ª –µ–µ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ 2.4%."
                },
                "en": {
                    "title": "Optimize Reasoning with Adaptive Thinking Modes!",
                    "desc": "This paper introduces AdaptThink, a reinforcement learning algorithm designed to optimize reasoning models by allowing them to choose between two thinking modes: NoThinking and traditional thinking. NoThinking enables models to skip lengthy reasoning processes for simpler tasks, improving efficiency without sacrificing performance. AdaptThink employs a constrained optimization objective to encourage the use of NoThinking while maintaining overall accuracy, and it uses importance sampling to balance training between both modes. The results show that AdaptThink significantly reduces inference costs and enhances performance on math tasks, demonstrating the effectiveness of adaptive thinking-mode selection."
                },
                "zh": {
                    "title": "Ëá™ÈÄÇÂ∫îÊÄùËÄÉÊ®°ÂºèÈÄâÊã©ÔºåÊèêÂçáÊé®ÁêÜÊïàÁéá‰∏éË¥®Èáè",
                    "desc": "ÊúÄËøëÔºåÂ§ßÂûãÊé®ÁêÜÊ®°ÂûãÂú®ÂêÑÁßç‰ªªÂä°‰∏äË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÖ∂ÂÜóÈïøÁöÑÊÄùËÄÉËøáÁ®ãÊòæËëóÂ¢ûÂä†‰∫ÜÊé®ÁêÜÂºÄÈîÄÔºåÂØºËá¥ÊïàÁéáÊàê‰∏∫Áì∂È¢à„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫NoThinkingÁöÑÊñπÊ≥ïÔºåÈºìÂä±Êé®ÁêÜÊ®°ÂûãË∑≥ËøáÊÄùËÄÉÔºåÁõ¥Êé•ÁîüÊàêÊúÄÁªàËß£ÂÜ≥ÊñπÊ°àÔºåÈÄÇÁî®‰∫éÁõ∏ÂØπÁÆÄÂçïÁöÑ‰ªªÂä°„ÄÇÂü∫‰∫éÊ≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜAdaptThinkÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºåÊó®Âú®Ê†πÊçÆÈóÆÈ¢òÈöæÂ∫¶Ëá™ÈÄÇÂ∫îÈÄâÊã©ÊúÄ‰Ω≥ÊÄùËÄÉÊ®°Âºè„ÄÇÂÆûÈ™åË°®ÊòéÔºåAdaptThinkÊòæËëóÈôç‰Ωé‰∫ÜÊé®ÁêÜÊàêÊú¨ÔºåÂêåÊó∂ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11896",
            "title": "AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.11896",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.",
            "score": 7,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 –º–∞—è",
                "en": "May 17",
                "zh": "5Êúà17Êó•"
            },
            "hash": "bdc79864df7cbd51",
            "authors": [
                "Chenwei Lou",
                "Zewei Sun",
                "Xinnian Liang",
                "Meng Qu",
                "Wei Shen",
                "Wenqi Wang",
                "Yuntao Li",
                "Qingping Yang",
                "Shuangzhi Wu"
            ],
            "affiliations": [
                "ByteDance Seed"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11896.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl",
                    "#training"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "AdaCoT: –£–º–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π",
                    "desc": "AdaCoT - —ç—Ç–æ –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –∫—Ä—É–ø–Ω—ã–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º (LLM) –∞–¥–∞–ø—Ç–∏–≤–Ω–æ —Ä–µ—à–∞—Ç—å, –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ —Ü–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (Chain-of-Thought, CoT). –ò—Å–ø–æ–ª—å–∑—É—è –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ Proximal Policy Optimization (PPO), AdaCoT –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –º–æ–¥–µ–ª–∏ –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–∞—Ç—Ä–∞—Ç–∞–º–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º CoT. –ö–ª—é—á–µ–≤—ã–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –≤–∫–ª–∞–¥–æ–º —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ç–æ–¥ Selective Loss Masking (SLM), –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—é—â–∏–π –∫–æ–ª–ª–∞–ø—Å –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º—è –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ AdaCoT –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CoT –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–µ —Ç—Ä–µ–±—É—é—â–∏—Ö —Å–ª–æ–∂–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º –≤—ã—Å–æ–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö."
                },
                "en": {
                    "title": "Adaptive Reasoning for Efficient Language Models",
                    "desc": "This paper presents AdaCoT, a new framework that improves the efficiency of Large Language Models (LLMs) by adaptively deciding when to use Chain-of-Thought (CoT) prompting. Traditional CoT prompting can be computationally expensive, especially for simpler queries, but AdaCoT optimizes this by framing the decision to use CoT as a Pareto optimization problem. The authors employ reinforcement learning, specifically Proximal Policy Optimization (PPO), to dynamically adjust when CoT is triggered based on the complexity of the input. Their approach includes a technique called Selective Loss Masking (SLM) to ensure stable training, resulting in significant reductions in CoT usage while maintaining high performance on complex tasks."
                },
                "zh": {
                    "title": "Ëá™ÈÄÇÂ∫îÈìæÂºèÊé®ÁêÜÔºåÊèêÂçáÊïàÁéá‰∏éÊÄßËÉΩ",
                    "desc": "Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Â§ÑÁêÜÂ§çÊùÇÊé®ÁêÜ‰ªªÂä°Êó∂Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÈù¢‰∏¥ÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜAdaCoTÔºàËá™ÈÄÇÂ∫îÈìæÂºèÊé®ÁêÜÔºâÔºåÂÆÉÂÖÅËÆ∏Ê®°ÂûãÊ†πÊçÆËæìÂÖ•ÁöÑÂ§çÊùÇÊÄßËá™ÈÄÇÂ∫îÂú∞ÂÜ≥ÂÆöÊòØÂê¶‰ΩøÁî®ÈìæÂºèÊé®ÁêÜ„ÄÇÊàë‰ª¨Â∞ÜËá™ÈÄÇÂ∫îÊé®ÁêÜËßÜ‰∏∫‰∏Ä‰∏™Â∏ïÁ¥ØÊâò‰ºòÂåñÈóÆÈ¢òÔºåÊó®Âú®Âπ≥Ë°°Ê®°ÂûãÊÄßËÉΩ‰∏éÈìæÂºèÊé®ÁêÜÁöÑËÆ°ÁÆóÊàêÊú¨„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAdaCoTÂú®‰∏çÈúÄË¶ÅÂ§çÊùÇÊé®ÁêÜÁöÑÊü•ËØ¢‰∏≠ÊòæËëóÂáèÂ∞ë‰∫ÜÈìæÂºèÊé®ÁêÜÁöÑ‰ΩøÁî®ÔºåÊèêÂçá‰∫ÜÊïàÁéá„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12849",
            "title": "Accelerate TarFlow Sampling with GS-Jacobi Iteration",
            "url": "https://huggingface.co/papers/2505.12849",
            "abstract": "Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computation, TarFlow's sampling process is extremely slow. In this paper, we demonstrate that through a series of optimization strategies, TarFlow sampling can be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as GS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow model have varying importance: a small number of blocks play a major role in image generation tasks, while other blocks contribute relatively little; some blocks are sensitive to initial values and prone to numerical overflow, while others are relatively robust. Based on these two characteristics, we propose the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM is used to identify whether a TarFlow block is \"simple\" (converges in few iterations) or \"tough\" (requires more iterations); IGM is used to evaluate whether the initial value of the iteration is good. Experiments on four TarFlow models demonstrate that GS-Jacobi sampling can significantly enhance sampling efficiency while maintaining the quality of generated images (measured by FID), achieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in Img64uncond, and 2.51x in Img64cond without degrading FID scores or sample quality. Code and checkpoints are accessible on https://github.com/encoreus/GS-Jacobi_for_TarFlow",
            "score": 4,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 –º–∞—è",
                "en": "May 19",
                "zh": "5Êúà19Êó•"
            },
            "hash": "191f5a409cc6b32e",
            "authors": [
                "Ben Liu",
                "Zhen Qin"
            ],
            "affiliations": [
                "TapTap, Shanghai, China",
                "Zhejiang University, Hangzhou, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12849.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#architecture",
                    "#open_source",
                    "#cv",
                    "#training"
                ],
                "emoji": "üöÄ",
                "ru": {
                    "title": "–£—Å–∫–æ—Ä–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ TarFlow —Å –ø–æ–º–æ—â—å—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π",
                    "desc": "–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥ —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –º–æ–¥–µ–ª–∏ TarFlow –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç –∏—Ç–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ì–∞—É—Å—Å–∞-–ó–µ–π–¥–µ–ª—è-–Ø–∫–æ–±–∏ –∏ –≤–≤–æ–¥—è—Ç –¥–≤–µ –º–µ—Ç—Ä–∏–∫–∏: Convergence Ranking Metric (CRM) –∏ Initial Guessing Metric (IGM). CRM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –±–ª–æ–∫–æ–≤ TarFlow, –∞ IGM –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∏—Ç–µ—Ä–∞—Ü–∏–π. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑–∞–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–æ 5.32 —Ä–∞–∑) –±–µ–∑ —É—Ö—É–¥—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
                },
                "en": {
                    "title": "Accelerating TarFlow: Faster Sampling without Quality Loss",
                    "desc": "This paper presents an optimization strategy for the TarFlow model, which combines transformer architecture with Normalizing Flow for image generation. The authors introduce the Gauss-Seidel-Jacobi (GS-Jacobi) iteration method to accelerate the slow sampling process of TarFlow. They identify that certain blocks within the model are more critical for image generation and propose metrics to evaluate their performance: the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM). Experimental results show that the GS-Jacobi method significantly improves sampling speed while preserving image quality, achieving notable speed-ups across various benchmarks."
                },
                "zh": {
                    "title": "Âä†ÈÄüTarFlowÈááÊ†∑ÔºåÊèêÂçáÂõæÂÉèÁîüÊàêÊïàÁéá",
                    "desc": "ÂõæÂÉèÁîüÊàêÊ®°ÂûãÂú®Â§ö‰∏™Â∫îÁî®‰∏≠ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇTarFlowÊ®°ÂûãÁªìÂêà‰∫ÜÂèòÊç¢Âô®Êû∂ÊûÑÂíåÂΩí‰∏ÄÂåñÊµÅÊ®°ÂûãÔºåÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûú„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÂõ†ÊûúÊ≥®ÊÑèÂäõÁöÑÈ°∫Â∫èËÆ°ÁÆóÔºåTarFlowÁöÑÈááÊ†∑ËøáÁ®ãÈùûÂ∏∏ÁºìÊÖ¢„ÄÇÊú¨ÊñáÈÄöËøá‰ºòÂåñÁ≠ñÁï•ÔºåÂà©Áî®È´òÊñØ-ËµõÂæ∑Â∞î-ÈõÖÂèØÊØîËø≠‰ª£ÊñπÊ≥ïÊòæËëóÂä†ÈÄü‰∫ÜTarFlowÁöÑÈááÊ†∑ËøáÁ®ãÔºåÂêåÊó∂‰øùÊåÅÁîüÊàêÂõæÂÉèÁöÑË¥®Èáè„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13379",
            "title": "Thinkless: LLM Learns When to Think",
            "url": "https://huggingface.co/papers/2505.13379",
            "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 –º–∞—è",
                "en": "May 19",
                "zh": "5Êúà19Êó•"
            },
            "hash": "d41117eabc11e5c3",
            "authors": [
                "Gongfan Fang",
                "Xinyin Ma",
                "Xinchao Wang"
            ],
            "affiliations": [
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13379.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–£–º–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –∫—Ä–∞—Ç–∫–∏–º –∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º –º—ã—à–ª–µ–Ω–∏–µ–º –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç Thinkless - –æ–±—É—á–∞–µ–º—É—é —Å–∏—Å—Ç–µ–º—É, –ø–æ–∑–≤–æ–ª—è—é—â—É—é —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –º–µ–∂–¥—É –∫—Ä–∞—Ç–∫–∏–º –∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏ –¥–≤–∞ —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö —Ç–æ–∫–µ–Ω–∞: <short> –¥–ª—è –∫—Ä–∞—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –∏ <think> –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è. –í –æ—Å–Ω–æ–≤–µ –º–µ—Ç–æ–¥–∞ –ª–µ–∂–∏—Ç –∞–ª–≥–æ—Ä–∏—Ç–º DeGRPO, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–∑–¥–µ–ª—è–µ—Ç —Ü–µ–ª—å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –≤—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤. –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ Thinkless —Å–ø–æ—Å–æ–±–µ–Ω —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –Ω–∞ 50-90%, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π."
                },
                "en": {
                    "title": "Thinkless: Smart Reasoning for Efficient Language Models",
                    "desc": "This paper introduces Thinkless, a framework designed to enhance the efficiency of Reasoning Language Models (RLMs) by enabling them to choose between short-form and long-form reasoning based on task complexity. The framework utilizes reinforcement learning and two control tokens, <short> for brief answers and <think> for detailed reasoning, to guide the model's response strategy. A novel algorithm called Decoupled Group Relative Policy Optimization (DeGRPO) is employed to separate the learning objectives, allowing for better control over reasoning mode selection and response accuracy. The results show that Thinkless can significantly reduce the reliance on long-chain reasoning, improving computational efficiency while maintaining performance on various benchmarks."
                },
                "zh": {
                    "title": "ËÆ©Ê®°ÂûãÂ≠¶‰ºö‰ΩïÊó∂ÊÄùËÄÉ",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ThinklessÁöÑÂèØÂ≠¶‰π†Ê°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Êé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊïàÁéá„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊ†πÊçÆ‰ªªÂä°Â§çÊùÇÊÄßÂíåËá™Ë∫´ËÉΩÂäõËá™ÈÄÇÂ∫îÈÄâÊã©Áü≠ÊúüÊàñÈïøÊúüÊé®ÁêÜ„ÄÇThinkless‰ΩøÁî®‰∏§‰∏™ÊéßÂà∂Ê†áËÆ∞<short>Âíå<think>Êù•ÂàÜÂà´Ë°®Á§∫ÁÆÄÊ¥ÅÂõûÁ≠îÂíåËØ¶ÁªÜÊé®ÁêÜ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåThinklessËÉΩÂ§üÂ∞ÜÈïøÊúüÊé®ÁêÜÁöÑ‰ΩøÁî®ÂáèÂ∞ë50%Ëá≥90%ÔºåÊòæËëóÊèêÂçáÊé®ÁêÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÊïàÁéá„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13215",
            "title": "Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation",
            "url": "https://huggingface.co/papers/2505.13215",
            "abstract": "Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 –º–∞—è",
                "en": "May 19",
                "zh": "5Êúà19Êó•"
            },
            "hash": "0ab00a261298ad44",
            "authors": [
                "Seungjun Oh",
                "Younggeun Lee",
                "Hyejin Jeon",
                "Eunbyung Park"
            ],
            "affiliations": [
                "Department of Artificial Intelligence, Sungkyunkwan University",
                "Department of Artificial Intelligence, Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13215.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "üé•",
                "ru": {
                    "title": "–ì–∏–±—Ä–∏–¥–Ω—ã–π 3D-4D –ø–æ–¥—Ö–æ–¥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ 3D-4DGS –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö 3D-—Å—Ü–µ–Ω. –û–Ω –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç 3D –≥–∞—É—Å—Å–∏–∞–Ω—ã –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π –∏ 4D –≥–∞—É—Å—Å–∏–∞–Ω—ã –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã –∏ –ø–∞–º—è—Ç—å –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é 4D –ø–æ–¥—Ö–æ–¥–æ–º. –ú–µ—Ç–æ–¥ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞."
                },
                "en": {
                    "title": "Efficient 3D-4D Scene Reconstruction with Hybrid Gaussian Splatting",
                    "desc": "This paper presents a new method called hybrid 3D-4D Gaussian Splatting (3D-4DGS) for dynamic 3D scene reconstruction. It combines 3D and 4D Gaussian representations to efficiently model static and dynamic elements in a scene. By converting static regions to 3D Gaussians, the method reduces computational load and memory usage while preserving the quality of dynamic elements with 4D Gaussians. The results show that 3D-4DGS achieves faster training times and improved visual quality compared to traditional 4D Gaussian Splatting techniques."
                },
                "zh": {
                    "title": "È´òÊïàÁöÑÂä®ÊÄÅ3DÂú∫ÊôØÈáçÂª∫Êñ∞ÊñπÊ≥ï",
                    "desc": "ÊúÄËøëÂä®ÊÄÅ3DÂú∫ÊôØÈáçÂª∫ÁöÑËøõÂ±ïÊòæÁ§∫Âá∫ËâØÂ•ΩÁöÑÊïàÊûúÔºåËÉΩÂ§üÂÆûÁé∞È´ò‰øùÁúüÂ∫¶ÁöÑ3DÊñ∞ËßÜÂõæÂêàÊàêÔºåÂπ∂ÊèêÈ´òÊó∂Èó¥‰∏ÄËá¥ÊÄß„ÄÇÂú®Ëøô‰∫õÊñπÊ≥ï‰∏≠Ôºå4DÈ´òÊñØÁÇπ‰∫ëÔºà4DGSÔºâÂõ†ÂÖ∂ËÉΩÂ§üÂª∫Ê®°È´ò‰øùÁúüÁöÑÁ©∫Èó¥ÂíåÊó∂Èó¥ÂèòÂåñËÄåÂèóÂà∞ÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÈùôÊÄÅÂå∫ÂüüÂÜó‰ΩôÂàÜÈÖç4DÈ´òÊñØÊó∂ÔºåÂØºËá¥‰∫ÜÊòæËëóÁöÑËÆ°ÁÆóÂíåÂÜÖÂ≠òÂºÄÈîÄÔºåÂπ∂ÂèØËÉΩÈôç‰ΩéÂõæÂÉèË¥®Èáè„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑Âêà3D-4DÈ´òÊñØÁÇπ‰∫ëÔºà3D-4DGSÔºâÊ°ÜÊû∂ÔºåËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞Áî®3DÈ´òÊñØË°®Á§∫ÈùôÊÄÅÂå∫ÂüüÔºåÂêåÊó∂‰∏∫Âä®ÊÄÅÂÖÉÁ¥†‰øùÁïô4DÈ´òÊñØÔºå‰ªéËÄåÊòæËëóÊèêÈ´òËÆ°ÁÆóÊïàÁéá„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11932",
            "title": "Neuro-Symbolic Query Compiler",
            "url": "https://huggingface.co/papers/2505.11932",
            "abstract": "Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar G[q] to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 –º–∞—è",
                "en": "May 17",
                "zh": "5Êúà17Êó•"
            },
            "hash": "9445be4eff7e4edc",
            "authors": [
                "Yuyao Zhang",
                "Zhicheng Dou",
                "Xiaoxi Li",
                "Jiajie Jin",
                "Yongkang Wu",
                "Zhonghua Li",
                "Qi Ye",
                "Ji-Rong Wen"
            ],
            "affiliations": [
                "Huawei Poisson Lab",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11932.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rag",
                    "#multimodal"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–ö–æ–º–ø–∏–ª—è—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ RAG-—Å–∏—Å—Ç–µ–º–∞—Ö",
                    "desc": "QCompiler - —ç—Ç–æ –Ω–µ–π—Ä–æ-—Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ RAG-—Å–∏—Å—Ç–µ–º–∞—Ö. –û–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –≥—Ä–∞–º–º–∞—Ç–∏–∫—É BNF –¥–ª—è —Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –∏—Ö –≤ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –¥–µ—Ä–µ–≤—å—è. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ –∏–∑–≤–ª–µ–∫–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏. QCompiler –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –≤—ã—Ä–∞–∂–µ–Ω–∏–π –∑–∞–ø—Ä–æ—Å–æ–≤, –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä."
                },
                "en": {
                    "title": "Enhancing Query Understanding in RAG Systems with QCompiler",
                    "desc": "This paper introduces QCompiler, a neuro-symbolic framework designed to enhance the understanding of complex search queries in Retrieval-Augmented Generation (RAG) systems. It utilizes a specially designed Backus-Naur Form (BNF) grammar to formalize these queries, ensuring that they are both complete and free of unnecessary complexity. QCompiler operates through a series of components, including a Query Expression Translator and a Lexical Syntax Parser, which work together to convert queries into Abstract Syntax Trees (ASTs). By focusing on the atomicity of sub-queries, QCompiler improves the accuracy of document retrieval and response generation for intricate queries."
                },
                "zh": {
                    "title": "ÊèêÂçáRAGÁ≥ªÁªüÁöÑÂ§çÊùÇÊü•ËØ¢ËØÜÂà´ËÉΩÂäõ",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫QCompilerÁöÑÁ•ûÁªèÁ¨¶Âè∑Ê°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÁ≥ªÁªüÂØπÂ§çÊùÇÊü•ËØ¢ÁöÑËØÜÂà´ËÉΩÂäõ„ÄÇQCompilerÂü∫‰∫éËØ≠Ë®ÄËØ≠Ê≥ïËßÑÂàôÂíåÁºñËØëÂô®ËÆæËÆ°ÔºåËÆæËÆ°‰∫Ü‰∏ÄÁßçÊúÄÂ∞è‰ΩÜË∂≥Â§üÁöÑÂ∑¥ÁßëÊñØ-ËØ∫Â∞îÂΩ¢ÂºèÔºàBNFÔºâËØ≠Ê≥ïG[q]Ôºå‰ª•ÂΩ¢ÂºèÂåñÂ§çÊùÇÊü•ËØ¢„ÄÇ‰∏é‰ª•ÂæÄÊñπÊ≥ï‰∏çÂêåÔºåËøôÁßçËØ≠Ê≥ïÂú®‰øùÊåÅÂÆåÊï¥ÊÄßÁöÑÂêåÊó∂ÔºåÂáèÂ∞ë‰∫ÜÂÜó‰Ωô„ÄÇÈÄöËøáÂ∞ÜÊü•ËØ¢ÁºñËØëÊàêÊäΩË±°ËØ≠Ê≥ïÊ†ëÔºàASTÔºâÔºåQCompilerËÉΩÂ§üÊõ¥Á≤æÁ°ÆÂú∞Ê£ÄÁ¥¢ÊñáÊ°£Âπ∂ÁîüÊàêÂìçÂ∫îÔºå‰ªéËÄåÊòæËëóÊèêÂçáRAGÁ≥ªÁªüÂ§ÑÁêÜÂ§çÊùÇÊü•ËØ¢ÁöÑËÉΩÂäõ„ÄÇ"
                }
            }
        }
    ],
    "link_prev": "2025-05-19.html",
    "link_next": "2025-05-21.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "19.05",
        "en": "05/19",
        "zh": "5Êúà19Êó•"
    },
    "short_date_next": {
        "ru": "21.05",
        "en": "05/21",
        "zh": "5Êúà21Êó•"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 2,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 5,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 5,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫ÜQwen3ÔºåËøôÊòØQwenÊ®°ÂûãÁ≥ªÂàóÁöÑÊúÄÊñ∞ÁâàÊú¨„ÄÇQwen3ÂåÖÊã¨Â§öÁßçÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®ÊèêÈ´òÊÄßËÉΩ„ÄÅÊïàÁéáÂíåÂ§öËØ≠Ë®ÄËÉΩÂäõ„ÄÇÂÆÉÂåÖÂê´ÂØÜÈõÜÂíåÊ∑∑Âêà‰∏ìÂÆ∂Êû∂ÊûÑÔºåÂèÇÊï∞ËßÑÊ®°‰ªé0.6Âà∞2350‰∫ø‰∏çÁ≠â„ÄÇQwen3ÁöÑÂàõÊñ∞‰πãÂ§ÑÂú®‰∫éÂ∞ÜÊÄùËÄÉÊ®°ÂºèÂíåÈùûÊÄùËÄÉÊ®°ÂºèÁªìÂêàÂú®‰∏Ä‰∏™Ê°ÜÊû∂‰∏≠ÔºåÊ∂àÈô§‰∫ÜÂàáÊç¢Ê®°ÂûãÁöÑÈúÄË¶Å„ÄÇÂÆÉËøòÂºïÂÖ•‰∫ÜÊÄùËÄÉÈ¢ÑÁÆóÊú∫Âà∂ÔºåÂÖÅËÆ∏Áî®Êà∑Ê†πÊçÆ‰ªªÂä°Â§çÊùÇÊÄßÂä®ÊÄÅÂàÜÈÖçËÆ°ÁÆóËµÑÊ∫ê„ÄÇ",
        "title": "Qwen3 Technical Report",
        "pinyin": "ËøôÁØáÊñáÁ´†‰ªãÁªç‰∫ÜQwen3ÔºåËøôÊòØQwenÊ®°ÂûãÁ≥ªÂàóÁöÑÊúÄÊñ∞ÁâàÊú¨„ÄÇ\nZh√® piƒÅn w√©nzhƒÅng ji√®sh√†o le Qwen3, zh√® sh√¨ Qwen m√≥x√≠ng x√¨li√® de zu√¨xƒ´n b«énbƒõn.\n\nQwen3ÂåÖÊã¨Â§öÁßçÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®ÊèêÈ´òÊÄßËÉΩ„ÄÅÊïàÁéáÂíåÂ§öËØ≠Ë®ÄËÉΩÂäõ„ÄÇ\nQwen3 bƒÅoku√≤ du≈çzh«íng d√†x√≠ng y«îy√°n m√≥x√≠ng, zh«ê z√†i t√≠gƒÅo x√¨ngn√©ng, xi√†ol«ú h√© du≈çy«îy√°n n√©ngl√¨.\n\nÂÆÉÂåÖÂê´ÂØÜÈõÜÂíåÊ∑∑Âêà‰∏ìÂÆ∂Êû∂ÊûÑÔºåÂèÇÊï∞ËßÑÊ®°‰ªé0.6Âà∞2350‰∫ø‰∏çÁ≠â„ÄÇ\nTƒÅ bƒÅoh√°n m√¨j√≠ h√© h√πnh√© zhuƒÅnjiƒÅ ji√†g√≤u, cƒÅnsh√π guƒ´m√≥ c√≥ng 0.6 d√†o 2350 y√¨ b√πdƒõng.\n\nQwen3ÁöÑÂàõÊñ∞‰πãÂ§ÑÂú®‰∫éÂ∞ÜÊÄùËÄÉÊ®°ÂºèÂíåÈùûÊÄùËÄÉÊ®°ÂºèÁªìÂêàÂú®‰∏Ä‰∏™Ê°ÜÊû∂‰∏≠ÔºåÊ∂àÈô§‰∫ÜÂàáÊç¢Ê®°ÂûãÁöÑÈúÄË¶Å„ÄÇ\nQwen3 de chu√†ngxƒ´n zhƒ´ ch√π z√†i y√∫ jiƒÅng sƒ´k«éo m√≥sh√¨ h√© fƒìi sƒ´k«éo m√≥sh√¨ ji√©h√© z√†i yƒ´g√® ku√†ngji√† zh≈çng, xiƒÅoch√∫ le qiƒìhu√†n m√≥x√≠ng de x≈´y√†o.\n\nÂÆÉËøòÂºïÂÖ•‰∫ÜÊÄùËÄÉÈ¢ÑÁÆóÊú∫Âà∂ÔºåÂÖÅËÆ∏Áî®Êà∑Ê†πÊçÆ‰ªªÂä°Â§çÊùÇÊÄßÂä®ÊÄÅÂàÜÈÖçËÆ°ÁÆóËµÑÊ∫ê„ÄÇ\nTƒÅ h√°i y«ênr√π le sƒ´k«éo y√πsu√†n jƒ´zh√¨, y«înx«î y√≤ngh√π gƒìnj√π r√®nw√π f√πz√°x√¨ng d√≤ngt√†i fƒìnp√®i j√¨su√†n zƒ´yu√°n.",
        "vocab": "[\n    {\"word\": \"Á≥ªÂàó\", \"pinyin\": \"x√¨li√®\", \"trans\": \"series\"},\n    {\"word\": \"ÁâàÊú¨\", \"pinyin\": \"b«énbƒõn\", \"trans\": \"version\"},\n    {\"word\": \"Êó®Âú®\", \"pinyin\": \"zh«êz√†i\", \"trans\": \"aim to\"},\n    {\"word\": \"ÊïàÁéá\", \"pinyin\": \"xi√†ol«ú\", \"trans\": \"efficiency\"},\n    {\"word\": \"Â§öËØ≠Ë®Ä\", \"pinyin\": \"du≈çy«îy√°n\", \"trans\": \"multilingual\"},\n    {\"word\": \"ËÉΩÂäõ\", \"pinyin\": \"n√©ngl√¨\", \"trans\": \"ability\"},\n    {\"word\": \"ÂåÖÂê´\", \"pinyin\": \"bƒÅoh√°n\", \"trans\": \"contain\"},\n    {\"word\": \"ÂØÜÈõÜ\", \"pinyin\": \"m√¨j√≠\", \"trans\": \"dense\"},\n    {\"word\": \"Ê∑∑Âêà\", \"pinyin\": \"h√πnh√©\", \"trans\": \"hybrid\"},\n    {\"word\": \"‰∏ìÂÆ∂\", \"pinyin\": \"zhuƒÅnjiƒÅ\", \"trans\": \"expert\"},\n    {\"word\": \"Êû∂ÊûÑ\", \"pinyin\": \"ji√†g√≤u\", \"trans\": \"architecture\"},\n    {\"word\": \"ÂèÇÊï∞\", \"pinyin\": \"cƒÅnsh«î\", \"trans\": \"parameter\"},\n    {\"word\": \"ËßÑÊ®°\", \"pinyin\": \"guƒ´m√≥\", \"trans\": \"scale\"},\n    {\"word\": \"ÂàõÊñ∞\", \"pinyin\": \"chu√†ngxƒ´n\", \"trans\": \"innovation\"},\n    {\"word\": \"‰πãÂ§Ñ\", \"pinyin\": \"zhƒ´ch√π\", \"trans\": \"place\"},\n    {\"word\": \"ÊÄùËÄÉ\", \"pinyin\": \"sƒ´k«éo\", \"trans\": \"think\"},\n    {\"word\": \"Ê®°Âºè\", \"pinyin\": \"m√≥sh√¨\", \"trans\": \"mode\"},\n    {\"word\": \"ÁªìÂêà\", \"pinyin\": \"ji√©h√©\", \"trans\": \"combine\"},\n    {\"word\": \"Ê°ÜÊû∂\", \"pinyin\": \"ku√†ngji√†\", \"trans\": \"framework\"},\n    {\"word\": \"Ê∂àÈô§\", \"pinyin\": \"xiƒÅoch√∫\", \"trans\": \"eliminate\"},\n    {\"word\": \"ÂàáÊç¢\", \"pinyin\": \"qiƒìhu√†n\", \"trans\": \"switch\"},\n    {\"word\": \"ÈúÄË¶Å\", \"pinyin\": \"x≈´y√†o\", \"trans\": \"need\"},\n    {\"word\": \"ÂºïÂÖ•\", \"pinyin\": \"y«ênr√π\", \"trans\": \"introduce\"},\n    {\"word\": \"È¢ÑÁÆó\", \"pinyin\": \"y√πsu√†n\", \"trans\": \"budget\"},\n    {\"word\": \"Êú∫Âà∂\", \"pinyin\": \"jƒ´zh√¨\", \"trans\": \"mechanism\"},\n    {\"word\": \"ÂÖÅËÆ∏\", \"pinyin\": \"y«înx«î\", \"trans\": \"allow\"},\n    {\"word\": \"Ê†πÊçÆ\", \"pinyin\": \"gƒìnj√π\", \"trans\": \"according to\"},\n    {\"word\": \"‰ªªÂä°\", \"pinyin\": \"r√®nw√π\", \"trans\": \"task\"},\n    {\"word\": \"Â§çÊùÇÊÄß\", \"pinyin\": \"f√πz√°x√¨ng\", \"trans\": \"complexity\"},\n    {\"word\": \"Âä®ÊÄÅ\", \"pinyin\": \"d√≤ngt√†i\", \"trans\": \"dynamic\"},\n    {\"word\": \"ÂàÜÈÖç\", \"pinyin\": \"fƒìnp√®i\", \"trans\": \"allocate\"},\n    {\"word\": \"ËÆ°ÁÆó\", \"pinyin\": \"j√¨su√†n\", \"trans\": \"compute\"},\n    {\"word\": \"ËµÑÊ∫ê\", \"pinyin\": \"zƒ´yu√°n\", \"trans\": \"resources\"}\n]",
        "trans": "This article introduces Qwen3, the latest version in the Qwen model series. Qwen3 includes a variety of large language models aimed at enhancing performance, efficiency, and multilingual capabilities. It features dense and mixture-of-experts architectures, with parameter sizes ranging from 0.6 to 2350 billion. The innovation of Qwen3 lies in combining thinking and non-thinking modes within a single framework, eliminating the need to switch models. It also introduces a thinking budget mechanism, allowing users to dynamically allocate computational resources based on the complexity of the task.",
        "update_ts": "2025-05-19 09:13"
    }
}