{
    "date": {
        "ru": "5 мая",
        "en": "May 5",
        "zh": "5月5日"
    },
    "time_utc": "2025-05-05 08:16",
    "weekday": 0,
    "issue_id": 3585,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2504.20438",
            "title": "PixelHacker: Image Inpainting with Structural and Semantic Consistency",
            "url": "https://huggingface.co/papers/2504.20438",
            "abstract": "Image inpainting is a fundamental research area between image editing and image generation. Recent state-of-the-art (SOTA) methods have explored novel attention mechanisms, lightweight architectures, and context-aware modeling, demonstrating impressive performance. However, they often struggle with complex structure (e.g., texture, shape, spatial relations) and semantics (e.g., color consistency, object restoration, and logical correctness), leading to artifacts and inappropriate generation. To address this challenge, we design a simple yet effective inpainting paradigm called latent categories guidance, and further propose a diffusion-based model named PixelHacker. Specifically, we first construct a large dataset containing 14 million image-mask pairs by annotating foreground and background (potential 116 and 21 categories, respectively). Then, we encode potential foreground and background representations separately through two fixed-size embeddings, and intermittently inject these features into the denoising process via linear attention. Finally, by pre-training on our dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker. Extensive experiments show that PixelHacker comprehensively outperforms the SOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits remarkable consistency in both structure and semantics. Project page at https://hustvl.github.io/PixelHacker.",
            "score": 16,
            "issue_id": 3584,
            "pub_date": "2025-04-29",
            "pub_date_card": {
                "ru": "29 апреля",
                "en": "April 29",
                "zh": "4月29日"
            },
            "hash": "987ce511e3c86e06",
            "authors": [
                "Ziyang Xu",
                "Kangsheng Duan",
                "Xiaolei Shen",
                "Zhifeng Ding",
                "Wenyu Liu",
                "Xiaohu Ruan",
                "Xiaoxin Chen",
                "Xinggang Wang"
            ],
            "affiliations": [
                "Huazhong University of Science and Technology",
                "VIVO AI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.20438.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#dataset",
                    "#training",
                    "#open_source",
                    "#optimization",
                    "#diffusion",
                    "#cv"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "PixelHacker: Революционный подход к восстановлению изображений с помощью латентных категорий",
                    "desc": "В статье представлен новый подход к задаче восстановления изображений под названием PixelHacker. Авторы разработали метод латентного категориального управления, используя большой набор данных из 14 миллионов пар изображение-маска с аннотациями переднего и заднего плана. PixelHacker применяет диффузионную модель с внедрением признаков через линейное внимание. Эксперименты показывают, что PixelHacker превосходит современные методы на различных наборах данных, демонстрируя высокую согласованность структуры и семантики изображений."
                },
                "en": {
                    "title": "PixelHacker: Revolutionizing Image Inpainting with Latent Categories Guidance",
                    "desc": "This paper presents a new approach to image inpainting called PixelHacker, which aims to improve the quality of generated images by addressing issues with complex structures and semantics. The authors introduce a large dataset of 14 million image-mask pairs to train their model, focusing on distinguishing between foreground and background categories. They utilize a diffusion-based model that incorporates linear attention to enhance the denoising process, ensuring better consistency in texture and color. Experimental results demonstrate that PixelHacker significantly outperforms existing state-of-the-art methods across various datasets, achieving superior image restoration results."
                },
                "zh": {
                    "title": "PixelHacker：图像修复的新突破",
                    "desc": "图像修复是图像编辑与生成之间的一个重要研究领域。最近的最先进方法探索了新颖的注意力机制、轻量级架构和上下文感知建模，取得了显著的性能。然而，这些方法在处理复杂结构和语义时常常面临挑战，导致生成的图像出现伪影和不当生成。为了解决这个问题，我们设计了一种简单而有效的修复范式，称为潜在类别引导，并提出了一种基于扩散的模型PixelHacker。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.01079",
            "title": "Improving Editability in Image Generation with Layer-wise Memory",
            "url": "https://huggingface.co/papers/2505.01079",
            "abstract": "Most real-world image editing tasks require multiple sequential edits to achieve desired results. Current editing approaches, primarily designed for single-object modifications, struggle with sequential editing: especially with maintaining previous edits along with adapting new objects naturally into the existing content. These limitations significantly hinder complex editing scenarios where multiple objects need to be modified while preserving their contextual relationships. We address this fundamental challenge through two key proposals: enabling rough mask inputs that preserve existing content while naturally integrating new elements and supporting consistent editing across multiple modifications. Our framework achieves this through layer-wise memory, which stores latent representations and prompt embeddings from previous edits. We propose Background Consistency Guidance that leverages memorized latents to maintain scene coherence and Multi-Query Disentanglement in cross-attention that ensures natural adaptation to existing content. To evaluate our method, we present a new benchmark dataset incorporating semantic alignment metrics and interactive editing scenarios. Through comprehensive experiments, we demonstrate superior performance in iterative image editing tasks with minimal user effort, requiring only rough masks while maintaining high-quality results throughout multiple editing steps.",
            "score": 10,
            "issue_id": 3582,
            "pub_date": "2025-05-02",
            "pub_date_card": {
                "ru": "2 мая",
                "en": "May 2",
                "zh": "5月2日"
            },
            "hash": "e1aa83ea7926943e",
            "authors": [
                "Daneul Kim",
                "Jaeah Lee",
                "Jaesik Park"
            ],
            "affiliations": [
                "Seoul National University, Republic of Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.01079.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#cv"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Умное последовательное редактирование изображений: сохраняем прошлое, добавляем новое",
                    "desc": "Статья представляет новый подход к последовательному редактированию изображений с использованием нейронных сетей. Авторы предлагают метод, позволяющий сохранять предыдущие изменения и естественно интегрировать новые элементы в существующий контент. Ключевые инновации включают использование приблизительных масок, послойную память для хранения латентных представлений и применение техник Background Consistency Guidance и Multi-Query Disentanglement. Эффективность метода подтверждается экспериментами на новом наборе данных с метриками семантического выравнивания."
                },
                "en": {
                    "title": "Seamless Sequential Image Editing with Context Preservation",
                    "desc": "This paper addresses the challenges of sequential image editing, where multiple edits are needed while keeping previous changes intact. Current methods struggle with integrating new objects into existing images without disrupting the overall context. The authors propose a framework that uses layer-wise memory to store previous edits and ensure consistency across modifications. Their approach includes Background Consistency Guidance and Multi-Query Disentanglement to enhance the natural integration of new elements, leading to improved performance in complex editing tasks with minimal user input."
                },
                "zh": {
                    "title": "实现自然连续的图像编辑",
                    "desc": "本论文探讨了图像编辑中的多次连续编辑问题，现有方法在处理多个对象的修改时存在困难，尤其是在保持之前编辑内容的同时自然地融入新对象。我们提出了两项关键方案：一是支持粗略的掩膜输入，以保留现有内容并自然整合新元素；二是支持多次修改的一致性编辑。我们的框架通过层级记忆存储先前编辑的潜在表示和提示嵌入，利用背景一致性引导保持场景的连贯性。实验结果表明，我们的方法在迭代图像编辑任务中表现优越，用户只需提供粗略掩膜即可实现高质量的编辑效果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00023",
            "title": "CORG: Generating Answers from Complex, Interrelated Contexts",
            "url": "https://huggingface.co/papers/2505.00023",
            "abstract": "In a real-world corpus, knowledge frequently recurs across documents but often contains inconsistencies due to ambiguous naming, outdated information, or errors, leading to complex interrelationships between contexts. Previous research has shown that language models struggle with these complexities, typically focusing on single factors in isolation. We classify these relationships into four types: distracting, ambiguous, counterfactual, and duplicated. Our analysis reveals that no single approach effectively addresses all these interrelationships simultaneously. Therefore, we introduce Context Organizer (CORG), a framework that organizes multiple contexts into independently processed groups. This design allows the model to efficiently find all relevant answers while ensuring disambiguation. CORG consists of three key components: a graph constructor, a reranker, and an aggregator. Our results demonstrate that CORG balances performance and efficiency effectively, outperforming existing grouping methods and achieving comparable results to more computationally intensive, single-context approaches.",
            "score": 3,
            "issue_id": 3582,
            "pub_date": "2025-04-25",
            "pub_date_card": {
                "ru": "25 апреля",
                "en": "April 25",
                "zh": "4月25日"
            },
            "hash": "46da290a5c894311",
            "authors": [
                "Hyunji Lee",
                "Franck Dernoncourt",
                "Trung Bui",
                "Seunghyun Yoon"
            ],
            "affiliations": [
                "Adobe Research",
                "KAIST AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00023.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#multimodal",
                    "#graphs",
                    "#architecture",
                    "#data"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "CORG: Умная организация контекста для улучшения работы языковых моделей",
                    "desc": "Статья представляет новый фреймворк под названием Context Organizer (CORG) для обработки сложных взаимосвязей между контекстами в корпусах реального мира. CORG организует множественные контексты в независимо обрабатываемые группы, что позволяет эффективно находить все релевантные ответы и обеспечивать устранение неоднозначности. Фреймворк состоит из трех ключевых компонентов: конструктора графов, ранжировщика и агрегатора. Результаты показывают, что CORG эффективно балансирует производительность и эффективность, превосходя существующие методы группировки."
                },
                "en": {
                    "title": "Organizing Contexts for Better Language Understanding",
                    "desc": "This paper addresses the challenges faced by language models when dealing with complex interrelationships in real-world data, which often contain inconsistencies. It categorizes these relationships into four types: distracting, ambiguous, counterfactual, and duplicated, highlighting that existing methods typically fail to handle them all at once. To tackle this issue, the authors propose a new framework called Context Organizer (CORG), which organizes contexts into separate groups for independent processing. CORG includes a graph constructor, a reranker, and an aggregator, and it demonstrates improved performance and efficiency compared to traditional methods."
                },
                "zh": {
                    "title": "上下文组织，提升模型效率与准确性",
                    "desc": "在现实世界的语料库中，知识经常在文档中重复出现，但由于命名模糊、信息过时或错误，导致上下文之间存在复杂的相互关系。以往的研究表明，语言模型在处理这些复杂性时通常只关注单一因素。我们将这些关系分为四种类型：干扰、模糊、反事实和重复。为了解决这些问题，我们提出了上下文组织器（CORG），它将多个上下文组织成独立处理的组，从而提高模型的效率和准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00174",
            "title": "Real-World Gaps in AI Governance Research",
            "url": "https://huggingface.co/papers/2505.00174",
            "abstract": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI papers (January 2020 - March 2025), we compare research outputs of leading AI companies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI universities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of Washington). We find that corporate AI research increasingly concentrates on pre-deployment areas -- model alignment and testing & evaluation -- while attention to deployment-stage issues such as model bias has waned. Significant research gaps exist in high-risk deployment domains, including healthcare, finance, misinformation, persuasive and addictive features, hallucinations, and copyright. Without improved observability into deployed AI, growing corporate concentration could deepen knowledge deficits. We recommend expanding external researcher access to deployment data and systematic observability of in-market AI behaviors.",
            "score": 2,
            "issue_id": 3582,
            "pub_date": "2025-04-30",
            "pub_date_card": {
                "ru": "30 апреля",
                "en": "April 30",
                "zh": "4月30日"
            },
            "hash": "7618edbafcee6b13",
            "authors": [
                "Ilan Strauss",
                "Isobel Moure",
                "Tim O'Reilly",
                "Sruly Rosenblat"
            ],
            "affiliations": [
                "AI Disclosures Project, Social Science Research Council",
                "Institute for Innovation and Public Purpose, University College London",
                "OReilly Media"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00174.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#ethics",
                    "#alignment",
                    "#healthcare",
                    "#hallucinations",
                    "#data"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Корпоративные исследования ИИ: пробелы в безопасности и необходимость прозрачности",
                    "desc": "Статья анализирует 1178 работ по безопасности и надежности из 9439 статей по генеративному ИИ за период с января 2020 по март 2025 года. Исследователи сравнивают результаты ведущих компаний и университетов в области ИИ. Обнаружено, что корпоративные исследования ИИ все больше концентрируются на предварительном развертывании, включая выравнивание моделей и тестирование, в то время как внимание к проблемам этапа развертывания, таким как смещение модели, ослабевает. Авторы рекомендуют расширить доступ внешних исследователей к данным развертывания и систематическое наблюдение за поведением ИИ на рынке."
                },
                "en": {
                    "title": "Bridging the Gap: Enhancing AI Safety in Deployment",
                    "desc": "This paper analyzes the trends in safety and reliability research within generative AI by examining 1,178 papers from major AI companies and universities. It highlights a shift in focus towards pre-deployment concerns like model alignment and evaluation, while issues related to deployment, such as model bias, are receiving less attention. The authors identify critical research gaps in high-risk areas like healthcare and finance, where the implications of AI deployment can be significant. They advocate for better access to deployment data and enhanced observability of AI systems in real-world applications to address these gaps."
                },
                "zh": {
                    "title": "关注人工智能部署阶段的研究缺口",
                    "desc": "本研究分析了1178篇安全性和可靠性论文与9439篇生成式人工智能论文，比较了主要人工智能公司和大学的研究成果。研究发现，企业的人工智能研究越来越集中在模型对齐和测试评估等预部署领域，而对部署阶段问题如模型偏见的关注有所减少。高风险部署领域（如医疗、金融、虚假信息等）存在显著的研究空白。为了改善对已部署人工智能的可观察性，建议扩大外部研究人员对部署数据的访问，并系统化市场中人工智能行为的可观察性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00562",
            "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
            "url": "https://huggingface.co/papers/2505.00562",
            "abstract": "Learning to solve complex tasks with signal temporal logic (STL) specifications is crucial to many real-world applications. However, most previous works only consider fixed or parametrized STL specifications due to the lack of a diverse STL dataset and encoders to effectively extract temporal logic information for downstream tasks. In this paper, we propose TeLoGraF, Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN) encoder and flow-matching to learn solutions for general STL specifications. We identify four commonly used STL templates and collect a total of 200K specifications with paired demonstrations. We conduct extensive experiments in five simulation environments ranging from simple dynamical models in the 2D space to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped navigation. Results show that our method outperforms other baselines in the STL satisfaction rate. Compared to classical STL planning algorithms, our approach is 10-100X faster in inference and can work on any system dynamics. Besides, we show our graph-encoding method's capability to solve complex STLs and robustness to out-distribution STL specifications. Code is available at https://github.com/mengyuest/TeLoGraF",
            "score": 1,
            "issue_id": 3583,
            "pub_date": "2025-05-01",
            "pub_date_card": {
                "ru": "1 мая",
                "en": "May 1",
                "zh": "5月1日"
            },
            "hash": "bf5b246f5848fa6e",
            "authors": [
                "Yue Meng",
                "Chuchu Fan"
            ],
            "affiliations": [
                "Department of Aeronautics and Astronautics, MIT, Cambridge, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00562.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#inference",
                    "#agents",
                    "#robotics",
                    "#graphs",
                    "#optimization"
                ],
                "emoji": "⏱️",
                "ru": {
                    "title": "Графовые нейросети для эффективного решения задач темпоральной логики",
                    "desc": "Статья представляет TeLoGraF - новый метод для решения задач с темпоральной логикой сигналов (STL). Авторы используют графовые нейронные сети и технику flow-matching для обучения на разнообразном наборе STL-спецификаций. Эксперименты проводились в пяти симуляционных средах, от простых 2D-моделей до сложных роботов. Результаты показывают превосходство TeLoGraF над базовыми методами по скорости и универсальности применения."
                },
                "en": {
                    "title": "TeLoGraF: Fast and Robust Solutions for Complex Temporal Logic Tasks",
                    "desc": "This paper introduces TeLoGraF, a novel approach that leverages Graph Neural Networks (GNN) to effectively learn solutions for complex tasks defined by signal temporal logic (STL) specifications. The authors address the limitations of previous methods that relied on fixed STL templates by creating a diverse dataset of 200,000 STL specifications paired with demonstrations. Through extensive experiments across various simulation environments, TeLoGraF demonstrates superior performance in STL satisfaction rates and significantly faster inference times compared to traditional STL planning algorithms. Additionally, the graph-encoding technique shows robustness in handling complex and out-of-distribution STL specifications, making it a versatile tool for real-world applications."
                },
                "zh": {
                    "title": "TeLoGraF：高效解决复杂时序逻辑任务的创新方法",
                    "desc": "本文提出了一种新的方法TeLoGraF，用于解决复杂任务的信号时序逻辑（STL）规范。我们利用图神经网络（GNN）编码器和流匹配技术，学习通用STL规范的解决方案。通过收集20万个配对示例，我们在多个仿真环境中进行了广泛实验，结果表明该方法在STL满足率上优于其他基线。与传统的STL规划算法相比，我们的方法在推理速度上快10到100倍，并且能够适应任何系统动态。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.20859",
            "title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain\n  Sequential Recommendation",
            "url": "https://huggingface.co/papers/2504.20859",
            "abstract": "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents ``X-Cross'' -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA). Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models. These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains. Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25% of the additional parameters. In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50%-75% less fine-tuning data than LoRA to make fine-tuning effective. Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines. Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments.",
            "score": 1,
            "issue_id": 3583,
            "pub_date": "2025-04-29",
            "pub_date_card": {
                "ru": "29 апреля",
                "en": "April 29",
                "zh": "4月29日"
            },
            "hash": "2102f697cfc2375e",
            "authors": [
                "Guy Hadad",
                "Haggai Roitman",
                "Yotam Eshel",
                "Bracha Shapira",
                "Lior Rokach"
            ],
            "affiliations": [
                "Ben-Gurion University of the Negev Beer Sheva, Israel",
                "eBay Netanya, Israel"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.20859.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#transfer_learning",
                    "#low_resource",
                    "#training",
                    "#multimodal"
                ],
                "emoji": "🔀",
                "ru": {
                    "title": "X-Cross: эффективные кросс-доменные рекомендации без обширного переобучения",
                    "desc": "Статья представляет модель X-Cross для кросс-доменных последовательных рекомендаций, использующую несколько доменно-специфичных языковых моделей с низкоранговыми адаптерами (LoRA). X-Cross динамически улучшает представления каждой исходной языковой модели, интегрируя знания из всех других моделей. Эксперименты на данных Amazon показывают, что X-Cross достигает производительности, сравнимой с моделью, дообученной с LoRA, используя лишь 25% дополнительных параметров. Модель демонстрирует надежную производительность в кросс-доменных задачах, требуя на 50-75% меньше данных для эффективной донастройки."
                },
                "en": {
                    "title": "X-Cross: Efficient Cross-Domain Recommendations with Minimal Data",
                    "desc": "The paper introduces 'X-Cross', a new model designed for cross-domain sequential recommendations that can quickly adapt to new product categories without extensive retraining. It utilizes multiple domain-specific language models, each fine-tuned with low-rank adapters (LoRA), to enhance the recommendation process. By refining the representations of these models layer by layer, X-Cross effectively integrates knowledge from different domains while maintaining their unique characteristics. The model shows strong performance on Amazon datasets, requiring significantly less fine-tuning data and parameters compared to traditional methods, making it efficient for data-limited scenarios."
                },
                "zh": {
                    "title": "X-Cross：高效的跨领域推荐解决方案",
                    "desc": "随着新产品的不断涌现，推荐系统需要快速适应新领域，而无需大量重新训练。本文提出了“X-Cross”模型，这是一种新颖的跨领域序列推荐模型，通过整合多个特定领域的语言模型来推荐新领域的产品。X-Cross通过逐层操作动态地优化每个源语言模型的表示，确保在跨领域适应时保留领域特有的细微差别。实验结果表明，X-Cross在跨领域任务中表现出色，且所需的微调数据量显著低于传统方法。"
                }
            }
        }
    ],
    "link_prev": "2025-05-02.html",
    "link_next": "2025-05-06.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "02.05",
        "en": "05/02",
        "zh": "5月2日"
    },
    "short_date_next": {
        "ru": "06.05",
        "en": "05/06",
        "zh": "5月6日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 2,
        "#benchmark": 2,
        "#agents": 1,
        "#cv": 2,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 1,
        "#training": 2,
        "#robotics": 1,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 1,
        "#graphs": 2,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "这篇文章介绍了一种新兴技术：互动生成视频（IGV）。它结合生成和互动功能，产生高质量视频内容，并让用户通过控制信号和响应反馈参与其中。IGV在游戏、人工智能和自动驾驶三大领域有重要应用。文章还提出了理想IGV系统的五个关键模块，并分析了每个模块的技术挑战和未来方向。",
        "title": "A Survey of Interactive Generative Video",
        "pinyin": "这篇文章介绍了一种新兴技术：互动生成视频（IGV）。它结合生成和互动功能，产生高质量视频内容，并让用户通过控制信号和响应反馈参与其中。IGV在游戏、人工智能和自动驾驶三大领域有重要应用。文章还提出了理想IGV系统的五个关键模块，并分析了每个模块的技术挑战和未来方向。\n\nZhè piān wénzhāng jièshào le yī zhǒng xīnxīng jìshù: hùdòng shēngchéng shìpín (IGV). Tā jiéhé shēngchéng hé hùdòng gōngnéng, chǎnshēng gāo zhìliàng shìpín nèiróng, bìng ràng yònghù tōngguò kòngzhì xìnhào hé xiǎngyìng fǎnkuì cānyù qízhōng. IGV zài yóuxì, réngōng zhìnéng hé zìdòng jiàshǐ sān dà lǐngyù yǒu zhòngyào yìngyòng. Wénzhāng hái tíchū le lǐxiǎng IGV xìtǒng de wǔ gè guǎnjiàn mókuài, bìng fēnxi le měi gè mókuài de jìshù tiǎozhàn hé wèilái fāngxiàng.",
        "vocab": "[\n    {\"word\": \"新兴\", \"pinyin\": \"xīn xīng\", \"trans\": \"emerging\"},\n    {\"word\": \"互动\", \"pinyin\": \"hù dòng\", \"trans\": \"interactive\"},\n    {\"word\": \"生成\", \"pinyin\": \"shēng chéng\", \"trans\": \"generate\"},\n    {\"word\": \"高质量\", \"pinyin\": \"gāo zhì liàng\", \"trans\": \"high quality\"},\n    {\"word\": \"控制\", \"pinyin\": \"kòng zhì\", \"trans\": \"control\"},\n    {\"word\": \"信号\", \"pinyin\": \"xìn hào\", \"trans\": \"signal\"},\n    {\"word\": \"反馈\", \"pinyin\": \"fǎn kuì\", \"trans\": \"feedback\"},\n    {\"word\": \"参与\", \"pinyin\": \"cān yù\", \"trans\": \"participate\"},\n    {\"word\": \"人工智能\", \"pinyin\": \"rén gōng zhì néng\", \"trans\": \"artificial intelligence\"},\n    {\"word\": \"自动驾驶\", \"pinyin\": \"zì dòng jià shǐ\", \"trans\": \"autonomous driving\"},\n    {\"word\": \"领域\", \"pinyin\": \"lǐng yù\", \"trans\": \"field\"},\n    {\"word\": \"重要\", \"pinyin\": \"zhòng yào\", \"trans\": \"important\"},\n    {\"word\": \"应用\", \"pinyin\": \"yìng yòng\", \"trans\": \"application\"},\n    {\"word\": \"理想\", \"pinyin\": \"lǐ xiǎng\", \"trans\": \"ideal\"},\n    {\"word\": \"系统\", \"pinyin\": \"xì tǒng\", \"trans\": \"system\"},\n    {\"word\": \"关键\", \"pinyin\": \"guān jiàn\", \"trans\": \"key\"},\n    {\"word\": \"模块\", \"pinyin\": \"mó kuài\", \"trans\": \"module\"},\n    {\"word\": \"技术\", \"pinyin\": \"jì shù\", \"trans\": \"technology\"},\n    {\"word\": \"挑战\", \"pinyin\": \"tiǎo zhàn\", \"trans\": \"challenge\"},\n    {\"word\": \"未来\", \"pinyin\": \"wèi lái\", \"trans\": \"future\"},\n    {\"word\": \"方向\", \"pinyin\": \"fāng xiàng\", \"trans\": \"direction\"}\n]",
        "trans": "This article introduces an emerging technology: Interactive Generative Video (IGV). It combines generative and interactive functions to produce high-quality video content and allows users to participate through control signals and response feedback. IGV has important applications in three major areas: gaming, artificial intelligence, and autonomous driving. The article also proposes five key modules for an ideal IGV system and analyzes the technical challenges and future directions for each module.",
        "update_ts": "2025-05-04 12:44"
    }
}