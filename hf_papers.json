{
    "date": {
        "ru": "4 ноября",
        "en": "November 4",
        "zh": "11月4日"
    },
    "time_utc": "2024-11-04 12:24",
    "weekday": 0,
    "issue_id": 413,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2410.23218",
            "title": "OS-ATLAS: A Foundation Action Model for Generalist GUI Agents",
            "url": "https://huggingface.co/papers/2410.23218",
            "abstract": "Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision. Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD) scenarios. To facilitate future research in this area, we developed OS-Atlas - a foundational GUI action model that excels at GUI grounding and OOD agentic tasks through innovations in both data and modeling. We have invested significant engineering effort in developing an open-source toolkit for synthesizing GUI grounding data across multiple platforms, including Windows, Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing the largest open-source cross-platform GUI grounding corpus to date, which contains over 13 million GUI elements. This dataset, combined with innovations in model training, provides a solid foundation for OS-Atlas to understand GUI screenshots and generalize to unseen interfaces. Through extensive evaluation across six benchmarks spanning three different platforms (mobile, desktop, and web), OS-Atlas demonstrates significant performance improvements over previous state-of-the-art models. Our evaluation also uncovers valuable insights into continuously improving and scaling the agentic capabilities of open-source VLMs.",
            "score": 18,
            "issue_id": 410,
            "pub_date": "2024-10-30",
            "pub_date_card": {
                "ru": "30 октября",
                "en": "October 30",
                "zh": "10月30日"
            },
            "hash": "d7a3f0fd08f934d5",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#agents",
                    "#training",
                    "#benchmark"
                ],
                "emoji": "🖥️",
                "ru": {
                    "title": "OS-Atlas: Открытая модель для универсального взаимодействия с GUI",
                    "desc": "Исследователи разработали OS-Atlas - основополагающую модель для взаимодействия с графическим интерфейсом пользователя (GUI). Модель использует инновационный подход к данным и моделированию, что позволяет ей эффективно работать с GUI и решать задачи вне распределения (OOD). Авторы создали открытый набор инструментов для синтеза данных о GUI на различных платформах и выпустили крупнейший открытый кросс-платформенный корпус, содержащий более 13 миллионов элементов GUI. OS-Atlas демонстрирует значительное улучшение производительности по сравнению с предыдущими моделями на шести тестовых наборах, охватывающих мобильные, настольные и веб-платформы."
                },
                "en": {
                    "title": "Empowering Open-Source GUI Agents with OS-Atlas",
                    "desc": "This paper introduces OS-Atlas, an open-source foundational model designed for GUI grounding and Out-Of-Distribution (OOD) tasks. It addresses the performance gap between commercial Vision-Language Models (VLMs) and open-source alternatives by providing a comprehensive toolkit for synthesizing GUI grounding data across various platforms. The authors present the largest open-source cross-platform GUI grounding dataset, featuring over 13 million GUI elements, which enhances the model's ability to understand and generalize from GUI screenshots. Extensive evaluations show that OS-Atlas outperforms previous models, offering insights for further advancements in open-source VLM capabilities."
                },
                "zh": {
                    "title": "开源GUI模型OS-Atlas：提升界面理解能力的创新之路",
                    "desc": "本论文介绍了OS-Atlas，一个开源的GUI动作模型，专注于GUI定位和超出分布（OOD）任务。我们开发了一个工具包，可以在多个平台上合成GUI定位数据，包括Windows、Linux、MacOS、Android和网页。OS-Atlas利用超过1300万个GUI元素的数据集，结合创新的模型训练方法，显著提高了对GUI截图的理解能力。通过在六个基准测试中进行广泛评估，OS-Atlas在移动、桌面和网页平台上表现出显著的性能提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00322",
            "title": "Constant Acceleration Flow",
            "url": "https://huggingface.co/papers/2411.00322",
            "abstract": "Rectified flow and reflow procedures have significantly advanced fast generation by progressively straightening ordinary differential equation (ODE) flows. They operate under the assumption that image and noise pairs, known as couplings, can be approximated by straight trajectories with constant velocity. However, we observe that modeling with constant velocity and using reflow procedures have limitations in accurately learning straight trajectories between pairs, resulting in suboptimal performance in few-step generation. To address these limitations, we introduce Constant Acceleration Flow (CAF), a novel framework based on a simple constant acceleration equation. CAF introduces acceleration as an additional learnable variable, allowing for more expressive and accurate estimation of the ODE flow. Moreover, we propose two techniques to further improve estimation accuracy: initial velocity conditioning for the acceleration model and a reflow process for the initial velocity. Our comprehensive studies on toy datasets, CIFAR-10, and ImageNet 64x64 demonstrate that CAF outperforms state-of-the-art baselines for one-step generation. We also show that CAF dramatically improves few-step coupling preservation and inversion over Rectified flow. Code is available at https://github.com/mlvlab/CAF{https://github.com/mlvlab/CAF}.",
            "score": 8,
            "issue_id": 412,
            "pub_date": "2024-11-01",
            "pub_date_card": {
                "ru": "1 ноября",
                "en": "November 1",
                "zh": "11月1日"
            },
            "hash": "edca1b3005d37bab",
            "data": {
                "categories": [
                    "#cv",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "CAF: Ускоряем генерацию изображений с помощью постоянного ускорения",
                    "desc": "Статья представляет новый подход к ускорению генерации изображений в машинном обучении, называемый Constant Acceleration Flow (CAF). В отличие от существующих методов, CAF использует модель постоянного ускорения вместо постоянной скорости для более точного моделирования траекторий между парами изображений и шума. Авторы вводят ускорение как дополнительную обучаемую переменную и предлагают техники улучшения точности оценки, включая обусловливание начальной скорости и процесс рефлоу. Эксперименты на различных наборах данных показывают превосходство CAF над современными методами в одношаговой генерации и сохранении связей при генерации за несколько шагов."
                },
                "en": {
                    "title": "Accelerating Image Generation with Constant Acceleration Flow",
                    "desc": "This paper presents a new method called Constant Acceleration Flow (CAF) to improve the generation of images using ordinary differential equations (ODEs). Traditional methods assume that the flow between images and noise can be modeled as straight lines moving at a constant speed, which can lead to inaccuracies. CAF enhances this by introducing acceleration as a learnable variable, allowing for more flexible and precise modeling of the flow. The authors demonstrate that CAF outperforms existing methods in generating images with fewer steps while maintaining better quality and accuracy."
                },
                "zh": {
                    "title": "常加速度流：提升图像生成的新方法",
                    "desc": "本文提出了一种新的框架，称为常加速度流（CAF），用于改进图像生成过程。CAF通过引入加速度作为可学习变量，能够更准确地估计常微分方程（ODE）流。与传统的直线轨迹假设不同，CAF允许在生成过程中考虑加速度，从而提高生成质量。实验结果表明，CAF在少步生成和耦合保持方面优于现有的最先进方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00776",
            "title": "Randomized Autoregressive Visual Generation",
            "url": "https://huggingface.co/papers/2411.00776",
            "abstract": "This paper presents Randomized AutoRegressive modeling (RAR) for visual generation, which sets a new state-of-the-art performance on the image generation task while maintaining full compatibility with language modeling frameworks. The proposed RAR is simple: during a standard autoregressive training process with a next-token prediction objective, the input sequence-typically ordered in raster form-is randomly permuted into different factorization orders with a probability r, where r starts at 1 and linearly decays to 0 over the course of training. This annealing training strategy enables the model to learn to maximize the expected likelihood over all factorization orders and thus effectively improve the model's capability of modeling bidirectional contexts. Importantly, RAR preserves the integrity of the autoregressive modeling framework, ensuring full compatibility with language modeling while significantly improving performance in image generation. On the ImageNet-256 benchmark, RAR achieves an FID score of 1.48, not only surpassing prior state-of-the-art autoregressive image generators but also outperforming leading diffusion-based and masked transformer-based methods. Code and models will be made available at https://github.com/bytedance/1d-tokenizer",
            "score": 7,
            "issue_id": 408,
            "pub_date": "2024-11-01",
            "pub_date_card": {
                "ru": "1 ноября",
                "en": "November 1",
                "zh": "11月1日"
            },
            "hash": "0cc2c0f19f735f79",
            "data": {
                "categories": [
                    "#cv",
                    "#architecture",
                    "#benchmark"
                ],
                "emoji": "🎨",
                "ru": {
                    "title": "Случайная перестановка для улучшения генерации изображений",
                    "desc": "Статья представляет метод Randomized AutoRegressive modeling (RAR) для генерации изображений. RAR использует случайную перестановку входной последовательности во время обучения авторегрессионной модели, что позволяет учитывать двунаправленный контекст. Метод сохраняет совместимость с языковыми моделями и достигает нового state-of-the-art результата на бенчмарке ImageNet-256 с показателем FID 1.48. RAR превосходит как авторегрессионные, так и диффузионные методы генерации изображений."
                },
                "en": {
                    "title": "Revolutionizing Image Generation with Randomized AutoRegressive Modeling",
                    "desc": "This paper introduces Randomized AutoRegressive modeling (RAR), a novel approach for generating images that enhances performance while remaining compatible with existing language modeling techniques. RAR employs a unique training method where the input sequence is randomly shuffled during the autoregressive training process, allowing the model to learn from various factorization orders. This strategy helps the model to better understand and utilize bidirectional contexts, leading to improved image generation capabilities. The results show that RAR achieves a remarkable FID score of 1.48 on the ImageNet-256 benchmark, outperforming previous state-of-the-art methods in both autoregressive and diffusion-based image generation."
                },
                "zh": {
                    "title": "随机自回归建模：图像生成的新突破",
                    "desc": "本文提出了一种随机自回归建模（RAR）方法用于视觉生成，在图像生成任务上设定了新的最先进性能，同时与语言建模框架完全兼容。RAR方法简单：在标准的自回归训练过程中，输入序列通常按光栅形式排列，但以概率r随机打乱为不同的因子化顺序，r从1开始，随着训练线性衰减到0。这种退火训练策略使模型能够学习最大化所有因子化顺序的期望似然，从而有效提高模型建模双向上下文的能力。RAR保持了自回归建模框架的完整性，确保与语言建模的完全兼容，同时在图像生成中显著提高了性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00412",
            "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
            "url": "https://huggingface.co/papers/2411.00412",
            "abstract": "Large Language Models (LLMs) demonstrate promising capabilities in solving simple scientific problems but often produce hallucinations for complex ones. While integrating LLMs with tools can increase reliability, this approach typically results in over-reliance on tools, diminishing the model's ability to solve simple problems through basic reasoning. In contrast, human experts first assess problem complexity using domain knowledge before choosing an appropriate solution approach. Inspired by this human problem-solving process, we propose a novel two-component fine-tuning method. In the first component World Knowledge Distillation (WKD), LLMs learn directly from solutions generated using tool's information to internalize domain knowledge. In the second component Tool Usage Adaptation (TUA), we partition problems into easy and hard categories based on the model's direct answering accuracy. While maintaining the same alignment target for easy problems as in WKD, we train the model to intelligently switch to tool usage for more challenging problems. We validate our method on six scientific benchmark datasets, spanning mathematics, climate science and epidemiology. On average, our models demonstrate a 28.18% improvement in answer accuracy and a 13.89% increase in tool usage precision across all datasets, surpassing state-of-the-art models including GPT-4o and Claude-3.5.",
            "score": 7,
            "issue_id": 407,
            "pub_date": "2024-11-01",
            "pub_date_card": {
                "ru": "1 ноября",
                "en": "November 1",
                "zh": "11月1日"
            },
            "hash": "27e4deefc7d09df0",
            "data": {
                "categories": [
                    "#rlhf",
                    "#alignment",
                    "#training",
                    "#benchmark",
                    "#math"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Умное переключение: как научить ИИ эффективно решать задачи разной сложности",
                    "desc": "Исследование посвящено улучшению способности больших языковых моделей (LLM) решать научные задачи. Авторы предлагают двухкомпонентный метод дообучения: дистилляция мировых знаний и адаптация использования инструментов. Этот подход позволяет LLM эффективно решать простые задачи с помощью базовых рассуждений, а для сложных - прибегать к инструментам. Метод показал значительное улучшение точности ответов и точности использования инструментов на шести научных наборах данных."
                },
                "en": {
                    "title": "Enhancing LLMs: Smart Tool Use for Complex Problems",
                    "desc": "This paper addresses the limitations of Large Language Models (LLMs) in solving complex scientific problems, which often lead to inaccuracies or 'hallucinations'. The authors propose a two-component fine-tuning method that mimics human problem-solving strategies by first assessing problem complexity. The first component, World Knowledge Distillation (WKD), allows LLMs to learn from solutions that utilize external tools, while the second component, Tool Usage Adaptation (TUA), helps the model categorize problems as easy or hard and decide when to use tools. The proposed method shows significant improvements in accuracy and tool usage precision across various scientific datasets, outperforming existing models."
                },
                "zh": {
                    "title": "智能切换，提升模型解决问题的能力",
                    "desc": "大型语言模型（LLMs）在解决简单科学问题方面表现出色，但在复杂问题上常常出现幻觉。我们提出了一种新颖的双组件微调方法，模仿人类专家的解决问题过程。第一个组件是世界知识蒸馏（WKD），使LLMs从工具生成的解决方案中学习领域知识。第二个组件是工具使用适应（TUA），根据模型的直接回答准确性将问题分为简单和困难两类，从而提高模型在复杂问题上的工具使用能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00027",
            "title": "Personalization of Large Language Models: A Survey",
            "url": "https://huggingface.co/papers/2411.00027",
            "abstract": "Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs for personalization-related downstream applications, such as recommendation systems. In this work, we bridge the gap between these two separate main directions for the first time by introducing a taxonomy for personalized LLM usage and summarizing the key differences and challenges. We provide a formalization of the foundations of personalized LLMs that consolidates and expands notions of personalization of LLMs, defining and discussing novel facets of personalization, usage, and desiderata of personalized LLMs. We then unify the literature across these diverse fields and usage scenarios by proposing systematic taxonomies for the granularity of personalization, personalization techniques, datasets, evaluation methods, and applications of personalized LLMs. Finally, we highlight challenges and important open problems that remain to be addressed. By unifying and surveying recent research using the proposed taxonomies, we aim to provide a clear guide to the existing literature and different facets of personalization in LLMs, empowering both researchers and practitioners.",
            "score": 5,
            "issue_id": 409,
            "pub_date": "2024-10-29",
            "pub_date_card": {
                "ru": "29 октября",
                "en": "October 29",
                "zh": "10月29日"
            },
            "hash": "a190b2e727d2d0ad",
            "data": {
                "categories": [
                    "#survey",
                    "#multimodal",
                    "#dataset"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "Объединяя подходы: комплексный взгляд на персонализацию больших языковых моделей",
                    "desc": "Статья посвящена персонализации больших языковых моделей (LLM) и объединяет два основных направления исследований в этой области. Авторы предлагают таксономию использования персонализированных LLM, формализуют основы и расширяют понятия персонализации. Они систематизируют литературу по различным аспектам, включая методы персонализации, наборы данных и способы оценки. В работе также выделяются нерешенные проблемы и открытые вопросы в данной области исследований."
                },
                "en": {
                    "title": "Bridging Personalization Gaps in Large Language Models",
                    "desc": "This paper addresses the growing need for personalization in Large Language Models (LLMs) by creating a comprehensive framework that connects personalized text generation with applications like recommendation systems. It introduces a taxonomy that categorizes various aspects of personalized LLMs, including techniques, datasets, and evaluation methods. The authors formalize the concept of personalization in LLMs, discussing its different dimensions and the challenges faced in this area. By synthesizing existing research and identifying open problems, the paper serves as a guide for researchers and practitioners interested in the personalization of LLMs."
                },
                "zh": {
                    "title": "统一个性化大型语言模型的研究",
                    "desc": "本文探讨了大型语言模型（LLMs）个性化的重要性及其应用。我们首次将个性化文本生成与个性化相关的下游应用（如推荐系统）结合起来，提出了个性化LLMs的分类法。文章对个性化LLMs的基础进行了形式化定义，并讨论了个性化的不同方面、使用场景和需求。最后，我们总结了现有文献，并指出了个性化LLMs面临的挑战和未解决的问题，以帮助研究人员和从业者更好地理解这一领域。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00233",
            "title": "SambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models",
            "url": "https://huggingface.co/papers/2411.00233",
            "abstract": "The state of health (SOH) of a Li-ion battery is a critical parameter that determines the remaining capacity and the remaining lifetime of the battery. In this paper, we propose SambaMixer a novel structured state space model (SSM) for predicting the state of health of Li-ion batteries. The proposed SSM is based on the MambaMixer architecture, which is designed to handle multi-variate time signals. We evaluate our model on the NASA battery discharge dataset and show that our model outperforms the state-of-the-art on this dataset. We further introduce a novel anchor-based resampling method which ensures time signals are of the expected length while also serving as augmentation technique. Finally, we condition prediction on the sample time and the cycle time difference using positional encodings to improve the performance of our model and to learn recuperation effects. Our results proof that our model is able to predict the SOH of Li-ion batteries with high accuracy and robustness.",
            "score": 4,
            "issue_id": 410,
            "pub_date": "2024-10-31",
            "pub_date_card": {
                "ru": "31 октября",
                "en": "October 31",
                "zh": "10月31日"
            },
            "hash": "6361ca66f5ca137f",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#benchmark",
                    "#architecture",
                    "#training",
                    "#medicine"
                ],
                "emoji": "🔋",
                "ru": {
                    "title": "Точное прогнозирование срока службы аккумуляторов с помощью глубокого обучения",
                    "desc": "Статья представляет SambaMixer - новую модель структурированного пространства состояний для прогнозирования состояния здоровья литий-ионных аккумуляторов. Модель основана на архитектуре MambaMixer и способна обрабатывать многомерные временные сигналы. Авторы предлагают метод ресэмплинга на основе якорей для нормализации длины сигналов и аугментации данных. Использование позиционного кодирования времени выборки и разницы циклов позволяет модели учитывать эффекты восстановления аккумуляторов."
                },
                "en": {
                    "title": "SambaMixer: Revolutionizing Li-ion Battery Health Prediction",
                    "desc": "This paper introduces SambaMixer, a new structured state space model (SSM) designed to predict the state of health (SOH) of Li-ion batteries. The model utilizes the MambaMixer architecture to effectively process multi-variate time signals, enhancing prediction accuracy. It is evaluated against the NASA battery discharge dataset, demonstrating superior performance compared to existing methods. Additionally, the paper presents an innovative anchor-based resampling technique and employs positional encodings to improve predictions by accounting for time-related factors."
                },
                "zh": {
                    "title": "高效预测锂离子电池健康状态的新方法",
                    "desc": "本文提出了一种新颖的结构化状态空间模型（SSM），用于预测锂离子电池的健康状态（SOH）。该模型基于MambaMixer架构，能够处理多变量时间信号。我们在NASA电池放电数据集上评估了该模型，结果显示其性能优于现有的最先进方法。此外，我们引入了一种新颖的基于锚点的重采样方法，以确保时间信号的预期长度，并作为数据增强技术。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.23775",
            "title": "In-Context LoRA for Diffusion Transformers",
            "url": "https://huggingface.co/papers/2410.23775",
            "abstract": "Recent research arXiv:2410.15027 has explored the use of diffusion transformers (DiTs) for task-agnostic image generation by simply concatenating attention tokens across images. However, despite substantial computational resources, the fidelity of the generated images remains suboptimal. In this study, we reevaluate and streamline this framework by hypothesizing that text-to-image DiTs inherently possess in-context generation capabilities, requiring only minimal tuning to activate them. Through diverse task experiments, we qualitatively demonstrate that existing text-to-image DiTs can effectively perform in-context generation without any tuning. Building on this insight, we propose a remarkably simple pipeline to leverage the in-context abilities of DiTs: (1) concatenate images instead of tokens, (2) perform joint captioning of multiple images, and (3) apply task-specific LoRA tuning using small datasets (e.g., 20sim 100 samples) instead of full-parameter tuning with large datasets. We name our models In-Context LoRA (IC-LoRA). This approach requires no modifications to the original DiT models, only changes to the training data. Remarkably, our pipeline generates high-fidelity image sets that better adhere to prompts. While task-specific in terms of tuning data, our framework remains task-agnostic in architecture and pipeline, offering a powerful tool for the community and providing valuable insights for further research on product-level task-agnostic generation systems. We release our code, data, and models at https://github.com/ali-vilab/In-Context-LoRA",
            "score": 4,
            "issue_id": 407,
            "pub_date": "2024-10-31",
            "pub_date_card": {
                "ru": "31 октября",
                "en": "October 31",
                "zh": "10月31日"
            },
            "hash": "748dab03a37a21a4",
            "data": {
                "categories": [
                    "#cv",
                    "#diffusion",
                    "#training"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Раскрытие скрытого потенциала DiT для многозадачной генерации изображений",
                    "desc": "Исследование предлагает новый подход к использованию диффузионных трансформеров (DiT) для генерации изображений в различных задачах. Авторы обнаружили, что существующие модели DiT для преобразования текста в изображение уже обладают способностью к контекстной генерации без дополнительной настройки. На основе этого наблюдения они разработали простой pipeline, включающий конкатенацию изображений, совместное создание подписей и применение LoRA-тюнинга на небольших датасетах. Предложенный метод, названный IC-LoRA, позволяет генерировать высококачественные наборы изображений, лучше соответствующие заданным промптам."
                },
                "en": {
                    "title": "Unlocking In-Context Generation with IC-LoRA",
                    "desc": "This paper investigates the use of diffusion transformers (DiTs) for generating images without being tied to specific tasks. The authors propose that DiTs can generate images effectively with minimal adjustments, leveraging their inherent in-context generation capabilities. They introduce a new method called In-Context LoRA (IC-LoRA), which simplifies the process by concatenating images and using joint captioning, along with small dataset tuning. This approach enhances the quality of generated images while maintaining a flexible architecture that can adapt to various tasks without extensive retraining."
                },
                "zh": {
                    "title": "激活上下文生成能力，提升图像生成质量",
                    "desc": "本研究探讨了扩散变换器（DiTs）在无任务特定的图像生成中的应用。我们提出，文本到图像的DiTs本身具备上下文生成能力，只需少量调整即可激活。通过实验，我们展示了现有的文本到图像DiTs能够在不调整的情况下有效进行上下文生成。我们提出了一种简单的流程，利用DiTs的上下文能力，生成高保真度的图像集，且不需要对原始模型进行修改。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.21157",
            "title": "M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation",
            "url": "https://huggingface.co/papers/2410.21157",
            "abstract": "Repository-level code completion has drawn great attention in software engineering, and several benchmark datasets have been introduced. However, existing repository-level code completion benchmarks usually focus on a limited number of languages (<5), which cannot evaluate the general code intelligence abilities across different languages for existing code Large Language Models (LLMs). Besides, the existing benchmarks usually report overall average scores of different languages, where the fine-grained abilities in different completion scenarios are ignored. Therefore, to facilitate the research of code LLMs in multilingual scenarios, we propose a massively multilingual repository-level code completion benchmark covering 18 programming languages (called M2RC-EVAL), and two types of fine-grained annotations (i.e., bucket-level and semantic-level) on different completion scenarios are provided, where we obtain these annotations based on the parsed abstract syntax tree. Moreover, we also curate a massively multilingual instruction corpora M2RC- INSTRUCT dataset to improve the repository-level code completion abilities of existing code LLMs. Comprehensive experimental results demonstrate the effectiveness of our M2RC-EVAL and M2RC-INSTRUCT.",
            "score": 3,
            "issue_id": 408,
            "pub_date": "2024-10-28",
            "pub_date_card": {
                "ru": "28 октября",
                "en": "October 28",
                "zh": "10月28日"
            },
            "hash": "d6a0779456870cae",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#plp",
                    "#multilingual"
                ],
                "emoji": "🖥️",
                "ru": {
                    "title": "Многоязычный бенчмарк для оценки LLM в автодополнении кода",
                    "desc": "Статья представляет новый бенчмарк M2RC-EVAL для оценки способностей больших языковых моделей (LLM) в задаче автодополнения кода на уровне репозитория. Бенчмарк охватывает 18 языков программирования и включает детальные аннотации для различных сценариев дополнения. Авторы также создали набор данных M2RC-INSTRUCT для улучшения возможностей существующих LLM в этой задаче. Эксперименты подтверждают эффективность предложенных инструментов."
                },
                "en": {
                    "title": "Empowering Multilingual Code Completion with M2RC-EVAL and M2RC-INSTRUCT",
                    "desc": "This paper introduces a new benchmark called M2RC-EVAL for repository-level code completion that supports 18 programming languages, addressing the limitations of existing benchmarks that only cover a few languages. It provides fine-grained annotations based on abstract syntax trees, allowing for a more detailed evaluation of code completion scenarios. Additionally, the authors present the M2RC-INSTRUCT dataset to enhance the performance of code Large Language Models (LLMs) in multilingual contexts. Experimental results show that both M2RC-EVAL and M2RC-INSTRUCT significantly improve the capabilities of existing code LLMs."
                },
                "zh": {
                    "title": "多语言代码补全的新基准测试",
                    "desc": "本论文提出了一种新的多语言代码补全基准测试，称为M2RC-EVAL，涵盖了18种编程语言。现有的基准测试通常只关注少数几种语言，无法全面评估大型语言模型在不同语言中的代码智能能力。此外，M2RC-EVAL提供了细粒度的注释，帮助研究人员更好地理解模型在不同补全场景下的表现。为了进一步提升代码补全能力，我们还构建了一个多语言指令数据集M2RC-INSTRUCT。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.22901",
            "title": "HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level and Fidelity-Rich Conditions in Diffusion Models",
            "url": "https://huggingface.co/papers/2410.22901",
            "abstract": "We propose an effective method for inserting adapters into text-to-image foundation models, which enables the execution of complex downstream tasks while preserving the generalization ability of the base model. The core idea of this method is to optimize the attention mechanism related to 2D feature maps, which enhances the performance of the adapter. This approach was validated on the task of meme video generation and achieved significant results. We hope this work can provide insights for post-training tasks of large text-to-image models. Additionally, as this method demonstrates good compatibility with SD1.5 derivative models, it holds certain value for the open-source community. Therefore, we will release the related code (https://songkey.github.io/hellomeme).",
            "score": 2,
            "issue_id": 408,
            "pub_date": "2024-10-30",
            "pub_date_card": {
                "ru": "30 октября",
                "en": "October 30",
                "zh": "10月30日"
            },
            "hash": "801963cbdcf75d7b",
            "data": {
                "categories": [
                    "#cv",
                    "#video",
                    "#training",
                    "#architecture"
                ],
                "emoji": "🎨",
                "ru": {
                    "title": "Адаптеры для текст-в-изображение моделей: новый подход к генерации мемов",
                    "desc": "Статья представляет эффективный метод внедрения адаптеров в базовые модели преобразования текста в изображение. Этот подход оптимизирует механизм внимания, связанный с двумерными картами признаков, что улучшает производительность адаптера. Метод был успешно применен для генерации мемов в видеоформате. Авторы отмечают совместимость метода с производными моделями SD1.5, что делает его ценным для сообщества открытого исходного кода."
                },
                "en": {
                    "title": "Enhancing Text-to-Image Models with Adapter Integration",
                    "desc": "This paper presents a novel method for integrating adapters into text-to-image foundation models, allowing them to perform complex tasks while maintaining their ability to generalize. The method focuses on optimizing the attention mechanism associated with 2D feature maps, which significantly boosts the performance of the adapters. The effectiveness of this approach was demonstrated through the task of meme video generation, yielding impressive results. The authors aim to contribute to the open-source community by sharing their code and providing insights for post-training tasks in large text-to-image models."
                },
                "zh": {
                    "title": "适配器插入：提升文本到图像模型的能力",
                    "desc": "本文提出了一种有效的方法，将适配器插入文本到图像的基础模型中，从而在执行复杂的下游任务时保持基础模型的泛化能力。该方法的核心思想是优化与二维特征图相关的注意力机制，从而增强适配器的性能。我们在生成表情包视频的任务上验证了该方法，并取得了显著的结果。希望这项工作能为大型文本到图像模型的后训练任务提供一些见解，并为开源社区带来价值。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00680",
            "title": "Zipfian Whitening",
            "url": "https://huggingface.co/papers/2411.00680",
            "abstract": "The word embedding space in neural models is skewed, and correcting this can improve task performance. We point out that most approaches for modeling, correcting, and measuring the symmetry of an embedding space implicitly assume that the word frequencies are uniform; in reality, word frequencies follow a highly non-uniform distribution, known as Zipf's law. Surprisingly, simply performing PCA whitening weighted by the empirical word frequency that follows Zipf's law significantly improves task performance, surpassing established baselines. From a theoretical perspective, both our approach and existing methods can be clearly categorized: word representations are distributed according to an exponential family with either uniform or Zipfian base measures. By adopting the latter approach, we can naturally emphasize informative low-frequency words in terms of their vector norm, which becomes evident from the information-geometric perspective, and in terms of the loss functions for imbalanced classification. Additionally, our theory corroborates that popular natural language processing methods, such as skip-gram negative sampling, WhiteningBERT, and headless language models, work well just because their word embeddings encode the empirical word frequency into the underlying probabilistic model.",
            "score": 1,
            "issue_id": 413,
            "pub_date": "2024-11-01",
            "pub_date_card": {
                "ru": "1 ноября",
                "en": "November 1",
                "zh": "11月1日"
            },
            "hash": "26e33c177a131240",
            "data": {
                "categories": [
                    "#data",
                    "#math",
                    "#interpretability",
                    "#transfer_learning"
                ],
                "emoji": "📊",
                "ru": {
                    "title": "Улучшение векторных представлений слов с учетом закона Ципфа",
                    "desc": "Статья посвящена проблеме асимметрии пространства векторных представлений слов в нейронных моделях. Авторы предлагают метод коррекции этой асимметрии с учетом закона Ципфа о распределении частот слов. Простое применение PCA отбеливания, взвешенного по эмпирической частоте слов, значительно улучшает производительность модели на различных задачах. Теоретический анализ показывает, что этот подход естественным образом подчеркивает информативные низкочастотные слова и объясняет эффективность популярных методов обработки естественного языка."
                },
                "en": {
                    "title": "Correcting Skewness in Word Embeddings for Better Performance",
                    "desc": "This paper discusses how the word embedding space in neural models can be improved by addressing its skewness. It highlights that many existing methods assume uniform word frequencies, while in reality, word frequencies follow Zipf's law, which is highly non-uniform. The authors propose using PCA whitening that is weighted by empirical word frequencies, leading to significant improvements in task performance. Their theoretical framework categorizes word representations based on exponential families, emphasizing the importance of low-frequency words and providing insights into popular NLP methods."
                },
                "zh": {
                    "title": "校正词嵌入空间，提升任务性能！",
                    "desc": "这篇论文探讨了神经模型中的词嵌入空间偏斜问题，并提出了通过校正这一偏斜来提高任务性能的方法。研究表明，现有的许多模型假设词频是均匀分布的，但实际上，词频遵循一种称为齐夫定律的高度非均匀分布。通过对词频进行加权的主成分分析（PCA）白化，显著提升了任务性能，超越了已有的基准。理论上，我们的方法与现有方法可以清晰地分类，强调了低频词的重要性，并解释了流行的自然语言处理方法为何有效。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00030",
            "title": "WikiNER-fr-gold: A Gold-Standard NER Corpus",
            "url": "https://huggingface.co/papers/2411.00030",
            "abstract": "We address in this article the the quality of the WikiNER corpus, a multilingual Named Entity Recognition corpus, and provide a consolidated version of it. The annotation of WikiNER was produced in a semi-supervised manner i.e. no manual verification has been carried out a posteriori. Such corpus is called silver-standard. In this paper we propose WikiNER-fr-gold which is a revised version of the French proportion of WikiNER. Our corpus consists of randomly sampled 20% of the original French sub-corpus (26,818 sentences with 700k tokens). We start by summarizing the entity types included in each category in order to define an annotation guideline, and then we proceed to revise the corpus. Finally we present an analysis of errors and inconsistency observed in the WikiNER-fr corpus, and we discuss potential future work directions.",
            "score": 1,
            "issue_id": 411,
            "pub_date": "2024-10-29",
            "pub_date_card": {
                "ru": "29 октября",
                "en": "October 29",
                "zh": "10月29日"
            },
            "hash": "5f3e739256c5e800",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#multilingual"
                ],
                "emoji": "🏷️",
                "ru": {
                    "title": "Золотой стандарт для французского NER: улучшение WikiNER",
                    "desc": "Статья посвящена улучшению качества корпуса WikiNER для распознавания именованных сущностей на нескольких языках. Авторы создали WikiNER-fr-gold - вручную проверенную версию французской части корпуса, состоящую из 20% оригинальных данных. Они разработали руководство по аннотации, пересмотрели корпус и проанализировали ошибки в исходном WikiNER-fr. Исследование направлено на повышение точности обучения моделей NER на французском языке."
                },
                "en": {
                    "title": "Enhancing Named Entity Recognition with WikiNER-fr-gold",
                    "desc": "This paper focuses on improving the quality of the WikiNER corpus, which is used for Named Entity Recognition (NER) in multiple languages. The original WikiNER corpus was created using a semi-supervised approach, resulting in a silver-standard dataset without manual verification. The authors introduce WikiNER-fr-gold, a refined version of the French subset of WikiNER, based on a carefully sampled 20% of the original data. They outline the types of entities included, establish annotation guidelines, and analyze errors in the original corpus to suggest future improvements."
                },
                "zh": {
                    "title": "提升WikiNER语料库质量的探索",
                    "desc": "本文讨论了WikiNER语料库的质量，这是一个多语言命名实体识别语料库，并提供了一个整合版本。WikiNER的标注是以半监督的方式生成的，即没有进行后期的人工验证，因此该语料库被称为银标准。我们提出了WikiNER-fr-gold，这是WikiNER法语部分的修订版本，包含了原法语子语料库的20%随机抽样（26,818个句子，700k个标记）。最后，我们分析了WikiNER-fr语料库中观察到的错误和不一致，并讨论了未来的研究方向。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.22370",
            "title": "Survey of User Interface Design and Interaction Techniques in Generative AI Applications",
            "url": "https://huggingface.co/papers/2410.22370",
            "abstract": "The applications of generative AI have become extremely impressive, and the interplay between users and AI is even more so. Current human-AI interaction literature has taken a broad look at how humans interact with generative AI, but it lacks specificity regarding the user interface designs and patterns used to create these applications. Therefore, we present a survey that comprehensively presents taxonomies of how a human interacts with AI and the user interaction patterns designed to meet the needs of a variety of relevant use cases. We focus primarily on user-guided interactions, surveying interactions that are initiated by the user and do not include any implicit signals given by the user. With this survey, we aim to create a compendium of different user-interaction patterns that can be used as a reference for designers and developers alike. In doing so, we also strive to lower the entry barrier for those attempting to learn more about the design of generative AI applications.",
            "score": 1,
            "issue_id": 409,
            "pub_date": "2024-10-28",
            "pub_date_card": {
                "ru": "28 октября",
                "en": "October 28",
                "zh": "10月28日"
            },
            "hash": "9701ceb4e85eeeba",
            "data": {
                "categories": [
                    "#survey",
                    "#multimodal"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Путеводитель по взаимодействию человека и ИИ",
                    "desc": "Статья представляет обзор таксономий взаимодействия человека с генеративным ИИ и паттернов пользовательского интерфейса для различных сценариев использования. Авторы фокусируются на взаимодействиях, инициируемых пользователем, без учета неявных сигналов. Цель работы - создать справочник паттернов взаимодействия для дизайнеров и разработчиков приложений генеративного ИИ. Исследование направлено на снижение входного барьера для тех, кто хочет изучить дизайн приложений генеративного ИИ."
                },
                "en": {
                    "title": "Enhancing User Interaction with Generative AI",
                    "desc": "This paper surveys the ways users interact with generative AI, focusing specifically on user-guided interactions. It identifies and categorizes various user interface designs and interaction patterns that cater to different use cases. By providing a comprehensive taxonomy, the authors aim to serve as a reference for designers and developers in creating more effective generative AI applications. The goal is to make it easier for newcomers to understand and engage with the design aspects of these technologies."
                },
                "zh": {
                    "title": "提升人机交互，设计更智能的生成式AI应用",
                    "desc": "本论文探讨了生成式人工智能（AI）与用户之间的互动，强调了用户界面设计的重要性。我们提供了一份全面的调查，分类了人类与AI的互动方式，特别关注用户主导的交互模式。通过这项调查，我们希望为设计师和开发者提供不同的用户交互模式参考，降低学习生成式AI应用设计的门槛。最终目标是提升人机交互的效率和用户体验。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00369",
            "title": "GRS-QA -- Graph Reasoning-Structured Question Answering Dataset",
            "url": "https://huggingface.co/papers/2411.00369",
            "abstract": "Large Language Models (LLMs) have excelled in multi-hop question-answering (M-QA) due to their advanced reasoning abilities. However, the impact of the inherent reasoning structures on LLM M-QA performance remains unclear, largely due to the absence of QA datasets that provide fine-grained reasoning structures. To address this gap, we introduce the Graph Reasoning-Structured Question Answering Dataset (GRS-QA), which includes both semantic contexts and reasoning structures for QA pairs. Unlike existing M-QA datasets, where different reasoning structures are entangled together, GRS-QA explicitly captures intricate reasoning pathways by constructing reasoning graphs, where nodes represent textual contexts and edges denote logical flows. These reasoning graphs of different structures enable a fine-grained evaluation of LLM reasoning capabilities across various reasoning structures. Our empirical analysis reveals that LLMs perform differently when handling questions with varying reasoning structures. This finding facilitates the exploration of textual structures as compared with semantics.",
            "score": 1,
            "issue_id": 409,
            "pub_date": "2024-11-01",
            "pub_date_card": {
                "ru": "1 ноября",
                "en": "November 1",
                "zh": "11月1日"
            },
            "hash": "b3e4773e065d1bc1",
            "data": {
                "categories": [
                    "#dataset",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Графы рассуждений раскрывают возможности языковых моделей",
                    "desc": "Статья представляет новый набор данных GRS-QA для оценки способностей больших языковых моделей (LLM) в многоходовых вопросно-ответных задачах. GRS-QA включает в себя как семантические контексты, так и структуры рассуждений для пар вопрос-ответ. Набор данных использует графы рассуждений, где узлы представляют текстовые контексты, а ребра обозначают логические связи. Эмпирический анализ показывает, что LLM по-разному справляются с вопросами, имеющими различные структуры рассуждений."
                },
                "en": {
                    "title": "Unlocking LLMs: Understanding Reasoning Structures in Multi-Hop QA",
                    "desc": "This paper discusses the performance of Large Language Models (LLMs) in multi-hop question-answering (M-QA) tasks, focusing on their reasoning abilities. The authors identify a gap in existing datasets that do not provide detailed reasoning structures, which are crucial for evaluating LLM performance. To fill this gap, they introduce the Graph Reasoning-Structured Question Answering Dataset (GRS-QA), which features reasoning graphs that clearly outline the logical pathways for answering questions. Their analysis shows that LLMs exhibit varying performance based on the complexity of the reasoning structures involved, highlighting the importance of understanding both textual and semantic elements in M-QA."
                },
                "zh": {
                    "title": "揭示推理结构对LLM表现的影响",
                    "desc": "大型语言模型（LLMs）在多跳问答（M-QA）中表现出色，主要得益于其先进的推理能力。然而，LLM在多跳问答中的表现受固有推理结构的影响尚不明确，主要是因为缺乏提供细粒度推理结构的问答数据集。为了解决这个问题，我们引入了图推理结构问答数据集（GRS-QA），该数据集为问答对提供了语义上下文和推理结构。与现有的M-QA数据集不同，GRS-QA通过构建推理图来明确捕捉复杂的推理路径，节点表示文本上下文，边表示逻辑流，从而实现对LLM推理能力的细粒度评估。"
                }
            }
        }
    ],
    "link_prev": "2024-11-01.html",
    "link_next": "2024-11-05.html",
    "short_date_prev": {
        "ru": "01.11",
        "en": "11/01",
        "zh": "11月1日"
    },
    "short_date_next": {
        "ru": "05.11",
        "en": "11/05",
        "zh": "11月5日"
    },
    "categories": {
        "#dataset": 6,
        "#data": 4,
        "#benchmark": 6,
        "#agents": 1,
        "#cv": 4,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 1,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 2,
        "#math": 2,
        "#multilingual": 2,
        "#architecture": 3,
        "#medicine": 1,
        "#training": 6,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 1,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 1,
        "#survey": 2,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#translation": 0
    },
    "zh": {
        "text": "这篇文章讨论了构建图形用户界面（GUI）代理的现有努力。目前主要依赖于强大的商业视觉语言模型（VLMs），如GPT-4o和GeminiProVision。开源VLMs在GUI理解和未见分布（OOD）场景中表现较差，因此实践者不太愿意使用。为了推动这一领域的研究，作者开发了OS-Atlas，这是一个擅长GUI理解和OOD任务的基础模型。他们还发布了一个包含1300多万GUI元素的跨平台数据集，并证明了OS-Atlas在多个基准测试中的显著性能提升。",
        "title": "OS-ATLAS: A Foundation Action Model for Generalist GUI Agents",
        "pinyin": "Zhè piān wénzhāng tǎolùn le gòujiàn túxíng yònghù jiēmiàn (GUI) dàilǐ de xiàn yǒu nǔlì. Dāngqián zhǔyào yīlài zài qiángdà de shāngyè shìjué yǔyán móxíng (VLMs) shàng, rú GPT-4o hé GeminiProVision. Kāiyuán VLMs zài GUI lǐjiě hé wèi jiàn fēnbù (OOD) chǎngjǐng zhōng biǎoxiǎn jiàochǎ, yīncǐ shíjiànzhě bù tài yuànyì shǐyòng. Wèile tuīdòng zhè yī lǐngyù de yánjiū, zuòzhě kāifāle OS-Atlas, zhè shì yīgè shàncháng GUI lǐjiě hé OOD rènwù de jīchǔ móxíng. Tāmen hái fābùle yīgè bāohán 1300 duō wàn GUI yuánsù de kuà píngtái shùjùjí, bìng zhèngmíngle OS-Atlas zài duōgè jīzhǔn cèshì zhōng de xiǎnzhù xiàonéng tǐshēng.",
        "vocab": "[\n    {\"word\": \"构建\", \"pinyin\": \"gòu jiàn\", \"trans\": \"construct\"},\n    {\"word\": \"图形用户界面\", \"pinyin\": \"tú xíng yòng hù jiè miàn\", \"trans\": \"graphical user interface\"},\n    {\"word\": \"代理\", \"pinyin\": \"dài lǐ\", \"trans\": \"agent\"},\n    {\"word\": \"现有\", \"pinyin\": \"xiàn yǒu\", \"trans\": \"existing\"},\n    {\"word\": \"努力\", \"pinyin\": \"nǔ lì\", \"trans\": \"efforts\"},\n    {\"word\": \"依赖\", \"pinyin\": \"yī lài\", \"trans\": \"rely on\"},\n    {\"word\": \"强大\", \"pinyin\": \"qiáng dà\", \"trans\": \"powerful\"},\n    {\"word\": \"商业\", \"pinyin\": \"shāng yè\", \"trans\": \"commercial\"},\n    {\"word\": \"视觉语言模型\", \"pinyin\": \"shì jué yǔ yán mó xíng\", \"trans\": \"visual language model\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāi yuán\", \"trans\": \"open-source\"},\n    {\"word\": \"理解\", \"pinyin\": \"lǐ jiě\", \"trans\": \"understanding\"},\n    {\"word\": \"未见分布\", \"pinyin\": \"wèi jiàn fēn bù\", \"trans\": \"out-of-distribution\"},\n    {\"word\": \"场景\", \"pinyin\": \"chǎng jǐng\", \"trans\": \"scenario\"},\n    {\"word\": \"表现\", \"pinyin\": \"biǎo xiàn\", \"trans\": \"performance\"},\n    {\"word\": \"较差\", \"pinyin\": \"jiào chà\", \"trans\": \"poor\"},\n    {\"word\": \"实践者\", \"pinyin\": \"shí jiàn zhě\", \"trans\": \"practitioner\"},\n    {\"word\": \"不太愿意\", \"pinyin\": \"bù tài yuàn yì\", \"trans\": \"not very willing\"},\n    {\"word\": \"推动\", \"pinyin\": \"tuī dòng\", \"trans\": \"promote\"},\n    {\"word\": \"领域\", \"pinyin\": \"lǐng yù\", \"trans\": \"field\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"开发\", \"pinyin\": \"kāi fā\", \"trans\": \"develop\"},\n    {\"word\": \"基础模型\", \"pinyin\": \"jī chǔ mó xíng\", \"trans\": \"foundation model\"},\n    {\"word\": \"擅长\", \"pinyin\": \"shàn cháng\", \"trans\": \"proficient\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wù\", \"trans\": \"task\"},\n    {\"word\": \"发布\", \"pinyin\": \"fā bù\", \"trans\": \"release\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shù jù jí\", \"trans\": \"dataset\"},\n    {\"word\": \"跨平台\", \"pinyin\": \"kuà píng tái\", \"trans\": \"cross-platform\"},\n    {\"word\": \"元素\", \"pinyin\": \"yuán sù\", \"trans\": \"element\"},\n    {\"word\": \"证明\", \"pinyin\": \"zhèng míng\", \"trans\": \"demonstrate\"},\n    {\"word\": \"基准测试\", \"pinyin\": \"jī zhǔn cè shì\", \"trans\": \"benchmark test\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"提升\", \"pinyin\": \"tí shēng\", \"trans\": \"improvement\"}\n]",
        "trans": "This article discusses current efforts in building graphical user interface (GUI) agents. Currently, these efforts primarily rely on powerful commercial vision language models (VLMs) such as GPT-4o and GeminiProVision. Open-source VLMs perform poorly in GUI understanding and out-of-distribution (OOD) scenarios, making practitioners reluctant to use them. To advance research in this field, the authors developed OS-Atlas, a foundational model adept at GUI understanding and OOD tasks. They also released a cross-platform dataset containing over 13 million GUI elements and demonstrated significant performance improvements of OS-Atlas across multiple benchmark tests.",
        "update_ts": "2024-11-04 10:14"
    }
}