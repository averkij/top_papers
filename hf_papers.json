{
    "date": {
        "ru": "21 июля",
        "en": "July 21",
        "zh": "7月21日"
    },
    "time_utc": "2025-07-21 06:19",
    "weekday": 0,
    "issue_id": 4917,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.12566",
            "title": "Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal\n  Large Language Models",
            "url": "https://huggingface.co/papers/2507.12566",
            "abstract": "Mono-InternVL, an advanced monolithic Multimodal Large Language Model, integrates visual experts and improved pre-training strategies to enhance visual learning and reduce computational costs while maintaining competitive performance.  \t\t\t\t\tAI-generated summary \t\t\t\t This paper focuses on monolithic Multimodal Large Language Models (MLLMs), which integrate visual encoding and language decoding into a single model. Existing structures and pre-training strategies for monolithic MLLMs often suffer from unstable optimization and catastrophic forgetting. To address these challenges, our key idea is to embed a new visual parameter space into a pre-trained LLM, enabling stable learning of visual knowledge from noisy data via delta tuning. Based on this principle, we first introduce Mono-InternVL, an advanced monolithic MLLM that incorporates a set of visual experts through a multimodal mixture-of-experts architecture. In addition, we design an innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize its visual capabilities via progressive learning. Mono-InternVL achieves competitive performance against existing MLLMs but also leads to relatively expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++ introduces additional visual attention experts to Mono-InternVL-1.5 and re-organizes the pre-training process in an efficient manner. During inference, it includes a fused CUDA kernel to speed up its MoE operations. With these designs, Mono-InternVL-1.5 significantly reduces training and inference costs, while still maintaining competitive performance with Mono-InternVL. To evaluate our approach, we conduct extensive experiments across 15 benchmarks. Results demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves similar multimodal performance while reducing first-token latency by up to 69%. Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.",
            "score": 3,
            "issue_id": 4917,
            "pub_date": "2025-07-16",
            "pub_date_card": {
                "ru": "16 июля",
                "en": "July 16",
                "zh": "7月16日"
            },
            "hash": "fdd7f0b217aa40b2",
            "authors": [
                "Gen Luo",
                "Wenhan Dou",
                "Wenhao Li",
                "Zhaokai Wang",
                "Xue Yang",
                "Changyao Tian",
                "Hao Li",
                "Weiyun Wang",
                "Wenhai Wang",
                "Xizhou Zhu",
                "Yu Qiao",
                "Jifeng Dai"
            ],
            "affiliations": [
                "Shanghai Artificial Intelligence Laboratory",
                "Shanghai Jiao Tong University",
                "The Chinese University of Hong Kong",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.12566.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#training",
                    "#architecture",
                    "#agi",
                    "#optimization",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Mono-InternVL: Монолитная мультимодальная модель с улучшенным визуальным обучением",
                    "desc": "Mono-InternVL - это усовершенствованная монолитная мультимодальная большая языковая модель (MLLM), которая объединяет визуальное кодирование и языковое декодирование в единую модель. Она использует визуальных экспертов и улучшенные стратегии предобучения для повышения визуального обучения и снижения вычислительных затрат. Mono-InternVL применяет архитектуру смеси экспертов и инновационное эндогенное визуальное предобучение (EViP) для максимизации своих визуальных возможностей. Модель демонстрирует конкурентоспособную производительность по сравнению с существующими MLLM, значительно улучшая результаты на различных бенчмарках."
                },
                "en": {
                    "title": "Revolutionizing Visual Learning with Mono-InternVL",
                    "desc": "The paper introduces Mono-InternVL, a monolithic Multimodal Large Language Model (MLLM) that combines visual and language processing into one model. It addresses issues like unstable optimization and catastrophic forgetting by embedding a new visual parameter space into a pre-trained language model, allowing for stable learning from noisy data. The model incorporates a multimodal mixture-of-experts architecture and an innovative Endogenous Visual Pre-training (EViP) strategy to enhance visual capabilities. Additionally, Mono-InternVL-1.5 is presented as a more efficient version that reduces training costs while maintaining competitive performance across multiple benchmarks."
                },
                "zh": {
                    "title": "Mono-InternVL：高效的单体多模态大语言模型",
                    "desc": "Mono-InternVL是一种先进的单体多模态大语言模型，结合了视觉专家和改进的预训练策略，以增强视觉学习并降低计算成本，同时保持竞争力的性能。该模型通过将新的视觉参数空间嵌入到预训练的语言模型中，解决了不稳定优化和灾难性遗忘的问题。Mono-InternVL-1.5在此基础上进一步优化，采用了改进的内生视觉预训练（EViP++），引入了额外的视觉注意力专家，并高效地重新组织了预训练过程。实验结果表明，Mono-InternVL在多个基准测试中表现优于现有的单体多模态大语言模型，且在推理时显著降低了延迟。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.11097",
            "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion\n  LLMs",
            "url": "https://huggingface.co/papers/2507.11097",
            "abstract": "DIJA is a framework that exploits safety weaknesses in diffusion-based large language models by constructing adversarial prompts, demonstrating significant vulnerabilities in their alignment mechanisms.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion-based large language models (dLLMs) have recently emerged as a powerful alternative to autoregressive LLMs, offering faster inference and greater interactivity via parallel decoding and bidirectional modeling. However, despite strong performance in code generation and text infilling, we identify a fundamental safety concern: existing alignment mechanisms fail to safeguard dLLMs against context-aware, masked-input adversarial prompts, exposing novel vulnerabilities. To this end, we present DIJA, the first systematic study and jailbreak attack framework that exploits unique safety weaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial interleaved mask-text prompts that exploit the text generation mechanisms of dLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional modeling drives the model to produce contextually consistent outputs for masked spans, even when harmful, while parallel decoding limits model dynamic filtering and rejection sampling of unsafe content. This causes standard alignment mechanisms to fail, enabling harmful completions in alignment-tuned dLLMs, even when harmful behaviors or unsafe instructions are directly exposed in the prompt. Through comprehensive experiments, we demonstrate that DIJA significantly outperforms existing jailbreak methods, exposing a previously overlooked threat surface in dLLM architectures. Notably, our method achieves up to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior baseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and by 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of harmful content in the jailbreak prompt. Our findings underscore the urgent need for rethinking safety alignment in this emerging class of language models. Code is available at https://github.com/ZichenWen1/DIJA.",
            "score": 3,
            "issue_id": 4917,
            "pub_date": "2025-07-15",
            "pub_date_card": {
                "ru": "15 июля",
                "en": "July 15",
                "zh": "7月15日"
            },
            "hash": "a104a398841ff4ff",
            "authors": [
                "Zichen Wen",
                "Jiashu Qu",
                "Dongrui Liu",
                "Zhiyuan Liu",
                "Ruixi Wu",
                "Yicun Yang",
                "Xiangqi Jin",
                "Haoyun Xu",
                "Xuyang Liu",
                "Weijia Li",
                "Chaochao Lu",
                "Jing Shao",
                "Conghui He",
                "Linfeng Zhang"
            ],
            "affiliations": [
                "EPIC Lab, Shanghai Jiao Tong University",
                "Shanghai AI Laboratory",
                "Sun Yat-sen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.11097.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#diffusion",
                    "#alignment",
                    "#security"
                ],
                "emoji": "🕵️",
                "ru": {
                    "title": "Уязвимости диффузионных языковых моделей: новый фронт в безопасности ИИ",
                    "desc": "DIJA - это фреймворк для создания состязательных промптов, который использует уязвимости в механизмах безопасности диффузионных языковых моделей. Он демонстрирует, что существующие методы выравнивания не защищают эти модели от вредоносных запросов с маскированным вводом. DIJA конструирует промпты, чередуя маскированный и обычный текст, что позволяет обойти стандартные механизмы безопасности. Эксперименты показывают, что DIJA значительно превосходит существующие методы взлома языковых моделей, раскрывая новую поверхность угроз."
                },
                "en": {
                    "title": "Unmasking Vulnerabilities in Diffusion-Based Language Models with DIJA",
                    "desc": "DIJA is a novel framework that identifies and exploits safety vulnerabilities in diffusion-based large language models (dLLMs) through the use of adversarial prompts. It reveals that existing alignment mechanisms are inadequate in preventing harmful outputs when faced with context-aware, masked-input prompts. By leveraging the unique features of dLLMs, such as bidirectional modeling and parallel decoding, DIJA demonstrates how these models can produce unsafe content despite alignment efforts. The framework significantly outperforms previous methods, highlighting the critical need for improved safety measures in the design of dLLMs."
                },
                "zh": {
                    "title": "揭示扩散型大语言模型的安全脆弱性",
                    "desc": "DIJA是一个框架，利用扩散型大语言模型中的安全弱点，通过构造对抗性提示，展示了其对齐机制的显著脆弱性。尽管扩散型大语言模型在代码生成和文本填充方面表现出色，但我们发现现有的对齐机制无法有效防护针对上下文的对抗性提示。DIJA通过构建对抗性交错掩码文本提示，利用了扩散型大语言模型的文本生成机制，导致标准对齐机制失效。我们的实验表明，DIJA在揭示扩散型大语言模型架构中的新威胁方面，显著优于现有的越狱方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.10605",
            "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking\n  Services",
            "url": "https://huggingface.co/papers/2507.10605",
            "abstract": "RedOne, a domain-specific LLM, enhances performance across multiple SNS tasks through a three-stage training strategy, improving generalization and reducing harmful content exposure.  \t\t\t\t\tAI-generated summary \t\t\t\t As a primary medium for modern information dissemination, social networking services (SNS) have experienced rapid growth, which has proposed significant challenges for platform content management and interaction quality improvement. Recently, the development of large language models (LLMs) has offered potential solutions but existing studies focus on isolated tasks, which not only encounter diminishing benefit from the data scaling within individual scenarios but also fail to flexibly adapt to diverse real-world context. To address these challenges, we introduce RedOne, a domain-specific LLM designed to break the performance bottleneck of single-task baselines and establish a comprehensive foundation for the SNS. RedOne was developed through a three-stage training strategy consisting of continue pretraining, supervised fine-tuning, and preference optimization, using a large-scale real-world dataset. Through extensive experiments, RedOne maintains strong general capabilities, and achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56% in SNS bilingual evaluation benchmark, compared with base models. Furthermore, through online testing, RedOne reduced the exposure rate in harmful content detection by 11.23% and improved the click page rate in post-view search by 14.95% compared with single-tasks finetuned baseline models. These results establish RedOne as a robust domain-specific LLM for SNS, demonstrating excellent generalization across various tasks and promising applicability in real-world scenarios.",
            "score": 2,
            "issue_id": 4914,
            "pub_date": "2025-07-13",
            "pub_date_card": {
                "ru": "13 июля",
                "en": "July 13",
                "zh": "7月13日"
            },
            "hash": "0f03049bcdca7ad4",
            "authors": [
                "Fei Zhao",
                "Chonggang Lu",
                "Yue Wang",
                "Zheyong Xie",
                "Ziyan Liu",
                "Haofu Qian",
                "JianZhao Huang",
                "Fangcheng Shi",
                "Zijie Meng",
                "Hongcheng Guo",
                "Mingqian He",
                "Xinze Lyu",
                "Yiming Lu",
                "Ziyang Xiang",
                "Zheyu Ye",
                "Chengqiang Lu",
                "Zhe Xu",
                "Yi Wu",
                "Yao Hu",
                "Yan Gao",
                "Jun Fan",
                "Xiaolong Jiang",
                "Weiting Liu",
                "Boyang Wang",
                "Shaosheng Cao"
            ],
            "affiliations": [
                "NLP Team, Xiaohongshu Inc., China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.10605.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#alignment",
                    "#optimization",
                    "#dataset",
                    "#multilingual",
                    "#science"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "RedOne: универсальная языковая модель для революции в социальных сетях",
                    "desc": "RedOne - это специализированная языковая модель для социальных сетей, разработанная с использованием трехэтапной стратегии обучения. Модель демонстрирует улучшение производительности в среднем на 14.02% по 8 основным задачам SNS по сравнению с базовыми моделями. RedOne также показывает хорошие результаты в обнаружении вредоносного контента и повышении кликабельности в поисковой выдаче. Модель обладает отличной обобщающей способностью для различных задач SNS и перспективна для применения в реальных сценариях."
                },
                "en": {
                    "title": "RedOne: Elevating SNS Performance with Domain-Specific LLMs",
                    "desc": "RedOne is a specialized large language model (LLM) designed to improve performance on various social networking service (SNS) tasks. It employs a three-stage training strategy that includes continued pretraining, supervised fine-tuning, and preference optimization, which helps it generalize better across different tasks. The model shows significant improvements, achieving up to 14.02% better performance on major SNS tasks and reducing harmful content exposure by 11.23%. Overall, RedOne demonstrates its effectiveness as a domain-specific LLM, enhancing interaction quality and content management in real-world SNS applications."
                },
                "zh": {
                    "title": "RedOne：社交网络服务的强大语言模型",
                    "desc": "RedOne是一种特定领域的大型语言模型（LLM），通过三阶段的训练策略提升了社交网络服务（SNS）任务的表现。该模型的训练包括持续预训练、监督微调和偏好优化，使用了大规模的真实世界数据集。实验结果显示，RedOne在8个主要SNS任务上平均提升了14.02%的性能，并在有害内容检测中减少了11.23%的曝光率。这些成果表明RedOne在多任务上具有良好的泛化能力，适用于实际应用场景。"
                }
            }
        }
    ],
    "link_prev": "2025-07-18.html",
    "link_next": "2025-07-22.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "18.07",
        "en": "07/18",
        "zh": "7月18日"
    },
    "short_date_next": {
        "ru": "22.07",
        "en": "07/22",
        "zh": "7月22日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 1,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    }
}