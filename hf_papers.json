{
    "date": {
        "ru": "7 –º–∞—Ä—Ç–∞",
        "en": "March 7",
        "zh": "3Êúà7Êó•"
    },
    "time_utc": "2025-03-07 03:21",
    "weekday": 4,
    "issue_id": 2578,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.04222",
            "title": "FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion",
            "url": "https://huggingface.co/papers/2503.04222",
            "abstract": "We introduce FuseChat-3.0, a suite of large language models (LLMs) developed by integrating the strengths of heterogeneous source LLMs into more compact target LLMs. Our source models include the powerful Gemma-2-27B-it, Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct. For target models, we focus on three widely-used smaller variants-Llama-3.1-8B-Instruct, Gemma-2-9B-it, and Qwen-2.5-7B-Instruct-along with two ultra-compact options, Llama-3.2-3B-Instruct and Llama-3.2-1B-Instruct. To leverage the diverse capabilities of these source models, we develop a specialized data construction protocol tailored to various tasks and domains. The FuseChat-3.0 training pipeline consists of two key stages: (1) supervised fine-tuning (SFT) to align the target and source model distributions, and (2) Direct Preference Optimization (DPO) to apply preferences from multiple source LLMs to fine-tune the target model. The resulting FuseChat-3.0 models exhibit significant performance gains across tasks such as instruction following, general knowledge, mathematics, and coding. As illustrated in Figure 1, using Llama-3.1-8B-Instruct as the target model, our fusion approach achieves an average improvement of 6.8 points across 14 benchmarks. Moreover, it demonstrates remarkable gains of 37.1 points and 30.1 points on the instruction-following benchmarks AlpacaEval-2 and Arena-Hard, respectively. Our code, models, and datasets are available at https://github.com/SLIT-AI/FuseChat-3.0.",
            "score": 0,
            "issue_id": 2578,
            "pub_date": "2025-03-06",
            "pub_date_card": {
                "ru": "6 –º–∞—Ä—Ç–∞",
                "en": "March 6",
                "zh": "3Êúà6Êó•"
            },
            "hash": "c7d793a0b91efd5d",
            "authors": [
                "Ziyi Yang",
                "Fanqi Wan",
                "Longguang Zhong",
                "Canbin Huang",
                "Guosheng Liang",
                "Xiaojun Quan"
            ],
            "affiliations": [
                "School of Computer Science and Engineering, Sun Yat-sen University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.04222.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#small_models",
                    "#rlhf",
                    "#transfer_learning",
                    "#open_source",
                    "#optimization"
                ],
                "emoji": "üîÄ",
                "ru": {
                    "title": "–°–ª–∏—è–Ω–∏–µ –º–æ—â–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ",
                    "desc": "FuseChat-3.0 –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–∞–±–æ—Ä –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—É—Ç–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω—ã—Ö LLM –≤ –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ —Ü–µ–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏. –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –≤–∫–ª—é—á–∞–µ—Ç –¥–≤–∞ –∫–ª—é—á–µ–≤—ã—Ö —ç—Ç–∞–ø–∞: –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–∞—è —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä—è–º—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π. –†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ FuseChat-3.0 –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –≤–∫–ª—é—á–∞—è —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º, –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è, –º–∞—Ç–µ–º–∞—Ç–∏–∫—É –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ. –ò—Å–ø–æ–ª—å–∑—É—è Llama-3.1-8B-Instruct –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏, –ø–æ–¥—Ö–æ–¥ –∞–≤—Ç–æ—Ä–æ–≤ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞ 6,8 –ø—É–Ω–∫—Ç–æ–≤ –ø–æ 14 –±–µ–Ω—á–º–∞—Ä–∫–∞–º."
                },
                "en": {
                    "title": "Fusing Strengths for Smarter, Smaller Models",
                    "desc": "FuseChat-3.0 is a collection of large language models (LLMs) that combines the strengths of various larger source models into smaller, more efficient target models. The training process involves supervised fine-tuning to align the target models with the source models, followed by Direct Preference Optimization to enhance performance based on preferences from multiple sources. This innovative approach leads to significant improvements in tasks like instruction following, general knowledge, mathematics, and coding. The results show an average performance boost of 6.8 points across 14 benchmarks, with particularly impressive gains in instruction-following tasks."
                },
                "zh": {
                    "title": "ËûçÂêàÂ§öÊ∫êÊ®°ÂûãÔºåÊèêÂçáËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõ",
                    "desc": "Êàë‰ª¨‰ªãÁªç‰∫ÜFuseChat-3.0ÔºåËøôÊòØ‰∏Ä‰∏™ÈÄöËøáÊï¥Âêà‰∏çÂêåÊù•Ê∫êÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ‰ºòÂäøËÄåÂºÄÂèëÁöÑÊõ¥Á¥ßÂáëÁöÑÁõÆÊ†áLLMÂ•ó‰ª∂„ÄÇÊ∫êÊ®°ÂûãÂåÖÊã¨Âº∫Â§ßÁöÑGemma-2-27B-it„ÄÅMistral-Large-Instruct-2407„ÄÅQwen-2.5-72B-InstructÂíåLlama-3.1-70B-Instruct„ÄÇÁõÆÊ†áÊ®°ÂûãÂàôÈõÜ‰∏≠Âú®‰∏âÁßçÂπøÊ≥õ‰ΩøÁî®ÁöÑÂ∞èÂûãÂèò‰Ωì‰∏äÔºå‰ª•Âèä‰∏§‰∏™Ë∂ÖÁ¥ßÂáëÈÄâÈ°π„ÄÇÈÄöËøá‰∏ìÈó®ÁöÑÊï∞ÊçÆÊûÑÂª∫ÂçèËÆÆÂíå‰∏§Èò∂ÊÆµÁöÑËÆ≠ÁªÉÊµÅÁ®ãÔºåFuseChat-3.0Âú®Â§ö‰∏™‰ªªÂä°‰∏äË°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.04378",
            "title": "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks",
            "url": "https://huggingface.co/papers/2503.04378",
            "abstract": "Inference-Time Scaling has been critical to the success of recent models such as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for inference-time scaling require tasks to have answers that can be verified, limiting their application to domains such as math, coding and logical reasoning. We take inspiration from how humans make first attempts, ask for detailed feedback from others and make improvements based on such feedback across a wide spectrum of open-ended endeavors. To this end, we collect data for and train dedicated Feedback and Edit Models that are capable of performing inference-time scaling for open-ended general-domain tasks. In our setup, one model generates an initial response, which are given feedback by a second model, that are then used by a third model to edit the response. We show that performance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo can be boosted by scaling the number of initial response drafts, effective feedback and edited responses. When scaled optimally, our setup based on 70B models from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7 as of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and DeepSeek R1 with 92.3.",
            "score": 0,
            "issue_id": 2578,
            "pub_date": "2025-03-06",
            "pub_date_card": {
                "ru": "6 –º–∞—Ä—Ç–∞",
                "en": "March 6",
                "zh": "3Êúà6Êó•"
            },
            "hash": "926e56aa51a0fefe",
            "authors": [
                "Zhilin Wang",
                "Jiaqi Zeng",
                "Olivier Delalleau",
                "Daniel Egert",
                "Ellie Evans",
                "Hoo-Chang Shin",
                "Felipe Soares",
                "Yi Dong",
                "Oleksii Kuchaiev"
            ],
            "affiliations": [
                "NVIDIA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.04378.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#benchmark",
                    "#inference",
                    "#reasoning",
                    "#rlhf",
                    "#optimization"
                ],
                "emoji": "üîÑ",
                "ru": {
                    "title": "–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ –≤—ã–≤–æ–¥–µ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∑–∞–¥–∞—á: –æ—Ç —á–µ—Ä–Ω–æ–≤–∏–∫–∞ –∫ —É–ª—É—á—à–µ–Ω–Ω–æ–º—É –æ—Ç–≤–µ—Ç—É",
                    "desc": "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ –≤—Ä–µ–º—è –≤—ã–≤–æ–¥–∞ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∑–∞–¥–∞—á –æ–±—â–µ–≥–æ –¥–æ–º–µ–Ω–∞. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–∏—Å—Ç–µ–º—É –∏–∑ —Ç—Ä–µ—Ö –º–æ–¥–µ–ª–µ–π: –æ–¥–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–∞—á–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –≤—Ç–æ—Ä–∞—è –¥–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å, –∞ —Ç—Ä–µ—Ç—å—è —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ —Ç–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ Arena Hard. –ü—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–µ–π —Å–µ–º–µ–π—Å—Ç–≤–∞ Llama 3 —Ä–∞–∑–º–µ—Ä–æ–º 70B –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è OpenAI o1 –∏ DeepSeek R1."
                },
                "en": {
                    "title": "Enhancing Open-Ended Task Performance through Feedback and Editing",
                    "desc": "This paper discusses a novel approach to improve inference-time scaling in machine learning models, particularly for open-ended tasks. It introduces a system where one model generates an initial response, a second model provides feedback, and a third model edits the response based on that feedback. This method allows for more flexible applications beyond traditional tasks that require verifiable answers, such as math or coding. The authors demonstrate that by optimizing the number of drafts, feedback, and edits, their model achieves state-of-the-art performance on the Arena Hard benchmark, outperforming previous models."
                },
                "zh": {
                    "title": "Êé®ÁêÜÊó∂Èó¥Êâ©Â±ïÔºöÊèêÂçáÂºÄÊîæÊÄß‰ªªÂä°ÁöÑÊÄßËÉΩ",
                    "desc": "Êú¨ÊñáÊé¢ËÆ®‰∫ÜÊé®ÁêÜÊó∂Èó¥Êâ©Â±ïÂú®Êú∫Âô®Â≠¶‰π†Ê®°Âûã‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÂ∞§ÂÖ∂ÊòØOpenAI o1ÂíåDeepSeek R1Á≠âÊ®°Âûã„ÄÇËÆ∏Â§öÁé∞ÊúâÊäÄÊúØË¶ÅÊ±Ç‰ªªÂä°ÁöÑÁ≠îÊ°àÂèØÈ™åËØÅÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®ÂºÄÊîæÊÄß‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®„ÄÇÊàë‰ª¨ÂÄüÈâ¥‰∫∫Á±ªÂ¶Ç‰ΩïËøõË°åÂàùÊ≠•Â∞ùËØï„ÄÅËØ∑Ê±ÇÂèçÈ¶àÂπ∂Ê†πÊçÆÂèçÈ¶àËøõË°åÊîπËøõÁöÑËøáÁ®ãÔºåÂºÄÂèë‰∫Ü‰∏ìÈó®ÁöÑÂèçÈ¶àÂíåÁºñËæëÊ®°Âûã„ÄÇÈÄöËøá‰ºòÂåñÂàùÂßãÂìçÂ∫îËçâÁ®ø„ÄÅÊúâÊïàÂèçÈ¶àÂíåÁºñËæëÂìçÂ∫îÁöÑÊï∞ÈáèÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®Arena HardÂü∫ÂáÜÊµãËØï‰∏≠ËææÂà∞‰∫Ü92.7ÁöÑÊúÄÊñ∞ÊÄßËÉΩÔºåË∂ÖË∂ä‰∫ÜÂÖ∂‰ªñÊ®°Âûã„ÄÇ"
                }
            }
        }
    ],
    "link_prev": "2025-03-06.html",
    "link_next": "2025-03-10.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "06.03",
        "en": "03/06",
        "zh": "3Êúà6Êó•"
    },
    "short_date_next": {
        "ru": "10.03",
        "en": "03/10",
        "zh": "3Êúà10Êó•"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 2,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂΩªÂ∫ïÊîπÂèò‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâÔºå‰ΩÜÂºÄÊ∫êÁöÑÂ§öËØ≠Ë®ÄLLMs‰ªçÁÑ∂Á®ÄÁº∫ÔºåÁé∞ÊúâÊ®°ÂûãÈÄöÂ∏∏ËØ≠Ë®ÄË¶ÜÁõñÊúâÈôê„ÄÇËøô‰∫õÊ®°ÂûãÈÄöÂ∏∏‰ºòÂÖàËÄÉËôëËµÑÊ∫ê‰∏∞ÂØåÁöÑËØ≠Ë®ÄÔºåËÄåÂøΩÁï•‰∫ÜÂπøÊ≥õ‰ΩøÁî®‰ΩÜËµÑÊ∫êÂåÆ‰πèÁöÑËØ≠Ë®Ä„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨‰ªãÁªç‰∫ÜBabelÔºå‰∏Ä‰∏™ÂºÄÊîæÁöÑÂ§öËØ≠Ë®ÄLLMÔºåÊ∂µÁõñ‰∫ÜÊåâ‰ΩøÁî®‰∫∫Êï∞ÊéíÂêçÂâç25ÁöÑËØ≠Ë®ÄÔºåÊîØÊåÅË∂ÖËøá90%ÁöÑÂÖ®ÁêÉ‰∫∫Âè£ÔºåÂπ∂ÂåÖÊã¨ËÆ∏Â§öÂÖ∂‰ªñÂºÄÊîæÂ§öËØ≠Ë®ÄLLMsÂøΩÁï•ÁöÑËØ≠Ë®Ä„ÄÇ‰∏é‰º†ÁªüÁöÑÁªßÁª≠È¢ÑËÆ≠ÁªÉÊñπÊ≥ï‰∏çÂêåÔºåBabelÈÄöËøá‰∏ÄÁßçÂ±ÇÊâ©Â±ïÊäÄÊúØÂ¢ûÂä†ÂÖ∂ÂèÇÊï∞Êï∞ÈáèÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜBabelÁöÑÊÄßËÉΩ‰∏äÈôê„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏§‰∏™Âèò‰ΩìÔºöBabel-9BÔºåÁî®‰∫éÈ´òÊïàÊé®ÁêÜÂíåÂæÆË∞ÉÔºå‰ª•ÂèäBabel-83BÔºå‰∏∫ÂºÄÊîæÂ§öËØ≠Ë®ÄLLMsËÆæÂÆö‰∫ÜÊñ∞Ê†áÂáÜ„ÄÇÂπøÊ≥õÁöÑÂ§öËØ≠Ë®Ä‰ªªÂä°ËØÑ‰º∞ËØÅÊòé‰∫ÜÂÖ∂‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®ÂºÄÊ∫êÁõëÁù£ÂæÆË∞ÉÊï∞ÊçÆÈõÜÔºåBabelÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÔºåBabel-9B-ChatÂú®10BÂ§ßÂ∞èÁöÑLLMs‰∏≠È¢ÜÂÖàÔºåBabel-83B-ChatÂú®Â§öËØ≠Ë®Ä‰ªªÂä°‰∏≠ËÆæÂÆö‰∫ÜÊñ∞Ê†áÂáÜÔºåËææÂà∞‰∫ÜÂïÜ‰∏öÊ®°ÂûãÁöÑÊ∞¥Âπ≥„ÄÇ",
        "title": "Babel: Open Multilingual Large Language Models Serving Over 90% of Global Speakers",
        "pinyin": "D√†x√≠ng y«îy√°n m√≥x√≠ng (LLMs) ch√®d«ê g«éibi√†nle z√¨r√°n y«îy√°n ch«îl«ê (NLP), d√†n kƒÅiyu√°n de du≈çy«îy√°n LLMs r√©ngr√°n xƒ´quƒì, xi√†ny«íu m√≥x√≠ng t≈çngch√°ng y«îy√°n f√∫g√†i y«íuxi√†n. Zh√®xiƒì m√≥x√≠ng t≈çngch√°ng y≈çuxiƒÅn k«éol«ú zƒ´yu√°n fƒìngf√π de y«îy√°n, √©r h≈´l√ºe le gu«éngf√†n sh«êy√≤ng d√†n zƒ´yu√°n ku√¨f√° de y«îy√°n. W√®ile jiƒõju√© zh√® yƒ´ chƒÅj√π, w«ímen ji√®sh√†o le Babel, yƒ´g√® kƒÅif√†ng de du≈çy«îy√°n LLM, h√†nhu√≤le √†n sh«êy√≤ng r√©nsh√π p√°im√≠ng qi√°n 25 de y«îy√°n, zhƒ´ch√≠ chƒÅogu√≤ 90% de qu√°nqi√∫ r√©nk«íu, b√¨ng bƒÅoku√≤ x«îdu≈ç q√≠tƒÅ kƒÅif√†ng du≈çy«îy√°n LLMs h≈´l√ºe de y«îy√°n. Y«î chu√°nt«íng de j√¨x√π y√πx√πn fƒÅngf«é b√πt√≥ng, Babel t≈çnggu√≤ yƒ´zh«íng c√©ng ku√≤zh«én j√¨sh√π zƒìngjiƒÅ q√≠ cƒÅnsh√π sh√πli√†ng, d√†ngr√°n t√≠gƒÅole Babel de x√¨ngn√©ng sh√†ngxi√†n. W«ímen y«ênr√πle li«éngg√® bi√†nt«ê: Babel-9B, y√≤ngy√∫ gƒÅoxi√†o tuƒ´l«ê h√© wƒìiti√°o, y«êji«é Babel-83B, w√®i kƒÅif√†ng du≈çy«îy√°n LLMs sh√®d√¨ngle xƒ´n biƒÅozh«în. Gu«éngf√†n de du≈çy«îy√°n r√®nw√π p√≠ngg≈´ zh√®ngm√≠ngle q√≠ y≈çubi√® de x√¨ngn√©ng. C«êw√†i, sh«êy√≤ng kƒÅiyu√°n ji√†nsh«ê wƒìiti√°o sh√πj√∫j√≠, Babel qu√®d√©le xi«énzh√π de x√¨ngn√©ng, Babel-9B-Chat z√†i 10B d√†x√¨ng de LLMs zh≈çng l«êngxiƒÅn, Babel-83B-Chat z√†i du≈çy«îy√°n r√®nw√π zh≈çng sh√®d√¨ngle xƒ´n biƒÅozh«în, d√°le shƒÅngy√® m√≥x√≠ng de shu«êp√≠ng.",
        "vocab": "[\n    {\"word\": \"Â§ßÂûã\", \"pinyin\": \"d√†x√≠ng\", \"trans\": \"large-scale\"},\n    {\"word\": \"ÂΩªÂ∫ï\", \"pinyin\": \"ch√®d«ê\", \"trans\": \"thoroughly\"},\n    {\"word\": \"Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ\", \"pinyin\": \"z√¨r√°n y«îy√°n ch«îl«ê\", \"trans\": \"Natural Language Processing\"},\n    {\"word\": \"Á®ÄÁº∫\", \"pinyin\": \"xƒ´quƒì\", \"trans\": \"scarce\"},\n    {\"word\": \"Ë¶ÜÁõñ\", \"pinyin\": \"f√πg√†i\", \"trans\": \"cover\"},\n    {\"word\": \"ÊúâÈôê\", \"pinyin\": \"y«íuxi√†n\", \"trans\": \"limited\"},\n    {\"word\": \"‰ºòÂÖà\", \"pinyin\": \"y≈çuxiƒÅn\", \"trans\": \"prioritize\"},\n    {\"word\": \"ËµÑÊ∫ê\", \"pinyin\": \"zƒ´yu√°n\", \"trans\": \"resources\"},\n    {\"word\": \"‰∏∞ÂØå\", \"pinyin\": \"fƒìngf√π\", \"trans\": \"abundant\"},\n    {\"word\": \"ÂåÆ‰πè\", \"pinyin\": \"ku√¨f√°\", \"trans\": \"scarce\"},\n    {\"word\": \"Â∑ÆË∑ù\", \"pinyin\": \"chƒÅj√π\", \"trans\": \"gap\"},\n    {\"word\": \"‰ªãÁªç\", \"pinyin\": \"ji√®sh√†o\", \"trans\": \"introduce\"},\n    {\"word\": \"Ê∂µÁõñ\", \"pinyin\": \"h√°ng√†i\", \"trans\": \"cover\"},\n    {\"word\": \"Êåâ\", \"pinyin\": \"√†n\", \"trans\": \"according to\"},\n    {\"word\": \"ÊéíÂêç\", \"pinyin\": \"p√°im√≠ng\", \"trans\": \"ranking\"},\n    {\"word\": \"ÊîØÊåÅ\", \"pinyin\": \"zhƒ´ch√≠\", \"trans\": \"support\"},\n    {\"word\": \"ÂÖ®ÁêÉ\", \"pinyin\": \"qu√°nqi√∫\", \"trans\": \"global\"},\n    {\"word\": \"‰∫∫Âè£\", \"pinyin\": \"r√©nk«íu\", \"trans\": \"population\"},\n    {\"word\": \"ÁªßÁª≠\", \"pinyin\": \"j√¨x√π\", \"trans\": \"continue\"},\n    {\"word\": \"È¢ÑËÆ≠ÁªÉ\", \"pinyin\": \"y√π x√πnli√†n\", \"trans\": \"pre-training\"},\n    {\"word\": \"ÊñπÊ≥ï\", \"pinyin\": \"fƒÅngf«é\", \"trans\": \"method\"},\n    {\"word\": \"Â±Ç\", \"pinyin\": \"c√©ng\", \"trans\": \"layer\"},\n    {\"word\": \"Êâ©Â±ï\", \"pinyin\": \"ku√≤zh«én\", \"trans\": \"expand\"},\n    {\"word\": \"ÊäÄÊúØ\", \"pinyin\": \"j√¨sh√π\", \"trans\": \"technology\"},\n    {\"word\": \"ÂèÇÊï∞\", \"pinyin\": \"cƒÅnsh«î\", \"trans\": \"parameters\"},\n    {\"word\": \"Êï∞Èáè\", \"pinyin\": \"sh√πli√†ng\", \"trans\": \"quantity\"},\n    {\"word\": \"ÊèêÈ´ò\", \"pinyin\": \"t√≠gƒÅo\", \"trans\": \"improve\"},\n    {\"word\": \"ÊÄßËÉΩ\", \"pinyin\": \"x√¨ngn√©ng\", \"trans\": \"performance\"},\n    {\"word\": \"‰∏äÈôê\", \"pinyin\": \"sh√†ngxi√†n\", \"trans\": \"upper limit\"},\n    {\"word\": \"ÂºïÂÖ•\", \"pinyin\": \"y«ênr√π\", \"trans\": \"introduce\"},\n    {\"word\": \"Âèò‰Ωì\", \"pinyin\": \"bi√†nt«ê\", \"trans\": \"variants\"},\n    {\"word\": \"È´òÊïà\", \"pinyin\": \"gƒÅoxi√†o\", \"trans\": \"efficient\"},\n    {\"word\": \"Êé®ÁêÜ\", \"pinyin\": \"tuƒ´l«ê\", \"trans\": \"inference\"},\n    {\"word\": \"ÂæÆË∞É\", \"pinyin\": \"wƒìiti√°o\", \"trans\": \"fine-tuning\"},\n    {\"word\": \"ËÆæÂÆö\", \"pinyin\": \"sh√®d√¨ng\", \"trans\": \"set\"},\n    {\"word\": \"Ê†áÂáÜ\", \"pinyin\": \"biƒÅozh«în\", \"trans\": \"standard\"},\n    {\"word\": \"ËØÑ‰º∞\", \"pinyin\": \"p√≠ngg≈´\", \"trans\": \"evaluation\"},\n    {\"word\": \"ËØÅÊòé\", \"pinyin\": \"zh√®ngm√≠ng\", \"trans\": \"prove\"},\n    {\"word\": \"‰ºòË∂ä\", \"pinyin\": \"y≈çuyu√®\", \"trans\": \"superior\"},\n    {\"word\": \"ÁõëÁù£\", \"pinyin\": \"ji√†nd≈´\", \"trans\": \"supervised\"},\n    {\"word\": \"Êï∞ÊçÆÈõÜ\", \"pinyin\": \"sh√πj√π j√≠\", \"trans\": \"dataset\"},\n    {\"word\": \"ÊòæËëó\", \"pinyin\": \"xi«énzh√π\", \"trans\": \"significant\"},\n    {\"word\": \"È¢ÜÂÖà\", \"pinyin\": \"l«êngxiƒÅn\", \"trans\": \"lead\"},\n    {\"word\": \"ÂïÜ‰∏ö\", \"pinyin\": \"shƒÅngy√®\", \"trans\": \"commercial\"},\n    {\"word\": \"Ê∞¥Âπ≥\", \"pinyin\": \"shu«êp√≠ng\", \"trans\": \"level\"}\n]",
        "trans": "Large language models (LLMs) have revolutionized natural language processing (NLP), but open-source multilingual LLMs remain scarce, with existing models often having limited language coverage. These models typically prioritize resource-rich languages while neglecting widely used but resource-scarce languages. To address this gap, we introduce Babel, an open multilingual LLM that covers the top 25 languages by number of speakers, supporting over 90% of the global population and including many languages overlooked by other open multilingual LLMs. Unlike traditional continued pre-training methods, Babel enhances its parameter count through a layer expansion technique, raising Babel's performance ceiling. We introduce two variants: Babel-9B for efficient inference and fine-tuning, and Babel-83B, setting a new standard for open multilingual LLMs. Extensive multilingual task evaluations demonstrate its superior performance. Additionally, using open-source supervised fine-tuning datasets, Babel achieves significant performance, with Babel-9B-Chat leading among 10B-sized LLMs and Babel-83B-Chat setting new standards in multilingual tasks, reaching the level of commercial models.",
        "update_ts": "2025-03-06 09:11"
    }
}