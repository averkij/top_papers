{
    "date": {
        "ru": "9 июня",
        "en": "June 9",
        "zh": "6月9日"
    },
    "time_utc": "2025-06-09 02:50",
    "weekday": 0,
    "issue_id": 4185,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2506.05984",
            "title": "Audio-Aware Large Language Models as Judges for Speaking Styles",
            "url": "https://huggingface.co/papers/2506.05984",
            "abstract": "Audio-aware large language models can assess speaking styles in audio inputs, demonstrating performance comparable to human judges in evaluating synthesized speech along dimensions like emotion, volume, and pitch.  \t\t\t\t\tAI-generated summary \t\t\t\t Audio-aware large language models (ALLMs) can understand the textual and non-textual information in the audio input. In this paper, we explore using ALLMs as an automatic judge to assess the speaking styles of speeches. We use ALLM judges to evaluate the speeches generated by SLMs on two tasks: voice style instruction following and role-playing. The speaking style we consider includes emotion, volume, speaking pace, word emphasis, pitch control, and non-verbal elements. We use four spoken language models (SLMs) to complete the two tasks and use humans and ALLMs to judge the SLMs' responses. We compare two ALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and show that the agreement between Gemini and human judges is comparable to the agreement between human evaluators. These promising results show that ALLMs can be used as a judge to evaluate SLMs. Our results also reveal that current SLMs, even GPT-4o-audio, still have room for improvement in controlling the speaking style and generating natural dialogues.",
            "score": 3,
            "issue_id": 4185,
            "pub_date": "2025-06-06",
            "pub_date_card": {
                "ru": "6 июня",
                "en": "June 6",
                "zh": "6月6日"
            },
            "hash": "10dcc4567ff634c1",
            "authors": [
                "Cheng-Han Chiang",
                "Xiaofei Wang",
                "Chung-Ching Lin",
                "Kevin Lin",
                "Linjie Li",
                "Radu Kopetz",
                "Yao Qian",
                "Zhendong Wang",
                "Zhengyuan Yang",
                "Hung-yi Lee",
                "Lijuan Wang"
            ],
            "affiliations": [
                "Microsoft",
                "National Taiwan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.05984.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#audio",
                    "#interpretability",
                    "#games"
                ],
                "emoji": "🎙️",
                "ru": {
                    "title": "АОБЛМ как объективные судьи стиля речи",
                    "desc": "Аудио-осведомленные большие языковые модели (АОБЛМ) способны оценивать стили речи в аудиовходах, демонстрируя производительность, сравнимую с оценками людей-судей. В исследовании АОБЛМ использовались для оценки речей, сгенерированных разговорными языковыми моделями (РЯМ) в задачах следования инструкциям по стилю голоса и ролевой игры. Оценивались такие аспекты, как эмоции, громкость, темп речи, выделение слов, контроль высоты тона и невербальные элементы. Результаты показали, что согласованность между оценками Gemini и человеческих судей сопоставима с согласованностью между оценками разных людей."
                },
                "en": {
                    "title": "Evaluating Speech Styles with AI: ALLMs vs. Human Judges",
                    "desc": "This paper discusses the capabilities of audio-aware large language models (ALLMs) in evaluating speaking styles from audio inputs. The authors demonstrate that ALLMs can assess synthesized speech similarly to human judges, focusing on aspects like emotion, volume, and pitch. They compare the performance of two ALLMs, GPT-4o-audio and Gemini-2.5-pro, against human evaluations in tasks involving voice style instruction and role-playing. The findings indicate that while ALLMs can effectively judge speaking styles, there is still potential for improvement in the speaking style control of current spoken language models (SLMs)."
                },
                "zh": {
                    "title": "音频感知模型：评估说话风格的新工具",
                    "desc": "音频感知的大型语言模型（ALLMs）能够评估音频输入中的说话风格，其表现与人类评审在情感、音量和音调等维度上的评估相当。本文探讨了使用ALLMs作为自动评审者来评估演讲的说话风格。我们使用四个口语语言模型（SLMs）完成两个任务，并通过人类和ALLMs对SLMs的响应进行评估。研究结果表明，ALLMs可以作为评审工具来评估SLMs，但当前的SLMs在控制说话风格和生成自然对话方面仍有改进空间。"
                }
            }
        }
    ],
    "link_prev": "2025-06-06.html",
    "link_next": "2025-06-10.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "06.06",
        "en": "06/06",
        "zh": "6月6日"
    },
    "short_date_next": {
        "ru": "10.06",
        "en": "06/10",
        "zh": "6月10日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 1,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了ComfyUI-Copilot，一个使用大型语言模型和多代理系统的插件。它旨在提高AI驱动的艺术创作平台ComfyUI的易用性和效率。ComfyUI虽然灵活，但对新手来说有一定难度。ComfyUI-Copilot通过智能推荐和自动化工作流构建来解决这些问题。测试和用户反馈显示它能准确推荐节点并加速工作流开发。",
        "title": "ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow\n  Development",
        "pinyin": "这篇文章介绍了ComfyUI-Copilot，一个使用大型语言模型和多代理系统的插件。它旨在提高AI驱动的艺术创作平台ComfyUI的易用性和效率。ComfyUI虽然灵活，但对新手来说有一定难度。ComfyUI-Copilot通过智能推荐和自动化工作流构建来解决这些问题。测试和用户反馈显示它能准确推荐节点并加速工作流开发。\n\nzhè piān wén zhāng jiè shào le ComfyUI-Copilot, yī gè shǐ yòng dà xíng yǔ yán mó xíng hé duō dài lǐ xì tǒng de chā jiàn. tā zhǐ yú tí gāo AI qū dòng de yì shù chuàng zuò píng tái ComfyUI de yì yòng xìng hé xiào lǜ. ComfyUI suī rán líng huó, dàn duì xīn shǒu lái shuō yǒu yī dìng nán dù. ComfyUI-Copilot tōng guò zhì néng tuī jiàn hé zì dòng huà gōng zuò liú gòu jiàn lái jiě jué zhè xiē wèn tí. cè shì hé yòng hù fǎn kuì xiǎn shì tā néng zhǔn què tuī jiàn jié diǎn bìng jiā sù gōng zuò liú kāi fā.",
        "vocab": "[{'word': '介绍', 'pinyin': 'jiè shào', 'trans': 'introduce'},\n{'word': '插件', 'pinyin': 'chā jiàn', 'trans': 'plugin'},\n{'word': '旨在', 'pinyin': 'zhǐ zài', 'trans': 'aim to'},\n{'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'},\n{'word': '易用性', 'pinyin': 'yì yòng xìng', 'trans': 'usability'},\n{'word': '效率', 'pinyin': 'xiào lǜ', 'trans': 'efficiency'},\n{'word': '灵活', 'pinyin': 'líng huó', 'trans': 'flexible'},\n{'word': '新手', 'pinyin': 'xīn shǒu', 'trans': 'beginner'},\n{'word': '难度', 'pinyin': 'nán dù', 'trans': 'difficulty'},\n{'word': '智能', 'pinyin': 'zhì néng', 'trans': 'intelligent'},\n{'word': '推荐', 'pinyin': 'tuī jiàn', 'trans': 'recommend'},\n{'word': '自动化', 'pinyin': 'zì dòng huà', 'trans': 'automation'},\n{'word': '工作流', 'pinyin': 'gōng zuò liú', 'trans': 'workflow'},\n{'word': '构建', 'pinyin': 'gòu jiàn', 'trans': 'build'},\n{'word': '解决', 'pinyin': 'jiě jué', 'trans': 'solve'},\n{'word': '准确', 'pinyin': 'zhǔn què', 'trans': 'accurate'},\n{'word': '节点', 'pinyin': 'jié diǎn', 'trans': 'node'},\n{'word': '加速', 'pinyin': 'jiā sù', 'trans': 'accelerate'},\n{'word': '开发', 'pinyin': 'kāi fā', 'trans': 'develop'},\n{'word': '反馈', 'pinyin': 'fǎn kuì', 'trans': 'feedback'}]",
        "trans": "This article introduces ComfyUI-Copilot, a plugin that utilizes large language models and multi-agent systems. It aims to enhance the usability and efficiency of the AI-driven art creation platform ComfyUI. While ComfyUI is flexible, it can be challenging for beginners. ComfyUI-Copilot addresses these issues by providing intelligent recommendations and automated workflow construction. Testing and user feedback indicate that it accurately recommends nodes and accelerates workflow development.",
        "update_ts": "2025-06-08 12:46"
    }
}