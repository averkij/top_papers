{
    "date": {
        "ru": "9 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
        "en": "February 9",
        "zh": "2æœˆ9æ—¥"
    },
    "time_utc": "2026-02-09 06:04",
    "weekday": 0,
    "issue_id": 963,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2602.03392",
            "title": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models",
            "url": "https://huggingface.co/papers/2602.03392",
            "abstract": "The paper establishes a theoretical framework for analyzing entropy dynamics in reinforcement fine-tuning of large language models, deriving expressions for entropy change and proposing entropy control methods based on discriminant analysis.  \t\t\t\t\tAI-generated summary \t\t\t\t Entropy serves as a critical metric for measuring the diversity of outputs generated by large language models (LLMs), providing valuable insights into their exploration capabilities. While recent studies increasingly focus on monitoring and adjusting entropy to better balance exploration and exploitation in reinforcement fine-tuning (RFT), a principled understanding of entropy dynamics during this process is yet to be thoroughly investigated. In this paper, we establish a theoretical framework for analyzing the entropy dynamics during the RFT process, which begins with a discriminant expression that quantifies entropy change under a single logit update. This foundation enables the derivation of a first-order expression for entropy change, which can be further extended to the update formula of Group Relative Policy Optimization (GRPO). The corollaries and insights drawn from the theoretical analysis inspire the design of entropy control methods, and also offer a unified lens for interpreting various entropy-based methods in existing studies. We provide empirical evidence to support the main conclusions of our analysis and demonstrate the effectiveness of the derived entropy-discriminator clipping methods. This study yields novel insights into RFT training dynamics, providing theoretical support and practical strategies for optimizing the exploration-exploitation balance during LLM fine-tuning.",
            "score": 32,
            "issue_id": 962,
            "pub_date": "2026-02-03",
            "pub_date_card": {
                "ru": "3 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 3",
                "zh": "2æœˆ3æ—¥"
            },
            "hash": "ddcd17135a2a2ca9",
            "authors": [
                "Shumin Wang",
                "Yuexiang Xie",
                "Wenhao Zhang",
                "Yuchang Sun",
                "Yanxi Chen",
                "Yaliang Li",
                "Yanyong Zhang"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.03392.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#math",
                    "#training",
                    "#rl"
                ],
                "emoji": "âš–ï¸",
                "ru": {
                    "title": "Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸ Ğ² ÑƒÑĞ¸Ğ»ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ÑÑ‚ Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸. Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¹Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² ĞµĞ´Ğ¸Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ğµ Ğ¸ Ğ²Ğ´Ğ¾Ñ…Ğ½Ğ¾Ğ²Ğ»ÑÑÑ‚ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ ÑĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸ Ñ„Ğ°Ğ¹Ğ½Ñ‚ÑĞ½Ğ¸Ğ½Ğ³Ğµ LLM."
                },
                "en": {
                    "title": "Optimizing Exploration-Exploitation in Language Models through Entropy Dynamics",
                    "desc": "This paper presents a theoretical framework for understanding how entropy changes during the reinforcement fine-tuning (RFT) of large language models (LLMs). It introduces a discriminant expression to quantify entropy change with each logit update, leading to a first-order expression that can be applied to Group Relative Policy Optimization (GRPO). The authors propose new entropy control methods based on their analysis, which help balance exploration and exploitation in model training. Empirical results validate their findings and demonstrate the effectiveness of the proposed entropy-discriminator clipping techniques."
                },
                "zh": {
                    "title": "ä¼˜åŒ–æ¢ç´¢ä¸åˆ©ç”¨çš„ç†µåŠ¨æ€åˆ†æ",
                    "desc": "æœ¬æ–‡å»ºç«‹äº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œç”¨äºåˆ†æå¤§è¯­è¨€æ¨¡å‹åœ¨å¼ºåŒ–å¾®è°ƒè¿‡ç¨‹ä¸­çš„ç†µåŠ¨æ€ã€‚ç†µæ˜¯è¡¡é‡æ¨¡å‹è¾“å‡ºå¤šæ ·æ€§çš„é‡è¦æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæä¾›æ¨¡å‹æ¢ç´¢èƒ½åŠ›çš„æ·±åˆ»è§è§£ã€‚æˆ‘ä»¬æ¨å¯¼äº†ç†µå˜åŒ–çš„è¡¨è¾¾å¼ï¼Œå¹¶æå‡ºäº†åŸºäºåˆ¤åˆ«åˆ†æçš„ç†µæ§åˆ¶æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡ã€‚é€šè¿‡å®è¯ç ”ç©¶ï¼Œæˆ‘ä»¬éªŒè¯äº†è¿™äº›æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºç°æœ‰ç ”ç©¶ä¸­çš„ç†µç›¸å…³æ–¹æ³•æä¾›äº†ç»Ÿä¸€çš„è§£é‡Šè§†è§’ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06291",
            "title": "Judging What We Cannot Solve: A Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math",
            "url": "https://huggingface.co/papers/2602.06291",
            "abstract": "Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose Consequence-Based Utility, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap, maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve.",
            "score": 13,
            "issue_id": 963,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "35fbd37e3ab0ae57",
            "authors": [
                "Guijin Son",
                "Donghun Yang",
                "Hitesh Laxmichand Patel",
                "Hyunwoo Ko",
                "Amit Agarwal",
                "Sunghee Ahn",
                "Kyong-Ha Lee",
                "Youngjae Yu"
            ],
            "affiliations": [
                "OnelineAI",
                "Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06291.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#reasoning",
                    "#science",
                    "#math",
                    "#dataset"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ñ… Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Consequence-Based Utility Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ². Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… reward Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ»Ğ¸ ÑÑƒĞ´ĞµĞ¹ÑÑ‚Ğ²Ğ° Ñ‡ĞµÑ€ĞµĞ· LLM, Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ĞºĞ°Ğº Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ (in-context exemplar) Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¼ ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼ Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ñ… Ğ¸ Ğ½ĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. ĞšĞ»ÑÑ‡ĞµĞ²Ğ°Ñ Ğ¸Ğ´ĞµÑ Ğ·Ğ°ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ»ÑƒÑ‡ÑˆĞµ, Ñ‡ĞµĞ¼ Ğ½ĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Evaluating Math Solutions with Consequence-Based Utility",
                    "desc": "This paper introduces Consequence-Based Utility, a new method for evaluating mathematical solutions by assessing their effectiveness as examples for similar problems. Unlike traditional reward models and LLM judges, this approach does not rely on pre-defined rewards but instead tests how well a solution can help solve related questions. The authors demonstrate that their method significantly improves the ranking quality of solutions, achieving higher accuracy and area under the curve (AUC) scores compared to existing models. This innovation addresses the challenge of verifying complex mathematical solutions while reducing the burden on expert evaluators."
                },
                "zh": {
                    "title": "åŸºäºåæœçš„æ•ˆç”¨ï¼šæå‡æ•°å­¦è§£ç­”è¯„ä¼°çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ï¼Œç§°ä¸ºåŸºäºåæœçš„æ•ˆç”¨ï¼ˆConsequence-Based Utilityï¼‰ï¼Œç”¨äºè¯„ä¼°æ•°å­¦é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•é€šè¿‡æµ‹è¯•å€™é€‰è§£åœ¨è§£å†³ç›¸å…³å¯éªŒè¯é—®é¢˜ä¸­çš„è¡¨ç°ï¼Œæ¥åˆ¤æ–­å…¶ä½œä¸ºç¤ºä¾‹çš„ä»·å€¼ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨æ’åè´¨é‡ä¸Šä¼˜äºä¼ ç»Ÿçš„å¥–åŠ±æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°è€…ã€‚å…·ä½“è€Œè¨€ï¼ŒåŸºäºåæœçš„æ•ˆç”¨åœ¨å¤šä¸ªç ”ç©¶çº§æ•°å­¦é—®é¢˜ä¸Šæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨æ­£ç¡®ä¸é”™è¯¯çš„åŒºåˆ†ä¸Šè¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06570",
            "title": "Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making",
            "url": "https://huggingface.co/papers/2602.06570",
            "abstract": "Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3.",
            "score": 12,
            "issue_id": 963,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "cb1f6a45692326d3",
            "authors": [
                "Baichuan-M3 Team",
                ":",
                "Chengfeng Dou",
                "Fan Yang",
                "Fei Li",
                "Jiyuan Jia",
                "Qiang Ju",
                "Shuai Wang",
                "Tianpeng Li",
                "Xiangrong Zeng",
                "Yijie Zhou",
                "Hongda Zhang",
                "Jinyang Tai",
                "Linzhuang Sun",
                "Peidong Guo",
                "Yichuan Mo",
                "Xiaochuan Wang",
                "Hengfu Cui",
                "Zhishou Zhang"
            ],
            "affiliations": [
                "Baichuan Inc."
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06570.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#science",
                    "#hallucinations",
                    "#reasoning"
                ],
                "emoji": "âš•ï¸",
                "ru": {
                    "title": "ĞÑ‚ Ğ¿Ğ°ÑÑĞ¸Ğ²Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğº Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ²Ñ€Ğ°Ñ‡ĞµĞ±Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞµ",
                    "desc": "Baichuan-M3 â€” ÑÑ‚Ğ¾ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ°Ñ LLM, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñƒ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ¾Ñ‚ Ğ¿Ğ°ÑÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞµ ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€Ğµ, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒÑÑ‰ĞµĞ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ²Ñ€Ğ°Ñ‡Ğ°, Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ñ‚Ñ€Ğ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸: Ğ¿Ñ€Ğ¾Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ÑĞ±Ğ¾Ñ€ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ² Ğ² ÑĞ²ÑĞ·Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾Ğ· Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ñ„Ğ°ĞºÑ‚-Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… HealthBench, HealthBench-Hallu Ğ¸ ScanBench, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ² ĞºĞ»Ğ¸Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸ÑÑ… Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ° Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾Ğ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğµ Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ² Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Revolutionizing Clinical Decision Support with Baichuan-M3",
                    "desc": "Baichuan-M3 is a large language model specifically designed for medical applications, focusing on enhancing clinical decision-making. It moves beyond traditional question-answering by actively supporting healthcare professionals with proactive information gathering and long-term reasoning. The model effectively integrates various pieces of evidence to form coherent diagnoses while minimizing inaccuracies through adaptive hallucination suppression. Evaluations show that Baichuan-M3 outperforms existing models like GPT-5.2 in clinical tasks, making it a significant advancement in medical AI."
                },
                "zh": {
                    "title": "ä¸»åŠ¨å†³ç­–æ”¯æŒï¼Œè¶…è¶Šä¼ ç»Ÿé—®ç­”",
                    "desc": "Baichuan-M3æ˜¯ä¸€ç§åŒ»å­¦å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨ä¸ºä¸´åºŠå†³ç­–æä¾›æ”¯æŒã€‚å®ƒçš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ä¸»åŠ¨ä¿¡æ¯è·å–ã€é•¿æ—¶é—´æ¨ç†å’Œå¹»è§‰æŠ‘åˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£å†³ç°æœ‰ç³»ç»Ÿåœ¨å¼€æ”¾å¼å’¨è¯¢ä¸­çš„å±€é™æ€§ã€‚è¯¥æ¨¡å‹é€šè¿‡ä¸“é—¨çš„è®­ç»ƒæµç¨‹æ¨¡æ‹ŸåŒ»ç”Ÿçš„ç³»ç»Ÿå·¥ä½œæµç¨‹ï¼Œèƒ½å¤Ÿå°†åˆ†æ•£çš„è¯æ®æ•´åˆä¸ºè¿è´¯çš„è¯Šæ–­ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒBaichuan-M3åœ¨HealthBenchç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—è¶…è¶Šäº†GPT-5.2ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.05940",
            "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training",
            "url": "https://huggingface.co/papers/2602.05940",
            "abstract": "TRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages.  \t\t\t\t\tAI-generated summary \t\t\t\t Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.",
            "score": 12,
            "issue_id": 962,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "370ca1f731ec277b",
            "authors": [
                "Junxiao Liu",
                "Zhijun Wang",
                "Yixiao Li",
                "Zhejian Lai",
                "Liqian Huang",
                "Xin Huang",
                "Xue Han",
                "Junlan Feng",
                "Shujian Huang"
            ],
            "affiliations": [
                "China Mobile Communications Company Limited Research Institute",
                "National Key Laboratory for Novel Software Technology, Nanjing University",
                "University of TÃ¼bingen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.05940.jpg",
            "data": {
                "categories": [
                    "#machine_translation",
                    "#transfer_learning",
                    "#multilingual",
                    "#training",
                    "#reasoning"
                ],
                "emoji": "ğŸŒ",
                "ru": {
                    "title": "ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº TRIT, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°ÑÑ‚ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ Ğ´Ğ°Ğ¶Ğµ Ğ´Ğ»Ñ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… ÑĞ·Ñ‹ĞºĞ°Ñ…, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ°Ğ¼Ğ¾ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰ĞµĞ³Ğ¾ÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ĞºĞ°Ğº Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ñ‚Ğ°Ğº Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ±ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ Ğ¸Ğ»Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ â€” Ğ² ÑÑ€ĞµĞ´Ğ½ĞµĞ¼ Ğ½Ğ° 7 Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¿ÑƒĞ½ĞºÑ‚Ğ° Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ MMATH Ñ Ğ·Ğ°Ğ¼ĞµÑ‚Ğ½Ñ‹Ğ¼ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸ĞµĞ¼ ĞºÑ€Ğ¾ÑÑ-Ğ»Ğ¸Ğ½Ğ³Ğ²Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing Multilingual Reasoning with Integrated Translation Training",
                    "desc": "The TRIT framework enhances multilingual reasoning by combining translation and reasoning training. This approach addresses the challenges of understanding and responding to questions in different languages, which often leads to inaccuracies. By integrating translation into the reasoning process, TRIT improves both the accuracy of answers and the consistency of language used. The framework shows significant performance improvements on multilingual tasks, demonstrating its effectiveness without needing extra data or feedback."
                },
                "zh": {
                    "title": "TRITæ¡†æ¶ï¼šæå‡å¤šè¯­è¨€æ¨ç†çš„æ–°æ–¹æ³•",
                    "desc": "TRITæ¡†æ¶é€šè¿‡è”åˆè®­ç»ƒç¿»è¯‘å’Œæ¨ç†ç»„ä»¶ï¼Œæå‡äº†å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ã€‚è¯¥æ–¹æ³•è§£å†³äº†å¤šè¯­è¨€é—®é¢˜ç†è§£å’Œæ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œé¿å…äº†åœ¨éè‹±è¯­é—®é¢˜ä¸Šæ¨ç†æ—¶çš„å‡†ç¡®æ€§ä¸‹é™ã€‚TRITæ¡†æ¶æ— éœ€å¤–éƒ¨åé¦ˆæˆ–é¢å¤–çš„å¤šè¯­è¨€æ•°æ®ï¼Œèƒ½å¤Ÿè‡ªæˆ‘æå‡å¤šè¯­è¨€é—®é¢˜ç†è§£å’Œå›ç­”ç”Ÿæˆçš„æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTRITåœ¨MMATHæ•°æ®é›†ä¸Šå¹³å‡æé«˜äº†7ä¸ªç™¾åˆ†ç‚¹ï¼Œæ˜¾è‘—æ”¹å–„äº†ç­”æ¡ˆçš„æ­£ç¡®æ€§å’Œè¯­è¨€ä¸€è‡´æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06075",
            "title": "MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments",
            "url": "https://huggingface.co/papers/2602.06075",
            "abstract": "A comprehensive memory-focused benchmark for mobile GUI agents reveals significant memory capability gaps and provides systematic evaluation methods and design insights.  \t\t\t\t\tAI-generated summary \t\t\t\t Current mobile GUI agent benchmarks systematically fail to assess memory capabilities, with only 5.2-11.8% memory-related tasks and no cross-session learning evaluation. We introduce MemGUI-Bench, a comprehensive memory-centric benchmark with pass@k and staged LLM-as-judge evaluation. Our contributions include: (1) a systematic memory taxonomy analyzing 11 agents across 5 architectures; (2) 128 tasks across 26 applications where 89.8% challenge memory through cross-temporal and cross-spatial retention; (3) MemGUI-Eval, an automated pipeline with Progressive Scrutiny and 7 hierarchical metrics; and (4) RQ-driven assessment of 11 state-of-the-art agents. Our experiments reveal significant memory deficits across all evaluated systems, identify 5 distinct failure modes, and synthesize 5 actionable design implications. All resources including code, benchmark, and evaluation results will be \\textit{fully open-sourced and continuously maintained} at https://lgy0404.github.io/MemGUI-Bench/.",
            "score": 8,
            "issue_id": 962,
            "pub_date": "2026-02-03",
            "pub_date_card": {
                "ru": "3 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 3",
                "zh": "2æœˆ3æ—¥"
            },
            "hash": "85791424d234c269",
            "authors": [
                "Guangyi Liu",
                "Pengxiang Zhao",
                "Yaozhen Liang",
                "Qinyi Luo",
                "Shunye Tang",
                "Yuxiang Chai",
                "Weifeng Lin",
                "Han Xiao",
                "WenHao Wang",
                "Siheng Chen",
                "Zhengxi Lu",
                "Gao Wu",
                "Hao Wang",
                "Liang Liu",
                "Yong Liu"
            ],
            "affiliations": [
                "Alibaba Group",
                "ByteDance",
                "Huawei",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06075.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞŸĞ°Ğ¼ÑÑ‚ÑŒ ĞºĞ°Ğº ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… GUI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° MemGUI-Bench â€” ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… GUI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğº Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚ĞºĞ¸ Ğ² ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¸ĞºĞ°Ñ… Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ğ³Ğ´Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 5.2-11.8% Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‚ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ, Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ‚Ğ°ĞºÑĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼ 11 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° 5 Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ñ…. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ 128 Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ LLM-as-judge Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ, Ğ²Ñ‹ÑĞ²Ğ¸Ğ² 5 Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ñ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ²ÑĞµÑ… Ğ¾Ñ†ĞµĞ½Ñ‘Ğ½Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ĞµĞµ ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing Memory Evaluation for Mobile GUI Agents",
                    "desc": "This paper addresses the shortcomings of current benchmarks for mobile GUI agents, particularly in evaluating their memory capabilities. It introduces MemGUI-Bench, a new benchmark that focuses on memory tasks and includes a systematic analysis of various agents. The benchmark features 128 tasks designed to challenge memory retention across different contexts and provides a structured evaluation method using advanced metrics. The findings highlight significant memory deficits in existing agents and propose actionable design insights to improve their performance."
                },
                "zh": {
                    "title": "æå‡ç§»åŠ¨GUIä»£ç†çš„è®°å¿†èƒ½åŠ›",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…¨é¢çš„ä»¥è®°å¿†ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯•MemGUI-Benchï¼Œç”¨äºè¯„ä¼°ç§»åŠ¨GUIä»£ç†çš„è®°å¿†èƒ½åŠ›ã€‚ç°æœ‰çš„åŸºå‡†æµ‹è¯•åœ¨è¯„ä¼°è®°å¿†èƒ½åŠ›æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œä»…æœ‰5.2%åˆ°11.8%çš„ä»»åŠ¡ä¸è®°å¿†ç›¸å…³ã€‚æˆ‘ä»¬è®¾è®¡äº†128ä¸ªä»»åŠ¡ï¼Œæ¶µç›–26ä¸ªåº”ç”¨ç¨‹åºï¼Œå…¶ä¸­89.8%çš„ä»»åŠ¡æŒ‘æˆ˜è·¨æ—¶é—´å’Œè·¨ç©ºé—´çš„è®°å¿†ä¿æŒèƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºæ‰€æœ‰è¯„ä¼°ç³»ç»Ÿåœ¨è®°å¿†èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œå¹¶æå‡ºäº†äº”ç§å¯è¡Œçš„è®¾è®¡å»ºè®®ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06391",
            "title": "POINTS-GUI-G: GUI-Grounding Journey",
            "url": "https://huggingface.co/papers/2602.06391",
            "abstract": "GUI agents for automated digital tasks rely on vision-language models with enhanced grounding capabilities, achieved through refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards.  \t\t\t\t\tAI-generated summary \t\t\t\t The rapid advancement of vision-language models has catalyzed the emergence of GUI agents, which hold immense potential for automating complex tasks, from online shopping to flight booking, thereby alleviating the burden of repetitive digital workflows. As a foundational capability, GUI grounding is typically established as a prerequisite for end-to-end task execution. It enables models to precisely locate interface elements, such as text and icons, to perform accurate operations like clicking and typing. Unlike prior works that fine-tune models already possessing strong spatial awareness (e.g., Qwen3-VL), we aim to master the full technical pipeline by starting from a base model with minimal grounding ability, such as POINTS-1.5. We introduce POINTS-GUI-G-8B, which achieves state-of-the-art performance with scores of 59.9 on ScreenSpot-Pro, 66.0 on OSWorld-G, 95.7 on ScreenSpot-v2, and 49.9 on UI-Vision. Our model's success is driven by three key factors: (1) Refined Data Engineering, involving the unification of diverse open-source datasets format alongside sophisticated strategies for augmentation, filtering, and difficulty grading; (2) Improved Training Strategies, including continuous fine-tuning of the vision encoder to enhance perceptual accuracy and maintaining resolution consistency between training and inference; and (3) Reinforcement Learning (RL) with Verifiable Rewards. While RL is traditionally used to bolster reasoning, we demonstrate that it significantly improves precision in the perception-intensive GUI grounding task. Furthermore, GUI grounding provides a natural advantage for RL, as rewards are easily verifiable and highly accurate.",
            "score": 7,
            "issue_id": 962,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "1ce7e27df005ead5",
            "authors": [
                "Zhongyin Zhao",
                "Yuan Liu",
                "Yikun Liu",
                "Haicheng Wang",
                "Le Tian",
                "Xiao Zhou",
                "Yangxiu You",
                "Zilin Yu",
                "Yang Yu",
                "Jie Zhou"
            ],
            "affiliations": [
                "WeChat AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06391.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#rl",
                    "#benchmark",
                    "#agents",
                    "#training",
                    "#cv",
                    "#data"
                ],
                "emoji": "ğŸ–±ï¸",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² GUI Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ POINTS-GUI-G-8B Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑÑ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‚ Ñ‚Ñ€Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°: Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ ÑƒĞ½Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹ Ğ¸ Ğ°ÑƒĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ², Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ĞµĞ¼ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°Ğ¼Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ScreenSpot-Pro (59.9) Ğ¸ OSWorld-G (66.0), Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ Ğ¸ Ğ±Ñ€Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¸Ğ»ĞµÑ‚Ğ¾Ğ², Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ²Ñ‹ĞºĞ°Ğ¼Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Empowering GUI Agents with Enhanced Grounding for Automation",
                    "desc": "This paper discusses the development of GUI agents that automate digital tasks using advanced vision-language models. The authors focus on enhancing grounding capabilities, which allow models to accurately identify and interact with graphical user interface elements. They introduce a new model, POINTS-GUI-G-8B, which outperforms existing models by utilizing refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards. The results show significant improvements in task execution accuracy, demonstrating the effectiveness of their approach in automating complex workflows."
                },
                "zh": {
                    "title": "æå‡GUIä»£ç†çš„è‡ªåŠ¨åŒ–èƒ½åŠ›",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹æ¥è‡ªåŠ¨åŒ–æ•°å­—ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºçš„æ¨¡å‹POINTS-GUI-G-8Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾ç¤ºäº†å…¶åœ¨ç•Œé¢å…ƒç´ å®šä½å’Œæ“ä½œæ‰§è¡Œæ–¹é¢çš„èƒ½åŠ›ã€‚é€šè¿‡ç²¾ç»†çš„æ•°æ®å·¥ç¨‹ã€æ”¹è¿›çš„è®­ç»ƒç­–ç•¥å’Œå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼Œæˆ‘ä»¬æ˜¾è‘—æå‡äº†æ¨¡å‹çš„ç²¾ç¡®åº¦ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼ŒGUIå®šä½ä»»åŠ¡çš„æˆåŠŸä¾èµ–äºè¿™äº›å…³é”®å› ç´ çš„ç»“åˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.05843",
            "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions",
            "url": "https://huggingface.co/papers/2602.05843",
            "abstract": "OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws.  \t\t\t\t\tAI-generated summary \t\t\t\t The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena",
            "score": 7,
            "issue_id": 963,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "22d2e90196a24045",
            "authors": [
                "Fangzhi Xu",
                "Hang Yan",
                "Qiushi Sun",
                "Jinyang Wu",
                "Zixian Huang",
                "Muye Huang",
                "Jingyang Gong",
                "Zichen Ding",
                "Kanzhi Cheng",
                "Yian Wang",
                "Xinyu Che",
                "Zeyi Sun",
                "Jian Zhang",
                "Zhangyue Yin",
                "Haoran Luo",
                "Xuanjing Huang",
                "Ben Kao",
                "Jun Liu",
                "Qika Lin"
            ],
            "affiliations": [
                "Fudan University",
                "Nanjing University",
                "Nanyang Technological University",
                "National University of Singapore",
                "Shanghai AI Laboratory",
                "The University of Hong Kong",
                "Tsinghua University",
                "Xian Jiaotong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.05843.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#benchmark",
                    "#reasoning",
                    "#long_context",
                    "#open_source",
                    "#dataset"
                ],
                "emoji": "ğŸ§­",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ² Ğ¿Ñ€Ğ¸Ñ€Ğ¾Ğ´Ñ‹ Ğ² Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ OdysseyArena â€” Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ¾Ğ¼ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ³Ğ´Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°ĞºĞ¾Ğ½Ñ‹ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¾Ğ² Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰ĞµĞ¹ ÑÑ€ĞµĞ´Ñ‹ Ğ¸Ğ· Ğ¾Ğ¿Ñ‹Ñ‚Ğ°. Ğ¡ÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² ÑĞ¾ÑÑ€ĞµĞ´Ğ¾Ñ‚Ğ¾Ñ‡ĞµĞ½Ñ‹ Ğ½Ğ° Ğ´ĞµĞ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ğµ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‚ ÑĞ²Ğ½Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾ Ğ¿Ñ€ĞµĞ½ĞµĞ±Ñ€ĞµĞ³Ğ°ÑÑ‚ Ğ¸Ğ½Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğº Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒÑÑ‚ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ Ğ¿Ñ€Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ğ²Ğ° Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ğº Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ Ğ´Ğ²Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°: OdysseyArena-Lite Ñ 120 Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ½Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ OdysseyArena-Challenge Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑÑ… (Ğ±Ğ¾Ğ»ĞµĞµ 200 ÑˆĞ°Ğ³Ğ¾Ğ²). Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° 15+ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… LLM Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº Ğ² ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº Ğ¸Ğ½Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰Ğ¸Ñ… ÑÑ€ĞµĞ´Ğ°Ñ…."
                },
                "en": {
                    "title": "Empowering Agents to Learn and Adapt Autonomously",
                    "desc": "OdysseyArena introduces a new framework for assessing large language models (LLMs) in tasks that require long-term planning and the ability to learn from their environment. Unlike traditional evaluations that rely on fixed rules, this framework emphasizes the importance of inductive reasoning, allowing agents to discover underlying transition laws through experience. The framework includes OdysseyArena-Lite for standardized benchmarking with 120 tasks, and OdysseyArena-Challenge to evaluate agent performance over extended interactions. Experiments show that even advanced LLMs struggle with these inductive tasks, highlighting a significant challenge in developing autonomous agents capable of effective long-term decision-making."
                },
                "zh": {
                    "title": "è‡ªä¸»å‘ç°çš„æœªæ¥ï¼šOdysseyArenaæ¡†æ¶",
                    "desc": "OdysseyArenaæ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æ—¶é—´èŒƒå›´å†…çš„è‡ªä¸»å‘ç°ç¯å¢ƒè½¬å˜è§„å¾‹çš„èƒ½åŠ›ã€‚ç°æœ‰çš„è¯„ä¼°æ–¹æ³•ä¸»è¦åŸºäºæ¼”ç»æ¨ç†ï¼Œå¿½è§†äº†ä»£ç†ä»ç»éªŒä¸­è‡ªä¸»å‘ç°æ½œåœ¨è½¬å˜è§„å¾‹çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬æå‡ºäº†OdysseyArenaï¼Œé‡æ–°èšç„¦äºé•¿æ—¶é—´èŒƒå›´å†…çš„ä¸»åŠ¨å’Œå½’çº³äº¤äº’ï¼Œå»ºç«‹äº†å››ä¸ªåŸºæœ¬åŸç†ï¼Œå°†æŠ½è±¡çš„è½¬å˜åŠ¨æ€è½¬åŒ–ä¸ºå…·ä½“çš„äº¤äº’ç¯å¢ƒã€‚é€šè¿‡æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯•OdysseyArena-Liteï¼Œæˆ‘ä»¬æä¾›äº†120ä¸ªä»»åŠ¡æ¥è¡¡é‡ä»£ç†çš„å½’çº³æ•ˆç‡å’Œé•¿æ—¶é—´å‘ç°èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.01734",
            "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
            "url": "https://huggingface.co/papers/2602.01734",
            "abstract": "Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.  \t\t\t\t\tAI-generated summary \t\t\t\t Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via Î¼P, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.",
            "score": 6,
            "issue_id": 963,
            "pub_date": "2026-02-02",
            "pub_date_card": {
                "ru": "2 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 2",
                "zh": "2æœˆ2æ—¥"
            },
            "hash": "3da9fd3fb00930a1",
            "authors": [
                "Lianhai Ren",
                "Yucheng Ding",
                "Xiao Liu",
                "Qianxiao Li",
                "Peng Cheng",
                "Yeyun Gong"
            ],
            "affiliations": [
                "Department of Mathematics, National University of Singapore",
                "Microsoft SIGMA Team, Microsoft Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.01734.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "MSign: ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ½Ğ³Ğ° Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€Ğ¾ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ²Ğ·Ñ€Ñ‹Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ¾ÑÑ‚Ğ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ Ğ´Ğ²Ğ° ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ, Ğ¿Ñ€ĞµĞ´ÑˆĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ĞºĞ¾Ğ»Ğ»Ğ°Ğ¿ÑÑƒ: ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ½Ğ³Ğ° Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ† Ğ²ĞµÑĞ¾Ğ² Ğ¸ Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚Ğ°ÑÑ‰ĞµĞµ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞºĞ¾Ğ±Ğ¸Ğ°Ğ½Ğ¾Ğ² ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ñ… ÑĞ»Ğ¾Ñ‘Ğ². ĞĞ½Ğ¸ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ²Ğ¼ĞµÑÑ‚Ğµ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ¾ÑÑ‚ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸. Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ MSign, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°ĞºĞ° Ğ´Ğ»Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ½Ğ³Ğ°."
                },
                "en": {
                    "title": "Stabilizing Training in Large Language Models with MSign",
                    "desc": "This paper addresses the problem of training instability in large language models, which often leads to gradient explosions during pretraining. The authors identify two critical factors that contribute to this instability: a rapid decline in the stable rank of weight matrices and increased alignment of Jacobians between layers. They introduce a new optimizer called MSign, which uses matrix sign operations to maintain stable rank and prevent these issues. Experimental results show that MSign successfully mitigates training failures with minimal additional computational cost."
                },
                "zh": {
                    "title": "è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒä¸ç¨³å®šæ€§çš„æ–°æ–¹æ³•",
                    "desc": "åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒä¸­ï¼Œè®­ç»ƒä¸ç¨³å®šæ€§æ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ï¼Œå¸¸å¸¸è¡¨ç°ä¸ºçªå‘çš„æ¢¯åº¦çˆ†ç‚¸ï¼Œæµªè´¹å¤§é‡è®¡ç®—èµ„æºã€‚æˆ‘ä»¬ç ”ç©¶äº†ä¸€ä¸ª5Må‚æ•°çš„NanoGPTæ¨¡å‹çš„è®­ç»ƒå¤±è´¥ï¼Œå‘ç°äº†å¯¼è‡´å´©æºƒçš„ä¸¤ä¸ªå…³é”®ç°è±¡ï¼šæƒé‡çŸ©é˜µç¨³å®šç§©çš„å¿«é€Ÿä¸‹é™å’Œç›¸é‚»å±‚é›…å¯æ¯”çŸ©é˜µä¹‹é—´çš„å¯¹é½å¢åŠ ã€‚æˆ‘ä»¬ç†è®ºè¯æ˜è¿™ä¸¤ä¸ªæ¡ä»¶å…±åŒå¯¼è‡´äº†éšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œæ¢¯åº¦èŒƒæ•°çš„æŒ‡æ•°å¢é•¿ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ä¸ç¨³å®šæœºåˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†MSignï¼Œä¸€ç§æ–°çš„ä¼˜åŒ–å™¨ï¼Œé€šè¿‡å‘¨æœŸæ€§åœ°åº”ç”¨çŸ©é˜µç¬¦å·æ“ä½œæ¥æ¢å¤ç¨³å®šç§©ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06960",
            "title": "InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning",
            "url": "https://huggingface.co/papers/2602.06960",
            "abstract": "InftyThink+ uses reinforcement learning to optimize iterative reasoning processes, improving accuracy and efficiency in large language models.  \t\t\t\t\tAI-generated summary \t\t\t\t Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization. InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning, enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.",
            "score": 5,
            "issue_id": 962,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "0d9d6ab163765d9f",
            "authors": [
                "Yuchen Yan",
                "Liang Jiang",
                "Jin Jiang",
                "Shuaicheng Li",
                "Zujie Wen",
                "Zhiqiang Zhang",
                "Jun Zhou",
                "Jian Shao",
                "Yueting Zhuang",
                "Yongliang Shen"
            ],
            "affiliations": [
                "Ant Group",
                "Peking University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06960.jpg",
            "data": {
                "categories": [
                    "#small_models",
                    "#optimization",
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#long_context"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° InftyThink+, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ğ·Ğ°ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ² ÑĞµÑ€ĞµĞ´Ğ¸Ğ½Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ° Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ñ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ñ€ĞµĞ·ÑĞ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ ÑÑ‚Ğ¾ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµÑ‚ÑŒ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ…ĞµĞ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ñ€ĞµÑˆĞµĞ½Ğ¸ÑĞ¼ Ğ¾ Ñ‚Ğ¾Ğ¼, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¸ ĞºĞ°Ğº Ñ€ĞµĞ·ÑĞ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° 21% Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ğ¸, Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑ Ğ»ÑƒÑ‡ÑˆÑƒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ…."
                },
                "en": {
                    "title": "Optimizing Reasoning with Reinforcement Learning",
                    "desc": "InftyThink+ is a novel framework that enhances large language models by using reinforcement learning to optimize iterative reasoning processes. It addresses the limitations of traditional reasoning methods, such as high computational costs and context length restrictions, by implementing strategic summarization of intermediate thoughts. The framework employs a two-stage training approach, starting with supervised learning and transitioning to reinforcement learning, allowing the model to effectively decide when to summarize and how to continue reasoning. Experimental results show that InftyThink+ significantly boosts accuracy and efficiency, outperforming existing methods in both reasoning performance and inference speed."
                },
                "zh": {
                    "title": "ä¼˜åŒ–æ¨ç†ï¼Œæå‡æ•ˆç‡â€”â€”InftyThink+",
                    "desc": "InftyThink+ æ˜¯ä¸€ä¸ªä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è¿­ä»£æ¨ç†è¿‡ç¨‹çš„æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¯¥æ–¹æ³•é€šè¿‡å®šæœŸæ€»ç»“ä¸­é—´æ€è·¯æ¥ç¼“è§£æ¨ç†è¿‡ç¨‹ä¸­çš„é—®é¢˜ï¼Œå¦‚äºŒæ¬¡æˆæœ¬å’Œä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒInftyThink+ é‡‡ç”¨ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ï¼Œä¼˜åŒ–æ•´ä¸ªè¿­ä»£æ¨ç†è½¨è¿¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒInftyThink+ åœ¨å‡†ç¡®æ€§å’Œæ¨ç†æ•ˆç‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06949",
            "title": "DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos",
            "url": "https://huggingface.co/papers/2602.06949",
            "abstract": "DreamDojo is a foundation world model trained on 44k hours of egocentric human videos that enables efficient simulation of dexterous robotic tasks through continuous latent actions and real-time distillation.  \t\t\t\t\tAI-generated summary \t\t\t\t Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels, we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world models, including live teleoperation, policy evaluation, and model-based planning. Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world models.",
            "score": 5,
            "issue_id": 962,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "4b7549558bf19284",
            "authors": [
                "Shenyuan Gao",
                "William Liang",
                "Kaiyuan Zheng",
                "Ayaan Malik",
                "Seonghyeon Ye",
                "Sihyun Yu",
                "Wei-Cheng Tseng",
                "Yuzhu Dong",
                "Kaichun Mo",
                "Chen-Hsuan Lin",
                "Qianli Ma",
                "Seungjun Nah",
                "Loic Magne",
                "Jiannan Xiang",
                "Yuqi Xie",
                "Ruijie Zheng",
                "Dantong Niu",
                "You Liang Tan",
                "K. R. Zentner",
                "George Kurian",
                "Suneel Indupuru",
                "Pooya Jannaty",
                "Jinwei Gu",
                "Jun Zhang",
                "Jitendra Malik",
                "Pieter Abbeel",
                "Ming-Yu Liu",
                "Yuke Zhu",
                "Joel Jang",
                "Linxi \"Jim\" Fan"
            ],
            "affiliations": [
                "HKUST",
                "KAIST",
                "NVIDIA",
                "Stanford",
                "UC Berkeley",
                "UCSD",
                "UT Austin",
                "UW"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06949.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#open_source",
                    "#synthetic",
                    "#transfer_learning",
                    "#video",
                    "#training",
                    "#robotics",
                    "#dataset"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ Ğ»Ğ¾Ğ²ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ±Ğ¾ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°",
                    "desc": "DreamDojo â€” ÑÑ‚Ğ¾ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ°, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° 44 Ñ‚Ñ‹ÑÑÑ‡Ğ°Ñ… Ñ‡Ğ°ÑĞ¾Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¾Ñ‚ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ñ†Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ². ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ğµ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ ĞµĞ´Ğ¸Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ½ĞµĞ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾, Ñ€ĞµÑˆĞ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ½ĞµÑ…Ğ²Ğ°Ñ‚ĞºĞ¸ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. ĞŸĞ¾ÑĞ»Ğµ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ (10.81 FPS) Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ¸Ğ·Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ Ñ‚ĞµĞ»ĞµĞ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸, Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… out-of-distribution Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Revolutionizing Robotics with DreamDojo: A New Era of Simulation and Control",
                    "desc": "DreamDojo is a foundational world model that leverages 44,000 hours of egocentric human videos to simulate complex robotic tasks effectively. It addresses the challenges of limited data and scarce action labels by introducing continuous latent actions, which serve as unified proxy actions for better knowledge transfer. After fine-tuning on specific robot data, DreamDojo exhibits strong physics understanding and precise control capabilities. This model not only accelerates real-time performance but also enhances context consistency, making it suitable for various applications like teleoperation and model-based planning."
                },
                "zh": {
                    "title": "DreamDojoï¼šçµå·§æœºå™¨äººä»»åŠ¡çš„æœªæ¥æ¨¡æ‹Ÿå™¨",
                    "desc": "DreamDojoæ˜¯ä¸€ä¸ªåŸºç¡€ä¸–ç•Œæ¨¡å‹ï¼Œåˆ©ç”¨44000å°æ—¶çš„è‡ªæˆ‘ä¸­å¿ƒäººç±»è§†é¢‘è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿé«˜æ•ˆæ¨¡æ‹Ÿçµå·§æœºå™¨äººä»»åŠ¡ã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥è¿ç»­æ½œåœ¨åŠ¨ä½œä½œä¸ºç»Ÿä¸€çš„ä»£ç†åŠ¨ä½œï¼Œè§£å†³äº†åŠ¨ä½œæ ‡ç­¾ç¨€ç¼ºçš„é—®é¢˜ï¼Œä»è€Œå¢å¼ºäº†ä»æœªæ ‡è®°è§†é¢‘ä¸­è½¬ç§»äº¤äº’çŸ¥è¯†çš„èƒ½åŠ›ã€‚ç»è¿‡å°è§„æ¨¡ç›®æ ‡æœºå™¨äººæ•°æ®çš„åè®­ç»ƒï¼ŒDreamDojoå±•ç°å‡ºå¯¹ç‰©ç†çš„å¼ºç†è§£å’Œç²¾ç¡®çš„åŠ¨ä½œæ§åˆ¶èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºåŸºäºç”Ÿæˆä¸–ç•Œæ¨¡å‹çš„é‡è¦åº”ç”¨å¥ å®šäº†åŸºç¡€ï¼ŒåŒ…æ‹¬å®æ—¶é¥æ“ä½œã€ç­–ç•¥è¯„ä¼°å’ŒåŸºäºæ¨¡å‹çš„è§„åˆ’ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06663",
            "title": "PlanViz: Evaluating Planning-Oriented Image Generation and Editing for Computer-Use Tasks",
            "url": "https://huggingface.co/papers/2602.06663",
            "abstract": "PlanViz benchmark evaluates unified multimodal models' capabilities in computer-use planning tasks through route planning, work diagramming, and web&UI displaying sub-tasks with a task-adaptive scoring system.  \t\t\t\t\tAI-generated summary \t\t\t\t Unified multimodal models (UMMs) have shown impressive capabilities in generating natural images and supporting multimodal reasoning. However, their potential in supporting computer-use planning tasks, which are closely related to our lives, remain underexplored. Image generation and editing in computer-use tasks require capabilities like spatial reasoning and procedural understanding, and it is still unknown whether UMMs have these capabilities to finish these tasks or not. Therefore, we propose PlanViz, a new benchmark designed to evaluate image generation and editing for computer-use tasks. To achieve the goal of our evaluation, we focus on sub-tasks which frequently involve in daily life and require planning steps. Specifically, three new sub-tasks are designed: route planning, work diagramming, and web&UI displaying. We address challenges in data quality ensuring by curating human-annotated questions and reference images, and a quality control process. For challenges of comprehensive and exact evaluation, a task-adaptive score, PlanScore, is proposed. The score helps understanding the correctness, visual quality and efficiency of generated images. Through experiments, we highlight key limitations and opportunities for future research on this topic.",
            "score": 5,
            "issue_id": 962,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "83fea21ac7f4026f",
            "authors": [
                "Junxian Li",
                "Kai Liu",
                "Leyang Chen",
                "Weida Wang",
                "Zhixin Wang",
                "Jiaqi Xu",
                "Fan Li",
                "Renjing Pei",
                "Linghe Kong",
                "Yulun Zhang"
            ],
            "affiliations": [
                "Alibaba Group",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06663.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#multimodal",
                    "#benchmark",
                    "#cv",
                    "#dataset"
                ],
                "emoji": "ğŸ“‹",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ°",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº PlanViz Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ°, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğµ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ, Ğ´Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ñ Ğ²ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°Ğ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ñ‹ Ñ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸Ñ… ÑƒĞ¼ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ´ÑƒÑ€. Ğ”Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ PlanScore, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° Ğ²Ñ‹ÑĞ²Ğ»ÑÑÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Evaluating Multimodal Models for Everyday Computer Planning Tasks",
                    "desc": "The paper introduces PlanViz, a benchmark designed to assess the capabilities of unified multimodal models (UMMs) in performing computer-use planning tasks. It focuses on three specific sub-tasks: route planning, work diagramming, and web & UI displaying, which are relevant to everyday life. The benchmark employs a task-adaptive scoring system called PlanScore to evaluate the correctness, visual quality, and efficiency of the generated images. This research aims to uncover the strengths and weaknesses of UMMs in spatial reasoning and procedural understanding within the context of computer-use tasks."
                },
                "zh": {
                    "title": "è¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹åœ¨è®¡ç®—æœºä½¿ç”¨è§„åˆ’ä¸­çš„èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æå‡ºäº†PlanVizåŸºå‡†ï¼Œç”¨äºè¯„ä¼°ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹åœ¨è®¡ç®—æœºä½¿ç”¨è§„åˆ’ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†é€šè¿‡è·¯çº¿è§„åˆ’ã€å·¥ä½œå›¾ç¤ºå’Œç½‘é¡µä¸ç”¨æˆ·ç•Œé¢å±•ç¤ºç­‰å­ä»»åŠ¡ï¼Œé‡‡ç”¨ä»»åŠ¡è‡ªé€‚åº”è¯„åˆ†ç³»ç»Ÿè¿›è¡Œè¯„ä¼°ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹åœ¨ç”Ÿæˆè‡ªç„¶å›¾åƒå’Œæ”¯æŒå¤šæ¨¡æ€æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è®¡ç®—æœºä½¿ç”¨è§„åˆ’ä»»åŠ¡ä¸­çš„æ½œåŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚é€šè¿‡å®éªŒï¼Œæˆ‘ä»¬æ­ç¤ºäº†å½“å‰æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æœºä¼šã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.05281",
            "title": "Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities",
            "url": "https://huggingface.co/papers/2602.05281",
            "abstract": "A novel reinforcement learning approach called ARM addresses entropy collapse in LLM reasoning by equilibrating confidence levels across correct responses through dynamic reward shaping.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an indispensable paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard policy optimization methods, such as Group Relative Policy Optimization (GRPO), often converge to low-entropy policies, leading to severe mode collapse and limited output diversity. We analyze this issue from the perspective of sampling probability dynamics, identifying that the standard objective disproportionately reinforces the highest-likelihood paths, thereby suppressing valid alternative reasoning chains. To address this, we propose a novel Advantage Re-weighting Mechanism (ARM) designed to equilibrate the confidence levels across all correct responses. By incorporating Prompt Perplexity and Answer Confidence into the advantage estimation, our method dynamically reshapes the reward signal to attenuate the gradient updates of over-confident reasoning paths, while redistributing probability mass toward under-explored correct solutions. Empirical results demonstrate that our approach significantly enhances generative diversity and response entropy while maintaining competitive accuracy, effectively achieving a superior trade-off between exploration and exploitation in reasoning tasks. Empirical results on Qwen2.5 and DeepSeek models across mathematical and coding benchmarks show that ProGRPO significantly mitigates entropy collapse. Specifically, on Qwen2.5-7B, our method outperforms GRPO by 5.7% in Pass@1 and, notably, by 13.9% in Pass@32, highlighting its superior capability in generating diverse correct reasoning paths.",
            "score": 5,
            "issue_id": 962,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "2267e7fff36f239f",
            "authors": [
                "Pengyi Li",
                "Elizaveta Goncharova",
                "Andrey Kuznetsov",
                "Ivan Oseledets"
            ],
            "affiliations": [
                "FusionBrain Lab, Russia Mathematics, Russia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.05281.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "âš–ï¸",
                "ru": {
                    "title": "Ğ£Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ²ĞµÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ARM (Advantage Re-weighting Mechanism) Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ ĞºĞ¾Ğ»Ğ»Ğ°Ğ¿ÑĞ° ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº GRPO, Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´ÑÑ‚ Ğº Ğ½Ğ¸Ğ·ĞºĞ¾ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¹Ğ½Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ², Ñ‚Ğ°Ğº ĞºĞ°Ğº Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ¾ ÑƒÑĞ¸Ğ»Ğ¸Ğ²Ğ°ÑÑ‚ Ğ¿ÑƒÑ‚Ğ¸ Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ¹ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ¾ÑĞ»Ğ°Ğ±Ğ»ÑÑ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿ĞµÑ€ĞµÑ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑÑ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñƒ Ğ¼Ğ°Ğ»Ğ¾Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Qwen2.5 Ğ¸ DeepSeek Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Balancing Confidence for Diverse Reasoning in LLMs",
                    "desc": "The paper introduces a new reinforcement learning method called Advantage Re-weighting Mechanism (ARM) to tackle the problem of entropy collapse in Large Language Models (LLMs). Traditional methods like Group Relative Policy Optimization (GRPO) often lead to low diversity in outputs due to over-reliance on high-likelihood responses. ARM addresses this by dynamically adjusting the reward structure to balance confidence levels across all valid responses, promoting exploration of alternative reasoning paths. Experimental results show that ARM improves generative diversity and response entropy while maintaining accuracy, outperforming GRPO in various benchmarks."
                },
                "zh": {
                    "title": "å¹³è¡¡ç½®ä¿¡åº¦ï¼Œæå‡æ¨ç†å¤šæ ·æ€§",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç§°ä¸ºä¼˜åŠ¿é‡åŠ æƒæœºåˆ¶ï¼ˆARMï¼‰ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­çš„ç†µå´©æºƒé—®é¢˜ã€‚é€šè¿‡åŠ¨æ€å¥–åŠ±å¡‘å½¢ï¼ŒARMèƒ½å¤Ÿå¹³è¡¡æ‰€æœ‰æ­£ç¡®å“åº”çš„ç½®ä¿¡æ°´å¹³ï¼Œé¿å…äº†ä¼ ç»Ÿç­–ç•¥ä¼˜åŒ–æ–¹æ³•å¯¼è‡´çš„ä½ç†µç­–ç•¥å’Œæ¨¡å¼å´©æºƒã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ç»“åˆæç¤ºå›°æƒ‘åº¦å’Œç­”æ¡ˆç½®ä¿¡åº¦æ¥é‡æ–°å¡‘é€ å¥–åŠ±ä¿¡å·ï¼Œä»è€ŒæŠ‘åˆ¶è¿‡äºè‡ªä¿¡çš„æ¨ç†è·¯å¾„çš„æ¢¯åº¦æ›´æ–°ï¼Œå¹¶å°†æ¦‚ç‡è´¨é‡é‡æ–°åˆ†é…ç»™æœªå……åˆ†æ¢ç´¢çš„æ­£ç¡®è§£å†³æ–¹æ¡ˆã€‚å®éªŒè¯æ˜ï¼ŒARMæ˜¾è‘—æé«˜äº†ç”Ÿæˆçš„å¤šæ ·æ€§å’Œå“åº”ç†µï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰åŠ›çš„å‡†ç¡®æ€§ï¼ŒæˆåŠŸå®ç°äº†æ¨ç†ä»»åŠ¡ä¸­æ¢ç´¢ä¸åˆ©ç”¨çš„ä¼˜è¶Šå¹³è¡¡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.05367",
            "title": "RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs",
            "url": "https://huggingface.co/papers/2602.05367",
            "abstract": "Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs.  \t\t\t\t\tAI-generated summary \t\t\t\t Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary (pm1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a 4.49times inference speed-up over full-precision models on an RTX 4090.",
            "score": 4,
            "issue_id": 963,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "042ce2bd26c0169f",
            "authors": [
                "Youngcheon You",
                "Banseok Lee",
                "Minseop Choi",
                "Seonyoung Kim",
                "Hyochan Chong",
                "Changdong Kim",
                "Youngmin Kim",
                "Dongkyu Kim"
            ],
            "affiliations": [
                "Samsung Research, Seoul, Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.05367.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#architecture",
                    "#training",
                    "#optimization"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° LLM",
                    "desc": "RaBiT â€” ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ñ… Ğ¿ÑƒÑ‚ĞµĞ¹. ĞšĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ·Ğ°ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ¸Ğ· Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ²ĞµÑĞ°, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼ ÑĞ»Ğ¾ĞµĞ¼. ĞœĞµÑ‚Ğ¾Ğ´ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ½Ğ°Ğ´Ñ‘Ğ¶Ğ½ÑƒÑ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ°Ğ´ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸Ğ±Ğ»Ğ¸Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ²ĞµÑĞ¾Ğ². RaBiT Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ, ĞºĞ¾Ğ½ĞºÑƒÑ€Ğ¸Ñ€ÑƒÑ Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ 4,49-ĞºÑ€Ğ°Ñ‚Ğ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ğ½Ğ° RTX 4090."
                },
                "en": {
                    "title": "RaBiT: Revolutionizing Quantization for Efficient LLMs",
                    "desc": "The paper introduces the Residual Binarization framework (RaBiT) to tackle the issue of feature co-adaptation in quantized large language models (LLMs). It highlights a problem called inter-path adaptation, where multiple binary paths learn similar features, which reduces the model's performance. RaBiT addresses this by creating a hierarchical structure for binary paths that ensures each path builds on the previous one, improving error correction. This method not only enhances accuracy but also significantly speeds up inference, outperforming traditional quantization techniques."
                },
                "zh": {
                    "title": "æ®‹å·®äºŒå€¼åŒ–ï¼šæå‡é‡åŒ–æ¨¡å‹æ€§èƒ½çš„åˆ›æ–°æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºRaBiTçš„æ®‹å·®äºŒå€¼åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é‡åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„ç‰¹å¾å…±é€‚åº”é—®é¢˜ã€‚é€šè¿‡åˆ†å±‚è·¯å¾„æ¨å¯¼å’Œç¨³å¥åˆå§‹åŒ–ï¼ŒRaBiTèƒ½å¤Ÿåœ¨ä½æ¯”ç‰¹æ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ä¹‹é—´å®ç°ä¼˜è¶Šçš„æƒè¡¡ã€‚è¯¥æ¡†æ¶é€šè¿‡ç®—æ³•æ€§åœ°å¼ºåˆ¶æ‰§è¡Œæ®‹å·®å±‚æ¬¡ç»“æ„ï¼Œç¡®ä¿æ¯ä¸ªäºŒè¿›åˆ¶è·¯å¾„éƒ½èƒ½çº æ­£å‰ä¸€ä¸ªè·¯å¾„çš„é”™è¯¯ï¼Œä»è€Œæé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚æœ€ç»ˆï¼ŒRaBiTåœ¨2æ¯”ç‰¹ç²¾åº¦æ•ˆç‡çš„å‰æ²¿ä¸Šé‡æ–°å®šä¹‰äº†æ€§èƒ½æ ‡å‡†ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06854",
            "title": "SEMA: Simple yet Effective Learning for Multi-Turn Jailbreak Attacks",
            "url": "https://huggingface.co/papers/2602.06854",
            "abstract": "A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and datasets.  \t\t\t\t\tAI-generated summary \t\t\t\t Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average 80.1% ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA.",
            "score": 3,
            "issue_id": 963,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "5545fb68273ad4d6",
            "authors": [
                "Mingqian Feng",
                "Xiaodong Liu",
                "Weiwei Yang",
                "Jialin Song",
                "Xuekai Zhu",
                "Chenliang Xu",
                "Jianfeng Gao"
            ],
            "affiliations": [
                "Microsoft Research",
                "University of Rochester"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06854.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rl",
                    "#alignment",
                    "#security",
                    "#open_source"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "ĞœĞ½Ğ¾Ğ³Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ğµ Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ½Ğ° LLM Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ±ĞµĞ· Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº SEMA Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ°Ñ‚Ğ°Ğº Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ±ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ¸ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞœĞµÑ‚Ğ¾Ğ´ ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… ÑÑ‚Ğ°Ğ¿Ğ¾Ğ²: Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ ÑĞ°Ğ¼Ğ¾Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¾Ğ¹ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ñ‹Ñ… Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ´Ñ€ĞµĞ¹Ñ„Ğ° Ğ¸Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ğ¾Ğ¹ Ñ†ĞµĞ»Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²Ğ° Ğ² Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ğ°Ñ‚Ğ°Ğº (80.1% Ğ½Ğ° AdvBench), Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ğµ Ğ¸ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚ĞµĞ½, Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¸ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸-Ğ¶ĞµÑ€Ñ‚Ğ²Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "SEMA: Revolutionizing Multi-Turn Attacks for Safer Language Models",
                    "desc": "The paper introduces SEMA, a new framework designed to train multi-turn attackers for large language models (LLMs) without using existing strategies or external data. It addresses the limitations of previous methods that struggle with exploration complexity and intent drift by employing a two-stage process: prefilling self-tuning and reinforcement learning with intent-drift-aware rewards. SEMA achieves state-of-the-art attack success rates by effectively generating adversarial prompts that maintain harmful intent across multiple turns. This approach is compact, reproducible, and transferable, making it a robust tool for testing the safety of LLMs."
                },
                "zh": {
                    "title": "SEMAï¼šå¤šè½®æ”»å‡»çš„æ–°æ¡†æ¶ï¼Œæå‡è¯­è¨€æ¨¡å‹å®‰å…¨æ€§",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºSEMAçš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨æœ‰æ•ˆè®­ç»ƒå¤šè½®æ”»å‡»è€…ï¼Œä»¥åº”å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§é—®é¢˜ã€‚SEMAä¸ä¾èµ–äºç°æœ‰ç­–ç•¥æˆ–å¤–éƒ¨æ•°æ®ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒæ¨¡å‹å’Œæ•°æ®é›†ä¸Šå®ç°æœ€å…ˆè¿›çš„æ”»å‡»æˆåŠŸç‡ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šè‡ªæˆ‘è°ƒä¼˜çš„é¢„å¡«å……å’ŒåŸºäºæ„å›¾æ¼‚ç§»çš„å¼ºåŒ–å­¦ä¹ ï¼Œç¡®ä¿ç”Ÿæˆæœ‰æ•ˆçš„å¤šè½®å¯¹æŠ—æç¤ºã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼ŒSEMAåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæä¾›äº†æ›´å¼ºå¤§å’Œç°å®çš„å‹åŠ›æµ‹è¯•ï¼Œä¿ƒè¿›äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ç ”ç©¶ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06471",
            "title": "Revisiting the Shape Convention of Transformer Language Models",
            "url": "https://huggingface.co/papers/2602.06471",
            "abstract": "Replacing conventional feed-forward networks with hourglass-shaped MLPs in Transformers improves model efficiency and performance by enabling better parameter utilization and competitive scaling.  \t\t\t\t\tAI-generated summary \t\t\t\t Dense Transformer language models have largely adhered to one consistent architectural shape: each layer consists of an attention module followed by a feed-forward network (FFN) with a narrow-wide-narrow MLP, allocating most parameters to the MLP at expansion ratios between 2 and 4. Motivated by recent results that residual wide-narrow-wide (hourglass) MLPs offer superior function approximation capabilities, we revisit the long-standing MLP shape convention in Transformer, challenging the necessity of the narrow-wide-narrow design. To study this, we develop a Transformer variant that replaces the conventional FFN with a deeper hourglass-shaped FFN, comprising a stack of hourglass sub-MLPs connected by residual pathways. We posit that a deeper but lighter hourglass FFN can serve as a competitive alternative to the conventional FFN, and that parameters saved by using a lighter hourglass FFN can be more effectively utilized, such as by enlarging model hidden dimensions under fixed budgets. We confirm these through empirical validations across model scales: hourglass FFNs outperform conventional FFNs up to 400M and achieve comparable performance at larger scales to 1B parameters; hourglass FFN variants with reduced FFN and increased attention parameters show consistent improvements over conventional configurations at matched budgets. Together, these findings shed new light on recent work and prompt a rethinking of the narrow-wide-narrow MLP convention and the balance between attention and FFN towards efficient and expressive modern language models.",
            "score": 1,
            "issue_id": 962,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "766c634e6c31c129",
            "authors": [
                "Feng-Ting Liao",
                "Meng-Hsi Chen",
                "Guan-Ting Yi",
                "Da-shan Shiu"
            ],
            "affiliations": [
                "MediaTek Research",
                "National Taiwan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06471.jpg",
            "data": {
                "categories": [
                    "#optimization"
                ],
                "emoji": "â³",
                "ru": {
                    "title": "ĞŸĞµÑĞ¾Ñ‡Ğ½Ñ‹Ğµ Ñ‡Ğ°ÑÑ‹ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¸: Ğ¿ĞµÑ€ĞµĞ¾ÑĞ¼Ñ‹ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ²",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ñ‹Ğµ ÑĞµÑ‚Ğ¸ (FFN) Ğ² Ğ¢Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ°Ñ… Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğµ ÑĞµÑ‚Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğµ Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ñ‹Ñ… Ñ‡Ğ°ÑĞ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ¾-ÑƒĞ·ĞºĞ¾-Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ (hourglass) Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ĞœĞ›ĞŸ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ»ÑƒÑ‡ÑˆÑƒÑ Ğ°Ğ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ÑƒĞ·ĞºĞ¾-ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾-ÑƒĞ·ĞºĞ¾Ğ¹ ÑÑ…ĞµĞ¼Ğ¾Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ñ‹Ñ… Ñ‡Ğ°ÑĞ¾Ğ² Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ´Ğ¾ 400 Ğ¼Ğ»Ğ½ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹, ÑÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° FFN, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ĞµĞµ Ğ¿ĞµÑ€ĞµÑ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ² ÑĞ»Ğ¾Ğ¸ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ. Ğ­Ñ‚Ğ¸ Ğ½Ğ°Ñ…Ğ¾Ğ´ĞºĞ¸ Ğ¿ĞµÑ€ĞµĞ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ÑÑ‚ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ¾Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ»Ğ¾ÑĞ¼Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¸ Ğ²Ñ‹Ñ€Ğ°Ğ·Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Rethinking MLP Shapes for Efficient Transformers",
                    "desc": "This paper explores the use of hourglass-shaped multi-layer perceptrons (MLPs) in Transformers, replacing the traditional narrow-wide-narrow feed-forward networks (FFNs). The authors argue that hourglass MLPs provide better parameter efficiency and performance by allowing for deeper architectures with effective residual connections. Empirical results show that hourglass FFNs outperform conventional designs in smaller models and maintain competitive performance in larger models. This research encourages a reevaluation of the standard MLP structure in Transformers, promoting a more efficient balance between attention mechanisms and feed-forward networks."
                },
                "zh": {
                    "title": "ç”¨å°æ—¶glass MLPæå‡Transformeræ•ˆç‡ä¸æ€§èƒ½",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„Transformeræ¶æ„ï¼Œä½¿ç”¨å°æ—¶glasså½¢çŠ¶çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰æ›¿ä»£ä¼ ç»Ÿçš„å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰ï¼Œä»¥æé«˜æ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°æ—¶glass MLPåœ¨å‚æ•°åˆ©ç”¨ç‡å’ŒåŠŸèƒ½é€¼è¿‘èƒ½åŠ›ä¸Šä¼˜äºä¼ ç»Ÿçš„çª„-å®½-çª„è®¾è®¡ã€‚é€šè¿‡å®éªŒè¯æ˜ï¼Œå°æ—¶glass FFNåœ¨æ¨¡å‹è§„æ¨¡è¾¾åˆ°4äº¿å‚æ•°æ—¶è¡¨ç°ä¼˜äºä¼ ç»ŸFFNï¼Œå¹¶åœ¨æ›´å¤§è§„æ¨¡ï¼ˆå¦‚10äº¿å‚æ•°ï¼‰æ—¶æ€§èƒ½ç›¸å½“ã€‚è¯¥ç ”ç©¶ä¿ƒä½¿æˆ‘ä»¬é‡æ–°æ€è€ƒTransformerä¸­FFNä¸æ³¨æ„åŠ›æœºåˆ¶ä¹‹é—´çš„å¹³è¡¡ï¼Œæ¨åŠ¨ç°ä»£è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆä¸è¡¨è¾¾èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06139",
            "title": "EgoAVU: Egocentric Audio-Visual Understanding",
            "url": "https://huggingface.co/papers/2602.06139",
            "abstract": "Multi-modal large language models struggle to jointly understand audio and visual signals in egocentric videos, but a new scalable data engine and dataset significantly improve their performance through targeted fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Understanding egocentric videos plays a vital role for embodied intelligence. Recent multi-modal large language models (MLLMs) can accept both visual and audio inputs. However, due to the challenge of obtaining text labels with coherent joint-modality information, whether MLLMs can jointly understand both modalities in egocentric videos remains under-explored. To address this problem, we introduce EgoAVU, a scalable data engine to automatically generate egocentric audio-visual narrations, questions, and answers. EgoAVU enriches human narrations with multimodal context and generates audio-visual narrations through cross-modal correlation modeling. Token-based video filtering and modular, graph-based curation ensure both data diversity and quality. Leveraging EgoAVU, we construct EgoAVU-Instruct, a large-scale training dataset of 3M samples, and EgoAVU-Bench, a manually verified evaluation split covering diverse tasks. EgoAVU-Bench clearly reveals the limitations of existing MLLMs: they bias heavily toward visual signals, often neglecting audio cues or failing to correspond audio with the visual source. Finetuning MLLMs on EgoAVU-Instruct effectively addresses this issue, enabling up to 113% performance improvement on EgoAVU-Bench. Such benefits also transfer to other benchmarks such as EgoTempo and EgoIllusion, achieving up to 28% relative performance gain. Code will be released to the community.",
            "score": 1,
            "issue_id": 962,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "5b2f07457e4c1967",
            "authors": [
                "Ashish Seth",
                "Xinhao Mei",
                "Changsheng Zhao",
                "Varun Nagaraja",
                "Ernie Chang",
                "Gregory P. Meyer",
                "Gael Le Lan",
                "Yunyang Xiong",
                "Vikas Chandra",
                "Yangyang Shi",
                "Dinesh Manocha",
                "Zhipeng Cai"
            ],
            "affiliations": [
                "Meta",
                "University of Maryland, College Park"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06139.jpg",
            "data": {
                "categories": [
                    "#audio",
                    "#multimodal",
                    "#benchmark",
                    "#video",
                    "#training",
                    "#robotics",
                    "#dataset"
                ],
                "emoji": "ğŸ‘ï¸â€ğŸ—¨ï¸",
                "ru": {
                    "title": "Ğ“Ğ°Ñ€Ğ¼Ğ¾Ğ½Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑĞ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ·Ğ²ÑƒĞºĞ° Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ½Ğ¸Ñ Ğ² ÑĞ³Ğ¾Ñ†ĞµĞ½Ñ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑÑ†ĞµĞ½Ğ°Ñ…",
                    "desc": "Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ² ÑĞ³Ğ¾Ñ†ĞµĞ½Ñ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ EgoAVU â€” Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ, Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ĞºÑ€Ğ¾ÑÑ-Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¸. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ¸Ğ· 3 Ğ¼Ğ»Ğ½ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° ÑÑ‚Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ ÑƒÑÑ‚Ñ€Ğ°Ğ½ÑĞµÑ‚ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ğ² ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñƒ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¾ 113%."
                },
                "en": {
                    "title": "Enhancing Multi-Modal Understanding in Egocentric Videos",
                    "desc": "This paper addresses the challenges faced by multi-modal large language models (MLLMs) in understanding both audio and visual signals in egocentric videos. The authors introduce EgoAVU, a scalable data engine that generates rich audio-visual narrations and questions, enhancing the training data for MLLMs. By fine-tuning these models on the newly created EgoAVU-Instruct dataset, significant performance improvements are achieved, particularly in tasks that require joint modality understanding. The study highlights the limitations of existing MLLMs and demonstrates how targeted training can enhance their ability to process and integrate audio and visual information effectively."
                },
                "zh": {
                    "title": "æå‡å¤šæ¨¡æ€ç†è§£ï¼Œçªç ´è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘çš„ç“¶é¢ˆ",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ä¸­çš„éŸ³é¢‘å’Œè§†è§‰ä¿¡å·æ–¹é¢çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†EgoAVUï¼Œä¸€ä¸ªå¯æ‰©å±•çš„æ•°æ®å¼•æ“ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆè‡ªæˆ‘ä¸­å¿ƒçš„éŸ³é¢‘-è§†è§‰å™è¿°ã€é—®é¢˜å’Œç­”æ¡ˆã€‚é€šè¿‡äº¤å‰æ¨¡æ€å…³è”å»ºæ¨¡ï¼ŒEgoAVUä¸°å¯Œäº†äººç±»å™è¿°çš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ï¼Œå¹¶ç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚å¯¹å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé’ˆå¯¹æ€§çš„å¾®è°ƒï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å…¶åœ¨è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ç†è§£ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.05711",
            "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale",
            "url": "https://huggingface.co/papers/2602.05711",
            "abstract": "OmniMoE presents a system-algorithm co-designed framework that achieves fine-grained expert specialization in Mixture-of-Experts architectures through vector-level atomic experts and optimized routing and scheduling mechanisms.  \t\t\t\t\tAI-generated summary \t\t\t\t Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.",
            "score": 1,
            "issue_id": 962,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "688adfd08d5f60d2",
            "authors": [
                "Jingze Shi",
                "Zhangyang Peng",
                "Yizhang Zhu",
                "Yifan Wu",
                "Guang Liu",
                "Yuyu Luo"
            ],
            "affiliations": [
                "Beijing Academy of Artificial Intelligence",
                "The Hong Kong University of Science and Technology (Guangzhou)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.05711.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#architecture"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "ĞÑ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ñ‹: Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸",
                    "desc": "OmniMoE Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ² Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Mixture-of-Experts Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ². Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ»Ğ¸ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹: Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´ĞµĞºĞ°Ñ€Ñ‚Ğ¾Ğ²Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ O(N) Ğ´Ğ¾ O(âˆšN), Ğ° Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ½Ğ° ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ², Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ Ñ€Ğ°ÑÑĞµÑĞ½Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ. ĞĞ° ÑĞµĞ¼Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… OmniMoE Ñ 1,7B Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ 50,9% Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² zero-shot Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ ĞºĞ°Ğº Ñ ĞºÑ€ÑƒĞ¿Ğ½Ğ¾Ğ¹, Ñ‚Ğ°Ğº Ğ¸ Ñ Ğ¼ĞµĞ»ĞºĞ¾Ğ¹ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ 10,9-ĞºÑ€Ğ°Ñ‚Ğ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° (Ñ 73ms Ğ´Ğ¾ 6,7ms) Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ PEER, Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ğ°Ñ fine-grained MoE Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹."
                },
                "en": {
                    "title": "Unlocking Speed and Precision in Mixture-of-Experts with OmniMoE",
                    "desc": "OmniMoE is a new framework designed to enhance Mixture-of-Experts (MoE) architectures by achieving fine-grained expert specialization. It introduces vector-level Atomic Experts, which allow for more efficient routing and execution within a single MoE layer while maintaining a shared dense MLP for general tasks. The framework addresses challenges in routing complexity and memory access through innovative techniques like the Cartesian Product Router and Expert-Centric Scheduling. As a result, OmniMoE significantly improves accuracy and reduces inference latency, demonstrating that fine-grained MoE can be both fast and effective."
                },
                "zh": {
                    "title": "OmniMoEï¼šç»†ç²’åº¦ä¸“å®¶çš„é«˜æ•ˆå®ç°",
                    "desc": "OmniMoEæ˜¯ä¸€ç§ç³»ç»Ÿä¸ç®—æ³•å…±åŒè®¾è®¡çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å‘é‡çº§åŸå­ä¸“å®¶å®ç°æ··åˆä¸“å®¶æ¶æ„ä¸­çš„ç»†ç²’åº¦ä¸“å®¶ä¸“ä¸šåŒ–ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¼˜åŒ–è·¯ç”±å’Œè°ƒåº¦æœºåˆ¶ï¼Œå…‹æœäº†ä¸“å®¶ä¸“ä¸šåŒ–ç²’åº¦ä¸ç¡¬ä»¶æ‰§è¡Œæ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚OmniMoEå¼•å…¥äº†åŸå­ä¸“å®¶ï¼Œä½¿å¾—åœ¨å•ä¸ªMoEå±‚å†…å®ç°å¯æ‰©å±•çš„è·¯ç”±å’Œæ‰§è¡Œï¼ŒåŒæ—¶ä¿ç•™äº†ç”¨äºé€šç”¨å¤„ç†çš„å…±äº«å¯†é›†MLPåˆ†æ”¯ã€‚ç»è¿‡ä¸ƒä¸ªåŸºå‡†æµ‹è¯•éªŒè¯ï¼ŒOmniMoEåœ¨æ¨ç†å»¶è¿Ÿå’Œå‡†ç¡®æ€§ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾ç¤ºå‡ºå¤§è§„æ¨¡ç»†ç²’åº¦MoEçš„å¿«é€Ÿä¸å‡†ç¡®æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2601.23039",
            "title": "Avoiding Premature Collapse: Adaptive Annealing for Entropy-Regularized Structural Inference",
            "url": "https://huggingface.co/papers/2601.23039",
            "abstract": "Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training.  \t\t\t\t\tAI-generated summary \t\t\t\t Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT), serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via annealing Îµto 0 is notoriously unstable. In this work, we identify a fundamental mechanism for this failure: Premature Mode Collapse. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map, we reveal a theoretical thermodynamic speed limit: standard exponential cooling outpaces the contraction rate of the inference operator, which degrades as O(1/Îµ). To address this, we propose Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC), an adaptive scheduling algorithm that monitors the stability of the inference process. We demonstrate that EPH-ASC is essential for stabilizing Manifold-Constrained Hyper-Connections (mHC) during large-scale training on the FineWeb-Edu dataset, effectively preventing late-stage gradient explosions by enforcing a linear stability law.",
            "score": 1,
            "issue_id": 963,
            "pub_date": "2026-01-30",
            "pub_date_card": {
                "ru": "30 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 30",
                "zh": "1æœˆ30æ—¥"
            },
            "hash": "0710cf59390fcf1d",
            "authors": [
                "Yizhi Liu"
            ],
            "affiliations": [
                "Department of Computer Science, Stony Brook University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2601.23039.jpg",
            "data": {
                "categories": [
                    "#optimization"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ² Ğ² Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğµ Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ¿Ñ€ĞµĞ¶Ğ´ĞµĞ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ»Ğ»Ğ°Ğ¿ÑĞ° Ğ¼Ğ¾Ğ´ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğµ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ»Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° Ğ¡Ğ¸Ğ½Ñ…Ğ¾Ñ€Ğ½Ğ° Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ: ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ñ…Ğ»Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ, Ñ‡ĞµĞ¼ ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°. Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ EPH-ASC, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ²Ğ·Ñ€Ñ‹Ğ²Ñ‹. ĞœĞµÑ‚Ğ¾Ğ´ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ… Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ° FineWeb-Edu, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Stabilizing Structural Prediction with Adaptive Control",
                    "desc": "This paper tackles the issue of premature mode collapse in optimal transport-based structural prediction models, which can lead to instability during training. The authors introduce an adaptive stability control algorithm called Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC) to prevent gradient explosions. By analyzing the dynamics of the Sinkhorn fixed-point map, they uncover a speed limit that contributes to the instability. The proposed method is shown to effectively stabilize the training process, particularly in large-scale applications like the FineWeb-Edu dataset."
                },
                "zh": {
                    "title": "é˜²æ­¢æ—©æœŸæ¨¡å¼å´©æºƒçš„è‡ªé€‚åº”ç¨³å®šæ€§æ§åˆ¶",
                    "desc": "æœ¬ç ”ç©¶é’ˆå¯¹åŸºäºæœ€ä¼˜ä¼ è¾“çš„ç»“æ„é¢„æµ‹æ¨¡å‹ä¸­çš„æ—©æœŸæ¨¡å¼å´©æºƒé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”ç¨³å®šæ€§æ§åˆ¶ç®—æ³•ã€‚è¯¥ç®—æ³•èƒ½å¤Ÿåœ¨å¤§è§„æ¨¡è®­ç»ƒè¿‡ç¨‹ä¸­é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œç¡®ä¿æ¨¡å‹çš„ç¨³å®šæ€§ã€‚æˆ‘ä»¬åˆ†æäº†Sinkhornå›ºå®šç‚¹æ˜ å°„çš„éæ­£å¸¸åŠ¨æ€ï¼Œæ­ç¤ºäº†ä¸€ä¸ªç†è®ºçƒ­åŠ›å­¦é€Ÿåº¦æé™ï¼ŒæŒ‡å‡ºæ ‡å‡†çš„æŒ‡æ•°å†·å´é€Ÿåº¦è¶…è¿‡äº†æ¨ç†ç®—å­çš„æ”¶ç¼©é€Ÿç‡ã€‚é€šè¿‡å¼•å…¥é«˜æ•ˆåˆ†æ®µæ··åˆè‡ªé€‚åº”ç¨³å®šæ€§æ§åˆ¶ï¼ˆEPH-ASCï¼‰ï¼Œæˆ‘ä»¬æˆåŠŸåœ°åœ¨FineWeb-Eduæ•°æ®é›†ä¸Šç¨³å®šäº†æµå½¢çº¦æŸè¶…è¿æ¥ï¼ˆmHCï¼‰ï¼Œæœ‰æ•ˆé¿å…äº†åæœŸçš„æ¢¯åº¦çˆ†ç‚¸ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06554",
            "title": "SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees",
            "url": "https://huggingface.co/papers/2602.06554",
            "abstract": "SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.   In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.   To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.   Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.",
            "score": 0,
            "issue_id": 963,
            "pub_date": "2026-02-06",
            "pub_date_card": {
                "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 6",
                "zh": "2æœˆ6æ—¥"
            },
            "hash": "b47e2950662223f8",
            "authors": [
                "Tianyi Hu",
                "Qingxu Fu",
                "Yanxi Chen",
                "Zhaoyang Liu",
                "Bolin Ding"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06554.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#training",
                    "#rl",
                    "#alignment",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ±ĞµĞ· ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ Ğ¸Ğ½Ğ´ÑƒĞºÑ†Ğ¸Ñ",
                    "desc": "SeeUPO â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ±ĞµĞ· ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ…Ğ¾Ğ´Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ (PPO, REINFORCE) Ñ‚ĞµÑ€ÑÑÑ‚ Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ğ¸ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ bepaÑ€ametrĞ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ°. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ğ¾Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ ĞºĞ°Ğº Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ±Ğ°Ğ½Ğ´Ğ¸Ñ‚Ğ° Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ Ğ¸Ğ½Ğ´ÑƒĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ² Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ Ñ…Ğ¾Ğ´Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… AppWorld Ğ¸ BFCL v4."
                },
                "en": {
                    "title": "SeeUPO: Ensuring Convergence in Multi-Turn Reinforcement Learning",
                    "desc": "The paper introduces SeeUPO, a novel reinforcement learning method designed for multi-turn interactions among agents. It addresses the lack of convergence guarantees in existing RL algorithms by modeling these interactions as multi-agent bandit problems. SeeUPO employs backward induction for policy updates, ensuring that the learning process leads to optimal solutions while maintaining stability. Experimental results show that SeeUPO significantly outperforms traditional RL methods, achieving higher performance and better training consistency."
                },
                "zh": {
                    "title": "SeeUPOï¼šå¤šè½®äº¤äº’ä¸­çš„æ— è¯„è®ºå¼ºåŒ–å­¦ä¹ æ–°æ–¹æ³•",
                    "desc": "SeeUPOæ˜¯ä¸€ç§æ— è¯„è®ºçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨ç¡®ä¿å¤šè½®ä»£ç†äº¤äº’ä¸­çš„æ”¶æ•›æ€§ã€‚å®ƒå°†é¡ºåºå†³ç­–å»ºæ¨¡ä¸ºå¤šæ™ºèƒ½ä½“èµŒåšé—®é¢˜ï¼Œå¹¶é€šè¿‡åå‘æ¨å¯¼è¿›è¡Œç­–ç•¥æ›´æ–°ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨å¤šè½®åœºæ™¯ä¸­æ— æ³•åŒæ—¶å®ç°æ— è¯„è®ºå’Œæ”¶æ•›ä¿è¯ã€‚SeeUPOé€šè¿‡é€è½®çš„åå‘æ‰§è¡Œé¡ºåºç­–ç•¥æ›´æ–°ï¼Œç¡®ä¿äº†å•è°ƒæ”¹è¿›å’Œå…¨å±€æœ€ä¼˜è§£çš„æ”¶æ•›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.01064",
            "title": "Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs",
            "url": "https://huggingface.co/papers/2602.01064",
            "abstract": "Knowledge purification techniques consolidate rationales from multiple teacher LLMs to reduce conflicts and improve efficiency in distillation processes.  \t\t\t\t\tAI-generated summary \t\t\t\t Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models. In this paper, we introduce the concept of Knowledge Purification, which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification, we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts. Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.",
            "score": 0,
            "issue_id": 962,
            "pub_date": "2026-02-01",
            "pub_date_card": {
                "ru": "1 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 1",
                "zh": "2æœˆ1æ—¥"
            },
            "hash": "cb1b1f412f81bede",
            "authors": [
                "Ruihan Jin",
                "Pengpeng Shao",
                "Zhengqi Wen",
                "Jinyang Wu",
                "Mingkuan Feng",
                "Shuo Yang",
                "Chu Yuan Zhang",
                "Jianhua Tao"
            ],
            "affiliations": [
                "Beijing National Research Center for Information Science and Technology",
                "Department of Automation, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.01064.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#small_models",
                    "#training"
                ],
                "emoji": "ğŸ§¹",
                "ru": {
                    "title": "ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¸Ğ· Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ñ… ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ğ¾Ñ‚ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… LLM Ğ² ĞµĞ´Ğ¸Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ñ‹ Ğ¿ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°Ñ… Ğº Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñƒ Ñ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²."
                },
                "en": {
                    "title": "Streamlining Knowledge Transfer with Purification Techniques",
                    "desc": "This paper presents Knowledge Purification, a novel approach to enhance knowledge distillation from multiple teacher large language models (LLMs). By consolidating rationales from these teachers, the method reduces conflicts that typically arise during the distillation process. The authors propose five distinct purification methods to evaluate their effectiveness in improving the performance of smaller models. Results show that these techniques not only boost model efficiency but also enhance generalization, making them valuable for deploying lightweight models in practical applications."
                },
                "zh": {
                    "title": "çŸ¥è¯†å‡€åŒ–ï¼šæå‡è’¸é¦æ•ˆç‡çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "çŸ¥è¯†å‡€åŒ–æŠ€æœ¯é€šè¿‡æ•´åˆå¤šä¸ªæ•™å¸ˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†ï¼Œå‡å°‘äº†çŸ¥è¯†å†²çªå¹¶æé«˜äº†è’¸é¦è¿‡ç¨‹çš„æ•ˆç‡ã€‚ä¼ ç»Ÿçš„çŸ¥è¯†è’¸é¦æ–¹æ³•åœ¨ä½¿ç”¨å¤šä¸ªæ•™å¸ˆæ¨¡å‹æ—¶é¢ä¸´çŸ¥è¯†å†²çªå’Œèµ„æºéœ€æ±‚é«˜çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†çŸ¥è¯†å‡€åŒ–çš„æ¦‚å¿µï¼Œå°†å¤šä¸ªæ•™å¸ˆLLMsçš„æ¨ç†æ•´åˆä¸ºå•ä¸€æ¨ç†ï¼Œä»è€Œç¼“è§£å†²çªå¹¶æå‡æ•ˆç‡ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›å‡€åŒ–æ–¹æ³•ä¸ä»…æé«˜äº†è’¸é¦æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜æœ‰æ•ˆå‡è½»äº†çŸ¥è¯†å†²çªã€‚"
                }
            }
        }
    ],
    "link_prev": "2026-02-06.html",
    "link_next": "2026-02-10.html",
    "link_month": "2026-02.html",
    "short_date_prev": {
        "ru": "06.02",
        "en": "02/06",
        "zh": "2æœˆ6æ—¥"
    },
    "short_date_next": {
        "ru": "10.02",
        "en": "02/10",
        "zh": "2æœˆ10æ—¥"
    },
    "categories": {
        "#dataset": 5,
        "#data": 1,
        "#benchmark": 5,
        "#agents": 3,
        "#cv": 2,
        "#rl": 6,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 3,
        "#3d": 0,
        "#audio": 1,
        "#video": 2,
        "#multimodal": 3,
        "#math": 2,
        "#multilingual": 1,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 13,
        "#robotics": 2,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 7,
        "#transfer_learning": 3,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 7,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 2,
        "#synthetic": 1,
        "#machine_translation": 1,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 2,
        "#science": 2,
        "#low_resource": 0
    }
}