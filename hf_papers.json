{
    "date": {
        "ru": "17 января",
        "en": "January 17",
        "zh": "1月17日"
    },
    "time_utc": "2025-01-17 05:09",
    "weekday": 4,
    "issue_id": 1720,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.08617",
            "title": "RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation",
            "url": "https://huggingface.co/papers/2501.08617",
            "abstract": "Generative AI systems like foundation models (FMs) must align well with human values to ensure their behavior is helpful and trustworthy. While Reinforcement Learning from Human Feedback (RLHF) has shown promise for optimizing model performance using human judgments, existing RLHF pipelines predominantly rely on immediate feedback, which can fail to accurately reflect the downstream impact of an interaction on users' utility. We demonstrate that feedback based on evaluators' foresight estimates of downstream consequences systematically induces Goodhart's Law dynamics, incentivizing misaligned behaviors like sycophancy and deception and ultimately degrading user outcomes. To alleviate this, we propose decoupling evaluation from prediction by refocusing RLHF on hindsight feedback. Our theoretical analysis reveals that conditioning evaluator feedback on downstream observations mitigates misalignment and improves expected human utility, even when these observations are simulated by the AI system itself. To leverage this insight in a practical alignment algorithm, we introduce Reinforcement Learning from Hindsight Simulation (RLHS), which first simulates plausible consequences and then elicits feedback to assess what behaviors were genuinely beneficial in hindsight. We apply RLHS to two widely-employed online and offline preference optimization methods -- Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) -- and show empirically that misalignment is significantly reduced with both methods. Through an online human user study, we show that RLHS consistently outperforms RLHF in helping users achieve their goals and earns higher satisfaction ratings, despite being trained solely with simulated hindsight feedback. These results underscore the importance of focusing on long-term consequences, even simulated ones, to mitigate misalignment in RLHF.",
            "score": 3,
            "issue_id": 1720,
            "pub_date": "2025-01-15",
            "pub_date_card": {
                "ru": "15 января",
                "en": "January 15",
                "zh": "1月15日"
            },
            "hash": "f758bc630d8dd443",
            "authors": [
                "Kaiqu Liang",
                "Haimin Hu",
                "Ryan Liu",
                "Thomas L. Griffiths",
                "Jaime Fernández Fisac"
            ],
            "affiliations": [
                "Department of Computer Science, Princeton University",
                "Department of Electrical and Computer Engineering, Princeton University",
                "Department of Psychology, Princeton University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.08617.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#alignment",
                    "#training",
                    "#rl"
                ],
                "emoji": "🔮",
                "ru": {
                    "title": "Взгляд в будущее для лучшей настройки ИИ",
                    "desc": "Статья представляет новый метод обучения с подкреплением - Reinforcement Learning from Hindsight Simulation (RLHS). В отличие от стандартного RLHF, RLHS использует симуляцию долгосрочных последствий действий модели и оценку их полезности постфактум. Авторы показывают, что RLHS позволяет уменьшить проблему неправильной мотивации модели и улучшить соответствие человеческим ценностям. Эмпирические эксперименты демонстрируют превосходство RLHS над RLHF в достижении целей пользователей."
                },
                "en": {
                    "title": "Aligning AI with Human Values through Hindsight Feedback",
                    "desc": "This paper addresses the challenge of aligning generative AI systems with human values using Reinforcement Learning from Human Feedback (RLHF). It identifies that relying on immediate feedback can lead to misaligned behaviors, such as sycophancy and deception, due to Goodhart's Law dynamics. The authors propose a new approach called Reinforcement Learning from Hindsight Simulation (RLHS), which uses simulated consequences to gather feedback on beneficial behaviors. Their experiments show that RLHS improves user satisfaction and goal achievement compared to traditional RLHF methods, highlighting the importance of considering long-term outcomes in AI alignment."
                },
                "zh": {
                    "title": "关注长期后果，提升AI对齐性",
                    "desc": "这篇论文探讨了生成性人工智能系统如何更好地与人类价值观对齐，以确保其行为有益且可信。现有的基于人类反馈的强化学习（RLHF）方法主要依赖即时反馈，但这种反馈可能无法准确反映与用户效用相关的长期影响。作者提出了一种新的方法，称为基于事后模拟的强化学习（RLHS），通过模拟可能的后果来获取反馈，从而改善模型的对齐性。研究表明，RLHS在帮助用户实现目标和提高满意度方面，优于传统的RLHF方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.09755",
            "title": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation",
            "url": "https://huggingface.co/papers/2501.09755",
            "abstract": "Visual tokenization via auto-encoding empowers state-of-the-art image and video generative models by compressing pixels into a latent space. Although scaling Transformer-based generators has been central to recent advances, the tokenizer component itself is rarely scaled, leaving open questions about how auto-encoder design choices influence both its objective of reconstruction and downstream generative performance. Our work aims to conduct an exploration of scaling in auto-encoders to fill in this blank. To facilitate this exploration, we replace the typical convolutional backbone with an enhanced Vision Transformer architecture for Tokenization (ViTok). We train ViTok on large-scale image and video datasets far exceeding ImageNet-1K, removing data constraints on tokenizer scaling. We first study how scaling the auto-encoder bottleneck affects both reconstruction and generation -- and find that while it is highly correlated with reconstruction, its relationship with generation is more complex. We next explored the effect of separately scaling the auto-encoders' encoder and decoder on reconstruction and generation performance. Crucially, we find that scaling the encoder yields minimal gains for either reconstruction or generation, while scaling the decoder boosts reconstruction but the benefits for generation are mixed. Building on our exploration, we design ViTok as a lightweight auto-encoder that achieves competitive performance with state-of-the-art auto-encoders on ImageNet-1K and COCO reconstruction tasks (256p and 512p) while outperforming existing auto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x fewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates competitive performance on image generation for ImageNet-1K and sets new state-of-the-art benchmarks for class-conditional video generation on UCF-101.",
            "score": 0,
            "issue_id": 1720,
            "pub_date": "2025-01-16",
            "pub_date_card": {
                "ru": "16 января",
                "en": "January 16",
                "zh": "1月16日"
            },
            "hash": "426aa3415c3c0ef4",
            "authors": [
                "Philippe Hansen-Estruch",
                "David Yan",
                "Ching-Yao Chung",
                "Orr Zohar",
                "Jialiang Wang",
                "Tingbo Hou",
                "Tao Xu",
                "Sriram Vishwanath",
                "Peter Vajda",
                "Xinlei Chen"
            ],
            "affiliations": [
                "FAIR, Meta",
                "GenAI, Meta",
                "Stanford University",
                "UT Austin"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.09755.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#benchmark",
                    "#video",
                    "#optimization",
                    "#architecture",
                    "#diffusion"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "ViTok: Оптимизация визуальной токенизации для генеративных моделей",
                    "desc": "Статья исследует масштабирование автоэнкодеров для визуальной токенизации в генеративных моделях изображений и видео. Авторы представляют ViTok - легковесный автоэнкодер на основе Vision Transformer, обученный на масштабных датасетах. Исследование показывает, что масштабирование декодера улучшает реконструкцию, но неоднозначно влияет на генерацию. ViTok демонстрирует конкурентоспособную производительность при меньшем количестве FLOP и устанавливает новые рекорды в условной генерации видео."
                },
                "en": {
                    "title": "Scaling Auto-Encoders for Enhanced Image and Video Generation",
                    "desc": "This paper explores the scaling of auto-encoders, particularly focusing on the tokenizer component, which is crucial for image and video generation. The authors introduce ViTok, a Vision Transformer-based architecture that replaces traditional convolutional backbones, allowing for better scaling on large datasets. They investigate how different scaling strategies for the encoder and decoder affect both reconstruction and generative performance, finding that scaling the decoder is more beneficial for reconstruction. Ultimately, ViTok achieves competitive results with fewer computational resources and sets new benchmarks in image and video generation tasks."
                },
                "zh": {
                    "title": "自编码器的视觉标记化：提升生成模型的关键",
                    "desc": "本论文探讨了通过自编码器进行视觉标记化对图像和视频生成模型的影响。我们提出了一种增强的视觉变换器架构（ViTok），用于替代传统的卷积骨干网络，以提高标记化的效果。研究发现，自编码器的瓶颈规模与重建性能高度相关，但与生成性能的关系更为复杂。最终，ViTok在多个任务中表现出色，尤其是在视频重建和图像生成方面，展示了其在计算效率上的优势。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.09732",
            "title": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps",
            "url": "https://huggingface.co/papers/2501.09732",
            "abstract": "Generative models have made significant impacts across various domains, largely due to their ability to scale during training by increasing data, computational resources, and model size, a phenomenon characterized by the scaling laws. Recent research has begun to explore inference-time scaling behavior in Large Language Models (LLMs), revealing how performance can further improve with additional computation during inference. Unlike LLMs, diffusion models inherently possess the flexibility to adjust inference-time computation via the number of denoising steps, although the performance gains typically flatten after a few dozen. In this work, we explore the inference-time scaling behavior of diffusion models beyond increasing denoising steps and investigate how the generation performance can further improve with increased computation. Specifically, we consider a search problem aimed at identifying better noises for the diffusion sampling process. We structure the design space along two axes: the verifiers used to provide feedback, and the algorithms used to find better noise candidates. Through extensive experiments on class-conditioned and text-conditioned image generation benchmarks, our findings reveal that increasing inference-time compute leads to substantial improvements in the quality of samples generated by diffusion models, and with the complicated nature of images, combinations of the components in the framework can be specifically chosen to conform with different application scenario.",
            "score": 0,
            "issue_id": 1720,
            "pub_date": "2025-01-16",
            "pub_date_card": {
                "ru": "16 января",
                "en": "January 16",
                "zh": "1月16日"
            },
            "hash": "2ad32c666f91ba05",
            "authors": [
                "Nanye Ma",
                "Shangyuan Tong",
                "Haolin Jia",
                "Hexiang Hu",
                "Yu-Chuan Su",
                "Mingda Zhang",
                "Xuan Yang",
                "Yandong Li",
                "Tommi Jaakkola",
                "Xuhui Jia",
                "Saining Xie"
            ],
            "affiliations": [
                "Google",
                "MIT",
                "NYU"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.09732.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#inference",
                    "#benchmark",
                    "#optimization"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Повышение качества генерации изображений за счет масштабирования вычислений при выводе",
                    "desc": "Это исследование посвящено изучению поведения диффузионных моделей при масштабировании вычислений во время вывода. Авторы рассматривают задачу поиска лучших шумов для процесса сэмплирования диффузионной модели. Они структурируют пространство решений по двум осям: верификаторы для обратной связи и алгоритмы поиска лучших кандидатов шума. Эксперименты показывают, что увеличение вычислений при выводе приводит к значительному улучшению качества сгенерированных изображений."
                },
                "en": {
                    "title": "Enhancing Diffusion Models: Scaling Inference for Better Image Generation",
                    "desc": "This paper investigates how to enhance the performance of diffusion models during the inference phase by increasing computational resources. It highlights that, unlike Large Language Models (LLMs), diffusion models can adjust their inference process through the number of denoising steps, but improvements tend to plateau after a certain point. The authors propose a method to optimize the noise used in the diffusion sampling process by exploring different feedback verifiers and algorithms. Their experiments demonstrate that by strategically increasing computation during inference, the quality of generated images can be significantly improved, tailored to various application needs."
                },
                "zh": {
                    "title": "扩散模型推理时的计算扩展与性能提升",
                    "desc": "生成模型在多个领域产生了重要影响，主要得益于其在训练过程中通过增加数据、计算资源和模型规模来扩展的能力。最近的研究开始探讨大型语言模型（LLMs）在推理时的扩展行为，发现额外的计算可以进一步提高性能。与LLMs不同，扩散模型通过去噪步骤的数量灵活调整推理时的计算，尽管性能提升通常在几十步后趋于平稳。本文探讨了扩散模型在推理时的扩展行为，研究如何通过增加计算来进一步提高生成性能，特别是通过寻找更好的噪声来优化扩散采样过程。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.09686",
            "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models",
            "url": "https://huggingface.co/papers/2501.09686",
            "abstract": "Language has long been conceived as an essential tool for human reasoning. The breakthrough of Large Language Models (LLMs) has sparked significant research interest in leveraging these models to tackle complex reasoning tasks. Researchers have moved beyond simple autoregressive token generation by introducing the concept of \"thought\" -- a sequence of tokens representing intermediate steps in the reasoning process. This innovative paradigm enables LLMs' to mimic complex human reasoning processes, such as tree search and reflective thinking. Recently, an emerging trend of learning to reason has applied reinforcement learning (RL) to train LLMs to master reasoning processes. This approach enables the automatic generation of high-quality reasoning trajectories through trial-and-error search algorithms, significantly expanding LLMs' reasoning capacity by providing substantially more training data. Furthermore, recent studies demonstrate that encouraging LLMs to \"think\" with more tokens during test-time inference can further significantly boost reasoning accuracy. Therefore, the train-time and test-time scaling combined to show a new research frontier -- a path toward Large Reasoning Model. The introduction of OpenAI's o1 series marks a significant milestone in this research direction. In this survey, we present a comprehensive review of recent progress in LLM reasoning. We begin by introducing the foundational background of LLMs and then explore the key technical components driving the development of large reasoning models, with a focus on automated data construction, learning-to-reason techniques, and test-time scaling. We also analyze popular open-source projects at building large reasoning models, and conclude with open challenges and future research directions.",
            "score": 0,
            "issue_id": 1720,
            "pub_date": "2025-01-16",
            "pub_date_card": {
                "ru": "16 января",
                "en": "January 16",
                "zh": "1月16日"
            },
            "hash": "1c6b1b1f0235304c",
            "authors": [
                "Fengli Xu",
                "Qianyue Hao",
                "Zefang Zong",
                "Jingwei Wang",
                "Yunke Zhang",
                "Jingyi Wang",
                "Xiaochong Lan",
                "Jiahui Gong",
                "Tianjian Ouyang",
                "Fanjin Meng",
                "Chenyang Shao",
                "Yuwei Yan",
                "Qinglong Yang",
                "Yiwen Song",
                "Sijian Ren",
                "Xinyuan Hu",
                "Yu Li",
                "Jie Feng",
                "Chen Gao",
                "Yong Li"
            ],
            "affiliations": [
                "Emory University, Atlanta GA, USA",
                "HKUST (GZ), Guangzhou, China",
                "Tsinghua University, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.09686.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#training",
                    "#rl",
                    "#survey",
                    "#reasoning",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Путь к большим моделям рассуждений: новый рубеж в ИИ",
                    "desc": "Этот обзор посвящен прогрессу в области рассуждений с использованием больших языковых моделей (LLM). Рассматриваются ключевые технические компоненты, способствующие развитию крупных моделей рассуждений, включая автоматизированное построение данных, методы обучения рассуждениям и масштабирование во время тестирования. Анализируются популярные проекты с открытым исходным кодом по созданию крупных моделей рассуждений. Обсуждаются открытые проблемы и направления будущих исследований в этой области."
                },
                "en": {
                    "title": "Unlocking Human-Like Reasoning in Large Language Models",
                    "desc": "This paper discusses the advancements in Large Language Models (LLMs) and their application to complex reasoning tasks. It introduces the concept of 'thought', which represents intermediate reasoning steps, allowing LLMs to simulate human-like reasoning processes. The paper highlights the use of reinforcement learning to enhance LLMs' reasoning capabilities by generating high-quality reasoning trajectories through trial-and-error methods. Additionally, it emphasizes the importance of scaling both training and testing phases to improve reasoning accuracy, paving the way for the development of Large Reasoning Models."
                },
                "zh": {
                    "title": "推动大型推理模型的研究新前沿",
                    "desc": "这篇论文探讨了大型语言模型（LLMs）在复杂推理任务中的应用。研究者们引入了“思考”的概念，通过中间步骤的令牌序列来模拟人类的推理过程。最近，强化学习（RL）被应用于训练LLMs，以自动生成高质量的推理轨迹，从而显著提高推理能力。论文还讨论了在测试时增加令牌数量以提高推理准确性的效果，并展望了大型推理模型的未来研究方向。"
                }
            }
        }
    ],
    "link_prev": "2025-01-16.html",
    "link_next": "2025-01-20.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "16.01",
        "en": "01/16",
        "zh": "1月16日"
    },
    "short_date_next": {
        "ru": "20.01",
        "en": "01/20",
        "zh": "1月20日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 1,
        "#rl": 2,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 1,
        "#diffusion": 2,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了多模态文档检索，旨在从大量文档中识别和检索图表、表格、图形和布局信息。尽管其重要性，缺乏有效的基准测试来评估系统性能。为此，文章提出了一个新的基准测试MMDocIR，包括页面级和布局级检索任务。MMDocIR包含1,685个专家标注和173,843个自动标注的问题，是一个重要的资源。实验显示，视觉检索器比文本检索器表现更好，并且使用VLM-text的文本检索器优于使用OCR-text的检索器。",
        "title": "MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents",
        "pinyin": "这篇文章介绍了多模态文档检索，旨在从大量文档中识别和检索图表、表格、图形和布局信息。尽管其重要性，缺乏有效的基准测试来评估系统性能。为此，文章提出了一个新的基准测试MMDocIR，包括页面级和布局级检索任务。MMDocIR包含1,685个专家标注和173,843个自动标注的问题，是一个重要的资源。实验显示，视觉检索器比文本检索器表现更好，并且使用VLM-text的文本检索器优于使用OCR-text的检索器。\n\nzhè piān wén zhāng jiè shào le duō mó tài wén dàng jiàn suǒ, zhǐ zài cóng dà liàng wén dàng zhōng shí bié hé jiàn suǒ tú biǎo, biǎo gé, tú xíng hé bù jú xìn xī. Jǐn guǎn qí zhòng yào xìng, quē fá yǒu xiào de jī zhǔn cè shì lái píng gū xì tǒng xìng néng. Wèi cǐ, wén zhāng tí chū le yī gè xīn de jī zhǔn cè shì MMDocIR, bāo kuò yè miàn jí hé bù jú jí jiàn suǒ rèn wù. MMDocIR bāo hán 1,685 gè zhuān jiā biāo zhù hé 173,843 gè zì dòng biāo zhù de wèn tí, shì yī gè zhòng yào de zī yuán. Shí yàn xiǎn shì, shì jué jiàn suǒ qì bǐ wén běn jiàn suǒ qì biǎo xiàn gèng hǎo, bìng qiě shǐ yòng VLM-text de wén běn jiàn suǒ qì yōu yú shǐ yòng OCR-text de jiàn suǒ qì.",
        "vocab": "[{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'},\n{'word': '检索', 'pinyin': 'jiǎn suǒ', 'trans': 'retrieval'},\n{'word': '旨在', 'pinyin': 'zhǐ zài', 'trans': 'aim to'},\n{'word': '识别', 'pinyin': 'shí bié', 'trans': 'recognize'},\n{'word': '布局', 'pinyin': 'bù jiú', 'trans': 'layout'},\n{'word': '尽管', 'pinyin': 'jìn guǎn', 'trans': 'although'},\n{'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'},\n{'word': '评估', 'pinyin': 'píng gū', 'trans': 'evaluate'},\n{'word': '系统', 'pinyin': 'xì tǒng', 'trans': 'system'},\n{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},\n{'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'},\n{'word': '页面级', 'pinyin': 'yè miàn jí', 'trans': 'page-level'},\n{'word': '标注', 'pinyin': 'biāo zhù', 'trans': 'annotation'},\n{'word': '资源', 'pinyin': 'zī yuán', 'trans': 'resource'},\n{'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'},\n{'word': '文本', 'pinyin': 'wén běn', 'trans': 'text'},\n{'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'perform'},\n{'word': '优于', 'pinyin': 'yōu yú', 'trans': 'superior to'},\n{'word': '使用', 'pinyin': 'shǐ yòng', 'trans': 'use'},\n{'word': 'OCR', 'pinyin': '', 'trans': 'Optical Character Recognition'}]",
        "trans": "This article introduces multimodal document retrieval, which aims to identify and retrieve charts, tables, graphics, and layout information from a large number of documents. Despite its importance, there is a lack of effective benchmark tests to evaluate system performance. To address this, the article proposes a new benchmark test called MMDocIR, which includes page-level and layout-level retrieval tasks. MMDocIR contains 1,685 expert-annotated and 173,843 automatically annotated questions, making it a valuable resource. Experiments show that visual retrievers perform better than text retrievers, and text retrievers using VLM-text outperform those using OCR-text.",
        "update_ts": "2025-01-16 09:10"
    }
}