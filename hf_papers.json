{
    "date": {
        "ru": "23 мая",
        "en": "May 23",
        "zh": "5月23日"
    },
    "time_utc": "2025-05-23 02:30",
    "weekday": 4,
    "issue_id": 3914,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.16410",
            "title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement\n  Learning",
            "url": "https://huggingface.co/papers/2505.16410",
            "abstract": "Tool-Star, an RL-based framework, enables LLMs to autonomously use multiple tools for stepwise reasoning, leveraging data synthesis and hierarchical reward design.  \t\t\t\t\tAI-generated summary \t\t\t\t Recently, large language models (LLMs) have shown remarkable reasoning capabilities via large-scale reinforcement learning (RL). However, leveraging the RL algorithm to empower effective multi-tool collaborative reasoning in LLMs remains an open challenge. In this paper, we introduce Tool-Star, an RL-based framework designed to empower LLMs to autonomously invoke multiple external tools during stepwise reasoning. Tool-Star integrates six types of tools and incorporates systematic designs in both data synthesis and training. To address the scarcity of tool-use data, we propose a general tool-integrated reasoning data synthesis pipeline, which combines tool-integrated prompting with hint-based sampling to automatically and scalably generate tool-use trajectories. A subsequent quality normalization and difficulty-aware classification process filters out low-quality samples and organizes the dataset from easy to hard. Furthermore, we propose a two-stage training framework to enhance multi-tool collaborative reasoning by: (1) cold-start fine-tuning, which guides LLMs to explore reasoning patterns via tool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with hierarchical reward design, which reinforces reward understanding and promotes effective tool collaboration. Experimental analyses on over 10 challenging reasoning benchmarks highlight the effectiveness and efficiency of Tool-Star. The code is available at https://github.com/dongguanting/Tool-Star.",
            "score": 6,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 мая",
                "en": "May 22",
                "zh": "5月22日"
            },
            "hash": "acbe5c0b965cb7af",
            "authors": [
                "Guanting Dong",
                "Yifei Chen",
                "Xiaoxi Li",
                "Jiajie Jin",
                "Hongjin Qian",
                "Yutao Zhu",
                "Hangyu Mao",
                "Guorui Zhou",
                "Zhicheng Dou",
                "Ji-Rong Wen"
            ],
            "affiliations": [
                "BAAI",
                "Kuaishou Technology",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16410.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "🛠️",
                "ru": {
                    "title": "Tool-Star: Автономное мультиинструментальное рассуждение для больших языковых моделей",
                    "desc": "Tool-Star - это фреймворк на основе обучения с подкреплением, который позволяет большим языковым моделям автономно использовать несколько инструментов для пошагового рассуждения. Он включает в себя шесть типов инструментов и систематические подходы к синтезу данных и обучению. Фреймворк использует конвейер синтеза данных для автоматической генерации траекторий использования инструментов, а также двухэтапный процесс обучения для улучшения совместного рассуждения с помощью нескольких инструментов. Экспериментальные анализы на более чем 10 сложных тестах показывают эффективность Tool-Star."
                },
                "en": {
                    "title": "Empowering LLMs with Multi-Tool Collaborative Reasoning",
                    "desc": "Tool-Star is a reinforcement learning (RL) framework that enhances large language models (LLMs) by enabling them to autonomously utilize multiple external tools for stepwise reasoning. It addresses the challenge of effective multi-tool collaboration by integrating a systematic approach to data synthesis and hierarchical reward design. The framework includes a novel data synthesis pipeline that generates tool-use trajectories and organizes them by difficulty, ensuring high-quality training data. Tool-Star's two-stage training process improves LLMs' reasoning capabilities through fine-tuning and a self-critic RL algorithm, leading to significant performance gains on various reasoning tasks."
                },
                "zh": {
                    "title": "Tool-Star：赋能LLM的多工具协作推理",
                    "desc": "Tool-Star是一个基于强化学习的框架，旨在使大型语言模型（LLMs）能够自主使用多个工具进行逐步推理。该框架整合了六种工具，并在数据合成和训练方面进行了系统设计，以解决工具使用数据稀缺的问题。通过结合工具集成提示和基于提示的采样，Tool-Star能够自动生成工具使用轨迹，并通过质量标准化和难度感知分类来过滤低质量样本。最后，Tool-Star采用两阶段训练框架，增强多工具协作推理能力，提升了模型的推理效果和效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14625",
            "title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM\n  Reasoning",
            "url": "https://huggingface.co/papers/2505.14625",
            "abstract": "Reinforcement Learning (RL) has become a powerful tool for enhancing the reasoning abilities of large language models (LLMs) by optimizing their policies with reward signals. Yet, RL's success relies on the reliability of rewards, which are provided by verifiers. In this paper, we expose and analyze a widespread problem--false negatives--where verifiers wrongly reject correct model outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals that over 38% of model-generated responses suffer from false negatives, where the verifier fails to recognize correct answers. We show, both empirically and theoretically, that these false negatives severely impair RL training by depriving the model of informative gradient signals and slowing convergence. To mitigate this, we propose tinyV, a lightweight LLM-based verifier that augments existing rule-based methods, which dynamically identifies potential false negatives and recovers valid responses to produce more accurate reward estimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts pass rates by up to 10% and accelerates convergence relative to the baseline. Our findings highlight the critical importance of addressing verifier false negatives and offer a practical approach to improve RL-based fine-tuning of LLMs. Our code is available at https://github.com/uw-nsl/TinyV.",
            "score": 4,
            "issue_id": 3914,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "0bcb0b140b7623c3",
            "authors": [
                "Zhangchen Xu",
                "Yuetai Li",
                "Fengqing Jiang",
                "Bhaskar Ramasubramanian",
                "Luyao Niu",
                "Bill Yuchen Lin",
                "Radha Poovendran"
            ],
            "affiliations": [
                "University of Washington",
                "Western Washington University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14625.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#reasoning",
                    "#training",
                    "#dataset",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Борьба с ложноотрицательными результатами для улучшения RL-обучения языковых моделей",
                    "desc": "В этой статье исследуется проблема ложноотрицательных результатов в верификаторах, используемых для обучения с подкреплением (RL) больших языковых моделей (LLM). Авторы обнаружили, что более 38% правильных ответов моделей неверно отклоняются верификаторами, что значительно ухудшает процесс обучения. Для решения этой проблемы предложен легковесный верификатор tinyV на основе LLM, который дополняет существующие методы и выявляет потенциальные ложноотрицательные результаты. Интеграция tinyV повышает точность на 10% и ускоряет сходимость при обучении LLM с помощью RL на нескольких математических тестах."
                },
                "en": {
                    "title": "Enhancing RL Training by Tackling Verifier False Negatives with TinyV",
                    "desc": "This paper discusses the challenges of using Reinforcement Learning (RL) to improve large language models (LLMs) due to the issue of false negatives from verifiers. False negatives occur when verifiers incorrectly reject correct outputs from the model, which can hinder the RL training process by limiting the feedback the model receives. The authors analyze a dataset and find that a significant portion of model responses are misclassified, leading to slower learning and convergence. To address this, they introduce TinyV, a new verifier that enhances existing methods by identifying and correcting these false negatives, resulting in improved performance on math-reasoning tasks."
                },
                "zh": {
                    "title": "解决假阴性，提升强化学习效果！",
                    "desc": "强化学习（RL）是一种通过奖励信号优化大语言模型（LLM）策略的强大工具。然而，RL的成功依赖于验证者提供的可靠奖励，而我们发现一个普遍存在的问题——假阴性，即验证者错误地拒绝正确的模型输出。我们的研究表明，超过38%的模型生成的响应受到假阴性的影响，这严重损害了RL训练的效果。为了解决这个问题，我们提出了tinyV，一个轻量级的LLM基础验证器，可以动态识别潜在的假阴性，从而提高奖励估计的准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16839",
            "title": "LaViDa: A Large Diffusion Language Model for Multimodal Understanding",
            "url": "https://huggingface.co/papers/2505.16839",
            "abstract": "LaViDa, a family of vision-language models built on discrete diffusion models, offers competitive performance on multimodal benchmarks with advantages in speed, controllability, and bidirectional reasoning.  \t\t\t\t\tAI-generated summary \t\t\t\t Modern Vision-Language Models (VLMs) can solve a wide range of tasks requiring visual reasoning. In real-world scenarios, desirable properties for VLMs include fast inference and controllable generation (e.g., constraining outputs to adhere to a desired format). However, existing autoregressive (AR) VLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs) offer a promising alternative, enabling parallel decoding for faster inference and bidirectional context for controllable generation through text-infilling. While effective in language-only settings, DMs' potential for multimodal tasks is underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build LaViDa by equipping DMs with a vision encoder and jointly fine-tune the combined parts for multimodal instruction following. To address challenges encountered, LaViDa incorporates novel techniques such as complementary masking for effective training, prefix KV cache for efficient inference, and timestep shifting for high-quality sampling. Experiments show that LaViDa achieves competitive or superior performance to AR VLMs on multi-modal benchmarks such as MMMU, while offering unique advantages of DMs, including flexible speed-quality tradeoff, controllability, and bidirectional reasoning. On COCO captioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x speedup. On bidirectional tasks, it achieves +59% improvement on Constrained Poem Completion. These results demonstrate LaViDa as a strong alternative to AR VLMs. Code and models will be released in the camera-ready version.",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 мая",
                "en": "May 22",
                "zh": "5月22日"
            },
            "hash": "9e2202389256fc59",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Hritik Bansal",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Jason Kuen",
                "Zhe Lin",
                "Kai-Wei Chang",
                "Aditya Grover"
            ],
            "affiliations": [
                "Adobe Research",
                "Panasonic AI Research",
                "Salesforce Research",
                "UCLA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16839.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#architecture",
                    "#training",
                    "#games",
                    "#cv",
                    "#diffusion"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "LaViDa: Быстрые и гибкие мультимодальные модели на основе дискретной диффузии",
                    "desc": "LaViDa - это семейство мультимодальных моделей, основанных на дискретных диффузионных моделях. Они предлагают конкурентоспособную производительность на различных мультимодальных задачах, при этом обеспечивая преимущества в скорости, контролируемости и двунаправленном рассуждении. В отличие от авторегрессионных моделей, LaViDa использует параллельное декодирование для более быстрого вывода и двунаправленный контекст для контролируемой генерации. Эксперименты показывают, что LaViDa достигает конкурентных или превосходящих результатов по сравнению с авторегрессионными мультимодальными моделями на различных бенчмарках."
                },
                "en": {
                    "title": "LaViDa: Fast and Controllable Vision-Language Models",
                    "desc": "LaViDa is a new family of vision-language models that utilize discrete diffusion models to enhance performance on multimodal tasks. It addresses the limitations of traditional autoregressive models by providing faster inference and better control over output generation. By integrating a vision encoder and employing techniques like complementary masking and prefix KV cache, LaViDa achieves high-quality results while maintaining efficiency. Experimental results show that LaViDa outperforms existing models in various benchmarks, demonstrating its potential as a robust alternative in the field of vision-language processing."
                },
                "zh": {
                    "title": "LaViDa：高效可控的视觉-语言模型",
                    "desc": "LaViDa是一种基于离散扩散模型的视觉-语言模型家族，能够在多模态基准测试中表现出色。与现有的自回归视觉-语言模型相比，LaViDa在推理速度、可控性和双向推理方面具有明显优势。该模型通过结合视觉编码器和联合微调技术，提升了多模态任务的处理能力。实验结果表明，LaViDa在多模态基准测试中表现优于传统模型，展示了其作为自回归模型强有力替代品的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16707",
            "title": "KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models",
            "url": "https://huggingface.co/papers/2505.16707",
            "abstract": "Recent advances in multi-modal generative models have enabled significant progress in instruction-based image editing. However, while these models produce visually plausible outputs, their capacity for knowledge-based reasoning editing tasks remains under-explored. In this paper, we introduce KRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a diagnostic benchmark designed to assess models through a cognitively informed lens. Drawing from educational theory, KRIS-Bench categorizes editing tasks across three foundational knowledge types: Factual, Conceptual, and Procedural. Based on this taxonomy, we design 22 representative tasks spanning 7 reasoning dimensions and release 1,267 high-quality annotated editing instances. To support fine-grained evaluation, we propose a comprehensive protocol that incorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints and calibrated through human studies. Empirical results on 10 state-of-the-art models reveal significant gaps in reasoning performance, highlighting the need for knowledge-centric benchmarks to advance the development of intelligent image editing systems.",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 мая",
                "en": "May 22",
                "zh": "5月22日"
            },
            "hash": "fa1902dc37796b16",
            "authors": [
                "Yongliang Wu",
                "Zonghui Li",
                "Xinting Hu",
                "Xinyu Ye",
                "Xianfang Zeng",
                "Gang Yu",
                "Wenbo Zhu",
                "Bernt Schiele",
                "Ming-Hsuan Yang",
                "Xu Yang"
            ],
            "affiliations": [
                "Max Planck Institute for Informatics",
                "Shanghai Jiao Tong University",
                "Southeast University",
                "StepFun",
                "University of California, Berkeley",
                "University of California, Merced"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16707.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "KRIS-Bench: когнитивная оценка моделей редактирования изображений",
                    "desc": "Статья представляет KRIS-Bench - диагностический бенчмарк для оценки моделей редактирования изображений с точки зрения когнитивных способностей. Бенчмарк классифицирует задачи редактирования по трем типам знаний: фактическим, концептуальным и процедурным. Авторы разработали 22 репрезентативные задачи по 7 аспектам рассуждений и собрали 1267 аннотированных примеров. Предложен комплексный протокол оценки, включающий новую метрику правдоподобности знаний."
                },
                "en": {
                    "title": "Advancing Image Editing with Knowledge-Based Reasoning",
                    "desc": "This paper presents KRIS-Bench, a new benchmark for evaluating multi-modal generative models in the context of instruction-based image editing. It focuses on assessing the models' ability to perform knowledge-based reasoning tasks, which has not been thoroughly investigated before. The benchmark categorizes editing tasks into three knowledge types: Factual, Conceptual, and Procedural, and includes 22 tasks with 1,267 annotated instances. The study reveals that current state-of-the-art models struggle with reasoning tasks, indicating a need for more knowledge-centric evaluation methods in image editing systems."
                },
                "zh": {
                    "title": "知识驱动的图像编辑评估新基准",
                    "desc": "本文介绍了KRIS-Bench（知识基础推理在图像编辑系统基准），这是一个旨在评估多模态生成模型在知识推理编辑任务中的能力的基准测试。KRIS-Bench根据教育理论将编辑任务分为三种基础知识类型：事实性、概念性和程序性，并设计了22个代表性任务。我们提出了一种综合评估协议，包含新的知识合理性指标，并通过人类研究进行校准。实证结果显示，当前最先进的模型在推理性能上存在显著差距，强调了以知识为中心的基准测试在智能图像编辑系统发展中的重要性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16151",
            "title": "Training-Free Reasoning and Reflection in MLLMs",
            "url": "https://huggingface.co/papers/2505.16151",
            "abstract": "The FRANK Model enhances multimodal LLMs with reasoning and reflection abilities without retraining, using a hierarchical weight merging approach that merges visual-pretrained and reasoning-specialized models.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Reasoning LLMs (e.g., DeepSeek-R1 and OpenAI-o1) have showcased impressive reasoning capabilities via reinforcement learning. However, extending these capabilities to Multimodal LLMs (MLLMs) is hampered by the prohibitive costs of retraining and the scarcity of high-quality, verifiable multimodal reasoning datasets. This paper introduces FRANK Model, a training-FRee ANd r1-liKe MLLM that imbues off-the-shelf MLLMs with reasoning and reflection abilities, without any gradient updates or extra supervision. Our key insight is to decouple perception and reasoning across MLLM decoder layers. Specifically, we observe that compared to the deeper decoder layers, the shallow decoder layers allocate more attention to visual tokens, while the deeper decoder layers concentrate on textual semantics. This observation motivates a hierarchical weight merging approach that combines a visual-pretrained MLLM with a reasoning-specialized LLM. To this end, we propose a layer-wise, Taylor-derived closed-form fusion mechanism that integrates reasoning capacity into deep decoder layers while preserving visual grounding in shallow decoder layers. Extensive experiments on challenging multimodal reasoning benchmarks demonstrate the effectiveness of our approach. On the MMMU benchmark, our model FRANK-38B achieves an accuracy of 69.2, outperforming the strongest baseline InternVL2.5-38B by +5.3, and even surpasses the proprietary GPT-4o model. Our project homepage is at: http://iip.whu.edu.cn/frank/index.html",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 мая",
                "en": "May 22",
                "zh": "5月22日"
            },
            "hash": "59af0e553fdc317e",
            "authors": [
                "Hongchen Wei",
                "Zhenzhong Chen"
            ],
            "affiliations": [
                "School of Remote Sensing and Information Engineering, Wuhan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16151.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#reasoning",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "FRANK: Мультимодальное рассуждение без переобучения",
                    "desc": "Модель FRANK улучшает мультимодальные языковые модели (MLLM), добавляя им способности к рассуждению и рефлексии без переобучения. Это достигается с помощью иерархического подхода к объединению весов, который сочетает модель, предобученную на визуальных данных, с моделью, специализированной на рассуждениях. Метод использует послойное слияние на основе разложения Тейлора, интегрируя способность к рассуждениям в глубокие слои декодера, сохраняя при этом визуальную привязку в поверхностных слоях. Эксперименты показывают эффективность подхода, превосходя сильные базовые модели на сложных мультимодальных тестах рассуждений."
                },
                "en": {
                    "title": "FRANK Model: Enhancing MLLMs with Reasoning Without Retraining",
                    "desc": "The FRANK Model enhances multimodal large language models (MLLMs) by integrating reasoning and reflection capabilities without the need for retraining. It employs a hierarchical weight merging technique that combines visual-pretrained models with reasoning-specialized models, allowing for effective reasoning in MLLMs. The model strategically decouples perception and reasoning across different layers of the decoder, leveraging shallow layers for visual attention and deeper layers for textual semantics. Experimental results show that FRANK-38B significantly outperforms existing models on multimodal reasoning tasks, achieving a notable accuracy increase on the MMMU benchmark."
                },
                "zh": {
                    "title": "FRANK模型：无需重训的多模态推理增强",
                    "desc": "FRANK模型通过分层权重合并的方法，增强了多模态大语言模型（MLLM）的推理和反思能力，而无需重新训练。该模型将视觉预训练的MLLM与专注于推理的LLM结合，避免了高昂的重新训练成本。研究发现，浅层解码器层对视觉信息的关注度更高，而深层解码器层则更注重文本语义，这一观察促成了分层权重合并的方法。通过在深层解码器中整合推理能力，同时保持浅层解码器的视觉基础，FRANK模型在多模态推理基准测试中表现出色，准确率超过了多个强基线模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14810",
            "title": "Scaling Reasoning, Losing Control: Evaluating Instruction Following in\n  Large Reasoning Models",
            "url": "https://huggingface.co/papers/2505.14810",
            "abstract": "An empirical analysis of MathIF identifies a tension between enhancing reasoning capacity and maintaining instruction adherence in large language models.  \t\t\t\t\tAI-generated summary \t\t\t\t Instruction-following is essential for aligning large language models (LLMs) with user intent. While recent reasoning-oriented models exhibit impressive performance on complex mathematical problems, their ability to adhere to natural language instructions remains underexplored. In this work, we introduce MathIF, a dedicated benchmark for evaluating instruction-following in mathematical reasoning tasks. Our empirical analysis reveals a consistent tension between scaling up reasoning capacity and maintaining controllability, as models that reason more effectively often struggle to comply with user directives. We find that models tuned on distilled long chains-of-thought or trained with reasoning-oriented reinforcement learning often degrade in instruction adherence, especially when generation length increases. Furthermore, we show that even simple interventions can partially recover obedience, though at the cost of reasoning performance. These findings highlight a fundamental tension in current LLM training paradigms and motivate the need for more instruction-aware reasoning models. We release the code and data at https://github.com/TingchenFu/MathIF.",
            "score": 2,
            "issue_id": 3914,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "97ed7c1fde734d7e",
            "authors": [
                "Tingchen Fu",
                "Jiawei Gu",
                "Yafu Li",
                "Xiaoye Qu",
                "Yu Cheng"
            ],
            "affiliations": [
                "Renmin University of China",
                "Shanghai AI Laboratory",
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14810.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#training",
                    "#benchmark",
                    "#optimization",
                    "#alignment"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Баланс между разумом и послушанием в ИИ",
                    "desc": "Исследование MathIF выявляет противоречие между улучшением способности к рассуждению и сохранением следования инструкциям в больших языковых моделях (LLM). Анализ показывает, что модели, настроенные на длинные цепочки рассуждений или обученные с помощью обучения с подкреплением, часто ухудшают способность следовать указаниям пользователя. Простые вмешательства могут частично восстановить послушание модели, но за счет снижения производительности рассуждений. Эти выводы подчеркивают фундаментальное противоречие в текущих парадигмах обучения LLM и мотивируют необходимость создания моделей, более осознанно следующих инструкциям при рассуждениях."
                },
                "en": {
                    "title": "Balancing Reasoning and Instruction in Language Models",
                    "desc": "This paper presents MathIF, a benchmark designed to evaluate how well large language models (LLMs) follow instructions while solving mathematical problems. The authors find a conflict between improving reasoning abilities and maintaining adherence to user instructions, as models that excel in reasoning often fail to follow directives accurately. They observe that training methods like reinforcement learning can enhance reasoning but may reduce the model's ability to comply with instructions, especially as the complexity of tasks increases. The study suggests that addressing this tension is crucial for developing more effective instruction-aware reasoning models."
                },
                "zh": {
                    "title": "平衡推理能力与指令遵循的挑战",
                    "desc": "本研究分析了大型语言模型在数学推理任务中的指令遵循能力与推理能力之间的矛盾。我们提出了MathIF基准，用于评估模型在数学推理中的指令遵循表现。研究发现，推理能力更强的模型往往在遵循用户指令时表现不佳，尤其是在生成内容较长时。我们的结果表明，当前的训练方法需要更多关注指令意识，以平衡推理能力和指令遵循。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16916",
            "title": "Backdoor Cleaning without External Guidance in MLLM Fine-tuning",
            "url": "https://huggingface.co/papers/2505.16916",
            "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in fine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt general-purpose models to downstream tasks. This flexibility, however, introduces serious security risks, as malicious fine-tuning can implant backdoors into MLLMs with minimal effort. In this paper, we observe that backdoor triggers systematically disrupt cross-modal processing by causing abnormal attention concentration on non-semantic regions--a phenomenon we term attention collapse. Based on this insight, we propose Believe Your Eyes (BYE), a data filtering framework that leverages attention entropy patterns as self-supervised signals to identify and filter backdoor samples. BYE operates via a three-stage pipeline: (1) extracting attention maps using the fine-tuned model, (2) computing entropy scores and profiling sensitive layers via bimodal separation, and (3) performing unsupervised clustering to remove suspicious samples. Unlike prior defenses, BYE equires no clean supervision, auxiliary labels, or model modifications. Extensive experiments across various datasets, models, and diverse trigger types validate BYE's effectiveness: it achieves near-zero attack success rates while maintaining clean-task performance, offering a robust and generalizable solution against backdoor threats in MLLMs.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 мая",
                "en": "May 22",
                "zh": "5月22日"
            },
            "hash": "36dbc47d484f0a53",
            "authors": [
                "Xuankun Rong",
                "Wenke Huang",
                "Jian Liang",
                "Jinhe Bi",
                "Xun Xiao",
                "Yiming Li",
                "Bo Du",
                "Mang Ye"
            ],
            "affiliations": [
                "Huawei Technologies",
                "Munich Research Center",
                "Nanyang Technological University",
                "School of Computer Science, Wuhan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16916.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#data",
                    "#training",
                    "#dataset",
                    "#security"
                ],
                "emoji": "🛡️",
                "ru": {
                    "title": "Защита мультимодальных ИИ от скрытых угроз: доверяй своим глазам",
                    "desc": "Статья посвящена проблеме безопасности мультимодальных больших языковых моделей (MLLM) в контексте дообучения на пользовательских данных. Авторы обнаружили, что вредоносные триггеры вызывают аномальную концентрацию внимания на несемантических областях, назвав это явление 'коллапсом внимания'. На основе этого наблюдения они разработали фреймворк BYE для фильтрации backdoor-образцов, используя паттерны энтропии внимания. BYE работает в три этапа и не требует чистых данных или модификации модели, обеспечивая эффективную защиту от backdoor-атак на MLLM."
                },
                "en": {
                    "title": "Defending MLLMs: Believe Your Eyes Against Backdoors!",
                    "desc": "This paper addresses the security risks associated with Multimodal Large Language Models (MLLMs) in fine-tuning-as-a-service (FTaaS) environments, where malicious fine-tuning can introduce backdoors. The authors identify a phenomenon called 'attention collapse', where backdoor triggers cause abnormal attention focus on irrelevant areas, disrupting cross-modal processing. To combat this, they propose a framework called Believe Your Eyes (BYE), which uses attention entropy patterns to filter out backdoor samples without needing clean supervision or model changes. BYE demonstrates strong effectiveness in various scenarios, achieving low attack success rates while preserving performance on clean tasks."
                },
                "zh": {
                    "title": "抵御后门威胁的创新解决方案",
                    "desc": "多模态大型语言模型（MLLMs）在微调服务中越来越常见，但这也带来了安全风险，恶意微调可能会在模型中植入后门。本文观察到，后门触发器会导致跨模态处理的异常注意力集中，形成我们称之为注意力崩溃的现象。基于这一发现，我们提出了\"相信你的眼睛\"（BYE）数据过滤框架，通过注意力熵模式作为自监督信号来识别和过滤后门样本。BYE通过三个阶段的流程操作，能够在不需要干净监督或模型修改的情况下，有效地抵御MLLMs中的后门威胁。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16175",
            "title": "QuickVideo: Real-Time Long Video Understanding with System Algorithm\n  Co-Design",
            "url": "https://huggingface.co/papers/2505.16175",
            "abstract": "QuickVideo accelerates long-video understanding by combining a parallelized video decoder, memory-efficient prefilling, and overlapping video decoding with inference, enabling real-time performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-video understanding has emerged as a crucial capability in real-world applications such as video surveillance, meeting summarization, educational lecture analysis, and sports broadcasting. However, it remains computationally prohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential video decoding, the process of converting the raw bit stream to RGB frames can take up to a minute for hour-long video inputs, and 2) costly prefilling of up to several million tokens for LLM inference, resulting in high latency and memory use. To address these challenges, we propose QuickVideo, a system-algorithm co-design that substantially accelerates long-video understanding to support real-time downstream applications. It comprises three key innovations: QuickDecoder, a parallelized CPU-based video decoder that achieves 2-3 times speedup by splitting videos into keyframe-aligned intervals processed concurrently; QuickPrefill, a memory-efficient prefilling method using KV-cache pruning to support more frames with less GPU memory; and an overlapping scheme that overlaps CPU video decoding with GPU inference. Together, these components infernece time reduce by a minute on long video inputs, enabling scalable, high-quality video understanding even on limited hardware. Experiments show that QuickVideo generalizes across durations and sampling rates, making long video processing feasible in practice.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 мая",
                "en": "May 22",
                "zh": "5月22日"
            },
            "hash": "0bcb5c833bad2340",
            "authors": [
                "Benjamin Schneider",
                "Dongfu Jiang",
                "Chao Du",
                "Tianyu Pang",
                "Wenhu Chen"
            ],
            "affiliations": [
                "University of Waterloo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16175.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#optimization",
                    "#video",
                    "#long_context"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Ускорение анализа длинных видео с помощью QuickVideo",
                    "desc": "QuickVideo - это система, ускоряющая понимание длинных видео для приложений реального времени. Она использует параллельный декодер видео, эффективное по памяти предзаполнение и перекрытие декодирования с выводом. QuickVideo включает QuickDecoder для параллельной обработки видео на CPU, QuickPrefill для оптимизации памяти GPU и схему перекрытия CPU-декодирования с GPU-выводом. Эксперименты показывают, что система обобщается на разные длительности и частоты дискретизации видео."
                },
                "en": {
                    "title": "Accelerating Long-Video Understanding for Real-Time Applications",
                    "desc": "QuickVideo is a novel system designed to enhance the understanding of long videos in real-time applications. It addresses two major challenges: the slow sequential video decoding and the high memory requirements for token prefilling in large language models (LLMs). By introducing a parallelized video decoder, a memory-efficient prefilling method, and an overlapping decoding scheme, QuickVideo significantly reduces inference time. This allows for efficient processing of long videos, making advanced video analysis accessible even on limited hardware."
                },
                "zh": {
                    "title": "QuickVideo：实时长视频理解的加速利器",
                    "desc": "QuickVideo 是一种加速长视频理解的系统，结合了并行视频解码、内存高效的预填充和重叠解码与推理。它通过快速解码器将视频分割成关键帧对齐的间隔，并同时处理，从而实现了 2-3 倍的速度提升。QuickPrefill 方法通过 KV-cache 剪枝减少了对 GPU 内存的需求，使得可以处理更多帧。该系统显著降低了长视频输入的推理时间，使得在有限硬件上也能实现高质量的视频理解。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15270",
            "title": "Scaling Diffusion Transformers Efficiently via μP",
            "url": "https://huggingface.co/papers/2505.15270",
            "abstract": "Maximal Update Parametrization (μP) is extended to diffusion Transformers, demonstrating efficient hyperparameter transferability and reduced tuning costs across various models and tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion Transformers have emerged as the foundation for vision generative models, but their scalability is limited by the high cost of hyperparameter (HP) tuning at large scales. Recently, Maximal Update Parametrization (muP) was proposed for vanilla Transformers, which enables stable HP transfer from small to large language models, and dramatically reduces tuning costs. However, it remains unclear whether muP of vanilla Transformers extends to diffusion Transformers, which differ architecturally and objectively. In this work, we generalize standard muP to diffusion Transformers and validate its effectiveness through large-scale experiments. First, we rigorously prove that muP of mainstream diffusion Transformers, including DiT, U-ViT, PixArt-alpha, and MMDiT, aligns with that of the vanilla Transformer, enabling the direct application of existing muP methodologies. Leveraging this result, we systematically demonstrate that DiT-muP enjoys robust HP transferability. Notably, DiT-XL-2-muP with transferred learning rate achieves 2.9 times faster convergence than the original DiT-XL-2. Finally, we validate the effectiveness of muP on text-to-image generation by scaling PixArt-alpha from 0.04B to 0.61B and MMDiT from 0.18B to 18B. In both cases, models under muP outperform their respective baselines while requiring small tuning cost, only 5.5% of one training run for PixArt-alpha and 3% of consumption by human experts for MMDiT-18B. These results establish muP as a principled and efficient framework for scaling diffusion Transformers.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "6c13e0c5ef8ee4a2",
            "authors": [
                "Chenyu Zheng",
                "Xinyu Zhang",
                "Rongzhen Wang",
                "Wei Huang",
                "Zhi Tian",
                "Weilin Huang",
                "Jun Zhu",
                "Chongxuan Li"
            ],
            "affiliations": [
                "Beijing Key Laboratory of Research on Large Models and Intelligent Governance",
                "ByteDance Seed",
                "Engineering Research Center of Next-Generation Intelligent Search and Recommendation, MOE",
                "Gaoling School of AI, Renmin University of China",
                "RIKEN AIP",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15270.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#transfer_learning",
                    "#diffusion",
                    "#optimization"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "μP: Эффективное масштабирование диффузионных трансформеров",
                    "desc": "Статья описывает расширение метода Maximal Update Parametrization (μP) для диффузионных трансформеров. Авторы доказывают, что μP может быть применен к различным архитектурам диффузионных трансформеров, таким как DiT, U-ViT, PixArt-alpha и MMDiT. Эксперименты показывают, что использование μP позволяет эффективно переносить гиперпараметры между моделями разного размера и значительно сокращает затраты на их настройку. Результаты демонстрируют, что μP является эффективным подходом для масштабирования диффузионных трансформеров в задачах генерации изображений."
                },
                "en": {
                    "title": "Efficient Hyperparameter Transfer for Diffusion Transformers with μP",
                    "desc": "This paper extends the Maximal Update Parametrization (μP) technique to diffusion Transformers, which are crucial for generative vision models. The authors demonstrate that μP allows for effective hyperparameter transfer from smaller to larger models, significantly reducing the costs associated with hyperparameter tuning. Through extensive experiments, they show that diffusion Transformers like DiT and PixArt-alpha benefit from μP, achieving faster convergence and better performance with minimal tuning effort. Overall, this work establishes μP as a valuable method for enhancing the scalability and efficiency of diffusion Transformers in various tasks."
                },
                "zh": {
                    "title": "最大更新参数化：扩散变换器的高效调优新方法",
                    "desc": "本文扩展了最大更新参数化（μP）到扩散变换器，展示了高效的超参数可转移性和降低的调优成本。扩散变换器在视觉生成模型中发挥了基础作用，但在大规模应用中超参数调优的高成本限制了其可扩展性。研究表明，μP可以有效地从小型模型转移到大型扩散变换器，并在大规模实验中验证了其有效性。通过系统性实验，结果显示在调优成本较低的情况下，使用μP的模型在性能上优于基线模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11711",
            "title": "Reinforcement Learning Finetunes Small Subnetworks in Large Language\n  Models",
            "url": "https://huggingface.co/papers/2505.11711",
            "abstract": "Reinforcement learning improves large language models with minimal parameter updates, affecting only a small subnetwork without explicit sparsity techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement learning (RL) yields substantial improvements in large language models (LLMs) downstream task performance and alignment with human values. Surprisingly, such large gains result from updating only a small subnetwork comprising just 5 percent to 30 percent of the parameters, with the rest effectively unchanged. We refer to this phenomenon as parameter update sparsity induced by RL. It is observed across all 7 widely used RL algorithms (e.g., PPO, GRPO, DPO) and all 10 LLMs from different families in our experiments. This sparsity is intrinsic and occurs without any explicit sparsity promoting regularizations or architectural constraints. Finetuning the subnetwork alone recovers the test accuracy, and, remarkably, produces a model nearly identical to the one obtained via full finetuning. The subnetworks from different random seeds, training data, and even RL algorithms show substantially greater overlap than expected by chance. Our analysis suggests that this sparsity is not due to updating only a subset of layers, instead, nearly all parameter matrices receive similarly sparse updates. Moreover, the updates to almost all parameter matrices are nearly full-rank, suggesting RL updates a small subset of parameters that nevertheless span almost the full subspaces that the parameter matrices can represent. We conjecture that the this update sparsity can be primarily attributed to training on data that is near the policy distribution, techniques that encourage the policy to remain close to the pretrained model, such as the KL regularization and gradient clipping, have limited impact.",
            "score": 1,
            "issue_id": 3914,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 мая",
                "en": "May 16",
                "zh": "5月16日"
            },
            "hash": "e7296e89ef67015f",
            "authors": [
                "Sagnik Mukherjee",
                "Lifan Yuan",
                "Dilek Hakkani-Tur",
                "Hao Peng"
            ],
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11711.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#training",
                    "#rl",
                    "#optimization",
                    "#alignment"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное обучение языковых моделей: меньше параметров, больше результат",
                    "desc": "Это исследование показывает, что методы обучения с подкреплением (RL) значительно улучшают производительность больших языковых моделей (LLM) при решении задач и их соответствие человеческим ценностям. Удивительно, но такие улучшения достигаются путем обновления только небольшой подсети, составляющей 5-30% параметров модели. Этот феномен, названный 'разреженностью обновления параметров', наблюдается для различных алгоритмов RL и семейств LLM без применения явных методов разреженности. Анализ показывает, что обновления затрагивают почти все матрицы параметров, но остаются разреженными и полноранговыми."
                },
                "en": {
                    "title": "Efficient Reinforcement Learning: Small Updates, Big Gains!",
                    "desc": "This paper explores how reinforcement learning (RL) can enhance the performance of large language models (LLMs) by making minimal updates to a small subnetwork of parameters. Remarkably, only 5 to 30 percent of the model's parameters are adjusted, while the majority remain unchanged, a phenomenon termed 'parameter update sparsity.' This sparsity occurs across various RL algorithms and LLMs, indicating a consistent pattern in how RL influences model training. The findings suggest that even with limited updates, the subnetwork can achieve performance comparable to full finetuning, highlighting the efficiency of RL in optimizing LLMs."
                },
                "zh": {
                    "title": "强化学习：小更新，大提升",
                    "desc": "强化学习（RL）在大型语言模型（LLM）中通过最小的参数更新显著提升了下游任务的表现和与人类价值观的对齐。令人惊讶的是，这种显著的提升仅通过更新占参数5%到30%的小子网络实现，其余参数基本保持不变。我们称这种现象为由RL引起的参数更新稀疏性。实验表明，这种稀疏性在七种广泛使用的RL算法和十种不同家族的LLM中普遍存在，且不需要任何显式的稀疏促进正则化或架构约束。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15963",
            "title": "OViP: Online Vision-Language Preference Learning",
            "url": "https://huggingface.co/papers/2505.15963",
            "abstract": "Large vision-language models (LVLMs) remain vulnerable to hallucination, often generating content misaligned with visual inputs. While recent approaches advance multi-modal Direct Preference Optimization (DPO) to mitigate hallucination, they typically rely on predefined or randomly edited negative samples that fail to reflect actual model errors, limiting training efficacy. In this work, we propose an Online Vision-language Preference Learning (OViP) framework that dynamically constructs contrastive training data based on the model's own hallucinated outputs. By identifying semantic differences between sampled response pairs and synthesizing negative images using a diffusion model, OViP generates more relevant supervision signals in real time. This failure-driven training enables adaptive alignment of both textual and visual preferences. Moreover, we refine existing evaluation protocols to better capture the trade-off between hallucination suppression and expressiveness. Experiments on hallucination and general benchmarks demonstrate that OViP effectively reduces hallucinations while preserving core multi-modal capabilities.",
            "score": 0,
            "issue_id": 3914,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 мая",
                "en": "May 21",
                "zh": "5月21日"
            },
            "hash": "4476380071b2e936",
            "authors": [
                "Shujun Liu",
                "Siyuan Wang",
                "Zejun Li",
                "Jianxiang Wang",
                "Cheng Zeng",
                "Zhongyu Wei"
            ],
            "affiliations": [
                "ByteDance",
                "Fudan University",
                "University of Southern California"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15963.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#training",
                    "#hallucinations",
                    "#benchmark",
                    "#diffusion",
                    "#rag",
                    "#alignment"
                ],
                "emoji": "🔮",
                "ru": {
                    "title": "OViP: Обучение без галлюцинаций для визуально-языковых моделей",
                    "desc": "Статья представляет новый подход к обучению мультимодальных моделей, называемый OViP (Online Vision-language Preference Learning). Этот метод направлен на уменьшение галлюцинаций в крупных визуально-языковых моделях (LVLM) путем динамического создания контрастных обучающих данных на основе собственных ошибочных выходов модели. OViP использует диффузионную модель для синтеза негативных изображений, что позволяет генерировать более релевантные сигналы обучения в реальном времени. Эксперименты показывают, что OViP эффективно снижает галлюцинации, сохраняя при этом ключевые мультимодальные возможности модели."
                },
                "en": {
                    "title": "Dynamic Learning to Combat Hallucination in Vision-Language Models",
                    "desc": "This paper addresses the issue of hallucination in large vision-language models (LVLMs), where the models generate content that does not match the visual inputs. The authors introduce a new framework called Online Vision-language Preference Learning (OViP), which creates training data based on the model's own incorrect outputs, rather than relying on static negative samples. By using a diffusion model to synthesize negative images, OViP provides more relevant feedback for the model to learn from. The results show that this approach not only reduces hallucinations but also maintains the model's ability to express multi-modal information effectively."
                },
                "zh": {
                    "title": "动态构建对比数据，减少幻觉！",
                    "desc": "大型视觉语言模型（LVLMs）在生成内容时容易出现幻觉，常常与视觉输入不一致。虽然最近的研究通过多模态直接偏好优化（DPO）来减轻幻觉问题，但通常依赖于预定义或随机编辑的负样本，这些样本无法真实反映模型的错误，限制了训练效果。我们提出了一种在线视觉语言偏好学习（OViP）框架，动态构建对比训练数据，基于模型自身的幻觉输出。通过识别响应对之间的语义差异并使用扩散模型合成负图像，OViP实时生成更相关的监督信号，有效减少幻觉，同时保持多模态能力。"
                }
            }
        }
    ],
    "link_prev": "2025-05-22.html",
    "link_next": "2025-05-26.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "22.05",
        "en": "05/22",
        "zh": "5月22日"
    },
    "short_date_next": {
        "ru": "26.05",
        "en": "05/26",
        "zh": "5月26日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 5,
        "#agents": 0,
        "#cv": 1,
        "#rl": 3,
        "#rlhf": 2,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 5,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 8,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 5,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 3,
        "#alignment": 3,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了网页导航的自动化任务。过去的研究使用多模态大语言模型（MLLM）作为奖励模型，但这对实际应用有限制。作者提出了第一个过程奖励模型（PRM），称为Web-Shepherd，用于逐步评估网页导航路径。他们创建了一个大规模数据集和评估基准，并在实验中证明了Web-Shepherd的有效性和成本效益。所有模型、数据集和代码都公开可用。",
        "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
        "pinyin": "这篇文章讨论了网页导航的自动化任务。过去的研究使用多模态大语言模型（MLLM）作为奖励模型，但这对实际应用有限制。作者提出了第一个过程奖励模型（PRM），称为Web-Shepherd，用于逐步评估网页导航路径。他们创建了一个大规模数据集和评估基准，并在实验中证明了Web-Shepherd的有效性和成本效益。所有模型、数据集和代码都公开可用。\n\nZhè piān wénzhāng tǎolùn le wǎngyè dǎoháng de zìdònghuà rènwù. Guòqù de yánjiū shǐyòng duō móshì dà yǔyán móxíng (MLLM) zuòwéi jiǎnglì móxíng, dàn zhè duì shíjì yìngyòng yǒu xiànzhì. Zuòzhě tíchū le dì-yīgè guòchéng jiǎnglì móxíng (PRM), chēngwéi Web-Shepherd, yòngyú zhúbù píngjià wǎngyè dǎoháng lùjìng. Tāmen chuàngjiàn le yīgè dà guīmó shùjùjí hé píngjià jīzhǔn, bìng zài shìyàn zhōng zhèngmíng le Web-Shepherd de yǒuxiàoxìng hé chéngběn xiàoyì. Suǒyǒu móxíng, shùjùjí hé dàimǎ dōu gōngkāi kěyòng.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"网页导航\", \"pinyin\": \"wǎng yè dǎo háng\", \"trans\": \"web navigation\"},\n    {\"word\": \"自动化\", \"pinyin\": \"zì dòng huà\", \"trans\": \"automation\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wu\", \"trans\": \"task\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"多模态\", \"pinyin\": \"duō mó tài\", \"trans\": \"multimodal\"},\n    {\"word\": \"大语言模型\", \"pinyin\": \"dà yǔ yán mó xíng\", \"trans\": \"large language model\"},\n    {\"word\": \"奖励模型\", \"pinyin\": \"jiǎng lì mó xíng\", \"trans\": \"reward model\"},\n    {\"word\": \"限制\", \"pinyin\": \"xiàn zhì\", \"trans\": \"limit\"},\n    {\"word\": \"提出\", \"pinyin\": \"tí chū\", \"trans\": \"propose\"},\n    {\"word\": \"过程奖励模型\", \"pinyin\": \"guò chéng jiǎng lì mó xíng\", \"trans\": \"process reward model\"},\n    {\"word\": \"逐步\", \"pinyin\": \"zhuó bù\", \"trans\": \"step-by-step\"},\n    {\"word\": \"评估\", \"pinyin\": \"píng gū\", \"trans\": \"evaluate\"},\n    {\"word\": \"路径\", \"pinyin\": \"lù jìng\", \"trans\": \"path\"},\n    {\"word\": \"创建\", \"pinyin\": \"chuàng jiàn\", \"trans\": \"create\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shù jù jí\", \"trans\": \"dataset\"},\n    {\"word\": \"评估基准\", \"pinyin\": \"píng gū jī zhǔn\", \"trans\": \"evaluation benchmark\"},\n    {\"word\": \"实验\", \"pinyin\": \"shí yàn\", \"trans\": \"experiment\"},\n    {\"word\": \"证明\", \"pinyin\": \"zhèng míng\", \"trans\": \"prove\"},\n    {\"word\": \"有效性\", \"pinyin\": \"yǒu xiào xìng\", \"trans\": \"effectiveness\"},\n    {\"word\": \"成本效益\", \"pinyin\": \"chéng běn xiào yì\", \"trans\": \"cost-effectiveness\"},\n    {\"word\": \"公开可用\", \"pinyin\": \"gōng kāi kě yòng\", \"trans\": \"publicly available\"}\n]",
        "trans": "This article discusses the automation of web page navigation tasks. Previous research has used multimodal large language models (MLLMs) as reward models, but this has limitations for practical applications. The authors propose the first process reward model (PRM), called Web-Shepherd, for step-by-step evaluation of web page navigation paths. They created a large-scale dataset and evaluation benchmark, and demonstrated the effectiveness and cost-efficiency of Web-Shepherd in experiments. All models, datasets, and code are publicly available.",
        "update_ts": "2025-05-22 09:12"
    }
}