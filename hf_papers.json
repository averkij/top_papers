{
    "date": {
        "ru": "21 мая",
        "en": "May 21",
        "zh": "5月21日"
    },
    "time_utc": "2025-05-21 02:30",
    "weekday": 2,
    "issue_id": 3868,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.14683",
            "title": "Emerging Properties in Unified Multimodal Pretraining",
            "url": "https://huggingface.co/papers/2505.14683",
            "abstract": "Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems. In this work, we introduce BAGEL, an open0source foundational model that natively supports multimodal understanding and generation. BAGEL is a unified, decoder0only model pretrained on trillions of tokens curated from large0scale interleaved text, image, video, and web data. When scaled with such diverse multimodal interleaved data, BAGEL exhibits emerging capabilities in complex multimodal reasoning. As a result, it significantly outperforms open-source unified models in both multimodal generation and understanding across standard benchmarks, while exhibiting advanced multimodal reasoning abilities such as free-form image manipulation, future frame prediction, 3D manipulation, and world navigation. In the hope of facilitating further opportunities for multimodal research, we share the key findings, pretraining details, data creation protocal, and release our code and checkpoints to the community. The project page is at https://bagel-ai.org/",
            "score": 13,
            "issue_id": 3868,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "57522649bb8f8010",
            "authors": [
                "Chaorui Deng",
                "Deyao Zhu",
                "Kunchang Li",
                "Chenhui Gou",
                "Feng Li",
                "Zeyu Wang",
                "Shu Zhong",
                "Weihao Yu",
                "Xiaonan Nie",
                "Ziang Song",
                "Guang Shi",
                "Haoqi Fan"
            ],
            "affiliations": [
                "ByteDance Seed",
                "Hong Kong University of Science and Technology",
                "Monash University",
                "Shenzhen Institutes of Advanced Technology",
                "UC Santa Cruz"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14683.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#benchmark",
                    "#reasoning",
                    "#open_source",
                    "#multimodal",
                    "#dataset"
                ],
                "emoji": "🥯",
                "ru": {
                    "title": "BAGEL: Объединение мультимодального понимания и генерации в открытой модели",
                    "desc": "BAGEL - это открытая фундаментальная модель для мультимодального понимания и генерации. Она обучена на триллионах токенов из текстовых, изображений, видео и веб-данных. BAGEL превосходит другие открытые унифицированные модели в задачах мультимодальной генерации и понимания. Модель демонстрирует продвинутые способности в мультимодальном рассуждении, включая манипуляции с изображениями, предсказание будущих кадров и 3D-манипуляции."
                },
                "en": {
                    "title": "BAGEL: Unifying Multimodal AI for Enhanced Understanding and Generation",
                    "desc": "This paper presents BAGEL, an open-source foundational model designed for multimodal understanding and generation. BAGEL is a decoder-only model that has been pretrained on a vast dataset comprising text, images, videos, and web content. By leveraging this diverse multimodal data, BAGEL demonstrates advanced capabilities in complex reasoning tasks, outperforming existing open-source models. The authors aim to promote further research in multimodal AI by sharing their findings, pretraining methods, and code with the community."
                },
                "zh": {
                    "title": "BAGEL：开源多模态理解与生成的统一模型",
                    "desc": "本文介绍了一个名为BAGEL的开源基础模型，它支持多模态理解和生成。BAGEL是一个统一的解码器模型，经过在大量文本、图像、视频和网络数据上进行预训练。通过使用多样化的多模态数据，BAGEL在复杂的多模态推理方面展现出新的能力，显著超越了现有的开源统一模型。我们希望通过分享关键发现、预训练细节和数据创建协议，促进多模态研究的进一步发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14513",
            "title": "Latent Flow Transformer",
            "url": "https://huggingface.co/papers/2505.14513",
            "abstract": "Transformers, the standard implementation for large language models (LLMs), typically consist of tens to hundreds of discrete layers. While more layers can lead to better performance, this approach has been challenged as far from efficient, especially given the superiority of continuous layers demonstrated by diffusion and flow-based models for image generation. We propose the Latent Flow Transformer (LFT), which replaces a block of layers with a single learned transport operator trained via flow matching, offering significant compression while maintaining compatibility with the original architecture. Additionally, we address the limitations of existing flow-based methods in preserving coupling by introducing the Flow Walking (FW) algorithm. On the Pythia-410M model, LFT trained with flow matching compresses 6 of 24 layers and outperforms directly skipping 2 layers (KL Divergence of LM logits at 0.407 vs. 0.529), demonstrating the feasibility of this design. When trained with FW, LFT further distills 12 layers into one while reducing the KL to 0.736 surpassing that from skipping 3 layers (0.932), significantly narrowing the gap between autoregressive and flow-based generation paradigms.",
            "score": 5,
            "issue_id": 3868,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "3683bab427c47086",
            "authors": [
                "Yen-Chen Wu",
                "Feng-Ting Liao",
                "Meng-Hsi Chen",
                "Pei-Chen Ho",
                "Farhang Nabiei",
                "Da-shan Shiu"
            ],
            "affiliations": [
                "MediaTek Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14513.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#optimization",
                    "#diffusion",
                    "#training"
                ],
                "emoji": "🌊",
                "ru": {
                    "title": "Непрерывные потоки вместо дискретных слоев: революция в архитектуре трансформеров",
                    "desc": "Статья представляет Latent Flow Transformer (LFT), новый подход к архитектуре языковых моделей. LFT заменяет несколько дискретных слоев одним непрерывным оператором переноса, обученным с помощью метода согласования потоков. Авторы также предлагают алгоритм Flow Walking для улучшения сохранения связей между токенами. Эксперименты на модели Pythia-410M показывают, что LFT позволяет значительно сжать модель, сохраняя или даже улучшая ее производительность."
                },
                "en": {
                    "title": "Efficient Layer Compression with Latent Flow Transformers",
                    "desc": "This paper introduces the Latent Flow Transformer (LFT), a new architecture for large language models that replaces multiple discrete layers with a single learned transport operator. By utilizing flow matching, LFT achieves significant model compression while still being compatible with traditional transformer designs. The authors also present the Flow Walking (FW) algorithm to enhance the coupling preservation in flow-based methods. Experimental results show that LFT can effectively reduce the number of layers while improving performance metrics, bridging the gap between autoregressive and flow-based generation techniques."
                },
                "zh": {
                    "title": "潜在流变换器：高效压缩大语言模型的创新方案",
                    "desc": "本文提出了一种新的模型——潜在流变换器（Latent Flow Transformer, LFT），旨在提高大语言模型的效率。LFT通过使用学习的传输算子替代多个离散层，从而实现显著的压缩，同时保持与原始架构的兼容性。我们还引入了流步行（Flow Walking, FW）算法，以解决现有流基方法在保持耦合方面的局限性。实验结果表明，LFT在压缩层数的同时，能够在性能上超越传统的层跳过方法，缩小自回归和流生成范式之间的差距。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13866",
            "title": "Reasoning Path Compression: Compressing Generation Trajectories for\n  Efficient LLM Reasoning",
            "url": "https://huggingface.co/papers/2505.13866",
            "abstract": "Recent reasoning-focused language models achieve high accuracy by generating lengthy intermediate reasoning paths before producing final answers. While this approach is effective in solving problems that require logical thinking, long reasoning paths significantly increase memory usage and throughput of token generation, limiting the practical deployment of such models. We propose Reasoning Path Compression (RPC), a training-free method that accelerates inference by leveraging the semantic sparsity of reasoning paths. RPC periodically compresses the KV cache by retaining KV cache that receive high importance score, which are computed using a selector window composed of recently generated queries. Experiments show that RPC improves generation throughput of QwQ-32B by up to 1.60times compared to the inference with full KV cache, with an accuracy drop of 1.2% on the AIME 2024 benchmark. Our findings demonstrate that semantic sparsity in reasoning traces can be effectively exploited for compression, offering a practical path toward efficient deployment of reasoning LLMs. Our code is available at https://github.com/jiwonsong-dev/ReasoningPathCompression.",
            "score": 5,
            "issue_id": 3868,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "72f6460e348e135a",
            "authors": [
                "Jiwon Song",
                "Dongwon Jo",
                "Yulhwa Kim",
                "Jae-Joon Kim"
            ],
            "affiliations": [
                "Seoul National University",
                "Sungkyunkwan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13866.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#optimization",
                    "#reasoning",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Ускорение языковых моделей через сжатие путей рассуждений",
                    "desc": "Статья представляет метод Сжатия Пути Рассуждений (RPC) для ускорения вывода моделей языка, ориентированных на рассуждения. RPC использует семантическую разреженность путей рассуждений, периодически сжимая KV-кэш путем сохранения наиболее важных элементов. Эксперименты показывают, что RPC увеличивает пропускную способность генерации модели QwQ-32B до 1.60 раз по сравнению с выводом с полным KV-кэшем. Метод демонстрирует, что семантическая разреженность в следах рассуждений может быть эффективно использована для сжатия, предлагая практический путь к эффективному развертыванию рассуждающих языковых моделей."
                },
                "en": {
                    "title": "Efficient Inference with Reasoning Path Compression",
                    "desc": "This paper introduces Reasoning Path Compression (RPC), a method designed to enhance the efficiency of reasoning-focused language models during inference. By utilizing the concept of semantic sparsity, RPC compresses the key-value (KV) cache, retaining only the most important elements based on recent queries. This approach significantly increases the throughput of token generation while only slightly affecting accuracy. The results indicate that RPC can improve the performance of large models like QwQ-32B, making them more practical for real-world applications."
                },
                "zh": {
                    "title": "推理路径压缩：高效推理的新方法",
                    "desc": "最近专注于推理的语言模型通过生成较长的中间推理路径来实现高准确率。这种方法在解决需要逻辑思维的问题时非常有效，但长推理路径显著增加了内存使用和令牌生成的吞吐量，限制了模型的实际应用。我们提出了一种名为推理路径压缩（RPC）的方法，通过利用推理路径的语义稀疏性来加速推理。实验表明，RPC在AIME 2024基准测试中相比于完整KV缓存，提升了QwQ-32B的生成吞吐量，准确率仅下降1.2%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14680",
            "title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search",
            "url": "https://huggingface.co/papers/2505.14680",
            "abstract": "Generative AI search is reshaping information retrieval by offering end-to-end answers to complex queries, reducing users' reliance on manually browsing and summarizing multiple web pages. However, while this paradigm enhances convenience, it disrupts the feedback-driven improvement loop that has historically powered the evolution of traditional Web search. Web search can continuously improve their ranking models by collecting large-scale, fine-grained user feedback (e.g., clicks, dwell time) at the document level. In contrast, generative AI search operates through a much longer search pipeline, spanning query decomposition, document retrieval, and answer generation, yet typically receives only coarse-grained feedback on the final answer. This introduces a feedback loop disconnect, where user feedback for the final output cannot be effectively mapped back to specific system components, making it difficult to improve each intermediate stage and sustain the feedback loop. In this paper, we envision NExT-Search, a next-generation paradigm designed to reintroduce fine-grained, process-level feedback into generative AI search. NExT-Search integrates two complementary modes: User Debug Mode, which allows engaged users to intervene at key stages; and Shadow User Mode, where a personalized user agent simulates user preferences and provides AI-assisted feedback for less interactive users. Furthermore, we envision how these feedback signals can be leveraged through online adaptation, which refines current search outputs in real-time, and offline update, which aggregates interaction logs to periodically fine-tune query decomposition, retrieval, and generation models. By restoring human control over key stages of the generative AI search pipeline, we believe NExT-Search offers a promising direction for building feedback-rich AI search systems that can evolve continuously alongside human feedback.",
            "score": 2,
            "issue_id": 3868,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "ace242db16327202",
            "authors": [
                "Sunhao Dai",
                "Wenjie Wang",
                "Liang Pang",
                "Jun Xu",
                "See-Kiong Ng",
                "Ji-Rong Wen",
                "Tat-Seng Chua"
            ],
            "affiliations": [
                "CAS Key Laboratory of AI Safety Institute of Computing Technology Chinese Academy of Sciences",
                "Gaoling School of Artificial Intelligence Renmin University of China",
                "National University of Singapore",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14680.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#rag",
                    "#rlhf",
                    "#agents",
                    "#alignment"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Возвращение человеческого контроля в ИИ-поиск",
                    "desc": "Статья представляет концепцию NExT-Search, новую парадигму генеративного ИИ-поиска. Она направлена на восстановление детальной обратной связи в процессе поиска, что было утрачено при переходе от традиционного веб-поиска к генеративному ИИ. NExT-Search предлагает два режима: режим отладки пользователем и режим теневого пользователя, позволяющие собирать обратную связь на разных этапах поиска. Система использует эту обратную связь для онлайн-адаптации и офлайн-обновления моделей декомпозиции запросов, извлечения и генерации ответов."
                },
                "en": {
                    "title": "NExT-Search: Enhancing Generative AI Search with User Feedback",
                    "desc": "This paper discusses the challenges of integrating user feedback into generative AI search systems, which provide direct answers to complex queries but lack detailed feedback mechanisms. Traditional web search benefits from fine-grained user interactions, allowing for continuous improvement of ranking models. The proposed NExT-Search framework aims to bridge this gap by introducing two modes of user feedback: User Debug Mode for active user engagement and Shadow User Mode for passive feedback collection. By leveraging both real-time and aggregated feedback, NExT-Search seeks to enhance the generative AI search process and ensure it evolves in response to user needs."
                },
                "zh": {
                    "title": "NExT-Search：重塑生成式搜索的反馈循环",
                    "desc": "生成式人工智能搜索正在改变信息检索，通过提供端到端的答案来应对复杂查询，减少用户手动浏览和总结多个网页的依赖。然而，这种新模式虽然提高了便利性，却打破了传统网页搜索中基于反馈的改进循环。传统搜索可以通过收集用户反馈（如点击率和停留时间）来不断改进排名模型，而生成式搜索则面临反馈循环断裂的问题，用户反馈难以有效映射到系统的具体组件。本文提出了NExT-Search，旨在将细粒度的过程级反馈重新引入生成式搜索，结合用户调试模式和影子用户模式，以实现实时和离线的反馈信号利用，从而持续改进搜索系统。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13380",
            "title": "CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via\n  Competition",
            "url": "https://huggingface.co/papers/2505.13380",
            "abstract": "Sparse mixture of experts (SMoE) offers an appealing solution to scale up the model complexity beyond the mean of increasing the network's depth or width. However, we argue that effective SMoE training remains challenging because of the suboptimal routing process where experts that perform computation do not directly contribute to the routing process. In this work, we propose competition, a novel mechanism to route tokens to experts with the highest neural response. Theoretically, we show that the competition mechanism enjoys a better sample efficiency than the traditional softmax routing. Furthermore, we develop CompeteSMoE, a simple yet effective algorithm to train large language models by deploying a router to learn the competition policy, thus enjoying strong performances at a low training overhead. Our extensive empirical evaluations on both the visual instruction tuning and language pre-training tasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE compared to state-of-the-art SMoE strategies. We have made the implementation available at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an improved version of the previous study at arXiv:2402.02526",
            "score": 1,
            "issue_id": 3868,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 мая",
                "en": "May 19",
                "zh": "5月19日"
            },
            "hash": "6a5e70a76e6f012c",
            "authors": [
                "Nam V. Nguyen",
                "Huy Nguyen",
                "Quang Pham",
                "Van Nguyen",
                "Savitha Ramasamy",
                "Nhat Ho"
            ],
            "affiliations": [
                "FPT Software AI Center",
                "Independent Researcher",
                "Institute for Infocomm Research, ASTAR",
                "The University of Texas at Austin"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13380.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#optimization",
                    "#open_source",
                    "#training"
                ],
                "emoji": "🏆",
                "ru": {
                    "title": "Конкуренция экспертов для эффективного обучения языковых моделей",
                    "desc": "Статья представляет новый механизм маршрутизации токенов в разреженных смесях экспертов (SMoE) под названием 'competition'. Авторы теоретически доказывают, что этот метод обладает лучшей эффективностью выборки по сравнению с традиционной маршрутизацией softmax. На основе этого механизма разработан алгоритм CompeteSMoE для обучения больших языковых моделей. Эмпирические эксперименты на задачах визуального обучения и предобучения языка демонстрируют эффективность, надежность и масштабируемость CompeteSMoE по сравнению с современными стратегиями SMoE."
                },
                "en": {
                    "title": "CompeteSMoE: Efficient Routing for Powerful Language Models",
                    "desc": "Sparse mixture of experts (SMoE) is a method that allows models to become more complex without simply making them deeper or wider. The challenge with SMoE is that the way experts are chosen to process data can be inefficient, as not all experts contribute to the decision-making process. This paper introduces a new routing mechanism called competition, which directs data to the most responsive experts, improving the efficiency of the model. The authors present CompeteSMoE, an algorithm that uses this competition mechanism to train large language models effectively, showing better performance and lower training costs compared to existing methods."
                },
                "zh": {
                    "title": "竞争机制提升稀疏专家混合模型的效率",
                    "desc": "稀疏专家混合模型（SMoE）是一种有效提升模型复杂度的方法，超越了简单增加网络深度或宽度的方式。然而，SMoE的训练仍然面临挑战，主要是因为计算的专家与路由过程之间的联系不够直接。我们提出了一种新的机制——竞争，能够将输入数据更有效地路由到响应最强的专家。通过理论分析，我们证明了竞争机制在样本效率上优于传统的softmax路由，并开发了CompeteSMoE算法，能够以较低的训练开销实现强大的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12182",
            "title": "Truth Neurons",
            "url": "https://huggingface.co/papers/2505.12182",
            "abstract": "Despite their remarkable success and deployment across diverse workflows, language models sometimes produce untruthful responses. Our limited understanding of how truthfulness is mechanistically encoded within these models jeopardizes their reliability and safety. In this paper, we propose a method for identifying representations of truthfulness at the neuron level. We show that language models contain truth neurons, which encode truthfulness in a subject-agnostic manner. Experiments conducted across models of varying scales validate the existence of truth neurons, confirming that the encoding of truthfulness at the neuron level is a property shared by many language models. The distribution patterns of truth neurons over layers align with prior findings on the geometry of truthfulness. Selectively suppressing the activations of truth neurons found through the TruthfulQA dataset degrades performance both on TruthfulQA and on other benchmarks, showing that the truthfulness mechanisms are not tied to a specific dataset. Our results offer novel insights into the mechanisms underlying truthfulness in language models and highlight potential directions toward improving their trustworthiness and reliability.",
            "score": 1,
            "issue_id": 3868,
            "pub_date": "2025-05-18",
            "pub_date_card": {
                "ru": "18 мая",
                "en": "May 18",
                "zh": "5月18日"
            },
            "hash": "ddeab64450bb26a9",
            "authors": [
                "Haohang Li",
                "Yupeng Cao",
                "Yangyang Yu",
                "Jordan W. Suchow",
                "Zining Zhu"
            ],
            "affiliations": [
                "Stevens Institute of Technology",
                "Vector Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12182.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#benchmark",
                    "#hallucinations",
                    "#alignment",
                    "#data",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Нейроны правды: путь к повышению надежности языковых моделей",
                    "desc": "Исследователи предложили метод идентификации представлений правдивости на уровне отдельных нейронов в языковых моделях. Они обнаружили так называемые 'нейроны правды', которые кодируют правдивость независимо от темы. Эксперименты подтвердили наличие таких нейронов в моделях разного масштаба. Подавление активации этих нейронов ухудшает производительность модели на различных тестах правдивости."
                },
                "en": {
                    "title": "Unveiling Truth Neurons: Enhancing Language Model Trustworthiness",
                    "desc": "This paper investigates how language models encode truthfulness at the neuron level, revealing the presence of 'truth neurons' that represent truthfulness in a way that is not dependent on specific subjects. The authors demonstrate that these truth neurons exist across various models, indicating a shared property among them. By analyzing the distribution of truth neurons across different layers, the study aligns with previous research on the geometry of truthfulness. Additionally, the suppression of these neurons negatively impacts model performance, suggesting that understanding and improving truthfulness in language models is crucial for their reliability."
                },
                "zh": {
                    "title": "揭示语言模型中的真相神经元",
                    "desc": "尽管语言模型在各种工作流程中取得了显著成功，但有时会产生不真实的回答。我们对这些模型中真相编码机制的理解有限，这影响了它们的可靠性和安全性。本文提出了一种方法，通过神经元层面识别真相的表示，发现语言模型中存在编码真相的真相神经元。实验表明，真相神经元的存在是许多语言模型的共同特性，并且其分布模式与真相的几何特征一致。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14178",
            "title": "Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic\n  Reasoning Limits",
            "url": "https://huggingface.co/papers/2505.14178",
            "abstract": "Tokenization is the first - and often underappreciated - layer of computation in language models. While Chain-of-Thought (CoT) prompting enables transformer models to approximate recurrent computation by externalizing intermediate steps, we show that the success of such reasoning is fundamentally bounded by the structure of tokenized inputs. This work presents a theoretical and empirical investigation into how tokenization schemes, particularly subword-based methods like byte-pair encoding (BPE), impede symbolic computation by merging or obscuring atomic reasoning units. We introduce the notion of Token Awareness to formalize how poor token granularity disrupts logical alignment and prevents models from generalizing symbolic procedures. Through systematic evaluation on arithmetic and symbolic tasks, we demonstrate that token structure dramatically affect reasoning performance, causing failure even with CoT, while atomically-aligned formats unlock strong generalization, allowing small models (e.g., GPT-4o-mini) to outperform larger systems (e.g., o1) in structured reasoning. Our findings reveal that symbolic reasoning ability in LLMs is not purely architectural, but deeply conditioned on token-level representations.",
            "score": 0,
            "issue_id": 3868,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "f4fdc7fb140f9273",
            "authors": [
                "Xiang Zhang",
                "Juntai Cao",
                "Jiaqi Wei",
                "Yiwei Xu",
                "Chenyu You"
            ],
            "affiliations": [
                "Cisco",
                "Stony Brook University",
                "University of British Columbia",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14178.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#reasoning",
                    "#architecture",
                    "#small_models",
                    "#data",
                    "#training"
                ],
                "emoji": "🧩",
                "ru": {
                    "title": "Токенизация: скрытый ключ к символьным рассуждениям в ИИ",
                    "desc": "Статья исследует влияние токенизации на способность языковых моделей к символьным вычислениям. Авторы вводят понятие 'осведомленности о токенах' (Token Awareness) для формализации того, как неоптимальная гранулярность токенов нарушает логическое выравнивание и препятствует обобщению символьных процедур. Эмпирические эксперименты показывают, что структура токенов существенно влияет на производительность рассуждений, даже при использовании метода цепочки рассуждений (Chain-of-Thought). Исследование демонстрирует, что способность к символьным рассуждениям в больших языковых моделях (LLM) глубоко обусловлена токен-уровневыми представлениями."
                },
                "en": {
                    "title": "Tokenization Matters: Unlocking Reasoning in Language Models",
                    "desc": "This paper explores the importance of tokenization in language models, particularly how it affects reasoning capabilities. It highlights that traditional tokenization methods, like byte-pair encoding (BPE), can obscure essential reasoning units, limiting the model's ability to perform symbolic computation. The authors introduce the concept of Token Awareness, which emphasizes the need for better token granularity to enhance logical alignment and generalization in models. Through experiments on arithmetic and symbolic tasks, they show that models with well-structured token representations can significantly outperform larger models in reasoning tasks."
                },
                "zh": {
                    "title": "分词结构决定推理能力",
                    "desc": "本文探讨了在语言模型中，分词（Tokenization）对推理能力的影响。我们发现，分词方案，特别是基于子词的方法（如字节对编码BPE），会合并或模糊基本的推理单元，从而妨碍符号计算。我们引入了“Token Awareness”的概念，强调了分词粒度不佳如何干扰逻辑对齐，阻碍模型的符号程序泛化。通过对算术和符号任务的系统评估，我们证明了分词结构显著影响推理性能，较小的模型在对齐格式下能够超越更大的系统。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12306",
            "title": "Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for\n  Real-world Knowledge Injection",
            "url": "https://huggingface.co/papers/2505.12306",
            "abstract": "Despite significant advances in large language models (LLMs), their knowledge memorization capabilities remain underexplored, due to the lack of standardized and high-quality test ground. In this paper, we introduce a novel, real-world and large-scale knowledge injection benchmark that evolves continuously over time without requiring human intervention. Specifically, we propose WikiDYK, which leverages recently-added and human-written facts from Wikipedia's \"Did You Know...\" entries. These entries are carefully selected by expert Wikipedia editors based on criteria such as verifiability and clarity. Each entry is converted into multiple question-answer pairs spanning diverse task formats from easy cloze prompts to complex multi-hop questions. WikiDYK contains 12,290 facts and 77,180 questions, which is also seamlessly extensible with future updates from Wikipedia editors. Extensive experiments using continued pre-training reveal a surprising insight: despite their prevalence in modern LLMs, Causal Language Models (CLMs) demonstrate significantly weaker knowledge memorization capabilities compared to Bidirectional Language Models (BiLMs), exhibiting a 23% lower accuracy in terms of reliability. To compensate for the smaller scales of current BiLMs, we introduce a modular collaborative framework utilizing ensembles of BiLMs as external knowledge repositories to integrate with LLMs. Experiment shows that our framework further improves the reliability accuracy by up to 29.1%.",
            "score": 0,
            "issue_id": 3868,
            "pub_date": "2025-05-18",
            "pub_date_card": {
                "ru": "18 мая",
                "en": "May 18",
                "zh": "5月18日"
            },
            "hash": "ccbad06f5ba35418",
            "authors": [
                "Yuwei Zhang",
                "Wenhao Yu",
                "Shangbin Feng",
                "Yifan Zhu",
                "Letian Peng",
                "Jayanth Srinivasa",
                "Gaowen Liu",
                "Jingbo Shang"
            ],
            "affiliations": [
                "Cisco",
                "Tencent AI Lab",
                "UC, San Diego",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12306.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#interpretability",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "WikiDYK: новый стандарт оценки памяти языковых моделей",
                    "desc": "Статья представляет новый масштабный бенчмарк WikiDYK для оценки способности языковых моделей запоминать знания. WikiDYK использует недавно добавленные факты из раздела Wikipedia 'Did You Know...', преобразуя их в разнообразные вопросно-ответные пары. Эксперименты показали, что двунаправленные языковые модели (BiLM) значительно лучше запоминают знания, чем однонаправленные причинные модели (CLM). Авторы предлагают модульную коллаборативную систему, использующую ансамбли BiLM в качестве внешних хранилищ знаний для интеграции с большими языковыми моделями."
                },
                "en": {
                    "title": "Enhancing Knowledge Memorization in Language Models with WikiDYK",
                    "desc": "This paper presents WikiDYK, a new benchmark for evaluating knowledge memorization in large language models (LLMs). It uses real-world facts from Wikipedia's 'Did You Know...' entries to create a diverse set of question-answer pairs. The study finds that Causal Language Models (CLMs) have weaker knowledge memorization capabilities compared to Bidirectional Language Models (BiLMs), with a notable accuracy gap. To enhance BiLMs' performance, the authors propose a collaborative framework that combines multiple BiLMs as external knowledge sources, resulting in improved accuracy in knowledge retrieval tasks."
                },
                "zh": {
                    "title": "知识记忆能力的新基准：WikiDYK",
                    "desc": "尽管大型语言模型（LLMs）取得了显著进展，但它们的知识记忆能力仍然未得到充分探索。本文提出了一种新颖的、真实世界的大规模知识注入基准，名为WikiDYK，能够随着时间的推移不断演变，而无需人工干预。WikiDYK利用维基百科“你知道吗...”条目中最近添加的、由人类撰写的事实，经过专家编辑的严格筛选，确保其可验证性和清晰性。实验结果表明，尽管因果语言模型（CLMs）在现代LLMs中普遍存在，但其知识记忆能力显著低于双向语言模型（BiLMs），准确性低23%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.10588",
            "title": "Understanding Gen Alpha Digital Language: Evaluation of LLM Safety\n  Systems for Content Moderation",
            "url": "https://huggingface.co/papers/2505.10588",
            "abstract": "This research offers a unique evaluation of how AI systems interpret the digital language of Generation Alpha (Gen Alpha, born 2010-2024). As the first cohort raised alongside AI, Gen Alpha faces new forms of online risk due to immersive digital engagement and a growing mismatch between their evolving communication and existing safety tools. Their distinct language, shaped by gaming, memes, and AI-driven trends, often conceals harmful interactions from both human moderators and automated systems. We assess four leading AI models (GPT-4, Claude, Gemini, and Llama 3) on their ability to detect masked harassment and manipulation within Gen Alpha discourse. Using a dataset of 100 recent expressions from gaming platforms, social media, and video content, the study reveals critical comprehension failures with direct implications for online safety. This work contributes: (1) a first-of-its-kind dataset capturing Gen Alpha expressions; (2) a framework to improve AI moderation systems for youth protection; (3) a multi-perspective evaluation including AI systems, human moderators, and parents, with direct input from Gen Alpha co-researchers; and (4) an analysis of how linguistic divergence increases youth vulnerability. Findings highlight the urgent need to redesign safety systems attuned to youth communication, especially given Gen Alpha reluctance to seek help when adults fail to understand their digital world. This study combines the insight of a Gen Alpha researcher with systematic academic analysis to address critical digital safety challenges.",
            "score": 0,
            "issue_id": 3868,
            "pub_date": "2025-05-14",
            "pub_date_card": {
                "ru": "14 мая",
                "en": "May 14",
                "zh": "5月14日"
            },
            "hash": "cdc9a4f93d65b071",
            "authors": [
                "Manisha Mehta",
                "Fausto Giunchiglia"
            ],
            "affiliations": [
                "University of Trento, Trento, Italy",
                "Warren Hyde Middle School, Cupertino, California, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.10588.jpg",
            "data": {
                "categories": [
                    "#healthcare",
                    "#interpretability",
                    "#benchmark",
                    "#ethics",
                    "#multimodal",
                    "#dataset"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Преодолевая языковой барьер: ИИ на страже безопасности цифрового поколения",
                    "desc": "Исследование оценивает способность ИИ-систем интерпретировать цифровой язык поколения Альфа. Авторы анализируют четыре ведущие модели искусственного интеллекта на предмет обнаружения скрытых форм домогательств и манипуляций в дискурсе этого поколения. Работа включает создание уникального датасета выражений поколения Альфа и разработку framework'а для улучшения систем модерации на базе ИИ. Результаты подчеркивают острую необходимость переработки систем безопасности с учетом особенностей коммуникации молодежи."
                },
                "en": {
                    "title": "Bridging the Gap: Enhancing AI Safety for Generation Alpha",
                    "desc": "This research evaluates how AI systems understand the unique digital language of Generation Alpha, who are growing up with AI technology. It highlights the risks they face online due to their distinct communication styles, influenced by gaming and memes, which can hide harmful interactions from both humans and automated systems. The study tests four AI models on their ability to detect subtle harassment in Gen Alpha's online expressions, revealing significant gaps in their comprehension. The findings emphasize the need for improved AI moderation tools that are better suited to protect youth in their digital environments."
                },
                "zh": {
                    "title": "重塑安全系统，保护阿尔法世代的数字交流",
                    "desc": "本研究独特地评估了人工智能系统如何解读阿尔法世代（2010-2024年出生）的数字语言。阿尔法世代是首个与人工智能共同成长的群体，他们在沉浸式数字环境中面临新的在线风险。研究分析了四种领先的人工智能模型（GPT-4、Claude、Gemini和Llama 3）在识别隐藏的骚扰和操控方面的能力。研究结果显示，现有的安全工具未能有效理解阿尔法世代的独特交流方式，强调了重新设计安全系统的紧迫性，以更好地保护年轻用户。"
                }
            }
        }
    ],
    "link_prev": "2025-05-20.html",
    "link_next": "2025-05-22.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "20.05",
        "en": "05/20",
        "zh": "5月20日"
    },
    "short_date_next": {
        "ru": "22.05",
        "en": "05/22",
        "zh": "5月22日"
    },
    "categories": {
        "#dataset": 4,
        "#data": 2,
        "#benchmark": 4,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 1,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 5,
        "#reasoning": 3,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章提出了一种新的学习范式，称为Chain-of-Model (CoM)。它将因果关系引入每层的隐藏状态，形成链式结构，提高了模型训练的扩展效率和部署的灵活性。作者引入了Chain-of-Representation (CoR)的概念，将每层的隐藏状态表示为多个子表示（即链）的组合。每层中，每个链只能查看输入表示中的所有前序链。因此，基于CoM框架的模型可以通过增加链来逐步扩展模型大小，并通过使用不同的链数量提供多个不同大小的子模型进行弹性推理。基于这一原则，作者设计了Chain-of-Language-Model (CoLM)，并进一步引入了KV共享机制的CoLM-Air，以实现更多的扩展功能。实验结果表明，CoLM系列模型在性能上与标准Transformer相当，同时提供了更大的灵活性。",
        "title": "Chain-of-Model Learning for Language Model",
        "pinyin": "Zhè piān wénzhāng tíchū le yīzhǒng xīn de xuéxí fànshì, chēngwéi Chain-of-Model (CoM). Tā jiāng yīnguǒ guānxì yǐnrù měi céng de yǐncáng zhuàngtài, xíngchéng liànshì jiégòu, tīgāo le móxíng xùnliàn de kuòzhǎn xiàolǜ hé bùshǔ de línghuóxìng. Zuòzhě yǐnrù le Chain-of-Representation (CoR) de gàiniàn, jiāng měi céng de yǐncáng zhuàngtài biǎoshì wéi duōgè zǐ biǎoshì (jiē liàn) de zǔhé. Měi céng zhōng, měi gè liàn zhǐnéng chá kàn shūrù biǎoshì zhōng de suǒyǒu qiánxù liàn. Yīncǐ, jīyú CoM kuàngjià de móxíng kěyǐ tōngguò zēngjiā liàn lái zhúbù kuòzhǎn móxíng dàxìng, bìng tōngguò shǐyòng bùtóng de liàn shùliàng tígōng duōgè bùtóng dàxìng de zǐ móxíng jìnxíng tánxìng tuīlǐ. Jīyú zhè yī yuánzé, zuòzhě shèjì le Chain-of-Language-Model (CoLM), bìng jìn yībù yǐnrù le KV gòngxiǎng jīzhì de CoLM-Air, yǐ shíxiàn gèng duō de kuòzhǎn gōngnéng. Shíyàn jiéguǒ biǎomíng, CoLM xìliè móxíng zài xìngnéng shàng yǔ biāozhǔn Transformer xiāngdāng, tóngshí tígōng le gèng dà de línghuóxìng.",
        "vocab": "[\n    {\"word\": \"范式\", \"pinyin\": \"fàn shì\", \"trans\": \"paradigm\"},\n    {\"word\": \"Chain-of-Model\", \"pinyin\": \"Chèin-òf-Módel\", \"trans\": \"Chain-of-Model\"},\n    {\"word\": \"因果关系\", \"pinyin\": \"yīn guǒ guān xì\", \"trans\": \"causal relationship\"},\n    {\"word\": \"隐藏状态\", \"pinyin\": \"yǐn cáng zhuàng tài\", \"trans\": \"hidden state\"},\n    {\"word\": \"链式结构\", \"pinyin\": \"liàn shì jiégòu\", \"trans\": \"chain structure\"},\n    {\"word\": \"扩展效率\", \"pinyin\": \"kuò zhǎn xiào lǜ\", \"trans\": \"scalability\"},\n    {\"word\": \"部署\", \"pinyin\": \"bù shǔ\", \"trans\": \"deployment\"},\n    {\"word\": \"灵活性\", \"pinyin\": \"líng huó xìng\", \"trans\": \"flexibility\"},\n    {\"word\": \"Chain-of-Representation\", \"pinyin\": \"Chèin-òf-Rěprizen téi shēn\", \"trans\": \"Chain-of-Representation\"},\n    {\"word\": \"子表示\", \"pinyin\": \"zǐ biǎo shì\", \"trans\": \"sub-representation\"},\n    {\"word\": \"组合\", \"pinyin\": \"zǔ hé\", \"trans\": \"combination\"},\n    {\"word\": \"前序链\", \"pinyin\": \"qián xù liàn\", \"trans\": \"preceding chain\"},\n    {\"word\": \"弹性推理\", \"pinyin\": \"tán xìng tuī lǐ\", \"trans\": \"elastic inference\"},\n    {\"word\": \"Chain-of-Language-Model\", \"pinyin\": \"Chèin-òf-Lánggù Módel\", \"trans\": \"Chain-of-Language-Model\"},\n    {\"word\": \"KV共享机制\", \"pinyin\": \"KV gòng xiǎng jī zhì\", \"trans\": \"KV sharing mechanism\"},\n    {\"word\": \"CoLM-Air\", \"pinyin\": \"CoLM-Éir\", \"trans\": \"CoLM-Air\"},\n    {\"word\": \"扩展功能\", \"pinyin\": \"kuò zhǎn gōng néng\", \"trans\": \"extended functionality\"},\n    {\"word\": \"Transformer\", \"pinyin\": \"Tèinshèin fōměi\", \"trans\": \"Transformer\"}\n]",
        "trans": "This article proposes a new learning paradigm called Chain-of-Model (CoM). It introduces causality into the hidden states of each layer, forming a chain-like structure that enhances the scalability of model training and the flexibility of deployment. The authors introduce the concept of Chain-of-Representation (CoR), representing the hidden states of each layer as a combination of multiple sub-representations (i.e., chains). Within each layer, each chain can only view all preceding chains in the input representation. Therefore, models based on the CoM framework can incrementally scale the model size by adding chains and provide multiple sub-models of different sizes for elastic inference by using different numbers of chains. Based on this principle, the authors designed Chain-of-Language-Model (CoLM) and further introduced CoLM-Air with a KV sharing mechanism to achieve more scalable functionalities. Experimental results show that the CoLM series models perform comparably to standard Transformers while offering greater flexibility.",
        "update_ts": "2025-05-20 09:13"
    }
}