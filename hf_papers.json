{
    "date": {
        "ru": "4 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
        "en": "March 4",
        "zh": "3æœˆ4æ—¥"
    },
    "time_utc": "2025-03-04 04:13",
    "weekday": 1,
    "issue_id": 2510,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.00784",
            "title": "DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with Dynamic Multi-Sequence Drafting",
            "url": "https://huggingface.co/papers/2503.00784",
            "abstract": "Large language models (LLMs) exhibit exceptional performance across a wide range of tasks; however, their token-by-token autoregressive generation process significantly hinders inference speed. Speculative decoding presents a promising draft-then-verify framework that reduces generation latency while maintaining output distribution fidelity. Nevertheless, the draft model introduces additional computational overhead, becoming a performance bottleneck and increasing the time to first token (TTFT). Previous approaches to mitigate draft model overhead have primarily relied on heuristics and generally failed to match the quality of the draft language models. To address these challenges, we propose DuoDecoding, a novel approach that strategically deploys the draft and target models on the CPU and GPU respectively, enabling parallel decoding while preserving draft quality. Our method incorporates a hardware-aware optimal draft budget to minimize idle times and employs dynamic multi-sequence drafting to enhance draft quality. Extensive experiments across seven tasks show that DuoDecoding achieves up to 2.61x speedup in generation latency, while reducing TTFT to 83% of that in conventional speculative decoding. The Code is available at https://github.com/KaiLv69/DuoDecoding.",
            "score": 5,
            "issue_id": 2510,
            "pub_date": "2025-03-02",
            "pub_date_card": {
                "ru": "2 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
                "en": "March 2",
                "zh": "3æœˆ2æ—¥"
            },
            "hash": "b4870a0e44c3cc55",
            "authors": [
                "Kai Lv",
                "Honglin Guo",
                "Qipeng Guo",
                "Xipeng Qiu"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.00784.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#optimization"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "DuoDecoding: ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ (LLM) Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ DuoDecoding. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° CPU Ğ¸ GPU, Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ¸ Ğ¾Ğ±Ñ‰ÑƒÑ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ. DuoDecoding Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ°Ğ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ğ½Ğ¾-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±ÑĞ´Ğ¶ĞµÑ‚ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ° Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¼ ÑĞ¿ĞµĞºÑƒĞ»ÑÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼."
                },
                "en": {
                    "title": "DuoDecoding: Speeding Up Text Generation with Smart Model Deployment",
                    "desc": "This paper introduces DuoDecoding, a new method to improve the speed of generating text with large language models (LLMs) while keeping the quality high. It uses a draft-then-verify approach, where a draft model quickly generates initial text, and a target model refines it, but does so in a way that reduces the time it takes to start generating text. By using both CPU and GPU for different parts of the process, DuoDecoding allows for faster and more efficient decoding. The results show that this method can significantly speed up text generation without sacrificing quality, achieving a notable improvement in performance across various tasks."
                },
                "zh": {
                    "title": "DuoDecodingï¼šåŠ é€Ÿç”Ÿæˆçš„æ–°æ–¹æ³•",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é€å­—è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹æ˜¾è‘—å½±å“æ¨ç†é€Ÿåº¦ã€‚æ¨æµ‹è§£ç æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è‰ç¨¿-éªŒè¯æ¡†æ¶ï¼Œèƒ½å¤Ÿå‡å°‘ç”Ÿæˆå»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒè¾“å‡ºåˆ†å¸ƒçš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬æå‡ºçš„DuoDecodingæ–¹æ³•é€šè¿‡åœ¨CPUå’ŒGPUä¸Šåˆ†åˆ«éƒ¨ç½²è‰ç¨¿æ¨¡å‹å’Œç›®æ ‡æ¨¡å‹ï¼Œå®ç°äº†å¹¶è¡Œè§£ç ï¼Œæå‡äº†ç”Ÿæˆæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDuoDecodingåœ¨ç”Ÿæˆå»¶è¿Ÿä¸Šå®ç°äº†æœ€é«˜2.61å€çš„åŠ é€Ÿï¼ŒåŒæ—¶å°†é¦–æ¬¡ç”Ÿæˆæ—¶é—´ç¼©çŸ­è‡³ä¼ ç»Ÿæ¨æµ‹è§£ç çš„83%ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-03-03.html",
    "link_next": "2025-03-05.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "03.03",
        "en": "03/03",
        "zh": "3æœˆ3æ—¥"
    },
    "short_date_next": {
        "ru": "05.03",
        "en": "03/05",
        "zh": "3æœˆ5æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è®¾è®¡å¤æ‚å·¥ç¨‹æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆå¯¹äººç±»ç”Ÿäº§æ´»åŠ¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä»¥å‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç ”ç©¶æœªèƒ½å……åˆ†è§£å†³ä¸å¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡ç›¸å…³çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼ŒSolutionBenchï¼Œæ¥è¯„ä¼°ç³»ç»Ÿç”Ÿæˆå®Œæ•´å’Œå¯è¡Œçš„å·¥ç¨‹é—®é¢˜è§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªæ–°ç³»ç»Ÿï¼ŒSolutionRAGï¼Œåˆ©ç”¨åŸºäºæ ‘çš„æ¢ç´¢å’ŒåŒç‚¹æ€ç»´æœºåˆ¶ç”Ÿæˆå¯é çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSolutionRAGåœ¨SolutionBenchä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­å¢å¼ºå¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡è‡ªåŠ¨åŒ–å’Œå¯é æ€§çš„æ½œåŠ›ã€‚",
        "title": "DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking",
        "pinyin": "è®¾è®¡å¤æ‚å·¥ç¨‹æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆå¯¹äººç±»ç”Ÿäº§æ´»åŠ¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä»¥å‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç ”ç©¶æœªèƒ½å……åˆ†è§£å†³ä¸å¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡ç›¸å…³çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼ŒSolutionBenchï¼Œæ¥è¯„ä¼°ç³»ç»Ÿç”Ÿæˆå®Œæ•´å’Œå¯è¡Œçš„å·¥ç¨‹é—®é¢˜è§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªæ–°ç³»ç»Ÿï¼ŒSolutionRAGï¼Œåˆ©ç”¨åŸºäºæ ‘çš„æ¢ç´¢å’ŒåŒç‚¹æ€ç»´æœºåˆ¶ç”Ÿæˆå¯é çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSolutionRAGåœ¨SolutionBenchä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­å¢å¼ºå¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡è‡ªåŠ¨åŒ–å’Œå¯é æ€§çš„æ½œåŠ›ã€‚\n\nShÃ¨jÃ¬ fÃ¹zÃ¡ gÅngchÃ©ng tiÇozhÃ n de jiÄ›juÃ© fÄng'Ã n duÃ¬ rÃ©nlÃ¨i shÄ“ngchÇn huÃ³dÃ²ng zhÃ¬guÄn zhÃ²ngyÃ o. RÃ¡n'Ã©r, yÇqiÃ¡n de jiÇnsuÇ’ zÄ“ngqiÃ¡ng shÄ“ngchÃ©ng (RAG) yÃ¡njiÅ« wÃ¨i nÃ©ng chÃ³ngfÄ“n jiÄ›juÃ© yÇ” fÃ¹zÃ¡ gÅngchÃ©ng jiÄ›juÃ© fÄng'Ã n shÃ¨jÃ¬ xiÄngguÄn de rÃ¨nwÃ¹. WÇ’men yÇnrÃ¹ le yÄ«gÃ¨ xÄ«n de jÄ«zhÇ”n, SolutionBench, lÃ¡i pÃ­nggÅ« xÃ¬tÇ’ng shÄ“ngchÃ©ng wÃ¡nzhÄ›ng hÃ© kÄ›xÃ­ng de gÅngchÃ©ng wÃ¨ntÃ­ jiÄ›juÃ© fÄng'Ã n de nÃ©nglÃ¬. WÇ’men hÃ¡i tÃ­chÅ« le yÄ«gÃ¨ xÄ«n xÃ¬tÇ’ng, SolutionRAG, lÃ¬yÃ²ng jÄ«yÃº shÃ¹ de tÃ nsuÇ’ hÃ© shuÄngdiÇn sÄ«wÃ©i jÄ«zhÃ¬ shÄ“ngchÃ©ng kÄ›kÃ o de jiÄ›juÃ© fÄng'Ã n. ShÃ­yÃ n jiÃ©guÇ’ xiÇnshÃ¬, SolutionRAG zÃ i SolutionBench shÃ ng dÃ¡ dÃ o le zuÃ¬ xiÄnjÃ¬n de xÃ¬ngnÃ©ng, tÅ«xÃ¬ le qÃ­ zÃ i shÃ­jÃ¬ yÃ¬ngyÃ²ng zhÅng zÄ“ngqiÃ¡ng fÃ¹zÃ¡ gÅngchÃ©ng jiÄ›juÃ© fÄng'Ã n shÃ¨jÃ¬ zÃ¬dÃ²nghuÃ  hÃ© kÄ›kÃ oxÃ¬ng de qiÃ¡nlÃ¬.",
        "vocab": "[{'word': 'è®¾è®¡', 'pinyin': 'shÃ¨jÃ¬', 'trans': 'design'},\n{'word': 'å¤æ‚', 'pinyin': 'fÃ¹zÃ¡', 'trans': 'complex'},\n{'word': 'å·¥ç¨‹', 'pinyin': 'gÅngchÃ©ng', 'trans': 'engineering'},\n{'word': 'æŒ‘æˆ˜', 'pinyin': 'tiÇozhÃ n', 'trans': 'challenge'},\n{'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ›juÃ© fÄngÃ n', 'trans': 'solution'},\n{'word': 'è‡³å…³é‡è¦', 'pinyin': 'zhÃ¬guÄn zhÃ²ngyÃ o', 'trans': 'crucial'},\n{'word': 'æ£€ç´¢', 'pinyin': 'jiÇnsuÇ’', 'trans': 'retrieval'},\n{'word': 'å¢å¼º', 'pinyin': 'zÄ“ngqiÃ¡ng', 'trans': 'enhanced'},\n{'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generation'},\n{'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡njiÅ«', 'trans': 'research'},\n{'word': 'æœªèƒ½', 'pinyin': 'wÃ¨inÃ©ng', 'trans': 'failed to'},\n{'word': 'å……åˆ†', 'pinyin': 'chÅngfÃ¨n', 'trans': 'adequately'},\n{'word': 'ç›¸å…³', 'pinyin': 'xiÄngguÄn', 'trans': 'related'},\n{'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨nwÃ¹', 'trans': 'task'},\n{'word': 'å¼•å…¥', 'pinyin': 'yÇnrÃ¹', 'trans': 'introduce'},\n{'word': 'åŸºå‡†', 'pinyin': 'jÄ«zhÇ”n', 'trans': 'benchmark'},\n{'word': 'è¯„ä¼°', 'pinyin': 'pÃ­nggÅ«', 'trans': 'evaluate'},\n{'word': 'ç³»ç»Ÿ', 'pinyin': 'xÃ¬tÇ’ng', 'trans': 'system'},\n{'word': 'å®Œæ•´', 'pinyin': 'wÃ¡nzhÄ›ng', 'trans': 'complete'},\n{'word': 'å¯è¡Œ', 'pinyin': 'kÄ›xÃ­ng', 'trans': 'feasible'},\n{'word': 'å·¥ç¨‹é—®é¢˜', 'pinyin': 'gÅngchÃ©ng wÃ¨ntÃ­', 'trans': 'engineering problem'},\n{'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ›juÃ© fÄngÃ n', 'trans': 'solution'},\n{'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©nglÃ¬', 'trans': 'capability'},\n{'word': 'æå‡º', 'pinyin': 'tÃ­chÅ«', 'trans': 'propose'},\n{'word': 'æ–°ç³»ç»Ÿ', 'pinyin': 'xÄ«n xÃ¬tÇ’ng', 'trans': 'new system'},\n{'word': 'åˆ©ç”¨', 'pinyin': 'lÃ¬yÃ²ng', 'trans': 'utilize'},\n{'word': 'åŸºäº', 'pinyin': 'jÄ«yÃº', 'trans': 'based on'},\n{'word': 'æ ‘', 'pinyin': 'shÃ¹', 'trans': 'tree'},\n{'word': 'æ¢ç´¢', 'pinyin': 'tÃ nsuÇ’', 'trans': 'exploration'},\n{'word': 'åŒç‚¹æ€ç»´', 'pinyin': 'shuÄngdiÇn sÄ«wÃ©i', 'trans': 'dual-point thinking'},\n{'word': 'æœºåˆ¶', 'pinyin': 'jÄ«zhÃ¬', 'trans': 'mechanism'},\n{'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generate'},\n{'word': 'å¯é ', 'pinyin': 'kÄ›kÃ o', 'trans': 'reliable'},\n{'word': 'å®éªŒ', 'pinyin': 'shÃ­yÃ n', 'trans': 'experiment'},\n{'word': 'ç»“æœ', 'pinyin': 'jiÃ©guÇ’', 'trans': 'result'},\n{'word': 'æ˜¾ç¤º', 'pinyin': 'xiÇnshÃ¬', 'trans': 'show'},\n{'word': 'è¾¾åˆ°', 'pinyin': 'dÃ¡dÃ o', 'trans': 'achieve'},\n{'word': 'æœ€å…ˆè¿›', 'pinyin': 'zuÃ¬ xiÄnjÃ¬n', 'trans': 'state-of-the-art'},\n{'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ngnÃ©ng', 'trans': 'performance'},\n{'word': 'çªæ˜¾', 'pinyin': 'tÅ«xiÇn', 'trans': 'highlight'},\n{'word': 'æ½œåŠ›', 'pinyin': 'qiÃ¡nlÃ¬', 'trans': 'potential'},\n{'word': 'å®é™…', 'pinyin': 'shÃ­jÃ¬', 'trans': 'practical'},\n{'word': 'åº”ç”¨', 'pinyin': 'yÃ¬ngyÃ²ng', 'trans': 'application'},\n{'word': 'å¢å¼º', 'pinyin': 'zÄ“ngqiÃ¡ng', 'trans': 'enhance'},\n{'word': 'è‡ªåŠ¨åŒ–', 'pinyin': 'zÃ¬dÃ²nghuÃ ', 'trans': 'automation'}]",
        "trans": "Designing solutions for complex engineering challenges is crucial for human productive activities. However, previous research on Retrieval-Augmented Generation (RAG) has failed to adequately address tasks related to the design of complex engineering solutions. We introduce a new benchmark, SolutionBench, to evaluate the capability of systems to generate complete and feasible engineering problem solutions. We also propose a new system, SolutionRAG, which utilizes tree-based exploration and dual-point thinking mechanisms to generate reliable solutions. Experimental results demonstrate that SolutionRAG achieves state-of-the-art performance on SolutionBench, highlighting its potential to enhance the automation and reliability of complex engineering solution design in practical applications.",
        "update_ts": "2025-03-03 09:12"
    }
}