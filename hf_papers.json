{
    "date": {
        "ru": "9 октября",
        "en": "October 9",
        "zh": "10月9日"
    },
    "time_utc": "2025-10-09 16:15",
    "weekday": 3,
    "issue_id": 6335,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2510.06590",
            "title": "Ming-UniVision: Joint Image Understanding and Generation with a Unified\n  Continuous Tokenizer",
            "url": "https://huggingface.co/papers/2510.06590",
            "abstract": "MingTok, a continuous latent space visual tokenizer, unifies vision-language understanding and generation within an autoregressive framework, achieving state-of-the-art performance across both domains.  \t\t\t\t\tAI-generated summary \t\t\t\t Visual tokenization remains a core challenge in unifying visual understanding and generation within the autoregressive paradigm. Existing methods typically employ tokenizers in discrete latent spaces to align with the tokens from large language models, where the quantization errors can limit semantic expressiveness and degrade the capability of vision-language understanding. To address this, we introduce MingTok, a new family of visual tokenizers with a continuous latent space, for unified autoregressive generation and understanding. While understanding tasks favor discriminative high-dimensional features, generation tasks prefer compact low-level codes. Thus, to reconcile these competing demands, MingTok adopts a three-stage sequential architecture involving low-level encoding, semantic expansion, and visual reconstruction. Built on top of it, Ming-UniVision eliminates the need for task-specific visual representations, and unifies diverse vision-language tasks under a single autoregrsssive prediction paradigm. By formulating both understanding and generation as next-token prediction in a shared continuous space, it seamlessly supports multi-round, in-context tasks such as iterative understanding, generation and editing. Empirically, we find that using a unified continuous visual representation reconciles the competing requirements on the tokenizers by the understanding and generation tasks, thereby leading to state-of-the-art level performance across both domains. We hope our findings will facilitate unified visual tokenization in the continuous domain. Inference code and model weights are released to benefit community.",
            "score": 54,
            "issue_id": 6328,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "c05ff2a1615b401f",
            "authors": [
                "Ziyuan Huang",
                "DanDan Zheng",
                "Cheng Zou",
                "Rui Liu",
                "Xiaolong Wang",
                "Kaixiang Ji",
                "Weilong Chai",
                "Jianxin Sun",
                "Libin Wang",
                "Yongjie Lv",
                "Taozhi Huang",
                "Jiajia Liu",
                "Qingpei Guo",
                "Ming Yang",
                "Jingdong Chen",
                "Jun Zhou"
            ],
            "affiliations": [
                "Ant Group",
                "Inclusion AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06590.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#multimodal",
                    "#optimization",
                    "#cv",
                    "#architecture",
                    "#open_source"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "MingTok: революция в визуальной токенизации",
                    "desc": "MingTok — это новый подход к визуальной токенизации, который использует непрерывное латентное пространство для объединения задач понимания и генерации изображений в рамках авторегрессионной модели. В отличие от существующих методов, которые работают с дискретными токенами и могут терять семантическую выразительность, MingTok предлагает трёхэтапную архитектуру для более точного представления визуальных данных. Это позволяет эффективно решать задачи как понимания, так и генерации, используя единое пространство токенов. В результате, MingTok достигает передовых результатов в обеих областях и упрощает работу с различными задачами, связанными с визуальными данными."
                },
                "en": {
                    "title": "MingTok: Unifying Vision and Language with Continuous Tokenization",
                    "desc": "MingTok is a new visual tokenizer that uses a continuous latent space to improve how machines understand and generate images and text together. Traditional methods use discrete tokenizers, which can create errors that limit how well machines can understand visual information. MingTok introduces a three-stage process that first encodes low-level features, then expands them semantically, and finally reconstructs the visuals, allowing for better performance in both understanding and generating tasks. This approach enables a unified framework for various vision-language tasks, achieving state-of-the-art results by treating both understanding and generation as next-token predictions in a shared space."
                },
                "zh": {
                    "title": "MingTok：统一视觉理解与生成的创新标记器",
                    "desc": "MingTok是一种连续潜在空间的视觉标记器，旨在统一视觉理解和生成。它通过自回归框架实现了在这两个领域的最先进性能。MingTok采用三阶段的架构，分别进行低级编码、语义扩展和视觉重建，以满足理解和生成任务的不同需求。通过在共享的连续空间中将理解和生成任务都视为下一个标记预测，MingTok支持多轮上下文任务，如迭代理解、生成和编辑。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.03215",
            "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
            "url": "https://huggingface.co/papers/2510.03215",
            "abstract": "Cache-to-Cache (C2C) enables direct semantic communication between LLMs using neural network projections, improving accuracy and reducing latency compared to text-based communication.  \t\t\t\t\tAI-generated summary \t\t\t\t Multi-LLM systems harness the complementary strengths of diverse Large Language Models, achieving performance and efficiency gains unattainable by a single model. In existing designs, LLMs communicate through text, forcing internal representations to be transformed into output token sequences. This process both loses rich semantic information and incurs token-by-token generation latency. Motivated by these limitations, we ask: Can LLMs communicate beyond text? Oracle experiments show that enriching the KV-Cache semantics can improve response quality without increasing cache size, supporting KV-Cache as an effective medium for inter-model communication. Thus, we propose Cache-to-Cache (C2C), a new paradigm for direct semantic communication between LLMs. C2C uses a neural network to project and fuse the source model's KV-cache with that of the target model to enable direct semantic transfer. A learnable gating mechanism selects the target layers that benefit from cache communication. Compared with text communication, C2C utilizes the deep, specialized semantics from both models, while avoiding explicit intermediate text generation. Experiments show that C2C achieves 8.5-10.5% higher average accuracy than individual models. It further outperforms the text communication paradigm by approximately 3.0-5.0%, while delivering an average 2.0x speedup in latency. Our code is available at https://github.com/thu-nics/C2C.",
            "score": 53,
            "issue_id": 6321,
            "pub_date": "2025-10-03",
            "pub_date_card": {
                "ru": "3 октября",
                "en": "October 3",
                "zh": "10月3日"
            },
            "hash": "3453eb2a78f90630",
            "authors": [
                "Tianyu Fu",
                "Zihan Min",
                "Hanling Zhang",
                "Jichao Yan",
                "Guohao Dai",
                "Wanli Ouyang",
                "Yu Wang"
            ],
            "affiliations": [
                "Infinigence AI",
                "Shanghai AI Laboratory",
                "Shanghai Jiao Tong University",
                "The Chinese University of Hong Kong",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.03215.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#multimodal",
                    "#optimization",
                    "#agi"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Общение LLM без слов: прямая передача семантики через кэш",
                    "desc": "Статья предлагает новый подход Cache-to-Cache (C2C) для коммуникации между несколькими LLM, который позволяет моделям обмениваться информацией напрямую через KV-Cache вместо текста. Специальная нейронная сеть проецирует и объединяет кэши разных моделей, сохраняя богатую семантическую информацию, которая теряется при генерации текста. Метод показывает улучшение точности на 8.5-10.5% по сравнению с отдельными моделями и на 3.0-5.0% по сравнению с текстовой коммуникацией. При этом C2C обеспечивает двукратное ускорение благодаря отсутствию необходимости генерировать промежуточный текст токен за токеном."
                },
                "en": {
                    "title": "Direct Semantic Communication for Enhanced LLM Collaboration",
                    "desc": "Cache-to-Cache (C2C) introduces a novel method for Large Language Models (LLMs) to communicate directly using their internal KV-caches instead of relying on text. This approach enhances the semantic richness of the communication, allowing models to share information more effectively and efficiently. By employing a neural network to project and merge the KV-caches, C2C minimizes the loss of information and reduces latency associated with text-based exchanges. Experimental results demonstrate that C2C improves accuracy by 8.5-10.5% and speeds up communication by approximately 2.0x compared to traditional methods."
                },
                "zh": {
                    "title": "直接语义通信，提升模型效率",
                    "desc": "Cache-to-Cache (C2C) 是一种新方法，允许大型语言模型（LLMs）之间直接进行语义通信。通过神经网络投影，C2C 可以提高准确性并减少延迟，避免了传统文本通信中信息损失和逐字生成的延迟。该方法通过融合源模型和目标模型的KV缓存，直接传递语义信息，从而实现更高效的模型间交流。实验结果表明，C2C 在准确性和速度上均优于传统的文本通信方式。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06308",
            "title": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal\n  Generation and Understanding",
            "url": "https://huggingface.co/papers/2510.06308",
            "abstract": "Lumina-DiMOO, an open-source foundational model, uses fully discrete diffusion modeling for efficient multi-modal generation and understanding, outperforming existing models.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Lumina-DiMOO, an open-source foundational model for seamless multi-modal generation and understanding. Lumina-DiMOO sets itself apart from prior unified models by utilizing a fully discrete diffusion modeling to handle inputs and outputs across various modalities. This innovative approach allows Lumina-DiMOO to achieve higher sampling efficiency compared to previous autoregressive (AR) or hybrid AR-Diffusion paradigms and adeptly support a broad spectrum of multi-modal tasks, including text-to-image generation, image-to-image generation (e.g., image editing, subject-driven generation, and image inpainting, etc.), as well as image understanding. Lumina-DiMOO achieves state-of-the-art performance on multiple benchmarks, surpassing existing open-source unified multi-modal models. To foster further advancements in multi-modal and discrete diffusion model research, we release our code and checkpoints to the community. Project Page: https://synbol.github.io/Lumina-DiMOO.",
            "score": 35,
            "issue_id": 6322,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "7ea946e09493c01b",
            "authors": [
                "Yi Xin",
                "Qi Qin",
                "Siqi Luo",
                "Kaiwen Zhu",
                "Juncheng Yan",
                "Yan Tai",
                "Jiayi Lei",
                "Yuewen Cao",
                "Keqi Wang",
                "Yibin Wang",
                "Jinbin Bai",
                "Qian Yu",
                "Dengyang Jiang",
                "Yuandong Pu",
                "Haoxing Chen",
                "Le Zhuo",
                "Junjun He",
                "Gen Luo",
                "Tianbin Li",
                "Ming Hu",
                "Jin Ye",
                "Shenglong Ye",
                "Bo Zhang",
                "Chang Xu",
                "Wenhai Wang",
                "Hongsheng Li",
                "Guangtao Zhai",
                "Tianfan Xue",
                "Bin Fu",
                "Xiaohong Liu",
                "Yu Qiao",
                "Yihao Liu"
            ],
            "affiliations": [
                "Nanjing University",
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "Shanghai Jiao Tong University",
                "The Chinese University of Hong Kong",
                "The University of Sydney",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06308.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#multimodal",
                    "#benchmark",
                    "#diffusion",
                    "#architecture"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "Дискретная диффузия для универсальной мультимодальности",
                    "desc": "Lumina-DiMOO - это открытая foundational модель для мультимодальной генерации и понимания контента. В отличие от предыдущих unified моделей, она использует полностью дискретное диффузионное моделирование для работы с различными модальностями. Этот подход обеспечивает более высокую эффективность сэмплирования по сравнению с autoregressive методами и поддерживает широкий спектр задач: генерацию изображений по тексту, редактирование изображений и их понимание. Модель демонстрирует state-of-the-art результаты на множестве бенчмарков, превосходя существующие открытые мультимодальные модели."
                },
                "en": {
                    "title": "Revolutionizing Multi-Modal Generation with Lumina-DiMOO",
                    "desc": "Lumina-DiMOO is an open-source foundational model designed for efficient multi-modal generation and understanding. It employs fully discrete diffusion modeling, which distinguishes it from traditional autoregressive and hybrid models. This innovative technique enhances sampling efficiency and supports a wide range of tasks, such as text-to-image generation and image editing. By achieving state-of-the-art results on various benchmarks, Lumina-DiMOO aims to advance research in multi-modal and discrete diffusion models."
                },
                "zh": {
                    "title": "Lumina-DiMOO：高效的多模态生成与理解模型",
                    "desc": "Lumina-DiMOO是一个开源的基础模型，采用完全离散的扩散建模方法，能够高效地进行多模态生成和理解。与之前的统一模型相比，它在处理不同模态的输入和输出时表现出色。该模型在文本到图像生成、图像编辑等多种多模态任务中展现了更高的采样效率，并在多个基准测试中达到了最先进的性能。为了推动多模态和离散扩散模型的研究进展，我们将代码和检查点发布给社区。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06917",
            "title": "SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models",
            "url": "https://huggingface.co/papers/2510.06917",
            "abstract": "SHANKS, a general inference framework, enables spoken language models to generate unspoken reasoning while listening to user input, enhancing real-time interaction and task completion.  \t\t\t\t\tAI-generated summary \t\t\t\t Current large language models (LLMs) and spoken language models (SLMs) begin thinking and taking actions only after the user has finished their turn. This prevents the model from interacting during the user's turn and can lead to high response latency while it waits to think. Consequently, thinking after receiving the full input is not suitable for speech-to-speech interaction, where real-time, low-latency exchange is important. We address this by noting that humans naturally \"think while listening.\" In this paper, we propose SHANKS, a general inference framework that enables SLMs to generate unspoken chain-of-thought reasoning while listening to the user input. SHANKS streams the input speech in fixed-duration chunks and, as soon as a chunk is received, generates unspoken reasoning based on all previous speech and reasoning, while the user continues speaking. SHANKS uses this unspoken reasoning to decide whether to interrupt the user and to make tool calls to complete the task. We demonstrate that SHANKS enhances real-time user-SLM interaction in two scenarios: (1) when the user is presenting a step-by-step solution to a math problem, SHANKS can listen, reason, and interrupt when the user makes a mistake, achieving 37.1% higher interruption accuracy than a baseline that interrupts without thinking; and (2) in a tool-augmented dialogue, SHANKS can complete 56.9% of the tool calls before the user finishes their turn. Overall, SHANKS moves toward models that keep thinking throughout the conversation, not only after a turn ends. Animated illustrations of Shanks can be found at https://d223302.github.io/SHANKS/",
            "score": 29,
            "issue_id": 6321,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "8587217f59423924",
            "authors": [
                "Cheng-Han Chiang",
                "Xiaofei Wang",
                "Linjie Li",
                "Chung-Ching Lin",
                "Kevin Lin",
                "Shujie Liu",
                "Zhendong Wang",
                "Zhengyuan Yang",
                "Hung-yi Lee",
                "Lijuan Wang"
            ],
            "affiliations": [
                "Microsoft",
                "National Taiwan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06917.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#reasoning",
                    "#inference",
                    "#long_context"
                ],
                "emoji": "🎧",
                "ru": {
                    "title": "Думай пока слушаешь: рассуждения в реальном времени для разговорных моделей",
                    "desc": "В статье представлен SHANKS — фреймворк для spoken language models (SLM), который позволяет моделям генерировать невысказанные цепочки рассуждений (chain-of-thought) во время прослушивания речи пользователя, а не после завершения его реплики. Система обрабатывает входной аудиопоток фиксированными чанками и на основе предыдущих рассуждений принимает решения о прерывании пользователя или выполнении вызовов инструментов в реальном времени. Эксперименты показали, что SHANKS достигает на 37.1% более высокой точности прерывания при обнаружении ошибок в математических решениях и завершает 56.9% вызовов инструментов до окончания речи пользователя. Подход приближает AI-модели к естественному человеческому поведению — способности думать во время слушания, что критично важно для низколатентного речевого взаимодействия."
                },
                "en": {
                    "title": "SHANKS: Real-Time Reasoning for Smarter Conversations",
                    "desc": "The paper introduces SHANKS, a novel inference framework designed for spoken language models (SLMs) that allows them to engage in unspoken reasoning while listening to user input. This approach addresses the limitation of current large language models, which only process information after the user has finished speaking, leading to delays in interaction. By streaming input in chunks, SHANKS enables real-time reasoning and decision-making, allowing the model to interrupt users when necessary and complete tasks more efficiently. The results show significant improvements in interruption accuracy and tool call completion, demonstrating the potential for more dynamic and responsive conversational AI."
                },
                "zh": {
                    "title": "实时思考，提升交互效率",
                    "desc": "SHANKS是一个通用推理框架，旨在提升语音语言模型在用户输入时的实时交互能力。它允许模型在用户说话时生成未说出的推理，从而减少响应延迟。SHANKS通过将输入语音分成固定时长的块进行处理，能够在接收每个块时进行推理。实验表明，SHANKS在用户解决数学问题时能够更准确地中断用户，并在对话中提前完成工具调用，显著提高了交互效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06710",
            "title": "RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training",
            "url": "https://huggingface.co/papers/2510.06710",
            "abstract": "RLinf-VLA is a unified framework for scalable reinforcement learning training of vision-language-action models, offering improved performance and generalization compared to supervised fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent progress in vision and language foundation models has significantly advanced multimodal understanding, reasoning, and generation, inspiring a surge of interest in extending such capabilities to embodied settings through vision-language-action (VLA) models. Yet, most VLA models are still trained with supervised fine-tuning (SFT), which struggles to generalize under distribution shifts due to error accumulation. Reinforcement learning (RL) offers a promising alternative by directly optimizing task performance through interaction, but existing attempts remain fragmented and lack a unified platform for fair and systematic comparison across model architectures and algorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and efficient framework for scalable RL training of VLA models. The system adopts a highly flexible resource allocation design that addresses the challenge of integrating rendering, training, and inference in RL+VLA training. In particular, for GPU-parallelized simulators, RLinf-VLA implements a novel hybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup in training. Through a unified interface, RLinf-VLA seamlessly supports diverse VLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g., PPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a unified model achieves 98.11\\% across 130 LIBERO tasks and 97.66\\% across 25 ManiSkill tasks. Beyond empirical performance, our study distills a set of best practices for applying RL to VLA training and sheds light on emerging patterns in this integration. Furthermore, we present preliminary deployment on a real-world Franka robot, where RL-trained policies exhibit stronger generalization than those trained with SFT. We envision RLinf-VLA as a foundation to accelerate and standardize research on embodied intelligence.",
            "score": 27,
            "issue_id": 6327,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "61d9506100fc9423",
            "authors": [
                "Hongzhi Zang",
                "Mingjie Wei",
                "Si Xu",
                "Yongji Wu",
                "Zhen Guo",
                "Yuanqing Wang",
                "Hao Lin",
                "Liangzhi Shi",
                "Yuqing Xie",
                "Zhexuan Xu",
                "Zhihao Liu",
                "Kang Chen",
                "Wenhao Tang",
                "Quanlu Zhang",
                "Weinan Zhang",
                "Chao Yu",
                "Yu Wang"
            ],
            "affiliations": [
                "Harbin Institute of Technology",
                "Infinigence AI",
                "Institute of Automation, Chinese Academy of Sciences",
                "Peking University",
                "Tsinghua University",
                "UC Berkeley",
                "Zhongguancun Academy"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06710.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#multimodal",
                    "#training",
                    "#reasoning",
                    "#optimization",
                    "#rl",
                    "#robotics"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Обучение роботов через взаимодействие: RL побеждает классический supervised learning",
                    "desc": "RLinf-VLA — это унифицированный фреймворк для масштабного обучения vision-language-action моделей с помощью reinforcement learning. В отличие от традиционного supervised fine-tuning, который плохо справляется со сдвигами в распределении данных, RL напрямую оптимизирует качество выполнения задач через взаимодействие со средой. Система поддерживает различные архитектуры VLA-моделей, алгоритмы RL (PPO, GRPO) и симуляторы, достигая точности 98.11% на 130 задачах LIBERO и 97.66% на 25 задачах ManiSkill. Эксперименты на реальном роботе Franka показали, что политики, обученные с помощью RL, демонстрируют лучшую генерализацию по сравнению с supervised fine-tuning."
                },
                "en": {
                    "title": "Reinforcement Learning Revolutionizes Vision-Language-Action Training",
                    "desc": "RLinf-VLA is a new framework designed to enhance the training of vision-language-action (VLA) models using reinforcement learning (RL). Unlike traditional supervised fine-tuning, which can struggle with generalization, RLinf-VLA optimizes model performance through direct interaction with tasks. The framework supports various VLA architectures and RL algorithms, allowing for efficient training and faster processing times. Initial results show that models trained with RLinf-VLA outperform those trained with supervised methods, demonstrating better adaptability in real-world applications."
                },
                "zh": {
                    "title": "RLinf-VLA：加速视觉-语言-动作模型的强化学习训练",
                    "desc": "RLinf-VLA是一个统一的框架，用于可扩展的强化学习训练视觉-语言-动作模型，相比于监督微调，它提供了更好的性能和泛化能力。该框架解决了在RL+VLA训练中整合渲染、训练和推理的挑战，并通过灵活的资源分配设计实现了高效的训练。RLinf-VLA支持多种VLA架构和强化学习算法，并在多个模拟任务中表现出色。我们的研究还总结了一系列最佳实践，帮助将强化学习应用于VLA训练，并展示了在真实机器人上的初步部署效果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07310",
            "title": "MATRIX: Mask Track Alignment for Interaction-aware Video Generation",
            "url": "https://huggingface.co/papers/2510.07310",
            "abstract": "MATRIX-11K dataset and MATRIX regularization enhance interaction fidelity and semantic alignment in video DiTs by aligning attention with multi-instance mask tracks.  \t\t\t\t\tAI-generated summary \t\t\t\t Video DiTs have advanced video generation, yet they still struggle to model multi-instance or subject-object interactions. This raises a key question: How do these models internally represent interactions? To answer this, we curate MATRIX-11K, a video dataset with interaction-aware captions and multi-instance mask tracks. Using this dataset, we conduct a systematic analysis that formalizes two perspectives of video DiTs: semantic grounding, via video-to-text attention, which evaluates whether noun and verb tokens capture instances and their relations; and semantic propagation, via video-to-video attention, which assesses whether instance bindings persist across frames. We find both effects concentrate in a small subset of interaction-dominant layers. Motivated by this, we introduce MATRIX, a simple and effective regularization that aligns attention in specific layers of video DiTs with multi-instance mask tracks from the MATRIX-11K dataset, enhancing both grounding and propagation. We further propose InterGenEval, an evaluation protocol for interaction-aware video generation. In experiments, MATRIX improves both interaction fidelity and semantic alignment while reducing drift and hallucination. Extensive ablations validate our design choices. Codes and weights will be released.",
            "score": 26,
            "issue_id": 6321,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "1dfefa942d4dfe75",
            "authors": [
                "Siyoon Jin",
                "Seongchan Kim",
                "Dahyun Chung",
                "Jaeho Lee",
                "Hyunwook Choi",
                "Jisu Nam",
                "Jiyoung Kim",
                "Seungryong Kim"
            ],
            "affiliations": [
                "KAIST AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07310.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#hallucinations",
                    "#benchmark",
                    "#video",
                    "#interpretability"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "Улучшение взаимодействий в видео через выравнивание внимания по маскам объектов",
                    "desc": "Исследователи создали датасет MATRIX-11K с видео, содержащими описания взаимодействий и треки масок нескольких объектов. Они проанализировали, как video DiT модели представляют взаимодействия между объектами, изучив semantic grounding (связь токенов с объектами) и semantic propagation (сохранение связей между кадрами). Оказалось, что эти эффекты концентрируются в небольшом числе специфичных слоёв модели. На основе этого была предложена регуляризация MATRIX, которая выравнивает attention механизм с масками объектов, что улучшает точность взаимодействий и уменьшает hallucination в генерируемом видео."
                },
                "en": {
                    "title": "Enhancing Video Generation with MATRIX Regularization",
                    "desc": "This paper introduces the MATRIX-11K dataset, which includes interaction-aware captions and multi-instance mask tracks to improve video generation models known as video DiTs. The authors analyze how these models represent interactions through two main perspectives: semantic grounding and semantic propagation, focusing on how well they capture and maintain relationships between objects over time. They propose a new regularization technique called MATRIX that aligns the attention mechanisms in specific layers of video DiTs with the multi-instance mask tracks from their dataset. The results show that MATRIX enhances interaction fidelity and semantic alignment, leading to better video generation outcomes while minimizing issues like drift and hallucination."
                },
                "zh": {
                    "title": "提升视频生成模型的交互保真度与语义对齐",
                    "desc": "本论文介绍了MATRIX-11K数据集和MATRIX正则化如何提高视频生成模型（DiTs）在交互保真度和语义对齐方面的表现。研究发现，视频生成模型在处理多实例或主体-对象交互时存在困难，因此我们创建了一个包含交互意识字幕和多实例掩码轨迹的数据集。通过系统分析，我们提出了语义基础和语义传播两个视角，评估模型在视频到文本和视频到视频的注意力机制。最终，MATRIX正则化通过对齐特定层的注意力与多实例掩码轨迹，显著提升了模型的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07315",
            "title": "Vibe Checker: Aligning Code Evaluation with Human Preference",
            "url": "https://huggingface.co/papers/2510.07315",
            "abstract": "Vibe Checker evaluates LLMs by combining functional correctness and instruction following to better align with human coding preferences.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have catalyzed vibe coding, where users leverage LLMs to generate and iteratively refine code through natural language interactions until it passes their vibe check. Vibe check is tied to real-world human preference and goes beyond functionality: the solution should feel right, read cleanly, preserve intent, and remain correct. However, current code evaluation remains anchored to pass@k and captures only functional correctness, overlooking the non-functional instructions that users routinely apply. In this paper, we hypothesize that instruction following is the missing piece underlying vibe check that represents human preference in coding besides functional correctness. To quantify models' code instruction following capabilities with measurable signals, we present VeriCode, a taxonomy of 30 verifiable code instructions together with corresponding deterministic verifiers. We use the taxonomy to augment established evaluation suites, resulting in Vibe Checker, a testbed to assess both code instruction following and functional correctness. Upon evaluating 31 leading LLMs, we show that even the strongest models struggle to comply with multiple instructions and exhibit clear functional regression. Most importantly, a composite score of functional correctness and instruction following correlates the best with human preference, with the latter emerging as the primary differentiator on real-world programming tasks. Our work identifies core factors of the vibe check, providing a concrete path for benchmarking and developing models that better align with user preferences in coding.",
            "score": 25,
            "issue_id": 6321,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "664f235019a59971",
            "authors": [
                "Ming Zhong",
                "Xiang Zhou",
                "Ting-Yun Chang",
                "Qingze Wang",
                "Nan Xu",
                "Xiance Si",
                "Dan Garrette",
                "Shyam Upadhyay",
                "Jeremiah Liu",
                "Jiawei Han",
                "Benoit Schillings",
                "Jiao Sun"
            ],
            "affiliations": [
                "Google",
                "Google DeepMind",
                "University of Illinois Urbana-Champaign (UIUC)",
                "University of Southern California (USC)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07315.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#alignment",
                    "#training",
                    "#benchmark",
                    "#plp"
                ],
                "emoji": "✨",
                "ru": {
                    "title": "Vibe Check: когда код должен не только работать, но и нравиться",
                    "desc": "Исследователи представили Vibe Checker — новый подход к оценке LLM для генерации кода, который учитывает не только функциональную корректность, но и следование инструкциям. Они создали VeriCode — таксономию из 30 проверяемых инструкций для кода с автоматическими верификаторами, чтобы измерить способность моделей следовать требованиям пользователя. Тестирование 31 ведущей LLM показало, что даже лучшие модели испытывают трудности с выполнением множественных инструкций, причём именно следование инструкциям оказалось главным фактором, отличающим предпочтения пользователей. Работа показывает, что человеческие предпочтения в программировании определяются комбинацией корректности и того, насколько код «ощущается правильным» — читается чисто и сохраняет изначальный замысел."
                },
                "en": {
                    "title": "Aligning AI with Human Coding Preferences",
                    "desc": "This paper introduces Vibe Checker, a new method for evaluating Large Language Models (LLMs) that combines functional correctness with instruction following to align better with human coding preferences. It highlights the importance of not just passing functional tests but also ensuring that code feels right and meets user expectations. The authors present VeriCode, a taxonomy of 30 verifiable code instructions, to measure how well models follow these instructions. Their findings show that a composite score of functional correctness and instruction following is a better predictor of human preference in coding tasks, revealing that instruction following is crucial for improving LLM performance in real-world applications."
                },
                "zh": {
                    "title": "Vibe Checker：更贴近人类编码偏好的评估方法",
                    "desc": "本文提出了一种名为Vibe Checker的评估方法，用于评估大型语言模型（LLMs）在代码生成中的表现。Vibe Checker结合了功能正确性和指令遵循，旨在更好地符合人类的编码偏好。我们引入了VeriCode，一个包含30个可验证代码指令的分类法，以量化模型的指令遵循能力。研究表明，功能正确性和指令遵循的综合得分与人类偏好高度相关，后者在实际编程任务中成为主要的区分因素。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04678",
            "title": "Multi-Agent Tool-Integrated Policy Optimization",
            "url": "https://huggingface.co/papers/2510.04678",
            "abstract": "MATPO, a reinforcement learning method, optimizes tool-integrated multi-agent roles within a single LLM, improving performance and robustness over single-agent systems.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) increasingly rely on multi-turn tool-integrated planning for knowledge-intensive and complex reasoning tasks. Existing implementations typically rely on a single agent, but they suffer from limited context length and noisy tool responses. A natural solution is to adopt a multi-agent framework with planner- and worker-agents to manage context. However, no existing methods support effective reinforcement learning post-training of tool-integrated multi-agent frameworks. To address this gap, we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which enables distinct roles (planner and worker) to be trained within a single LLM instance using role-specific prompts via reinforcement learning. MATPO is derived from a principled credit assignment mechanism across planner and worker rollouts. This design eliminates the need to deploy multiple LLMs, which would be memory-intensive, while preserving the benefits of specialization. Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently outperforms single-agent baselines by an average of 18.38% relative improvement in performance and exhibits greater robustness to noisy tool outputs. Our findings highlight the effectiveness of unifying multiple agent roles within a single LLM and provide practical insights for stable and efficient multi-agent RL training.",
            "score": 16,
            "issue_id": 6321,
            "pub_date": "2025-10-06",
            "pub_date_card": {
                "ru": "6 октября",
                "en": "October 6",
                "zh": "10月6日"
            },
            "hash": "a8d8251d93e429c4",
            "authors": [
                "Zhanfeng Mo",
                "Xingxuan Li",
                "Yuntao Chen",
                "Lidong Bing"
            ],
            "affiliations": [
                "MiroMind AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04678.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#optimization",
                    "#agents",
                    "#rl"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "Один LLM в роли целой команды агентов",
                    "desc": "Исследователи представили MATPO — метод обучения с подкреплением для оптимизации мультиагентных систем внутри одной языковой модели. Традиционные подходы используют либо одного агента с ограниченным контекстом, либо несколько отдельных LLM, что требует много памяти. MATPO позволяет одной модели играть разные роли (планировщик и исполнитель) через специальные промпты, используя механизм распределения наград между ролями. Эксперименты показали улучшение производительности на 18,38% по сравнению с одноагентными системами и большую устойчивость к шуму в ответах инструментов."
                },
                "en": {
                    "title": "Optimizing Multi-Agent Roles in LLMs for Enhanced Performance",
                    "desc": "MATPO is a novel reinforcement learning approach that enhances the performance of large language models (LLMs) by integrating multiple agent roles within a single model. It introduces a planner-worker framework, where the planner strategizes and the worker executes tasks, allowing for better management of context and tool responses. This method leverages a credit assignment mechanism to optimize the training of these roles, avoiding the need for multiple LLMs and thus saving memory. Experimental results demonstrate that MATPO significantly improves performance and robustness compared to traditional single-agent systems, making it a promising solution for complex reasoning tasks."
                },
                "zh": {
                    "title": "多代理工具集成优化，提升LLM性能与鲁棒性",
                    "desc": "MATPO是一种强化学习方法，旨在优化单个大型语言模型（LLM）中的多代理角色，提升其性能和鲁棒性。该方法通过角色特定的提示，允许规划者和工作者在同一LLM实例中进行训练，解决了现有单代理系统在上下文长度和工具响应噪声方面的局限。MATPO采用了一种原则性的信用分配机制，避免了部署多个LLM所需的高内存消耗，同时保留了专业化的优势。实验结果表明，MATPO在多个任务上相较于单代理基线平均提高了18.38%的性能，并对噪声工具输出表现出更强的鲁棒性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04204",
            "title": "CALM Before the STORM: Unlocking Native Reasoning for Optimization\n  Modeling",
            "url": "https://huggingface.co/papers/2510.04204",
            "abstract": "CALM framework uses expert interventions to refine LRM reasoning for optimization tasks, achieving high accuracy with fewer modifications compared to traditional methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs -- In particular, we show that direct fine-tuning on traditional non-reflective datasets leads to limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose CALM (Corrective Adaptation with Lightweight Modification), a framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6\\% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop STORM (Smart Thinking Optimization Reasoning Model), a 4B-parameter LRM that achieves a new state-of-the-art average accuracy of 68.9\\% across five popular optimization modeling benchmarks, matching the performance of a 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering a more effective and scalable path towards expert-level performance on challenging optimization modeling tasks.",
            "score": 16,
            "issue_id": 6332,
            "pub_date": "2025-10-05",
            "pub_date_card": {
                "ru": "5 октября",
                "en": "October 5",
                "zh": "10月5日"
            },
            "hash": "b7f79f325ea1e236",
            "authors": [
                "Zhengyang Tang",
                "Zihan Ye",
                "Chenyu Huang",
                "Xuhan Huang",
                "Chengpeng Li",
                "Sihang Li",
                "Guanhua Chen",
                "Ming Yan",
                "Zizhuo Wang",
                "Hongyuan Zha",
                "Dayiheng Liu",
                "Benyou Wang"
            ],
            "affiliations": [
                "Qwen Team, Alibaba Inc.",
                "Shanghai University of Finance and Economics",
                "Shenzhen Loop Area Institute (SLAI)",
                "Southern University of Science and Technology",
                "The Chinese University of Hong Kong, Shenzhen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04204.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#dataset",
                    "#optimization",
                    "#training",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Точечные коррекции вместо тотального файн-тюнинга",
                    "desc": "Статья представляет CALM — фреймворк для адаптации больших reasoning-моделей (LRM) к задачам оптимизационного моделирования. Вместо традиционного файн-тюнинга авторы используют экспертные подсказки, которые корректируют менее 2.6% сгенерированных токенов, сохраняя естественные паттерны рассуждений модели. На основе CALM создана модель STORM с 4 миллиардами параметров, которая достигает точности 68.9% на бенчмарках по оптимизации, сравнявшись с моделью в 671 миллиард параметров. Подход демонстрирует, что целенаправленная коррекция рассуждений эффективнее массового дообучения для сложных задач оптимизации."
                },
                "en": {
                    "title": "Refining Reasoning with Expert Hints for Optimization Success",
                    "desc": "The CALM framework enhances Large Reasoning Models (LRMs) by using expert interventions to correct reasoning errors during optimization tasks. It allows LRMs to maintain their advanced reasoning capabilities while making minimal modifications to their outputs. By incorporating concise corrective hints from experts, CALM enables the model to generate high-quality data for further training through supervised fine-tuning. This approach leads to significant improvements in accuracy, demonstrating a more effective method for adapting LRMs to complex optimization challenges."
                },
                "zh": {
                    "title": "CALM框架：优化推理的智能干预",
                    "desc": "CALM框架通过专家干预来优化大型推理模型（LRM）的推理过程，从而在优化任务中实现高准确率。与传统方法相比，CALM在修改方面的需求更少，能够更好地利用LRM的推理能力。该框架通过识别推理缺陷并提供简洁的纠正提示，帮助LRM生成更优质的推理轨迹。最终，基于CALM的STORM模型在多个优化建模基准测试中达到了新的最高平均准确率，展示了动态提示数据合成的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04212",
            "title": "Why Low-Precision Transformer Training Fails: An Analysis on Flash\n  Attention",
            "url": "https://huggingface.co/papers/2510.04212",
            "abstract": "Low-precision training of transformer models with flash attention suffers from catastrophic loss explosions due to low-rank representations and biased rounding errors, which are addressed by a minimal modification to the flash attention mechanism.  \t\t\t\t\tAI-generated summary \t\t\t\t The pursuit of computational efficiency has driven the adoption of low-precision formats for training transformer models. However, this progress is often hindered by notorious training instabilities. This paper provides the first mechanistic explanation for a long-standing and unresolved failure case where training with flash attention in low-precision settings leads to catastrophic loss explosions. Our in-depth analysis reveals that the failure is not a random artifact but caused by two intertwined phenomena: the emergence of similar low-rank representations within the attention mechanism and the compounding effect of biased rounding errors inherent in low-precision arithmetic. We demonstrate how these factors create a vicious cycle of error accumulation that corrupts weight updates, ultimately derailing the training dynamics. To validate our findings, we introduce a minimal modification to the flash attention that mitigates the bias in rounding errors. This simple change stabilizes the training process, confirming our analysis and offering a practical solution to this persistent problem.",
            "score": 14,
            "issue_id": 6321,
            "pub_date": "2025-10-05",
            "pub_date_card": {
                "ru": "5 октября",
                "en": "October 5",
                "zh": "10月5日"
            },
            "hash": "e0a5e1e23247359f",
            "authors": [
                "Haiquan Qiu",
                "Quanming Yao"
            ],
            "affiliations": [
                "Department of Electronic Engineering, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04212.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#optimization"
                ],
                "emoji": "💥",
                "ru": {
                    "title": "Укрощение взрывов: стабильная тренировка трансформеров с низкой точностью",
                    "desc": "Исследователи выяснили, почему обучение transformer-моделей с flash attention в низкой точности приводит к катастрофическим взрывам функции потерь. Проблема возникает из-за двух связанных факторов: появления похожих low-rank представлений в механизме attention и накопления смещённых ошибок округления при арифметике низкой точности. Эти явления создают порочный круг накопления ошибок, который искажает обновления весов и разрушает динамику обучения. Авторы предложили минимальную модификацию flash attention, которая снижает смещение в ошибках округления и стабилизирует процесс тренировки."
                },
                "en": {
                    "title": "Stabilizing Low-Precision Training in Transformers",
                    "desc": "This paper addresses the challenges of training transformer models using low-precision formats, which often lead to significant training instabilities. It identifies the root cause of catastrophic loss explosions during low-precision training with flash attention, linking it to low-rank representations and biased rounding errors. The authors explain how these issues create a cycle of error accumulation that disrupts weight updates and training dynamics. To resolve this, they propose a minimal modification to the flash attention mechanism that reduces rounding bias, stabilizing the training process effectively."
                },
                "zh": {
                    "title": "低精度训练中的闪存注意力稳定性解决方案",
                    "desc": "本论文探讨了在低精度训练变换器模型时，使用闪存注意力机制所面临的灾难性损失爆炸问题。研究发现，这种问题并非偶然，而是由于注意力机制中出现的相似低秩表示和低精度算术中固有的偏差舍入误差相互作用所导致。我们提出了一种对闪存注意力机制的最小修改，能够减轻舍入误差的偏差，从而稳定训练过程。通过这一简单的改动，我们验证了分析结果，并为这一长期存在的问题提供了实用的解决方案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06751",
            "title": "OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot",
            "url": "https://huggingface.co/papers/2510.06751",
            "abstract": "OBS-Diff is a novel one-shot pruning framework that compresses large-scale text-to-image diffusion models with minimal quality loss and significant inference acceleration.  \t\t\t\t\tAI-generated summary \t\t\t\t Large-scale text-to-image diffusion models, while powerful, suffer from prohibitive computational cost. Existing one-shot network pruning methods can hardly be directly applied to them due to the iterative denoising nature of diffusion models. To bridge the gap, this paper presents OBS-Diff, a novel one-shot pruning framework that enables accurate and training-free compression of large-scale text-to-image diffusion models. Specifically, (i) OBS-Diff revitalizes the classic Optimal Brain Surgeon (OBS), adapting it to the complex architectures of modern diffusion models and supporting diverse pruning granularity, including unstructured, N:M semi-structured, and structured (MHA heads and FFN neurons) sparsity; (ii) To align the pruning criteria with the iterative dynamics of the diffusion process, by examining the problem from an error-accumulation perspective, we propose a novel timestep-aware Hessian construction that incorporates a logarithmic-decrease weighting scheme, assigning greater importance to earlier timesteps to mitigate potential error accumulation; (iii) Furthermore, a computationally efficient group-wise sequential pruning strategy is proposed to amortize the expensive calibration process. Extensive experiments show that OBS-Diff achieves state-of-the-art one-shot pruning for diffusion models, delivering inference acceleration with minimal degradation in visual quality.",
            "score": 13,
            "issue_id": 6322,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "719c136fdd131e9e",
            "authors": [
                "Junhan Zhu",
                "Hesong Wang",
                "Mingluo Su",
                "Zefang Wang",
                "Huan Wang"
            ],
            "affiliations": [
                "Westlake University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06751.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#inference",
                    "#diffusion",
                    "#architecture"
                ],
                "emoji": "✂️",
                "ru": {
                    "title": "Умное сжатие диффузионных моделей за один проход",
                    "desc": "OBS-Diff — это новый метод одношаговой обрезки (pruning) для сжатия больших текст-в-изображение диффузионных моделей без дополнительного обучения. Авторы адаптировали классический алгоритм Optimal Brain Surgeon для современных диффузионных архитектур, учитывая их итеративную природу генерации. Ключевая инновация — взвешивание по временным шагам с логарифмическим убыванием, которое придаёт больший вес ранним этапам диффузии для предотвращения накопления ошибок. Метод поддерживает различные типы разреженности и достигает ускорения inference при минимальной потере качества изображений."
                },
                "en": {
                    "title": "Efficient Pruning for Powerful Diffusion Models",
                    "desc": "OBS-Diff is a new framework designed to efficiently prune large-scale text-to-image diffusion models, which are typically expensive to run. Traditional one-shot pruning methods struggle with these models due to their complex iterative denoising processes. This paper introduces a modified version of the Optimal Brain Surgeon technique, allowing for various levels of pruning while maintaining model performance. By focusing on the error accumulation during the diffusion process and implementing a smart pruning strategy, OBS-Diff significantly speeds up inference with little loss in image quality."
                },
                "zh": {
                    "title": "OBS-Diff：高效压缩扩散模型的新方法",
                    "desc": "OBS-Diff是一种新颖的一次性剪枝框架，旨在压缩大规模文本到图像的扩散模型，同时保持最小的质量损失和显著的推理加速。现有的一次性网络剪枝方法难以直接应用于扩散模型，因为这些模型具有迭代去噪的特性。为了解决这个问题，OBS-Diff对经典的最佳脑外科医生（OBS）进行了改进，使其适应现代扩散模型的复杂架构，并支持多种剪枝粒度。通过引入时间步长感知的Hessian构造和高效的分组顺序剪枝策略，OBS-Diff在视觉质量损失最小的情况下，实现了扩散模型的最先进的一次性剪枝。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04230",
            "title": "Pushing on Multilingual Reasoning Models with Language-Mixed\n  Chain-of-Thought",
            "url": "https://huggingface.co/papers/2510.04230",
            "abstract": "A language-mixed chain-of-thought reasoning approach improves performance in Korean-specific tasks by switching between English and Korean, achieving state-of-the-art results across various benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent frontier models employ long chain-of-thought reasoning to explore solution spaces in context and achieve stonger performance. While many works study distillation to build smaller yet capable models, most focus on English and little is known about language-specific reasoning. To bridge this gap, we first introduct **Language-Mixed CoT**, a reasoning schema that switches between English and a target language, using English as an anchor to excel in reasoning while minimizing translation artificats. As a Korean case study, we curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5, Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves state-of-the-art performance, with the highest overall average score (64.0 \\pm 25), ranking first on 5/9 benchmarks and second on the remainder. Samller and mid-sized models also benefit substantially, with an average improvement of +18.6 points across teh evaluated nine benchmarks. Ablations show **Language-Mixed CoT** is more effective than monolingual CoT, also resulting in cross-lingual and mult-modal performance gains. We release our data-curation pipeline, evaluation system, datasets, and models to advance research on language-specific reasoning. Data and model collection: https://huggingface.co/KOREAson.",
            "score": 13,
            "issue_id": 6332,
            "pub_date": "2025-10-05",
            "pub_date_card": {
                "ru": "5 октября",
                "en": "October 5",
                "zh": "10月5日"
            },
            "hash": "26e466401e9dcc0f",
            "authors": [
                "Guijin Son",
                "Donghun Yang",
                "Hitesh Laxmichand Patel",
                "Amit Agarwal",
                "Hyunwoo Ko",
                "Chanuk Lim",
                "Srikant Panda",
                "Minhyuk Kim",
                "Nikunj Drolia",
                "Dasol Choi",
                "Kyong-Ha Lee",
                "Youngjae Yu"
            ],
            "affiliations": [
                "KISTI",
                "Korea University",
                "Modulabs",
                "OneLineAI",
                "Oracle AI",
                "Seoul National University",
                "University College Dublin"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04230.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#reasoning",
                    "#low_resource",
                    "#benchmark",
                    "#multilingual",
                    "#dataset",
                    "#long_context",
                    "#training",
                    "#data"
                ],
                "emoji": "🇰🇷",
                "ru": {
                    "title": "Смешанный языковой reasoning: английский как якорь для усиления корейских LLM",
                    "desc": "Исследователи предложили метод Language-Mixed CoT, который переключается между английским и целевым языком (корейским) для улучшения reasoning способностей LLM. Они создали датасет Yi-Sang с 5.79M корейских промптов и 3.7M длинных reasoning traces, обученных на базе Qwen3-32B. Их лучшая модель KO-REAson-35B достигла state-of-the-art результатов на корейских бенчмарках, заняв первое место на 5 из 9 тестов со средним улучшением +18.6 баллов. Эксперименты показали, что смешанный языковой подход превосходит монолингвальный CoT и даже улучшает cross-lingual и мультимодальные способности моделей."
                },
                "en": {
                    "title": "Bridging Languages for Better Reasoning in Korean Tasks",
                    "desc": "This paper introduces a novel reasoning approach called Language-Mixed Chain-of-Thought (CoT) that enhances performance on Korean-specific tasks by alternating between English and Korean. By using English as a reference point, the method minimizes translation errors and improves reasoning capabilities. The authors present a comprehensive dataset, Yi-Sang, consisting of millions of Korean prompts and reasoning traces, which supports the training of various models. The best-performing model, KO-REAson-35B, achieves state-of-the-art results across multiple benchmarks, demonstrating significant improvements for both large and smaller models."
                },
                "zh": {
                    "title": "语言混合推理，提升韩语任务表现！",
                    "desc": "这篇论文提出了一种语言混合的思维链推理方法，旨在提高韩语特定任务的表现。该方法通过在英语和韩语之间切换，利用英语作为锚点来增强推理能力，同时减少翻译带来的干扰。研究中使用了名为Yi-Sang的韩语数据集，并训练了多个模型，其中最好的模型KO-REAson-35B在多个基准测试中取得了最先进的成绩。实验结果表明，语言混合的思维链推理方法比单语推理方法更有效，且对中小型模型也有显著的性能提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07318",
            "title": "Artificial Hippocampus Networks for Efficient Long-Context Modeling",
            "url": "https://huggingface.co/papers/2510.07318",
            "abstract": "A memory framework combining short-term and long-term memory in neural networks improves long-sequence modeling efficiency and performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-sequence modeling faces a fundamental trade-off between the efficiency of compressive fixed-size memory in RNN-like models and the fidelity of lossless growing memory in attention-based Transformers. Inspired by the Multi-Store Model in cognitive science, we introduce a memory framework of artificial neural networks. Our method maintains a sliding window of the Transformer's KV cache as lossless short-term memory, while a learnable module termed Artificial Hippocampus Network (AHN) recurrently compresses out-of-window information into a fixed-size compact long-term memory. To validate this framework, we instantiate AHNs using modern RNN-like architectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensive experiments on long-context benchmarks LV-Eval and InfiniteBench demonstrate that AHN-augmented models consistently outperform sliding window baselines and achieve performance comparable or even superior to full-attention models, while substantially reducing computational and memory requirements. For instance, augmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5% and memory cache by 74.0%, while improving its average score on LV-Eval (128k sequence length) from 4.41 to 5.88. Code is available at: https://github.com/ByteDance-Seed/AHN.",
            "score": 12,
            "issue_id": 6321,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "95c7f8990db3ab94",
            "authors": [
                "Yunhao Fang",
                "Weihao Yu",
                "Shu Zhong",
                "Qinghao Ye",
                "Xuehan Xiong",
                "Lai Wei"
            ],
            "affiliations": [
                "ByteDance"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07318.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#benchmark",
                    "#optimization",
                    "#long_context"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Искусственный гиппокамп для эффективной памяти нейросетей",
                    "desc": "Исследователи предложили архитектуру памяти для нейросетей, вдохновлённую моделью многокомпонентной памяти из когнитивной психологии. Система сочетает кратковременную память (скользящее окно KV-кеша Transformer) и долговременную память (компактное представление, сжимаемое модулем Artificial Hippocampus Network). AHN реализован на базе современных RNN-подобных архитектур, включая Mamba2, DeltaNet и Gated DeltaNet. Эксперименты показали, что модели с AHN превосходят базовые методы со скользящим окном и сопоставимы с full-attention моделями, при этом снижая вычислительные затраты на 40.5% и использование памяти на 74%."
                },
                "en": {
                    "title": "Enhancing Long-Sequence Modeling with Memory Integration",
                    "desc": "This paper presents a new memory framework for neural networks that combines short-term and long-term memory to enhance the modeling of long sequences. The framework uses a sliding window for short-term memory, which retains recent information, while an Artificial Hippocampus Network (AHN) compresses older data into a fixed-size long-term memory. By integrating this approach into existing RNN-like architectures, the models show improved efficiency and performance on long-context tasks. Experiments reveal that these models not only outperform traditional methods but also significantly reduce computational costs and memory usage."
                },
                "zh": {
                    "title": "提升长序列建模效率的记忆框架",
                    "desc": "本论文提出了一种结合短期和长期记忆的神经网络记忆框架，以提高长序列建模的效率和性能。该框架借鉴了认知科学中的多存储模型，使用变换器的KV缓存作为无损短期记忆，同时通过人工海马体网络（AHN）将超出窗口的信息压缩为固定大小的长期记忆。实验结果表明，使用AHN的模型在长上下文基准测试中表现优于传统的滑动窗口模型，并且在计算和内存需求上显著降低。具体来说，Qwen2.5-3B-Instruct模型在引入AHN后，推理计算量减少了40.5%，内存缓存减少了74.0%，同时在LV-Eval上的平均得分从4.41提高到5.88。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07019",
            "title": "Native Hybrid Attention for Efficient Sequence Modeling",
            "url": "https://huggingface.co/papers/2510.07019",
            "abstract": "Native Hybrid Attention (NHA) combines linear and full attention mechanisms to maintain long-term context while improving efficiency, outperforming Transformers in recall-intensive tasks and offering efficiency gains in pretrained LLMs.  \t\t\t\t\tAI-generated summary \t\t\t\t Transformers excel at sequence modeling but face quadratic complexity, while linear attention offers improved efficiency but often compromises recall accuracy over long contexts. In this work, we introduce Native Hybrid Attention (NHA), a novel hybrid architecture of linear and full attention that integrates both intra \\& inter-layer hybridization into a unified layer design. NHA maintains long-term context in key-value slots updated by a linear RNN, and augments them with short-term tokens from a sliding window. A single softmax attention operation is then applied over all keys and values, enabling per-token and per-head context-dependent weighting without requiring additional fusion parameters. The inter-layer behavior is controlled through a single hyperparameter, the sliding window size, which allows smooth adjustment between purely linear and full attention while keeping all layers structurally uniform. Experimental results show that NHA surpasses Transformers and other hybrid baselines on recall-intensive and commonsense reasoning tasks. Furthermore, pretrained LLMs can be structurally hybridized with NHA, achieving competitive accuracy while delivering significant efficiency gains. Code is available at https://github.com/JusenD/NHA.",
            "score": 12,
            "issue_id": 6328,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "d6cafe9c8dd0bad4",
            "authors": [
                "Jusen Du",
                "Jiaxi Hu",
                "Tao Zhang",
                "Weigao Sun",
                "Yu Cheng"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "The Chinese University of Hong Kong",
                "The Hong Kong University of Science and Technology (Guangzhou)",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07019.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#optimization",
                    "#architecture",
                    "#long_context"
                ],
                "emoji": "🔀",
                "ru": {
                    "title": "Гибридное внимание: эффективность линейных моделей с точностью Transformer",
                    "desc": "Статья представляет Native Hybrid Attention (NHA) — новую архитектуру, которая объединяет линейное и полное внимание в единый механизм. NHA использует linear RNN для поддержания долгосрочного контекста в key-value слотах и дополняет их токенами из скользящего окна для краткосрочной информации. Архитектура превосходит классические Transformer в задачах, требующих хорошей памяти, и позволяет легко конвертировать предобученные LLM с существенным приростом эффективности. Переход между чисто линейным и полным вниманием контролируется одним гиперпараметром — размером скользящего окна."
                },
                "en": {
                    "title": "Efficient Recall with Native Hybrid Attention",
                    "desc": "Native Hybrid Attention (NHA) is a new approach that combines linear and full attention mechanisms to enhance efficiency while preserving long-term context in machine learning models. Unlike traditional Transformers, which struggle with quadratic complexity, NHA integrates both types of attention in a single layer, allowing for better recall in tasks that require remembering information over long sequences. It uses a linear RNN to manage key-value slots and incorporates short-term tokens through a sliding window, optimizing the attention process with a single softmax operation. Experimental results demonstrate that NHA outperforms existing models in recall-intensive tasks and can be effectively integrated into pretrained large language models for improved performance and efficiency."
                },
                "zh": {
                    "title": "混合注意力，提升效率与召回率！",
                    "desc": "本论文提出了一种新的混合注意力机制，称为Native Hybrid Attention（NHA），它结合了线性和全注意力机制。NHA能够在保持长期上下文的同时，提高计算效率，特别是在需要高召回率的任务中表现优于传统的Transformer模型。该方法通过线性RNN更新关键值槽，并利用滑动窗口中的短期标记来增强上下文信息。实验结果表明，NHA在召回密集和常识推理任务上超越了Transformer和其他混合基线，同时在预训练的大型语言模型中也实现了显著的效率提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.05862",
            "title": "Revisiting Long-context Modeling from Context Denoising Perspective",
            "url": "https://huggingface.co/papers/2510.05862",
            "abstract": "Context Denoising Training (CDT) improves long-context models' performance by mitigating contextual noise and enhancing attention on critical tokens.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-context models (LCMs) have demonstrated great potential in processing long sequences, facilitating many real-world applications. The success of LCMs can be attributed to their ability to locate implicit critical information within the context for further prediction. However, recent research reveals that LCMs are often susceptible to contextual noise, i.e., irrelevant tokens, that can mislead model attention. In this paper, we conduct a fine-grained analysis of the context noise and propose an effective metric, the Integrated Gradient (IG) score, to detect and quantify the noise information within the context. Our findings reveal that even simple mitigation of detected context noise can substantially boost the model's attention on critical tokens and benefit subsequent predictions. Building on this insight, we propose Context Denoising Training (CDT), a straightforward yet effective training strategy that improves attention on critical tokens while reinforcing their influence on model predictions. Extensive experiments across four tasks, under both context window scaling and long-context alignment settings, demonstrate the superiority of CDT. Notably, when trained with CDT, an open-source 8B model can achieve performance (50.92) comparable to GPT-4o (51.00).",
            "score": 12,
            "issue_id": 6321,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "efa8b7d057b81865",
            "authors": [
                "Zecheng Tang",
                "Baibei Ji",
                "Juntao Li",
                "Lijun Wu",
                "Haijia Gui",
                "Min Zhang"
            ],
            "affiliations": [
                "LCM Laboratory",
                "Shanghai Artificial Intelligence Laboratory",
                "Soochow University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.05862.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#long_context",
                    "#optimization"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Обучение с очисткой контекста: фокус на важном",
                    "desc": "Исследователи предлагают метод Context Denoising Training (CDT) для улучшения работы моделей с длинным контекстом. Проблема заключается в том, что модели часто отвлекаются на нерелевантные токены (контекстный шум), что мешает им сосредоточиться на критически важной информации. Авторы используют метрику Integrated Gradient для обнаружения такого шума и предлагают стратегию обучения, которая усиливает внимание модели на ключевых токенах. Эксперименты показывают, что open-source модель на 8B параметров, обученная с CDT, достигает результатов, сопоставимых с GPT-4o."
                },
                "en": {
                    "title": "Enhancing Long-Context Models with Context Denoising Training",
                    "desc": "Context Denoising Training (CDT) is a novel approach designed to enhance the performance of long-context models (LCMs) by reducing the impact of contextual noise. This noise, which consists of irrelevant tokens, can distract the model from focusing on important information needed for accurate predictions. The paper introduces the Integrated Gradient (IG) score as a metric to identify and measure this noise, allowing for targeted mitigation strategies. By implementing CDT, the model's attention on critical tokens is improved, leading to better overall performance in various tasks, even achieving results comparable to advanced models like GPT-4o."
                },
                "zh": {
                    "title": "上下文去噪，提升模型性能！",
                    "desc": "上下文去噪训练（CDT）通过减少上下文噪声，提升了长上下文模型的性能。长上下文模型（LCMs）在处理长序列方面表现出色，但容易受到无关标记的干扰。本文提出了一种有效的度量标准——积分梯度（IG）分数，用于检测和量化上下文中的噪声信息。通过简单的噪声缓解方法，CDT显著增强了模型对关键标记的关注，从而改善了后续的预测效果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07143",
            "title": "Are We Using the Right Benchmark: An Evaluation Framework for Visual\n  Token Compression Methods",
            "url": "https://huggingface.co/papers/2510.07143",
            "abstract": "VTC-Bench is introduced to provide a fair evaluation framework for visual token compression by incorporating a data filtering mechanism to denoise existing benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent endeavors to accelerate inference in Multimodal Large Language Models (MLLMs) have primarily focused on visual token compression. The effectiveness of these methods is typically assessed by measuring the accuracy drop on established benchmarks, comparing model performance before and after compression. However, these benchmarks are originally designed to assess the perception and reasoning capabilities of MLLMs, rather than to evaluate compression techniques. As a result, directly applying them to visual token compression introduces a task mismatch. Strikingly, our investigation reveals that simple image downsampling consistently outperforms many advanced compression methods across multiple widely used benchmarks. Through extensive experiments, we make the following observations: (i) Current benchmarks are noisy for the visual token compression task. (ii) Down-sampling is able to serve as a data filter to evaluate the difficulty of samples in the visual token compression task. Motivated by these findings, we introduce VTC-Bench, an evaluation framework that incorporates a data filtering mechanism to denoise existing benchmarks, thereby enabling fairer and more accurate assessment of visual token compression methods. All data and code are available at https://github.com/Chenfei-Liao/VTC-Bench.",
            "score": 10,
            "issue_id": 6325,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "8dd7873ac575e1d1",
            "authors": [
                "Chenfei Liao",
                "Wensong Wang",
                "Zichen Wen",
                "Xu Zheng",
                "Yiyu Wang",
                "Haocong He",
                "Yuanhuiyi Lyu",
                "Lutao Jiang",
                "Xin Zou",
                "Yuqian Fu",
                "Bin Ren",
                "Linfeng Zhang",
                "Xuming Hu"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Hong Kong University of Science and Technology (Guangzhou)",
                "INSAIT, Sofia University St. Kliment Ohridski",
                "Northeastern University",
                "Shanghai AI Laboratory",
                "Shanghai Jiao Tong University",
                "University of Pisa",
                "University of Trento"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07143.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "VTC-Bench: честная оценка сжатия визуальных токенов в мультимодальных LLM",
                    "desc": "Статья представляет VTC-Bench — новый фреймворк для честной оценки методов сжатия визуальных токенов в мультимодальных больших языковых моделях (MLLM). Исследователи обнаружили, что существующие бенчмарки содержат шум и не подходят для оценки компрессии, а простое уменьшение разрешения изображений часто работает лучше сложных методов сжатия. VTC-Bench использует механизм фильтрации данных для очистки существующих бенчмарков от шума и более точной оценки методов компрессии. Это позволяет корректно сравнивать различные подходы к ускорению inference в мультимодальных LLM через сжатие визуальных токенов."
                },
                "en": {
                    "title": "VTC-Bench: Fair Evaluation for Visual Token Compression",
                    "desc": "VTC-Bench is a new evaluation framework designed to improve the assessment of visual token compression methods in Multimodal Large Language Models (MLLMs). It addresses the issue of noisy benchmarks that were not originally intended for evaluating compression techniques, leading to inaccurate performance comparisons. The framework incorporates a data filtering mechanism that helps to denoise these benchmarks, allowing for a more reliable evaluation of compression methods. Our findings show that simple image downsampling can outperform complex compression techniques, highlighting the need for a better evaluation approach."
                },
                "zh": {
                    "title": "VTC-Bench：公平评估视觉令牌压缩的新框架",
                    "desc": "VTC-Bench是一个新的评估框架，旨在为视觉令牌压缩提供公平的评估。它通过引入数据过滤机制来去噪现有基准，从而提高评估的准确性。研究发现，简单的图像下采样在多个基准测试中表现优于许多先进的压缩方法。VTC-Bench的目标是解决当前基准测试的噪声问题，使视觉令牌压缩方法的评估更加公正和准确。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06557",
            "title": "The Markovian Thinker",
            "url": "https://huggingface.co/papers/2510.06557",
            "abstract": "Markovian Thinking, implemented in Delethink, enables efficient and scalable reinforcement learning for long-chain-of-thought reasoning in LLMs by decoupling thinking length from context size, resulting in linear compute and constant memory usage.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement learning (RL) has recently become a strong recipe for training reasoning LLMs that produce long chains of thought (LongCoT). Yet the standard RL \"thinking environment\", where the state is the prompt plus all prior reasoning tokens, makes the state unbounded and forces attention-based policies to pay quadratic compute as thoughts lengthen. We revisit the environment itself. We propose Markovian Thinking, a paradigm in which the policy advances reasoning while conditioning on a constant-size state, decoupling thinking length from context size. As an immediate consequence this yields linear compute with constant memory. We instantiate this idea with Delethink, an RL environment that structures reasoning into fixed-size chunks. Within each chunk, the model thinks as usual; at the boundary, the environment resets the context and reinitializes the prompt with a short carryover. Through RL, the policy learns to write a textual state near the end of each chunk sufficient for seamless continuation of reasoning after reset. Trained in this environment, an R1-Distill 1.5B model reasons in 8K-token chunks yet thinks up to 24K tokens, matching or surpassing LongCoT-RL trained with a 24K budget. With test-time scaling, Delethink continues to improve where LongCoT plateaus. The effect of linear compute is substantial: we empirically estimate at 96K average thinking length LongCoT-RL costs 27 H100-months vs. 7 for Delethink. Analysis at RL initialization shows off-the-shelf reasoning models (1.5B-120B) often sample Markovian traces zero-shot across diverse benchmarks, providing positive samples that make RL effective at scale. Our results show that redesigning the thinking environment is a powerful lever: it enables very long reasoning without quadratic overhead and opens a path toward efficient, scalable reasoning LLMs.",
            "score": 10,
            "issue_id": 6330,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "24d3191793e49f1b",
            "authors": [
                "Milad Aghajohari",
                "Kamran Chitsaz",
                "Amirhossein Kazemnejad",
                "Sarath Chandar",
                "Alessandro Sordoni",
                "Aaron Courville",
                "Siva Reddy"
            ],
            "affiliations": [
                "Canada CIFAR AI Chair",
                "Chandar Research Lab",
                "McGill University",
                "Microsoft Research",
                "Mila",
                "Polytechnique Montréal",
                "ServiceNow Research",
                "Université de Montréal"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06557.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#rlhf",
                    "#long_context",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "🧩",
                "ru": {
                    "title": "Марковское мышление: эффективные длинные рассуждения без квадратичных затрат",
                    "desc": "Статья представляет Markovian Thinking и систему Delethink — новый подход к обучению языковых моделей длинным цепочкам рассуждений (LongCoT) через reinforcement learning. Ключевая идея заключается в разбиении рассуждений на фиксированные блоки (чанки), где модель сохраняет только компактное текстовое представление состояния между блоками, вместо хранения всего контекста. Это снижает вычислительную сложность с квадратичной до линейной, а использование памяти делает константным, что критично для масштабирования. Эксперименты показывают, что модель на 1.5B параметров может рассуждать до 24K токенов, обучаясь на блоках по 8K, при этом затраты вычислительных ресурсов сокращаются в 4 раза по сравнению со стандартным подходом."
                },
                "en": {
                    "title": "Efficient Long-Chain Reasoning with Markovian Thinking",
                    "desc": "This paper introduces Markovian Thinking, a new approach for reinforcement learning (RL) that enhances long-chain-of-thought reasoning in large language models (LLMs). By decoupling the length of reasoning from the context size, it allows for linear computational costs and constant memory usage, making it more efficient. The authors present Delethink, an RL environment that organizes reasoning into fixed-size chunks, enabling the model to maintain coherence across resets. The results demonstrate that this method significantly reduces resource consumption while improving reasoning capabilities compared to traditional RL methods."
                },
                "zh": {
                    "title": "马尔可夫思维：高效推理的新路径",
                    "desc": "本文提出了一种名为马尔可夫思维的强化学习新方法，旨在提高大型语言模型（LLMs）在长链推理中的效率和可扩展性。通过将思维长度与上下文大小解耦，马尔可夫思维使得计算复杂度呈线性增长，同时内存使用保持不变。我们通过Delethink环境实现了这一理念，该环境将推理结构化为固定大小的块，使得模型在每个块内进行常规思考。实验结果表明，使用Delethink的模型在推理长度上表现优异，显著降低了计算成本。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.05057",
            "title": "StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact\n  State Representation",
            "url": "https://huggingface.co/papers/2510.05057",
            "abstract": "An unsupervised method learns a compact state representation using a lightweight encoder and Diffusion Transformer decoder, improving robotic performance and enabling latent action decoding from static images.  \t\t\t\t\tAI-generated summary \t\t\t\t A fundamental challenge in embodied intelligence is developing expressive and compact state representations for efficient world modeling and decision making. However, existing methods often fail to achieve this balance, yielding representations that are either overly redundant or lacking in task-critical information. We propose an unsupervised approach that learns a highly compressed two-token state representation using a lightweight encoder and a pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong generative prior. Our representation is efficient, interpretable, and integrates seamlessly into existing VLA-based models, improving performance by 14.3% on LIBERO and 30% in real-world task success with minimal inference overhead. More importantly, we find that the difference between these tokens, obtained via latent interpolation, naturally serves as a highly effective latent action, which can be further decoded into executable robot actions. This emergent capability reveals that our representation captures structured dynamics without explicit supervision. We name our method StaMo for its ability to learn generalizable robotic Motion from compact State representation, which is encoded from static images, challenging the prevalent dependence to learning latent action on complex architectures and video data. The resulting latent actions also enhance policy co-training, outperforming prior methods by 10.4% with improved interpretability. Moreover, our approach scales effectively across diverse data sources, including real-world robot data, simulation, and human egocentric video.",
            "score": 10,
            "issue_id": 6326,
            "pub_date": "2025-10-06",
            "pub_date_card": {
                "ru": "6 октября",
                "en": "October 6",
                "zh": "10月6日"
            },
            "hash": "1e9f45f6911e2d61",
            "authors": [
                "Mingyu Liu",
                "Jiuhe Shu",
                "Hui Chen",
                "Zeju Li",
                "Canyu Zhao",
                "Jiange Yang",
                "Shenyuan Gao",
                "Hao Chen",
                "Chunhua Shen"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Nanjing University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.05057.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#training",
                    "#agents",
                    "#optimization",
                    "#robotics",
                    "#diffusion"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Два токена для управления роботом: компактное представление состояния и действия",
                    "desc": "Статья предлагает метод StaMo для обучения компактного представления состояния робота всего в два токена с использованием легковесного энкодера и предобученного Diffusion Transformer декодера. Ключевая находка: разность между этими токенами естественным образом формирует латентное действие, которое можно декодировать в команды для робота, причём это происходит без явного supervised обучения. Метод улучшает производительность VLA-моделей на 14.3% на бенчмарке LIBERO и на 30% в реальных задачах, при этом работая эффективно с минимальными вычислительными затратами. Подход масштабируется на различные источники данных включая реальные роботы, симуляции и egocentric видео людей, обучая латентные действия из статичных изображений без необходимости видеоданных."
                },
                "en": {
                    "title": "Efficient State Representation for Enhanced Robotic Motion",
                    "desc": "This paper presents an unsupervised method called StaMo that learns a compact state representation for robotic applications using a lightweight encoder and a Diffusion Transformer decoder. The method addresses the challenge of creating efficient and expressive state representations, which are crucial for decision-making in robotics. By utilizing a two-token representation, StaMo improves performance significantly on various benchmarks while enabling the decoding of latent actions from static images. This approach not only enhances interpretability and efficiency but also demonstrates the ability to capture structured dynamics without requiring explicit supervision."
                },
                "zh": {
                    "title": "紧凑状态表示，提升机器人智能",
                    "desc": "本文提出了一种无监督的方法，通过轻量级编码器和扩散变换器解码器学习紧凑的状态表示。这种方法能够从静态图像中提取出高效且可解释的状态表示，显著提高了机器人在真实任务中的成功率。我们的方法在LIBERO数据集上提高了14.3%的性能，并在实际任务中提升了30%。此外，通过潜在插值获得的状态差异可以自然地作为有效的潜在动作，进一步解码为可执行的机器人动作。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07238",
            "title": "When Benchmarks Age: Temporal Misalignment through Large Language Model\n  Factuality Evaluation",
            "url": "https://huggingface.co/papers/2510.07238",
            "abstract": "Research investigates the aging of factuality benchmarks and its impact on evaluating the factuality of large language models, revealing significant unreliability due to outdated samples.  \t\t\t\t\tAI-generated summary \t\t\t\t The rapid evolution of large language models (LLMs) and the real world has outpaced the static nature of widely used evaluation benchmarks, raising concerns about their reliability for evaluating LLM factuality. While substantial works continue to rely on the popular but old benchmarks, their temporal misalignment with real-world facts and modern LLMs, and their effects on LLM factuality evaluation remain underexplored. Therefore, in this work, we present a systematic investigation of this issue by examining five popular factuality benchmarks and eight LLMs released across different years. An up-to-date fact retrieval pipeline and three metrics are tailored to quantify benchmark aging and its impact on LLM factuality evaluation. Experimental results and analysis illustrate that a considerable portion of samples in the widely used factuality benchmarks are outdated, leading to unreliable assessments of LLM factuality. We hope our work can provide a testbed to assess the reliability of a benchmark for LLM factuality evaluation and inspire more research on the benchmark aging issue. Codes are available in https://github.com/JiangXunyi/BenchAge.",
            "score": 9,
            "issue_id": 6322,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "1477f170bed5f8aa",
            "authors": [
                "Xunyi Jiang",
                "Dingyi Chang",
                "Julian McAuley",
                "Xin Xu"
            ],
            "affiliations": [
                "University of California, San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07238.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#hallucinations",
                    "#benchmark"
                ],
                "emoji": "⏳",
                "ru": {
                    "title": "Когда бенчмарки стареют: проблема устаревших тестов для оценки фактуальности LLM",
                    "desc": "Исследование показывает, что популярные бенчмарки для оценки фактуальности LLM устаревают со временем, что делает их ненадёжными для тестирования современных моделей. Авторы проанализировали пять известных бенчмарков и восемь LLM, выпущенных в разные годы, используя специальную систему проверки актуальности фактов. Оказалось, что значительная часть примеров в этих бенчмарках содержит устаревшую информацию, что приводит к неточной оценке способности моделей работать с фактами. Работа предлагает методологию для оценки надёжности бенчмарков и привлекает внимание к проблеме их старения."
                },
                "en": {
                    "title": "Outdated Benchmarks, Unreliable Evaluations: Rethinking LLM Factuality",
                    "desc": "This research paper examines how the aging of factuality benchmarks affects the evaluation of large language models (LLMs). It highlights that many commonly used benchmarks are outdated, which can lead to unreliable assessments of how factual these models are. The authors conducted a systematic study of five popular benchmarks and eight LLMs, using a new fact retrieval pipeline and metrics to measure the impact of benchmark aging. The findings suggest that relying on these old benchmarks can mislead evaluations, emphasizing the need for updated standards in assessing LLM factuality."
                },
                "zh": {
                    "title": "基准老化影响LLM事实性评估的可靠性",
                    "desc": "本研究探讨了事实基准的老化及其对大型语言模型（LLM）事实性评估的影响，发现由于样本过时，评估结果存在显著的不可靠性。随着大型语言模型和现实世界的快速发展，广泛使用的评估基准的静态特性引发了对其可靠性的担忧。我们系统地研究了五个流行的事实基准和八个不同年份发布的LLM，提出了一个更新的事实检索管道和三种指标来量化基准老化及其对LLM事实性评估的影响。实验结果表明，许多流行事实基准中的样本已经过时，导致对LLM事实性的评估不可靠。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.01954",
            "title": "Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in\n  MLLMs",
            "url": "https://huggingface.co/papers/2510.01954",
            "abstract": "PaDT, a unified paradigm for multimodal large language models, directly generates both textual and visual outputs, achieving state-of-the-art performance in visual perception tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Multimodal large language models (MLLMs) have advanced rapidly in recent years. However, existing approaches for vision tasks often rely on indirect representations, such as generating coordinates as text for detection, which limits performance and prevents dense prediction tasks like segmentation. To overcome these challenges, we introduce Patch-as-Decodable Token (PaDT), a unified paradigm that enables MLLMs to directly generate both textual and diverse visual outputs. Central to PaDT are Visual Reference Tokens (VRTs), derived from visual patch embeddings of query images and interleaved seamlessly with LLM's output textual tokens. A lightweight decoder then transforms LLM's outputs into detection, segmentation, and grounding predictions. Unlike prior methods, PaDT processes VRTs independently at each forward pass and dynamically expands the embedding table, thus improving localization and differentiation among similar objects. We further tailor a training strategy for PaDT by randomly selecting VRTs for supervised fine-tuning and introducing a robust per-token cross-entropy loss. Our empirical studies across four visual perception and understanding tasks suggest PaDT consistently achieving state-of-the-art performance, even compared with significantly larger MLLM models. The code is available at https://github.com/Gorilla-Lab-SCUT/PaDT.",
            "score": 8,
            "issue_id": 6327,
            "pub_date": "2025-10-02",
            "pub_date_card": {
                "ru": "2 октября",
                "en": "October 2",
                "zh": "10月2日"
            },
            "hash": "4b2f2c5648bbe9c2",
            "authors": [
                "Yongyi Su",
                "Haojie Zhang",
                "Shijie Li",
                "Nanqing Liu",
                "Jingyi Liao",
                "Junyi Pan",
                "Yuan Liu",
                "Xiaofen Xing",
                "Chong Sun",
                "Chen Li",
                "Nancy F. Chen",
                "Shuicheng Yan",
                "Xulei Yang",
                "Xun Xu"
            ],
            "affiliations": [
                "Foshan University",
                "Institute for Infocomm Research (I2R), A*STAR",
                "Nanyang Technological University",
                "National University of Singapore",
                "South China University of Technology",
                "WeChat Vision, Tencent Inc."
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.01954.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#multimodal",
                    "#training",
                    "#cv",
                    "#optimization",
                    "#open_source"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Прямая генерация визуальных результатов через токены-патчи",
                    "desc": "В статье представлен PaDT — новый подход для мультимодальных LLM, который позволяет напрямую генерировать как текстовые, так и визуальные результаты. Ключевая идея — использование Visual Reference Tokens (VRT), полученных из эмбеддингов патчей изображений и встроенных в выходную последовательность токенов языковой модели. Легковесный декодер преобразует выходы LLM в предсказания для детекции, сегментации и grounding задач. Метод достигает state-of-the-art результатов в задачах визуального восприятия, превосходя даже значительно более крупные MLLM модели."
                },
                "en": {
                    "title": "PaDT: Directly Bridging Text and Vision for Superior Performance",
                    "desc": "The paper introduces PaDT, a new approach for multimodal large language models (MLLMs) that generates both text and visual outputs directly. This method addresses limitations of previous models that used indirect representations, which hindered performance in tasks like segmentation. PaDT utilizes Visual Reference Tokens (VRTs) that are integrated with textual tokens, allowing for better detection and localization of objects. The results show that PaDT outperforms existing models in various visual perception tasks, demonstrating its effectiveness and efficiency."
                },
                "zh": {
                    "title": "PaDT：多模态生成的统一范式",
                    "desc": "PaDT是一种统一的多模态大语言模型范式，能够直接生成文本和视觉输出，提升了视觉感知任务的性能。与传统方法不同，PaDT使用视觉参考标记（VRTs），这些标记直接从图像的视觉补丁嵌入中提取，并与文本输出无缝结合。通过轻量级解码器，PaDT能够将输出转化为检测、分割和定位预测。我们的实证研究表明，PaDT在四个视觉感知任务中表现出色，甚至超越了更大规模的多模态大语言模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06783",
            "title": "TTRV: Test-Time Reinforcement Learning for Vision Language Models",
            "url": "https://huggingface.co/papers/2510.06783",
            "abstract": "TTRV enhances vision language understanding through test-time reinforcement learning, improving performance on object recognition and VQA without labeled data.  \t\t\t\t\tAI-generated summary \t\t\t\t Existing methods for extracting reward signals in Reinforcement Learning typically rely on labeled data and dedicated training splits, a setup that contrasts with how humans learn directly from their environment. In this work, we propose TTRV to enhance vision language understanding by adapting the model on the fly at inference time, without the need for any labeled data. Concretely, we enhance the Group Relative Policy Optimization (GRPO) framework by designing rewards based on the frequency of the base model's output, while inferring on each test sample multiple times. Further, we also propose to control the diversity of the model's output by simultaneously rewarding the model for obtaining low entropy of the output empirical distribution. Our approach delivers consistent gains across both object recognition and visual question answering (VQA), with improvements of up to 52.4% and 29.8%, respectively, and average boosts of 24.6% and 10.0% across 16 datasets.Remarkably, on image recognition, TTRV applied to InternVL 8B surpasses GPT-4o by an average of 2.3% over 8 benchmarks, while remaining highly competitive on VQA, demonstrating that test-time reinforcement learning can match or exceed the strongest proprietary models. Finally, we find many interesting properties of test-time RL for VLMs: for example, even in extremely data-constrained scenarios, where adaptation is performed on a single randomly chosen unlabeled test example, TTRV still yields non-trivial improvements of up to 5.5% in recognition tasks.",
            "score": 6,
            "issue_id": 6322,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "54afe116302f9e7c",
            "authors": [
                "Akshit Singh",
                "Shyam Marjit",
                "Wei Lin",
                "Paul Gavrikov",
                "Serena Yeung-Levy",
                "Hilde Kuehne",
                "Rogerio Feris",
                "Sivan Doveh",
                "James Glass",
                "M. Jehanzeb Mirza"
            ],
            "affiliations": [
                "IISc Bangalore",
                "Independent Researcher",
                "JKU Linz",
                "MIT CSAIL",
                "MIT-IBM Watson AI Lab",
                "Stanford",
                "Tübingen AI Center"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06783.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#rl",
                    "#multimodal",
                    "#rlhf",
                    "#cv",
                    "#transfer_learning"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Обучение с подкреплением на лету: модели учатся прямо во время тестирования",
                    "desc": "Исследователи предложили метод TTRV, который улучшает понимание изображений и текста через reinforcement learning прямо во время инференса, без использования размеченных данных. Подход основан на улучшенном алгоритме GRPO, где награды вычисляются на основе частоты ответов базовой модели при многократном инференсе на одном примере. Метод показывает впечатляющие результаты: до 52.4% улучшения в распознавании объектов и до 29.8% в visual question answering на 16 датасетах. Примечательно, что TTRV с моделью InternVL 8B превосходит GPT-4o в среднем на 2.3%, причём улучшения наблюдаются даже при адаптации всего на одном тестовом примере."
                },
                "en": {
                    "title": "Enhancing Vision Language Understanding with Test-Time Reinforcement Learning",
                    "desc": "The paper introduces TTRV, a novel approach that enhances vision language understanding using test-time reinforcement learning (RL) without requiring labeled data. It improves the Group Relative Policy Optimization (GRPO) framework by creating rewards based on the frequency of outputs from the base model, allowing for dynamic adaptation during inference. The method also encourages diversity in outputs by rewarding lower entropy in the empirical distribution of predictions. TTRV shows significant performance improvements in object recognition and visual question answering (VQA), outperforming existing models like GPT-4o in certain benchmarks, even in scenarios with limited data."
                },
                "zh": {
                    "title": "测试时强化学习提升视觉语言理解",
                    "desc": "本文提出了一种名为TTRV的方法，通过在推理时进行强化学习，增强视觉语言理解能力，而无需标记数据。该方法改进了群体相对策略优化（GRPO）框架，通过基于基础模型输出频率设计奖励信号，来优化模型的表现。TTRV在物体识别和视觉问答（VQA）任务中均取得了显著提升，分别提高了52.4%和29.8%。研究表明，即使在数据极其有限的情况下，TTRV也能在识别任务中实现高达5.5%的改进。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.05644",
            "title": "The African Languages Lab: A Collaborative Approach to Advancing\n  Low-Resource African NLP",
            "url": "https://huggingface.co/papers/2510.05644",
            "abstract": "The African Languages Lab addresses the underserved status of African languages in NLP by creating a large dataset and demonstrating improved model performance through fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Despite representing nearly one-third of the world's languages, African languages remain critically underserved by modern NLP technologies, with 88\\% classified as severely underrepresented or completely ignored in computational linguistics. We present the African Languages Lab (All Lab), a comprehensive research initiative that addresses this technological gap through systematic data collection, model development, and capacity building. Our contributions include: (1) a quality-controlled data collection pipeline, yielding the largest validated African multi-modal speech and text dataset spanning 40 languages with 19 billion tokens of monolingual text and 12,628 hours of aligned speech data; (2) extensive experimental validation demonstrating that our dataset, combined with fine-tuning, achieves substantial improvements over baseline models, averaging +23.69 ChrF++, +0.33 COMET, and +15.34 BLEU points across 31 evaluated languages; and (3) a structured research program that has successfully mentored fifteen early-career researchers, establishing sustainable local capacity. Our comparative evaluation against Google Translate reveals competitive performance in several languages while identifying areas that require continued development.",
            "score": 6,
            "issue_id": 6327,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "9dc4aa03a2c96864",
            "authors": [
                "Sheriff Issaka",
                "Keyi Wang",
                "Yinka Ajibola",
                "Oluwatumininu Samuel-Ipaye",
                "Zhaoyi Zhang",
                "Nicte Aguillon Jimenez",
                "Evans Kofi Agyei",
                "Abraham Lin",
                "Rohan Ramachandran",
                "Sadick Abdul Mumin",
                "Faith Nchifor",
                "Mohammed Shuraim",
                "Lieqi Liu",
                "Erick Rosas Gonzalez",
                "Sylvester Kpei",
                "Jemimah Osei",
                "Carlene Ajeneza",
                "Persis Boateng",
                "Prisca Adwoa Dufie Yeboah",
                "Saadia Gabriel"
            ],
            "affiliations": [
                "Carleton University",
                "Columbia University",
                "Cornell University",
                "Georgia Institute of Technology",
                "Northwestern University in Qatar",
                "Soka University of America",
                "Stetson University",
                "University of California, Los Angeles",
                "University of Cape Coast",
                "University of Wisconsin - Madison"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.05644.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#training",
                    "#data",
                    "#multilingual",
                    "#low_resource"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "Африканские языки выходят из тени: масштабный датасет для NLP",
                    "desc": "Исследователи создали African Languages Lab для решения проблемы недостаточной представленности африканских языков в NLP технологиях. Они собрали крупнейший валидированный мультимодальный датасет, охватывающий 40 африканских языков с 19 миллиардами токенов текста и 12,628 часами речевых данных. Fine-tuning моделей на этом датасете показал впечатляющие улучшения: в среднем +23.69 ChrF++, +0.33 COMET и +15.34 BLEU по сравнению с базовыми моделями. Проект также включает программу наставничества для местных исследователей, создавая устойчивую экспертизу в регионе."
                },
                "en": {
                    "title": "Empowering African Languages in NLP",
                    "desc": "The African Languages Lab (All Lab) aims to improve the representation of African languages in natural language processing (NLP) by creating a large, high-quality dataset. This dataset includes 19 billion tokens of text and over 12,000 hours of speech data across 40 languages, addressing the significant underrepresentation of these languages in computational linguistics. The paper demonstrates that fine-tuning models with this dataset leads to notable performance improvements, with average increases in evaluation metrics like BLEU and ChrF++. Additionally, the initiative supports local researchers, fostering sustainable development in the field of NLP for African languages."
                },
                "zh": {
                    "title": "提升非洲语言处理能力的创新之路",
                    "desc": "非洲语言实验室旨在解决非洲语言在自然语言处理（NLP）中的不足，通过创建一个大型数据集并展示模型性能的提升。该实验室收集了40种语言的多模态语音和文本数据，包含190亿个单语文本和12628小时的对齐语音数据。通过对数据集的精细调优，实验结果显示在31种语言上，模型性能显著提升，平均提高了23.69 ChrF++、0.33 COMET和15.34 BLEU分数。此外，实验室还成功培养了15名早期职业研究人员，建立了可持续的本地能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07313",
            "title": "WristWorld: Generating Wrist-Views via 4D World Models for Robotic\n  Manipulation",
            "url": "https://huggingface.co/papers/2510.07313",
            "abstract": "WristWorld is a 4D world model that generates wrist-view videos from anchor views, improving video generation consistency and VLA performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Wrist-view observations are crucial for VLA models as they capture fine-grained hand-object interactions that directly enhance manipulation performance. Yet large-scale datasets rarely include such recordings, resulting in a substantial gap between abundant anchor views and scarce wrist views. Existing world models cannot bridge this gap, as they require a wrist-view first frame and thus fail to generate wrist-view videos from anchor views alone. Amid this gap, recent visual geometry models such as VGGT emerge with geometric and cross-view priors that make it possible to address extreme viewpoint shifts. Inspired by these insights, we propose WristWorld, the first 4D world model that generates wrist-view videos solely from anchor views. WristWorld operates in two stages: (i) Reconstruction, which extends VGGT and incorporates our Spatial Projection Consistency (SPC) Loss to estimate geometrically consistent wrist-view poses and 4D point clouds; (ii) Generation, which employs our video generation model to synthesize temporally coherent wrist-view videos from the reconstructed perspective. Experiments on Droid, Calvin, and Franka Panda demonstrate state-of-the-art video generation with superior spatial consistency, while also improving VLA performance, raising the average task completion length on Calvin by 3.81% and closing 42.4% of the anchor-wrist view gap.",
            "score": 5,
            "issue_id": 6322,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "72337b6fb9bb399b",
            "authors": [
                "Zezhong Qian",
                "Xiaowei Chi",
                "Yuming Li",
                "Shizun Wang",
                "Zhiyuan Qin",
                "Xiaozhu Ju",
                "Sirui Han",
                "Shanghang Zhang"
            ],
            "affiliations": [
                "Beijing Innovation Center of Humanoid Robotics",
                "Hong Kong University of Science and Technology",
                "National University of Singapore",
                "State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07313.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#synthetic",
                    "#cv",
                    "#video"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Генерация видео с запястья из обычных камер для роботов",
                    "desc": "WristWorld — это 4D модель мира, которая генерирует видео с точки зрения запястья робота, используя только записи с обычных стационарных камер. Модель работает в два этапа: сначала реконструирует геометрически согласованную 4D сцену с новой позицией камеры, затем генерирует временно связное видео. Видео с запястья критически важны для VLA моделей, так как фиксируют детальные взаимодействия руки с объектами, но такие данные редко присутствуют в датасетах. Эксперименты показали улучшение качества генерации видео и повышение производительности VLA на 3.81% в задачах манипуляции."
                },
                "en": {
                    "title": "Bridging the Gap: Generating Wrist-View Videos from Anchor Views",
                    "desc": "WristWorld is a novel 4D world model designed to generate wrist-view videos from anchor views, addressing the challenge of limited wrist-view data in video generation. It enhances video generation consistency and improves Visual Language Action (VLA) performance by capturing detailed hand-object interactions. The model operates in two stages: first, it reconstructs wrist-view poses and 4D point clouds using a Spatial Projection Consistency (SPC) Loss, and second, it synthesizes coherent wrist-view videos from these reconstructions. Experiments show that WristWorld achieves state-of-the-art results in video generation, significantly improving task completion rates and bridging the gap between anchor and wrist views."
                },
                "zh": {
                    "title": "WristWorld：从锚点视图生成手腕视角视频的创新模型",
                    "desc": "WristWorld是一个4D世界模型，能够从锚点视图生成手腕视角的视频，提升视频生成的一致性和VLA性能。手腕视角的观察对于VLA模型至关重要，因为它们捕捉到细致的手与物体的交互，直接增强了操作性能。现有的世界模型无法弥补锚点视图与手腕视图之间的差距，因为它们需要手腕视角的第一帧。WristWorld通过重建和生成两个阶段，利用空间投影一致性损失和视频生成模型，成功合成了时间上连贯的手腕视角视频。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.01982",
            "title": "G^2RPO: Granular GRPO for Precise Reward in Flow Models",
            "url": "https://huggingface.co/papers/2510.01982",
            "abstract": "A novel Granular-GRPO framework enhances reinforcement learning in diffusion and flow models by improving reward assessment and reducing bias in denoising.  \t\t\t\t\tAI-generated summary \t\t\t\t The integration of online reinforcement learning (RL) into diffusion and flow models has recently emerged as a promising approach for aligning generative models with human preferences. Stochastic sampling via Stochastic Differential Equations (SDE) is employed during the denoising process to generate diverse denoising directions for RL exploration. While existing methods effectively explore potential high-value samples, they suffer from sub-optimal preference alignment due to sparse and narrow reward signals. To address these challenges, we propose a novel Granular-GRPO (G^2RPO ) framework that achieves precise and comprehensive reward assessments of sampling directions in reinforcement learning of flow models. Specifically, a Singular Stochastic Sampling strategy is introduced to support step-wise stochastic exploration while enforcing a high correlation between the reward and the injected noise, thereby facilitating a faithful reward for each SDE perturbation. Concurrently, to eliminate the bias inherent in fixed-granularity denoising, we introduce a Multi-Granularity Advantage Integration module that aggregates advantages computed at multiple diffusion scales, producing a more comprehensive and robust evaluation of the sampling directions. Experiments conducted on various reward models, including both in-domain and out-of-domain evaluations, demonstrate that our G^2RPO significantly outperforms existing flow-based GRPO baselines,highlighting its effectiveness and robustness.",
            "score": 5,
            "issue_id": 6324,
            "pub_date": "2025-10-02",
            "pub_date_card": {
                "ru": "2 октября",
                "en": "October 2",
                "zh": "10月2日"
            },
            "hash": "76076ef0cec86cef",
            "authors": [
                "Yujie Zhou",
                "Pengyang Ling",
                "Jiazi Bu",
                "Yibin Wang",
                "Yuhang Zang",
                "Jiaqi Wang",
                "Li Niu",
                "Guangtao Zhai"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "Shanghai Jiao Tong University",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.01982.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#alignment",
                    "#rlhf",
                    "#diffusion",
                    "#optimization",
                    "#training",
                    "#rl"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Точная настройка диффузионных моделей через мультимасштабное обучение с подкреплением",
                    "desc": "Статья представляет новый фреймворк Granular-GRPO для улучшения обучения с подкреплением в диффузионных моделях и flow-based моделях. Основная проблема существующих методов заключается в разреженных и узких сигналах вознаграждения, что приводит к неоптимальному выравниванию с предпочтениями. Авторы предлагают стратегию Singular Stochastic Sampling для точной оценки вознаграждения на каждом шаге и модуль Multi-Granularity Advantage Integration для агрегации преимуществ на разных масштабах диффузии. Эксперименты показывают значительное превосходство G^2RPO над базовыми методами как на внутридоменных, так и на кросс-доменных задачах."
                },
                "en": {
                    "title": "Enhancing Reward Assessment in Reinforcement Learning with Granular-GRPO",
                    "desc": "The Granular-GRPO (G^2RPO) framework enhances reinforcement learning (RL) in diffusion and flow models by improving how rewards are assessed and reducing bias during the denoising process. It utilizes Stochastic Differential Equations (SDE) for stochastic sampling, allowing for diverse exploration of denoising directions. The framework introduces a Singular Stochastic Sampling strategy to ensure that rewards are closely aligned with the noise introduced, leading to better reward signals. Additionally, a Multi-Granularity Advantage Integration module aggregates advantages from different diffusion scales, resulting in a more accurate evaluation of sampling directions and improved performance over existing methods."
                },
                "zh": {
                    "title": "提升强化学习的Granular-GRPO框架",
                    "desc": "本文提出了一种新颖的Granular-GRPO框架，旨在增强扩散和流模型中的强化学习。该框架通过改进奖励评估和减少去噪中的偏差，提升了生成模型与人类偏好的对齐。我们引入了单一随机采样策略，以支持逐步随机探索，并确保奖励与注入噪声之间的高相关性。实验结果表明，G^2RPO在多种奖励模型上显著优于现有的基于流的GRPO基线，展示了其有效性和鲁棒性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07307",
            "title": "MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline",
            "url": "https://huggingface.co/papers/2510.07307",
            "abstract": "MLE-Smith automates the creation of high-quality, diverse MLE tasks from raw datasets using a multi-agent pipeline, improving scalability and maintaining task quality.  \t\t\t\t\tAI-generated summary \t\t\t\t While Language Models (LMs) have made significant progress in automating machine learning engineering (MLE), the acquisition of high-quality MLE training data is significantly constrained. Current MLE benchmarks suffer from low scalability and limited applicability because they rely on static, manually curated tasks, demanding extensive time and manual effort to produce. We introduce MLE-Smith, a fully automated multi-agent pipeline, to transform raw datasets into competition-style MLE challenges through an efficient generate-verify-execute paradigm for scaling MLE tasks with verifiable quality, real-world usability, and rich diversity. The proposed multi-agent pipeline in MLE-Smith drives structured task design and standardized refactoring, coupled with a hybrid verification mechanism that enforces strict structural rules and high-level semantic soundness. It further validates empirical solvability and real-world fidelity through interactive execution. We apply MLE-Smith to 224 of real-world datasets and generate 606 tasks spanning multiple categories, objectives, and modalities, demonstrating that MLE-Smith can work effectively across a wide range of real-world datasets. Evaluation on the generated tasks shows that the performance of eight mainstream and cutting-edge LLMs on MLE-Smith tasks is strongly correlated with their performance on carefully human-designed tasks, highlighting the effectiveness of the MLE-Smith to scaling up MLE tasks, while maintaining task quality.",
            "score": 4,
            "issue_id": 6322,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "3cffdc5a57565890",
            "authors": [
                "Rushi Qiang",
                "Yuchen Zhuang",
                "Anikait Singh",
                "Percy Liang",
                "Chao Zhang",
                "Sherry Yang",
                "Bo Dai"
            ],
            "affiliations": [
                "Georgia Institute of Technology",
                "Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07307.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#optimization",
                    "#dataset",
                    "#benchmark",
                    "#data",
                    "#agents"
                ],
                "emoji": "🏭",
                "ru": {
                    "title": "Автоматическая фабрика ML-задач из сырых данных",
                    "desc": "Статья представляет MLE-Smith — полностью автоматизированный мульти-агентный пайплайн для создания качественных задач по машинному обучению из сырых датасетов. Система использует парадигму генерация-верификация-исполнение для масштабирования задач с проверяемым качеством и разнообразием. Применение MLE-Smith к 224 реальным датасетам позволило создать 606 разнообразных задач, охватывающих множество категорий и модальностей. Эксперименты показали, что производительность восьми современных LLM на сгенерированных задачах сильно коррелирует с их результатами на задачах, созданных вручную, что подтверждает эффективность автоматизированного подхода."
                },
                "en": {
                    "title": "Automating Diverse MLE Tasks with MLE-Smith",
                    "desc": "MLE-Smith is a novel automated system designed to create diverse and high-quality machine learning engineering (MLE) tasks from raw datasets. It utilizes a multi-agent pipeline that follows a generate-verify-execute approach, ensuring that the tasks produced are scalable and maintain rigorous quality standards. The system incorporates a hybrid verification mechanism to uphold structural integrity and semantic accuracy, while also confirming the tasks' practical applicability through interactive execution. By applying MLE-Smith to numerous real-world datasets, the study demonstrates its capability to generate a wide variety of tasks that align well with the performance of existing language models."
                },
                "zh": {
                    "title": "MLE-Smith：自动化高质量机器学习任务的利器",
                    "desc": "MLE-Smith 是一个自动化的多智能体管道，能够从原始数据集中创建高质量、多样化的机器学习工程（MLE）任务。它通过生成-验证-执行的高效范式，提升了任务的可扩展性，同时确保了任务的质量和实际应用性。该系统采用结构化任务设计和标准化重构，并结合混合验证机制，确保任务的结构规则和语义合理性。通过在224个真实数据集上应用MLE-Smith，生成了606个跨多个类别和目标的任务，验证了其在真实世界数据集上的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06953",
            "title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning\n  Traces",
            "url": "https://huggingface.co/papers/2510.06953",
            "abstract": "Step-level uniformity in information density, measured using entropy-based metrics, improves reasoning accuracy in large language models across various benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stable flow of information. In this work, we revisit this principle in the context of large language model (LLM) reasoning traces, asking whether step-level uniformity reflects reasoning quality. To this end, we propose an entropy-based stepwise information density metric and introduce two complementary measures of uniformity, local and global uniformity scores. Across the experiments on six different reasoning benchmarks, we find that step-level uniformity not only provides a strong theoretical lens but also yields practical performance benefits; for example, selecting reasoning traces with more uniform information density at the step-level improves accuracy by 10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals that correct reasoning traces tend to avoid sharp information density spikes, while incorrect traces exhibit irregular information bursts. These results demonstrate that UID-inspired information density measures outperform alternative internal signals as predictors of reasoning quality. Results highlight the uniformity of the information density as a robust diagnostic and selection criterion for building more reliable and accurate reasoning systems.",
            "score": 4,
            "issue_id": 6331,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "f4a84fa12f0087d2",
            "authors": [
                "Minju Gwak",
                "Guijin Son",
                "Jaehyung Kim"
            ],
            "affiliations": [
                "OneLine AI",
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06953.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "📊",
                "ru": {
                    "title": "Равномерность информации — ключ к точности рассуждений LLM",
                    "desc": "Исследователи применили гипотезу равномерной плотности информации (UID) к анализу цепочек рассуждений больших языковых моделей. Они предложили метрику на основе энтропии для измерения плотности информации на каждом шаге рассуждения и ввели локальные и глобальные оценки равномерности. Эксперименты на шести бенчмарках показали, что выбор цепочек рассуждений с более равномерным распределением информации повышает точность на 10-32% по сравнению с базовыми подходами. Корректные рассуждения избегают резких скачков плотности информации, в то время как ошибочные демонстрируют нерегулярные всплески, что делает равномерность надёжным критерием для построения более точных систем рассуждений."
                },
                "en": {
                    "title": "Boosting Reasoning Accuracy with Uniform Information Density",
                    "desc": "This paper explores the Uniform Information Density (UID) hypothesis, which posits that effective communication has a consistent flow of information. The authors introduce a new metric based on entropy to measure step-level information density in large language models (LLMs). They find that maintaining uniformity in information density significantly enhances reasoning accuracy across various benchmarks, with improvements of 10-32% over existing methods. The study concludes that uniform information density is a valuable indicator for assessing and improving the reasoning capabilities of LLMs."
                },
                "zh": {
                    "title": "信息密度均匀性提升推理准确性",
                    "desc": "本文探讨了信息密度的均匀性对大型语言模型推理准确性的影响。我们提出了一种基于熵的逐步信息密度度量，并引入了局部和全局均匀性评分。实验结果表明，逐步均匀性不仅在理论上具有重要意义，还能在多个推理基准上显著提高模型的准确性。我们的分析显示，正确的推理轨迹避免了信息密度的剧烈波动，而错误的轨迹则表现出不规则的信息爆发。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06855",
            "title": "Online Generic Event Boundary Detection",
            "url": "https://huggingface.co/papers/2510.06855",
            "abstract": "A novel framework for real-time event boundary detection in streaming videos uses prediction and error measurement to identify subtle event changes.  \t\t\t\t\tAI-generated summary \t\t\t\t Generic Event Boundary Detection (GEBD) aims to interpret long-form videos through the lens of human perception. However, current GEBD methods require processing complete video frames to make predictions, unlike humans processing data online and in real-time. To bridge this gap, we introduce a new task, Online Generic Event Boundary Detection (On-GEBD), aiming to detect boundaries of generic events immediately in streaming videos. This task faces unique challenges of identifying subtle, taxonomy-free event changes in real-time, without the access to future frames. To tackle these challenges, we propose a novel On-GEBD framework, Estimator, inspired by Event Segmentation Theory (EST) which explains how humans segment ongoing activity into events by leveraging the discrepancies between predicted and actual information. Our framework consists of two key components: the Consistent Event Anticipator (CEA), and the Online Boundary Discriminator (OBD). Specifically, the CEA generates a prediction of the future frame reflecting current event dynamics based solely on prior frames. Then, the OBD measures the prediction error and adaptively adjusts the threshold using statistical tests on past errors to capture diverse, subtle event transitions. Experimental results demonstrate that Estimator outperforms all baselines adapted from recent online video understanding models and achieves performance comparable to prior offline-GEBD methods on the Kinetics-GEBD and TAPOS datasets.",
            "score": 3,
            "issue_id": 6325,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "fe5f12618eba61f3",
            "authors": [
                "Hyungrok Jung",
                "Daneul Kim",
                "Seunggyun Lim",
                "Jeany Son",
                "Jonghyun Choi"
            ],
            "affiliations": [
                "GIST",
                "POSTECH",
                "Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06855.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#video",
                    "#benchmark",
                    "#long_context"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "Распознавание границ событий в видео в реальном времени через предсказание и ошибку",
                    "desc": "Статья представляет новую задачу Online Generic Event Boundary Detection (On-GEBD) — обнаружение границ событий в потоковом видео в режиме реального времени, без доступа к будущим кадрам. Предложенный фреймворк Estimator основан на теории сегментации событий и состоит из двух компонентов: модуль предсказания будущего кадра на основе прошлых данных и модуль измерения ошибки предсказания для детекции границ. Система адаптивно настраивает пороги обнаружения с помощью статистических тестов на основе истории ошибок, что позволяет улавливать разнообразные и тонкие переходы между событиями. Эксперименты показывают, что метод превосходит базовые модели онлайн-анализа видео и достигает результатов, сопоставимых с офлайн-методами на датасетах Kinetics-GEBD и TAPOS."
                },
                "en": {
                    "title": "Real-Time Event Detection: Bridging Human Perception and Machine Learning",
                    "desc": "This paper presents a new approach for detecting event boundaries in streaming videos, called Online Generic Event Boundary Detection (On-GEBD). Unlike traditional methods that analyze complete video frames, this framework processes video data in real-time, mimicking human perception. The proposed On-GEBD framework, named Estimator, utilizes two main components: the Consistent Event Anticipator (CEA) for predicting future frames and the Online Boundary Discriminator (OBD) for measuring prediction errors. Experimental results show that Estimator significantly outperforms existing models and achieves results comparable to offline methods, highlighting its effectiveness in identifying subtle event changes in dynamic video streams."
                },
                "zh": {
                    "title": "实时事件边界检测的新框架",
                    "desc": "本文提出了一种新颖的实时事件边界检测框架，旨在处理流媒体视频中的细微事件变化。与传统的通用事件边界检测方法不同，该框架能够在线实时识别事件边界，而无需访问未来帧。框架的核心包括一致事件预测器（CEA）和在线边界判别器（OBD），前者基于过去帧预测未来帧，后者则通过测量预测误差来调整阈值。实验结果表明，该框架在Kinetics-GEBD和TAPOS数据集上表现优于现有的在线视频理解模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04999",
            "title": "Bridging Text and Video Generation: A Survey",
            "url": "https://huggingface.co/papers/2510.04999",
            "abstract": "A survey of text-to-video generative models from GANs and VAEs to hybrid Diffusion-Transformer architectures, detailing their development, limitations, and future directions.  \t\t\t\t\tAI-generated summary \t\t\t\t Text-to-video (T2V) generation technology holds potential to transform multiple domains such as education, marketing, entertainment, and assistive technologies for individuals with visual or reading comprehension challenges, by creating coherent visual content from natural language prompts. From its inception, the field has advanced from adversarial models to diffusion-based models, yielding higher-fidelity, temporally consistent outputs. Yet challenges persist, such as alignment, long-range coherence, and computational efficiency. Addressing this evolving landscape, we present a comprehensive survey of text-to-video generative models, tracing their development from early GANs and VAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these models work, what limitations they addressed in their predecessors, and why shifts toward new architectural paradigms were necessary to overcome challenges in quality, coherence, and control. We provide a systematic account of the datasets, which the surveyed text-to-video models were trained and evaluated on, and, to support reproducibility and assess the accessibility of training such models, we detail their training configurations, including their hardware specifications, GPU counts, batch sizes, learning rates, optimizers, epochs, and other key hyperparameters. Further, we outline the evaluation metrics commonly used for evaluating such models and present their performance across standard benchmarks, while also discussing the limitations of these metrics and the emerging shift toward more holistic, perception-aligned evaluation strategies. Finally, drawing from our analysis, we outline the current open challenges and propose a few promising future directions, laying out a perspective for future researchers to explore and build upon in advancing T2V research and applications.",
            "score": 3,
            "issue_id": 6321,
            "pub_date": "2025-10-06",
            "pub_date_card": {
                "ru": "6 октября",
                "en": "October 6",
                "zh": "10月6日"
            },
            "hash": "2ff1fd3dd4354c0a",
            "authors": [
                "Nilay Kumar",
                "Priyansh Bhandari",
                "G. Maragatham"
            ],
            "affiliations": [
                "Department of Computational Intelligence SRM Institute of Science and Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04999.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#video",
                    "#diffusion",
                    "#survey"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "От GAN к Diffusion: эволюция генерации видео из текста",
                    "desc": "Статья представляет обзор моделей генерации видео из текста (text-to-video), прослеживая их развитие от ранних GAN и VAE до современных гибридных Diffusion-Transformer архитектур. Авторы детально анализируют принципы работы этих моделей, ограничения предшественников и причины перехода к новым архитектурным парадигмам для улучшения качества, согласованности и контроля. Особое внимание уделяется датасетам, конфигурациям обучения, метрикам оценки и их ограничениям, а также сравнению производительности моделей на стандартных бенчмарках. В заключение обсуждаются текущие открытые проблемы, включая выравнивание с текстом, долгосрочную когерентность и вычислительную эффективность, и предлагаются перспективные направления будущих исследований."
                },
                "en": {
                    "title": "Transforming Text into Video: A Journey Through Generative Models",
                    "desc": "This paper surveys the evolution of text-to-video (T2V) generative models, highlighting the transition from Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) to advanced Diffusion-Transformer architectures. It discusses the potential applications of T2V technology in various fields and the improvements in output quality and coherence achieved through these newer models. The paper also addresses ongoing challenges such as alignment, long-range coherence, and computational efficiency, while providing insights into training configurations and evaluation metrics used in the field. Finally, it outlines future research directions and open challenges to guide further advancements in T2V generation."
                },
                "zh": {
                    "title": "文本生成视频技术的未来探索",
                    "desc": "本文对文本生成视频（T2V）模型进行了全面的调查，涵盖了从对抗生成网络（GANs）和变分自编码器（VAEs）到混合扩散-变换器架构的发展历程。尽管该领域已经取得了显著进展，但仍面临对齐、长时间一致性和计算效率等挑战。我们详细介绍了这些模型的工作原理、解决的局限性以及为何需要向新架构范式转变。最后，我们提出了当前的开放挑战和未来的研究方向，以推动T2V技术的发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06261",
            "title": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into\n  a Self-Evolving System for Deep Agentic Reasoning",
            "url": "https://huggingface.co/papers/2510.06261",
            "abstract": "AlphaApollo, a self-evolving reasoning system, enhances foundation model performance through tool integration and iterative refinement, achieving significant improvements in accuracy and pass rates.  \t\t\t\t\tAI-generated summary \t\t\t\t We present AlphaApollo, a self-evolving agentic reasoning system that aims to address two bottlenecks in foundation model (FM) reasoning-limited model-intrinsic capacity and unreliable test-time iteration. AlphaApollo orchestrates multiple models with professional tools to enable deliberate, verifiable reasoning. It couples (i) a computation tool (Python with numerical and symbolic libraries) and (ii) a retrieval tool (task-relevant external information) to execute exact calculations and ground decisions. The system further supports multi-round, multi-model solution evolution via a shared state map that records candidates, executable checks, and feedback for iterative refinement. In evaluations on AIME 2024/2025 across multiple models, AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32 for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool calls are successfully executed, with consistent outperformance of non-tool baselines, thereby lifting the capability ceiling of FMs. More empirical results and implementation details will be updated at https://github.com/tmlr-group/AlphaApollo.",
            "score": 3,
            "issue_id": 6322,
            "pub_date": "2025-10-05",
            "pub_date_card": {
                "ru": "5 октября",
                "en": "October 5",
                "zh": "10月5日"
            },
            "hash": "d4056c4e12881117",
            "authors": [
                "Zhanke Zhou",
                "Chentao Cao",
                "Xiao Feng",
                "Xuan Li",
                "Zongze Li",
                "Xiangyu Lu",
                "Jiangchao Yao",
                "Weikai Huang",
                "Linrui Xu",
                "Tian Cheng",
                "Guanyu Jiang",
                "Yiming Zheng",
                "Brando Miranda",
                "Tongliang Liu",
                "Sanmi Koyejo",
                "Masashi Sugiyama",
                "Bo Han"
            ],
            "affiliations": [
                "Cooperative Medianet Innovation Center, Shanghai Jiao Tong University",
                "RIKEN AIP",
                "Stanford University",
                "Sydney AI Centre, The University of Sydney",
                "TMLR Group, Department of Computer Science, Hong Kong Baptist University",
                "The University of Tokyo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06261.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#training",
                    "#agents"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Самоэволюция через инструменты: AlphaApollo поднимает потолок возможностей LLM",
                    "desc": "AlphaApollo — это самообучающаяся система агентного рассуждения, которая решает две ключевые проблемы foundation models: ограниченные внутренние возможности модели и ненадёжную итерацию во время тестирования. Система объединяет несколько моделей с профессиональными инструментами — Python для вычислений и retrieval для извлечения релевантной информации — что обеспечивает проверяемые рассуждения. AlphaApollo поддерживает многораундовую эволюцию решений через общую карту состояний, которая записывает кандидатов, проверки и обратную связь для итеративного улучшения. На бенчмарке AIME 2024/2025 система показала значительный прирост точности: +5.15% Average@32 и +23.34% Pass@32 для Qwen2.5-14B-Instruct, при этом более 80% обращений к инструментам выполняются успешно."
                },
                "en": {
                    "title": "Elevating Foundation Models with Self-Evolving Reasoning",
                    "desc": "AlphaApollo is a self-evolving reasoning system designed to improve the performance of foundation models (FMs) by integrating various tools and refining its processes iteratively. It addresses limitations in the intrinsic reasoning capacity of models and enhances reliability during testing by using a combination of computational and retrieval tools. The system allows for multi-round solution evolution, maintaining a shared state map that tracks candidates and feedback for continuous improvement. In evaluations, AlphaApollo demonstrated significant performance gains across multiple models, showcasing its ability to effectively utilize tools and surpass traditional baselines."
                },
                "zh": {
                    "title": "自我进化的推理系统，提升基础模型性能",
                    "desc": "AlphaApollo 是一个自我进化的推理系统，通过工具集成和迭代优化来提升基础模型的性能。它解决了基础模型推理中的两个瓶颈：模型内在能力有限和测试时迭代不可靠。该系统结合了计算工具（如 Python 及其数值和符号库）和检索工具（相关外部信息），以执行精确计算和做出基于证据的决策。通过共享状态图记录候选项、可执行检查和反馈，AlphaApollo 支持多轮、多模型的解决方案演化，显著提高了准确性和通过率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07041",
            "title": "U-Bench: A Comprehensive Understanding of U-Net through 100-Variant\n  Benchmarking",
            "url": "https://huggingface.co/papers/2510.07041",
            "abstract": "U-Bench is a comprehensive benchmark evaluating 100 U-Net variants across 28 datasets and 10 imaging modalities, focusing on statistical robustness, zero-shot generalization, and computational efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t Over the past decade, U-Net has been the dominant architecture in medical image segmentation, leading to the development of thousands of U-shaped variants. Despite its widespread adoption, there is still no comprehensive benchmark to systematically evaluate their performance and utility, largely because of insufficient statistical validation and limited consideration of efficiency and generalization across diverse datasets. To bridge this gap, we present U-Bench, the first large-scale, statistically rigorous benchmark that evaluates 100 U-Net variants across 28 datasets and 10 imaging modalities. Our contributions are threefold: (1) Comprehensive Evaluation: U-Bench evaluates models along three key dimensions: statistical robustness, zero-shot generalization, and computational efficiency. We introduce a novel metric, U-Score, which jointly captures the performance-efficiency trade-off, offering a deployment-oriented perspective on model progress. (2) Systematic Analysis and Model Selection Guidance: We summarize key findings from the large-scale evaluation and systematically analyze the impact of dataset characteristics and architectural paradigms on model performance. Based on these insights, we propose a model advisor agent to guide researchers in selecting the most suitable models for specific datasets and tasks. (3) Public Availability: We provide all code, models, protocols, and weights, enabling the community to reproduce our results and extend the benchmark with future methods. In summary, U-Bench not only exposes gaps in previous evaluations but also establishes a foundation for fair, reproducible, and practically relevant benchmarking in the next decade of U-Net-based segmentation models. The project can be accessed at: https://fenghetan9.github.io/ubench. Code is available at: https://github.com/FengheTan9/U-Bench.",
            "score": 2,
            "issue_id": 6321,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "382dc490ec7534fd",
            "authors": [
                "Fenghe Tang",
                "Chengqi Dong",
                "Wenxin Ma",
                "Zikang Xu",
                "Heqin Zhu",
                "Zihang Jiang",
                "Rongsheng Wang",
                "Yuhao Wang",
                "Chenxu Wu",
                "Shaohua Kevin Zhou"
            ],
            "affiliations": [
                "HCNS",
                "MIRACLE Center",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07041.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#open_source",
                    "#dataset",
                    "#benchmark",
                    "#optimization",
                    "#survey"
                ],
                "emoji": "🏥",
                "ru": {
                    "title": "U-Bench: всесторонний бенчмарк для U-Net архитектур в медицинской сегментации",
                    "desc": "U-Bench представляет собой первый масштабный бенчмарк для систематической оценки U-Net архитектур в медицинской сегментации изображений. Исследователи протестировали 100 вариантов U-Net на 28 датасетах и 10 типах медицинских изображений, оценивая статистическую надёжность, zero-shot обобщение и вычислительную эффективность. Введена новая метрика U-Score, которая учитывает баланс между производительностью и эффективностью моделей. На основе результатов создан агент-советник для помощи исследователям в выборе оптимальной модели под конкретную задачу."
                },
                "en": {
                    "title": "U-Bench: A New Standard for Evaluating U-Net Models in Medical Imaging",
                    "desc": "U-Bench is a new benchmark designed to evaluate 100 different U-Net models across 28 datasets and 10 types of imaging. It focuses on three main areas: how robust the models are statistically, how well they can generalize to new data without prior training (zero-shot), and how efficient they are in terms of computation. The benchmark introduces a unique metric called U-Score, which helps to balance performance and efficiency, making it easier to choose the right model for specific tasks. By providing comprehensive evaluations and public access to resources, U-Bench aims to improve the way U-Net models are assessed and utilized in medical image segmentation."
                },
                "zh": {
                    "title": "U-Bench：U-Net变体的全面评估基准",
                    "desc": "U-Bench是一个全面的基准测试，评估100种U-Net变体在28个数据集和10种成像模式下的表现，重点关注统计稳健性、零样本泛化和计算效率。该基准测试填补了以往缺乏系统评估的空白，提供了一个新的度量标准U-Score，帮助研究者理解性能与效率之间的权衡。通过系统分析数据集特征和模型架构对性能的影响，U-Bench为研究者提供了模型选择的指导。所有代码、模型和协议均已公开，促进了社区的再现性和未来方法的扩展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07037",
            "title": "Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era\n  of Large Language Models",
            "url": "https://huggingface.co/papers/2510.07037",
            "abstract": "This survey analyzes the current state of code-switching aware large language models, highlighting advancements and challenges in multilingual NLP.  \t\t\t\t\tAI-generated summary \t\t\t\t Code-switching (CSW), the alternation of languages and scripts within a single utterance, remains a fundamental challenge for multiling ual NLP, even amidst the rapid advances of large language models (LLMs). Most LLMs still struggle with mixed-language inputs, limited CSW datasets, and evaluation biases, hindering deployment in multilingual societies. This survey provides the first comprehensive analysis of CSW-aware LLM research, reviewing unique_references studies spanning five research areas, 12 NLP tasks, 30+ datasets, and 80+ languages. We classify recent advances by architecture, training strategy, and evaluation methodology, outlining how LLMs have reshaped CSW modeling and what challenges persist. The paper concludes with a roadmap emphasizing the need for inclusive datasets, fair evaluation, and linguistically grounded models to achieve truly multilingual intelligence. A curated collection of all resources is maintained at https://github.com/lingo-iitgn/awesome-code-mixing/.",
            "score": 2,
            "issue_id": 6325,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "dcf8b5cd9f394b07",
            "authors": [
                "Rajvee Sheth",
                "Samridhi Raj Sinha",
                "Mahavir Patil",
                "Himanshu Beniwal",
                "Mayank Singh"
            ],
            "affiliations": [
                "IIT Gandhinagar",
                "LINGO Research Group",
                "NMIMS Mumbai",
                "SVNIT Surat"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07037.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#multilingual",
                    "#architecture",
                    "#benchmark",
                    "#survey",
                    "#dataset",
                    "#low_resource"
                ],
                "emoji": "🔀",
                "ru": {
                    "title": "Переключение языков: вызов для современных LLM",
                    "desc": "Статья представляет собой обзор современного состояния больших языковых моделей (LLM), способных работать с переключением кодов — явлением, когда в одном высказывании смешиваются разные языки. Несмотря на прогресс в области LLM, большинство моделей всё ещё испытывают трудности с обработкой смешанных языковых входов из-за ограниченных датасетов и предвзятости в методах оценки. Авторы проанализировали исследования в пяти областях, охватывающих 12 NLP-задач, более 30 датасетов и более 80 языков, классифицируя достижения по архитектуре, стратегиям обучения и методологии оценки. В заключении предложена дорожная карта развития, подчёркивающая необходимость инклюзивных датасетов, справедливой оценки и лингвистически обоснованных моделей для достижения настоящего мультиязычного интеллекта."
                },
                "en": {
                    "title": "Navigating Code-Switching: Challenges and Advances in Multilingual NLP",
                    "desc": "This survey examines the progress and obstacles faced by large language models (LLMs) in handling code-switching, which is the mixing of languages in communication. It highlights that despite advancements, many LLMs still have difficulties with mixed-language inputs due to a lack of diverse datasets and evaluation methods. The paper reviews a wide range of studies across various NLP tasks and languages, categorizing recent improvements in model architecture and training strategies. It emphasizes the importance of developing inclusive datasets and fair evaluation practices to enhance multilingual capabilities in AI."
                },
                "zh": {
                    "title": "推动多语言智能的代码切换研究",
                    "desc": "这篇调查论文分析了对代码切换（CSW）敏感的大型语言模型的现状，强调了多语言自然语言处理（NLP）的进展和挑战。尽管大型语言模型（LLMs）迅速发展，但它们在处理混合语言输入、有限的CSW数据集和评估偏见方面仍然面临困难。论文提供了对CSW敏感LLM研究的首次全面分析，涵盖了五个研究领域、12个NLP任务、30多个数据集和80多种语言。最后，论文提出了一个路线图，强调需要包容性数据集、公平评估和基于语言学的模型，以实现真正的多语言智能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06673",
            "title": "Heptapod: Language Modeling on Visual Signals",
            "url": "https://huggingface.co/papers/2510.06673",
            "abstract": "Heptapod, an image autoregressive model using causal attention and next 2D distribution prediction, achieves superior performance on ImageNet generation by combining sequential modeling with holistic self-supervised learning.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Heptapod, an image autoregressive model that adheres to the foundational principles of language modeling. Heptapod employs causal attention, eliminates reliance on CFG, and eschews the trend of semantic tokenizers. Our key innovation is next 2D distribution prediction: a causal Transformer with reconstruction-focused visual tokenizer, learns to predict the distribution over the entire 2D spatial grid of images at each timestep. This learning objective unifies the sequential modeling of autoregressive framework with the holistic self-supervised learning of masked autoencoding, enabling the model to capture comprehensive image semantics via generative training. On the ImageNet generation benchmark, Heptapod achieves an FID of 2.70, significantly outperforming previous causal autoregressive approaches. We hope our work inspires a principled rethinking of language modeling on visual signals and beyond.",
            "score": 2,
            "issue_id": 6326,
            "pub_date": "2025-10-08",
            "pub_date_card": {
                "ru": "8 октября",
                "en": "October 8",
                "zh": "10月8日"
            },
            "hash": "19f2468fce496409",
            "authors": [
                "Yongxin Zhu",
                "Jiawei Chen",
                "Yuanzhe Chen",
                "Zhuo Chen",
                "Dongya Jia",
                "Jian Cong",
                "Xiaobin Zhuang",
                "Yuping Wang",
                "Yuxuan Wang"
            ],
            "affiliations": [
                "ByteDance Seed"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06673.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#optimization",
                    "#games",
                    "#benchmark",
                    "#cv"
                ],
                "emoji": "🐙",
                "ru": {
                    "title": "Предсказание 2D распределений для авторегрессивной генерации изображений",
                    "desc": "Heptapod — это авторегрессивная модель для генерации изображений, которая использует causal attention и предсказывает распределение по всей 2D пространственной сетке изображения на каждом шаге. Модель объединяет последовательное моделирование автоregрессивного подхода с целостным self-supervised обучением masked autoencoding, используя визуальный токенизатор, ориентированный на реконструкцию. На бенчмарке ImageNet модель достигает FID 2.70, значительно превосходя предыдущие causal авторегрессивные подходы. Работа предлагает принципиально новый взгляд на применение языкового моделирования к визуальным данным."
                },
                "en": {
                    "title": "Heptapod: Redefining Image Generation with Causal Attention",
                    "desc": "Heptapod is an advanced image autoregressive model that utilizes causal attention to enhance image generation. It innovatively predicts the next 2D distribution of images, allowing it to learn from the entire spatial grid at each step. By integrating sequential modeling with holistic self-supervised learning, Heptapod effectively captures complex image semantics. Its performance on the ImageNet benchmark, achieving an FID of 2.70, demonstrates its superiority over earlier causal autoregressive models."
                },
                "zh": {
                    "title": "Heptapod：图像生成的新思路",
                    "desc": "Heptapod是一种图像自回归模型，采用因果注意力和下一步二维分布预测的方法。它结合了顺序建模和整体自监督学习，显著提高了在ImageNet生成任务上的表现。该模型通过重建为中心的视觉标记器，学习在每个时间步预测整个二维空间网格的分布。Heptapod的创新之处在于其学习目标，统一了自回归框架的顺序建模与掩码自编码的自监督学习。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.05491",
            "title": "NorMuon: Making Muon more efficient and scalable",
            "url": "https://huggingface.co/papers/2510.05491",
            "abstract": "NorMuon, a novel optimizer combining orthogonalization with neuron-level adaptive learning rates, enhances training efficiency and balances parameter utilization in large language models.  \t\t\t\t\tAI-generated summary \t\t\t\t The choice of optimizer significantly impacts the training efficiency and computational costs of large language models (LLMs). Recently, the Muon optimizer has demonstrated promising results by orthogonalizing parameter updates, improving optimization geometry through better conditioning. Despite Muon's emergence as a candidate successor to Adam, the potential for jointly leveraging their strengths has not been systematically explored. In this work, we bridge this gap by proposing NorMuon (Neuron-wise Normalized Muon), an optimizer that synergistically combines orthogonalization with neuron-level adaptive learning rates. Our analysis reveals that while Muon effectively reduces condition numbers, the resulting updates exhibit highly non-uniform neuron norms, causing certain neurons to dominate the optimization process. NorMuon addresses this imbalance by maintaining second-order momentum statistics for each neuron and applying row-wise normalization after orthogonalization, ensuring balanced parameter utilization while preserving Muon's conditioning benefits. To enable practical deployment at scale, we develop an efficient distributed implementation under the FSDP2 framework that strategically distributes orthogonalization computations across devices. Experiments across multiple model scales demonstrate that NorMuon consistently outperforms both Adam and Muon, achieving 21.74% better training efficiency than Adam and 11.31% improvement over Muon on 1.1 B pretraining setting, while maintaining a comparable memory footprint to Muon. Our findings suggest that orthogonalization and adaptive learning rates are complementary rather than competing approaches, opening new avenues for optimizer design in large-scale deep learning.",
            "score": 2,
            "issue_id": 6326,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "51527f2ec5914706",
            "authors": [
                "Zichong Li",
                "Liming Liu",
                "Chen Liang",
                "Weizhu Chen",
                "Tuo Zhao"
            ],
            "affiliations": [
                "Georgia Tech",
                "Microsoft"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.05491.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#optimization"
                ],
                "emoji": "⚖️",
                "ru": {
                    "title": "Балансировка нейронов через ортогонализацию и адаптивные шаги обучения",
                    "desc": "Статья представляет NorMuon — новый оптимизатор для обучения больших языковых моделей, который объединяет ортогонализацию обновлений параметров с адаптивными learning rates на уровне отдельных нейронов. Авторы обнаружили, что хотя оптимизатор Muon улучшает геометрию оптимизации через ортогонализацию, он создаёт дисбаланс в нормах нейронов, из-за чего некоторые нейроны доминируют в процессе обучения. NorMuon решает эту проблему, применяя построчную нормализацию после ортогонализации и сохраняя статистику второго порядка для каждого нейрона. Эксперименты показали улучшение эффективности обучения на 21.74% по сравнению с Adam и на 11.31% по сравнению с Muon на модели размером 1.1B параметров."
                },
                "en": {
                    "title": "NorMuon: Balancing Efficiency and Utilization in Large Language Model Training",
                    "desc": "NorMuon is a new optimizer designed to improve the training of large language models by combining orthogonalization with neuron-level adaptive learning rates. This approach enhances training efficiency and ensures that all parameters are utilized effectively, preventing any single neuron from dominating the optimization process. By maintaining second-order momentum statistics and applying normalization, NorMuon balances the updates across neurons while benefiting from improved optimization geometry. Experiments show that NorMuon outperforms traditional optimizers like Adam and Muon, achieving significant gains in training efficiency without increasing memory usage."
                },
                "zh": {
                    "title": "NorMuon：提升大语言模型训练效率的新优化器",
                    "desc": "NorMuon是一种新型优化器，它结合了正交化和神经元级自适应学习率，提升了大语言模型的训练效率。该方法通过保持每个神经元的二阶动量统计，并在正交化后进行行归一化，解决了参数利用不均衡的问题。实验结果表明，NorMuon在多个模型规模上均优于Adam和Muon，训练效率提高了21.74%。这项研究表明，正交化和自适应学习率是互补的，可以为大规模深度学习的优化器设计开辟新的方向。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.21842",
            "title": "DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for\n  Autonomous Travel Planning Agents",
            "url": "https://huggingface.co/papers/2509.21842",
            "abstract": "DeepTravel is an end-to-end reinforcement learning framework for autonomous travel planning that uses a hierarchical reward system and reply-augmented learning to improve performance over existing models.  \t\t\t\t\tAI-generated summary \t\t\t\t Travel planning (TP) agent has recently worked as an emerging building block to interact with external tools and resources for travel itinerary generation, ensuring enjoyable user experience. Despite its benefits, existing studies rely on hand craft prompt and fixed agent workflow, hindering more flexible and autonomous TP agent. This paper proposes DeepTravel, an end to end agentic reinforcement learning framework for building autonomous travel planning agent, capable of autonomously planning, executing tools, and reflecting on tool responses to explore, verify, and refine intermediate actions in multi step reasoning. To achieve this, we first construct a robust sandbox environment by caching transportation, accommodation and POI data, facilitating TP agent training without being constrained by real world APIs limitations (e.g., inconsistent outputs). Moreover, we develop a hierarchical reward modeling system, where a trajectory level verifier first checks spatiotemporal feasibility and filters unsatisfied travel itinerary, and then the turn level verifier further validate itinerary detail consistency with tool responses, enabling efficient and precise reward service. Finally, we propose the reply augmented reinforcement learning method that enables TP agent to periodically replay from a failures experience buffer, emerging notable agentic capacity. We deploy trained TP agent on DiDi Enterprise Solutions App and conduct comprehensive online and offline evaluations, demonstrating that DeepTravel enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.",
            "score": 2,
            "issue_id": 6328,
            "pub_date": "2025-09-26",
            "pub_date_card": {
                "ru": "26 сентября",
                "en": "September 26",
                "zh": "9月26日"
            },
            "hash": "400daa394145aff0",
            "authors": [
                "Yansong Ning",
                "Rui Liu",
                "Jun Wang",
                "Kai Chen",
                "Wei Li",
                "Jun Fang",
                "Kan Zheng",
                "Naiqiang Tan",
                "Hao Liu"
            ],
            "affiliations": [
                "Didichuxing Co. Ltd",
                "The Hong Kong University of Science and Technology (Guangzhou)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.21842.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#games",
                    "#reasoning",
                    "#training",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "🗺️",
                "ru": {
                    "title": "Автономный AI-агент для планирования путешествий превосходит frontier модели",
                    "desc": "DeepTravel — это end-to-end фреймворк на основе reinforcement learning для автономного планирования путешествий. Система использует иерархическую модель наград, которая проверяет выполнимость маршрута на уровне всей траектории и деталей на уровне отдельных шагов. Агент обучается в sandbox-окружении с кешированными данными о транспорте и достопримечательностях, используя метод replay-augmented learning для обучения на ошибках. Обученная модель на базе Qwen3 32B превосходит frontier LLMs вроде OpenAI o1, o3 и DeepSeek R1 в задачах планирования путешествий."
                },
                "en": {
                    "title": "Revolutionizing Travel Planning with DeepTravel's Smart Learning!",
                    "desc": "DeepTravel is a novel reinforcement learning framework designed for autonomous travel planning. It utilizes a hierarchical reward system to enhance the agent's ability to plan and execute travel itineraries while reflecting on tool responses for continuous improvement. The framework operates in a controlled sandbox environment, allowing for effective training without the limitations of real-world data inconsistencies. By implementing a reply-augmented learning approach, DeepTravel significantly boosts the performance of smaller language models in travel planning tasks compared to larger models."
                },
                "zh": {
                    "title": "DeepTravel：自主旅行规划的新纪元",
                    "desc": "DeepTravel是一个端到端的强化学习框架，专注于自主旅行规划。它采用分层奖励系统和回复增强学习方法，提升了模型的性能。该框架能够自主规划和执行工具，并根据工具的反馈进行反思和优化。通过构建强大的沙盒环境和有效的奖励建模，DeepTravel在旅行规划任务中显著超越了现有的前沿模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.05891",
            "title": "D^3QE: Learning Discrete Distribution Discrepancy-aware\n  Quantization Error for Autoregressive-Generated Image Detection",
            "url": "https://huggingface.co/papers/2510.05891",
            "abstract": "A novel method using Discrete Distribution Discrepancy-aware Quantization Error (D$^3$QE) detects images generated by visual autoregressive models by analyzing codebook frequency statistics and quantization errors.  \t\t\t\t\tAI-generated summary \t\t\t\t The emergence of visual autoregressive (AR) models has revolutionized image generation while presenting new challenges for synthetic image detection. Unlike previous GAN or diffusion-based methods, AR models generate images through discrete token prediction, exhibiting both marked improvements in image synthesis quality and unique characteristics in their vector-quantized representations. In this paper, we propose to leverage Discrete Distribution Discrepancy-aware Quantization Error (D^3QE) for autoregressive-generated image detection that exploits the distinctive patterns and the frequency distribution bias of the codebook existing in real and fake images. We introduce a discrete distribution discrepancy-aware transformer that integrates dynamic codebook frequency statistics into its attention mechanism, fusing semantic features and quantization error latent. To evaluate our method, we construct a comprehensive dataset termed ARForensics covering 7 mainstream visual AR models. Experiments demonstrate superior detection accuracy and strong generalization of D^3QE across different AR models, with robustness to real-world perturbations. Code is available at https://github.com/Zhangyr2022/D3QE{https://github.com/Zhangyr2022/D3QE}.",
            "score": 1,
            "issue_id": 6321,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "b5fce1a59c0d659b",
            "authors": [
                "Yanran Zhang",
                "Bingyao Yu",
                "Yu Zheng",
                "Wenzhao Zheng",
                "Yueqi Duan",
                "Lei Chen",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "affiliations": [
                "Department of Automation, Tsinghua University, China",
                "Department of Electronic Engineering, Tsinghua University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.05891.jpg",
            "data": {
                "categories": [
                    "#security",
                    "#synthetic",
                    "#cv",
                    "#dataset",
                    "#inference"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Поиск искусственного через анализ квантизации",
                    "desc": "Исследователи предложили новый метод D³QE для обнаружения изображений, сгенерированных визуальными autoregressive моделями. Метод анализирует паттерны распределения частот в codebook и ошибки квантизации, которые отличаются у реальных и синтетических изображений. Для этого используется специальный transformer, который учитывает статистику частот codebook в механизме attention и объединяет семантические признаки с латентными представлениями ошибок квантизации. Эксперименты на датасете ARForensics из 7 моделей показали высокую точность детекции и хорошую обобщающую способность метода."
                },
                "en": {
                    "title": "Detecting AI-Generated Images with D^3QE",
                    "desc": "This paper presents a new method called Discrete Distribution Discrepancy-aware Quantization Error (D^3QE) for detecting images created by visual autoregressive models. It focuses on analyzing the frequency statistics of codebooks and the quantization errors that arise during image generation. By using a transformer that incorporates these frequency statistics into its attention mechanism, the method effectively distinguishes between real and synthetic images. The proposed approach shows high accuracy and generalization across various autoregressive models, making it robust against real-world image variations."
                },
                "zh": {
                    "title": "利用D^3QE检测自回归生成图像的创新方法",
                    "desc": "本文提出了一种新方法，利用离散分布差异感知量化误差（D^3QE）来检测由视觉自回归模型生成的图像。该方法通过分析代码本频率统计和量化误差，识别真实与伪造图像之间的独特模式和频率分布偏差。与传统的生成对抗网络（GAN）或扩散模型不同，自回归模型通过离散标记预测生成图像，展现出更高的合成质量。实验结果表明，D^3QE在不同自回归模型中具有优越的检测准确性和强大的泛化能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06475",
            "title": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning\n  with Puzzles",
            "url": "https://huggingface.co/papers/2510.06475",
            "abstract": "PuzzlePlex benchmark assesses reasoning and planning capabilities of foundation models through diverse puzzles, providing metrics and insights into their performance and scalability.  \t\t\t\t\tAI-generated summary \t\t\t\t This work investigates the reasoning and planning capabilities of foundation models and their scalability in complex, dynamic environments. We introduce PuzzlePlex, a benchmark designed to assess these capabilities through a diverse set of puzzles. PuzzlePlex consists of 15 types of puzzles, including deterministic and stochastic games of varying difficulty, as well as single-player and two-player scenarios. The PuzzlePlex framework provides a comprehensive environment for each game, and supports extensibility to generate more challenging instances as foundation models evolve. Additionally, we implement customized game-playing strategies for comparison. Building on this benchmark, we develop fine-grained metrics to measure performance and conduct an in-depth analysis of frontier foundation models across two settings: instruction-based and code-based. Furthermore, we systematically investigate their scaling limits. Our findings show that reasoning models outperform others in instruction-based settings, while code-based execution presents greater challenges but offers a scalable and efficient alternative. PuzzlePlex enables targeted evaluation and guides future improvements in reasoning, planning, and generalization for foundation models.",
            "score": 0,
            "issue_id": 6335,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "f3109cfc5f50d36a",
            "authors": [
                "Yitao Long",
                "Yuru Jiang",
                "Hongjun Liu",
                "Yilun Zhao",
                "Jingchen Sun",
                "Yiqiu Shen",
                "Chen Zhao",
                "Arman Cohan",
                "Dennis Shasha"
            ],
            "affiliations": [
                "NYU Grossman School of Medicine",
                "New York University",
                "University at Buffalo, SUNY",
                "Yale University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06475.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#games",
                    "#benchmark"
                ],
                "emoji": "🧩",
                "ru": {
                    "title": "Головоломки как испытание для AI: проверка логики и планирования",
                    "desc": "Исследователи представили PuzzlePlex — бенчмарк для оценки способностей foundation models к рассуждению и планированию через решение разнообразных головоломок. Бенчмарк включает 15 типов задач различной сложности: детерминированные и стохастические игры, одиночные и двухпользовательские сценарии. Эксперименты показали, что reasoning models лучше справляются с инструкциями на естественном языке, в то время как подход на основе кода представляет большую сложность, но обеспечивает масштабируемость. PuzzlePlex позволяет детально измерить производительность моделей и определить направления для улучшения их способностей к обобщению и планированию."
                },
                "en": {
                    "title": "PuzzlePlex: Benchmarking Reasoning and Planning in Foundation Models",
                    "desc": "The paper introduces PuzzlePlex, a benchmark designed to evaluate the reasoning and planning abilities of foundation models through a variety of puzzles. It includes 15 different types of puzzles, ranging from deterministic to stochastic games, and accommodates both single-player and two-player scenarios. The framework allows for the generation of increasingly complex puzzles as models improve, and it provides metrics for assessing model performance in instruction-based and code-based settings. The results indicate that while reasoning models excel in instruction-based tasks, code-based tasks present more challenges but are scalable and efficient alternatives."
                },
                "zh": {
                    "title": "PuzzlePlex：评估推理与规划能力的基准",
                    "desc": "PuzzlePlex基准测试评估基础模型的推理和规划能力，使用多样化的难题提供性能和可扩展性的指标和见解。该基准包含15种类型的难题，包括确定性和随机性游戏，难度各异，适用于单人和双人场景。PuzzlePlex框架为每个游戏提供全面的环境，并支持生成更具挑战性的实例，以适应基础模型的发展。此外，我们开发了细致的指标来测量性能，并对前沿基础模型在指令基础和代码基础的两种设置下进行了深入分析。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.06426",
            "title": "FinLFQA: Evaluating Attributed Text Generation of LLMs in Financial\n  Long-Form Question Answering",
            "url": "https://huggingface.co/papers/2510.06426",
            "abstract": "FinLFQA evaluates LLMs' ability to provide reliable and nuanced attributions in long-form financial question answering through human and automatic assessments.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) frequently hallucinate to long-form questions, producing plausible yet factually incorrect answers. A common mitigation strategy is to provide attribution to LLM outputs. However, existing benchmarks primarily focus on simple attribution that retrieves supporting textual evidence as references. We argue that in real-world scenarios such as financial applications, attribution goes beyond reference retrieval. We introduce FinLFQA, a benchmark designed to evaluate the ability of LLMs to generate long-form answers to complex financial questions with reliable and nuanced attributions. FinLFQA evaluates three critical aspects of attribution through human annotations: (1) supporting evidence extracted from financial reports, (2) intermediate numerical reasoning steps, and (3) domain-specific financial knowledge that informs the reasoning process. We further provide an automatic evaluation framework covering both answer quality and attribution quality. Through extensive experiments on eight LLMs across multiple attribution-generation paradigms, we find that fine-grained metrics are important to distinguish model capabilities, that end-to-end generation achieves comparable performance to post-hoc approaches, and that iterative refinement only helps when guided by external feedback.",
            "score": 0,
            "issue_id": 6335,
            "pub_date": "2025-10-07",
            "pub_date_card": {
                "ru": "7 октября",
                "en": "October 7",
                "zh": "10月7日"
            },
            "hash": "70ed711d0398d91b",
            "authors": [
                "Yitao Long",
                "Tiansheng Hu",
                "Yilun Zhao",
                "Arman Cohan",
                "Chen Zhao"
            ],
            "affiliations": [
                "NYU Shanghai",
                "New York University",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.06426.jpg",
            "data": {
                "categories": [
                    "#long_context",
                    "#hallucinations",
                    "#benchmark",
                    "#reasoning",
                    "#multimodal"
                ],
                "emoji": "💰",
                "ru": {
                    "title": "Проверка LLM на честность в финансовых ответах",
                    "desc": "Статья представляет FinLFQA — бенчмарк для оценки способности LLM генерировать развёрнутые ответы на сложные финансовые вопросы с надёжной атрибуцией источников. Проблема в том, что LLM часто галлюцинируют, выдавая правдоподобные, но фактически неверные ответы, особенно в финансовой сфере. Бенчмарк оценивает три аспекта атрибуции: извлечение подтверждающих данных из финансовых отчётов, промежуточные шаги численных расчётов и использование специфических знаний из финансовой области. Эксперименты на восьми LLM показали, что детальные метрики важны для различения возможностей моделей, а end-to-end генерация работает сравнимо с post-hoc подходами."
                },
                "en": {
                    "title": "Enhancing Financial Question Answering with Reliable Attributions",
                    "desc": "FinLFQA is a benchmark that assesses how well Large Language Models (LLMs) can answer complex financial questions while providing reliable attributions. It highlights the issue of LLMs generating plausible but incorrect answers, known as hallucinations, and emphasizes the need for nuanced attribution beyond simple reference retrieval. The evaluation focuses on three key aspects: extracting supporting evidence from financial reports, demonstrating intermediate numerical reasoning, and applying domain-specific financial knowledge. The study shows that fine-grained metrics are crucial for evaluating model performance and that iterative refinement is beneficial when guided by external feedback."
                },
                "zh": {
                    "title": "评估金融问答中的归因能力",
                    "desc": "FinLFQA是一个评估大型语言模型（LLMs）在长篇金融问答中提供可靠和细致归因能力的基准。现有的评估主要关注简单的引用检索，而我们认为在金融应用中，归因应超越这一点。FinLFQA通过人类注释评估三个关键方面：从财务报告中提取的支持证据、中间数值推理步骤，以及影响推理过程的领域特定金融知识。此外，我们还提供了一个自动评估框架，涵盖答案质量和归因质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04910",
            "title": "Glocal Information Bottleneck for Time Series Imputation",
            "url": "https://huggingface.co/papers/2510.04910",
            "abstract": "A new training paradigm, Glocal Information Bottleneck, improves time series imputation by aligning latent representations to retain global structure and local details under high missingness.  \t\t\t\t\tAI-generated summary \t\t\t\t Time Series Imputation (TSI), which aims to recover missing values in temporal data, remains a fundamental challenge due to the complex and often high-rate missingness in real-world scenarios. Existing models typically optimize the point-wise reconstruction loss, focusing on recovering numerical values (local information). However, we observe that under high missing rates, these models still perform well in the training phase yet produce poor imputations and distorted latent representation distributions (global information) in the inference phase. This reveals a critical optimization dilemma: current objectives lack global guidance, leading models to overfit local noise and fail to capture global information of the data. To address this issue, we propose a new training paradigm, Glocal Information Bottleneck (Glocal-IB). Glocal-IB is model-agnostic and extends the standard IB framework by introducing a Global Alignment loss, derived from a tractable mutual information approximation. This loss aligns the latent representations of masked inputs with those of their originally observed counterparts. It helps the model retain global structure and local details while suppressing noise caused by missing values, giving rise to better generalization under high missingness. Extensive experiments on nine datasets confirm that Glocal-IB leads to consistently improved performance and aligned latent representations under missingness. Our code implementation is available in https://github.com/Muyiiiii/NeurIPS-25-Glocal-IB.",
            "score": 0,
            "issue_id": 6334,
            "pub_date": "2025-10-06",
            "pub_date_card": {
                "ru": "6 октября",
                "en": "October 6",
                "zh": "10月6日"
            },
            "hash": "cd332a35c362b2d3",
            "authors": [
                "Jie Yang",
                "Kexin Zhang",
                "Guibin Zhang",
                "Philip S. Yu",
                "Kaize Ding"
            ],
            "affiliations": [
                "National University of Singapore",
                "Northwestern University",
                "University of Illinois Chicago"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04910.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#optimization",
                    "#training"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "Баланс между глобальным и локальным: новый подход к восстановлению временных рядов",
                    "desc": "Статья представляет новую парадигму обучения Glocal Information Bottleneck для восстановления пропущенных значений во временных рядах. Существующие модели фокусируются на точечном восстановлении значений, но при высоком проценте пропусков они переобучаются на локальном шуме и теряют глобальную структуру данных. Предложенный метод расширяет классический Information Bottleneck framework, добавляя функцию Global Alignment loss, которая выравнивает латентные представления между данными с пропусками и оригинальными наблюдениями. Это позволяет модели одновременно сохранять глобальную структуру и локальные детали, обеспечивая лучшую генерализацию при большом количестве пропущенных значений."
                },
                "en": {
                    "title": "Glocal-IB: Bridging Global Structure and Local Details in Time Series Imputation",
                    "desc": "The paper introduces a new training method called Glocal Information Bottleneck (Glocal-IB) to enhance time series imputation, which is the process of filling in missing values in time-dependent data. Traditional models often focus on recovering individual values but struggle with high rates of missing data, leading to poor performance during inference. Glocal-IB addresses this by aligning latent representations to maintain both global structure and local details, thus reducing the impact of noise from missing values. Experiments show that this approach significantly improves the quality of imputations and the alignment of latent representations across various datasets."
                },
                "zh": {
                    "title": "全局与局部信息的完美结合",
                    "desc": "本文提出了一种新的训练范式，称为Glocal Information Bottleneck（Glocal-IB），旨在改善时间序列缺失值填补。传统模型通常只关注局部信息，优化点对点重建损失，导致在高缺失率下表现不佳。Glocal-IB通过引入全局对齐损失，帮助模型在保留全局结构的同时，抑制由缺失值引起的噪声。实验结果表明，Glocal-IB在九个数据集上均表现出一致的性能提升和对齐的潜在表示。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.05152",
            "title": "A Single Character can Make or Break Your LLM Evals",
            "url": "https://huggingface.co/papers/2510.05152",
            "abstract": "The choice of delimiter in formatting in-context examples significantly impacts the performance of large language models across different families and tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Common Large Language model (LLM) evaluations rely on demonstration examples to steer models' responses to the desired style. While the number of examples used has been studied and standardized, the choice of how to format examples is less investigated. In evaluation protocols and real world usage, users face the choice how to separate in-context examples: use a comma? new line? semi-colon? hashtag? etc.? Surprisingly, we find this seemingly minor choice can dramatically alter model response quality. Across leading model families (Llama, Qwen, Gemma), performance on MMLU for example can vary by pm 23% depending on the choice of delimiter. In fact, one can manipulate model rankings to put any model in the lead by only modifying the single character separating examples. We find LLMs' brittleness pervades topics, model families, and doesn't improve with scale. By probing attention head scores, we find that good-performing delimiters steer attention towards key tokens in the input. Finally, we explore methods to improve LLMs' robustness to the choice of delimiter. We find specifying the selected delimiter in the prompt boosts robustness and offer practical recommendations for the best-performing delimiters to select.",
            "score": 0,
            "issue_id": 6335,
            "pub_date": "2025-10-02",
            "pub_date_card": {
                "ru": "2 октября",
                "en": "October 2",
                "zh": "10月2日"
            },
            "hash": "acabea177e30672c",
            "authors": [
                "Jingtong Su",
                "Jianyu Zhang",
                "Karen Ullrich",
                "Léon Bottou",
                "Mark Ibrahim"
            ],
            "affiliations": [
                "FAIR at Meta",
                "New York University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.05152.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#training",
                    "#data",
                    "#benchmark",
                    "#optimization"
                ],
                "emoji": "🔗",
                "ru": {
                    "title": "Один символ может изменить всё: как разделители влияют на работу LLM",
                    "desc": "Исследование показывает, что выбор разделителя между примерами в промпте (запятая, точка с запятой, новая строка) драматически влияет на качество ответов больших языковых моделей. На тесте MMLU производительность может меняться на ±23% в зависимости от одного символа-разделителя, причём можно манипулировать рейтингом моделей, меняя только этот символ. Анализ attention heads показал, что успешные разделители направляют внимание модели на ключевые токены во входных данных. Авторы предлагают практические рекомендации по выбору разделителей и показывают, что явное указание разделителя в промпте повышает устойчивость модели."
                },
                "en": {
                    "title": "Delimiter Decisions Matter: Boosting LLM Performance!",
                    "desc": "This paper investigates how the choice of delimiter in formatting in-context examples affects the performance of large language models (LLMs). It reveals that even minor formatting decisions, such as using a comma or a new line, can lead to significant variations in model performance, with differences up to 23% on tasks like MMLU. The study shows that this sensitivity is consistent across various model families and does not improve with larger models. Additionally, the authors propose methods to enhance LLM robustness by specifying delimiters in prompts and provide recommendations for optimal delimiter choices."
                },
                "zh": {
                    "title": "分隔符选择影响模型表现的关键",
                    "desc": "在这篇论文中，我们研究了在上下文示例中选择分隔符对大型语言模型（LLM）性能的影响。尽管示例的数量已经被研究和标准化，但分隔符的选择却鲜有探讨。我们的实验表明，分隔符的不同选择可以导致模型响应质量的显著变化，甚至影响模型的排名。我们还提出了一些方法来提高LLM对分隔符选择的鲁棒性，建议在提示中明确指定分隔符以提升性能。"
                }
            }
        }
    ],
    "link_prev": "2025-10-08.html",
    "link_next": "2025-10-10.html",
    "link_month": "2025-10.html",
    "short_date_prev": {
        "ru": "08.10",
        "en": "10/08",
        "zh": "10月8日"
    },
    "short_date_next": {
        "ru": "10.10",
        "en": "10/10",
        "zh": "10月10日"
    },
    "categories": {
        "#dataset": 11,
        "#data": 4,
        "#benchmark": 18,
        "#agents": 6,
        "#cv": 7,
        "#rl": 7,
        "#rlhf": 3,
        "#rag": 0,
        "#plp": 1,
        "#inference": 3,
        "#3d": 0,
        "#audio": 0,
        "#video": 4,
        "#multimodal": 8,
        "#math": 0,
        "#multilingual": 3,
        "#architecture": 11,
        "#healthcare": 0,
        "#training": 25,
        "#robotics": 2,
        "#agi": 1,
        "#games": 6,
        "#interpretability": 6,
        "#reasoning": 12,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 25,
        "#survey": 4,
        "#diffusion": 5,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 3,
        "#long_context": 8,
        "#synthetic": 2,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 5,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 3
    }
}