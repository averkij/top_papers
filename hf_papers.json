{
    "date": {
        "ru": "22 января",
        "en": "January 22",
        "zh": "1月22日"
    },
    "time_utc": "2025-01-22 04:12",
    "weekday": 2,
    "issue_id": 1796,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.12273",
            "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
            "url": "https://huggingface.co/papers/2501.12273",
            "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs). However, as LLMs become more advanced, the availability of high-quality human-annotated SFT data has become a significant bottleneck, necessitating a greater reliance on synthetic training data. In this work, we introduce Condor, a novel two-stage synthetic data generation framework that incorporates World Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data at scale. Our experimental results demonstrate that a base model fine-tuned on only 20K Condor-generated samples achieves superior performance compared to counterparts. The additional refinement stage in Condor further enables iterative self-improvement for LLMs at various scales (up to 72B), validating the effectiveness of our approach. Furthermore, our investigation into the scaling for synthetic data in post-training reveals substantial unexplored potential for performance improvements, opening promising avenues for future research.",
            "score": 5,
            "issue_id": 1796,
            "pub_date": "2025-01-21",
            "pub_date_card": {
                "ru": "21 января",
                "en": "January 21",
                "zh": "1月21日"
            },
            "hash": "10499c8b820d5368",
            "authors": [
                "Maosong Cao",
                "Taolin Zhang",
                "Mo Li",
                "Chuyu Zhang",
                "Yunxin Liu",
                "Haodong Duan",
                "Songyang Zhang",
                "Kai Chen"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.12273.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#synthetic",
                    "#data",
                    "#dataset",
                    "#training"
                ],
                "emoji": "🦅",
                "ru": {
                    "title": "Condor: прорыв в создании синтетических данных для обучения языковых моделей",
                    "desc": "В статье представлен Condor - новый фреймворк для генерации синтетических данных для обучения больших языковых моделей (LLM). Он использует дерево мировых знаний и самоанализ для создания высококачественных обучающих данных. Эксперименты показали, что модель, обученная на 20 тысячах сгенерированных Condor примеров, превосходит аналоги. Исследование также выявило потенциал для улучшения производительности LLM при масштабировании синтетических данных."
                },
                "en": {
                    "title": "Unlocking LLM Potential with Synthetic Data Generation",
                    "desc": "This paper addresses the challenge of obtaining high-quality Supervised Fine-Tuning (SFT) data for Large Language Models (LLMs). It presents Condor, a two-stage framework that generates synthetic training data using World Knowledge Tree and Self-Reflection Refinement techniques. The results show that models fine-tuned with just 20,000 samples from Condor outperform those trained with traditional methods. Additionally, the framework allows for iterative self-improvement, suggesting significant potential for enhancing LLM performance through synthetic data."
                },
                "zh": {
                    "title": "合成数据生成，提升对话能力的关键",
                    "desc": "本论文探讨了监督微调（SFT）数据的质量对大型语言模型（LLMs）对话能力的重要性。随着LLMs的进步，高质量的人类标注SFT数据变得稀缺，因此需要更多依赖合成训练数据。我们提出了一种名为Condor的两阶段合成数据生成框架，结合了世界知识树和自我反思精炼，以大规模生成高质量的SFT数据。实验结果表明，仅用20K个Condor生成的样本微调的基础模型，其性能优于其他模型，验证了我们方法的有效性。"
                }
            }
        }
    ],
    "link_prev": "2025-01-21.html",
    "link_next": "2025-01-23.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "21.01",
        "en": "01/21",
        "zh": "1月21日"
    },
    "short_date_next": {
        "ru": "23.01",
        "en": "01/23",
        "zh": "1月23日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种名为GameFactory的框架，旨在通过生成游戏引擎来革新游戏开发。它使用预训练的视频扩散模型，能够创建全新且多样化的游戏。为了解决现有方法在场景生成上的局限，作者提出了一种多阶段训练策略。他们还发布了一个基于Minecraft的高质量视频数据集，并展示了框架能够生成开放域、多样化和可控的游戏视频。",
        "title": "GameFactory: Creating New Games with Generative Interactive Videos",
        "pinyin": "这篇文章介绍了一种名为GameFactory的框架，旨在通过生成游戏引擎来革新游戏开发。它使用预训练的视频扩散模型，能够创建全新且多样化的游戏。为了解决现有方法在场景生成上的局限，作者提出了一种多阶段训练策略。他们还发布了一个基于Minecraft的高质量视频数据集，并展示了框架能够生成开放域、多样化和可控的游戏视频。\n\nzhè piān wén zhāng jiè shào le yī zhǒng míng wèi GameFactory de kuàng jià, zhǐ zài tōng guò shēng chéng yòu xí yǐn qíng lái gé xīn yòu xí kāi fā. tā shǐ yòng yù xùn liàn de shì pín kuò sàn mó xíng, néng gòu chuàng jiàn quán xīn qiě duō yàng huà de yòu xí. wèi le jiě jué xiàn yǒu fāng fǎ zài chǎng jīng shēng chéng shàng de jú xiàn, zuò zhě tí chū le yī zhǒng duō jiē duàn xùn liàn cè lüè. tā men hái fā bù le yī gè jī yú Minecraft de gāo zhì liàng shì pín shù jù jí, bìng zhàn shì le kuàng jià néng gòu shēng chéng kāi fàng yù, duō yàng huà hé kě kòng de yòu xí shì pín.",
        "vocab": "[{'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'},\n{'word': '旨在', 'pinyin': 'zhǐzài', 'trans': 'aim to'},\n{'word': '革新', 'pinyin': 'géxīn', 'trans': 'innovate'},\n{'word': '引擎', 'pinyin': 'yǐnqíng', 'trans': 'engine'},\n{'word': '预训练', 'pinyin': 'yù xùnliàn', 'trans': 'pre-trained'},\n{'word': '扩散', 'pinyin': 'kuòsàn', 'trans': 'diffusion'},\n{'word': '多样化', 'pinyin': 'duōyànghuà', 'trans': 'diversified'},\n{'word': '局限', 'pinyin': 'júxiàn', 'trans': 'limitation'},\n{'word': '提出', 'pinyin': 'tíchū', 'trans': 'propose'},\n{'word': '策略', 'pinyin': 'cèlüè', 'trans': 'strategy'},\n{'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'},\n{'word': '高质量', 'pinyin': 'gāo zhìliàng', 'trans': 'high quality'},\n{'word': '数据集', 'pinyin': 'shùjù jí', 'trans': 'dataset'},\n{'word': '展示', 'pinyin': 'zhǎnshì', 'trans': 'demonstrate'},\n{'word': '开放域', 'pinyin': 'kāifàng yù', 'trans': 'open domain'},\n{'word': '可控', 'pinyin': 'kěkòng', 'trans': 'controllable'}]",
        "trans": "This article introduces a framework called GameFactory, which aims to revolutionize game development by generating game engines. It utilizes pre-trained video diffusion models to create novel and diverse games. To address the limitations of existing methods in scene generation, the authors propose a multi-stage training strategy. They also release a high-quality video dataset based on Minecraft and demonstrate that the framework can generate open-domain, diverse, and controllable game videos.",
        "update_ts": "2025-01-21 09:10"
    }
}