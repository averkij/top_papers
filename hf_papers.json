{
    "date": {
        "ru": "15 января",
        "en": "January 15",
        "zh": "1月15日"
    },
    "time_utc": "2025-01-15 03:11",
    "weekday": 2,
    "issue_id": 1672,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.08313",
            "title": "MiniMax-01: Scaling Foundation Models with Lightning Attention",
            "url": "https://huggingface.co/papers/2501.08313",
            "abstract": "We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01, which are comparable to top-tier models while offering superior capabilities in processing longer contexts. The core lies in lightning attention and its efficient scaling. To maximize computational capacity, we integrate it with Mixture of Experts (MoE), creating a model with 32 experts and 456 billion total parameters, of which 45.9 billion are activated for each token. We develop an optimized parallel strategy and highly efficient computation-communication overlap techniques for MoE and lightning attention. This approach enables us to conduct efficient training and inference on models with hundreds of billions of parameters across contexts spanning millions of tokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens during training and extrapolate to 4 million tokens during inference at an affordable cost. Our vision-language model, MiniMax-VL-01 is built through continued training with 512 billion vision-language tokens. Experiments on both standard and in-house benchmarks show that our models match the performance of state-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32 times longer context window. We publicly release MiniMax-01 at https://github.com/MiniMax-AI.",
            "score": 91,
            "issue_id": 1672,
            "pub_date": "2025-01-14",
            "pub_date_card": {
                "ru": "14 января",
                "en": "January 14",
                "zh": "1月14日"
            },
            "hash": "a57d7b1914e7383a",
            "authors": [
                "MiniMax",
                "Aonian Li",
                "Bangwei Gong",
                "Bo Yang",
                "Boji Shan",
                "Chang Liu",
                "Cheng Zhu",
                "Chunhao Zhang",
                "Congchao Guo",
                "Da Chen",
                "Dong Li",
                "Enwei Jiao",
                "Gengxin Li",
                "Guojun Zhang",
                "Haohai Sun",
                "Houze Dong",
                "Jiadai Zhu",
                "Jiaqi Zhuang",
                "Jiayuan Song",
                "Jin Zhu",
                "Jingtao Han",
                "Jingyang Li",
                "Junbin Xie",
                "Junhao Xu",
                "Junjie Yan",
                "Kaishun Zhang",
                "Kecheng Xiao",
                "Kexi Kang",
                "Le Han",
                "Leyang Wang",
                "Lianfei Yu",
                "Liheng Feng",
                "Lin Zheng",
                "Linbo Chai",
                "Long Xing",
                "Meizhi Ju",
                "Mingyuan Chi",
                "Mozhi Zhang",
                "Peikai Huang",
                "Pengcheng Niu",
                "Pengfei Li",
                "Pengyu Zhao",
                "Qi Yang",
                "Qidi Xu",
                "Qiexiang Wang",
                "Qin Wang",
                "Qiuhui Li",
                "Ruitao Leng",
                "Shengmin Shi",
                "Shuqi Yu",
                "Sichen Li",
                "Songquan Zhu",
                "Tao Huang",
                "Tianrun Liang",
                "Weigao Sun",
                "Weixuan Sun",
                "Weiyu Cheng",
                "Wenkai Li",
                "Xiangjun Song",
                "Xiao Su",
                "Xiaodong Han",
                "Xinjie Zhang",
                "Xinzhu Hou",
                "Xu Min",
                "Xun Zou",
                "Xuyang Shen",
                "Yan Gong",
                "Yingjie Zhu",
                "Yipeng Zhou",
                "Yiran Zhong",
                "Yongyi Hu",
                "Yuanxiang Fan",
                "Yue Yu",
                "Yufeng Yang",
                "Yuhao Li",
                "Yunan Huang",
                "Yunji Li",
                "Yunpeng Huang",
                "Yunzhi Xu",
                "Yuxin Mao",
                "Zehan Li",
                "Zekang Li",
                "Zewei Tao",
                "Zewen Ying",
                "Zhaoyang Cong",
                "Zhen Qin",
                "Zhenhua Fan",
                "Zhihang Yu",
                "Zhuo Jiang",
                "Zijia Wu"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2501.08313.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#architecture",
                    "#optimization",
                    "#benchmark",
                    "#long_context",
                    "#training"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "MiniMax-01: Революция в обработке длинных контекстов",
                    "desc": "Исследователи представили серию моделей MiniMax-01, включая MiniMax-Text-01 и MiniMax-VL-01, которые сравнимы с лучшими моделями, но обладают улучшенными возможностями обработки длинных контекстов. В основе лежит технология lightning attention и ее эффективное масштабирование, интегрированные с Mixture of Experts (MoE). Модель имеет 32 эксперта и 456 миллиардов параметров, из которых 45,9 миллиардов активируются для каждого токена. Контекстное окно MiniMax-Text-01 может достигать 1 миллиона токенов при обучении и экстраполироваться до 4 миллионов токенов при инференсе."
                },
                "en": {
                    "title": "Unleashing Long Contexts with MiniMax-01 Models",
                    "desc": "The MiniMax-01 series introduces advanced models, MiniMax-Text-01 and MiniMax-VL-01, designed to handle longer contexts effectively. These models utilize lightning attention and a Mixture of Experts (MoE) architecture, featuring 32 experts and a staggering 456 billion parameters, optimizing the activation of 45.9 billion parameters per token. By implementing efficient parallel strategies and computation-communication overlap techniques, the models can train and infer on extensive datasets, reaching context windows of up to 1 million tokens during training and 4 million during inference. Performance evaluations indicate that MiniMax-01 models rival leading models like GPT-4o and Claude-3.5-Sonnet while significantly extending context capabilities."
                },
                "zh": {
                    "title": "MiniMax-01：超长上下文处理的新纪元",
                    "desc": "我们介绍了MiniMax-01系列，包括MiniMax-Text-01和MiniMax-VL-01，这些模型在处理更长的上下文时具有优越的能力。核心技术是闪电注意力和高效的扩展能力。为了最大化计算能力，我们将其与专家混合模型（MoE）结合，创建了一个拥有32个专家和4560亿参数的模型。我们的实验表明，这些模型在标准和内部基准测试中表现出色，能够与最先进的模型相媲美，同时提供20到32倍更长的上下文窗口。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.08187",
            "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following",
            "url": "https://huggingface.co/papers/2501.08187",
            "abstract": "Large language models excel at interpreting complex natural language instructions, enabling them to perform a wide range of tasks. In the life sciences, single-cell RNA sequencing (scRNA-seq) data serves as the \"language of cellular biology\", capturing intricate gene expression patterns at the single-cell level. However, interacting with this \"language\" through conventional tools is often inefficient and unintuitive, posing challenges for researchers. To address these limitations, we present InstructCell, a multi-modal AI copilot that leverages natural language as a medium for more direct and flexible single-cell analysis. We construct a comprehensive multi-modal instruction dataset that pairs text-based instructions with scRNA-seq profiles from diverse tissues and species. Building on this, we develop a multi-modal cell language architecture capable of simultaneously interpreting and processing both modalities. InstructCell empowers researchers to accomplish critical tasks-such as cell type annotation, conditional pseudo-cell generation, and drug sensitivity prediction-using straightforward natural language commands. Extensive evaluations demonstrate that InstructCell consistently meets or exceeds the performance of existing single-cell foundation models, while adapting to diverse experimental conditions. More importantly, InstructCell provides an accessible and intuitive tool for exploring complex single-cell data, lowering technical barriers and enabling deeper biological insights.",
            "score": 9,
            "issue_id": 1672,
            "pub_date": "2025-01-14",
            "pub_date_card": {
                "ru": "14 января",
                "en": "January 14",
                "zh": "1月14日"
            },
            "hash": "de984ce7cc62fa5e",
            "authors": [
                "Yin Fang",
                "Xinle Deng",
                "Kangwei Liu",
                "Ningyu Zhang",
                "Jingyang Qian",
                "Penghui Yang",
                "Xiaohui Fan",
                "Huajun Chen"
            ],
            "affiliations": [
                "College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China",
                "College of Pharmaceutical Sciences, Zhejiang University, Hangzhou 310058, China",
                "Future Health Laboratory, Innovation Center of Yangtze River Delta, Zhejiang University, Jiaxing 314100, China",
                "Innovation Center in Zhejiang University, State Key Laboratory of Component-Based Chinese Medicine, Hangzhou 310058, China",
                "School of Software Technology, Zhejiang University, Ningbo 315048, China",
                "ZJU-Hangzhou Global Scientific and Technological Innovation Center, Hangzhou 311200, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.08187.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#multimodal",
                    "#dataset",
                    "#science",
                    "#healthcare"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "Естественный язык как ключ к расшифровке клеточной биологии",
                    "desc": "InstructCell - это мультимодальный ИИ-помощник для анализа данных одноклеточного РНК-секвенирования (scRNA-seq). Он использует архитектуру, способную интерпретировать как естественный язык, так и профили экспрессии генов. InstructCell позволяет исследователям выполнять такие задачи, как аннотация типов клеток и предсказание чувствительности к лекарствам, с помощью простых текстовых команд. Модель демонстрирует высокую производительность и адаптивность к различным экспериментальным условиям."
                },
                "en": {
                    "title": "InstructCell: Bridging Language and Biology for Seamless Single-Cell Analysis",
                    "desc": "This paper introduces InstructCell, an AI tool designed to simplify the analysis of single-cell RNA sequencing (scRNA-seq) data using natural language instructions. By creating a dataset that links text commands with scRNA-seq profiles, InstructCell allows researchers to perform complex tasks like cell type annotation and drug sensitivity prediction more intuitively. The model employs a multi-modal architecture that processes both text and biological data simultaneously, enhancing its usability. Evaluations show that InstructCell outperforms existing models, making single-cell analysis more accessible and efficient for researchers in the life sciences."
                },
                "zh": {
                    "title": "用自然语言解锁单细胞数据的潜力",
                    "desc": "这篇论文介绍了InstructCell，一个多模态的人工智能助手，旨在通过自然语言简化单细胞RNA测序(scRNA-seq)数据的分析。传统工具在处理细胞生物学的复杂数据时效率低下，而InstructCell通过将文本指令与scRNA-seq数据结合，提供了更直接和灵活的分析方式。该系统能够执行细胞类型注释、条件伪细胞生成和药物敏感性预测等关键任务，且使用简单的自然语言命令即可完成。评估结果表明，InstructCell在性能上优于现有的单细胞基础模型，同时适应多种实验条件，降低了技术门槛，促进了生物学的深入理解。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.08316",
            "title": "Diffusion Adversarial Post-Training for One-Step Video Generation",
            "url": "https://huggingface.co/papers/2501.08316",
            "abstract": "The diffusion models are widely used for image and video generation, but their iterative generation process is slow and expansive. While existing distillation approaches have demonstrated the potential for one-step generation in the image domain, they still suffer from significant quality degradation. In this work, we propose Adversarial Post-Training (APT) against real data following diffusion pre-training for one-step video generation. To improve the training stability and quality, we introduce several improvements to the model architecture and training procedures, along with an approximated R1 regularization objective. Empirically, our experiments show that our adversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720, 24fps videos in real time using a single forward evaluation step. Additionally, our model is capable of generating 1024px images in a single step, achieving quality comparable to state-of-the-art methods.",
            "score": 1,
            "issue_id": 1672,
            "pub_date": "2025-01-14",
            "pub_date_card": {
                "ru": "14 января",
                "en": "January 14",
                "zh": "1月14日"
            },
            "hash": "4122a780e8356ce7",
            "authors": [
                "Shanchuan Lin",
                "Xin Xia",
                "Yuxi Ren",
                "Ceyuan Yang",
                "Xuefeng Xiao",
                "Lu Jiang"
            ],
            "affiliations": [
                "ByteDance"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.08316.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#optimization",
                    "#video",
                    "#diffusion",
                    "#training"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "Революция в генерации видео: от итераций к мгновенному результату",
                    "desc": "Эта статья представляет новый метод под названием Adversarial Post-Training (APT) для одношаговой генерации видео. Авторы предлагают улучшения архитектуры модели и процедур обучения, включая аппроксимированную регуляризацию R1. Их модель Seaweed-APT способна генерировать 2-секундные видео высокого разрешения в реальном времени за один проход. Кроме того, модель может создавать изображения размером 1024px за один шаг, достигая качества, сравнимого с современными методами."
                },
                "en": {
                    "title": "Fast and High-Quality Video Generation with Seaweed-APT",
                    "desc": "This paper addresses the slow and costly iterative process of generating images and videos using diffusion models. The authors introduce Adversarial Post-Training (APT) to enhance one-step video generation while maintaining high quality. They implement architectural and procedural improvements, including an approximated R1 regularization, to stabilize training. Their model, Seaweed-APT, successfully generates high-quality 2-second videos and 1024px images in real time with a single forward evaluation step."
                },
                "zh": {
                    "title": "对抗后训练：快速高质量视频生成的新方法",
                    "desc": "扩散模型广泛应用于图像和视频生成，但其迭代生成过程较慢且成本高昂。现有的蒸馏方法在图像领域展示了单步生成的潜力，但仍存在显著的质量下降。本文提出了一种针对真实数据的对抗后训练（APT）方法，以实现单步视频生成。我们的实验表明，经过对抗后训练的模型Seaweed-APT能够实时生成1280x720、24fps的2秒视频，并且在单步生成1024px图像时，其质量可与最先进的方法相媲美。"
                }
            }
        }
    ],
    "link_prev": "2025-01-14.html",
    "link_next": "2025-01-16.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "14.01",
        "en": "01/14",
        "zh": "1月14日"
    },
    "short_date_next": {
        "ru": "16.01",
        "en": "01/16",
        "zh": "1月16日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 1,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种新的方法，叫做过程奖励模型（PRMs），用于大型语言模型（LLMs）在数学推理中的过程监督。目标是识别和减少推理过程中的错误。研究发现，常用的蒙特卡罗（MC）估计方法效果不佳，因为它依赖完成模型评估当前步骤的正确性，导致步骤验证不准确。文章还指出了传统Best-of-N（BoN）评估策略的偏差，并提出了一种共识过滤机制，结合MC估计和LLM-as-a-judge，改进了模型性能和数据效率。最后，文章发布了一个新的最先进的PRM，并提供了未来研究的实用指南。",
        "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
        "pinyin": "这篇文章介绍了一种新的方法，叫做过程奖励模型（PRMs），用于大型语言模型（LLMs）在数学推理中的过程监督。目标是识别和减少推理过程中的错误。研究发现，常用的蒙特卡罗（MC）估计方法效果不佳，因为它依赖完成模型评估当前步骤的正确性，导致步骤验证不准确。文章还指出了传统Best-of-N（BoN）评估策略的偏差，并提出了一种共识过滤机制，结合MC估计和LLM-as-a-judge，改进了模型性能和数据效率。最后，文章发布了一个新的最先进的PRM，并提供了未来研究的实用指南。\n\nzhè piān wénzhāng jièshào le yī zhǒng xīn de fāngfǎ, jiàozuò guòchéng jiǎnglì móxíng (PRMs), yòngyú dàxíng yǔyán móxíng (LLMs) zài shùxué tuīlǐ zhōng de guòchéng jiàndū. Mùbiāo shì shíbié hé jiǎnshǎo tuīlǐ guòchéng zhōng de cuòwù. Yánjiū fāxiàn, chángyòng de méngtèkǎluó (MC) gūjì fāngfǎ xiàojià, yīnwèi tā yīlài wánchéng móxíng píngjià dāngqián bùzhòu de zhèngquèxìng, dǎozhì bùzhòu yànzhèng bù zhǔnquè. Wénzhāng hái zhǐchū le chuántǒng Best-of-N (BoN) píngjià cèlüè de piānchā, bìng tíchū le yī zhǒng gòngshì guòlǜ jīzhì, jiéhé MC gūjì hé LLM-as-a-judge, gǎijìn le móxíng xìngnéng hé shùjù xiàoyòng. Zuìhòu, wénzhāng fābù le yīgè xīn de zuì xiānjìn de PRM, bìng tígōng le wèilái yánjiū de shíyòng zhǐnán.",
        "vocab": "[\n    {\"word\": \"过程奖励模型\", \"pinyin\": \"guòchéng jiǎnglì móxíng\", \"trans\": \"Process Reward Model\"},\n    {\"word\": \"大型语言模型\", \"pinyin\": \"dàxíng yǔyán móxíng\", \"trans\": \"Large Language Model\"},\n    {\"word\": \"数学推理\", \"pinyin\": \"shùxué tuīlǐ\", \"trans\": \"Mathematical Reasoning\"},\n    {\"word\": \"过程监督\", \"pinyin\": \"guòchéng jiàndū\", \"trans\": \"Process Supervision\"},\n    {\"word\": \"蒙特卡罗\", \"pinyin\": \"méngtèkǎluó\", \"trans\": \"Monte Carlo\"},\n    {\"word\": \"估计\", \"pinyin\": \"gūjì\", \"trans\": \"Estimation\"},\n    {\"word\": \"依赖\", \"pinyin\": \"yīlài\", \"trans\": \"Depend\"},\n    {\"word\": \"评估\", \"pinyin\": \"pínggū\", \"trans\": \"Evaluate\"},\n    {\"word\": \"步骤验证\", \"pinyin\": \"bùzhòu yànzhèng\", \"trans\": \"Step Verification\"},\n    {\"word\": \"偏差\", \"pinyin\": \"piānchā\", \"trans\": \"Bias\"},\n    {\"word\": \"共识过滤机制\", \"pinyin\": \"gòngshí guòlǜ jīzhì\", \"trans\": \"Consensus Filtering Mechanism\"},\n    {\"word\": \"LLM-as-a-judge\", \"pinyin\": \"LLM-as-a-judge\", \"trans\": \"LLM-as-a-judge\"},\n    {\"word\": \"最先进\", \"pinyin\": \"zuìxiānjìn\", \"trans\": \"State-of-the-art\"},\n    {\"word\": \"实用指南\", \"pinyin\": \"shíyòng zhǐnán\", \"trans\": \"Practical Guide\"}\n]",
        "trans": "This article introduces a new method called Process Reward Models (PRMs) for process supervision of large language models (LLMs) in mathematical reasoning. The goal is to identify and reduce errors in the reasoning process. The research found that the commonly used Monte Carlo (MC) estimation method performs poorly because it relies on the completion model to evaluate the correctness of the current step, leading to inaccurate step verification. The article also points out the bias in traditional Best-of-N (BoN) evaluation strategies and proposes a consensus filtering mechanism that combines MC estimation and LLM-as-a-judge to improve model performance and data efficiency. Finally, the article releases a new state-of-the-art PRM and provides practical guidelines for future research.",
        "update_ts": "2025-01-14 09:10"
    }
}