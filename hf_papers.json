{
    "date": {
        "ru": "4 июля",
        "en": "July 4",
        "zh": "7月4日"
    },
    "time_utc": "2025-07-04 07:13",
    "weekday": 4,
    "issue_id": 4643,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.02813",
            "title": "LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with\n  TriMap Video Diffusion",
            "url": "https://huggingface.co/papers/2507.02813",
            "abstract": "Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction paradigm, thereby suffering from severe rendering artifacts and implausible semantic synthesis when limited views are available. In this paper, we introduce a novel generative framework, coined LangScene-X, to unify and generate 3D consistent multi-modality information for reconstruction and understanding. Powered by the generative capability of creating more consistent novel observations, we can build generalizable 3D language-embedded scenes from only sparse views. Specifically, we first train a TriMap video diffusion model that can generate appearance (RGBs), geometry (normals), and semantics (segmentation maps) from sparse inputs through progressive knowledge integration. Furthermore, we propose a Language Quantized Compressor (LQC), trained on large-scale image datasets, to efficiently encode language embeddings, enabling cross-scene generalization without per-scene retraining. Finally, we reconstruct the language surface fields by aligning language information onto the surface of 3D scenes, enabling open-ended language queries. Extensive experiments on real-world data demonstrate the superiority of our LangScene-X over state-of-the-art methods in terms of quality and generalizability. Project Page: https://liuff19.github.io/LangScene-X.",
            "score": 33,
            "issue_id": 4638,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 июля",
                "en": "July 3",
                "zh": "7月3日"
            },
            "hash": "726c080e7ea88c4b",
            "authors": [
                "Fangfu Liu",
                "Hao Li",
                "Jiawei Chi",
                "Hanyang Wang",
                "Minghui Yang",
                "Fudong Wang",
                "Yueqi Duan"
            ],
            "affiliations": [
                "Ant Group",
                "NTU",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02813.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#3d",
                    "#games",
                    "#multimodal",
                    "#diffusion"
                ],
                "emoji": "🏙️",
                "ru": {
                    "title": "Генерация 3D-сцен с языковым пониманием по нескольким изображениям",
                    "desc": "LangScene-X - это новая генеративная система для восстановления и понимания 3D-сцен с открытым словарем на основе 2D-изображений. Она использует видео-диффузионную модель TriMap для генерации согласованной мультимодальной информации (RGB, нормали, сегментация) из ограниченного числа ракурсов. Система включает языковой квантованный компрессор (LQC) для эффективного кодирования языковых эмбеддингов, что позволяет обобщать на новые сцены без переобучения. LangScene-X превосходит современные методы по качеству и обобщаемости при реконструкции 3D-сцен с языковой привязкой."
                },
                "en": {
                    "title": "Revolutionizing 3D Reconstruction with Language-Embedded Insights",
                    "desc": "This paper presents LangScene-X, a new framework for creating 3D structures from 2D images using language information. It addresses the limitations of previous methods that relied on dense-view reconstructions, which often resulted in poor quality when only limited views were available. LangScene-X utilizes a TriMap video diffusion model to generate consistent visual and semantic data from sparse inputs, enhancing the reconstruction process. Additionally, it introduces a Language Quantized Compressor to efficiently encode language embeddings, allowing for better generalization across different scenes without needing to retrain for each one."
                },
                "zh": {
                    "title": "LangScene-X：从稀疏视图生成一致的3D场景",
                    "desc": "本文提出了一种新颖的生成框架LangScene-X，用于从稀疏视图中恢复3D结构并进行场景理解。该框架结合了语言信息和多模态数据，能够生成一致的3D场景。我们首先训练了一个TriMap视频扩散模型，从稀疏输入中生成外观、几何和语义信息。通过引入语言量化压缩器（LQC），我们实现了跨场景的泛化，避免了逐场景的重新训练。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02025",
            "title": "IntFold: A Controllable Foundation Model for General and Specialized\n  Biomolecular Structure Prediction",
            "url": "https://huggingface.co/papers/2507.02025",
            "abstract": "We introduce IntFold, a controllable foundation model for both general and specialized biomolecular structure prediction. IntFold demonstrates predictive accuracy comparable to the state-of-the-art AlphaFold3, while utilizing a superior customized attention kernel. Beyond standard structure prediction, IntFold can be adapted to predict allosteric states, constrained structures, and binding affinity through the use of individual adapters. Furthermore, we introduce a novel confidence head to estimate docking quality, offering a more nuanced assessment for challenging targets such as antibody-antigen complexes. Finally, we share insights gained during the training process of this computationally intensive model.",
            "score": 27,
            "issue_id": 4642,
            "pub_date": "2025-07-02",
            "pub_date_card": {
                "ru": "2 июля",
                "en": "July 2",
                "zh": "7月2日"
            },
            "hash": "5e8a0f59d9493778",
            "authors": [
                "The IntFold Team",
                "Leon Qiao",
                "Wayne Bai",
                "He Yan",
                "Gary Liu",
                "Nova Xi",
                "Xiang Zhang"
            ],
            "affiliations": [
                "IntelliGen AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02025.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#healthcare"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "IntFold: Гибкий инструмент для точного прогнозирования биомолекулярных структур",
                    "desc": "IntFold - это новая управляемая базовая модель для предсказания как общих, так и специализированных биомолекулярных структур. Она демонстрирует точность прогнозирования, сравнимую с современной моделью AlphaFold3, используя улучшенное пользовательское ядро внимания. IntFold может быть адаптирована для предсказания аллостерических состояний, ограниченных структур и аффинности связывания с помощью индивидуальных адаптеров. Модель также включает новый блок оценки уверенности для определения качества докинга, что особенно полезно для сложных целей, таких как комплексы антитело-антиген."
                },
                "en": {
                    "title": "IntFold: Advancing Biomolecular Structure Prediction with Precision and Flexibility",
                    "desc": "IntFold is a new foundation model designed for predicting the structures of biomolecules, both in general and specialized contexts. It achieves high accuracy in predictions, rivaling the leading model AlphaFold3, by employing a unique attention mechanism. The model is versatile, allowing for adaptations to predict various states and properties of biomolecules, such as allosteric states and binding affinities, through the use of specific adapters. Additionally, IntFold includes a confidence head that assesses the quality of docking predictions, particularly for complex targets like antibody-antigen interactions, and shares valuable insights from its training process."
                },
                "zh": {
                    "title": "IntFold：生物分子结构预测的新突破",
                    "desc": "我们介绍了IntFold，这是一种可控的基础模型，用于一般和专业的生物分子结构预测。IntFold的预测准确性与最先进的AlphaFold3相当，同时采用了更优的定制注意力核。除了标准的结构预测，IntFold还可以通过使用单独的适配器来预测变构状态、受限结构和结合亲和力。此外，我们引入了一种新颖的置信度头，以评估对接质量，为抗体-抗原复合物等具有挑战性的目标提供更细致的评估。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.01352",
            "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
            "url": "https://huggingface.co/papers/2507.01352",
            "abstract": "Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
            "score": 23,
            "issue_id": 4638,
            "pub_date": "2025-07-02",
            "pub_date_card": {
                "ru": "2 июля",
                "en": "July 2",
                "zh": "7月2日"
            },
            "hash": "955bbdefa8606d12",
            "authors": [
                "Chris Yuhao Liu",
                "Liang Zeng",
                "Yuzhen Xiao",
                "Jujie He",
                "Jiacai Liu",
                "Chaojie Wang",
                "Rui Yan",
                "Wei Shen",
                "Fuxiang Zhang",
                "Jiacheng Xu",
                "Yang Liu",
                "Yahui Zhou"
            ],
            "affiliations": [
                "2050 Research, Skywork AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.01352.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#rlhf",
                    "#training",
                    "#alignment",
                    "#data",
                    "#dataset"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Синергия человека и ИИ для создания передовых моделей вознаграждения",
                    "desc": "Статья представляет новый набор данных предпочтений SynPref-40M, содержащий 40 миллионов пар предпочтений, созданный с помощью двухэтапного процесса, сочетающего человеческую аннотацию и масштабируемость ИИ. На основе этих данных авторы разработали набор моделей вознаграждения Skywork-Reward-V2 с параметрами от 0.6B до 8B. Модели демонстрируют высокую эффективность в различных задачах, включая соответствие человеческим предпочтениям, объективную корректность и безопасность. Исследование подчеркивает важность качественной курации данных и синергии человека и ИИ для улучшения моделей вознаграждения в обучении с подкреплением на основе обратной связи от человека (RLHF)."
                },
                "en": {
                    "title": "Unlocking Human Preferences with Skywork-Reward-V2",
                    "desc": "This paper addresses the limitations of current reward models (RMs) in reinforcement learning from human feedback (RLHF), which struggle to accurately reflect complex human preferences. The authors propose a new large-scale preference dataset, SynPref-40M, containing 40 million preference pairs, to improve the training of RMs. They introduce a two-stage human-AI curation pipeline that combines human annotation with AI scalability to ensure high-quality data. The resulting Skywork-Reward-V2 models, trained on a refined subset of this dataset, demonstrate superior performance across various benchmarks, showcasing the importance of quality data in enhancing reward model effectiveness."
                },
                "zh": {
                    "title": "提升奖励模型的质量与性能",
                    "desc": "本论文探讨了奖励模型在从人类反馈中进行强化学习的重要性。当前的开放奖励模型在评估基准上表现不佳，无法有效捕捉人类偏好的复杂性。为了解决这一问题，作者提出了一个包含4000万对偏好的大规模数据集SynPref-40M，并设计了一个人机协作的两阶段数据处理流程。通过高质量的数据标注和AI的自动化处理，作者训练了Skywork-Reward-V2系列奖励模型，展示了其在多项基准测试中的优越性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.23918",
            "title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and\n  Future Frontiers",
            "url": "https://huggingface.co/papers/2506.23918",
            "abstract": "Recent progress in multimodal reasoning has been significantly advanced by textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning within language. This text-centric approach, however, treats vision as a static, initial context, creating a fundamental \"semantic gap\" between rich perceptual data and discrete symbolic thought. Human cognition often transcends language, utilizing vision as a dynamic mental sketchpad. A similar evolution is now unfolding in AI, marking a fundamental paradigm shift from models that merely think about images to those that can truly think with images. This emerging paradigm is characterized by models leveraging visual information as intermediate steps in their thought process, transforming vision from a passive input into a dynamic, manipulable cognitive workspace. In this survey, we chart this evolution of intelligence along a trajectory of increasing cognitive autonomy, which unfolds across three key stages: from external tool exploration, through programmatic manipulation, to intrinsic imagination. To structure this rapidly evolving field, our survey makes four key contributions. (1) We establish the foundational principles of the think with image paradigm and its three-stage framework. (2) We provide a comprehensive review of the core methods that characterize each stage of this roadmap. (3) We analyze the critical landscape of evaluation benchmarks and transformative applications. (4) We identify significant challenges and outline promising future directions. By providing this structured overview, we aim to offer a clear roadmap for future research towards more powerful and human-aligned multimodal AI.",
            "score": 17,
            "issue_id": 4640,
            "pub_date": "2025-06-30",
            "pub_date_card": {
                "ru": "30 июня",
                "en": "June 30",
                "zh": "6月30日"
            },
            "hash": "8526b6b1e8d4b31e",
            "authors": [
                "Zhaochen Su",
                "Peng Xia",
                "Hangyu Guo",
                "Zhenhua Liu",
                "Yan Ma",
                "Xiaoye Qu",
                "Jiaqi Liu",
                "Yanshu Li",
                "Kaide Zeng",
                "Zhengyuan Yang",
                "Linjie Li",
                "Yu Cheng",
                "Heng Ji",
                "Junxian He",
                "Yi R. Fung"
            ],
            "affiliations": [
                "Microsoft",
                "The Chinese University of Hong Kong",
                "The Hong Kong University of Science and Technology",
                "UIUC",
                "UNC-Chapel Hill"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.23918.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#multimodal",
                    "#reasoning",
                    "#alignment",
                    "#survey"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "От мышления об изображениях к мышлению изображениями: новая эра мультимодального ИИ",
                    "desc": "Эта статья описывает новую парадигму в мультимодальном искусственном интеллекте, где визуальная информация используется как динамический инструмент мышления, а не просто статичный входной контекст. Авторы выделяют три ключевых этапа развития этой парадигмы: от внешнего исследования инструментов через программную манипуляцию к внутреннему воображению. В работе представлен всесторонний обзор методов, характерных для каждого этапа, а также анализ критически важных эталонных тестов и трансформационных приложений. Статья также определяет значительные проблемы и намечает перспективные направления будущих исследований в области мультимодального ИИ."
                },
                "en": {
                    "title": "Transforming Vision into Dynamic Thought in AI",
                    "desc": "This paper discusses the advancements in multimodal reasoning, particularly focusing on the 'think with images' paradigm. It highlights the limitations of traditional text-based reasoning, which treats visual data as static, leading to a disconnect between perception and thought. The authors propose a three-stage framework that evolves from using images as tools to integrating them into cognitive processes, allowing for dynamic manipulation of visual information. The survey aims to provide a structured overview of this emerging field, outlining foundational principles, core methods, evaluation benchmarks, and future research directions."
                },
                "zh": {
                    "title": "从图像思考到思考图像的转变",
                    "desc": "这篇论文探讨了多模态推理的最新进展，特别是文本链式思维（CoT）在语言推理中的应用。作者指出，传统的文本中心方法将视觉视为静态背景，导致感知数据与符号思维之间存在“语义差距”。论文提出了一种新的思维模式，强调视觉信息在思维过程中的动态作用，使其成为可操作的认知工作空间。通过建立三阶段框架，论文为未来的多模态人工智能研究提供了清晰的路线图。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02592",
            "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
            "url": "https://huggingface.co/papers/2507.02592",
            "abstract": "Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.",
            "score": 15,
            "issue_id": 4638,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 июля",
                "en": "July 3",
                "zh": "7月3日"
            },
            "hash": "0a8cc61c0251e5da",
            "authors": [
                "Kuan Li",
                "Zhongwang Zhang",
                "Huifeng Yin",
                "Liwen Zhang",
                "Litu Ou",
                "Jialong Wu",
                "Wenbiao Yin",
                "Baixuan Li",
                "Zhengwei Tao",
                "Xinyu Wang",
                "Weizhou Shen",
                "Junkai Zhang",
                "Dingchu Zhang",
                "Xixi Wu",
                "Yong Jiang",
                "Ming Yan",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02592.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#training",
                    "#agents",
                    "#rl"
                ],
                "emoji": "🧭",
                "ru": {
                    "title": "WebSailor: навигация в океане неопределенности для ИИ",
                    "desc": "Статья представляет новый метод обучения языковых моделей под названием WebSailor. Он направлен на преодоление когнитивных ограничений человека в задачах поиска сложной информации. WebSailor использует генерацию задач с высокой неопределенностью и обучение с подкреплением для развития способности моделей систематически снижать неопределенность. Результаты показывают, что WebSailor позволяет открытым моделям достичь производительности проприетарных систем в сложных информационных задачах."
                },
                "en": {
                    "title": "Empowering Open-Source Agents to Compete with the Best",
                    "desc": "This paper discusses advancements in training large language models (LLMs) to surpass human cognitive limitations. It highlights the success of proprietary systems like DeepResearch, which excel in complex information-seeking tasks due to their unique reasoning abilities. The authors introduce WebSailor, a post-training methodology that enhances LLMs by generating high-uncertainty tasks and employing a novel reinforcement learning algorithm called Duplicating Sampling Policy Optimization (DUPO). The results show that WebSailor significantly improves the performance of open-source agents, enabling them to compete with proprietary models in challenging information retrieval scenarios."
                },
                "zh": {
                    "title": "超越认知局限，提升信息检索能力",
                    "desc": "本论文探讨了超越人类认知局限性在大型语言模型（LLM）训练中的重要性。我们提出的WebSailor方法通过系统性地减少在广阔信息环境中导航时的极端不确定性，来提升模型的推理能力。该方法结合了结构化采样和信息模糊化等技术，生成新的高不确定性任务，并采用高效的强化学习算法进行训练。实验结果表明，WebSailor在复杂的信息检索任务中显著优于所有开源代理，缩小了与专有代理的能力差距。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02652",
            "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for\n  Deep Search",
            "url": "https://huggingface.co/papers/2507.02652",
            "abstract": "Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA.",
            "score": 10,
            "issue_id": 4638,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 июля",
                "en": "July 3",
                "zh": "7月3日"
            },
            "hash": "e833cc483ac9b10c",
            "authors": [
                "Jiajie Jin",
                "Xiaoxi Li",
                "Guanting Dong",
                "Yuyao Zhang",
                "Yutao Zhu",
                "Yang Zhao",
                "Hongjin Qian",
                "Zhicheng Dou"
            ],
            "affiliations": [
                "Gaoling School of Artificial Intelligence, Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02652.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rag",
                    "#benchmark",
                    "#multimodal",
                    "#agents"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "HiRA: Иерархический подход к сложному информационному поиску",
                    "desc": "Статья представляет HiRA - иерархическую систему для сложных информационных запросов. HiRA разделяет стратегическое планирование и специализированное выполнение задач, что позволяет эффективнее обрабатывать многоэтапные запросы. Система декомпозирует сложные задачи на подзадачи и назначает их специализированным агентам с внешними инструментами. Эксперименты показали, что HiRA превосходит современные RAG-системы и агентные подходы по качеству ответов и эффективности."
                },
                "en": {
                    "title": "HiRA: Enhancing Search Efficiency through Hierarchical Reasoning",
                    "desc": "This paper presents HiRA, a new framework designed to improve complex information retrieval tasks by separating high-level planning from detailed execution. Traditional methods often struggle because they use a single model for both tasks, which can lead to inefficiencies. HiRA addresses this by breaking down complex search tasks into smaller subtasks, each handled by specialized agents that have their own tools and reasoning abilities. The results show that HiRA outperforms existing systems in both the quality of answers and overall efficiency, demonstrating the benefits of this hierarchical approach."
                },
                "zh": {
                    "title": "HiRA：分层框架提升搜索效率与质量",
                    "desc": "在现实世界的搜索场景中，复杂的信息需求需要深度推理和知识综合，而传统的检索增强生成（RAG）管道难以有效应对。当前的推理方法存在一个根本性限制：它们使用单一模型处理高层次规划和详细执行，导致推理效率低下和可扩展性有限。本文提出了HiRA，一个分层框架，将战略规划与专业执行分开。我们的研究表明，HiRA在复杂的跨模态深度搜索基准测试中显著优于现有的RAG和基于代理的系统，提升了答案质量和系统效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02754",
            "title": "Fast and Simplex: 2-Simplicial Attention in Triton",
            "url": "https://huggingface.co/papers/2507.02754",
            "abstract": "Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency.   In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that 2-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention.",
            "score": 6,
            "issue_id": 4638,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 июля",
                "en": "July 3",
                "zh": "7月3日"
            },
            "hash": "a9492490e5a70bc4",
            "authors": [
                "Aurko Roy",
                "Timothy Chou",
                "Sai Surya Duvvuri",
                "Sijia Chen",
                "Jiecao Yu",
                "Xiaodong Wang",
                "Manzil Zaheer",
                "Rohan Anil"
            ],
            "affiliations": [
                "Department of Computer Science University of Texas at Austin",
                "Meta Menlo Park, CA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02754.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#optimization",
                    "#reasoning",
                    "#math",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Повышение эффективности языковых моделей с помощью 2-симплициального внимания",
                    "desc": "В статье исследуется архитектура 2-симплициального трансформера, обобщающая стандартное внимание на основе скалярного произведения до трилинейных функций. Авторы показывают, что эта архитектура достигает лучшей эффективности использования токенов по сравнению со стандартными трансформерами. При фиксированном бюджете токенов модели сопоставимого размера превосходят аналоги со скалярным произведением в задачах математики, программирования, рассуждений и логики. Количественно преимущества выражаются в изменении показателя степени в законах масштабирования для задач, связанных со знаниями и рассуждениями."
                },
                "en": {
                    "title": "Enhancing Token Efficiency with 2-Simplicial Transformers",
                    "desc": "This paper explores the limitations of current scaling laws in machine learning, particularly in the context of large language models that are no longer purely compute-bound due to their reliance on vast datasets. It introduces the 2-simplicial Transformer, a new architecture that enhances standard attention mechanisms by using trilinear functions, which improves token efficiency. The authors show that this new architecture allows models to perform better on various tasks, such as mathematics and reasoning, while using the same number of tokens. By quantifying the improvements, they reveal that the 2-simplicial attention modifies the scaling laws, leading to better performance in knowledge and reasoning tasks compared to traditional dot-product attention."
                },
                "zh": {
                    "title": "提升标记效率的2-单纯形变换器",
                    "desc": "最近的研究表明，训练损失与模型大小和标记数量呈幂律关系，达到计算最优模型需要同时扩大模型大小和标记数量。然而，这些缩放法则假设数据是无限的，并主要适用于计算受限的环境。随着现代大型语言模型越来越依赖于大规模互联网数据集，这种假设变得不再有效。因此，我们需要优先考虑标记效率的架构。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02694",
            "title": "Can LLMs Identify Critical Limitations within Scientific Research? A\n  Systematic Evaluation on AI Research Papers",
            "url": "https://huggingface.co/papers/2507.02694",
            "abstract": "Peer review is fundamental to scientific research, but the growing volume of publications has intensified the challenges of this expertise-intensive process. While LLMs show promise in various scientific tasks, their potential to assist with peer review, particularly in identifying paper limitations, remains understudied. We first present a comprehensive taxonomy of limitation types in scientific research, with a focus on AI. Guided by this taxonomy, for studying limitations, we present LimitGen, the first comprehensive benchmark for evaluating LLMs' capability to support early-stage feedback and complement human peer review. Our benchmark consists of two subsets: LimitGen-Syn, a synthetic dataset carefully created through controlled perturbations of high-quality papers, and LimitGen-Human, a collection of real human-written limitations. To improve the ability of LLM systems to identify limitations, we augment them with literature retrieval, which is essential for grounding identifying limitations in prior scientific findings. Our approach enhances the capabilities of LLM systems to generate limitations in research papers, enabling them to provide more concrete and constructive feedback.",
            "score": 6,
            "issue_id": 4641,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 июля",
                "en": "July 3",
                "zh": "7月3日"
            },
            "hash": "d7b392be540c08ba",
            "authors": [
                "Zhijian Xu",
                "Yilun Zhao",
                "Manasi Patwardhan",
                "Lovekesh Vig",
                "Arman Cohan"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2507.02694.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#rag",
                    "#dataset",
                    "#benchmark",
                    "#synthetic",
                    "#science"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "ИИ на страже научной объективности: LLM как помощник в рецензировании",
                    "desc": "Статья посвящена использованию больших языковых моделей (LLM) для помощи в процессе рецензирования научных работ, особенно в выявлении ограничений исследований. Авторы представляют таксономию типов ограничений в научных исследованиях и создают бенчмарк LimitGen для оценки способности LLM поддерживать ранние этапы обратной связи. LimitGen включает синтетический набор данных и реальные ограничения, написанные людьми. Исследователи улучшают способность LLM выявлять ограничения, дополняя их поиском по научной литературе."
                },
                "en": {
                    "title": "Empowering Peer Review with AI: LimitGen for Identifying Research Limitations",
                    "desc": "This paper addresses the challenges of peer review in scientific research due to the increasing number of publications. It introduces a taxonomy of limitation types specifically for AI research, which helps in understanding the weaknesses of scientific papers. The authors present LimitGen, a benchmark designed to evaluate how well large language models (LLMs) can assist in identifying these limitations and provide feedback. By incorporating literature retrieval, the study enhances LLMs' ability to generate relevant and constructive critiques of research papers."
                },
                "zh": {
                    "title": "提升同行评审的智能化支持",
                    "desc": "同行评审是科学研究的重要环节，但随着出版物数量的增加，这一过程面临越来越大的挑战。本文提出了一种全面的科学研究局限性分类法，特别关注人工智能领域。我们介绍了LimitGen，这是第一个评估大型语言模型（LLM）在支持早期反馈和补充人类评审方面能力的基准测试。通过结合文献检索，我们增强了LLM系统识别研究局限性的能力，从而能够提供更具体和建设性的反馈。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02726",
            "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving",
            "url": "https://huggingface.co/papers/2507.02726",
            "abstract": "Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.",
            "score": 2,
            "issue_id": 4638,
            "pub_date": "2025-07-03",
            "pub_date_card": {
                "ru": "3 июля",
                "en": "July 3",
                "zh": "7月3日"
            },
            "hash": "42e132c4863440b8",
            "authors": [
                "Matthieu Zimmer",
                "Xiaotong Ji",
                "Rasul Tutunov",
                "Anthony Bordg",
                "Jun Wang",
                "Haitham Bou Ammar"
            ],
            "affiliations": [
                "Huawei Noahs Ark Lab",
                "Imperial College London",
                "Lagrange Center",
                "UCL Centre for AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02726.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#reasoning",
                    "#benchmark",
                    "#agents",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Самогенерируемые цели улучшают автоматическое доказательство теорем",
                    "desc": "Статья представляет новый подход к автоматическому доказательству теорем с использованием больших языковых моделей (LLM). Авторы предлагают фреймворк sG-MDP, в котором агенты генерируют и преследуют подцели на основе текущего состояния доказательства. Они применяют алгоритмы, подобные Monte Carlo Tree Search, для решения sG-MDP. Результатом является система Bourbaki (7B), которая достигает новых рекордных результатов на бенчмарке PutnamBench для моделей своего масштаба."
                },
                "en": {
                    "title": "Empowering Reasoning with Self-Generated Goals in Theorem Proving",
                    "desc": "This paper addresses the difficulties that large language models (LLMs) face in reasoning tasks, particularly in automated theorem proving (ATP) where rewards are sparse and proofs are complex. The authors propose a novel framework called self-generated goal-conditioned MDPs (sG-MDPs), which allows agents to create and pursue subgoals based on the current state of the proof. By structuring goal generation, the problem becomes easier to navigate and search. The framework is implemented in a system called Bourbaki (7B), which utilizes multiple LLMs to enhance subgoal generation and tactic synthesis, achieving state-of-the-art results on the challenging PutnamBench benchmark."
                },
                "zh": {
                    "title": "自生成目标助力推理挑战",
                    "desc": "本文探讨了大型语言模型（LLMs）在自动定理证明（ATP）中的推理挑战，尤其是在稀疏奖励和证明规模庞大的情况下。为了解决这些问题，提出了一种新的框架——自生成目标条件马尔可夫决策过程（sG-MDPs），使得智能体能够根据不断变化的证明状态生成和追求子目标。通过这种结构化的目标生成，问题变得更易于搜索。最后，应用类似蒙特卡洛树搜索（MCTS）的算法解决sG-MDP，并在Bourbaki（7B）系统中实现，成功在PutnamBench上解决了26个问题，创造了新的最先进结果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.02092",
            "title": "Energy-Based Transformers are Scalable Learners and Thinkers",
            "url": "https://huggingface.co/papers/2507.02092",
            "abstract": "Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question \"Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?\" Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.",
            "score": 2,
            "issue_id": 4642,
            "pub_date": "2025-07-02",
            "pub_date_card": {
                "ru": "2 июля",
                "en": "July 2",
                "zh": "7月2日"
            },
            "hash": "9f33fd27885f443d",
            "authors": [
                "Alexi Gladstone",
                "Ganesh Nanduru",
                "Md Mofijul Islam",
                "Peixuan Han",
                "Hyeonjeong Ha",
                "Aman Chadha",
                "Yilun Du",
                "Heng Ji",
                "Jundong Li",
                "Tariq Iqbal"
            ],
            "affiliations": [
                "Amazon GenAI",
                "Harvard University",
                "Stanford University",
                "UIUC",
                "UVA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.02092.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#inference",
                    "#training",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "EBTs: Обучение мышлению через неконтролируемое обучение",
                    "desc": "Эта статья представляет новый класс моделей - Energy-Based Transformers (EBTs), которые обучаются проверять совместимость входных данных и предсказаний. EBTs переформулируют задачу предсказания как оптимизацию относительно верификатора, что позволяет им применять методы мышления 'Системы 2' без дополнительного обучения. Исследования показывают, что EBTs масштабируются быстрее, чем стандартные трансформеры, и демонстрируют лучшую производительность на задачах обработки текста и изображений. Авторы утверждают, что EBTs представляют собой многообещающую новую парадигму для масштабирования как обучающих, так и мыслительных способностей моделей."
                },
                "en": {
                    "title": "Energy-Based Transformers: Scaling Learning and Thinking in AI",
                    "desc": "This paper introduces Energy-Based Transformers (EBTs), a new type of model that enhances inference-time computation by mimicking human System 2 Thinking. EBTs learn to verify the compatibility between inputs and predictions without needing additional supervision, making them more generalizable across different modalities and tasks. The authors demonstrate that EBTs can scale faster than existing models like Transformer++ and achieve superior performance in both language and image tasks. Overall, EBTs represent a significant advancement in the efficiency and effectiveness of machine learning models."
                },
                "zh": {
                    "title": "能量基础变换器：无监督学习的新思维方式",
                    "desc": "本文探讨了一种新的模型——能量基础变换器（EBTs），旨在通过无监督学习来实现更好的推理能力。EBTs通过显式验证输入与候选预测之间的兼容性，将预测问题重新框架为优化问题，从而提高模型的性能。研究表明，EBTs在训练过程中比传统的Transformer++方法具有更快的扩展速度，并在推理时在语言任务上提高了29%的性能。总体而言，EBTs在大多数下游任务中表现优于现有模型，显示出更好的泛化能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.01663",
            "title": "AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM\n  Post-Training",
            "url": "https://huggingface.co/papers/2507.01663",
            "abstract": "Reinforcement learning (RL) has become a pivotal technology in the post-training phase of large language models (LLMs). Traditional task-colocated RL frameworks suffer from significant scalability bottlenecks, while task-separated RL frameworks face challenges in complex dataflows and the corresponding resource idling and workload imbalance. Moreover, most existing frameworks are tightly coupled with LLM training or inference engines, making it difficult to support custom-designed engines. To address these challenges, we propose AsyncFlow, an asynchronous streaming RL framework for efficient post-training. Specifically, we introduce a distributed data storage and transfer module that provides a unified data management and fine-grained scheduling capability in a fully streamed manner. This architecture inherently facilitates automated pipeline overlapping among RL tasks and dynamic load balancing. Moreover, we propose a producer-consumer-based asynchronous workflow engineered to minimize computational idleness by strategically deferring parameter update process within staleness thresholds. Finally, the core capability of AsynFlow is architecturally decoupled from underlying training and inference engines and encapsulated by service-oriented user interfaces, offering a modular and customizable user experience. Extensive experiments demonstrate an average of 1.59 throughput improvement compared with state-of-the-art baseline. The presented architecture in this work provides actionable insights for next-generation RL training system designs.",
            "score": 1,
            "issue_id": 4639,
            "pub_date": "2025-07-02",
            "pub_date_card": {
                "ru": "2 июля",
                "en": "July 2",
                "zh": "7月2日"
            },
            "hash": "8a3f43a4a9e735d7",
            "authors": [
                "Zhenyu Han",
                "Ansheng You",
                "Haibo Wang",
                "Kui Luo",
                "Guang Yang",
                "Wenqi Shi",
                "Menglong Chen",
                "Sicheng Zhang",
                "Zeshun Lan",
                "Chunshi Deng",
                "Huazhong Ji",
                "Wenjie Liu",
                "Yu Huang",
                "Yixiang Zhang",
                "Chenyi Pan",
                "Jing Wang",
                "Xin Huang",
                "Chunsheng Li",
                "Jianping Wu"
            ],
            "affiliations": [
                "Huawei"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.01663.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "AsyncFlow: Асинхронное обучение с подкреплением для больших языковых моделей",
                    "desc": "AsyncFlow - это новая асинхронная потоковая система обучения с подкреплением для эффективной пост-обработки больших языковых моделей. Она вводит распределенный модуль хранения и передачи данных, обеспечивающий унифицированное управление данными и детальное планирование в потоковом режиме. AsyncFlow использует асинхронный рабочий процесс на основе модели производитель-потребитель для минимизации простоев вычислений. Система показывает среднее улучшение пропускной способности в 1,59 раза по сравнению с современными аналогами."
                },
                "en": {
                    "title": "AsyncFlow: Revolutionizing RL for Large Language Models",
                    "desc": "This paper introduces AsyncFlow, a new framework for reinforcement learning (RL) that enhances the post-training phase of large language models (LLMs). It addresses scalability issues found in traditional RL frameworks by implementing a distributed data storage and transfer system, which allows for efficient data management and scheduling. The framework also features an asynchronous workflow that reduces idle computation time by optimizing the timing of parameter updates. Overall, AsyncFlow is designed to be modular and customizable, making it easier to integrate with various training and inference engines while improving throughput significantly."
                },
                "zh": {
                    "title": "AsyncFlow：高效的异步流式强化学习框架",
                    "desc": "强化学习（RL）在大型语言模型（LLM）的后训练阶段变得至关重要。传统的任务共存RL框架面临可扩展性瓶颈，而任务分离的RL框架在复杂数据流和资源闲置方面存在挑战。为了解决这些问题，我们提出了AsyncFlow，一个高效的异步流式RL框架，能够实现自动化的管道重叠和动态负载平衡。我们的实验表明，与最先进的基线相比，AsyncFlow在吞吐量上平均提高了1.59倍。"
                }
            }
        }
    ],
    "link_prev": "2025-07-03.html",
    "link_next": "2025-07-07.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "03.07",
        "en": "07/03",
        "zh": "7月3日"
    },
    "short_date_next": {
        "ru": "07.07",
        "en": "07/07",
        "zh": "7月7日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 4,
        "#agents": 3,
        "#cv": 0,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 2,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 4,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 5,
        "#healthcare": 1,
        "#training": 6,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 6,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 5,
        "#survey": 1,
        "#diffusion": 1,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    }
}