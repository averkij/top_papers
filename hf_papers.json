{
    "date": {
        "ru": "25 августа",
        "en": "August 25",
        "zh": "8月25日"
    },
    "time_utc": "2025-08-25 10:14",
    "weekday": 0,
    "issue_id": 5524,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2508.16153",
            "title": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs",
            "url": "https://huggingface.co/papers/2508.16153",
            "abstract": "A novel memory-augmented reinforcement learning paradigm enables adaptive LLM agents to continually learn without fine-tuning, using episodic memory and a neural case-selection policy.  \t\t\t\t\tAI-generated summary \t\t\t\t In this paper, we introduce a novel learning paradigm for adaptive Large Language Model (LLM) agents that eliminates the need for fine-tuning the underlying LLMs. Existing approaches are often either rigid, relying on static, handcrafted reflection workflows, or computationally intensive, requiring gradient updates of LLM model parameters. In contrast, our method enables low-cost continual adaptation via memory-based online reinforcement learning. We formalise this as a Memory-augmented Markov Decision Process (M-MDP), equipped with a neural case-selection policy to guide action decisions. Past experiences are stored in an episodic memory, either differentiable or non-parametric. The policy is continually updated based on environmental feedback through a memory rewriting mechanism, whereas policy improvement is achieved through efficient memory reading (retrieval). We instantiate our agent model in the deep research setting, namely AgentFly, which attains top-1 on GAIA validation (87.88% Pass@3) and 79.40% on the test set. It reaches 66.6% F1 and 80.4% PM on the DeepResearcher dataset, outperforming the state-of-the-art training-based method, while case-based memory adds 4.7% to 9.6% absolute points on out-of-distribution tasks. Our approach offers a scalable and efficient pathway for developing generalist LLM agents capable of continuous, real-time learning without gradient updates, advancing machine learning towards open-ended skill acquisition and deep research scenarios. The code is available at https://github.com/Agent-on-the-Fly/AgentFly.",
            "score": 27,
            "issue_id": 5518,
            "pub_date": "2025-08-22",
            "pub_date_card": {
                "ru": "22 августа",
                "en": "August 22",
                "zh": "8月22日"
            },
            "hash": "6286f08d6e4a4187",
            "authors": [
                "Huichi Zhou",
                "Yihang Chen",
                "Siyuan Guo",
                "Xue Yan",
                "Kin Hei Lee",
                "Zihan Wang",
                "Ka Yiu Lee",
                "Guchun Zhang",
                "Kun Shao",
                "Linyi Yang",
                "Jun Wang"
            ],
            "affiliations": [
                "AI Centre, UCL",
                "Huawei Noahs Ark Lab, UK",
                "Institute of Automation, CAS",
                "Jilin University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.16153.jpg",
            "data": {
                "categories": [
                    "#agi",
                    "#optimization",
                    "#rl",
                    "#agents"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Непрерывное обучение LLM-агентов без дообучения",
                    "desc": "В этой статье представлена новая парадигма обучения для адаптивных агентов на основе больших языковых моделей (LLM), которая устраняет необходимость в их дообучении. Метод использует эпизодическую память и нейронную политику выбора примеров для непрерывной адаптации через обучение с подкреплением на основе памяти. Авторы формализуют подход как марковский процесс принятия решений с дополненной памятью (M-MDP). Реализация модели агента под названием AgentFly достигает высоких результатов на нескольких наборах данных, превосходя современные методы, основанные на обучении."
                },
                "en": {
                    "title": "Empowering LLMs with Memory for Continuous Learning",
                    "desc": "This paper presents a new approach for adaptive Large Language Model (LLM) agents that allows them to learn continuously without the need for fine-tuning. The method utilizes a Memory-augmented Markov Decision Process (M-MDP) that incorporates episodic memory and a neural case-selection policy to make decisions based on past experiences. By leveraging memory-based online reinforcement learning, the agents can adapt to new information efficiently, improving their performance on various tasks. The results show that this approach outperforms traditional training methods, making it a promising direction for developing versatile LLM agents capable of ongoing learning."
                },
                "zh": {
                    "title": "记忆增强的自适应学习，持续进步无微调",
                    "desc": "本文提出了一种新颖的记忆增强强化学习范式，使自适应的大型语言模型（LLM）代理能够在不进行微调的情况下持续学习。与传统方法相比，我们的方法通过基于记忆的在线强化学习实现了低成本的持续适应，避免了静态的手工反思流程和计算密集型的梯度更新。我们将其形式化为记忆增强马尔可夫决策过程（M-MDP），并使用神经案例选择策略来指导行动决策。我们的代理模型在深度研究环境中表现优异，超越了现有的基于训练的方法，展示了在开放式技能获取和深度研究场景中的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.08240",
            "title": "ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for\n  Long-Horizon Tasks",
            "url": "https://huggingface.co/papers/2508.08240",
            "abstract": "ODYSSEY is a unified mobile manipulation framework for quadruped robots that integrates high-level task planning with low-level whole-body control, addressing challenges in egocentric perception, generalization, and coordination in unstructured environments.  \t\t\t\t\tAI-generated summary \t\t\t\t Language-guided long-horizon mobile manipulation has long been a grand challenge in embodied semantic reasoning, generalizable manipulation, and adaptive locomotion. Three fundamental limitations hinder progress: First, although large language models have improved spatial reasoning and task planning through semantic priors, existing implementations remain confined to tabletop scenarios, failing to address the constrained perception and limited actuation ranges of mobile platforms. Second, current manipulation strategies exhibit insufficient generalization when confronted with the diverse object configurations encountered in open-world environments. Third, while crucial for practical deployment, the dual requirement of maintaining high platform maneuverability alongside precise end-effector control in unstructured settings remains understudied.   In this work, we present ODYSSEY, a unified mobile manipulation framework for agile quadruped robots equipped with manipulators, which seamlessly integrates high-level task planning with low-level whole-body control. To address the challenge of egocentric perception in language-conditioned tasks, we introduce a hierarchical planner powered by a vision-language model, enabling long-horizon instruction decomposition and precise action execution. At the control level, our novel whole-body policy achieves robust coordination across challenging terrains. We further present the first benchmark for long-horizon mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through successful sim-to-real transfer, we demonstrate the system's generalization and robustness in real-world deployments, underscoring the practicality of legged manipulators in unstructured environments. Our work advances the feasibility of generalized robotic assistants capable of complex, dynamic tasks. Our project page: https://kaijwang.github.io/odyssey.github.io/",
            "score": 25,
            "issue_id": 5522,
            "pub_date": "2025-08-11",
            "pub_date_card": {
                "ru": "11 августа",
                "en": "August 11",
                "zh": "8月11日"
            },
            "hash": "313edb98990f0684",
            "authors": [
                "Kaijun Wang",
                "Liqin Lu",
                "Mingyu Liu",
                "Jianuo Jiang",
                "Zeju Li",
                "Bolin Zhang",
                "Wancai Zheng",
                "Xinyi Yu",
                "Hao Chen",
                "Chunhua Shen"
            ],
            "affiliations": [
                "The Chinese University of Hong Kong, Shenzhen",
                "Zhejiang University",
                "Zhejiang University of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.08240.jpg",
            "data": {
                "categories": [
                    "#robotics",
                    "#transfer_learning",
                    "#optimization",
                    "#reasoning",
                    "#agents",
                    "#benchmark"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Мобильная манипуляция роботов: от планирования к действию",
                    "desc": "ODYSSEY - это унифицированная система мобильной манипуляции для четвероногих роботов, объединяющая высокоуровневое планирование задач с низкоуровневым управлением всем телом. Система решает проблемы эгоцентрического восприятия, обобщения и координации в неструктурированной среде с помощью иерархического планировщика на основе визуально-языковой модели. На уровне управления используется оригинальная политика для всего тела робота, обеспечивающая надежную координацию на сложных поверхностях. ODYSSEY демонстрирует обобщение и надежность при развертывании в реальном мире, подчеркивая практичность использования четвероногих манипуляторов в неструктурированных средах."
                },
                "en": {
                    "title": "Empowering Quadruped Robots for Complex Mobile Manipulation",
                    "desc": "ODYSSEY is a new framework designed for quadruped robots that combines high-level planning with low-level control to improve mobile manipulation. It addresses key challenges such as understanding tasks through language, adapting to various object configurations, and coordinating movements in complex environments. The framework uses a vision-language model for better perception and task execution, allowing robots to follow long-term instructions effectively. Additionally, it includes a benchmark for testing these capabilities in real-world scenarios, showcasing the potential of robots to perform complex tasks in dynamic settings."
                },
                "zh": {
                    "title": "四足机器人移动操控的新突破",
                    "desc": "ODYSSEY是一个统一的移动操控框架，专为四足机器人设计，结合了高层次的任务规划和低层次的全身控制。该框架解决了在非结构化环境中自我中心感知、泛化和协调等挑战。我们引入了一种基于视觉-语言模型的分层规划器，能够实现长时间指令的分解和精确执行。通过成功的模拟到现实转移，展示了该系统在真实环境中的泛化能力和鲁棒性，推动了复杂动态任务的机器人助手的可行性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.14029",
            "title": "Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains\n  RLVR",
            "url": "https://huggingface.co/papers/2508.14029",
            "abstract": "An online self-play strategy with variational problem synthesis for RLVR training maintains policy entropy and improves Pass@k performance on reasoning benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a key paradigm for post-training Large Language Models (LLMs), particularly for complex reasoning tasks. However, vanilla RLVR training has been shown to improve Pass@1 performance at the expense of policy entropy, leading to reduced generation diversity and limiting the Pass@k performance, which typically represents the upper bound of LLM reasoning capability. In this paper, we systematically analyze the policy's generation diversity from the perspective of training problems and find that augmenting and updating training problems helps mitigate entropy collapse during training. Based on these observations, we propose an online Self-play with Variational problem Synthesis (SvS) strategy for RLVR training, which uses the policy's correct solutions to synthesize variational problems while ensuring their reference answers remain identical to the originals. This self-improving strategy effectively maintains policy entropy during training and substantially improves Pass@k compared with standard RLVR, sustaining prolonged improvements and achieving absolute gains of 18.3% and 22.8% in Pass@32 performance on the competition-level AIME24 and AIME25 benchmarks. Experiments on 12 reasoning benchmarks across varying model sizes from 3B to 32B consistently demonstrate the generalizability and robustness of SvS.",
            "score": 13,
            "issue_id": 5520,
            "pub_date": "2025-08-19",
            "pub_date_card": {
                "ru": "19 августа",
                "en": "August 19",
                "zh": "8月19日"
            },
            "hash": "615692d5b0adab3d",
            "authors": [
                "Xiao Liang",
                "Zhongzhi Li",
                "Yeyun Gong",
                "Yelong Shen",
                "Ying Nian Wu",
                "Zhijiang Guo",
                "Weizhu Chen"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Hong Kong University of Science and Technology (Guangzhou)",
                "Microsoft",
                "School of Artificial Intelligence, Chinese Academy of Sciences",
                "University of California, Los Angeles"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.14029.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#benchmark",
                    "#optimization",
                    "#rlhf",
                    "#reasoning",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Самоулучшение языковых моделей через синтез вариативных задач",
                    "desc": "Статья представляет новую стратегию обучения с подкреплением с проверяемыми наградами (RLVR) для улучшения языковых моделей в задачах рассуждения. Предложенный метод Self-play with Variational problem Synthesis (SvS) использует правильные решения модели для синтеза вариативных задач, сохраняя при этом энтропию политики. Это позволяет значительно улучшить показатель Pass@k по сравнению со стандартным RLVR. Эксперименты на 12 наборах данных для оценки рассуждений показали эффективность и обобщаемость предложенного подхода для моделей различного размера."
                },
                "en": {
                    "title": "Enhancing Reasoning Performance with Self-Play and Variational Synthesis",
                    "desc": "This paper introduces a novel online self-play strategy called Self-play with Variational problem Synthesis (SvS) for training Reinforcement Learning with Verifiable Rewards (RLVR) in large language models. The authors identify that traditional RLVR training can lead to reduced policy entropy, which negatively impacts the diversity of generated outputs and overall performance on reasoning tasks. By augmenting and updating training problems, SvS maintains policy entropy and enhances the model's ability to generate diverse and accurate responses. The results show significant improvements in Pass@k performance on various reasoning benchmarks, demonstrating the effectiveness and robustness of the proposed method."
                },
                "zh": {
                    "title": "自我对弈策略提升推理能力",
                    "desc": "本文提出了一种在线自我对弈策略，结合变分问题合成，用于强化学习可验证奖励（RLVR）训练。该方法通过增强和更新训练问题，解决了传统RLVR训练中策略熵降低的问题，从而提高了生成多样性。我们的方法在训练过程中有效维持了策略熵，并显著提升了在推理基准测试中的Pass@k表现。实验结果表明，该策略在不同规模的模型上均表现出良好的泛化能力和鲁棒性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.13650",
            "title": "CRISP: Persistent Concept Unlearning via Sparse Autoencoders",
            "url": "https://huggingface.co/papers/2508.13650",
            "abstract": "CRISP is a parameter-efficient method using sparse autoencoders to permanently remove unwanted knowledge from large language models while preserving their utility.  \t\t\t\t\tAI-generated summary \t\t\t\t As large language models (LLMs) are increasingly deployed in real-world applications, the need to selectively remove unwanted knowledge while preserving model utility has become paramount. Recent work has explored sparse autoencoders (SAEs) to perform precise interventions on monosemantic features. However, most SAE-based methods operate at inference time, which does not create persistent changes in the model's parameters. Such interventions can be bypassed or reversed by malicious actors with parameter access. We introduce CRISP, a parameter-efficient method for persistent concept unlearning using SAEs. CRISP automatically identifies salient SAE features across multiple layers and suppresses their activations. We experiment with two LLMs and show that our method outperforms prior approaches on safety-critical unlearning tasks from the WMDP benchmark, successfully removing harmful knowledge while preserving general and in-domain capabilities. Feature-level analysis reveals that CRISP achieves semantically coherent separation between target and benign concepts, allowing precise suppression of the target features.",
            "score": 10,
            "issue_id": 5520,
            "pub_date": "2025-08-19",
            "pub_date_card": {
                "ru": "19 августа",
                "en": "August 19",
                "zh": "8月19日"
            },
            "hash": "bfe846ca6ab823e6",
            "authors": [
                "Tomer Ashuach",
                "Dana Arad",
                "Aaron Mueller",
                "Martin Tutek",
                "Yonatan Belinkov"
            ],
            "affiliations": [
                "Boston University",
                "TakeLab, University of Zagreb",
                "Technion Israel Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.13650.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#ethics",
                    "#training",
                    "#security"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Точное удаление знаний из нейросетей без потери функциональности",
                    "desc": "CRISP - это эффективный метод для удаления нежелательных знаний из больших языковых моделей (LLM) с использованием разреженных автоэнкодеров. Метод позволяет сохранить полезность модели, при этом внося постоянные изменения в её параметры. CRISP автоматически идентифицирует важные признаки в нескольких слоях модели и подавляет их активации. Эксперименты показали, что CRISP превосходит предыдущие подходы в задачах забывания критически важной информации, сохраняя при этом общие возможности модели."
                },
                "en": {
                    "title": "CRISP: Permanently Unlearning Harmful Knowledge in LLMs",
                    "desc": "CRISP is a novel method designed to efficiently remove unwanted knowledge from large language models (LLMs) using sparse autoencoders (SAEs). Unlike previous approaches that only intervene at inference time, CRISP makes permanent changes to the model's parameters, ensuring that harmful knowledge cannot be easily restored. The method identifies important features across different layers of the model and suppresses their activations, effectively achieving concept unlearning. Our experiments demonstrate that CRISP outperforms existing techniques in safety-critical tasks, maintaining the model's overall performance while ensuring a clear distinction between harmful and benign knowledge."
                },
                "zh": {
                    "title": "CRISP：高效的知识去除方法",
                    "desc": "CRISP是一种高效的参数方法，利用稀疏自编码器（SAE）从大型语言模型中永久性地去除不必要的知识，同时保持模型的实用性。随着大型语言模型在实际应用中的广泛使用，选择性去除不必要知识的需求变得尤为重要。CRISP能够自动识别多个层次中的显著SAE特征，并抑制其激活，从而实现持久的概念遗忘。实验结果表明，CRISP在安全关键的遗忘任务中优于之前的方法，成功去除了有害知识，同时保留了模型的通用能力和领域内能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.07877",
            "title": "Selective Contrastive Learning for Weakly Supervised Affordance\n  Grounding",
            "url": "https://huggingface.co/papers/2508.07877",
            "abstract": "The method uses selective prototypical and pixel contrastive objectives to learn affordance-relevant cues from third-person demonstrations, improving upon traditional weakly supervised affordance grounding by focusing on both part and object levels.  \t\t\t\t\tAI-generated summary \t\t\t\t Facilitating an entity's interaction with objects requires accurately identifying parts that afford specific actions. Weakly supervised affordance grounding (WSAG) seeks to imitate human learning from third-person demonstrations, where humans intuitively grasp functional parts without needing pixel-level annotations. To achieve this, grounding is typically learned using a shared classifier across images from different perspectives, along with distillation strategies incorporating part discovery process. However, since affordance-relevant parts are not always easily distinguishable, models primarily rely on classification, often focusing on common class-specific patterns that are unrelated to affordance. To address this limitation, we move beyond isolated part-level learning by introducing selective prototypical and pixel contrastive objectives that adaptively learn affordance-relevant cues at both the part and object levels, depending on the granularity of the available information. Initially, we find the action-associated objects in both egocentric (object-focused) and exocentric (third-person example) images by leveraging CLIP. Then, by cross-referencing the discovered objects of complementary views, we excavate the precise part-level affordance clues in each perspective. By consistently learning to distinguish affordance-relevant regions from affordance-irrelevant background context, our approach effectively shifts activation from irrelevant areas toward meaningful affordance cues. Experimental results demonstrate the effectiveness of our method. Codes are available at github.com/hynnsk/SelectiveCL.",
            "score": 10,
            "issue_id": 5520,
            "pub_date": "2025-08-11",
            "pub_date_card": {
                "ru": "11 августа",
                "en": "August 11",
                "zh": "8月11日"
            },
            "hash": "1be5d42feb9fc4d7",
            "authors": [
                "WonJun Moon",
                "Hyun Seok Seong",
                "Jae-Pil Heo"
            ],
            "affiliations": [
                "Sungkyunkwan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.07877.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#multimodal",
                    "#cv"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Улучшенное распознавание возможностей взаимодействия с помощью селективного контрастивного обучения",
                    "desc": "Эта статья представляет новый метод слабо контролируемого обучения распознаванию возможностей взаимодействия с объектами. Авторы предлагают использовать селективные прототипические и пиксельные контрастивные цели для извлечения релевантных признаков как на уровне частей объектов, так и целых объектов. Метод применяет CLIP для нахождения связанных с действиями объектов в эгоцентрических и экзоцентрических изображениях. Экспериментальные результаты демонстрируют эффективность предложенного подхода в сравнении с традиционными методами."
                },
                "en": {
                    "title": "Enhancing Affordance Grounding with Selective Learning Techniques",
                    "desc": "This paper presents a novel approach to weakly supervised affordance grounding (WSAG) by utilizing selective prototypical and pixel contrastive objectives. The method enhances the learning of affordance-relevant cues from third-person demonstrations, focusing on both object and part levels. By leveraging CLIP to identify action-associated objects from different perspectives, the model effectively distinguishes meaningful affordance regions from irrelevant background. Experimental results show that this approach significantly improves the accuracy of identifying parts that facilitate specific actions, addressing limitations of traditional classification methods."
                },
                "zh": {
                    "title": "通过选择性学习提升功能基础定位的准确性",
                    "desc": "本文提出了一种新的方法，通过选择性原型和像素对比目标，从第三人称示范中学习与功能相关的线索，从而改进传统的弱监督功能基础定位。该方法关注于物体和部件的层面，能够更准确地识别与特定动作相关的部件。我们利用CLIP技术在不同视角的图像中找到与动作相关的物体，并通过交叉参考发现的物体来挖掘每个视角中的精确部件功能线索。实验结果表明，该方法在功能基础定位任务中表现出色。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.16402",
            "title": "AetherCode: Evaluating LLMs' Ability to Win In Premier Programming\n  Competitions",
            "url": "https://huggingface.co/papers/2508.16402",
            "abstract": "AetherCode is a new benchmark for evaluating Large Language Models in competitive programming, offering more challenging and expert-validated test cases than existing benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Competitive programming has emerged as a critical benchmark for evaluating the reasoning and coding capabilities of Large Language Models (LLMs). Despite impressive progress on existing benchmarks, we argue that current evaluations overstate model proficiency, masking a substantial gap between LLMs and elite human programmers. This gap arises from two key limitations: insufficient difficulty and scope of benchmark problems, and evaluation bias from low-quality test cases. To address these shortcomings, we present AetherCode, a new benchmark that draws problems from premier programming competitions such as IOI and ICPC, offering broader coverage and higher difficulty. AetherCode further incorporates comprehensive, expert-validated test suites built through a hybrid of automated generation and human curation, ensuring rigorous and reliable assessment. By combining challenging problem design with robust evaluation, AetherCode provides a more faithful measure of LLM capabilities and sets a new standard for future research in code reasoning.",
            "score": 8,
            "issue_id": 5517,
            "pub_date": "2025-08-22",
            "pub_date_card": {
                "ru": "22 августа",
                "en": "August 22",
                "zh": "8月22日"
            },
            "hash": "e6c79bec20f431d6",
            "authors": [
                "Zihan Wang",
                "Jiaze Chen",
                "Zhicheng Liu",
                "Markus Mak",
                "Yidi Du",
                "Geonsik Moon",
                "Luoqi Xu",
                "Aaron Tua",
                "Kunshuo Peng",
                "Jiayi Lu",
                "Mingfei Xia",
                "Boqian Zou",
                "Chenyang Ran",
                "Guang Tian",
                "Shoutai Zhu",
                "Yeheng Duan",
                "Zhenghui Kang",
                "Zhenxing Lin",
                "Shangshu Li",
                "Qiang Luo",
                "Qingshen Long",
                "Zhiyong Chen",
                "Yihan Xiao",
                "Yurong Wu",
                "Daoguang Zan",
                "Yuyi Fu",
                "Mingxuan Wang",
                "Ming Ding"
            ],
            "affiliations": [
                "ByteDance"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.16402.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "🏆",
                "ru": {
                    "title": "AetherCode: Новая планка в оценке ИИ-программистов",
                    "desc": "AetherCode - новый эталон для оценки больших языковых моделей в соревновательном программировании. Он предлагает более сложные и экспертно проверенные тестовые случаи, чем существующие бенчмарки. AetherCode использует задачи из престижных соревнований по программированию, таких как IOI и ICPC, обеспечивая более широкий охват и повышенную сложность. Бенчмарк включает в себя комплексные наборы тестов, созданные с помощью гибридного подхода автоматической генерации и ручной курации."
                },
                "en": {
                    "title": "AetherCode: Raising the Bar for LLM Evaluation in Competitive Programming",
                    "desc": "AetherCode is a benchmark designed to evaluate Large Language Models (LLMs) specifically in the context of competitive programming. It addresses the limitations of existing benchmarks by providing more difficult and expertly validated test cases, which better reflect the skills of elite human programmers. The benchmark includes problems sourced from prestigious competitions like IOI and ICPC, ensuring a wider range of challenges. By combining automated generation with human curation, AetherCode aims to deliver a more accurate assessment of LLM capabilities in coding and reasoning tasks."
                },
                "zh": {
                    "title": "AetherCode：提升大型语言模型评估标准的基准",
                    "desc": "AetherCode是一个新的基准，用于评估大型语言模型在竞争编程中的表现。与现有基准相比，它提供了更具挑战性和经过专家验证的测试案例。当前的评估往往夸大了模型的能力，掩盖了大型语言模型与顶尖人类程序员之间的差距。AetherCode通过从顶级编程竞赛中提取问题，结合自动生成和人工策划的测试套件，确保了评估的严格性和可靠性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.13013",
            "title": "EgoTwin: Dreaming Body and View in First Person",
            "url": "https://huggingface.co/papers/2508.13013",
            "abstract": "EgoTwin, a diffusion transformer framework, addresses viewpoint alignment and causal interplay in joint egocentric video and human motion generation using a head-centric motion representation and cybernetics-inspired interaction mechanism.  \t\t\t\t\tAI-generated summary \t\t\t\t While exocentric video synthesis has achieved great progress, egocentric video generation remains largely underexplored, which requires modeling first-person view content along with camera motion patterns induced by the wearer's body movements. To bridge this gap, we introduce a novel task of joint egocentric video and human motion generation, characterized by two key challenges: 1) Viewpoint Alignment: the camera trajectory in the generated video must accurately align with the head trajectory derived from human motion; 2) Causal Interplay: the synthesized human motion must causally align with the observed visual dynamics across adjacent video frames. To address these challenges, we propose EgoTwin, a joint video-motion generation framework built on the diffusion transformer architecture. Specifically, EgoTwin introduces a head-centric motion representation that anchors the human motion to the head joint and incorporates a cybernetics-inspired interaction mechanism that explicitly captures the causal interplay between video and motion within attention operations. For comprehensive evaluation, we curate a large-scale real-world dataset of synchronized text-video-motion triplets and design novel metrics to assess video-motion consistency. Extensive experiments demonstrate the effectiveness of the EgoTwin framework.",
            "score": 7,
            "issue_id": 5521,
            "pub_date": "2025-08-18",
            "pub_date_card": {
                "ru": "18 августа",
                "en": "August 18",
                "zh": "8月18日"
            },
            "hash": "3573d981a35e3de1",
            "authors": [
                "Jingqiao Xiu",
                "Fangzhou Hong",
                "Yicong Li",
                "Mengze Li",
                "Wentao Wang",
                "Sirui Han",
                "Liang Pan",
                "Ziwei Liu"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Nanyang Technological University",
                "National University of Singapore",
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.13013.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#video",
                    "#multimodal",
                    "#dataset",
                    "#architecture"
                ],
                "emoji": "👀",
                "ru": {
                    "title": "EgoTwin: Синхронная генерация эгоцентрического видео и движений человека",
                    "desc": "EgoTwin - это новая система генерации эгоцентрического видео и движений человека на основе архитектуры диффузионного трансформера. Она решает проблемы выравнивания точки обзора и причинно-следственной взаимосвязи между видео и движениями с помощью представления движений относительно головы и механизма взаимодействия, вдохновленного кибернетикой. Авторы создали большой набор данных из синхронизированных триплетов текст-видео-движение для обучения и оценки. Эксперименты показывают эффективность предложенного подхода EgoTwin."
                },
                "en": {
                    "title": "EgoTwin: Bridging Video and Motion in First-Person View",
                    "desc": "EgoTwin is a new framework that combines video generation and human motion modeling in a first-person perspective. It tackles two main challenges: ensuring that the camera movement matches the head movement of the person and making sure that the generated human actions correspond to the visual changes in the video. The framework uses a special representation that focuses on the head's motion and a mechanism inspired by cybernetics to understand how video and motion influence each other. By creating a large dataset and new evaluation methods, EgoTwin shows significant improvements in generating realistic egocentric videos and human movements."
                },
                "zh": {
                    "title": "EgoTwin：自我中心视频与人类运动生成的创新框架",
                    "desc": "EgoTwin是一个扩散变换器框架，旨在解决联合自我中心视频和人类运动生成中的视角对齐和因果关系问题。该框架采用以头部为中心的运动表示，结合受网络控制启发的交互机制，能够有效捕捉视频与运动之间的因果关系。通过建立一个新的任务，EgoTwin需要处理相机轨迹与人类运动的头部轨迹之间的对齐，以及合成的人类运动与相邻视频帧的视觉动态之间的因果关系。实验结果表明，EgoTwin在视频与运动的一致性生成方面表现出色。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.16292",
            "title": "Do What? Teaching Vision-Language-Action Models to Reject the Impossible",
            "url": "https://huggingface.co/papers/2508.16292",
            "abstract": "A unified framework, Instruct-Verify-and-Act (IVA), enhances Vision-Language-Action (VLA) models to detect and respond to false-premise instructions by leveraging contextually augmented datasets.  \t\t\t\t\tAI-generated summary \t\t\t\t Recently, Vision-Language-Action (VLA) models have demonstrated strong performance on a range of robotic tasks. These models rely on multimodal inputs, with language instructions playing a crucial role -- not only in predicting actions, but also in robustly interpreting user intent, even when the requests are impossible to fulfill. In this work, we investigate how VLAs can recognize, interpret, and respond to false-premise instructions: natural language commands that reference objects or conditions absent from the environment. We propose Instruct-Verify-and-Act (IVA), a unified framework that (i) detects when an instruction cannot be executed due to a false premise, (ii) engages in language-based clarification or correction, and (iii) grounds plausible alternatives in perception and action. Towards this end, we construct a large-scale instruction tuning setup with structured language prompts and train a VLA model capable of handling both accurate and erroneous requests. Our approach leverages a contextually augmented, semi-synthetic dataset containing paired positive and false-premise instructions, enabling robust detection and natural language correction. Our experiments show that IVA improves false premise detection accuracy by 97.56% over baselines, while increasing successful responses in false-premise scenarios by 50.78%.",
            "score": 5,
            "issue_id": 5518,
            "pub_date": "2025-08-22",
            "pub_date_card": {
                "ru": "22 августа",
                "en": "August 22",
                "zh": "8月22日"
            },
            "hash": "fad295352d591bab",
            "authors": [
                "Wen-Han Hsieh",
                "Elvis Hsieh",
                "Dantong Niu",
                "Trevor Darrell",
                "Roei Herzig",
                "David M. Chan"
            ],
            "affiliations": [
                "University of California, Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.16292.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#interpretability",
                    "#robotics",
                    "#alignment",
                    "#dataset"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Умные роботы учатся распознавать невыполнимые команды",
                    "desc": "Исследователи предложили единую систему Instruct-Verify-and-Act (IVA) для улучшения моделей Vision-Language-Action (VLA) в робототехнике. IVA позволяет обнаруживать и реагировать на инструкции с ложными предпосылками, используя контекстно дополненные наборы данных. Система способна распознавать невыполнимые команды, уточнять их через диалог и находить альтернативные решения. Эксперименты показали значительное улучшение точности обнаружения ложных предпосылок и успешности ответов в таких сценариях."
                },
                "en": {
                    "title": "Enhancing VLA Models to Handle False-Premise Instructions with IVA",
                    "desc": "The paper introduces a new framework called Instruct-Verify-and-Act (IVA) that improves Vision-Language-Action (VLA) models in handling incorrect instructions. It focuses on detecting false-premise commands, which are instructions that refer to non-existent objects or conditions. The IVA framework not only identifies these erroneous instructions but also engages in clarifying or correcting them through natural language. By using a specially designed dataset for training, the model significantly enhances its ability to respond accurately to both valid and invalid requests, achieving remarkable improvements in detection and response rates."
                },
                "zh": {
                    "title": "指令验证与行动：提升VLA模型的智能响应能力",
                    "desc": "本文提出了一种统一框架，称为指令验证与行动（IVA），旨在增强视觉-语言-行动（VLA）模型的能力，以检测和响应错误前提的指令。该框架通过利用上下文增强的数据集，帮助模型识别无法执行的指令，并进行语言上的澄清或修正。我们构建了一个大规模的指令调优设置，训练出能够处理准确和错误请求的VLA模型。实验结果表明，IVA在错误前提检测准确率上提高了97.56%，并在错误前提场景中成功响应的比例增加了50.78%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.15746",
            "title": "End-to-End Agentic RAG System Training for Traceable Diagnostic\n  Reasoning",
            "url": "https://huggingface.co/papers/2508.15746",
            "abstract": "Deep-DxSearch, an agentic RAG system trained with reinforcement learning, enhances medical diagnosis accuracy by integrating a large-scale retrieval corpus and tailored rewards.  \t\t\t\t\tAI-generated summary \t\t\t\t Accurate diagnosis with medical large language models is hindered by knowledge gaps and hallucinations. Retrieval and tool-augmented methods help, but their impact is limited by weak use of external knowledge and poor feedback-reasoning traceability. To address these challenges, We introduce Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement learning (RL) that enables steer tracebale retrieval-augmented reasoning for medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical retrieval corpus comprising patient records and reliable medical knowledge sources to support retrieval-aware reasoning across diagnostic scenarios. More crutially, we frame the LLM as the core agent and the retrieval corpus as its environment, using tailored rewards on format, retrieval, reasoning structure, and diagnostic accuracy, thereby evolving the agentic RAG policy from large-scale data through RL.   Experiments demonstrate that our end-to-end agentic RL training framework consistently outperforms prompt-engineering and training-free RAG approaches across multiple data centers. After training, Deep-DxSearch achieves substantial gains in diagnostic accuracy, surpassing strong diagnostic baselines such as GPT-4o, DeepSeek-R1, and other medical-specific frameworks for both common and rare disease diagnosis under in-distribution and out-of-distribution settings. Moreover, ablation studies on reward design and retrieval corpus components confirm their critical roles, underscoring the uniqueness and effectiveness of our approach compared with traditional implementations. Finally, case studies and interpretability analyses highlight improvements in Deep-DxSearch's diagnostic policy, providing deeper insight into its performance gains and supporting clinicians in delivering more reliable and precise preliminary diagnoses. See https://github.com/MAGIC-AI4Med/Deep-DxSearch.",
            "score": 5,
            "issue_id": 5519,
            "pub_date": "2025-08-21",
            "pub_date_card": {
                "ru": "21 августа",
                "en": "August 21",
                "zh": "8月21日"
            },
            "hash": "7a7f46f22403e421",
            "authors": [
                "Qiaoyu Zheng",
                "Yuze Sun",
                "Chaoyi Wu",
                "Weike Zhao",
                "Pengcheng Qiu",
                "Yongguo Yu",
                "Kun Sun",
                "Yanfeng Wang",
                "Ya Zhang",
                "Weidi Xie"
            ],
            "affiliations": [
                "Shanghai AI Laboratory, Shanghai, China",
                "Shanghai Jiao Tong University, Shanghai, China",
                "Xinhua Hospital affiliated to Shanghai Jiao Tong University School of Medicine, Shanghai, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.15746.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#interpretability",
                    "#healthcare",
                    "#rl",
                    "#reasoning",
                    "#rag",
                    "#hallucinations"
                ],
                "emoji": "🩺",
                "ru": {
                    "title": "Искусственный интеллект на страже здоровья: революция в медицинской диагностике",
                    "desc": "Deep-DxSearch - это система диагностики на основе агентного RAG, обученная с помощью обучения с подкреплением. Она использует большой корпус медицинских данных для поиска и специальные награды для улучшения точности диагностики. Система превосходит существующие подходы, включая GPT-4 и DeepSeek-R1, как для распространенных, так и для редких заболеваний. Deep-DxSearch демонстрирует значительное улучшение в диагностической политике и может помочь врачам в предварительной диагностике."
                },
                "en": {
                    "title": "Revolutionizing Medical Diagnosis with Deep-DxSearch",
                    "desc": "Deep-DxSearch is a novel retrieval-augmented generation (RAG) system that uses reinforcement learning (RL) to improve the accuracy of medical diagnoses. It integrates a large-scale retrieval corpus of patient records and medical knowledge, allowing the model to perform better reasoning in diagnostic scenarios. By framing the large language model (LLM) as an agent and the retrieval corpus as its environment, the system utilizes tailored rewards to enhance its performance in terms of format, reasoning structure, and diagnostic accuracy. Experimental results show that Deep-DxSearch significantly outperforms existing models, providing clinicians with more reliable and precise preliminary diagnoses."
                },
                "zh": {
                    "title": "提升医疗诊断准确性的智能检索系统",
                    "desc": "Deep-DxSearch 是一个通过强化学习训练的代理 RAG 系统，旨在提高医疗诊断的准确性。它结合了大规模的检索语料库和定制的奖励机制，以支持基于检索的推理。该系统通过构建包含患者记录和可靠医学知识来源的检索语料库，增强了诊断场景中的推理能力。实验结果表明，Deep-DxSearch 在多种数据中心的诊断准确性上显著超越了传统的提示工程和无训练的 RAG 方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.15881",
            "title": "TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated\n  Prefill \\& Decode Inference",
            "url": "https://huggingface.co/papers/2508.15881",
            "abstract": "Tensor-Parallel Latent Attention (TPLA) enhances tensor parallelism efficiency by partitioning latent representations and input dimensions, preserving the benefits of compressed key-value caches while maintaining strong representational capacity.  \t\t\t\t\tAI-generated summary \t\t\t\t Multi-Head Latent Attention (MLA), introduced in DeepSeek-V2, compresses key-value states into a low-rank latent vector, caching only this vector to reduce memory. In tensor parallelism (TP), however, attention heads are computed across multiple devices, and each device must load the full cache, eroding the advantage of MLA over Grouped Query Attention (GQA). We propose Tensor-Parallel Latent Attention (TPLA): a scheme that partitions both the latent representation and each head's input dimension across devices, performs attention independently per shard, and then combines results with an all-reduce. TPLA preserves the benefits of a compressed KV cache while unlocking TP efficiency. Unlike Grouped Latent Attention (GLA), every head in TPLA still leverages the full latent representation, maintaining stronger representational capacity. TPLA is drop-in compatible with models pre-trained using MLA: it supports MLA-style prefilling and enables efficient tensor-parallel decoding without retraining. Applying simple orthogonal transforms -- e.g., the Hadamard transform or PCA -- before TP slicing further mitigates cross-shard interference, yielding minimal accuracy degradation. By reducing the per-device KV cache for DeepSeek-V3 and Kimi-K2, we achieve 1.79x and 1.93x speedups, respectively, at a 32K-token context length while maintaining performance on commonsense and LongBench benchmarks. TPLA can be implemented with FlashAttention-3, enabling practical end-to-end acceleration.",
            "score": 5,
            "issue_id": 5516,
            "pub_date": "2025-08-21",
            "pub_date_card": {
                "ru": "21 августа",
                "en": "August 21",
                "zh": "8月21日"
            },
            "hash": "603c38aea1aa4a8f",
            "authors": [
                "Xiaojuan Tang",
                "Fanxu Meng",
                "Pingzhi Tang",
                "Yuxuan Wang",
                "Di Yin",
                "Xing Sun",
                "Muhan Zhang"
            ],
            "affiliations": [
                "Institute for Artificial Intelligence, Peking University",
                "State Key Laboratory of General Artificial Intelligence, BIGAI",
                "Tencent Youtu Lab, Shanghai, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.15881.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#optimization",
                    "#training",
                    "#benchmark",
                    "#long_context"
                ],
                "emoji": "⚡",
                "ru": {
                    "title": "TPLA: Эффективный тензорный параллелизм для ускорения обработки длинных последовательностей",
                    "desc": "Статья представляет новый метод тензорного параллелизма для моделей машинного обучения - Tensor-Parallel Latent Attention (TPLA). TPLA разделяет латентные представления и входные размерности между устройствами, сохраняя преимущества сжатого кэша ключей и значений. Этот подход позволяет эффективно распараллеливать вычисления, сохраняя при этом сильную репрезентативную способность модели. TPLA совместим с предобученными моделями и показывает значительное ускорение обработки длинных последовательностей."
                },
                "en": {
                    "title": "Boosting Tensor Parallelism with TPLA",
                    "desc": "Tensor-Parallel Latent Attention (TPLA) improves the efficiency of tensor parallelism by dividing latent representations and input dimensions across multiple devices. This method retains the advantages of compressed key-value caches while ensuring that each attention head can still utilize the full latent representation, thus enhancing its representational capacity. TPLA is compatible with models that have been pre-trained using Multi-Head Latent Attention (MLA), allowing for efficient tensor-parallel decoding without the need for retraining. By applying orthogonal transforms before partitioning, TPLA minimizes cross-shard interference, leading to significant speedups in processing time while maintaining accuracy on various benchmarks."
                },
                "zh": {
                    "title": "张量并行潜在注意力：提升效率与表现的完美结合",
                    "desc": "Tensor-Parallel Latent Attention (TPLA) 是一种提高张量并行效率的方法，通过在设备之间划分潜在表示和输入维度，保持压缩的键值缓存的优势，同时保持强大的表示能力。与多头潜在注意力（MLA）相比，TPLA 允许每个头在不同设备上独立计算注意力，并通过全归约组合结果，从而提高了效率。TPLA 兼容使用 MLA 预训练的模型，支持 MLA 风格的预填充，并实现高效的张量并行解码，而无需重新训练。通过在 TP 切片之前应用简单的正交变换，可以进一步减少跨分片干扰，确保在保持性能的同时实现显著的加速。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.16279",
            "title": "AgentScope 1.0: A Developer-Centric Framework for Building Agentic\n  Applications",
            "url": "https://huggingface.co/papers/2508.16279",
            "abstract": "AgentScope enhances agentic applications by providing flexible tool-based interactions, unified interfaces, and advanced infrastructure based on the ReAct paradigm, supporting efficient and safe development and deployment.  \t\t\t\t\tAI-generated summary \t\t\t\t Driven by rapid advancements of Large Language Models (LLMs), agents are empowered to combine intrinsic knowledge with dynamic tool use, greatly enhancing their capacity to address real-world tasks. In line with such an evolution, AgentScope introduces major improvements in a new version (1.0), towards comprehensively supporting flexible and efficient tool-based agent-environment interactions for building agentic applications. Specifically, we abstract foundational components essential for agentic applications and provide unified interfaces and extensible modules, enabling developers to easily leverage the latest progress, such as new models and MCPs. Furthermore, we ground agent behaviors in the ReAct paradigm and offer advanced agent-level infrastructure based on a systematic asynchronous design, which enriches both human-agent and agent-agent interaction patterns while improving execution efficiency. Building on this foundation, we integrate several built-in agents tailored to specific practical scenarios. AgentScope also includes robust engineering support for developer-friendly experiences. We provide a scalable evaluation module with a visual studio interface, making the development of long-trajectory agentic applications more manageable and easier to trace. In addition, AgentScope offers a runtime sandbox to ensure safe agent execution and facilitates rapid deployment in production environments. With these enhancements, AgentScope provides a practical foundation for building scalable, adaptive, and effective agentic applications.",
            "score": 3,
            "issue_id": 5518,
            "pub_date": "2025-08-22",
            "pub_date_card": {
                "ru": "22 августа",
                "en": "August 22",
                "zh": "8月22日"
            },
            "hash": "5a3094b08e023d2b",
            "authors": [
                "Dawei Gao",
                "Zitao Li",
                "Yuexiang Xie",
                "Weirui Kuang",
                "Liuyi Yao",
                "Bingchen Qian",
                "Zhijian Ma",
                "Yue Cui",
                "Haohao Luo",
                "Shen Li",
                "Lu Yi",
                "Yi Yu",
                "Shiqi He",
                "Zhiling Luo",
                "Wenmeng Zhou",
                "Zhicheng Zhang",
                "Xuguang He",
                "Ziqian Chen",
                "Weikai Liao",
                "Farruh Isakulovich Kushnazarov",
                "Yaliang Li",
                "Bolin Ding",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.16279.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#architecture"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "AgentScope: гибкая платформа для создания ИИ-агентов нового поколения",
                    "desc": "AgentScope 1.0 - это новая версия фреймворка для разработки агентных приложений на основе больших языковых моделей. Он предоставляет унифицированные интерфейсы и расширяемые модули для гибкого взаимодействия агентов с инструментами. AgentScope основан на парадигме ReAct и включает асинхронную инфраструктуру для эффективного выполнения задач. Фреймворк также обеспечивает масштабируемую оценку, визуальный интерфейс разработки и безопасное выполнение агентов в production-среде."
                },
                "en": {
                    "title": "Empowering Agentic Applications with AgentScope",
                    "desc": "AgentScope is a framework designed to improve the development of agentic applications by offering flexible interactions and a unified interface. It leverages the ReAct paradigm to enhance agent capabilities, allowing them to effectively use tools and interact with their environments. The latest version introduces foundational components and extensible modules that simplify the integration of new models and methodologies. Additionally, it includes features like a visual evaluation module and a runtime sandbox to ensure safe and efficient deployment of agents in real-world scenarios."
                },
                "zh": {
                    "title": "AgentScope：构建灵活高效的智能代理应用",
                    "desc": "AgentScope 是一个增强智能代理应用程序的工具，提供灵活的工具交互和统一的接口。它基于 ReAct 理论，支持高效和安全的开发与部署。新版本 1.0 引入了重要改进，帮助开发者轻松利用最新的模型和模块。AgentScope 还提供了可扩展的评估模块和安全的运行时沙箱，确保代理的安全执行。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.16072",
            "title": "InMind: Evaluating LLMs in Capturing and Applying Individual Human\n  Reasoning Styles",
            "url": "https://huggingface.co/papers/2508.16072",
            "abstract": "InMind evaluates LLMs' ability to capture and apply personalized reasoning styles in social deduction games, highlighting limitations in current models' adaptive reasoning.  \t\t\t\t\tAI-generated summary \t\t\t\t LLMs have shown strong performance on human-centric reasoning tasks. While previous evaluations have explored whether LLMs can infer intentions or detect deception, they often overlook the individualized reasoning styles that influence how people interpret and act in social contexts. Social deduction games (SDGs) provide a natural testbed for evaluating individualized reasoning styles, where different players may adopt diverse but contextually valid reasoning strategies under identical conditions. To address this, we introduce InMind, a cognitively grounded evaluation framework designed to assess whether LLMs can capture and apply personalized reasoning styles in SDGs. InMind enhances structured gameplay data with round-level strategy traces and post-game reflections, collected under both Observer and Participant modes. It supports four cognitively motivated tasks that jointly evaluate both static alignment and dynamic adaptation. As a case study, we apply InMind to the game Avalon, evaluating 11 state-of-the-art LLMs. General-purpose LLMs, even GPT-4o frequently rely on lexical cues, struggling to anchor reflections in temporal gameplay or adapt to evolving strategies. In contrast, reasoning-enhanced LLMs like DeepSeek-R1 exhibit early signs of style-sensitive reasoning. These findings reveal key limitations in current LLMs' capacity for individualized, adaptive reasoning, and position InMind as a step toward cognitively aligned human-AI interaction.",
            "score": 0,
            "issue_id": 5518,
            "pub_date": "2025-08-22",
            "pub_date_card": {
                "ru": "22 августа",
                "en": "August 22",
                "zh": "8月22日"
            },
            "hash": "1987a0ba86bfb9ad",
            "authors": [
                "Zizhen Li",
                "Chuanhao Li",
                "Yibin Wang",
                "Qi Chen",
                "Diping Song",
                "Yukang Feng",
                "Jianwen Sun",
                "Jiaxin Ai",
                "Fanrui Zhang",
                "Mingzhu Sun",
                "Kaipeng Zhang"
            ],
            "affiliations": [
                "Fudan University",
                "Johns Hopkins University",
                "Nankai University",
                "Shanghai AI Laboratory",
                "Shanghai Innovation Institute",
                "University of Science and Technology of China",
                "Wuhan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.16072.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#multimodal",
                    "#games",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Оценка индивидуальных стилей рассуждения в ИИ: ограничения и перспективы",
                    "desc": "Статья представляет InMind - систему оценки способности языковых моделей (LLM) улавливать и применять индивидуальные стили рассуждений в играх с социальной дедукцией. Исследование выявило, что большинство современных LLM, включая GPT-4, часто опираются на лексические подсказки и испытывают трудности с адаптацией к меняющимся стратегиям. Модели, усиленные возможностями рассуждения, такие как DeepSeek-R1, показывают первые признаки рассуждений, чувствительных к индивидуальному стилю. Результаты указывают на ограничения текущих LLM в индивидуализированном адаптивном рассуждении."
                },
                "en": {
                    "title": "InMind: Evaluating Personalized Reasoning in AI for Social Deduction Games",
                    "desc": "The paper introduces InMind, a framework for evaluating large language models (LLMs) on their ability to understand and apply personalized reasoning styles in social deduction games (SDGs). It highlights that while LLMs perform well in human-centric reasoning tasks, they often fail to adapt to the unique reasoning strategies that different players use in similar situations. By analyzing gameplay data and player reflections, InMind assesses both static alignment and dynamic adaptation of reasoning styles. The study finds that many general-purpose LLMs struggle with individualized reasoning, while some enhanced models show potential for better adaptation to diverse reasoning styles."
                },
                "zh": {
                    "title": "评估个性化推理风格的InMind框架",
                    "desc": "InMind是一个评估大型语言模型（LLMs）在社交推理游戏中捕捉和应用个性化推理风格能力的框架。当前的模型在适应性推理方面存在局限，尤其是在处理个体化推理风格时。通过在社交推理游戏中引入结构化的游戏数据和策略追踪，InMind能够更好地评估LLMs的推理能力。研究表明，尽管一些先进的LLMs表现出一定的推理能力，但仍然在个性化和动态适应性推理方面存在不足。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.13562",
            "title": "Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose\n  Inverse Kinematics",
            "url": "https://huggingface.co/papers/2508.13562",
            "abstract": "Learnable SMPLify replaces iterative optimization in SMPLify with a neural network for faster and more generalized 3D human pose and shape estimation.  \t\t\t\t\tAI-generated summary \t\t\t\t In 3D human pose and shape estimation, SMPLify remains a robust baseline that solves inverse kinematics (IK) through iterative optimization. However, its high computational cost limits its practicality. Recent advances across domains have shown that replacing iterative optimization with data-driven neural networks can achieve significant runtime improvements without sacrificing accuracy. Motivated by this trend, we propose Learnable SMPLify, a neural framework that replaces the iterative fitting process in SMPLify with a single-pass regression model. The design of our framework targets two core challenges in neural IK: data construction and generalization. To enable effective training, we propose a temporal sampling strategy that constructs initialization-target pairs from sequential frames. To improve generalization across diverse motions and unseen poses, we propose a human-centric normalization scheme and residual learning to narrow the solution space. Learnable SMPLify supports both sequential inference and plug-in post-processing to refine existing image-based estimators. Extensive experiments demonstrate that our method establishes itself as a practical and simple baseline: it achieves nearly 200x faster runtime compared to SMPLify, generalizes well to unseen 3DPW and RICH, and operates in a model-agnostic manner when used as a plug-in tool on LucidAction. The code is available at https://github.com/Charrrrrlie/Learnable-SMPLify.",
            "score": 0,
            "issue_id": 5523,
            "pub_date": "2025-08-19",
            "pub_date_card": {
                "ru": "19 августа",
                "en": "August 19",
                "zh": "8月19日"
            },
            "hash": "b08c5280107ed4d1",
            "authors": [
                "Yuchen Yang",
                "Linfeng Dong",
                "Wei Wang",
                "Zhihang Zhong",
                "Xiao Sun"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai Artificial Intelligence Laboratory",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.13562.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#data",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🏃",
                "ru": {
                    "title": "Быстрая и обобщаемая оценка 3D позы человека с помощью нейросетей",
                    "desc": "Статья представляет Learnable SMPLify - нейросетевой подход к оценке 3D позы и формы человека. Он заменяет итеративную оптимизацию в SMPLify на однопроходную регрессионную модель, что значительно ускоряет процесс. Для эффективного обучения предложена стратегия временной выборки и нормализация, ориентированная на человека. Метод показывает 200-кратное ускорение по сравнению с SMPLify и хорошо обобщается на новые данные."
                },
                "en": {
                    "title": "Speeding Up 3D Pose Estimation with Neural Networks",
                    "desc": "Learnable SMPLify introduces a neural network approach to 3D human pose and shape estimation, replacing the traditional iterative optimization used in SMPLify. This method significantly reduces computational time while maintaining accuracy, making it more practical for real-world applications. The framework addresses key challenges in neural inverse kinematics, such as data construction and generalization, by utilizing a temporal sampling strategy and a human-centric normalization scheme. Extensive testing shows that Learnable SMPLify is nearly 200 times faster than its predecessor and effectively generalizes to new poses and motions."
                },
                "zh": {
                    "title": "Learnable SMPLify：加速3D人体姿态估计的神经网络",
                    "desc": "Learnable SMPLify 是一种新的神经网络框架，用于更快和更通用的 3D 人体姿态和形状估计。它用单次回归模型替代了 SMPLify 中的迭代优化过程，从而显著提高了运行速度。该框架通过时间采样策略构建初始化-目标对，并采用人本归一化和残差学习来改善对不同动作和未见姿态的泛化能力。实验表明，Learnable SMPLify 的运行速度比 SMPLify 快近 200 倍，并且在多种情况下表现良好。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.10390",
            "title": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts",
            "url": "https://huggingface.co/papers/2508.10390",
            "abstract": "A hybrid framework combining LLMs and human oversight is proposed to clean datasets and detect jailbreak attacks, with new strategies to enhance jailbreak success.  \t\t\t\t\tAI-generated summary \t\t\t\t Evaluating jailbreak attacks is challenging when prompts are not overtly harmful or fail to induce harmful outputs. Unfortunately, many existing red-teaming datasets contain such unsuitable prompts. To evaluate attacks accurately, these datasets need to be assessed and cleaned for maliciousness. However, existing malicious content detection methods rely on either manual annotation, which is labor-intensive, or large language models (LLMs), which have inconsistent accuracy in harmful types. To balance accuracy and efficiency, we propose a hybrid evaluation framework named MDH (Malicious content Detection based on LLMs with Human assistance) that combines LLM-based annotation with minimal human oversight, and apply it to dataset cleaning and detection of jailbroken responses. Furthermore, we find that well-crafted developer messages can significantly boost jailbreak success, leading us to propose two new strategies: D-Attack, which leverages context simulation, and DH-CoT, which incorporates hijacked chains of thought. The Codes, datasets, judgements, and detection results will be released in github repository: https://github.com/AlienZhang1996/DH-CoT.",
            "score": 0,
            "issue_id": 5518,
            "pub_date": "2025-08-14",
            "pub_date_card": {
                "ru": "14 августа",
                "en": "August 14",
                "zh": "8月14日"
            },
            "hash": "df08ead155e89f8d",
            "authors": [
                "Chiyu Zhang",
                "Lu Zhou",
                "Xiaogang Xu",
                "Jiafei Wu",
                "Liming Fang",
                "Zhe Liu"
            ],
            "affiliations": [
                "Collaborative Innovation Center of Novel Software Technology and Industrialization",
                "Nanjing University of Aeronautics and Astronautics",
                "The Chinese University of Hong Kong",
                "Zhejiang Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.10390.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#benchmark",
                    "#data",
                    "#security",
                    "#dataset"
                ],
                "emoji": "🛡️",
                "ru": {
                    "title": "Гибридный подход к обнаружению вредоносного контента и усилению jailbreak-атак",
                    "desc": "Предложена гибридная система, сочетающая большие языковые модели (LLM) и человеческий контроль для очистки датасетов и обнаружения атак по обходу ограничений (jailbreak). Система MDH использует LLM для аннотации с минимальным участием человека, что позволяет эффективно оценивать и очищать наборы данных от вредоносного контента. Разработаны новые стратегии D-Attack и DH-CoT для повышения успешности jailbreak-атак с использованием контекстной симуляции и измененных цепочек рассуждений. Предложенный подход позволяет более точно оценивать jailbreak-атаки, особенно в случаях неявно вредоносных промптов."
                },
                "en": {
                    "title": "Enhancing Dataset Integrity and Jailbreak Detection with Hybrid LLMs",
                    "desc": "This paper introduces a hybrid framework called MDH that combines large language models (LLMs) with minimal human oversight to improve the detection of malicious content in datasets and evaluate jailbreak attacks. The framework addresses the limitations of existing methods, which either require extensive manual work or suffer from inconsistent accuracy. By integrating LLMs with human assistance, the proposed approach enhances the cleaning of datasets and the identification of harmful prompts. Additionally, the authors present two innovative strategies, D-Attack and DH-CoT, to increase the success rate of jailbreak attempts by utilizing context simulation and hijacked reasoning processes."
                },
                "zh": {
                    "title": "混合框架提升数据集清理与越狱检测",
                    "desc": "本文提出了一种混合框架，结合了大型语言模型（LLMs）和人工监督，用于清理数据集和检测越狱攻击。现有的恶意内容检测方法要么依赖人工标注，耗时耗力，要么依赖LLMs，但在识别有害类型时准确性不一致。我们提出的MDH框架通过最小化人工干预，结合LLM标注，提高了检测的准确性和效率。此外，我们发现精心设计的开发者消息可以显著提高越狱成功率，并提出了两种新策略：D-Attack和DH-CoT。"
                }
            }
        }
    ],
    "link_prev": "2025-08-22.html",
    "link_next": "2025-08-26.html",
    "link_month": "2025-08.html",
    "short_date_prev": {
        "ru": "22.08",
        "en": "08/22",
        "zh": "8月22日"
    },
    "short_date_next": {
        "ru": "26.08",
        "en": "08/26",
        "zh": "8月26日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 2,
        "#benchmark": 6,
        "#agents": 3,
        "#cv": 1,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 4,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 1,
        "#training": 4,
        "#robotics": 2,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 2,
        "#reasoning": 5,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 2,
        "#optimization": 8,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}