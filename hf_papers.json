{
    "date": {
        "ru": "22 ноября",
        "en": "November 22",
        "zh": "11月22日"
    },
    "time_utc": "2024-11-22 03:23",
    "weekday": 4,
    "issue_id": 720,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.14251",
            "title": "Natural Language Reinforcement Learning",
            "url": "https://huggingface.co/papers/2411.14251",
            "abstract": "Reinforcement Learning (RL) mathematically formulates decision-making with Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable breakthroughs across various domains, including games, robotics, and language models. This paper seeks a new possibility, Natural Language Reinforcement Learning (NLRL), by extending traditional MDP to natural language-based representation space. Specifically, NLRL innovatively redefines RL principles, including task objectives, policy, value function, Bellman equation, and policy iteration, into their language counterparts. With recent advancements in large language models (LLMs), NLRL can be practically implemented to achieve RL-like policy and value improvement by either pure prompting or gradient-based training. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games demonstrate the effectiveness, efficiency, and interpretability of the NLRL framework among diverse use cases. Our code will be released at https://github.com/waterhorse1/Natural-language-RL.",
            "score": 2,
            "issue_id": 719,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "351fc2a705b34aff",
            "authors": [
                "Xidong Feng",
                "Ziyu Wan",
                "Haotian Fu",
                "Bo Liu",
                "Mengyue Yang",
                "Girish A. Koushik",
                "Zhiyuan Hu",
                "Ying Wen",
                "Jun Wang"
            ],
            "affiliations": [
                "Brown University",
                "National University of Singapore",
                "Shanghai Jiao Tong University",
                "University College London",
                "University of Bristol",
                "University of Surrey"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14251.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#rl",
                    "#rlhf",
                    "#open_source",
                    "#games"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "Обучение с подкреплением заговорило на естественном языке",
                    "desc": "Эта статья представляет новую концепцию - обучение с подкреплением на естественном языке (NLRL). NLRL расширяет традиционные марковские процессы принятия решений, переопределяя основные принципы RL в языковом пространстве. Используя достижения в области больших языковых моделей, NLRL может быть реализовано с помощью промптов или градиентного обучения. Эксперименты на играх Maze, Breakthrough и крестики-нолики демонстрируют эффективность и интерпретируемость этого подхода."
                },
                "en": {
                    "title": "Revolutionizing Decision-Making with Language: Natural Language Reinforcement Learning",
                    "desc": "This paper introduces Natural Language Reinforcement Learning (NLRL), which adapts traditional Reinforcement Learning (RL) methods to work with natural language representations. By extending the Markov Decision Process (MDP) framework, NLRL redefines key RL concepts such as task objectives, policies, and value functions in the context of language. The approach leverages advancements in large language models (LLMs) to enhance policy and value updates through prompting or gradient-based training. Experimental results on games like Maze, Breakthrough, and Tic-Tac-Toe showcase NLRL's effectiveness and interpretability across various applications."
                },
                "zh": {
                    "title": "自然语言强化学习：决策的新视角",
                    "desc": "强化学习（RL）通过马尔可夫决策过程（MDP）来数学化决策制定。本文提出了一种新的可能性，即自然语言强化学习（NLRL），通过将传统的MDP扩展到基于自然语言的表示空间。NLRL创新性地重新定义了强化学习的原则，包括任务目标、策略、价值函数、贝尔曼方程和策略迭代，使其适应语言的对应关系。通过在迷宫、突破和井字棋等游戏中的实验，验证了NLRL框架在多种应用场景中的有效性、效率和可解释性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14432",
            "title": "Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models",
            "url": "https://huggingface.co/papers/2411.14432",
            "abstract": "Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high-quality long-chain reasoning data and optimized training pipelines still remain inadequately explored in vision-language tasks. In this paper, we present Insight-V, an early effort to 1) scalably produce long and robust reasoning data for complex multi-modal tasks, and 2) an effective training pipeline to enhance the reasoning capabilities of multi-modal large language models (MLLMs). Specifically, to create long and structured reasoning data without human labor, we design a two-step pipeline with a progressive strategy to generate sufficiently long and diverse reasoning paths and a multi-granularity assessment method to ensure data quality. We observe that directly supervising MLLMs with such long and complex reasoning data will not yield ideal reasoning ability. To tackle this problem, we design a multi-agent system consisting of a reasoning agent dedicated to performing long-chain reasoning and a summary agent trained to judge and summarize reasoning results. We further incorporate an iterative DPO algorithm to enhance the reasoning agent's generation stability and quality. Based on the popular LLaVA-NeXT model and our stronger base MLLM, we demonstrate significant performance gains across challenging multi-modal benchmarks requiring visual reasoning. Benefiting from our multi-agent system, Insight-V can also easily maintain or improve performance on perception-focused multi-modal tasks.",
            "score": 1,
            "issue_id": 720,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "0af1bb82d8021d3b",
            "authors": [
                "Yuhao Dong",
                "Zuyan Liu",
                "Hai-Long Sun",
                "Jingkang Yang",
                "Winston Hu",
                "Yongming Rao",
                "Ziwei Liu"
            ],
            "affiliations": [
                "Nanjing University",
                "S-Lab, NTU",
                "Tencent",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14432.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#long_context",
                    "#multimodal",
                    "#data",
                    "#dataset",
                    "#benchmark",
                    "#agents",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Улучшение визуальных рассуждений ИИ через длинные цепочки и мультиагентное обучение",
                    "desc": "Статья представляет Insight-V - подход к улучшению способностей мультимодальных больших языковых моделей (MLLM) к рассуждениям. Авторы предлагают двухэтапный конвейер для создания длинных и структурированных данных для обучения без участия человека. Они также разрабатывают мультиагентную систему, состоящую из агента рассуждений и агента-резюме, для эффективного обучения MLLM. Результаты показывают значительное улучшение производительности на сложных мультимодальных задачах, требующих визуального рассуждения."
                },
                "en": {
                    "title": "Empowering Multi-Modal Reasoning with Insight-V",
                    "desc": "This paper introduces Insight-V, a novel approach to enhance the reasoning capabilities of multi-modal large language models (MLLMs) by generating high-quality long-chain reasoning data. The authors propose a two-step pipeline that creates structured reasoning paths without human intervention and employs a multi-granularity assessment method to ensure the quality of the generated data. They also develop a multi-agent system that includes a reasoning agent for long-chain reasoning and a summary agent to evaluate and condense the reasoning outputs. The results show that Insight-V significantly improves performance on complex multi-modal tasks, particularly those requiring visual reasoning, while maintaining effectiveness on perception-focused tasks."
                },
                "zh": {
                    "title": "提升多模态推理能力的创新方法",
                    "desc": "本文介绍了一种名为Insight-V的系统，旨在提高多模态大语言模型（MLLMs）的推理能力。我们设计了一个两步生成管道，以无人工干预的方式创建长且结构化的推理数据，并采用多粒度评估方法确保数据质量。研究表明，直接用复杂推理数据监督MLLMs并不能达到理想效果，因此我们构建了一个多代理系统，包括专注于长链推理的推理代理和负责评估和总结推理结果的总结代理。通过这种方法，Insight-V在视觉推理等多模态基准测试中表现出显著的性能提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14199",
            "title": "OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs",
            "url": "https://huggingface.co/papers/2411.14199",
            "abstract": "Scientific progress depends on researchers' ability to synthesize the growing body of literature. Can large language models (LMs) assist scientists in this task? We introduce OpenScholar, a specialized retrieval-augmented LM that answers scientific queries by identifying relevant passages from 45 million open-access papers and synthesizing citation-backed responses. To evaluate OpenScholar, we develop ScholarQABench, the first large-scale multi-domain benchmark for literature search, comprising 2,967 expert-written queries and 208 long-form answers across computer science, physics, neuroscience, and biomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o hallucinates citations 78 to 90% of the time, OpenScholar achieves citation accuracy on par with human experts. OpenScholar's datastore, retriever, and self-feedback inference loop also improves off-the-shelf LMs: for instance, OpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations, experts preferred OpenScholar-8B and OpenScholar-GPT4o responses over expert-written ones 51% and 70% of the time, respectively, compared to GPT4o's 32%. We open-source all of our code, models, datastore, data and a public demo.",
            "score": 1,
            "issue_id": 720,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "f429efe07ec308f2",
            "authors": [
                "Akari Asai",
                "Jacqueline He",
                "Rulin Shao",
                "Weijia Shi",
                "Amanpreet Singh",
                "Joseph Chee Chang",
                "Kyle Lo",
                "Luca Soldaini",
                "Sergey Feldman",
                "Mike D'arcy",
                "David Wadden",
                "Matt Latzke",
                "Minyang Tian",
                "Pan Ji",
                "Shengyan Liu",
                "Hao Tong",
                "Bohao Wu",
                "Yanyu Xiong",
                "Luke Zettlemoyer",
                "Graham Neubig",
                "Dan Weld",
                "Doug Downey",
                "Wen-tau Yih",
                "Pang Wei Koh",
                "Hannaneh Hajishirzi"
            ],
            "affiliations": [
                "Allen Institute for AI",
                "Carnegie Mellon University",
                "Meta",
                "Stanford University",
                "University of Illinois, Urbana-Champaign",
                "University of North Carolina, Chapel Hill",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14199.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#rag",
                    "#open_source",
                    "#multimodal",
                    "#benchmark",
                    "#hallucinations"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "OpenScholar: ИИ-помощник для синтеза научной литературы",
                    "desc": "Статья представляет OpenScholar - специализированную языковую модель с расширенным поиском, которая отвечает на научные запросы, используя 45 миллионов научных статей. Для оценки модели авторы разработали ScholarQABench - первый масштабный мультидоменный бенчмарк для поиска литературы. OpenScholar-8B превосходит GPT-4 и PaperQA2 по точности ответов, несмотря на меньший размер модели. Эксперты предпочли ответы OpenScholar-8B и OpenScholar-GPT4o экспертным ответам в 51% и 70% случаев соответственно."
                },
                "en": {
                    "title": "Empowering Scientific Research with OpenScholar: Accurate, Citation-Backed Insights",
                    "desc": "This paper presents OpenScholar, a retrieval-augmented language model designed to assist researchers in synthesizing scientific literature. OpenScholar effectively identifies relevant passages from a vast collection of 45 million open-access papers and generates citation-backed responses to scientific queries. The model is evaluated using ScholarQABench, a benchmark that includes expert-written queries and answers across multiple domains, demonstrating superior performance in correctness compared to other models like GPT-4o. Additionally, OpenScholar shows a significant reduction in citation hallucination, achieving accuracy comparable to human experts, and enhances the performance of existing models through its innovative architecture."
                },
                "zh": {
                    "title": "OpenScholar：提升科学文献检索的智能助手",
                    "desc": "本论文介绍了一种名为OpenScholar的专用检索增强语言模型，旨在帮助科学家从4500万篇开放获取论文中提取相关信息并生成基于引用的回答。我们开发了ScholarQABench，这是第一个大规模的多领域文献搜索基准，包含2967个专家编写的查询和208个长答案，涵盖计算机科学、物理学、神经科学和生物医学等领域。OpenScholar在准确性上超越了GPT-4o和PaperQA2，尽管其模型规模较小，且在引用准确性方面与人类专家相当。我们还开源了所有代码、模型和数据，提供了公共演示，促进了科学文献的检索和理解。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14405",
            "title": "Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions",
            "url": "https://huggingface.co/papers/2411.14405",
            "abstract": "Currently OpenAI o1 has sparked a surge of interest in the study of large reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on disciplines with standard answers, such as mathematics, physics, and coding -- which are well-suited for reinforcement learning (RL) -- but also places greater emphasis on open-ended resolutions. We aim to address the question: \"Can the o1 model effectively generalize to broader domains where clear standards are absent and rewards are challenging to quantify?\" Marco-o1 is powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and innovative reasoning strategies -- optimized for complex real-world problem-solving tasks.",
            "score": 0,
            "issue_id": 720,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "ef4a95abeea69237",
            "authors": [
                "Yu Zhao",
                "Huifeng Yin",
                "Bo Zeng",
                "Hao Wang",
                "Tianqi Shi",
                "Chenyang Lyu",
                "Longyue Wang",
                "Weihua Luo",
                "Kaifu Zhang"
            ],
            "affiliations": [
                "MarcoPolo Team, Alibaba International Digital Commerce"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14405.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#rl",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Расширение границ искусственного интеллекта: от стандартных задач к открытым проблемам",
                    "desc": "Статья описывает разработку модели Marco-o1, которая расширяет возможности OpenAI o1 в области рассуждений. Модель нацелена на решение задач с открытым концом, где отсутствуют четкие стандарты и сложно количественно оценить результаты. Marco-o1 использует усовершенствованные методы, такие как обучение с подкреплением, цепочки размышлений и метод Монте-Карло. Основная цель - создать модель, способную эффективно обобщать знания и решать сложные задачи реального мира."
                },
                "en": {
                    "title": "Unlocking Generalization in Large Reasoning Models",
                    "desc": "This paper explores the capabilities of the Marco-o1 model in handling large reasoning tasks across various domains. It emphasizes the model's ability to generalize beyond traditional areas like mathematics and coding, where answers are clear-cut. The research investigates how Marco-o1 can tackle open-ended problems where standard solutions and quantifiable rewards are not readily available. Key techniques employed include Chain-of-Thought fine-tuning and Monte Carlo Tree Search, which enhance the model's reasoning and problem-solving abilities in complex scenarios."
                },
                "zh": {
                    "title": "推动推理模型的广泛应用",
                    "desc": "这篇论文探讨了大型推理模型（LRM）的研究，特别是OpenAI的o1模型。Marco-o1不仅关注数学、物理和编程等有标准答案的学科，还强调开放式问题的解决能力。研究的核心问题是o1模型是否能够有效地推广到缺乏明确标准和难以量化奖励的更广泛领域。Marco-o1结合了链式思维（CoT）微调、蒙特卡洛树搜索（MCTS）、反思机制和创新推理策略，以优化复杂的现实问题解决任务。"
                }
            }
        }
    ],
    "link_prev": "2024-11-21.html",
    "link_next": "2024-11-25.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "21.11",
        "en": "11/21",
        "zh": "11月21日"
    },
    "short_date_next": {
        "ru": "25.11",
        "en": "11/25",
        "zh": "11月25日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 1,
        "#cv": 0,
        "#rl": 2,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种加速注意力计算的方法，称为 SageAttention2。它使用 4-bit 矩阵乘法和精度增强技术。首先，将矩阵 Q 和 K 量化为 INT4，将矩阵 P 和 V 量化为 FP8。然后，提出平滑 Q 和 V 的方法，提高注意力精度。实验证明，这种方法在多种模型上几乎没有性能损失，并且在 RTX4090 上的操作速度是 FlashAttention2 和 xformers 的 3 倍和 5 倍。代码已在 GitHub 上公开。",
        "title": "SageAttention2 Technical Report: Accurate 4 Bit Attention for Plug-and-play Inference Acceleration",
        "pinyin": "这篇文章介绍了一种加速注意力计算的方法，称为 SageAttention2。它使用 4-bit 矩阵乘法和精度增强技术。首先，将矩阵 Q 和 K 量化为 INT4，将矩阵 P 和 V 量化为 FP8。然后，提出平滑 Q 和 V 的方法，提高注意力精度。实验证明，这种方法在多种模型上几乎没有性能损失，并且在 RTX4090 上的操作速度是 FlashAttention2 和 xformers 的 3 倍和 5 倍。代码已在 GitHub 上公开。\n\nzhè piān wén zhāng jiè shào le yī zhǒng jiā sù zhù yì lì jì suàn de fāng fǎ, chēng wéi SageAttention2. tā shǐ yòng 4-bit jǔ zhèn chéng fǎ hé jīng dù zēng qiáng jì shù. shǒu xiān, jiāng jǔ zhèn Q hé K liàng huà wéi INT4, jiāng jǔ zhèn P hé V liàng huà wéi FP8. rán hòu, tí chū píng huá Q hé V de fāng fǎ, tí gāo zhù yì lì jīng dù. shí yàn zhèng míng, zhè zhǒng fāng fǎ zài duō zhǒng mó xíng shàng jī hū méi yǒu xìng néng sǔn shī, bìng qiě zài RTX4090 shàng de cāo zuò sù dù shì FlashAttention2 hé xformers de 3 bèi hé 5 bèi. dài mǎ yǐ zài GitHub shàng gōng kāi.",
        "vocab": "[{'word': '加速', 'pinyin': 'jiā sù', 'trans': 'accelerate'},\n{'word': '注意力', 'pinyin': 'zhù yì lì', 'trans': 'attention'},\n{'word': '计算', 'pinyin': 'jì suàn', 'trans': 'calculation'},\n{'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'},\n{'word': '称为', 'pinyin': 'chēng wéi', 'trans': 'called'},\n{'word': '矩阵', 'pinyin': 'jǔ zhèn', 'trans': 'matrix'},\n{'word': '乘法', 'pinyin': 'chén fǎ', 'trans': 'multiplication'},\n{'word': '精度', 'pinyin': 'jīng dù', 'trans': 'precision'},\n{'word': '增强', 'pinyin': 'zēng qiáng', 'trans': 'enhancement'},\n{'word': '技术', 'pinyin': 'jì shù', 'trans': 'technology'},\n{'word': '量化', 'pinyin': 'liàng huà', 'trans': 'quantization'},\n{'word': '平滑', 'pinyin': 'píng huá', 'trans': 'smooth'},\n{'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'},\n{'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'},\n{'word': '证明', 'pinyin': 'zhèng míng', 'trans': 'prove'},\n{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},\n{'word': '损失', 'pinyin': 'sǔn shī', 'trans': 'loss'},\n{'word': '操作', 'pinyin': 'cāo zuò', 'trans': 'operation'},\n{'word': '速度', 'pinyin': 'sù dù', 'trans': 'speed'},\n{'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'},\n{'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'}]",
        "trans": "This article introduces a method for accelerating attention computation, called SageAttention2. It employs 4-bit matrix multiplication and precision enhancement techniques. First, matrices Q and K are quantized to INT4, while matrices P and V are quantized to FP8. Then, a method for smoothing Q and V is proposed to improve attention precision. Experiments demonstrate that this method incurs almost no performance loss across various models and operates at speeds that are 3 times and 5 times faster than FlashAttention2 and xformers, respectively, on the RTX4090. The code has been made publicly available on GitHub.",
        "update_ts": "2024-11-21 09:11"
    }
}