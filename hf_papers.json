{
    "date": {
        "ru": "8 Ğ°Ğ¿Ñ€ĞµĞ»Ñ",
        "en": "April 8",
        "zh": "4æœˆ8æ—¥"
    },
    "time_utc": "2025-04-08 03:27",
    "weekday": 1,
    "issue_id": 3115,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2504.05305",
            "title": "URECA: Unique Region Caption Anything",
            "url": "https://huggingface.co/papers/2504.05305",
            "abstract": "Region-level captioning aims to generate natural language descriptions for specific image regions while highlighting their distinguishing features. However, existing methods struggle to produce unique captions across multi-granularity, limiting their real-world applicability. To address the need for detailed region-level understanding, we introduce URECA dataset, a large-scale dataset tailored for multi-granularity region captioning. Unlike prior datasets that focus primarily on salient objects, URECA dataset ensures a unique and consistent mapping between regions and captions by incorporating a diverse set of objects, parts, and background elements. Central to this is a stage-wise data curation pipeline, where each stage incrementally refines region selection and caption generation. By leveraging Multimodal Large Language Models (MLLMs) at each stage, our pipeline produces distinctive and contextually grounded captions with improved accuracy and semantic diversity. Building upon this dataset, we present URECA, a novel captioning model designed to effectively encode multi-granularity regions. URECA maintains essential spatial properties such as position and shape through simple yet impactful modifications to existing MLLMs, enabling fine-grained and semantically rich region descriptions. Our approach introduces dynamic mask modeling and a high-resolution mask encoder to enhance caption uniqueness. Experiments show that URECA achieves state-of-the-art performance on URECA dataset and generalizes well to existing region-level captioning benchmarks.",
            "score": 0,
            "issue_id": 3115,
            "pub_date": "2025-04-07",
            "pub_date_card": {
                "ru": "7 Ğ°Ğ¿Ñ€ĞµĞ»Ñ",
                "en": "April 7",
                "zh": "4æœˆ7æ—¥"
            },
            "hash": "6eec948e6319fc99",
            "authors": [
                "Sangbeom Lim",
                "Junwan Kim",
                "Heeji Yoon",
                "Jaewoo Jung",
                "Seungryong Kim"
            ],
            "affiliations": [
                "KAIST AI",
                "Korea University",
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.05305.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#games",
                    "#cv",
                    "#interpretability",
                    "#dataset",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… URECA Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ¾Ğ³Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ URECA, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ñ‹ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¹ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¸Ñ… Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ URECA Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹."
                },
                "en": {
                    "title": "Enhancing Region-Level Captioning with URECA Dataset and Model",
                    "desc": "This paper presents a new approach to region-level captioning, which generates detailed descriptions for specific parts of images. The authors introduce the URECA dataset, designed to improve the uniqueness of captions by including a variety of objects and backgrounds. They propose a novel captioning model, URECA, that uses advanced techniques like dynamic mask modeling to maintain spatial properties and enhance the quality of generated captions. The results demonstrate that URECA outperforms existing methods, providing more accurate and diverse descriptions across different image regions."
                },
                "zh": {
                    "title": "å¤šç²’åº¦åŒºåŸŸæè¿°çš„æ–°çªç ´",
                    "desc": "åŒºåŸŸçº§æè¿°æ—¨åœ¨ä¸ºç‰¹å®šå›¾åƒåŒºåŸŸç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼Œå¹¶çªå‡ºå…¶ç‹¬ç‰¹ç‰¹å¾ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¤šç²’åº¦ç”Ÿæˆç‹¬ç‰¹æè¿°æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†URECAæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šç²’åº¦åŒºåŸŸæè¿°çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œç¡®ä¿åŒºåŸŸä¸æè¿°ä¹‹é—´çš„ç‹¬ç‰¹å’Œä¸€è‡´çš„æ˜ å°„ã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†URECAæ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼–ç å¤šç²’åº¦åŒºåŸŸï¼Œç”Ÿæˆç»†è‡´ä¸”è¯­ä¹‰ä¸°å¯Œçš„æè¿°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.05304",
            "title": "Gaussian Mixture Flow Matching Models",
            "url": "https://huggingface.co/papers/2504.05304",
            "abstract": "Diffusion models approximate the denoising distribution as a Gaussian and predict its mean, whereas flow matching models reparameterize the Gaussian mean as flow velocity. However, they underperform in few-step sampling due to discretization error and tend to produce over-saturated colors under classifier-free guidance (CFG). To address these limitations, we propose a novel Gaussian mixture flow matching (GMFlow) model: instead of predicting the mean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a multi-modal flow velocity distribution, which can be learned with a KL divergence loss. We demonstrate that GMFlow generalizes previous diffusion and flow matching models where a single Gaussian is learned with an L_2 denoising loss. For inference, we derive GM-SDE/ODE solvers that leverage analytic denoising distributions and velocity fields for precise few-step sampling. Furthermore, we introduce a novel probabilistic guidance scheme that mitigates the over-saturation issues of CFG and improves image generation quality. Extensive experiments demonstrate that GMFlow consistently outperforms flow matching baselines in generation quality, achieving a Precision of 0.942 with only 6 sampling steps on ImageNet 256times256.",
            "score": 0,
            "issue_id": 3115,
            "pub_date": "2025-04-07",
            "pub_date_card": {
                "ru": "7 Ğ°Ğ¿Ñ€ĞµĞ»Ñ",
                "en": "April 7",
                "zh": "4æœˆ7æ—¥"
            },
            "hash": "b0223808c61a3545",
            "authors": [
                "Hansheng Chen",
                "Kai Zhang",
                "Hao Tan",
                "Zexiang Xu",
                "Fujun Luan",
                "Leonidas Guibas",
                "Gordon Wetzstein",
                "Sai Bi"
            ],
            "affiliations": [
                "Adobe Research, CA 95110, USA",
                "Hillbot",
                "Stanford University, CA 94305, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.05304.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#cv",
                    "#diffusion",
                    "#inference"
                ],
                "emoji": "ğŸŒŠ",
                "ru": {
                    "title": "GMFlow: Ğ¼Ğ¾Ñ‰Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ³Ğ°ÑƒÑÑĞ¾Ğ²Ñ‹Ğ¼Ğ¸ ÑĞ¼ĞµÑÑĞ¼Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Gaussian mixture flow matching (GMFlow) Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. GMFlow Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³Ğ°ÑƒÑÑĞ¾Ğ²Ğ¾Ğ¹ ÑĞ¼ĞµÑĞ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ KL-Ğ´Ğ¸Ğ²ĞµÑ€Ğ³ĞµĞ½Ñ†Ğ¸Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑˆĞ°Ñ‚ĞµĞ»Ğ¸ GM-SDE/ODE Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ° Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ ÑˆĞ°Ğ³Ğ¾Ğ². Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ ÑÑ…ĞµĞ¼Ğ° Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ°Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ñ€ĞµÑˆĞ°ÑÑ‰Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ¿ĞµÑ€ĞµÑÑ‹Ñ‰ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾-ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğ¼ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "GMFlow: Enhancing Image Generation with Dynamic Gaussian Mixtures",
                    "desc": "This paper introduces a new model called Gaussian Mixture Flow Matching (GMFlow) that improves upon traditional diffusion models and flow matching models. Instead of just predicting a single Gaussian mean, GMFlow predicts parameters for a dynamic Gaussian mixture, allowing it to better capture complex distributions in the data. The model addresses issues like discretization error and color saturation in generated images by using a novel probabilistic guidance scheme. Experimental results show that GMFlow achieves higher image generation quality with fewer sampling steps compared to existing methods."
                },
                "zh": {
                    "title": "é«˜æ–¯æ··åˆæµåŒ¹é…ï¼šæå‡å›¾åƒç”Ÿæˆè´¨é‡çš„æ–°æ–¹æ³•",
                    "desc": "æ‰©æ•£æ¨¡å‹é€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥è¿‘ä¼¼å»å™ªåˆ†å¸ƒå¹¶é¢„æµ‹å…¶å‡å€¼ï¼Œè€ŒæµåŒ¹é…æ¨¡å‹åˆ™å°†é«˜æ–¯å‡å€¼é‡æ–°å‚æ•°åŒ–ä¸ºæµé€Ÿã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å°‘æ­¥é‡‡æ ·æ—¶è¡¨ç°ä¸ä½³ï¼Œä¸»è¦æ˜¯ç”±äºç¦»æ•£åŒ–è¯¯å·®ï¼Œå¹¶ä¸”åœ¨æ— åˆ†ç±»å™¨å¼•å¯¼ä¸‹å®¹æ˜“äº§ç”Ÿè¿‡é¥±å’Œçš„é¢œè‰²ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„é«˜æ–¯æ··åˆæµåŒ¹é…ï¼ˆGMFlowï¼‰æ¨¡å‹ï¼šGMFlowé¢„æµ‹åŠ¨æ€é«˜æ–¯æ··åˆå‚æ•°ï¼Œä»¥æ•æ‰å¤šæ¨¡æ€æµé€Ÿåˆ†å¸ƒï¼Œå¹¶é€šè¿‡KLæ•£åº¦æŸå¤±è¿›è¡Œå­¦ä¹ ã€‚å®éªŒè¡¨æ˜ï¼ŒGMFlowåœ¨ç”Ÿæˆè´¨é‡ä¸Šå§‹ç»ˆä¼˜äºæµåŒ¹é…åŸºçº¿ï¼Œåœ¨ImageNet 256x256ä¸Šä»…ç”¨6ä¸ªé‡‡æ ·æ­¥éª¤å°±è¾¾åˆ°äº†0.942çš„ç²¾åº¦ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-04-07.html",
    "link_next": "2025-04-09.html",
    "link_month": "2025-04.html",
    "short_date_prev": {
        "ru": "07.04",
        "en": "04/07",
        "zh": "4æœˆ7æ—¥"
    },
    "short_date_next": {
        "ru": "09.04",
        "en": "04/09",
        "zh": "4æœˆ9æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 2,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªæ–°çš„å¤šè¯­è¨€é—®é¢˜è§£å†³åŸºå‡†ï¼Œç§°ä¸ºMulti-SWE-benchã€‚å®ƒæ¶µç›–äº†Javaã€TypeScriptã€JavaScriptã€Goã€Rustã€Cå’ŒC++ç­‰è¯­è¨€ã€‚è¯¥åŸºå‡†åŒ…å«1,632ä¸ªé«˜è´¨é‡å®ä¾‹ï¼Œç”±68ä½ä¸“å®¶æ³¨é‡Šã€‚åŸºäºè¿™ä¸ªåŸºå‡†ï¼Œä½œè€…è¯„ä¼°äº†ä¸€ç³»åˆ—å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„åˆ†æã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å®£å¸ƒæˆç«‹äº†ä¸€ä¸ªå¼€æºç¤¾åŒºMulti-SWE-RLï¼Œæ—¨åœ¨ä¸ºé—®é¢˜è§£å†³ä»»åŠ¡æ„å»ºå¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ•°æ®é›†ã€‚",
        "title": "Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ä¸ªæ–°çš„å¤šè¯­è¨€é—®é¢˜è§£å†³åŸºå‡†ï¼Œç§°ä¸ºMulti-SWE-benchã€‚å®ƒæ¶µç›–äº†Javaã€TypeScriptã€JavaScriptã€Goã€Rustã€Cå’ŒC++ç­‰è¯­è¨€ã€‚è¯¥åŸºå‡†åŒ…å«1,632ä¸ªé«˜è´¨é‡å®ä¾‹ï¼Œç”±68ä½ä¸“å®¶æ³¨é‡Šã€‚åŸºäºè¿™ä¸ªåŸºå‡†ï¼Œä½œè€…è¯„ä¼°äº†ä¸€ç³»åˆ—å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„åˆ†æã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å®£å¸ƒæˆç«‹äº†ä¸€ä¸ªå¼€æºç¤¾åŒºMulti-SWE-RLï¼Œæ—¨åœ¨ä¸ºé—®é¢˜è§£å†³ä»»åŠ¡æ„å»ºå¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ•°æ®é›†ã€‚\n\nzhÃ¨ piÄn wÃ©n zhÄng jiÃ¨ shÃ o le yÄ« gÃ¨ xÄ«n de duÅ yÇ” yÃ¡n wÃ¨n tÃ­ jiÄ› juÃ© jÄ« zhÇ”n, chÄ“ng wÃ©i Multi-SWE-bench. tÄ hÃ¡n gÇi le Java, TypeScript, JavaScript, Go, Rust, C hÃ© C++ dÄ›ng yÇ” yÃ¡n. gÇi jÄ« zhÇ”n bÄo hÃ¡n 1,632 gÃ¨ gÄo zhÃ¬ liÃ ng shÃ­ lÃ¬, yÇ’u 68 wÃ¨i zhuÄn jiÄ zhÃ¹ shÃ¬. jÄ« yÃº zhÃ¨ gÃ¨ jÄ« zhÇ”n, zuÃ² zhÄ› pÃ­ng gÅ« le yÄ« xÃ¬ liÃ¨ xiÄn jÃ¬n de mÃ³ xÃ­ng, bÃ¬ng tÃ­ gÅng le xiÃ¡ng xÃ¬ de fÄ“n xÄ«. cÇ wÃ i, wÃ©n zhÄng hÃ¡i xuÄn bÃ¹ chÃ©ng lÃ¬ le yÄ« gÃ¨ kÄi yuÃ¡n shÃ¨ qÅ« Multi-SWE-RL, zhÇ yÃº wÃ¨i wÃ¨n tÃ­ jiÄ› juÃ© rÃ¨n wÃ¹ gÃ²u jiÃ n dÃ  guÄ« mÃ³ qiÃ¡ng huÃ  xuÃ© xÃ¹n liÃ n shÃ¹ jÃ¹ jÃ­.",
        "vocab": "[\n    {\"word\": \"æ¶µç›–\", \"pinyin\": \"hÃ¡ngÃ i\", \"trans\": \"cover\"},\n    {\"word\": \"åŸºå‡†\", \"pinyin\": \"jÄ«zhÇ”n\", \"trans\": \"benchmark\"},\n    {\"word\": \"æ³¨é‡Š\", \"pinyin\": \"zhÃ¹shÃ¬\", \"trans\": \"annotate\"},\n    {\"word\": \"è¯„ä¼°\", \"pinyin\": \"pÃ­nggÅ«\", \"trans\": \"evaluate\"},\n    {\"word\": \"å…ˆè¿›\", \"pinyin\": \"xiÄnjÃ¬n\", \"trans\": \"advanced\"},\n    {\"word\": \"è¯¦ç»†\", \"pinyin\": \"xiÃ¡ngxÃ¬\", \"trans\": \"detailed\"},\n    {\"word\": \"åˆ†æ\", \"pinyin\": \"fÄ“nxÄ«\", \"trans\": \"analysis\"},\n    {\"word\": \"å®£å¸ƒ\", \"pinyin\": \"xuÄnbÃ¹\", \"trans\": \"announce\"},\n    {\"word\": \"æˆç«‹\", \"pinyin\": \"chÃ©nglÃ¬\", \"trans\": \"establish\"},\n    {\"word\": \"å¼€æº\", \"pinyin\": \"kÄiyuÃ¡n\", \"trans\": \"open-source\"},\n    {\"word\": \"ç¤¾åŒº\", \"pinyin\": \"shÃ¨qÅ«\", \"trans\": \"community\"},\n    {\"word\": \"æ—¨åœ¨\", \"pinyin\": \"zhÇzÃ i\", \"trans\": \"aim to\"},\n    {\"word\": \"æ„å»º\", \"pinyin\": \"gÃ²ujiÃ n\", \"trans\": \"build\"},\n    {\"word\": \"ä»»åŠ¡\", \"pinyin\": \"rÃ¨nwÃ¹\", \"trans\": \"task\"},\n    {\"word\": \"å¼ºåŒ–å­¦ä¹ \", \"pinyin\": \"qiÃ¡ng huÃ  xuÃ©xÃ­\", \"trans\": \"reinforcement learning\"},\n    {\"word\": \"è®­ç»ƒ\", \"pinyin\": \"xÃ¹nliÃ n\", \"trans\": \"training\"},\n    {\"word\": \"æ•°æ®é›†\", \"pinyin\": \"shÃ¹jÃ¹jÃ­\", \"trans\": \"dataset\"}\n]",
        "trans": "This article introduces a new multilingual problem-solving benchmark called Multi-SWE-bench. It covers languages such as Java, TypeScript, JavaScript, Go, Rust, C, and C++. The benchmark contains 1,632 high-quality instances annotated by 68 experts. Based on this benchmark, the authors evaluated a series of advanced models and provided detailed analyses. Additionally, the article announces the establishment of an open-source community, Multi-SWE-RL, aimed at building large-scale reinforcement learning training datasets for problem-solving tasks.",
        "update_ts": "2025-04-07 09:12"
    }
}