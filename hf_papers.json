{
    "date": {
        "ru": "9 января",
        "en": "January 9",
        "zh": "1月9日"
    },
    "time_utc": "2025-01-09 19:07",
    "weekday": 3,
    "issue_id": 1588,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.04519",
            "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
            "url": "https://huggingface.co/papers/2501.04519",
            "abstract": "We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising \"deep thinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\\"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels. On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% the brightest high school math students. Code and data will be available at https://github.com/microsoft/rStar.",
            "score": 92,
            "issue_id": 1572,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "b065003de5fa3bde",
            "authors": [
                "Xinyu Guan",
                "Li Lyna Zhang",
                "Yifei Liu",
                "Ning Shang",
                "Youran Sun",
                "Yi Zhu",
                "Fan Yang",
                "Mao Yang"
            ],
            "affiliations": [
                "Microsoft",
                "Peking University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04519.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#optimization",
                    "#benchmark",
                    "#small_models",
                    "#dataset"
                ],
                "emoji": "🧮",
                "ru": {
                    "title": "Малые модели решают большие задачи: rStar-Math превосходит гигантов в математике",
                    "desc": "Статья представляет rStar-Math - подход, позволяющий малым языковым моделям (SLM) достичь или превзойти способности крупных моделей в математических рассуждениях. Метод использует поиск по методу Монте-Карло (MCTS) с двумя специально обученными SLM: политикой и моделью вознаграждения. Авторы вводят новые методы синтеза обучающих данных, обучения модели вознаграждения и итеративного улучшения моделей. В результате rStar-Math значительно повышает эффективность SLM на математических тестах, превосходя более крупные модели."
                },
                "en": {
                    "title": "Empowering Small Models to Excel in Math Reasoning",
                    "desc": "The paper introduces rStar-Math, a framework that enhances the math reasoning abilities of small language models (SLMs) without relying on larger models. It employs Monte Carlo Tree Search (MCTS) to enable deep thinking, allowing the SLM to perform guided search during problem-solving. Key innovations include a code-augmented Chain of Thought (CoT) data synthesis method for generating verified reasoning paths, a refined process preference model (PPM) for better reward training, and a self-evolution strategy for iterative improvement. As a result, rStar-Math significantly boosts the performance of SLMs on math benchmarks, achieving state-of-the-art results in various assessments."
                },
                "zh": {
                    "title": "小型语言模型的数学推理新突破",
                    "desc": "rStar-Math展示了小型语言模型（SLMs）在数学推理能力上可以与OpenAI的o1相媲美，甚至超越它，而无需从更强大的模型中蒸馏。该方法通过蒙特卡洛树搜索（MCTS）实现“深度思考”，在测试时由SLM驱动的过程奖励模型指导数学策略SLM进行搜索。rStar-Math引入了三项创新来解决训练两个SLM的挑战，包括新颖的代码增强的链式推理数据合成方法和更有效的过程偏好模型（PPM）训练方法。经过四轮自我进化，rStar-Math在747,000个数学问题上生成了数百万个合成解，使SLMs的数学推理能力达到了最先进的水平。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04682",
            "title": "Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though",
            "url": "https://huggingface.co/papers/2501.04682",
            "abstract": "We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.",
            "score": 38,
            "issue_id": 1574,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "3479f7793755e586",
            "authors": [
                "Violet Xiang",
                "Charlie Snell",
                "Kanishk Gandhi",
                "Alon Albalak",
                "Anikait Singh",
                "Chase Blagden",
                "Duy Phung",
                "Rafael Rafailov",
                "Nathan Lile",
                "Dakota Mahan",
                "Louis Castricato",
                "Jan-Philipp Franken",
                "Nick Haber",
                "Chelsea Finn"
            ],
            "affiliations": [
                "Stanford University",
                "SynthLabs.ai",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04682.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#training",
                    "#rlhf",
                    "#rl",
                    "#multimodal",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Meta-CoT: новый уровень рассуждений для ИИ",
                    "desc": "Исследователи предлагают новую концепцию под названием Meta Chain-of-Thought (Meta-CoT), которая расширяет традиционный подход Chain-of-Thought. Meta-CoT моделирует базовые рассуждения, необходимые для построения цепочки мыслей. Авторы представляют эмпирические доказательства того, что современные языковые модели демонстрируют поведение, согласующееся с контекстным поиском. Они также описывают конкретный процесс обучения модели для генерации Meta-CoT, включающий инструктивную настройку и обучение с подкреплением."
                },
                "en": {
                    "title": "Empowering AI with Enhanced Reasoning through Meta-CoT",
                    "desc": "The paper introduces a new framework called Meta Chain-of-Thought (Meta-CoT), which enhances the traditional Chain-of-Thought (CoT) approach by focusing on the reasoning processes behind generating CoTs. It provides experimental results from advanced models that show behaviors similar to in-context search, and discusses techniques for creating Meta-CoT through process supervision, synthetic data, and search algorithms. The authors propose a detailed training pipeline that combines instruction tuning with search traces and reinforcement learning to improve the generation of Meta-CoTs. Additionally, the paper raises important questions about scaling, the role of verifiers, and the potential for discovering new reasoning methods, aiming to advance the reasoning capabilities of large language models (LLMs)."
                },
                "zh": {
                    "title": "推动人工智能推理能力的元思维链",
                    "desc": "我们提出了一种新颖的框架，称为元思维链（Meta-CoT），它通过明确建模所需的推理过程来扩展传统的思维链（CoT）。我们展示了来自最先进模型的实证证据，这些模型表现出与上下文搜索一致的行为，并探索了通过过程监督、合成数据生成和搜索算法来生成元思维链的方法。最后，我们概述了一个具体的训练流程，结合了指令调优、线性化搜索轨迹和强化学习后训练，以生成元思维链。此项工作为在大型语言模型中实现元思维链提供了理论和实践的路线图，推动了人工智能更强大和更人性化的推理能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04686",
            "title": "URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics",
            "url": "https://huggingface.co/papers/2501.04686",
            "abstract": "Chain-of-thought (CoT) reasoning has been widely applied in the mathematical reasoning of Large Language Models (LLMs). Recently, the introduction of derivative process supervision on CoT trajectories has sparked discussions on enhancing scaling capabilities during test time, thereby boosting the potential of these models. However, in multimodal mathematical reasoning, the scarcity of high-quality CoT training data has hindered existing models from achieving high-precision CoT reasoning and has limited the realization of reasoning potential during test time. In this work, we propose a three-module synthesis strategy that integrates CoT distillation, trajectory-format rewriting, and format unification. It results in a high-quality CoT reasoning instruction fine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively validate the state-of-the-art (SOTA) performance of the trained URSA-7B model on multiple multimodal mathematical benchmarks. For test-time scaling, we introduce a data synthesis strategy that automatically generates process annotation datasets, known as DualMath-1.1M, focusing on both interpretation and logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT reasoning capabilities to robust supervision abilities. The trained URSA-RM-7B acts as a verifier, effectively enhancing the performance of URSA-7B at test time. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD) verifying capabilities, showcasing its generalization. Model weights, training data and code will be open-sourced.",
            "score": 35,
            "issue_id": 1576,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "089df0fb9a548ce8",
            "authors": [
                "Ruilin Luo",
                "Zhuofan Zheng",
                "Yifan Wang",
                "Yiyao Yu",
                "Xinzhe Ni",
                "Zicheng Lin",
                "Jin Zeng",
                "Yujiu Yang"
            ],
            "affiliations": [
                "ByteDance",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04686.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#training",
                    "#multimodal",
                    "#data",
                    "#open_source",
                    "#reasoning",
                    "#math",
                    "#architecture",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Усиление мультимодальных математических рассуждений через синтез данных и верификацию",
                    "desc": "Статья представляет новый подход к улучшению математических рассуждений в мультимодальных языковых моделях. Авторы предлагают стратегию синтеза высококачественного набора данных MMathCoT-1M для обучения цепочкам рассуждений. Они также вводят метод DualMath-1.1M для генерации аннотаций процесса рассуждений, что позволяет модели URSA-7B перейти от способности рассуждать к возможности проверять рассуждения. Результаты показывают улучшение производительности и обобщающей способности модели."
                },
                "en": {
                    "title": "Enhancing Multimodal Mathematical Reasoning with CoT Synthesis",
                    "desc": "This paper discusses improving mathematical reasoning in Large Language Models (LLMs) using a method called Chain-of-Thought (CoT) reasoning. The authors introduce a new dataset, MMathCoT-1M, which is created through a three-module synthesis strategy to enhance the quality of CoT training data in multimodal mathematics. They also present a data synthesis strategy, DualMath-1.1M, that generates additional training data to improve the model's reasoning capabilities during testing. The results show that their model, URSA-RM-7B, significantly enhances performance and generalization in multimodal mathematical tasks."
                },
                "zh": {
                    "title": "提升多模态数学推理的链式推理能力",
                    "desc": "本文探讨了链式推理（CoT）在大型语言模型（LLMs）中的应用，特别是在多模态数学推理中的挑战。由于高质量的CoT训练数据稀缺，现有模型在测试时的推理能力受到限制。为了解决这个问题，作者提出了一种三模块合成策略，生成了高质量的多模态数学推理指令微调数据集MMathCoT-1M。通过进一步训练URSA-7B模型，结合生成的数据集DualMath-1.1M，显著提升了模型在测试时的推理能力和验证能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04227",
            "title": "Agent Laboratory: Using LLM Agents as Research Assistants",
            "url": "https://huggingface.co/papers/2501.04227",
            "abstract": "Historically, scientific discovery has been a lengthy and costly process, demanding substantial time and resources from initial conception to final results. To accelerate scientific discovery, reduce research costs, and improve research quality, we introduce Agent Laboratory, an autonomous LLM-based framework capable of completing the entire research process. This framework accepts a human-provided research idea and progresses through three stages--literature review, experimentation, and report writing to produce comprehensive research outputs, including a code repository and a research report, while enabling users to provide feedback and guidance at each stage. We deploy Agent Laboratory with various state-of-the-art LLMs and invite multiple researchers to assess its quality by participating in a survey, providing human feedback to guide the research process, and then evaluate the final paper. We found that: (1) Agent Laboratory driven by o1-preview generates the best research outcomes; (2) The generated machine learning code is able to achieve state-of-the-art performance compared to existing methods; (3) Human involvement, providing feedback at each stage, significantly improves the overall quality of research; (4) Agent Laboratory significantly reduces research expenses, achieving an 84% decrease compared to previous autonomous research methods. We hope Agent Laboratory enables researchers to allocate more effort toward creative ideation rather than low-level coding and writing, ultimately accelerating scientific discovery.",
            "score": 32,
            "issue_id": 1574,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "ff592ae1a5a88909",
            "authors": [
                "Samuel Schmidgall",
                "Yusheng Su",
                "Ze Wang",
                "Ximeng Sun",
                "Jialian Wu",
                "Xiaodong Yu",
                "Jiang Liu",
                "Zicheng Liu",
                "Emad Barsoum"
            ],
            "affiliations": [
                "AMD",
                "Johns Hopkins University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04227.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#training",
                    "#agents",
                    "#rlhf",
                    "#survey"
                ],
                "emoji": "🧪",
                "ru": {
                    "title": "Автономная лаборатория ИИ: революция в научных исследованиях",
                    "desc": "Статья представляет Agent Laboratory - автономную систему на основе моделей LLM, способную выполнять полный цикл научного исследования. Система проходит через этапы обзора литературы, экспериментов и написания отчета, позволяя пользователям давать обратную связь на каждом этапе. Эксперименты показали, что Agent Laboratory, работающая на модели o1-preview, генерирует лучшие результаты исследований и значительно снижает затраты на исследования. Авторы надеются, что эта система позволит исследователям сосредоточиться на творческом процессе, ускоряя научные открытия."
                },
                "en": {
                    "title": "Accelerating Science with Autonomous Research Frameworks",
                    "desc": "The paper presents Agent Laboratory, an autonomous framework that utilizes large language models (LLMs) to streamline the scientific research process. It operates in three stages: conducting a literature review, performing experiments, and writing reports, all while allowing human researchers to provide feedback. The study shows that Agent Laboratory can produce high-quality research outputs, including code that outperforms existing methods, and significantly reduces research costs by 84%. By automating routine tasks, the framework aims to free researchers to focus more on innovative ideas and less on tedious coding and documentation."
                },
                "zh": {
                    "title": "Agent Laboratory：加速科学发现的智能助手",
                    "desc": "本文介绍了一种名为Agent Laboratory的自主框架，旨在加速科学发现并降低研究成本。该框架基于大型语言模型（LLM），能够完成文献综述、实验和报告撰写等整个研究过程。研究表明，Agent Laboratory在生成研究成果方面表现优异，尤其是在机器学习代码的性能上，达到了最先进的水平。通过人类反馈的参与，研究质量显著提高，同时研究费用减少了84%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04306",
            "title": "LLM4SR: A Survey on Large Language Models for Scientific Research",
            "url": "https://huggingface.co/papers/2501.04306",
            "abstract": "In recent years, the rapid advancement of Large Language Models (LLMs) has transformed the landscape of scientific research, offering unprecedented support across various stages of the research cycle. This paper presents the first systematic survey dedicated to exploring how LLMs are revolutionizing the scientific research process. We analyze the unique roles LLMs play across four critical stages of research: hypothesis discovery, experiment planning and implementation, scientific writing, and peer reviewing. Our review comprehensively showcases the task-specific methodologies and evaluation benchmarks. By identifying current challenges and proposing future research directions, this survey not only highlights the transformative potential of LLMs, but also aims to inspire and guide researchers and practitioners in leveraging LLMs to advance scientific inquiry. Resources are available at the following repository: https://github.com/du-nlp-lab/LLM4SR",
            "score": 17,
            "issue_id": 1576,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "bfb9039780003b6d",
            "authors": [
                "Ziming Luo",
                "Zonglin Yang",
                "Zexin Xu",
                "Wei Yang",
                "Xinya Du"
            ],
            "affiliations": [
                "Nanyang Technological University, Singapore",
                "University of Texas at Dallas, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04306.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#survey",
                    "#multimodal",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "LLM как революционный инструмент в научных исследованиях",
                    "desc": "Эта статья представляет собой первый систематический обзор роли больших языковых моделей (LLM) в научных исследованиях. Авторы анализируют, как LLM используются на четырех ключевых этапах исследовательского процесса: формирование гипотез, планирование и проведение экспериментов, научное письмо и рецензирование. В работе рассматриваются специфические методологии и критерии оценки для каждой задачи. Статья также обсуждает текущие проблемы и предлагает направления для будущих исследований в этой области."
                },
                "en": {
                    "title": "Revolutionizing Research: The Power of Large Language Models",
                    "desc": "This paper systematically surveys the impact of Large Language Models (LLMs) on the scientific research process. It identifies how LLMs assist in four key stages: generating hypotheses, planning and conducting experiments, writing scientific papers, and facilitating peer reviews. The authors discuss specific methodologies and evaluation benchmarks for each task, highlighting the transformative potential of LLMs in enhancing research efficiency. Additionally, the paper addresses current challenges and suggests future research directions to further integrate LLMs into scientific inquiry."
                },
                "zh": {
                    "title": "大型语言模型：科学研究的变革者",
                    "desc": "近年来，大型语言模型（LLMs）的快速发展改变了科学研究的格局，为研究周期的各个阶段提供了前所未有的支持。本文首次系统性地调查了LLMs如何革新科学研究过程，分析了它们在假设发现、实验规划与实施、科学写作和同行评审等四个关键阶段的独特作用。我们的综述全面展示了任务特定的方法论和评估基准，并识别了当前面临的挑战，提出了未来的研究方向。通过强调LLMs的变革潜力，本文旨在激励和指导研究人员和从业者利用LLMs推动科学探索。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04575",
            "title": "InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection",
            "url": "https://huggingface.co/papers/2501.04575",
            "abstract": "Graphical User Interface (GUI) Agents, powered by multimodal large language models (MLLMs), have shown great potential for task automation on computing devices such as computers and mobile phones. However, existing agents face challenges in multi-step reasoning and reliance on textual annotations, limiting their effectiveness. We introduce InfiGUIAgent, an MLLM-based GUI Agent trained with a two-stage supervised fine-tuning pipeline. Stage 1 enhances fundamental skills such as GUI understanding and grounding, while Stage 2 integrates hierarchical reasoning and expectation-reflection reasoning skills using synthesized data to enable native reasoning abilities of the agents. InfiGUIAgent achieves competitive performance on several GUI benchmarks, highlighting the impact of native reasoning skills in enhancing GUI interaction for automation tasks. Resources are available at https://github.com/Reallm-Labs/InfiGUIAgent.",
            "score": 14,
            "issue_id": 1574,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "501c7ba58ede235b",
            "authors": [
                "Yuhang Liu",
                "Pengxiang Li",
                "Zishu Wei",
                "Congkai Xie",
                "Xueyu Hu",
                "Xinchen Xu",
                "Shengyu Zhang",
                "Xiaotian Han",
                "Hongxia Yang",
                "Fei Wu"
            ],
            "affiliations": [
                "ByteDance Inc",
                "Dalian University of Technology",
                "Reallm Labs",
                "The Hong Kong Polytechnic University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04575.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#synthetic",
                    "#training",
                    "#agents",
                    "#multimodal",
                    "#reasoning"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Умный агент GUI: новый уровень автоматизации интерфейсов",
                    "desc": "InfiGUIAgent - это агент графического пользовательского интерфейса, основанный на мультимодальных больших языковых моделях (MLLM). Он обучается с помощью двухэтапного процесса точной настройки, который улучшает базовые навыки понимания GUI и развивает способности к иерархическому рассуждению. InfiGUIAgent демонстрирует высокую эффективность в автоматизации задач взаимодействия с GUI, превосходя существующие подходы. Разработка направлена на преодоление ограничений, связанных с многошаговыми рассуждениями и зависимостью от текстовых аннотаций."
                },
                "en": {
                    "title": "Empowering GUI Agents with Native Reasoning Skills",
                    "desc": "InfiGUIAgent is a new type of Graphical User Interface (GUI) agent that uses multimodal large language models (MLLMs) to improve task automation on devices like computers and smartphones. This agent addresses the limitations of existing systems by employing a two-stage supervised fine-tuning process. The first stage focuses on developing basic skills such as understanding and interacting with GUIs, while the second stage enhances the agent's ability to perform complex reasoning tasks. As a result, InfiGUIAgent demonstrates strong performance on various GUI benchmarks, showcasing the importance of advanced reasoning capabilities in automating GUI interactions."
                },
                "zh": {
                    "title": "提升GUI交互的原生推理能力",
                    "desc": "本文介绍了一种名为InfiGUIAgent的图形用户界面（GUI）代理，它基于多模态大型语言模型（MLLM）进行任务自动化。InfiGUIAgent通过两阶段的监督微调流程进行训练，第一阶段提升了GUI理解和基础技能，第二阶段则通过合成数据整合了层次推理和期望反思推理能力。该代理在多个GUI基准测试中表现出色，显示了原生推理能力在增强GUI交互中的重要性。此研究为提高计算设备上的自动化任务提供了新的思路和方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.02772",
            "title": "GeAR: Generation Augmented Retrieval",
            "url": "https://huggingface.co/papers/2501.02772",
            "abstract": "Document retrieval techniques form the foundation for the development of large-scale information systems. The prevailing methodology is to construct a bi-encoder and compute the semantic similarity. However, such scalar similarity is difficult to reflect enough information and impedes our comprehension of the retrieval results. In addition, this computational process mainly emphasizes the global semantics and ignores the fine-grained semantic relationship between the query and the complex text in the document. In this paper, we propose a new method called Generation Augmented Retrieval (GeAR) that incorporates well-designed fusion and decoding modules. This enables GeAR to generate the relevant text from documents based on the fused representation of the query and the document, thus learning to \"focus on\" the fine-grained information. Also when used as a retriever, GeAR does not add any computational burden over bi-encoders. To support the training of the new framework, we have introduced a pipeline to efficiently synthesize high-quality data by utilizing large language models. GeAR exhibits competitive retrieval and localization performance across diverse scenarios and datasets. Moreover, the qualitative analysis and the results generated by GeAR provide novel insights into the interpretation of retrieval results. The code, data, and models will be released after completing technical review to facilitate future research.",
            "score": 11,
            "issue_id": 1572,
            "pub_date": "2025-01-06",
            "pub_date_card": {
                "ru": "6 января",
                "en": "January 6",
                "zh": "1月6日"
            },
            "hash": "dafa87428ce906b5",
            "authors": [
                "Haoyu Liu",
                "Shaohan Huang",
                "Jianfeng Liu",
                "Yuefeng Zhan",
                "Hao Sun",
                "Weiwei Deng",
                "Feng Sun",
                "Furu Wei",
                "Qi Zhang"
            ],
            "affiliations": [
                "Microsoft Corporation"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.02772.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#data",
                    "#rag",
                    "#synthetic",
                    "#dataset"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "GeAR: Новый взгляд на извлечение документов через генерацию",
                    "desc": "Статья предлагает новый метод извлечения документов под названием Generation Augmented Retrieval (GeAR). В отличие от традиционных би-энкодеров, GeAR использует модули слияния и декодирования для генерации релевантного текста на основе запроса и документа. Это позволяет модели фокусироваться на детальной информации, не увеличивая вычислительную нагрузку. Авторы также разработали конвейер для синтеза качественных данных с помощью больших языковых моделей для обучения GeAR."
                },
                "en": {
                    "title": "GeAR: Enhancing Document Retrieval with Fine-Grained Semantic Focus",
                    "desc": "This paper introduces a new method called Generation Augmented Retrieval (GeAR) that enhances document retrieval techniques by focusing on fine-grained semantic relationships. Unlike traditional bi-encoders that primarily assess global semantics, GeAR generates relevant text from documents by fusing the query and document representations. This approach allows for a deeper understanding of retrieval results without increasing computational costs. Additionally, the authors provide a pipeline for synthesizing high-quality training data using large language models, leading to improved performance across various datasets."
                },
                "zh": {
                    "title": "生成增强检索：关注细粒度信息的创新方法",
                    "desc": "本文提出了一种新的文档检索方法，称为生成增强检索（GeAR）。GeAR通过融合查询和文档的表示，生成相关文本，从而关注细粒度信息。与传统的双编码器方法相比，GeAR在检索时不会增加计算负担，同时在多种场景和数据集上表现出竞争力的检索和定位性能。该方法还通过利用大型语言模型合成高质量数据，支持新框架的训练。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04144",
            "title": "Chirpy3D: Continuous Part Latents for Creative 3D Bird Generation",
            "url": "https://huggingface.co/papers/2501.04144",
            "abstract": "In this paper, we push the boundaries of fine-grained 3D generation into truly creative territory. Current methods either lack intricate details or simply mimic existing objects -- we enable both. By lifting 2D fine-grained understanding into 3D through multi-view diffusion and modeling part latents as continuous distributions, we unlock the ability to generate entirely new, yet plausible parts through interpolation and sampling. A self-supervised feature consistency loss further ensures stable generation of these unseen parts. The result is the first system capable of creating novel 3D objects with species-specific details that transcend existing examples. While we demonstrate our approach on birds, the underlying framework extends beyond things that can chirp! Code will be released at https://github.com/kamwoh/chirpy3d.",
            "score": 9,
            "issue_id": 1578,
            "pub_date": "2025-01-07",
            "pub_date_card": {
                "ru": "7 января",
                "en": "January 7",
                "zh": "1月7日"
            },
            "hash": "89e2fad397bf0684",
            "authors": [
                "Kam Woh Ng",
                "Jing Yang",
                "Jia Wei Sii",
                "Jiankang Deng",
                "Chee Seng Chan",
                "Yi-Zhe Song",
                "Tao Xiang",
                "Xiatian Zhu"
            ],
            "affiliations": [
                "Imperial College London",
                "Universiti Malaya",
                "University of Cambridge",
                "University of Surrey"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04144.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#open_source",
                    "#3d"
                ],
                "emoji": "🐦",
                "ru": {
                    "title": "Генерация креативных 3D-моделей с беспрецедентной детализацией",
                    "desc": "Эта статья представляет новый метод генерации детализированных 3D-объектов, выходящий за рамки простого копирования существующих примеров. Авторы используют мультиракурсную диффузию и моделирование латентных представлений частей объекта как непрерывных распределений. Это позволяет создавать совершенно новые, но правдоподобные части объектов путем интерполяции и сэмплирования. Самоконтролируемая функция потерь обеспечивает стабильную генерацию этих невиданных ранее частей."
                },
                "en": {
                    "title": "Unlocking Creative 3D Generation with Fine-Grained Detail",
                    "desc": "This paper introduces a novel approach to generating detailed 3D objects that are not just replicas of existing items. By utilizing multi-view diffusion and treating part latents as continuous distributions, the authors enable the creation of new and realistic 3D parts through interpolation and sampling techniques. A self-supervised feature consistency loss is implemented to maintain stability in generating these novel parts. The system is demonstrated on birds, showcasing its ability to produce unique species-specific details, while the framework is applicable to a broader range of objects."
                },
                "zh": {
                    "title": "突破性细粒度3D生成，创造全新物体！",
                    "desc": "本文提出了一种创新的细粒度3D生成方法，能够创造出全新的3D物体，而不仅仅是模仿现有物体。我们通过多视角扩散将2D细粒度理解提升到3D，并将部分潜变量建模为连续分布，从而实现了新部件的插值和采样生成。自监督特征一致性损失确保了这些未见部件的稳定生成。我们的系统能够生成具有特定物种细节的全新3D对象，超越了现有的示例。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04689",
            "title": "SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images",
            "url": "https://huggingface.co/papers/2501.04689",
            "abstract": "We study the problem of single-image 3D object reconstruction. Recent works have diverged into two directions: regression-based modeling and generative modeling. Regression methods efficiently infer visible surfaces, but struggle with occluded regions. Generative methods handle uncertain regions better by modeling distributions, but are computationally expensive and the generation is often misaligned with visible surfaces. In this paper, we present SPAR3D, a novel two-stage approach aiming to take the best of both directions. The first stage of SPAR3D generates sparse 3D point clouds using a lightweight point diffusion model, which has a fast sampling speed. The second stage uses both the sampled point cloud and the input image to create highly detailed meshes. Our two-stage design enables probabilistic modeling of the ill-posed single-image 3D task while maintaining high computational efficiency and great output fidelity. Using point clouds as an intermediate representation further allows for interactive user edits. Evaluated on diverse datasets, SPAR3D demonstrates superior performance over previous state-of-the-art methods, at an inference speed of 0.7 seconds. Project page with code and model: https://spar3d.github.io",
            "score": 9,
            "issue_id": 1576,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "00474027a65aa27c",
            "authors": [
                "Zixuan Huang",
                "Mark Boss",
                "Aaryaman Vasishta",
                "James M. Rehg",
                "Varun Jampani"
            ],
            "affiliations": [
                "Stability AI",
                "UIUC"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04689.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "🧊",
                "ru": {
                    "title": "SPAR3D: Эффективная реконструкция 3D-объектов с использованием облаков точек",
                    "desc": "В статье представлен новый двухэтапный подход SPAR3D для реконструкции 3D-объектов по одному изображению. На первом этапе генерируется разреженное облако точек с помощью легковесной модели диффузии точек. На втором этапе используются сгенерированное облако точек и исходное изображение для создания детализированных 3D-моделей. Этот метод сочетает преимущества регрессионного и генеративного моделирования, обеспечивая высокую вычислительную эффективность и качество результатов."
                },
                "en": {
                    "title": "SPAR3D: Efficient and Detailed 3D Reconstruction from a Single Image",
                    "desc": "This paper introduces SPAR3D, a new method for reconstructing 3D objects from a single image. It combines regression and generative modeling to efficiently create 3D point clouds and detailed meshes. The first stage generates sparse point clouds quickly, while the second stage refines these into high-quality meshes using the input image. SPAR3D achieves high fidelity and speed, outperforming existing methods and allowing for user interaction with the 3D output."
                },
                "zh": {
                    "title": "SPAR3D：高效的单图像三维重建新方法",
                    "desc": "我们研究了单幅图像的三维物体重建问题。最近的研究分为两种方向：基于回归的建模和生成建模。回归方法能够有效推断可见表面，但在处理遮挡区域时表现不佳；而生成方法通过建模分布更好地处理不确定区域，但计算开销大且生成结果常常与可见表面不对齐。本文提出了SPAR3D，这是一种新颖的两阶段方法，旨在结合两种方法的优点，快速生成稀疏的三维点云，并利用输入图像创建高细节的网格。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.03271",
            "title": "DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization",
            "url": "https://huggingface.co/papers/2501.03271",
            "abstract": "The rapid rise of large language models (LLMs) has unlocked many applications but also underscores the challenge of aligning them with diverse values and preferences. Direct Preference Optimization (DPO) is central to alignment but constrained by fixed divergences and limited feature transformations. We propose DPO-Kernels, which integrates kernel methods to address these issues through four key contributions: (i) Kernelized Representations with polynomial, RBF, Mahalanobis, and spectral kernels for richer transformations, plus a hybrid loss combining embedding-based and probability-based objectives; (ii) Divergence Alternatives (Jensen-Shannon, Hellinger, Renyi, Bhattacharyya, Wasserstein, and f-divergences) for greater stability; (iii) Data-Driven Selection metrics that automatically choose the best kernel-divergence pair; and (iv) a Hierarchical Mixture of Kernels for both local precision and global modeling. Evaluations on 12 datasets demonstrate state-of-the-art performance in factuality, safety, reasoning, and instruction following. Grounded in Heavy-Tailed Self-Regularization, DPO-Kernels maintains robust generalization for LLMs, offering a comprehensive resource for further alignment research.",
            "score": 4,
            "issue_id": 1576,
            "pub_date": "2025-01-05",
            "pub_date_card": {
                "ru": "5 января",
                "en": "January 5",
                "zh": "1月5日"
            },
            "hash": "33d1640aee045ed5",
            "authors": [
                "Amitava Das",
                "Suranjana Trivedy",
                "Danush Khanna",
                "Rajarshi Roy",
                "Gurpreet Singh",
                "Basab Ghosh",
                "Yaswanth Narsupalli",
                "Vinija Jain",
                "Vasu Sharma",
                "Aishwarya Naresh Reganti",
                "Aman Chadha"
            ],
            "affiliations": [
                "Amazon AI, USA",
                "Artificial Intelligence Institute, University of South Carolina, USA",
                "Meta AI, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.03271.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#alignment",
                    "#reasoning",
                    "#dataset",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "DPO-Kernels: Новый подход к выравниванию языковых моделей",
                    "desc": "Статья представляет новый метод под названием DPO-Kernels для улучшения выравнивания больших языковых моделей (LLM) с различными ценностями и предпочтениями. Авторы предлагают использовать методы ядер для расширения возможностей прямой оптимизации предпочтений (DPO), включая кернелизованные представления, альтернативные дивергенции и data-driven выбор наилучшей комбинации ядра и дивергенции. DPO-Kernels демонстрирует улучшенные результаты в задачах фактологичности, безопасности, рассуждений и следования инструкциям на 12 наборах данных. Метод основан на саморегуляризации с тяжелыми хвостами и обеспечивает надежную генерализацию для LLM."
                },
                "en": {
                    "title": "Enhancing LLM Alignment with DPO-Kernels",
                    "desc": "This paper introduces DPO-Kernels, a method designed to improve the alignment of large language models (LLMs) with diverse user values. It enhances Direct Preference Optimization (DPO) by incorporating kernel methods, allowing for more flexible feature transformations and better divergence measures. The approach includes a hybrid loss function, various divergence alternatives, and data-driven selection metrics to optimize performance. Evaluations show that DPO-Kernels achieves state-of-the-art results in key areas such as factuality and safety across multiple datasets."
                },
                "zh": {
                    "title": "DPO-Kernels：提升大型语言模型对齐的创新方法",
                    "desc": "大型语言模型（LLMs）的快速发展带来了许多应用，但也突显了与多样化价值观和偏好对齐的挑战。直接偏好优化（DPO）是对齐的核心，但受到固定散度和有限特征变换的限制。我们提出了DPO-Kernels，通过四个关键贡献来解决这些问题，包括使用多项式、RBF、Mahalanobis和谱核的核化表示，以及结合嵌入基础和基于概率的目标的混合损失。我们的评估在12个数据集上展示了在事实性、安全性、推理和指令遵循方面的最先进性能，DPO-Kernels为进一步的对齐研究提供了全面的资源。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04694",
            "title": "EpiCoder: Encompassing Diversity and Complexity in Code Generation",
            "url": "https://huggingface.co/papers/2501.04694",
            "abstract": "Effective instruction tuning is indispensable for optimizing code LLMs, aligning model behavior with user expectations and enhancing model performance in real-world applications. However, most existing methods focus on code snippets, which are limited to specific functionalities and rigid structures, restricting the complexity and diversity of the synthesized data. To address these limitations, we introduce a novel feature tree-based synthesis framework inspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic structure of code, our framework models semantic relationships between code elements, enabling the generation of more nuanced and diverse data. The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features. This process enables the identification of more complex patterns and relationships within the code. By sampling subtrees with controlled depth and breadth, our framework allows precise adjustments to the complexity of the generated code, supporting a wide range of tasks from simple function-level operations to intricate multi-file scenarios. We fine-tuned widely-used base models to create the EpiCoder series, achieving state-of-the-art performance at both the function and file levels across multiple benchmarks. Notably, empirical evidence indicates that our approach shows significant potential in synthesizing highly complex repository-level code data. Further analysis elucidates the merits of this approach by rigorously assessing data complexity and diversity through software engineering principles and LLM-as-a-judge method.",
            "score": 3,
            "issue_id": 1581,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "1c1ef93cdfc23c2f",
            "authors": [
                "Yaoxiang Wang",
                "Haoling Li",
                "Xin Zhang",
                "Jie Wu",
                "Xiao Liu",
                "Wenxiang Hu",
                "Zhongxin Guo",
                "Yangyu Huang",
                "Ying Xin",
                "Yujiu Yang",
                "Jinsong Su",
                "Qi Chen",
                "Scarlett Li"
            ],
            "affiliations": [
                "Microsoft",
                "Tsinghua University",
                "Xiamen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04694.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#synthetic",
                    "#training",
                    "#optimization",
                    "#alignment",
                    "#architecture"
                ],
                "emoji": "🌳",
                "ru": {
                    "title": "Дерево признаков: новый путь к улучшению языковых моделей для кода",
                    "desc": "Статья представляет новый подход к улучшению языковых моделей для программирования с использованием дерева признаков, вдохновленного абстрактными синтаксическими деревьями. Этот метод позволяет генерировать более сложные и разнообразные обучающие данные, моделируя семантические связи между элементами кода. Авторы создали серию моделей EpiCoder, достигших высоких результатов в нескольких бенчмарках. Эмпирические данные показывают потенциал метода для синтеза сложных репозиториев кода."
                },
                "en": {
                    "title": "Unlocking Code Complexity with Feature Trees",
                    "desc": "This paper presents a new framework for instruction tuning in code language models (LLMs) that enhances their performance by generating more complex and diverse code data. The proposed feature tree-based synthesis framework goes beyond traditional code snippet methods by modeling semantic relationships between code elements, inspired by Abstract Syntax Trees (AST). By iteratively refining the feature tree, the framework captures intricate patterns and relationships, allowing for the generation of code that ranges from simple functions to complex multi-file scenarios. The authors demonstrate that their fine-tuned EpiCoder models achieve state-of-the-art results across various benchmarks, highlighting the effectiveness of their approach in synthesizing complex repository-level code data."
                },
                "zh": {
                    "title": "特征树框架：提升代码生成的复杂性与多样性",
                    "desc": "本论文提出了一种新的特征树合成框架，用于优化代码大语言模型（LLMs）的指令调优。该框架通过建模代码元素之间的语义关系，克服了现有方法在功能和结构上的局限性，从而生成更复杂和多样化的数据。特征树从原始数据构建，并通过迭代精炼，增加提取特征的数量和多样性。最终，我们通过微调广泛使用的基础模型，创建了EpiCoder系列，在多个基准测试中实现了函数和文件级别的最先进性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04652",
            "title": "Multi-task retriever fine-tuning for domain-specific and efficient RAG",
            "url": "https://huggingface.co/papers/2501.04652",
            "abstract": "Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information. However, when building real-world RAG applications, practical issues arise. First, the retrieved information is generally domain-specific. Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input. Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers. Moreover, these RAG applications normally retrieve different kinds of data. Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed. We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases.",
            "score": 1,
            "issue_id": 1584,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 января",
                "en": "January 8",
                "zh": "1月8日"
            },
            "hash": "1c906eb3ec9e3da5",
            "authors": [
                "Patrice Béchard",
                "Orlando Marquez Ayala"
            ],
            "affiliations": [
                "ServiceNow"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04652.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#training",
                    "#hallucinations",
                    "#rag",
                    "#optimization"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Универсальный извлекатель информации для эффективного RAG",
                    "desc": "Данная статья представляет новый подход к улучшению систем извлечения информации для крупных языковых моделей. Авторы предлагают дообучать небольшой энкодер для извлечения информации на различных доменно-специфичных задачах. Это позволяет использовать один энкодер для множества приложений, обеспечивая масштабируемость и эффективность. Исследование показывает, что такой подход хорошо обобщается на новые домены и задачи извлечения информации в реальных корпоративных сценариях."
                },
                "en": {
                    "title": "One Retriever to Rule Them All: Scalable RAG Solutions",
                    "desc": "This paper discusses the challenges of using Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs), particularly the issues of domain-specific information retrieval and the high cost of fine-tuning LLMs. The authors propose a solution that involves instruction fine-tuning a small retriever encoder on multiple domain-specific tasks, allowing it to serve various applications without needing separate retrievers. This approach enhances the quality of data fed into the LLM while maintaining low costs and scalability. The results demonstrate that the fine-tuned encoder can effectively generalize to new, unseen tasks in real-world scenarios."
                },
                "zh": {
                    "title": "一个编码器，多种应用，低成本高效能",
                    "desc": "检索增强生成（RAG）在部署大型语言模型（LLM）时变得非常普遍，因为它可以解决生成虚假或过时信息的典型问题。本文提出了一种解决方案，通过对小型检索器编码器进行指令微调，使其能够在多种特定领域任务上工作，从而实现一个编码器服务多个用例。这样可以降低成本，提高可扩展性和速度，同时避免为每个应用程序部署单独的检索器。我们的实验表明，该编码器在不同领域设置和未见过的检索任务中也能很好地泛化。"
                }
            }
        }
    ],
    "link_prev": "2025-01-08.html",
    "link_next": "2025-01-10.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "08.01",
        "en": "01/08",
        "zh": "1月8日"
    },
    "short_date_next": {
        "ru": "10.01",
        "en": "01/10",
        "zh": "1月10日"
    },
    "categories": {
        "#dataset": 5,
        "#data": 3,
        "#benchmark": 4,
        "#agents": 2,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 3,
        "#rag": 2,
        "#plp": 0,
        "#inference": 0,
        "#3d": 2,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 4,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 8,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 5,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 4,
        "#survey": 2,
        "#diffusion": 1,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 4,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 2,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了 rStar-Math，展示了小型语言模型（SLMs）可以通过蒙特卡罗树搜索（MCTS）进行“深度思考”，从而媲美或超越 OpenAI o1 的数学推理能力。rStar-Math 通过三项创新训练两个 SLMs：代码增强的思维链数据合成方法、更有效的过程偏好模型（PPM）训练方法和自我进化配方。经过四轮自我进化，rStar-Math 将 SLMs 的数学推理能力提升到最先进的水平。",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
        "pinyin": "这篇文章介绍了 rStar-Math，展示了小型语言模型（SLMs）可以通过蒙特卡罗树搜索（MCTS）进行“深度思考”，从而媲美或超越 OpenAI o1 的数学推理能力。rStar-Math 通过三项创新训练两个 SLMs：代码增强的思维链数据合成方法、更有效的过程偏好模型（PPM）训练方法和自我进化配方。经过四轮自我进化，rStar-Math 将 SLMs 的数学推理能力提升到最先进的水平。\n\nZhè piān wénzhāng jièshào le rStar-Math, zhǎnshì le xiǎoxíng yǔyán móxíng (SLMs) kěyǐ tōngguò méngtèkǎluó shù sōusuǒ (MCTS) jìnxíng “shēndù sīkǎo”, cóng'ér qíbǐ huò chāoyuè OpenAI o1 de shùxué tuīlǐ nénglì. rStar-Math tōngguò sān xiàng chuàngxīn xùnliàn liǎng gè SLMs: dàimǎ zēngqiáng de sīwéi liàn shùjù héchéng fāngfǎ, gèng yǒuxiào de guòchéng qiānhuò móxíng (PPM) xùnliàn fāngfǎ hé zìwǒ jìnhuà pèifáng. Jīngguò sì lún zìwǒ jìnhuà, rStar-Math jiāng SLMs de shùxué tuīlǐ nénglì tíshēng dào zuì xiānjìn de shuǐpíng.",
        "vocab": "[\n    {\"word\": \"展示\", \"pinyin\": \"zhǎnshì\", \"trans\": \"display, show\"},\n    {\"word\": \"小型\", \"pinyin\": \"xiǎoxíng\", \"trans\": \"small, mini\"},\n    {\"word\": \"语言模型\", \"pinyin\": \"yǔyán móxíng\", \"trans\": \"language model\"},\n    {\"word\": \"蒙特卡罗树搜索\", \"pinyin\": \"Méngtèkǎluó shù sōusuǒ\", \"trans\": \"Monte Carlo Tree Search\"},\n    {\"word\": \"深度思考\", \"pinyin\": \"shēndù sīkǎo\", \"trans\": \"deep thinking\"},\n    {\"word\": \"媲美\", \"pinyin\": \"pìměi\", \"trans\": \"rival, match\"},\n    {\"word\": \"超越\", \"pinyin\": \"chāoyuè\", \"trans\": \"surpass, exceed\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuīlǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"能力\", \"pinyin\": \"nénglì\", \"trans\": \"ability, capability\"},\n    {\"word\": \"创新\", \"pinyin\": \"chuàngxīn\", \"trans\": \"innovation\"},\n    {\"word\": \"训练\", \"pinyin\": \"xùnliàn\", \"trans\": \"train, training\"},\n    {\"word\": \"代码\", \"pinyin\": \"dàimǎ\", \"trans\": \"code\"},\n    {\"word\": \"增强\", \"pinyin\": \"zēngqiáng\", \"trans\": \"enhance, strengthen\"},\n    {\"word\": \"思维链\", \"pinyin\": \"sīwéi lián\", \"trans\": \"chain of thought\"},\n    {\"word\": \"数据合成\", \"pinyin\": \"shùjù héchéng\", \"trans\": \"data synthesis\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāngfǎ\", \"trans\": \"method\"},\n    {\"word\": \"过程\", \"pinyin\": \"guòchéng\", \"trans\": \"process\"},\n    {\"word\": \"偏好\", \"pinyin\": \"piānhào\", \"trans\": \"preference\"},\n    {\"word\": \"模型\", \"pinyin\": \"móxíng\", \"trans\": \"model\"},\n    {\"word\": \"自我进化\", \"pinyin\": \"zìwǒ jìnhuà\", \"trans\": \"self-evolution\"},\n    {\"word\": \"配方\", \"pinyin\": \"pèifāng\", \"trans\": \"formula, recipe\"},\n    {\"word\": \"四轮\", \"pinyin\": \"sì lún\", \"trans\": \"four rounds\"},\n    {\"word\": \"最先进\", \"pinyin\": \"zuì xiānjìn\", \"trans\": \"most advanced\"}\n]",
        "trans": "This article introduces rStar-Math, demonstrating that Small Language Models (SLMs) can engage in \"deep thinking\" through Monte Carlo Tree Search (MCTS), thereby matching or surpassing the mathematical reasoning capabilities of OpenAI o1. rStar-Math achieves this through three innovative approaches to train two SLMs: a code-enhanced chain-of-thought data synthesis method, a more effective Process Preference Model (PPM) training method, and a self-evolutionary recipe. After four rounds of self-evolution, rStar-Math elevates the mathematical reasoning abilities of SLMs to the most advanced level.",
        "update_ts": "2025-01-09 09:11"
    }
}