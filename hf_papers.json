{
    "date": {
        "ru": "20 ноября",
        "en": "November 20",
        "zh": "11月20日"
    },
    "time_utc": "2024-11-20 03:22",
    "weekday": 2,
    "issue_id": 674,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.11925",
            "title": "Continuous Speculative Decoding for Autoregressive Image Generation",
            "url": "https://huggingface.co/papers/2411.11925",
            "abstract": "Continuous-valued Autoregressive (AR) image generation models have demonstrated notable superiority over their discrete-token counterparts, showcasing considerable reconstruction quality and higher generation fidelity. However, the computational demands of the autoregressive framework result in significant inference overhead. While speculative decoding has proven effective in accelerating Large Language Models (LLMs), their adaptation to continuous-valued visual autoregressive models remains unexplored. This work generalizes the speculative decoding algorithm from discrete tokens to continuous space. By analyzing the intrinsic properties of output distribution, we establish a tailored acceptance criterion for the diffusion distributions prevalent in such models. To overcome the inconsistency that occurred in speculative decoding output distributions, we introduce denoising trajectory alignment and token pre-filling methods. Additionally, we identify the hard-to-sample distribution in the rejection phase. To mitigate this issue, we propose a meticulous acceptance-rejection sampling method with a proper upper bound, thereby circumventing complex integration. Experimental results show that our continuous speculative decoding achieves a remarkable 2.33times speed-up on off-the-shelf models while maintaining the output distribution. Codes will be available at https://github.com/MarkXCloud/CSpD",
            "score": 0,
            "issue_id": 674,
            "pub_date": "2024-11-18",
            "pub_date_card": {
                "ru": "18 ноября",
                "en": "November 18",
                "zh": "11月18日"
            },
            "hash": "17049106ecc06192",
            "authors": [
                "Zili Wang",
                "Robert Zhang",
                "Kun Ding",
                "Qi Yang",
                "Fei Li",
                "Shiming Xiang"
            ],
            "affiliations": [
                "China Tower Corporation Limited",
                "Institute of Automation, Chinese Academy of Sciences, China",
                "University of Chinese Academy of Sciences, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.11925.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#diffusion",
                    "#cv"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Ускорение генерации изображений: от дискретного к непрерывному",
                    "desc": "Статья представляет новый метод ускорения генерации изображений с помощью авторегрессионных моделей с непрерывными значениями. Авторы адаптируют алгоритм спекулятивного декодирования, ранее применявшийся для ускорения больших языковых моделей, к непрерывному пространству. Они вводят специальный критерий принятия для диффузионных распределений и предлагают методы выравнивания траектории шумоподавления и предварительного заполнения токенов. Экспериментальные результаты показывают 2.33-кратное ускорение без ухудшения качества выходных данных."
                },
                "en": {
                    "title": "Speeding Up Image Generation with Continuous Speculative Decoding",
                    "desc": "This paper presents a new approach to improve the speed of continuous-valued autoregressive image generation models. It adapts speculative decoding, a technique previously used in large language models, to work with continuous data. The authors introduce methods to align denoising trajectories and pre-fill tokens to enhance the output quality during the decoding process. Their experiments demonstrate that this new method can significantly speed up the generation process by over two times while preserving the quality of the generated images."
                },
                "zh": {
                    "title": "加速连续值自回归图像生成的推测解码",
                    "desc": "本文提出了一种针对连续值自回归图像生成模型的推测解码算法，旨在提高生成速度。通过分析输出分布的内在特性，建立了适合扩散分布的接受标准。为了解决推测解码输出分布的不一致性，本文引入了去噪轨迹对齐和令牌预填充方法。实验结果表明，该方法在保持输出分布的同时，实现了2.33倍的速度提升。"
                }
            }
        }
    ],
    "link_prev": "2024-11-19.html",
    "link_next": "2024-11-21.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "19.11",
        "en": "11/19",
        "zh": "11月19日"
    },
    "short_date_next": {
        "ru": "21.11",
        "en": "11/21",
        "zh": "11月21日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了多模态大语言模型（MLLMs）的兴起及其在日常生活中的潜力。手机是部署MLLMs的最佳平台，但由于内存和计算能力有限，难以实现流畅的实时处理。文章提出了BlueLM-V-3B，一种专为移动平台设计的算法和系统。它通过重新设计动态分辨率方案和硬件感知部署优化，实现了小尺寸、快速度和强性能。\n\nTranslation:\nThis article discusses the rise of multimodal large language models (MLLMs) and their potential in daily life. Mobile phones are the best platform for deploying MLLMs, but due to memory and computational limitations, real-time processing is challenging. The article presents BlueLM-V-3B, an algorithm and system designed for mobile platforms. It achieves small size, fast speed, and strong performance through dynamic resolution scheme redesign and hardware-aware deployment optimization.",
        "title": "BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices",
        "pinyin": "Sure, here is the pinyin transcription for the given text:\n\nZhè piān wén zhāng jiè shào le duō mó tài dà yǔ yán mó xíng (MLLMs) de xīng qǐ jí qí zài rì cháng shēng huó zhōng de qián lì. Shǒu jī shì bù shǔ MLLMs de zuì jiā píng tài, dàn yóu yú nèi cùn hé suàn jì néng lì yǒu xiàn, nán yǐ shí xiàn liú chàng de shí shí chǔ lǐ. Wén zhāng tí chū le BlueLM-V-3B, yī zhǒng zhuān wèi yí dòng píng tài shè jì de suàn fǎ hé xì tǒng. Tā tōng guò chóng xīn shè jì dòng tài fēn bié lǜ fāng ān hé yìng jiàn gǎn zhī bù shǔ yōu huà, shí xiàn le xiǎo chǐ cù, kuài sù dù hé qiáng xìng néng.\n\nTranslation:\nThis article discusses the rise of multimodal large language models (MLLMs) and their potential in daily life. Mobile phones are the best platform for deploying MLLMs, but due to memory and computational limitations, real-time processing is challenging. The article presents BlueLM-V-3B, an algorithm and system designed for mobile platforms. It achieves small size, fast speed, and strong performance through dynamic resolution scheme redesign and hardware-aware deployment optimization.",
        "vocab": "[{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'},\n{'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language models'},\n{'word': '兴起', 'pinyin': 'xīng qǐ', 'trans': 'rise'},\n{'word': '潜力', 'pinyin': 'qián lì', 'trans': 'potential'},\n{'word': '部署', 'pinyin': 'bù shǔ', 'trans': 'deploy'},\n{'word': '平台', 'pinyin': 'píng tái', 'trans': 'platform'},\n{'word': '内存', 'pinyin': 'nèi cún', 'trans': 'memory'},\n{'word': '计算', 'pinyin': 'jì suàn', 'trans': 'computational'},\n{'word': '流畅', 'pinyin': 'liú chàng', 'trans': 'smooth'},\n{'word': '实时', 'pinyin': 'shí shí', 'trans': 'real-time'},\n{'word': '处理', 'pinyin': 'chǔ lǐ', 'trans': 'processing'},\n{'word': '算法', 'pinyin': 'suàn fǎ', 'trans': 'algorithm'},\n{'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'},\n{'word': '分辨率', 'pinyin': 'fēn biàn lǜ', 'trans': 'resolution'},\n{'word': '方案', 'pinyin': 'fāng àn', 'trans': 'scheme'},\n{'word': '硬件', 'pinyin': 'yìng jiàn', 'trans': 'hardware'},\n{'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'aware'},\n{'word': '优化', 'pinyin': 'yōu huà', 'trans': 'optimization'}]",
        "trans": "Here's a refined translation of the text:\n\n\"This article explores the emergence of multimodal large language models (MLLMs) and their potential applications in everyday life. While mobile phones serve as an ideal platform for deploying MLLMs, their limited memory and computational power present challenges for smooth real-time processing. To address these issues, the article introduces BlueLM-V-3B, an algorithm and system tailored for mobile platforms. By employing a redesigned dynamic resolution scheme and hardware-aware deployment optimizations, BlueLM-V-3B achieves a compact size, high speed, and robust performance.\"\n\nChanges made:\n1. Used \"explores the emergence\" instead of \"discusses the rise\" for a more formal tone.\n2. Added \"applications in\" for better flow.\n3. Changed \"difficult to achieve\" to \"present challenges for\" to improve phrasing.\n4. Used \"to address these issues\" to create a stronger connection between sentences.\n5. Changed \"it achieves\" to \"By employing... BlueLM-V-3B achieves\" for clarity.\n6. Used \"robust performance\" instead of \"strong performance\" for more natural English.",
        "update_ts": "2024-11-19 09:11"
    }
}