{
    "date": {
        "ru": "30 ÑĞ½Ğ²Ğ°Ñ€Ñ",
        "en": "January 30",
        "zh": "1æœˆ30æ—¥"
    },
    "time_utc": "2025-01-30 06:13",
    "weekday": 3,
    "issue_id": 1943,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.17703",
            "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
            "url": "https://huggingface.co/papers/2501.17703",
            "abstract": "Supervised Fine-Tuning (SFT) is commonly used to train language models to imitate annotated responses for given instructions. In this paper, we challenge this paradigm and propose Critique Fine-Tuning (CFT), a strategy where models learn to critique noisy responses rather than simply imitate correct ones. Inspired by human learning processes that emphasize critical thinking, CFT encourages deeper analysis and nuanced understanding-traits often overlooked by standard SFT. To validate the effectiveness of CFT, we construct a 50K-sample dataset from WebInstruct, using GPT-4o as the teacher to generate critiques in the form of (input=[query; noisy response], output=critique). CFT on this dataset yields a consistent 4-10% improvement over SFT on six math benchmarks with different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We further expand to MetaMath and NuminaMath datasets and observe similar gains over SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50K samples-matches or outperforms competitive models such as AceMath and Qwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples. Ablation studies show that CFT is robust to the source of noisy response and teacher critique model. Through these findings, we argue that critique-based training offers a more effective alternative to advance the reasoning of language models.",
            "score": 6,
            "issue_id": 1940,
            "pub_date": "2025-01-29",
            "pub_date_card": {
                "ru": "29 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 29",
                "zh": "1æœˆ29æ—¥"
            },
            "hash": "18b6407976346581",
            "authors": [
                "Yubo Wang",
                "Xiang Yue",
                "Wenhu Chen"
            ],
            "affiliations": [
                "Carnegie Mellon University, Pittsburgh",
                "Department of Computer Science, University of Waterloo",
                "Vector Institute, Toronto"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.17703.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#optimization",
                    "#dataset",
                    "#math"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšÑ€Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ğ¸: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ - Critique Fine-Tuning (CFT), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒÑ‡Ğ¸Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹, Ğ° Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ. CFT Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ½Ğ° 4-10% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼ Supervised Fine-Tuning (SFT) Ğ½Ğ° ÑˆĞµÑÑ‚Ğ¸ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Qwen2.5-Math-CFT, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ²ÑĞµĞ³Ğ¾ Ğ½Ğ° 50 Ñ‚Ñ‹ÑÑÑ‡Ğ°Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ², Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¸Ğ»Ğ¸ Ğ»ÑƒÑ‡ÑˆĞµ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ñ… Ğ±Ğ¾Ğ»ĞµĞµ 2 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Critique Fine-Tuning: Enhancing Language Model Reasoning through Critical Analysis",
                    "desc": "This paper introduces Critique Fine-Tuning (CFT), a novel approach to training language models that focuses on teaching them to critique noisy responses instead of merely imitating correct ones. By mimicking human critical thinking, CFT fosters a deeper understanding and analysis of language, which is often neglected in traditional Supervised Fine-Tuning (SFT). The authors validate CFT's effectiveness using a dataset of 50,000 samples generated by GPT-4o, demonstrating consistent performance improvements of 4-10% over SFT across various math benchmarks. The results suggest that critique-based training can significantly enhance the reasoning capabilities of language models, outperforming models trained on much larger datasets."
                },
                "zh": {
                    "title": "æ‰¹è¯„å¾®è°ƒï¼šæå‡è¯­è¨€æ¨¡å‹æ¨ç†çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œç§°ä¸ºæ‰¹è¯„å¾®è°ƒï¼ˆCFTï¼‰ï¼Œä¸ä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä¸åŒï¼ŒCFTè®©æ¨¡å‹å­¦ä¹ å¦‚ä½•æ‰¹è¯„å™ªå£°å“åº”ï¼Œè€Œä¸æ˜¯ä»…ä»…æ¨¡ä»¿æ­£ç¡®çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•å—åˆ°äººç±»å­¦ä¹ è¿‡ç¨‹çš„å¯å‘ï¼Œå¼ºè°ƒæ‰¹åˆ¤æ€§æ€ç»´ï¼Œä¿ƒè¿›æ›´æ·±å±‚æ¬¡çš„åˆ†æå’Œç»†è‡´çš„ç†è§£ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«5ä¸‡æ ·æœ¬çš„æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨GPT-4oç”Ÿæˆæ‰¹è¯„ï¼ŒCFTåœ¨å¤šä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºSFTå–å¾—äº†4-10%çš„ä¸€è‡´æ€§æå‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäºæ‰¹è¯„çš„è®­ç»ƒæ–¹æ³•ä¸ºæå‡è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æä¾›äº†æ›´æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.17195",
            "title": "Atla Selene Mini: A General Purpose Evaluation Model",
            "url": "https://huggingface.co/papers/2501.17195",
            "abstract": "We introduce Atla Selene Mini, a state-of-the-art small language model-as-a-judge (SLMJ). Selene Mini is a general-purpose evaluator that outperforms the best SLMJs and GPT-4o-mini on overall performance across 11 out-of-distribution benchmarks, spanning absolute scoring, classification, and pairwise preference tasks. It is the highest-scoring 8B generative model on RewardBench, surpassing strong baselines like GPT-4o and specialized judges. To achieve this, we develop a principled data curation strategy that augments public datasets with synthetically generated critiques and ensures high quality through filtering and dataset ablations. We train our model on a combined direct preference optimization (DPO) and supervised fine-tuning (SFT) loss, and produce a highly promptable evaluator that excels in real-world scenarios. Selene Mini shows dramatically improved zero-shot agreement with human expert evaluations on financial and medical industry datasets. It is also robust to variations in prompt format. Preliminary results indicate that Selene Mini is the top-ranking evaluator in a live, community-driven Judge Arena. We release the model weights on HuggingFace (https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B) and Ollama to encourage widespread community adoption.",
            "score": 1,
            "issue_id": 1940,
            "pub_date": "2025-01-27",
            "pub_date_card": {
                "ru": "27 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 27",
                "zh": "1æœˆ27æ—¥"
            },
            "hash": "fb718aaf1278709b",
            "authors": [
                "Andrei Alexandru",
                "Antonia Calvi",
                "Henry Broomfield",
                "Jackson Golden",
                "Kyle Dai",
                "Mathias Leys",
                "Maurice Burger",
                "Max Bartolo",
                "Roman Engeler",
                "Sashank Pisupati",
                "Toby Drane",
                "Young Sun Park"
            ],
            "affiliations": [
                "Cohere",
                "University College London",
                "atla"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.17195.jpg",
            "data": {
                "categories": [
                    "#small_models",
                    "#open_source",
                    "#agi",
                    "#synthetic",
                    "#data",
                    "#training",
                    "#optimization",
                    "#dataset",
                    "#rlhf"
                ],
                "emoji": "âš–ï¸",
                "ru": {
                    "title": "Atla Selene Mini: ĞœĞ°Ğ»Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-ÑÑƒĞ´ÑŒÑ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Atla Selene Mini - Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²ÑƒÑ Ğ¼Ğ°Ğ»ÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-ÑÑƒĞ´ÑŒÑ (SLMJ). ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ SLMJ Ğ¸ GPT-4o-mini Ğ¿Ğ¾ Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² 11 Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ…. Selene Mini Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ĞºÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ÑĞ¾Ñ‡ĞµÑ‚Ğ°ÑÑ‰ĞµĞ¹ Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¸Ğµ Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²-Ğ»ÑĞ´ĞµĞ¹ Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ğ¸ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ±ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸."
                },
                "en": {
                    "title": "Selene Mini: The Next Level in Language Model Evaluation!",
                    "desc": "Atla Selene Mini is a cutting-edge small language model designed to evaluate various tasks effectively. It surpasses existing models, including GPT-4o-mini, by achieving superior performance on 11 benchmarks related to scoring, classification, and preference tasks. The model benefits from a unique data curation strategy that enhances public datasets with synthetic critiques, ensuring high-quality training data. With a combination of direct preference optimization and supervised fine-tuning, Selene Mini demonstrates strong alignment with human evaluations, particularly in specialized fields like finance and medicine."
                },
                "zh": {
                    "title": "Atla Selene Miniï¼šè¶…è¶Šä¼ ç»Ÿè¯„ä¼°çš„è¯­è¨€æ¨¡å‹",
                    "desc": "æˆ‘ä»¬ä»‹ç»äº†Atla Selene Miniï¼Œè¿™æ˜¯ä¸€ç§å…ˆè¿›çš„å°å‹è¯­è¨€æ¨¡å‹è¯„ä¼°å™¨ï¼ˆSLMJï¼‰ã€‚Selene Miniåœ¨11ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼ŒåŒ…æ‹¬GPT-4o-miniï¼Œå°¤å…¶åœ¨ç»å¯¹è¯„åˆ†ã€åˆ†ç±»å’Œæˆå¯¹åå¥½ä»»åŠ¡ä¸Šã€‚é€šè¿‡ç²¾å¿ƒçš„æ•°æ®ç­–åˆ’ç­–ç•¥ï¼Œæˆ‘ä»¬å¢å¼ºäº†å…¬å…±æ•°æ®é›†ï¼Œå¹¶ç¡®ä¿æ•°æ®è´¨é‡ï¼Œä»è€Œè®­ç»ƒå‡ºä¸€ä¸ªåœ¨çœŸå®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²çš„è¯„ä¼°å™¨ã€‚Selene Miniåœ¨é‡‘èå’ŒåŒ»ç–—è¡Œä¸šæ•°æ®é›†ä¸Šä¸äººç±»ä¸“å®¶è¯„ä¼°çš„é›¶-shotä¸€è‡´æ€§æ˜¾è‘—æé«˜ï¼Œä¸”å¯¹æç¤ºæ ¼å¼çš„å˜åŒ–å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.17749",
            "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
            "url": "https://huggingface.co/papers/2501.17749",
            "abstract": "Large Language Models (LLMs) have become an integral part of our daily lives. However, they impose certain risks, including those that can harm individuals' privacy, perpetuate biases and spread misinformation. These risks highlight the need for robust safety mechanisms, ethical guidelines, and thorough testing to ensure their responsible deployment. Safety of LLMs is a key property that needs to be thoroughly tested prior the model to be deployed and accessible to the general users. This paper reports the external safety testing experience conducted by researchers from Mondragon University and University of Seville on OpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing program. In particular, we apply our tool, ASTRAL, to automatically and systematically generate up to date unsafe test inputs (i.e., prompts) that helps us test and assess different safety categories of LLMs. We automatically generate and execute a total of 10,080 unsafe test input on a early o3-mini beta version. After manually verifying the test cases classified as unsafe by ASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We highlight key insights and findings uncovered during the pre-deployment external testing phase of OpenAI's latest LLM.",
            "score": 1,
            "issue_id": 1940,
            "pub_date": "2025-01-29",
            "pub_date_card": {
                "ru": "29 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 29",
                "zh": "1æœˆ29æ—¥"
            },
            "hash": "325df13c4995c5e9",
            "authors": [
                "Aitor Arrieta",
                "Miriam Ugarte",
                "Pablo Valle",
                "JosÃ© Antonio Parejo",
                "Sergio Segura"
            ],
            "affiliations": [
                "Mondragon University, Mondragon, Spain",
                "University of Seville, Seville, Spain"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.17749.jpg",
            "data": {
                "categories": [
                    "#ethics",
                    "#data",
                    "#inference",
                    "#training",
                    "#security"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: ĞºĞ»ÑÑ‡ Ğº Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼Ñƒ Ğ˜Ğ˜",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ¿Ñ‹Ñ‚ Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ OpenAI o3-mini. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ ASTRAL Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½ĞµĞ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ², Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ‘Ñ‹Ğ»Ğ¾ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾ 10 080 Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¸Ğ· ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… 87 ÑĞ»ÑƒÑ‡Ğ°ĞµĞ² Ğ±Ñ‹Ğ»Ğ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ ĞºĞ°Ğº Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ½ĞµĞ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ñ… Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼."
                },
                "en": {
                    "title": "Ensuring Safety in Large Language Models: A Testing Approach",
                    "desc": "This paper discusses the safety testing of Large Language Models (LLMs), focusing on the o3-mini model from OpenAI. Researchers from Mondragon University and University of Seville used a tool called ASTRAL to automatically create unsafe test inputs to evaluate the model's safety. They generated and executed 10,080 test prompts, identifying 87 instances of unsafe behavior after manual verification. The findings emphasize the importance of rigorous safety assessments before deploying LLMs to mitigate risks like privacy violations and misinformation."
                },
                "zh": {
                    "title": "ç¡®ä¿å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ä¸è´£ä»»ä½¿ç”¨",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æˆ‘ä»¬çš„æ—¥å¸¸ç”Ÿæ´»ä¸­å˜å¾—ä¸å¯æˆ–ç¼ºï¼Œä½†å®ƒä»¬ä¹Ÿå¸¦æ¥äº†éšç§é£é™©ã€åè§å’Œé”™è¯¯ä¿¡æ¯ä¼ æ’­ç­‰é—®é¢˜ã€‚è¿™äº›é£é™©è¡¨æ˜éœ€è¦å»ºç«‹å¼ºæœ‰åŠ›çš„å®‰å…¨æœºåˆ¶å’Œä¼¦ç†æŒ‡å¯¼ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„è´Ÿè´£ä»»ä½¿ç”¨ã€‚æœ¬æ–‡æŠ¥å‘Šäº†è’™å¾·æ‹‰è´¡å¤§å­¦å’Œå¡ç»´åˆ©äºšå¤§å­¦çš„ç ”ç©¶äººå‘˜å¯¹OpenAIçš„æ–°o3-mini LLMè¿›è¡Œçš„å¤–éƒ¨å®‰å…¨æµ‹è¯•ç»éªŒã€‚æˆ‘ä»¬ä½¿ç”¨ASTRALå·¥å…·è‡ªåŠ¨ç”Ÿæˆä¸å®‰å…¨çš„æµ‹è¯•è¾“å…¥ï¼Œä»¥è¯„ä¼°LLMsçš„ä¸åŒå®‰å…¨ç±»åˆ«ï¼Œå¹¶å‘ç°äº†87ä¸ªå®é™…çš„ä¸å®‰å…¨è¡Œä¸ºå®ä¾‹ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-01-29.html",
    "link_next": "2025-01-31.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "29.01",
        "en": "01/29",
        "zh": "1æœˆ29æ—¥"
    },
    "short_date_next": {
        "ru": "31.01",
        "en": "01/31",
        "zh": "1æœˆ31æ—¥"
    },
    "categories": {
        "#dataset": 2,
        "#data": 2,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 1,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 1,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« æ¯”è¾ƒäº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨åŸºç¡€æ¨¡å‹ä¸Šçš„ä½œç”¨ã€‚ç ”ç©¶å‘ç°ï¼ŒRLåœ¨æ–‡æœ¬å’Œè§†è§‰ä»»åŠ¡ä¸Šéƒ½è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚SFTå€¾å‘äºè®°ä½è®­ç»ƒæ•°æ®ï¼Œè€ŒRLèƒ½å¤Ÿå¤„ç†æœªè§è¿‡çš„å˜ä½“ã€‚RLè¿˜æé«˜äº†æ¨¡å‹çš„è§†è§‰è¯†åˆ«èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒSFTå¯¹äºRLçš„æœ‰æ•ˆè®­ç»ƒä»ç„¶ä¸å¯æˆ–ç¼ºã€‚",
        "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
        "pinyin": "è¿™ç¯‡æ–‡ç« æ¯”è¾ƒäº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨åŸºç¡€æ¨¡å‹ä¸Šçš„ä½œç”¨ã€‚ç ”ç©¶å‘ç°ï¼ŒRLåœ¨æ–‡æœ¬å’Œè§†è§‰ä»»åŠ¡ä¸Šéƒ½è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚SFTå€¾å‘äºè®°ä½è®­ç»ƒæ•°æ®ï¼Œè€ŒRLèƒ½å¤Ÿå¤„ç†æœªè§è¿‡çš„å˜ä½“ã€‚RLè¿˜æé«˜äº†æ¨¡å‹çš„è§†è§‰è¯†åˆ«èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒSFTå¯¹äºRLçš„æœ‰æ•ˆè®­ç»ƒä»ç„¶ä¸å¯æˆ–ç¼ºã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng bÇjiÃ o le jiÃ ndÅ« wÄ“itiÃ¡o (SFT) hÃ© qiÃ¡ng huÃ  xuÃ©xÃ­ (RL) zÃ i jÄ«chÇ” mÃ³xÃ­ng shÃ ng de zuÃ²yÃ²ng. YÃ¡njiÅ« fÄxiÃ n, RL zÃ i wÃ©nbÄ›n hÃ© shÃ¬juÃ© rÃ¨nwÃ¹ shÃ ng dÅu biÇoxiÃ n chÅ« gÃ¨ng hÇo de fÃ nhuÃ  nÃ©nglÃ¬. SFT qÄ«ngxiÃ ng yÃº jÃ¬zhÃ¹ xÃ¹nliÃ n shÃ¹jÃ¹, Ã©r RL nÃ©nggÃ²u chÇ”lÇ wÃ¨i jiÃ nguÃ² de biÃ ntÇ. RL hÃ¡i tÃ­gÄo le mÃ³xÃ­ng de shÃ¬juÃ© shÃ­biÃ© nÃ©nglÃ¬. RÃ¡n'Ã©r, SFT duÃ¬yÃº RL de yÇ’uxiÃ o xÃ¹nliÃ n rÃ©ngrÃ¡n bÃ¹kÄ› huÃ²quÄ“.",
        "vocab": "[{'word': 'ç›‘ç£', 'pinyin': 'jiÃ n dÅ«', 'trans': 'supervised'},\n{'word': 'å¾®è°ƒ', 'pinyin': 'wÄ“i tiÃ¡o', 'trans': 'fine-tuning'},\n{'word': 'å¼ºåŒ–å­¦ä¹ ', 'pinyin': 'qiÃ¡ng huÃ  xuÃ© xÃ­', 'trans': 'reinforcement learning'},\n{'word': 'åŸºç¡€æ¨¡å‹', 'pinyin': 'jÄ« chÇ” mÃ³ xÃ­ng', 'trans': 'foundational model'},\n{'word': 'ä½œç”¨', 'pinyin': 'zuÃ² yÃ²ng', 'trans': 'effect'},\n{'word': 'æ³›åŒ–', 'pinyin': 'fÃ n huÃ ', 'trans': 'generalization'},\n{'word': 'å€¾å‘äº', 'pinyin': 'qÄ«ng xiÃ ng yÃº', 'trans': 'tend to'},\n{'word': 'æœªè§è¿‡', 'pinyin': 'wÃ¨i jiÃ n guÃ²', 'trans': 'unseen'},\n{'word': 'å˜ä½“', 'pinyin': 'biÃ n tÇ', 'trans': 'variant'},\n{'word': 'è§†è§‰è¯†åˆ«', 'pinyin': 'shÃ¬ juÃ© shÃ­ biÃ©', 'trans': 'visual recognition'},\n{'word': 'ä¸å¯æˆ–ç¼º', 'pinyin': 'bÃ¹ kÄ› huÃ² quÄ“', 'trans': 'indispensable'}]",
        "trans": "This article compares the roles of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on base models. The study found that RL demonstrates better generalization capabilities in both textual and visual tasks. SFT tends to memorize training data, while RL can handle unseen variants. RL also enhances the model's visual recognition capabilities. However, SFT remains indispensable for effective RL training.",
        "update_ts": "2025-01-29 09:10"
    }
}