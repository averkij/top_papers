{
    "date": {
        "ru": "25 декабря",
        "en": "December 25",
        "zh": "12月25日"
    },
    "time_utc": "2024-12-25 04:12",
    "weekday": 2,
    "issue_id": 1305,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.14711",
            "title": "ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Routing",
            "url": "https://huggingface.co/papers/2412.14711",
            "abstract": "Sparsely activated Mixture-of-Experts (MoE) models are widely adopted to scale up model capacity without increasing the computation budget. However, vanilla TopK routers are trained in a discontinuous, non-differentiable way, limiting their performance and scalability. To address this issue, we propose ReMoE, a fully differentiable MoE architecture that offers a simple yet effective drop-in replacement for the conventional TopK+Softmax routing, utilizing ReLU as the router instead. We further propose methods to regulate the router's sparsity while balancing the load among experts. ReMoE's continuous nature enables efficient dynamic allocation of computation across tokens and layers, while also exhibiting domain specialization. Our experiments demonstrate that ReMoE consistently outperforms vanilla TopK-routed MoE across various model sizes, expert counts, and levels of granularity. Furthermore, ReMoE exhibits superior scalability with respect to the number of experts, surpassing traditional MoE architectures. The implementation based on Megatron-LM is available at https://github.com/thu-ml/ReMoE.",
            "score": 2,
            "issue_id": 1305,
            "pub_date": "2024-12-19",
            "pub_date_card": {
                "ru": "19 декабря",
                "en": "December 19",
                "zh": "12月19日"
            },
            "hash": "0b43c3f140601a96",
            "authors": [
                "Ziteng Wang",
                "Jianfei Chen",
                "Jun Zhu"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.14711.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "ReMoE: Дифференцируемая архитектура для эффективных моделей Mixture-of-Experts",
                    "desc": "Статья представляет новую архитектуру ReMoE для моделей Mixture-of-Experts (MoE). ReMoE использует полностью дифференцируемый маршрутизатор на основе ReLU вместо традиционного TopK+Softmax. Это позволяет эффективно распределять вычисления между токенами и слоями, а также обеспечивает специализацию по доменам. Эксперименты показывают, что ReMoE превосходит обычные MoE по производительности и масштабируемости при различных размерах моделей и количестве экспертов."
                },
                "en": {
                    "title": "ReMoE: Revolutionizing Mixture-of-Experts with Differentiable Routing",
                    "desc": "This paper introduces ReMoE, a new architecture for Mixture-of-Experts (MoE) models that improves upon traditional TopK routers by making them fully differentiable. By using ReLU as the routing mechanism, ReMoE allows for continuous optimization, which enhances performance and scalability. The authors also present techniques to manage the sparsity of the router and ensure an even distribution of workload among experts. Experimental results show that ReMoE outperforms conventional MoE models in various scenarios, demonstrating better scalability with an increasing number of experts."
                },
                "zh": {
                    "title": "ReMoE：提升混合专家模型的性能与可扩展性",
                    "desc": "本文提出了一种新的稀疏激活混合专家模型ReMoE，旨在提高模型的性能和可扩展性。与传统的TopK路由器不同，ReMoE采用了完全可微分的架构，使用ReLU作为路由器，从而克服了非连续性带来的限制。我们还提出了调节路由器稀疏性的方法，以平衡专家之间的负载。实验结果表明，ReMoE在不同模型规模和专家数量下，均优于传统的TopK路由混合专家模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.18153",
            "title": "DepthLab: From Partial to Complete",
            "url": "https://huggingface.co/papers/2412.18153",
            "abstract": "Missing values remain a common challenge for depth data across its wide range of applications, stemming from various causes like incomplete data acquisition and perspective alteration. This work bridges this gap with DepthLab, a foundation depth inpainting model powered by image diffusion priors. Our model features two notable strengths: (1) it demonstrates resilience to depth-deficient regions, providing reliable completion for both continuous areas and isolated points, and (2) it faithfully preserves scale consistency with the conditioned known depth when filling in missing values. Drawing on these advantages, our approach proves its worth in various downstream tasks, including 3D scene inpainting, text-to-3D scene generation, sparse-view reconstruction with DUST3R, and LiDAR depth completion, exceeding current solutions in both numerical performance and visual quality. Our project page with source code is available at https://johanan528.github.io/depthlab_web/.",
            "score": 1,
            "issue_id": 1305,
            "pub_date": "2024-12-24",
            "pub_date_card": {
                "ru": "24 декабря",
                "en": "December 24",
                "zh": "12月24日"
            },
            "hash": "c319c831137b3ce6",
            "authors": [
                "Zhiheng Liu",
                "Ka Leong Cheng",
                "Qiuyu Wang",
                "Shuzhe Wang",
                "Hao Ouyang",
                "Bin Tan",
                "Kai Zhu",
                "Yujun Shen",
                "Qifeng Chen",
                "Ping Luo"
            ],
            "affiliations": [
                "Aalto University",
                "Ant Group",
                "HKU",
                "HKUST",
                "Tongyi Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.18153.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#3d",
                    "#open_source",
                    "#dataset"
                ],
                "emoji": "🕳️",
                "ru": {
                    "title": "DepthLab: Восполнение пробелов в данных глубины с помощью ИИ",
                    "desc": "DepthLab - это модель для восстановления глубины изображения, основанная на диффузионных приорах. Она способна надежно заполнять как большие области, так и отдельные точки с отсутствующими данными глубины. Модель сохраняет согласованность масштаба с известной глубиной при заполнении пропусков. DepthLab превосходит существующие решения в различных задачах, включая инпейнтинг 3D-сцен и дополнение данных LiDAR."
                },
                "en": {
                    "title": "DepthLab: Bridging the Gap in Depth Data Completion",
                    "desc": "This paper presents DepthLab, a novel model designed to address the issue of missing values in depth data, which often occurs due to incomplete data collection or changes in perspective. DepthLab utilizes image diffusion priors to effectively inpaint depth information, ensuring that both continuous and isolated missing regions are filled accurately. The model maintains scale consistency with known depth values, which is crucial for realistic depth completion. DepthLab outperforms existing methods in various applications, such as 3D scene inpainting and LiDAR depth completion, demonstrating superior numerical and visual results."
                },
                "zh": {
                    "title": "深度修复新突破：DepthLab模型",
                    "desc": "本论文提出了一种名为DepthLab的深度图像修复模型，旨在解决深度数据中的缺失值问题。该模型利用图像扩散先验，能够有效填补深度不足的区域，确保连续区域和孤立点的可靠修复。DepthLab在填补缺失值时，能够保持与已知深度的一致性，确保尺度的准确性。通过这些优势，该模型在3D场景修复、文本到3D场景生成、稀疏视图重建和LiDAR深度补全等任务中表现优异，超越了现有的解决方案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.15443",
            "title": "SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval",
            "url": "https://huggingface.co/papers/2412.15443",
            "abstract": "Retrieval-Augmented Generation (RAG) systems have become pivotal in leveraging vast corpora to generate informed and contextually relevant responses, notably reducing hallucinations in Large Language Models. Despite significant advancements, these systems struggle to efficiently process and retrieve information from large datasets while maintaining a comprehensive understanding of the context. This paper introduces SKETCH, a novel methodology that enhances the RAG retrieval process by integrating semantic text retrieval with knowledge graphs, thereby merging structured and unstructured data for a more holistic comprehension. SKETCH, demonstrates substantial improvements in retrieval performance and maintains superior context integrity compared to traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER, NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline approaches on key RAGAS metrics such as answer_relevancy, faithfulness, context_precision and context_recall. Notably, on the Italian Cuisine dataset, SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99, representing the highest performance across all evaluated metrics. These results highlight SKETCH's capability in delivering more accurate and contextually relevant responses, setting new benchmarks for future retrieval systems.",
            "score": 1,
            "issue_id": 1305,
            "pub_date": "2024-12-19",
            "pub_date_card": {
                "ru": "19 декабря",
                "en": "December 19",
                "zh": "12月19日"
            },
            "hash": "2d16e57527037cb7",
            "authors": [
                "Aakash Mahalingam",
                "Vinesh Kumar Gande",
                "Aman Chadha",
                "Vinija Jain",
                "Divya Chaudhary"
            ],
            "affiliations": [
                "Amazon AI",
                "Meta",
                "Northeastern University",
                "Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.15443.jpg",
            "data": {
                "categories": [
                    "#graphs",
                    "#dataset",
                    "#hallucinations",
                    "#benchmark",
                    "#rag",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "SKETCH: Революция в извлечении информации для генеративных моделей",
                    "desc": "Данная статья представляет новый метод SKETCH, улучшающий процесс извлечения информации в системах генерации с аугментацией извлечения (RAG). SKETCH объединяет семантический поиск текста с графами знаний, интегрируя структурированные и неструктурированные данные для более целостного понимания контекста. Метод показывает значительные улучшения в производительности извлечения и сохранении целостности контекста по сравнению с традиционными подходами. SKETCH превосходит базовые методы по ключевым метрикам RAGAS на четырех различных наборах данных, демонстрируя высокую точность и контекстуальную релевантность ответов."
                },
                "en": {
                    "title": "SKETCH: Elevating RAG with Semantic and Structured Data Integration",
                    "desc": "This paper presents SKETCH, a new method that improves Retrieval-Augmented Generation (RAG) systems by combining semantic text retrieval with knowledge graphs. This integration allows for better processing of large datasets while ensuring a deeper understanding of context. SKETCH shows significant enhancements in retrieval performance and context integrity compared to traditional RAG methods. The results from various datasets demonstrate that SKETCH achieves high scores in answer relevancy and context precision, establishing new standards for retrieval systems."
                },
                "zh": {
                    "title": "SKETCH：提升检索增强生成系统的新方法",
                    "desc": "本论文介绍了一种名为SKETCH的新方法，旨在提升检索增强生成（RAG）系统的性能。SKETCH通过将语义文本检索与知识图谱相结合，能够更有效地处理和检索大数据集中的信息，同时保持对上下文的全面理解。研究表明，SKETCH在多个数据集上表现优异，尤其是在意大利美食数据集上，达到了0.94的答案相关性和0.99的上下文精度。这些结果表明，SKETCH能够提供更准确和上下文相关的响应，为未来的检索系统设定了新的基准。"
                }
            }
        }
    ],
    "link_prev": "2024-12-24.html",
    "link_next": "2024-12-26.html",
    "link_month": "2024-12.html",
    "short_date_prev": {
        "ru": "24.12",
        "en": "12/24",
        "zh": "12月24日"
    },
    "short_date_next": {
        "ru": "26.12",
        "en": "12/26",
        "zh": "12月26日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 1,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了在缺乏大量人工标注数据的情况下，模型通过自我改进来提高性能的方法。文章指出，自我改进的关键因素和机制尚不清楚。研究者识别并提出了监控两个重要因素的方法：模型生成多样化响应的能力（探索）和外部奖励区分高质量候选的有效性（利用）。通过数学推理的案例研究，发现模型的探索能力和利用外部奖励的有效性在迭代中迅速下降。因此，研究者提出了B-STaR框架，自动调整配置以平衡探索和利用，优化自我改进的效果。实验表明，B-STaR在数学推理、编程和常识推理任务中表现优异。",
        "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners",
        "pinyin": "这篇文章讨论了在缺乏大量人工标注数据的情况下，模型通过自我改进来提高性能的方法。\nZhè piān wénzhāng tǎolùn le zài quēfá dàliàng réngōng biāozhù shùjù de qíngkuàng xià, móxíng tōngguò zìwǒ gǎijìn lái tígāo xìngnéng de fāngfǎ.\n\n文章指出，自我改进的关键因素和机制尚不清楚。\nWénzhāng zhǐchū, zìwǒ gǎijìn de guǎnjiàn yīnsù hé jīzhì shàng bù qīngchǔ.\n\n研究者识别并提出了监控两个重要因素的方法：模型生成多样化响应的能力（探索）和外部奖励区分高质量候选的有效性（利用）。\nYánjiùzhě shíbié bìng tíchū le jiànkòng liǎng gè zhòngyào yīnsù de fāngfǎ: móxíng shēngchēng duōyànghuà xiǎngyìng de nénglì (tànsuǒ) hé wàibù jiǎnglì qūfēn gāo zhìliàng hòuxuǎn de yǒuxiàoxìng (lìyòng).\n\n通过数学推理的案例研究，发现模型的探索能力和利用外部奖励的有效性在迭代中迅速下降。\nTōngguò shùxué tuīlǐ de ànlì yánjiū, fāxiàn móxíng de tànsuǒ nénglì hé lìyòng wàibù jiǎnglì de yǒuxiàoxìng zài diédǎi zhōng xùnsù xiàjiàng.\n\n因此，研究者提出了B-STaR框架，自动调整配置以平衡探索和利用，优化自我改进的效果。\nYīncǐ, yánjiùzhě tíchū le B-STaR kuàngjià, zìdòng tiáozhěng pèizhì yǐ pínghéng tànsuǒ hé lìyòng, yōuhuà zìwǒ gǎijìn de xiàoguǒ.\n\n实验表明，B-STaR在数学推理、编程和常识推理任务中表现优异。\nShíyàn biǎomíng, B-STaR zài shùxué tuīlǐ, biānchéng hé chángshí tuīlǐ rènwù zhōng biǎoxiàn yōuyì.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"缺乏\", \"pinyin\": \"quē fá\", \"trans\": \"lack\"},\n    {\"word\": \"人工标注\", \"pinyin\": \"rén gōng biāo zhù\", \"trans\": \"manual annotation\"},\n    {\"word\": \"数据\", \"pinyin\": \"shù jù\", \"trans\": \"data\"},\n    {\"word\": \"情况\", \"pinyin\": \"qíng kuàng\", \"trans\": \"situation\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"自我改进\", \"pinyin\": \"zì wǒ gǎi jìn\", \"trans\": \"self-improvement\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"指出\", \"pinyin\": \"zhǐ chū\", \"trans\": \"point out\"},\n    {\"word\": \"关键因素\", \"pinyin\": \"guān jiàn yīn sù\", \"trans\": \"key factors\"},\n    {\"word\": \"机制\", \"pinyin\": \"jī zhì\", \"trans\": \"mechanism\"},\n    {\"word\": \"尚不清楚\", \"pinyin\": \"shàng bù qīng chǔ\", \"trans\": \"not clear\"},\n    {\"word\": \"识别\", \"pinyin\": \"shí bié\", \"trans\": \"identify\"},\n    {\"word\": \"提出\", \"pinyin\": \"tí chū\", \"trans\": \"propose\"},\n    {\"word\": \"监控\", \"pinyin\": \"jiàn kòng\", \"trans\": \"monitor\"},\n    {\"word\": \"多样化\", \"pinyin\": \"duō yàng huà\", \"trans\": \"diversify\"},\n    {\"word\": \"响应\", \"pinyin\": \"xiǎng yìng\", \"trans\": \"response\"},\n    {\"word\": \"能力\", \"pinyin\": \"néng lì\", \"trans\": \"ability\"},\n    {\"word\": \"探索\", \"pinyin\": \"tàn suǒ\", \"trans\": \"explore\"},\n    {\"word\": \"外部奖励\", \"pinyin\": \"wài bù jiǎng lì\", \"trans\": \"external reward\"},\n    {\"word\": \"区分\", \"pinyin\": \"qū fēn\", \"trans\": \"distinguish\"},\n    {\"word\": \"高质量\", \"pinyin\": \"gāo zhì liàng\", \"trans\": \"high quality\"},\n    {\"word\": \"候选\", \"pinyin\": \"hòu xuǎn\", \"trans\": \"candidate\"},\n    {\"word\": \"有效性\", \"pinyin\": \"yǒu xiào xìng\", \"trans\": \"effectiveness\"},\n    {\"word\": \"利用\", \"pinyin\": \"lì yòng\", \"trans\": \"utilize\"},\n    {\"word\": \"数学推理\", \"pinyin\": \"shù xué tuī lǐ\", \"trans\": \"mathematical reasoning\"},\n    {\"word\": \"案例研究\", \"pinyin\": \"àn lì yán jiū\", \"trans\": \"case study\"},\n    {\"word\": \"发现\", \"pinyin\": \"fā xiàn\", \"trans\": \"discover\"},\n    {\"word\": \"迭代\", \"pinyin\": \"dié dài\", \"trans\": \"iteration\"},\n    {\"word\": \"迅速\", \"pinyin\": \"xùn sù\", \"trans\": \"rapidly\"},\n    {\"word\": \"下降\", \"pinyin\": \"xià jiàng\", \"trans\": \"decline\"},\n    {\"word\": \"因此\", \"pinyin\": \"yīn cǐ\", \"trans\": \"therefore\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàng jià\", \"trans\": \"framework\"},\n    {\"word\": \"自动调整\", \"pinyin\": \"zì dòng tiáo zhěng\", \"trans\": \"automatic adjustment\"},\n    {\"word\": \"配置\", \"pinyin\": \"pèi zhì\", \"trans\": \"configuration\"},\n    {\"word\": \"平衡\", \"pinyin\": \"píng héng\", \"trans\": \"balance\"},\n    {\"word\": \"优化\", \"pinyin\": \"yōu huà\", \"trans\": \"optimize\"},\n    {\"word\": \"效果\", \"pinyin\": \"xiào guǒ\", \"trans\": \"effect\"},\n    {\"word\": \"实验\", \"pinyin\": \"shí yàn\", \"trans\": \"experiment\"},\n    {\"word\": \"表明\", \"pinyin\": \"biǎo míng\", \"trans\": \"indicate\"},\n    {\"word\": \"编程\", \"pinyin\": \"biān chéng\", \"trans\": \"programming\"},\n    {\"word\": \"常识推理\", \"pinyin\": \"cháng shí tuī lǐ\", \"trans\": \"commonsense reasoning\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wù\", \"trans\": \"task\"},\n    {\"word\": \"表现\", \"pinyin\": \"biǎo xiàn\", \"trans\": \"performance\"},\n    {\"word\": \"优异\", \"pinyin\": \"yōu yì\", \"trans\": \"excellent\"}\n]",
        "trans": "This article discusses methods for improving model performance through self-improvement in the absence of large amounts of manually labeled data. The article notes that the key factors and mechanisms of self-improvement are not yet clear. Researchers have identified and proposed methods to monitor two important factors: the model's ability to generate diverse responses (exploration) and the effectiveness of external rewards in distinguishing high-quality candidates (exploitation). Through a case study on mathematical reasoning, it was found that the model's exploration ability and the effectiveness of utilizing external rewards rapidly decline during iterations. Therefore, the researchers proposed the B-STaR framework, which automatically adjusts configurations to balance exploration and exploitation, optimizing the effects of self-improvement. Experiments show that B-STaR performs excellently in mathematical reasoning, programming, and common sense reasoning tasks.",
        "update_ts": "2024-12-24 09:10"
    }
}