{
    "date": {
        "ru": "10 января",
        "en": "January 10",
        "zh": "1月10日"
    },
    "time_utc": "2025-01-10 04:12",
    "weekday": 4,
    "issue_id": 1596,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.05441",
            "title": "The GAN is dead; long live the GAN! A Modern GAN Baseline",
            "url": "https://huggingface.co/papers/2501.05441",
            "abstract": "There is a widely-spread claim that GANs are difficult to train, and GAN architectures in the literature are littered with empirical tricks. We provide evidence against this claim and build a modern GAN baseline in a more principled manner. First, we derive a well-behaved regularized relativistic GAN loss that addresses issues of mode dropping and non-convergence that were previously tackled via a bag of ad-hoc tricks. We analyze our loss mathematically and prove that it admits local convergence guarantees, unlike most existing relativistic losses. Second, our new loss allows us to discard all ad-hoc tricks and replace outdated backbones used in common GANs with modern architectures. Using StyleGAN2 as an example, we present a roadmap of simplification and modernization that results in a new minimalist baseline -- R3GAN. Despite being simple, our approach surpasses StyleGAN2 on FFHQ, ImageNet, CIFAR, and Stacked MNIST datasets, and compares favorably against state-of-the-art GANs and diffusion models.",
            "score": 4,
            "issue_id": 1596,
            "pub_date": "2025-01-09",
            "pub_date_card": {
                "ru": "9 января",
                "en": "January 9",
                "zh": "1月9日"
            },
            "hash": "eb1cd90c4d5cb0ef",
            "authors": [
                "Yiwen Huang",
                "Aaron Gokaslan",
                "Volodymyr Kuleshov",
                "James Tompkin"
            ],
            "affiliations": [
                "Brown University",
                "Cornell University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.05441.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#diffusion",
                    "#optimization",
                    "#cv"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "Упрощение и модернизация GAN: новый взгляд на обучение генеративных моделей",
                    "desc": "Исследователи опровергают распространенное мнение о сложности обучения генеративно-состязательных сетей (GAN). Они разработали новый регуляризованный релятивистский GAN-лосс, который решает проблемы потери мод и отсутствия сходимости. Авторы математически доказывают, что их лосс обеспечивает локальную сходимость, в отличие от большинства существующих релятивистских лоссов. На основе этого подхода они создали минималистичную базовую модель R3GAN, которая превосходит StyleGAN2 и другие современные GAN на нескольких наборах данных."
                },
                "en": {
                    "title": "Simplifying GAN Training with R3GAN: A New Era of Efficiency",
                    "desc": "This paper challenges the common belief that Generative Adversarial Networks (GANs) are inherently difficult to train. It introduces a new GAN loss function called the regularized relativistic GAN loss, which effectively addresses issues like mode dropping and non-convergence without relying on numerous empirical tricks. The authors provide mathematical analysis showing that their loss function guarantees local convergence, which is a significant improvement over existing methods. By applying this new loss to modern architectures like StyleGAN2, they create a simplified and efficient GAN model named R3GAN, which outperforms previous models on several benchmark datasets."
                },
                "zh": {
                    "title": "简化GAN训练，超越传统架构",
                    "desc": "这篇论文探讨了生成对抗网络（GAN）训练的难点，并提出了一种新的方法来简化这一过程。作者提出了一种正则化的相对GAN损失函数，解决了模式丢失和非收敛的问题。通过数学分析，证明了这种损失函数具有局部收敛的保证，优于现有的相对损失函数。最终，作者展示了一个新的简约基线R3GAN，其在多个数据集上的表现超过了StyleGAN2，并与最先进的GAN和扩散模型相媲美。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.05453",
            "title": "An Empirical Study of Autoregressive Pre-training from Videos",
            "url": "https://huggingface.co/papers/2501.05453",
            "abstract": "We empirically study autoregressive pre-training from videos. To perform our study, we construct a series of autoregressive video models, called Toto. We treat videos as sequences of visual tokens and train transformer models to autoregressively predict future tokens. Our models are pre-trained on a diverse dataset of videos and images comprising over 1 trillion visual tokens. We explore different architectural, training, and inference design choices. We evaluate the learned visual representations on a range of downstream tasks including image recognition, video classification, object tracking, and robotics. Our results demonstrate that, despite minimal inductive biases, autoregressive pre-training leads to competitive performance across all benchmarks. Finally, we find that scaling our video models results in similar scaling curves to those seen in language models, albeit with a different rate. More details at https://brjathu.github.io/toto/",
            "score": 3,
            "issue_id": 1596,
            "pub_date": "2025-01-09",
            "pub_date_card": {
                "ru": "9 января",
                "en": "January 9",
                "zh": "1月9日"
            },
            "hash": "3846ea8507d046be",
            "authors": [
                "Jathushan Rajasegaran",
                "Ilija Radosavovic",
                "Rahul Ravishankar",
                "Yossi Gandelsman",
                "Christoph Feichtenhofer",
                "Jitendra Malik"
            ],
            "affiliations": [
                "Meta FAIR",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.05453.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#architecture",
                    "#robotics",
                    "#video",
                    "#cv"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "Авторегрессионное предобучение видео: путь к универсальному компьютерному зрению",
                    "desc": "В статье исследуется авторегрессионное предобучение на видеоданных с использованием модели Toto. Авторы рассматривают видео как последовательности визуальных токенов и обучают трансформеры предсказывать будущие токены. Модели предобучаются на разнообразном наборе данных из более чем триллиона визуальных токенов. Результаты показывают, что такой подход дает конкурентоспособную производительность на различных задачах компьютерного зрения."
                },
                "en": {
                    "title": "Unlocking Video Understanding with Autoregressive Models",
                    "desc": "This paper investigates the use of autoregressive pre-training for video data through a series of models named Toto. The authors treat videos as sequences of visual tokens and employ transformer architectures to predict future tokens in these sequences. They pre-train their models on a massive dataset containing over 1 trillion visual tokens, exploring various design choices in architecture and training. The results show that these autoregressive models achieve strong performance on tasks like image recognition and video classification, indicating that scaling video models can yield similar benefits as seen in language models."
                },
                "zh": {
                    "title": "自回归预训练：视频模型的新突破",
                    "desc": "本文研究了视频的自回归预训练。我们构建了一系列名为Toto的自回归视频模型，将视频视为视觉标记的序列，并训练变换器模型以自回归方式预测未来的标记。我们的模型在一个包含超过1万亿视觉标记的多样化视频和图像数据集上进行预训练，并在多个下游任务上评估学习到的视觉表示。结果表明，尽管诱导偏差较小，自回归预训练在所有基准测试中表现出竞争力的性能。"
                }
            }
        }
    ],
    "link_prev": "2025-01-09.html",
    "link_next": "2025-01-13.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "09.01",
        "en": "01/09",
        "zh": "1月9日"
    },
    "short_date_next": {
        "ru": "13.01",
        "en": "01/13",
        "zh": "1月13日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 2,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 1,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了 rStar-Math，展示了小型语言模型（SLMs）可以通过蒙特卡罗树搜索（MCTS）进行“深度思考”，从而媲美或超越 OpenAI o1 的数学推理能力。rStar-Math 通过三项创新训练两个 SLMs：代码增强的思维链数据合成方法、更有效的过程偏好模型（PPM）训练方法和自我进化配方。经过四轮自我进化，rStar-Math 将 SLMs 的数学推理能力提升到最先进的水平。",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
        "pinyin": "这篇文章介绍了 rStar-Math，展示了小型语言模型（SLMs）可以通过蒙特卡罗树搜索（MCTS）进行“深度思考”，从而媲美或超越 OpenAI o1 的数学推理能力。rStar-Math 通过三项创新训练两个 SLMs：代码增强的思维链数据合成方法、更有效的过程偏好模型（PPM）训练方法和自我进化配方。经过四轮自我进化，rStar-Math 将 SLMs 的数学推理能力提升到最先进的水平。\n\nZhè piān wénzhāng jièshào le rStar-Math, zhǎnshì le xiǎoxíng yǔyán móxíng (SLMs) kěyǐ tōngguò méngtèkǎluó shù sōusuǒ (MCTS) jìnxíng “shēndù sīkǎo”, cóng'ér qíbǐ huò chāoyuè OpenAI o1 de shùxué tuīlǐ nénglì. rStar-Math tōngguò sān xiàng chuàngxīn xùnliàn liǎng gè SLMs: dàimǎ zēngqiáng de sīwéi liàn shùjù héchéng fāngfǎ, gèng yǒuxiào de guòchéng qiānhuò móxíng (PPM) xùnliàn fāngfǎ hé zìwǒ jìnhuà pèifáng. Jīngguò sì lún zìwǒ jìnhuà, rStar-Math jiāng SLMs de shùxué tuīlǐ nénglì tíshēng dào zuì xiānjìn de shuǐpíng.",
        "vocab": "[\n    {\"word\": \"展示\", \"pinyin\": \"zhǎnshì\", \"trans\": \"display, show\"},\n    {\"word\": \"小型\", \"pinyin\": \"xiǎoxíng\", \"trans\": \"small, mini\"},\n    {\"word\": \"语言模型\", \"pinyin\": \"yǔyán móxíng\", \"trans\": \"language model\"},\n    {\"word\": \"蒙特卡罗树搜索\", \"pinyin\": \"Méngtèkǎluó shù sōusuǒ\", \"trans\": \"Monte Carlo Tree Search\"},\n    {\"word\": \"深度思考\", \"pinyin\": \"shēndù sīkǎo\", \"trans\": \"deep thinking\"},\n    {\"word\": \"媲美\", \"pinyin\": \"pìměi\", \"trans\": \"rival, match\"},\n    {\"word\": \"超越\", \"pinyin\": \"chāoyuè\", \"trans\": \"surpass, exceed\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuīlǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"能力\", \"pinyin\": \"nénglì\", \"trans\": \"ability, capability\"},\n    {\"word\": \"创新\", \"pinyin\": \"chuàngxīn\", \"trans\": \"innovation\"},\n    {\"word\": \"训练\", \"pinyin\": \"xùnliàn\", \"trans\": \"train, training\"},\n    {\"word\": \"代码\", \"pinyin\": \"dàimǎ\", \"trans\": \"code\"},\n    {\"word\": \"增强\", \"pinyin\": \"zēngqiáng\", \"trans\": \"enhance, strengthen\"},\n    {\"word\": \"思维链\", \"pinyin\": \"sīwéi lián\", \"trans\": \"chain of thought\"},\n    {\"word\": \"数据合成\", \"pinyin\": \"shùjù héchéng\", \"trans\": \"data synthesis\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāngfǎ\", \"trans\": \"method\"},\n    {\"word\": \"过程\", \"pinyin\": \"guòchéng\", \"trans\": \"process\"},\n    {\"word\": \"偏好\", \"pinyin\": \"piānhào\", \"trans\": \"preference\"},\n    {\"word\": \"模型\", \"pinyin\": \"móxíng\", \"trans\": \"model\"},\n    {\"word\": \"自我进化\", \"pinyin\": \"zìwǒ jìnhuà\", \"trans\": \"self-evolution\"},\n    {\"word\": \"配方\", \"pinyin\": \"pèifāng\", \"trans\": \"formula, recipe\"},\n    {\"word\": \"四轮\", \"pinyin\": \"sì lún\", \"trans\": \"four rounds\"},\n    {\"word\": \"最先进\", \"pinyin\": \"zuì xiānjìn\", \"trans\": \"most advanced\"}\n]",
        "trans": "This article introduces rStar-Math, demonstrating that Small Language Models (SLMs) can engage in \"deep thinking\" through Monte Carlo Tree Search (MCTS), thereby matching or surpassing the mathematical reasoning capabilities of OpenAI o1. rStar-Math achieves this through three innovative approaches to train two SLMs: a code-enhanced chain-of-thought data synthesis method, a more effective Process Preference Model (PPM) training method, and a self-evolutionary recipe. After four rounds of self-evolution, rStar-Math elevates the mathematical reasoning abilities of SLMs to the most advanced level.",
        "update_ts": "2025-01-09 09:11"
    }
}