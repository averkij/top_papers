{
    "date": {
        "ru": "17 февраля",
        "en": "February 17",
        "zh": "2月17日"
    },
    "time_utc": "2025-02-17 03:17",
    "weekday": 0,
    "issue_id": 2240,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.10177",
            "title": "STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning",
            "url": "https://huggingface.co/papers/2502.10177",
            "abstract": "A key objective of embodied intelligence is enabling agents to perform long-horizon tasks in dynamic environments while maintaining robust decision-making and adaptability. To achieve this goal, we propose the Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task planning and execution by integrating spatio-temporal memory. STMA is built upon three critical components: (1) a spatio-temporal memory module that captures historical and environmental changes in real time, (2) a dynamic knowledge graph that facilitates adaptive spatial reasoning, and (3) a planner-critic mechanism that iteratively refines task strategies. We evaluate STMA in the TextWorld environment on 32 tasks, involving multi-step planning and exploration under varying levels of complexity. Experimental results demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7% increase in average score compared to the state-of-the-art model. The results highlight the effectiveness of spatio-temporal memory in advancing the memory capabilities of embodied agents.",
            "score": 0,
            "issue_id": 2240,
            "pub_date": "2025-02-14",
            "pub_date_card": {
                "ru": "14 февраля",
                "en": "February 14",
                "zh": "2月14日"
            },
            "hash": "1b17b668b26c2264",
            "authors": [
                "Mingcong Lei",
                "Yiming Zhao",
                "Ge Wang",
                "Zhixin Mai",
                "Shuguang Cui",
                "Yatong Han",
                "Jinke Ren"
            ],
            "affiliations": [
                "FNii-Shenzhen, The Chinese University of Hong Kong, Shenzhen, China",
                "Harbin Engineering University, China",
                "Infused Synapse AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.10177.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#agents",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Пространственно-временная память повышает эффективность воплощенных агентов",
                    "desc": "Статья представляет новый фреймворк под названием Spatio-Temporal Memory Agent (STMA) для улучшения планирования и выполнения задач агентами с воплощенным интеллектом. STMA включает в себя модуль пространственно-временной памяти, динамический граф знаний и механизм планировщика-критика. Эксперименты в среде TextWorld показали значительное улучшение успешности и средней оценки по сравнению с современными моделями. Результаты подчеркивают эффективность пространственно-временной памяти для улучшения возможностей памяти воплощенных агентов."
                },
                "en": {
                    "title": "Enhancing Agent Intelligence with Spatio-Temporal Memory",
                    "desc": "The paper introduces the Spatio-Temporal Memory Agent (STMA), which aims to improve how agents perform complex tasks in changing environments. STMA incorporates a spatio-temporal memory module to track past events and environmental shifts, enhancing decision-making. It also utilizes a dynamic knowledge graph for better spatial reasoning and a planner-critic mechanism to refine strategies over time. The results show that STMA significantly outperforms existing models in task success rates and scoring, demonstrating the importance of memory in embodied intelligence."
                },
                "zh": {
                    "title": "时空记忆智能体：提升智能体决策与适应能力的关键",
                    "desc": "本文提出了一种新的框架，称为时空记忆智能体（STMA），旨在提高智能体在动态环境中执行长期任务的能力。STMA集成了时空记忆模块、动态知识图谱和规划-评估机制，以增强任务规划和执行的效果。通过在TextWorld环境中进行32个任务的评估，STMA在成功率和平均得分上分别提高了31.25%和24.7%。实验结果表明，时空记忆在提升智能体的记忆能力方面具有显著效果。"
                }
            }
        }
    ],
    "link_prev": "2025-02-14.html",
    "link_next": "2025-02-18.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "14.02",
        "en": "02/14",
        "zh": "2月14日"
    },
    "short_date_next": {
        "ru": "18.02",
        "en": "02/18",
        "zh": "2月18日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了大语言模型（LLMs）处理超长文本时面临的挑战，包括推理速度慢和内存成本高。为解决这些问题，作者提出了InfiniteHiP，一种新的推理框架，通过动态删除无关的上下文标记来加速处理。该方法还通过选择性应用RoPE调整方法来泛化到更长的序列，并将键值缓存卸载到主机内存中，减少GPU内存压力。结果显示，InfiniteHiP可以在单个L40s 48GB GPU上处理多达300万个标记，速度提高了18.95倍。",
        "title": "InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU",
        "pinyin": "这篇文章讨论了大语言模型（LLMs）处理超长文本时面临的挑战，包括推理速度慢和内存成本高。为解决这些问题，作者提出了InfiniteHiP，一种新的推理框架，通过动态删除无关的上下文标记来加速处理。该方法还通过选择性应用RoPE调整方法来泛化到更长的序列，并将键值缓存卸载到主机内存中，减少GPU内存压力。结果显示，InfiniteHiP可以在单个L40s 48GB GPU上处理多达300万个标记，速度提高了18.95倍。\n\nzhè piān wén zhāng tǎo lùn le dà yǔ yán mó xíng (LLMs) chǔ lǐ chāo cháng wén běn shí miàn lín de tiǎo zhàn, bāo kuò tuī lǐ sù dù màn hé nèi cún chéng běn gāo. wèi jiě jué zhè xiē wèn tí, zuò zhě tí chū le InfiniteHiP, yī zhǒng xīn de tuī lǐ kuàng jià, tōng guò dòng tài shān chú wú guān de shàng xià wén biāo jì lái jiā sù chǔ lǐ. gǎi fǎng fǎ hái tōng guò xuǎn zé xìng yìng yòng RoPE tiáo zhěng fǎng fǎ lái fàn huà dào gèng cháng de xù liè, bìng jiāng jiàn zhí huàn cún xiè zài zhǔ jī nèi cún zhōng, jiǎn shǎo GPU nèi cún yā lì. jié guǒ xiǎn shì, InfiniteHiP kě yǐ zài dān gè L40s 48GB GPU shàng chǔ lǐ duō dà 300 wàn gè biāo jì, sù dù tí gāo le 18.95 bèi.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'},\n{'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'},\n{'word': '处理', 'pinyin': 'chǔ lǐ', 'trans': 'process'},\n{'word': '超长', 'pinyin': 'chāo cháng', 'trans': 'ultra-long'},\n{'word': '文本', 'pinyin': 'wén běn', 'trans': 'text'},\n{'word': '面临', 'pinyin': 'miàn lín', 'trans': 'face'},\n{'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'},\n{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'},\n{'word': '速度', 'pinyin': 'sù dù', 'trans': 'speed'},\n{'word': '内存', 'pinyin': 'nèi cún', 'trans': 'memory'},\n{'word': '成本', 'pinyin': 'chéng běn', 'trans': 'cost'},\n{'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'},\n{'word': '框架', 'pinyin': 'kuàng jià', 'trans': 'framework'},\n{'word': '动态', 'pinyin': 'dòng tài', 'trans': 'dynamic'},\n{'word': '删除', 'pinyin': 'shān chú', 'trans': 'delete'},\n{'word': '无关', 'pinyin': 'wú guān', 'trans': 'irrelevant'},\n{'word': '上下文', 'pinyin': 'shàng xià wén', 'trans': 'context'},\n{'word': '标记', 'pinyin': 'biāo jì', 'trans': 'token'},\n{'word': '加速', 'pinyin': 'jiā sù', 'trans': 'accelerate'},\n{'word': '选择性', 'pinyin': 'xuǎn zé xìng', 'trans': 'selective'},\n{'word': '应用', 'pinyin': 'yìng yòng', 'trans': 'apply'},\n{'word': 'RoPE', 'pinyin': 'RoPE', 'trans': 'RoPE'},\n{'word': '调整', 'pinyin': 'tiáo zhěng', 'trans': 'adjust'},\n{'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'},\n{'word': '泛化', 'pinyin': 'fàn huà', 'trans': 'generalize'},\n{'word': '序列', 'pinyin': 'xù liè', 'trans': 'sequence'},\n{'word': '键值', 'pinyin': 'jiàn zhí', 'trans': 'key-value'},\n{'word': '缓存', 'pinyin': 'huǎn cún', 'trans': 'cache'},\n{'word': '卸载', 'pinyin': 'xiè zài', 'trans': 'unload'},\n{'word': '主机', 'pinyin': 'zhǔ jī', 'trans': 'host'},\n{'word': '压力', 'pinyin': 'yā lì', 'trans': 'pressure'},\n{'word': '结果', 'pinyin': 'jié guǒ', 'trans': 'result'},\n{'word': '显示', 'pinyin': 'xiǎn shì', 'trans': 'show'},\n{'word': '单个', 'pinyin': 'dān gè', 'trans': 'single'},\n{'word': 'L40s', 'pinyin': 'L40s', 'trans': 'L40s'},\n{'word': '48GB', 'pinyin': '48GB', 'trans': '48GB'},\n{'word': 'GPU', 'pinyin': 'GPU', 'trans': 'GPU'},\n{'word': '多达', 'pinyin': 'duō dá', 'trans': 'up to'},\n{'word': '提高', 'pinyin': 'tí gāo', 'trans': 'improve'},\n{'word': '倍', 'pinyin': 'bèi', 'trans': 'times'}]",
        "trans": "This article discusses the challenges faced by large language models (LLMs) when processing extremely long texts, including slow inference speed and high memory costs. To address these issues, the authors propose InfiniteHiP, a new inference framework that accelerates processing by dynamically removing irrelevant context tokens. This method also generalizes to longer sequences by selectively applying the RoPE adjustment method and offloads key-value caching to host memory, reducing GPU memory pressure. The results show that InfiniteHiP can handle up to 30 million tokens on a single L40s 48GB GPU, with a speed increase of 18.95 times.",
        "update_ts": "2025-02-16 12:40"
    }
}