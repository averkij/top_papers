{
    "date": {
        "ru": "3 июня",
        "en": "June 3",
        "zh": "6月3日"
    },
    "time_utc": "2025-06-03 02:41",
    "weekday": 1,
    "issue_id": 4087,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.23001",
            "title": "DyePack: Provably Flagging Test Set Contamination in LLMs Using\n  Backdoors",
            "url": "https://huggingface.co/papers/2505.23001",
            "abstract": "DyePack, a framework using backdoor attacks, identifies models that leveraged benchmark test sets during training by introducing benign backdoor samples, ensuring precise false positive rates while preventing false accusations.  \t\t\t\t\tAI-generated summary \t\t\t\t Open benchmarks are essential for evaluating and advancing large language models, offering reproducibility and transparency. However, their accessibility makes them likely targets of test set contamination. In this work, we introduce DyePack, a framework that leverages backdoor attacks to identify models that used benchmark test sets during training, without requiring access to the loss, logits, or any internal details of the model. Like how banks mix dye packs with their money to mark robbers, DyePack mixes backdoor samples with the test data to flag models that trained on it. We propose a principled design incorporating multiple backdoors with stochastic targets, enabling exact false positive rate (FPR) computation when flagging every model. This provably prevents false accusations while providing strong evidence for every detected case of contamination. We evaluate DyePack on five models across three datasets, covering both multiple-choice and open-ended generation tasks. For multiple-choice questions, it successfully detects all contaminated models with guaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard using eight backdoors. For open-ended generation tasks, it generalizes well and identifies all contaminated models on Alpaca with a guaranteed false positive rate of just 0.127% using six backdoors.",
            "score": 8,
            "issue_id": 4087,
            "pub_date": "2025-05-29",
            "pub_date_card": {
                "ru": "29 мая",
                "en": "May 29",
                "zh": "5月29日"
            },
            "hash": "cd584a75fce48ae2",
            "authors": [
                "Yize Cheng",
                "Wenxiao Wang",
                "Mazda Moayeri",
                "Soheil Feizi"
            ],
            "affiliations": [
                "University of Maryland"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23001.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#security",
                    "#leakage"
                ],
                "emoji": "🕵️",
                "ru": {
                    "title": "DyePack: Ловушка для нечестных моделей машинного обучения",
                    "desc": "DyePack - это фреймворк, использующий атаки типа backdoor для выявления моделей, которые использовали тестовые наборы данных во время обучения. Он вводит безвредные образцы backdoor в тестовые данные, чтобы пометить модели, обучавшиеся на них. DyePack обеспечивает точный расчет уровня ложноположительных результатов и предотвращает ложные обвинения. Фреймворк был успешно протестирован на пяти моделях и трех наборах данных, охватывающих задачи с множественным выбором и открытой генерацией."
                },
                "en": {
                    "title": "DyePack: Safeguarding Model Integrity with Backdoor Detection",
                    "desc": "DyePack is a novel framework designed to detect models that have been trained using benchmark test sets by employing backdoor attacks. It introduces benign backdoor samples into the test data, allowing for the identification of contaminated models without needing access to their internal workings. The framework ensures precise computation of false positive rates, effectively preventing wrongful accusations against models. Through extensive evaluation, DyePack demonstrates its capability to accurately flag contaminated models across various tasks while maintaining low false positive rates."
                },
                "zh": {
                    "title": "DyePack：精准识别训练中使用基准测试集的模型",
                    "desc": "DyePack是一个利用后门攻击的框架，用于识别在训练中使用基准测试集的模型。它通过引入良性后门样本，确保准确的假阳性率，同时防止错误指控。DyePack的设计结合了多个具有随机目标的后门，使得在标记每个模型时能够精确计算假阳性率。通过在多个模型和数据集上的评估，DyePack成功检测到所有受污染的模型，且假阳性率极低。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.01049",
            "title": "Taming LLMs by Scaling Learning Rates with Gradient Grouping",
            "url": "https://huggingface.co/papers/2506.01049",
            "abstract": "SGG, an optimizer wrapper, enhances adaptive learning rates for large language models by grouping gradients and applying cluster-specific scaling, improving convergence and stability.  \t\t\t\t\tAI-generated summary \t\t\t\t Training large language models (LLMs) poses challenges due to their massive scale and heterogeneous architectures. While adaptive optimizers like AdamW help address gradient variations, they still struggle with efficient and effective parameter-wise learning rate estimation, resulting in training instability, slow convergence, and poor compatibility with parameter-efficient fine-tuning (PEFT) techniques. This work introduces Scaling with Gradient Grouping (SGG), an optimizer wrapper that improves adaptive learning rate estimation by dynamic grouping and group-specific scaling. SGG first groups gradient statistics in each layer into clusters and then applies cluster-specific scaling to calibrate learning rates for each parameter, thus imposing collective group-wise constraints while maintaining precise per-parameter adaptation. Experiments on diverse (M)LLM benchmarks show that SGG integrates seamlessly with existing optimizers, and offers consistent gains and faster convergence over baselines, with various model sizes. Its stability across varying batch sizes and learning rates establishes SGG as a robust choice for LLM optimization.",
            "score": 7,
            "issue_id": 4087,
            "pub_date": "2025-06-01",
            "pub_date_card": {
                "ru": "1 июня",
                "en": "June 1",
                "zh": "6月1日"
            },
            "hash": "350401d748400bad",
            "authors": [
                "Siyuan Li",
                "Juanxi Tian",
                "Zedong Wang",
                "Xin Jin",
                "Zicheng Liu",
                "Wentao Zhang",
                "Dan Xu"
            ],
            "affiliations": [
                "Peking University",
                "The Hong Kong University of Science and Technology",
                "Westlake University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.01049.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "SGG: Групповое масштабирование градиентов для эффективного обучения языковых моделей",
                    "desc": "Статья представляет новый метод оптимизации для обучения больших языковых моделей под названием SGG (Scaling with Gradient Grouping). SGG группирует градиенты и применяет масштабирование для каждой группы, что улучшает адаптивную оценку скорости обучения. Этот подход повышает стабильность и скорость сходимости при обучении крупных языковых моделей. Эксперименты показывают, что SGG хорошо интегрируется с существующими оптимизаторами и дает стабильные улучшения на различных бенчмарках."
                },
                "en": {
                    "title": "SGG: Optimizing Learning Rates for Better LLM Training",
                    "desc": "This paper presents Scaling with Gradient Grouping (SGG), an innovative optimizer wrapper designed to enhance adaptive learning rates for large language models (LLMs). SGG addresses the challenges of training LLMs by dynamically grouping gradient statistics and applying specific scaling for each group, which improves convergence and stability. By imposing collective constraints on groups while allowing precise adjustments for individual parameters, SGG optimizes the learning process more effectively than traditional methods. Experimental results demonstrate that SGG integrates well with existing optimizers, leading to faster convergence and improved performance across various model sizes and training conditions."
                },
                "zh": {
                    "title": "SGG：提升大语言模型训练的自适应学习率优化器",
                    "desc": "SGG是一种优化器包装器，通过对梯度进行分组和应用特定于集群的缩放，增强了大语言模型的自适应学习率。它解决了大规模模型训练中的不稳定性和收敛速度慢的问题。SGG通过动态分组和集群特定的缩放来改善学习率估计，从而实现更精确的参数调整。实验结果表明，SGG与现有优化器无缝集成，并在不同模型规模上提供了一致的性能提升和更快的收敛速度。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23977",
            "title": "VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL",
            "url": "https://huggingface.co/papers/2505.23977",
            "abstract": "VisualSphinx provides a large-scale synthetic dataset to improve multimodal reasoning in vision language models, enhancing performance on various logical reasoning tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Vision language models (VLMs) are expected to perform effective multimodal reasoning and make logically coherent decisions, which is critical to tasks such as diagram understanding and spatial problem solving. However, current VLM reasoning lacks large-scale and well-structured training datasets. To bridge this gap, we propose VisualSphinx, a first-of-its-kind large-scale synthetic visual logical reasoning training data. To tackle the challenge of image synthesis with grounding answers, we propose a rule-to-image synthesis pipeline, which extracts and expands puzzle rules from seed questions and generates the code of grounding synthesis image synthesis for puzzle sample assembly. Experiments demonstrate that VLM trained using GRPO on VisualSphinx benefit from logical coherence and readability of our dataset and exhibit improved performance on logical reasoning tasks. The enhanced reasoning capabilities developed from VisualSphinx also benefit other reasoning tasks such as algebraic reasoning, arithmetic reasoning and geometry reasoning.",
            "score": 3,
            "issue_id": 4087,
            "pub_date": "2025-05-29",
            "pub_date_card": {
                "ru": "29 мая",
                "en": "May 29",
                "zh": "5月29日"
            },
            "hash": "fef2cab0e56bc9bd",
            "authors": [
                "Yichen Feng",
                "Zhangchen Xu",
                "Fengqing Jiang",
                "Yuetai Li",
                "Bhaskar Ramasubramanian",
                "Luyao Niu",
                "Bill Yuchen Lin",
                "Radha Poovendran"
            ],
            "affiliations": [
                "University of Washington",
                "Western Washington University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23977.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#cv",
                    "#multimodal",
                    "#reasoning",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Синтетические данные для улучшения логического мышления ИИ",
                    "desc": "VisualSphinx - это крупномасштабный синтетический набор данных для улучшения мультимодального рассуждения в визуально-языковых моделях. Он создан с помощью специального конвейера синтеза изображений на основе правил. Эксперименты показывают, что обучение на VisualSphinx улучшает способности моделей к логическому рассуждению. Усовершенствованные навыки рассуждения, полученные на VisualSphinx, также полезны для других задач, таких как алгебраические, арифметические и геометрические рассуждения."
                },
                "en": {
                    "title": "Enhancing Multimodal Reasoning with VisualSphinx",
                    "desc": "VisualSphinx is a synthetic dataset designed to enhance multimodal reasoning in vision language models (VLMs). It addresses the lack of large-scale, structured training data necessary for effective logical reasoning in tasks like diagram understanding. The dataset is created using a rule-to-image synthesis pipeline that generates images based on logical rules extracted from questions. Experiments show that VLMs trained on VisualSphinx demonstrate improved logical coherence and performance across various reasoning tasks, including algebra and geometry."
                },
                "zh": {
                    "title": "VisualSphinx：提升视觉语言模型的逻辑推理能力",
                    "desc": "VisualSphinx是一个大规模的合成数据集，旨在提升视觉语言模型在多模态推理方面的表现。该数据集专注于逻辑推理任务，解决了当前模型缺乏结构化训练数据的问题。通过规则到图像的合成流程，VisualSphinx能够生成与问题相关的图像，增强模型的逻辑一致性和可读性。实验表明，使用VisualSphinx训练的视觉语言模型在逻辑推理、代数推理、算术推理和几何推理等任务上表现更佳。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23504",
            "title": "VAU-R1: Advancing Video Anomaly Understanding via Reinforcement\n  Fine-Tuning",
            "url": "https://huggingface.co/papers/2505.23504",
            "abstract": "VAU-R1 uses Multimodal Large Language Models with Reinforcement Fine-Tuning to enhance video anomaly reasoning, complemented by VAU-Bench, a Chain-of-Thought benchmark for evaluating anomaly understanding.  \t\t\t\t\tAI-generated summary \t\t\t\t Video Anomaly Understanding (VAU) is essential for applications such as smart cities, security surveillance, and disaster alert systems, yet remains challenging due to its demand for fine-grained spatio-temporal perception and robust reasoning under ambiguity. Despite advances in anomaly detection, existing methods often lack interpretability and struggle to capture the causal and contextual aspects of abnormal events. This limitation is further compounded by the absence of comprehensive benchmarks for evaluating reasoning ability in anomaly scenarios. To address both challenges, we introduce VAU-R1, a data-efficient framework built upon Multimodal Large Language Models (MLLMs), which enhances anomaly reasoning through Reinforcement Fine-Tuning (RFT). Besides, we propose VAU-Bench, the first Chain-of-Thought benchmark tailored for video anomaly reasoning, featuring multiple-choice QA, detailed rationales, temporal annotations, and descriptive captions. Empirical results show that VAU-R1 significantly improves question answering accuracy, temporal grounding, and reasoning coherence across diverse contexts. Together, our method and benchmark establish a strong foundation for interpretable and reasoning-aware video anomaly understanding. Our code is available at https://github.com/GVCLab/VAU-R1.",
            "score": 3,
            "issue_id": 4087,
            "pub_date": "2025-05-29",
            "pub_date_card": {
                "ru": "29 мая",
                "en": "May 29",
                "zh": "5月29日"
            },
            "hash": "c243189c9ec32d1f",
            "authors": [
                "Liyun Zhu",
                "Qixiang Chen",
                "Xi Shen",
                "Xiaodong Cun"
            ],
            "affiliations": [
                "Australian National University",
                "GVC Lab, Great Bay University",
                "Intellindust AI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23504.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#interpretability",
                    "#multimodal",
                    "#reasoning",
                    "#video",
                    "#benchmark"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Умное видеонаблюдение: ИИ учится понимать аномалии",
                    "desc": "VAU-R1 - это новая система для понимания аномалий в видео, использующая мультимодальные большие языковые модели (MLLM) и усиленное обучение. Авторы также представили VAU-Bench - первый бенчмарк для оценки рассуждений об аномалиях в видео, основанный на методе цепочки мыслей. Система VAU-R1 значительно улучшает точность ответов на вопросы, временную привязку и согласованность рассуждений в различных контекстах. Это исследование закладывает основу для интерпретируемого и основанного на рассуждениях понимания аномалий в видео."
                },
                "en": {
                    "title": "Enhancing Video Anomaly Reasoning with VAU-R1 and VAU-Bench",
                    "desc": "The paper introduces VAU-R1, a framework that uses Multimodal Large Language Models (MLLMs) and Reinforcement Fine-Tuning (RFT) to improve the understanding of video anomalies. It addresses the challenges of fine-grained spatio-temporal perception and the need for robust reasoning in ambiguous situations. Additionally, the authors present VAU-Bench, a new benchmark designed to evaluate reasoning capabilities in video anomaly scenarios through multiple-choice questions and detailed rationales. The results demonstrate that VAU-R1 enhances accuracy in question answering and improves the coherence of reasoning across various contexts."
                },
                "zh": {
                    "title": "提升视频异常推理的智能框架",
                    "desc": "VAU-R1 是一个基于多模态大语言模型的框架，旨在提升视频异常推理能力。通过强化微调（Reinforcement Fine-Tuning），该方法能够更好地理解和解释异常事件。我们还提出了 VAU-Bench，这是一个专门用于视频异常推理的链式思维基准，包含多项选择问答、详细推理、时间标注和描述性标题。实验结果表明，VAU-R1 在问答准确性、时间定位和推理连贯性方面有显著提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24625",
            "title": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision\n  Geometry Priors",
            "url": "https://huggingface.co/papers/2505.24625",
            "abstract": "A novel Video-3D Geometry Large Language Model (VG LLM) extracts 3D information directly from video sequences to enhance 3D scene understanding without additional 3D data, achieving competitive results in various tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Previous research has investigated the application of Multimodal Large Language Models (MLLMs) in understanding 3D scenes by interpreting them as videos. These approaches generally depend on comprehensive 3D data inputs, such as point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research, we advance this field by enhancing the capability of MLLMs to understand and reason in 3D spaces directly from video data, without the need for additional 3D input. We propose a novel and efficient method, the Video-3D Geometry Large Language Model (VG LLM). Our approach employs a 3D visual geometry encoder that extracts 3D prior information from video sequences. This information is integrated with visual tokens and fed into the MLLM. Extensive experiments have shown that our method has achieved substantial improvements in various tasks related to 3D scene understanding and spatial reasoning, all directly learned from video sources. Impressively, our 4B model, which does not rely on explicit 3D data inputs, achieves competitive results compared to existing state-of-the-art methods, and even surpasses the Gemini-1.5-Pro in the VSI-Bench evaluations.",
            "score": 2,
            "issue_id": 4087,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "8bfa132788ee6990",
            "authors": [
                "Duo Zheng",
                "Shijia Huang",
                "Yanyang Li",
                "Liwei Wang"
            ],
            "affiliations": [
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24625.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#reasoning",
                    "#video",
                    "#games",
                    "#architecture",
                    "#3d"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Революция в 3D-понимании: извлечение геометрии напрямую из видео",
                    "desc": "Исследователи представили новую модель Video-3D Geometry Large Language Model (VG LLM), которая извлекает трехмерную информацию непосредственно из видеопоследовательностей для улучшения понимания 3D-сцен. В отличие от предыдущих подходов, VG LLM не требует дополнительных 3D-данных, таких как облака точек или реконструированные карты с видом сверху. Модель использует энкодер 3D-визуальной геометрии для извлечения априорной 3D-информации из видео, которая затем интегрируется с визуальными токенами и подается в мультимодальную языковую модель. Эксперименты показали, что VG LLM достигает конкурентоспособных результатов в различных задачах 3D-понимания сцен и пространственного рассуждения, превосходя некоторые современные методы."
                },
                "en": {
                    "title": "Revolutionizing 3D Scene Understanding from Video Alone!",
                    "desc": "The paper introduces the Video-3D Geometry Large Language Model (VG LLM), which enhances 3D scene understanding by extracting 3D information directly from video sequences. Unlike previous methods that require extensive 3D data inputs, VG LLM operates solely on video data, making it more efficient. It utilizes a 3D visual geometry encoder to gather 3D prior information, which is then combined with visual tokens for processing in a Multimodal Large Language Model. The results demonstrate that VG LLM achieves competitive performance in 3D tasks, outperforming existing models without the need for additional 3D data."
                },
                "zh": {
                    "title": "视频驱动的3D理解新突破",
                    "desc": "本文提出了一种新颖的视频-3D几何大语言模型（VG LLM），能够直接从视频序列中提取3D信息，从而增强3D场景理解，而无需额外的3D数据。该模型利用3D视觉几何编码器，从视频中提取3D先验信息，并将其与视觉标记结合，输入到多模态大语言模型中。通过大量实验，结果表明该方法在3D场景理解和空间推理等任务上取得了显著的改进。值得注意的是，我们的4B模型在不依赖显式3D数据输入的情况下，达到了与现有最先进方法相媲美的结果，甚至在VSI-Bench评估中超越了Gemini-1.5-Pro。"
                }
            }
        }
    ],
    "link_prev": "2025-06-02.html",
    "link_next": "2025-06-04.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "02.06",
        "en": "06/02",
        "zh": "6月2日"
    },
    "short_date_next": {
        "ru": "04.06",
        "en": "06/04",
        "zh": "6月4日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 0,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 2,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 3,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 1,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了强化学习（RL）在语言模型推理能力中的作用。研究表明，延长RL训练可以发现基础模型无法访问的新推理策略。作者提出了ProRL方法，结合KL散度控制和多样化任务。实验结果显示，RL训练的模型在多种评估中表现优于基础模型。推理边界的改进与基础模型的任务能力和训练时长密切相关。",
        "title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in\n  Large Language Models",
        "pinyin": "这篇文章讨论了强化学习（RL）在语言模型推理能力中的作用。\nZhè piān wénzhāng tǎolùn le qiáng huà xuéxí (RL) zài yǔyán móxíng tuīlǐ nénglì zhōng de zuòyòng.\n\n研究表明，延长RL训练可以发现基础模型无法访问的新推理策略。\nYánjiū biǎomíng, yáncháng RL xùnliàn kěyǐ fāxiàn jīchǔ móxíng wúfǎ fǎngwèn de xīn tuīlǐ cèlüè.\n\n作者提出了ProRL方法，结合KL散度控制和多样化任务。\nZuòzhě tíchū le ProRL fāngfǎ, jiéhé KL sǎndù kòngzhì hé duōyànghuà rènwù.\n\n实验结果显示，RL训练的模型在多种评估中表现优于基础模型。\nShíyàn jiéguǒ xiǎnshì, RL xùnliàn de móxíng zài duōzhǒng pínggū zhōng biǎoxiàn yōuyú jīchǔ móxíng.\n\n推理边界的改进与基础模型的任务能力和训练时长密切相关。\nTuīlǐ biānjiè de gǎijìn yǔ jīchǔ móxíng de rènwù nénglì hé xùnliàn shícháng mìqiè xiāngguān.",
        "vocab": "[\n    {\"word\": \"强化学习\", \"pinyin\": \"qiáng huà xué xí\", \"trans\": \"reinforcement learning\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuī lǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"作用\", \"pinyin\": \"zuò yòng\", \"trans\": \"role\"},\n    {\"word\": \"表明\", \"pinyin\": \"biǎo míng\", \"trans\": \"indicate\"},\n    {\"word\": \"延长\", \"pinyin\": \"yán cháng\", \"trans\": \"extend\"},\n    {\"word\": \"策略\", \"pinyin\": \"cè lüè\", \"trans\": \"strategy\"},\n    {\"word\": \"提出\", \"pinyin\": \"tí chū\", \"trans\": \"propose\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"结合\", \"pinyin\": \"jié hé\", \"trans\": \"combine\"},\n    {\"word\": \"散度\", \"pinyin\": \"sàn dù\", \"trans\": \"divergence\"},\n    {\"word\": \"控制\", \"pinyin\": \"kòng zhì\", \"trans\": \"control\"},\n    {\"word\": \"多样化\", \"pinyin\": \"duō yàng huà\", \"trans\": \"diversify\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wu\", \"trans\": \"task\"},\n    {\"word\": \"表现\", \"pinyin\": \"biǎo xiàn\", \"trans\": \"performance\"},\n    {\"word\": \"优于\", \"pinyin\": \"yōu yú\", \"trans\": \"superior to\"},\n    {\"word\": \"边界\", \"pinyin\": \"biān jiè\", \"trans\": \"boundary\"},\n    {\"word\": \"改进\", \"pinyin\": \"gǎi jìn\", \"trans\": \"improvement\"},\n    {\"word\": \"密切相关\", \"pinyin\": \"mì qiè xiāng guān\", \"trans\": \"closely related\"}\n]",
        "trans": "This article discusses the role of reinforcement learning (RL) in the reasoning capabilities of language models. Research indicates that extending RL training can uncover new reasoning strategies that the base model cannot access. The authors propose the ProRL method, which combines KL divergence control and diverse tasks. Experimental results show that RL-trained models outperform the base model in various evaluations. Improvements in reasoning boundaries are closely related to the task capabilities and training duration of the base model.",
        "update_ts": "2025-06-02 11:10"
    }
}