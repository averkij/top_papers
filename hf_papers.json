{
    "date": {
        "ru": "8 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
        "en": "September 8",
        "zh": "9æœˆ8æ—¥"
    },
    "time_utc": "2025-09-08 03:34",
    "weekday": 0,
    "issue_id": 5761,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.04744",
            "title": "WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning",
            "url": "https://huggingface.co/papers/2509.04744",
            "abstract": "WildScore evaluates MLLMs' symbolic music reasoning through a benchmark of real-world music scores and user-generated queries, revealing both strengths and challenges.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various vision-language tasks. However, their reasoning abilities in the multimodal symbolic music domain remain largely unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to interpret real-world music scores and answer complex musicological queries. Each instance in WildScore is sourced from genuine musical compositions and accompanied by authentic user-generated questions and discussions, capturing the intricacies of practical music analysis. To facilitate systematic evaluation, we propose a systematic taxonomy, comprising both high-level and fine-grained musicological ontologies. Furthermore, we frame complex music reasoning as multiple-choice question answering, enabling controlled and scalable assessment of MLLMs' symbolic music understanding. Empirical benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns in their visual-symbolic reasoning, uncovering both promising directions and persistent challenges for MLLMs in symbolic music reasoning and analysis. We release the dataset and code.",
            "score": 4,
            "issue_id": 5761,
            "pub_date": "2025-09-05",
            "pub_date_card": {
                "ru": "5 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 5",
                "zh": "9æœˆ5æ—¥"
            },
            "hash": "44d75a7c2c61a026",
            "authors": [
                "Gagan Mundada",
                "Yash Vishe",
                "Amit Namburi",
                "Xin Xu",
                "Zachary Novack",
                "Julian McAuley",
                "Junda Wu"
            ],
            "affiliations": [
                "University of California, San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04744.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#benchmark",
                    "#reasoning",
                    "#survey"
                ],
                "emoji": "ğŸ¼",
                "ru": {
                    "title": "WildScore: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ÑƒĞ±ĞµĞ¶ Ğ² Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğ¸ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ¾Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ WildScore - Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM) Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¾ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¼ÑƒĞ·Ñ‹ĞºĞµ. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼ÑƒĞ·Ñ‹ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ñ‚ÑƒÑ€ Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼ÑƒĞ·Ñ‹ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ‚Ğ°ĞºÑĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ ĞºĞ°Ğº Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğ¼. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… MLLM Ğ½Ğ° WildScore Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ ĞºĞ°Ğº Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ, Ñ‚Ğ°Ğº Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‰Ğ¸ĞµÑÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¾ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¼ÑƒĞ·Ñ‹ĞºĞµ."
                },
                "en": {
                    "title": "WildScore: Unlocking MLLMs' Music Reasoning Potential",
                    "desc": "WildScore is a benchmark designed to assess the reasoning abilities of Multimodal Large Language Models (MLLMs) in the context of symbolic music. It evaluates how well these models can interpret real-world music scores and respond to complex questions about music. The benchmark includes genuine musical compositions and user-generated queries, providing a realistic setting for analysis. By framing music reasoning as multiple-choice questions, WildScore allows for systematic evaluation of MLLMs' understanding of music, revealing both their strengths and areas needing improvement."
                },
                "zh": {
                    "title": "WildScoreï¼šéŸ³ä¹æ¨ç†çš„æ–°åŸºå‡†",
                    "desc": "WildScoreæ˜¯ä¸€ä¸ªè¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç¬¦å·éŸ³ä¹æ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚å®ƒé€šè¿‡çœŸå®çš„éŸ³ä¹ä¹è°±å’Œç”¨æˆ·ç”Ÿæˆçš„æŸ¥è¯¢ï¼Œæ­ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨éŸ³ä¹åˆ†æä¸­çš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚è¯¥åŸºå‡†æµ‹è¯•é‡‡ç”¨äº†ç³»ç»Ÿçš„åˆ†ç±»æ³•ï¼Œæ¶µç›–äº†é«˜å±‚æ¬¡å’Œç»†ç²’åº¦çš„éŸ³ä¹å­¦æœ¬ä½“ã€‚é€šè¿‡å°†å¤æ‚çš„éŸ³ä¹æ¨ç†æ¡†æ¶åŒ–ä¸ºå¤šé¡¹é€‰æ‹©é¢˜å›ç­”ï¼ŒWildScoreä¸ºMLLMsçš„ç¬¦å·éŸ³ä¹ç†è§£æä¾›äº†å¯æ§å’Œå¯æ‰©å±•çš„è¯„ä¼°æ–¹å¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.05263",
            "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for\n  Interactive Complex World Generation",
            "url": "https://huggingface.co/papers/2509.05263",
            "abstract": "LatticeWorld, a 3D world generation framework using lightweight LLMs and Unreal Engine 5, creates dynamic, interactive environments from textual and visual inputs, achieving high accuracy and efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real world conveniently. While traditional manual modeling has enabled the creation of virtual 3D scenes, modern approaches have leveraged advanced machine learning algorithms for 3D world generation, with most recent advances focusing on generative methods that can create virtual worlds based on user instructions. This work explores such a research direction by proposing LatticeWorld, a simple yet effective 3D world generation framework that streamlines the industrial production pipeline of 3D environments. LatticeWorld leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed framework accepts textual descriptions and visual instructions as multimodal inputs and creates large-scale 3D interactive worlds with dynamic agents, featuring competitive multi-agent interaction, high-fidelity physics simulation, and real-time rendering. We conduct comprehensive experiments to evaluate LatticeWorld, showing that it achieves superior accuracy in scene layout generation and visual fidelity. Moreover, LatticeWorld achieves over a 90times increase in industrial production efficiency while maintaining high creative quality compared with traditional manual production methods. Our demo video is available at https://youtu.be/8VWZXpERR18",
            "score": 1,
            "issue_id": 5761,
            "pub_date": "2025-09-05",
            "pub_date_card": {
                "ru": "5 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 5",
                "zh": "9æœˆ5æ—¥"
            },
            "hash": "027e61af3a0f5c1a",
            "authors": [
                "Yinglin Duan",
                "Zhengxia Zou",
                "Tongwei Gu",
                "Wei Jia",
                "Zhan Zhao",
                "Luyi Xu",
                "Xinzhu Liu",
                "Hao Jiang",
                "Kang Chen",
                "Shuang Qiu"
            ],
            "affiliations": [
                "Beihang University, China",
                "City University of Hong Kong, China",
                "NetEase, Inc., China",
                "Tsinghua University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.05263.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#games",
                    "#optimization",
                    "#agents",
                    "#3d"
                ],
                "emoji": "ğŸŒ",
                "ru": {
                    "title": "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 3D-Ğ¼Ğ¸Ñ€Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ˜Ğ˜: Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾, Ñ‚Ğ¾Ñ‡Ğ½Ğ¾, Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾",
                    "desc": "LatticeWorld - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ñ‚Ñ€Ñ‘Ñ…Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ¼Ğ¸Ñ€Ğ¾Ğ², Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¾Ğ±Ğ»ĞµĞ³Ñ‡Ñ‘Ğ½Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Unreal Engine 5. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑÑ€ĞµĞ´. LatticeWorld Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ ÑÑ†ĞµĞ½ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ€ÑƒÑ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Revolutionizing 3D World Generation with LatticeWorld",
                    "desc": "LatticeWorld is a 3D world generation framework that utilizes lightweight large language models (LLMs) and Unreal Engine 5 to create interactive environments from both textual and visual inputs. This framework aims to enhance the realism of simulations, bridging the gap between simulated and real-world scenarios, which is crucial for applications like autonomous driving and embodied AI. By employing generative methods, LatticeWorld can produce large-scale 3D worlds with dynamic agents, showcasing high-fidelity physics and real-time rendering capabilities. The results demonstrate a significant increase in production efficiency, achieving over 90 times faster output compared to traditional modeling techniques while maintaining high visual quality."
                },
                "zh": {
                    "title": "LatticeWorldï¼šé«˜æ•ˆç”ŸæˆåŠ¨æ€3Dä¸–ç•Œçš„åˆ›æ–°æ¡†æ¶",
                    "desc": "LatticeWorldæ˜¯ä¸€ä¸ªä½¿ç”¨è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹å’Œè™šå¹»å¼•æ“5çš„3Dä¸–ç•Œç”Ÿæˆæ¡†æ¶ã€‚å®ƒèƒ½å¤Ÿæ ¹æ®æ–‡æœ¬å’Œè§†è§‰è¾“å…¥åˆ›å»ºåŠ¨æ€ã€äº’åŠ¨çš„ç¯å¢ƒï¼Œå…·æœ‰é«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¯¥æ¡†æ¶é€šè¿‡å¤šæ¨¡æ€è¾“å…¥ç”Ÿæˆå¤§è§„æ¨¡çš„3Däº’åŠ¨ä¸–ç•Œï¼Œæ”¯æŒåŠ¨æ€ä»£ç†å’Œé«˜ä¿çœŸç‰©ç†æ¨¡æ‹Ÿã€‚ä¸ä¼ ç»Ÿæ‰‹åŠ¨å»ºæ¨¡æ–¹æ³•ç›¸æ¯”ï¼ŒLatticeWorldåœ¨å·¥ä¸šç”Ÿäº§æ•ˆç‡ä¸Šæé«˜äº†90å€ï¼ŒåŒæ—¶ä¿æŒäº†é«˜åˆ›æ„è´¨é‡ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-09-05.html",
    "link_next": "2025-09-09.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "05.09",
        "en": "09/05",
        "zh": "9æœˆ5æ—¥"
    },
    "short_date_next": {
        "ru": "09.09",
        "en": "09/09",
        "zh": "9æœˆ9æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}