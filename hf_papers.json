{
    "date": {
        "ru": "16 апреля",
        "en": "April 16",
        "zh": "4月16日"
    },
    "time_utc": "2025-04-16 02:24",
    "weekday": 2,
    "issue_id": 3258,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2504.10481",
            "title": "xVerify: Efficient Answer Verifier for Reasoning Model Evaluations",
            "url": "https://huggingface.co/papers/2504.10481",
            "abstract": "With the release of the o1 model by OpenAI, reasoning models adopting slow thinking strategies have gradually emerged. As the responses generated by such models often include complex reasoning, intermediate steps, and self-reflection, existing evaluation methods are often inadequate. They struggle to determine whether the LLM output is truly equivalent to the reference answer, and also have difficulty identifying and extracting the final answer from long, complex responses. To address this issue, we propose xVerify, an efficient answer verifier for reasoning model evaluations. xVerify demonstrates strong capability in equivalence judgment, enabling it to effectively determine whether the answers produced by reasoning models are equivalent to reference answers across various types of objective questions. To train and evaluate xVerify, we construct the VAR dataset by collecting question-answer pairs generated by multiple LLMs across various datasets, leveraging multiple reasoning models and challenging evaluation sets designed specifically for reasoning model assessment. A multi-round annotation process is employed to ensure label accuracy. Based on the VAR dataset, we train multiple xVerify models of different scales. In evaluation experiments conducted on both the test set and generalization set, all xVerify models achieve overall F1 scores and accuracy exceeding 95\\%. Notably, the smallest variant, xVerify-0.5B-I, outperforms all evaluation methods except GPT-4o, while xVerify-3B-Ib surpasses GPT-4o in overall performance. These results validate the effectiveness and generalizability of xVerify.",
            "score": 10,
            "issue_id": 3258,
            "pub_date": "2025-04-14",
            "pub_date_card": {
                "ru": "14 апреля",
                "en": "April 14",
                "zh": "4月14日"
            },
            "hash": "72678fc1ff453072",
            "authors": [
                "Ding Chen",
                "Qingchen Yu",
                "Pengyuan Wang",
                "Wentao Zhang",
                "Bo Tang",
                "Feiyu Xiong",
                "Xinchi Li",
                "Minchuan Yang",
                "Zhiyu Li"
            ],
            "affiliations": [
                "Center for Data Science, Peking University",
                "MemTensor (Shanghai) Technology Co., Ltd.",
                "Research Institute of China Telecom, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.10481.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#benchmark",
                    "#dataset",
                    "#reasoning",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "xVerify: точная верификация ответов моделей рассуждения",
                    "desc": "Статья представляет xVerify - эффективный верификатор ответов для оценки моделей рассуждения. xVerify способен определять эквивалентность ответов, генерируемых моделями рассуждения, эталонным ответам для различных типов объективных вопросов. Для обучения и оценки xVerify был создан набор данных VAR, содержащий пары вопросов-ответов от нескольких языковых моделей. Эксперименты показали, что модели xVerify достигают F1-меры и точности выше 95% на тестовом и обобщающем наборах данных."
                },
                "en": {
                    "title": "xVerify: Elevating Reasoning Model Evaluation with Precision",
                    "desc": "This paper introduces xVerify, a novel answer verification tool designed to evaluate reasoning models that utilize slow thinking strategies. Traditional evaluation methods struggle with complex outputs from large language models (LLMs), particularly in assessing the equivalence of answers and extracting final responses. xVerify addresses these challenges by leveraging a specially constructed VAR dataset, which includes diverse question-answer pairs generated by various LLMs. The results show that xVerify models achieve high accuracy and F1 scores, demonstrating their effectiveness in evaluating reasoning models compared to existing methods."
                },
                "zh": {
                    "title": "xVerify：推理模型评估的新标准",
                    "desc": "随着OpenAI发布o1模型，采用慢思维策略的推理模型逐渐出现。这些模型生成的响应通常包含复杂的推理、中间步骤和自我反思，现有的评估方法往往无法有效判断LLM输出是否真正等同于参考答案。为了解决这个问题，我们提出了xVerify，一个高效的答案验证器，用于推理模型的评估。xVerify在等价判断方面表现出色，能够有效判断推理模型生成的答案是否与参考答案等价，并在多个客观问题类型中表现优异。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.10337",
            "title": "Heimdall: test-time scaling on the generative verification",
            "url": "https://huggingface.co/papers/2504.10337",
            "abstract": "An AI system can create and maintain knowledge only to the extent that it can verify that knowledge itself. Recent work on long Chain-of-Thought reasoning has demonstrated great potential of LLMs on solving competitive problems, but their verification ability remains to be weak and not sufficiently investigated. In this paper, we propose Heimdall, the long CoT verification LLM that can accurately judge the correctness of solutions. With pure reinforcement learning, we boost the verification accuracy from 62.5% to 94.5% on competitive math problems. By scaling with repeated sampling, the accuracy further increases to 97.5%. Through human evaluation, Heimdall demonstrates impressive generalization capabilities, successfully detecting most issues in challenging math proofs, the type of which is not included during training. Furthermore, we propose Pessimistic Verification to extend the functionality of Heimdall to scaling up the problem solving. It calls Heimdall to judge the solutions from a solver model and based on the pessimistic principle, selects the most likely correct solution with the least uncertainty. Taking DeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification improves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute budget and to 83.3% with more compute budget. With the stronger solver Gemini 2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge discovery system, a ternary system where one poses questions, another provides solutions, and the third verifies the solutions. Using the data synthesis work NuminaMath for the first two components, Heimdall effectively identifies problematic records within the dataset and reveals that nearly half of the data is flawed, which interestingly aligns with the recent ablation studies from NuminaMath.",
            "score": 2,
            "issue_id": 3258,
            "pub_date": "2025-04-14",
            "pub_date_card": {
                "ru": "14 апреля",
                "en": "April 14",
                "zh": "4月14日"
            },
            "hash": "6da5db970a101d21",
            "authors": [
                "Wenlei Shi",
                "Xing Jin"
            ],
            "affiliations": [
                "bytedance.com"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.10337.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#reasoning",
                    "#long_context",
                    "#optimization",
                    "#training",
                    "#rl",
                    "#math"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Heimdall: ИИ-верификатор для повышения надежности рассуждений языковых моделей",
                    "desc": "Статья представляет Heimdall - модель верификации для длинных цепочек рассуждений (Chain-of-Thought). С помощью обучения с подкреплением точность верификации была повышена с 62.5% до 94.5% на сложных математических задачах. Предложен метод пессимистической верификации для масштабирования решения задач. Heimdall демонстрирует высокую способность к обобщению, обнаруживая ошибки даже в сложных математических доказательствах."
                },
                "en": {
                    "title": "Heimdall: Elevating AI Verification with Chain-of-Thought Reasoning",
                    "desc": "This paper introduces Heimdall, a long Chain-of-Thought (CoT) verification model designed to enhance the accuracy of solution verification in AI systems. By employing pure reinforcement learning, Heimdall significantly improves verification accuracy on competitive math problems from 62.5% to 94.5%, and with repeated sampling, it reaches 97.5%. The paper also presents Pessimistic Verification, which optimizes solution selection by minimizing uncertainty, leading to improved accuracy in problem-solving tasks. Additionally, Heimdall is part of an automatic knowledge discovery system that identifies flaws in datasets, revealing that a substantial portion of the data is incorrect, which is consistent with findings from previous studies."
                },
                "zh": {
                    "title": "提升AI知识验证能力的Heimdall模型",
                    "desc": "本文提出了一种名为Heimdall的长链思维验证大语言模型（LLM），旨在提高解决竞争性数学问题的解答准确性。通过纯强化学习，Heimdall的验证准确率从62.5%提升至94.5%，并通过重复采样进一步提高至97.5%。此外，Heimdall还展示了出色的泛化能力，能够检测出训练中未包含的复杂数学证明中的大多数问题。我们还提出了悲观验证方法，以扩展Heimdall的功能，显著提高了解决方案的准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.11447",
            "title": "Diffusion Distillation With Direct Preference Optimization For Efficient\n  3D LiDAR Scene Completion",
            "url": "https://huggingface.co/papers/2504.11447",
            "abstract": "The application of diffusion models in 3D LiDAR scene completion is limited due to diffusion's slow sampling speed. Score distillation accelerates diffusion sampling but with performance degradation, while post-training with direct policy optimization (DPO) boosts performance using preference data. This paper proposes Distillation-DPO, a novel diffusion distillation framework for LiDAR scene completion with preference aligment. First, the student model generates paired completion scenes with different initial noises. Second, using LiDAR scene evaluation metrics as preference, we construct winning and losing sample pairs. Such construction is reasonable, since most LiDAR scene metrics are informative but non-differentiable to be optimized directly. Third, Distillation-DPO optimizes the student model by exploiting the difference in score functions between the teacher and student models on the paired completion scenes. Such procedure is repeated until convergence. Extensive experiments demonstrate that, compared to state-of-the-art LiDAR scene completion diffusion models, Distillation-DPO achieves higher-quality scene completion while accelerating the completion speed by more than 5-fold. Our method is the first to explore adopting preference learning in distillation to the best of our knowledge and provide insights into preference-aligned distillation. Our code is public available on https://github.com/happyw1nd/DistillationDPO.",
            "score": 1,
            "issue_id": 3258,
            "pub_date": "2025-04-15",
            "pub_date_card": {
                "ru": "15 апреля",
                "en": "April 15",
                "zh": "4月15日"
            },
            "hash": "cda8d39111df28d8",
            "authors": [
                "An Zhaol",
                "Shengyuan Zhang",
                "Ling Yang",
                "Zejian Li",
                "Jiale Wu",
                "Haoran Xu",
                "AnYang Wei",
                "Perry Pengyun GU Lingyun Sun"
            ],
            "affiliations": [
                "Peking University",
                "Zhejiang Green Zhixing Technology co., ltd",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.11447.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#3d",
                    "#rlhf",
                    "#training",
                    "#diffusion",
                    "#optimization"
                ],
                "emoji": "🚗",
                "ru": {
                    "title": "Ускоренное и улучшенное заполнение сцен LiDAR с помощью Distillation-DPO",
                    "desc": "Эта статья представляет новый метод под названием Distillation-DPO для ускорения и улучшения качества заполнения сцен LiDAR с использованием диффузионных моделей. Метод сочетает дистилляцию знаний с оптимизацией прямой политики (DPO), используя метрики оценки сцен LiDAR в качестве предпочтений. Distillation-DPO оптимизирует модель ученика, используя разницу в функциях оценки между учителем и учеником на парных сценах завершения. Эксперименты показывают, что метод достигает более высокого качества заполнения сцены при ускорении процесса более чем в 5 раз по сравнению с современными моделями."
                },
                "en": {
                    "title": "Accelerating 3D LiDAR Scene Completion with Distillation-DPO",
                    "desc": "This paper introduces Distillation-DPO, a new framework that enhances 3D LiDAR scene completion using diffusion models. It combines score distillation with direct policy optimization (DPO) to improve performance while speeding up the sampling process. The method generates paired scene completions with varying initial noises and uses LiDAR evaluation metrics to create winning and losing pairs for optimization. The results show that Distillation-DPO significantly outperforms existing models in both quality and speed, marking a novel approach in preference-aligned distillation for LiDAR applications."
                },
                "zh": {
                    "title": "提升LiDAR场景补全速度与质量的创新方法",
                    "desc": "本论文提出了一种新的扩散蒸馏框架，称为Distillation-DPO，用于3D LiDAR场景补全。该方法通过偏好对齐来优化学生模型，首先生成不同初始噪声的配对补全场景。然后，利用LiDAR场景评估指标构建胜负样本对，以此来优化模型。实验表明，Distillation-DPO在场景补全质量和速度上均优于现有的最先进模型，补全速度提高了5倍以上。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.10766",
            "title": "How Instruction and Reasoning Data shape Post-Training: Data Quality\n  through the Lens of Layer-wise Gradients",
            "url": "https://huggingface.co/papers/2504.10766",
            "abstract": "As the post-training of large language models (LLMs) advances from instruction-following to complex reasoning tasks, understanding how different data affect finetuning dynamics remains largely unexplored. In this paper, we present a spectral analysis of layer-wise gradients induced by low/high-quality instruction and reasoning data for LLM post-training. Our analysis reveals that widely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and Reward, can be explained and unified by spectral properties computed from gradients' singular value decomposition (SVD). Specifically, higher-quality data are usually associated with lower nuclear norms and higher effective ranks. Notably, effective rank exhibits better robustness and resolution than nuclear norm in capturing subtle quality differences. For example, reasoning data achieves substantially higher effective ranks than instruction data, implying richer gradient structures on more complex tasks. Our experiments also highlight that models within the same family share similar gradient patterns regardless of their sizes, whereas different model families diverge significantly. Providing a unified view on the effects of data quality across instruction and reasoning data, this work illuminates the interplay between data quality and training stability, shedding novel insights into developing better data exploration strategies for post-training.",
            "score": 0,
            "issue_id": 3258,
            "pub_date": "2025-04-14",
            "pub_date_card": {
                "ru": "14 апреля",
                "en": "April 14",
                "zh": "4月14日"
            },
            "hash": "b95bec819bad5307",
            "authors": [
                "Ming Li",
                "Yanhong Li",
                "Ziyue Li",
                "Tianyi Zhou"
            ],
            "affiliations": [
                "University of Chicago",
                "University of Maryland"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.10766.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#data",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Спектральный анализ раскрывает секреты качества данных в обучении языковых моделей",
                    "desc": "Эта статья представляет спектральный анализ послойных градиентов, вызванных данными разного качества при дообучении больших языковых моделей (LLM). Исследование показывает, что метрики оценки данных, такие как IFD, InsTag, Difficulty и Reward, можно объяснить и объединить с помощью спектральных свойств, вычисленных из сингулярного разложения градиентов. Авторы обнаружили, что данные более высокого качества обычно связаны с более низкими ядерными нормами и более высокими эффективными рангами. Эксперименты также показывают, что модели одного семейства имеют схожие паттерны градиентов независимо от их размера, в то время как разные семейства моделей значительно различаются."
                },
                "en": {
                    "title": "Unlocking the Secrets of Data Quality in LLM Fine-Tuning",
                    "desc": "This paper investigates how the quality of data influences the fine-tuning of large language models (LLMs) during post-training, particularly for complex reasoning tasks. It employs spectral analysis of layer-wise gradients to understand the effects of low and high-quality instruction and reasoning data. The study finds that traditional metrics for data evaluation can be unified through the spectral properties derived from the singular value decomposition (SVD) of gradients. Notably, it shows that higher-quality data leads to lower nuclear norms and higher effective ranks, with effective rank being a more reliable measure for capturing quality differences, especially in reasoning tasks."
                },
                "zh": {
                    "title": "数据质量与训练稳定性的统一视角",
                    "desc": "本文探讨了大语言模型（LLM）在后训练阶段中，不同数据对微调动态的影响。我们通过对低质量和高质量指令及推理数据的层级梯度进行谱分析，发现常用的数据评估指标可以通过梯度的奇异值分解（SVD）谱特性来解释和统一。研究表明，高质量数据通常与较低的核范数和较高的有效秩相关，且有效秩在捕捉细微质量差异方面表现出更好的鲁棒性和分辨率。我们的实验还表明，同一家族的模型在梯度模式上相似，而不同模型家族之间则存在显著差异。"
                }
            }
        }
    ],
    "link_prev": "2025-04-15.html",
    "link_next": "2025-04-17.html",
    "link_month": "2025-04.html",
    "short_date_prev": {
        "ru": "15.04",
        "en": "04/15",
        "zh": "4月15日"
    },
    "short_date_next": {
        "ru": "17.04",
        "en": "04/17",
        "zh": "4月17日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 3,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "我们介绍了 InternVL3，这是 InternVL 系列的重大进步，采用了本地多模态预训练范式。与其他方法不同，InternVL3 在单个预训练阶段内，从多模态数据和纯文本数据中同时获取多模态和语言能力。这种统一的训练范式有效解决了传统训练流程中的复杂性和对齐挑战。为了进一步提高性能和可扩展性，InternVL3 使用了可变视觉位置编码和先进的后训练技术。实验结果显示，InternVL3 在多种多模态任务中表现优异，特别是 InternVL3-78B 在 MMMU 基准测试中获得了 72.2 的分数，创下新纪录。我们将公开发布训练数据和模型权重，以促进下一代 MLLMs 的研究和开发。",
        "title": "InternVL3: Exploring Advanced Training and Test-Time Recipes for\n  Open-Source Multimodal Models",
        "pinyin": "Wǒmen jièshào le InternVL3, zhè shì InternVL xìliè de zhòngdà jìnbù, cǎiyòng le běndì duōmóshī yùxùnliàn fànshì. Yǔ qítā fāngfǎ bùtóng, InternVL3 zài dān gè yùxùnliàn jiēduàn nèi, cóng duōmóshī shùjù hé chún wénběn shùjù zhōng tóngshí huòdé duōmóshī hé yǔyán nénglì. Zhè zhǒng tǒngyī de xùnliàn fànshì yǒuxiào jiějué le chuántǒng xùnliàn liúchéng zhōng de fùzáxìng hé duìqǐ tiǎozhàn. Wèile jìnfū tīgāo xíngnéng hé kěkuòzhǎn xìng, InternVL3 shǐyòng le kěbiàn shìjué wèizhì biānmǎ hé xiānjìn de hòuxùnliàn jìshù. Shíyàn jiéguǒ xiǎnshì, InternVL3 zài duōzhǒng duōmóshī rènwù zhōng biǎoxiàn yōuyù, tèbié shì InternVL3-78B zài MMMU jīzhǔn cèshì zhōng huòdé le 72.2 de fēnshù, chuàng xià xīn jìlù. Wǒmen jiāng gōngkāi fābù xùnliàn shùjù hé móxíng quánzhòng, yǐ cùjìn xià yīdài MLLMs de yánjiū hé kāifā.",
        "vocab": "[{'word': '介绍', 'pinyin': 'jiè shào', 'trans': 'introduce'},\n{'word': '重大', 'pinyin': 'zhòng dà', 'trans': 'major'},\n{'word': '进步', 'pinyin': 'jìn bù', 'trans': 'progress'},\n{'word': '采用', 'pinyin': 'cǎi yòng', 'trans': 'adopt'},\n{'word': '范式', 'pinyin': 'fàn shì', 'trans': 'paradigm'},\n{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'},\n{'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-training'},\n{'word': '阶段', 'pinyin': 'jiē duàn', 'trans': 'stage'},\n{'word': '获取', 'pinyin': 'huò qǔ', 'trans': 'obtain'},\n{'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'},\n{'word': '统一', 'pinyin': 'tǒng yī', 'trans': 'unified'},\n{'word': '解决', 'pinyin': 'jiě jué', 'trans': 'solve'},\n{'word': '复杂性', 'pinyin': 'fù zá xìng', 'trans': 'complexity'},\n{'word': '对齐', 'pinyin': 'duì qí', 'trans': 'alignment'},\n{'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'},\n{'word': '可变', 'pinyin': 'kě biàn', 'trans': 'variable'},\n{'word': '视觉', 'pinyin': 'shì jué', 'trans': 'visual'},\n{'word': '位置', 'pinyin': 'wèi zhì', 'trans': 'position'},\n{'word': '编码', 'pinyin': 'biān mǎ', 'trans': 'encoding'},\n{'word': '先进', 'pinyin': 'xiān jìn', 'trans': 'advanced'},\n{'word': '后训练', 'pinyin': 'hòu xùn liàn', 'trans': 'post-training'},\n{'word': '技术', 'pinyin': 'jì shù', 'trans': 'technology'},\n{'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'},\n{'word': '优异', 'pinyin': 'yōu yì', 'trans': 'excellent'},\n{'word': '特别', 'pinyin': 'tè bié', 'trans': 'especially'},\n{'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'},\n{'word': '测试', 'pinyin': 'cè shì', 'trans': 'test'},\n{'word': '分数', 'pinyin': 'fēn shù', 'trans': 'score'},\n{'word': '纪录', 'pinyin': 'jì lù', 'trans': 'record'},\n{'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'},\n{'word': '发布', 'pinyin': 'fā bù', 'trans': 'release'},\n{'word': '权重', 'pinyin': 'quán zhòng', 'trans': 'weights'},\n{'word': '促进', 'pinyin': 'cù jìn', 'trans': 'promote'},\n{'word': '下一代', 'pinyin': 'xià yī dài', 'trans': 'next generation'},\n{'word': '研究', 'pinyin': 'yán jiū', 'trans': 'research'},\n{'word': '开发', 'pinyin': 'kāi fā', 'trans': 'development'}]",
        "trans": "We introduced InternVL3, a significant advancement in the InternVL series, which adopts a local multimodal pretraining paradigm. Unlike other methods, InternVL3 simultaneously acquires multimodal and language capabilities from both multimodal data and pure text data within a single pretraining stage. This unified training paradigm effectively addresses the complexity and alignment challenges of traditional training processes. To further enhance performance and scalability, InternVL3 employs variable visual positional encoding and advanced post-training techniques. Experimental results demonstrate that InternVL3 performs exceptionally well across various multimodal tasks, particularly with InternVL3-78B achieving a score of 72.2 on the MMMU benchmark, setting a new record. We will publicly release the training data and model weights to promote research and development of the next generation of MLLMs.",
        "update_ts": "2025-04-15 09:12"
    }
}