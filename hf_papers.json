{
    "date": {
        "ru": "18 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ",
        "en": "December 18",
        "zh": "12æœˆ18æ—¥"
    },
    "time_utc": "2024-12-18 03:22",
    "weekday": 2,
    "issue_id": 1181,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.13147",
            "title": "Are Your LLMs Capable of Stable Reasoning?",
            "url": "https://huggingface.co/papers/2412.13147",
            "abstract": "The rapid advancement of Large Language Models (LLMs) has demonstrated remarkable progress in complex reasoning tasks. However, a significant discrepancy persists between benchmark performances and real-world applications. We identify this gap as primarily stemming from current evaluation protocols and metrics, which inadequately capture the full spectrum of LLM capabilities, particularly in complex reasoning tasks where both accuracy and consistency are crucial. This work makes two key contributions. First, we introduce G-Pass@k, a novel evaluation metric that provides a continuous assessment of model performance across multiple sampling attempts, quantifying both the model's peak performance potential and its stability. Second, we present LiveMathBench, a dynamic benchmark comprising challenging, contemporary mathematical problems designed to minimize data leakage risks during evaluation. Through extensive experiments using G-Pass@k on state-of-the-art LLMs with LiveMathBench, we provide comprehensive insights into both their maximum capabilities and operational consistency. Our findings reveal substantial room for improvement in LLMs' \"realistic\" reasoning capabilities, highlighting the need for more robust evaluation methods. The benchmark and detailed results are available at: https://github.com/open-compass/GPassK.",
            "score": 8,
            "issue_id": 1181,
            "pub_date": "2024-12-17",
            "pub_date_card": {
                "ru": "17 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ",
                "en": "December 17",
                "zh": "12æœˆ17æ—¥"
            },
            "hash": "a030a3cb6cc36da2",
            "authors": [
                "Junnan Liu",
                "Hongwei Liu",
                "Linchen Xiao",
                "Ziyi Wang",
                "Kuikun Liu",
                "Songyang Gao",
                "Wenwei Zhang",
                "Songyang Zhang",
                "Kai Chen"
            ],
            "affiliations": [
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.13147.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#benchmark",
                    "#evaluation",
                    "#reasoning",
                    "#leakage"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ G-Pass@k, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ°Ğº Ğ¿Ğ¸ĞºĞ¾Ğ²ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ñ‚Ğ°Ğº Ğ¸ ĞµÑ‘ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ĞºÑ€Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°Ñ…. Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº LiveMathBench Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞµ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ 'Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ…' ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ LLM Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼."
                },
                "en": {
                    "title": "Bridging the Gap: Enhancing LLM Evaluation for Real-World Reasoning",
                    "desc": "This paper addresses the gap between the performance of Large Language Models (LLMs) on benchmarks and their effectiveness in real-world scenarios, particularly in complex reasoning tasks. The authors propose a new evaluation metric called G-Pass@k, which assesses model performance over multiple attempts, focusing on both peak performance and stability. Additionally, they introduce LiveMathBench, a benchmark of challenging mathematical problems that reduces data leakage during evaluation. The study reveals that current LLMs have significant room for improvement in their reasoning capabilities, emphasizing the need for better evaluation methods."
                },
                "zh": {
                    "title": "æå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„è¯„ä¼°æ–°æ–¹æ³•",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸å®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™ä¸€å·®è·ä¸»è¦æºäºå½“å‰çš„è¯„ä¼°åè®®å’ŒæŒ‡æ ‡æ— æ³•å…¨é¢åæ˜ LLMsçš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å‡†ç¡®æ€§å’Œä¸€è‡´æ€§è‡³å…³é‡è¦çš„å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†G-Pass@kè¿™ä¸€æ–°è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿåœ¨å¤šæ¬¡é‡‡æ ·ä¸­æŒç»­è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œå¹¶é‡åŒ–æ¨¡å‹çš„æœ€ä½³è¡¨ç°æ½œåŠ›å’Œç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†LiveMathBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŠ¨æ€åŸºå‡†ï¼ŒåŒ…å«å…·æœ‰æŒ‘æˆ˜æ€§çš„ç°ä»£æ•°å­¦é—®é¢˜ï¼Œæ—¨åœ¨å‡å°‘è¯„ä¼°è¿‡ç¨‹ä¸­çš„æ•°æ®æ³„éœ²é£é™©ã€‚"
                }
            }
        }
    ],
    "link_prev": "2024-12-17.html",
    "link_next": "2024-12-19.html",
    "link_month": "2024-12.html",
    "short_date_prev": {
        "ru": "17.12",
        "en": "12/17",
        "zh": "12æœˆ17æ—¥"
    },
    "short_date_next": {
        "ru": "19.12",
        "en": "12/19",
        "zh": "12æœˆ19æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 1,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0,
        "#evaluation": 1
    },
    "zh": {
        "text": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç¤ºäº†æ˜¾è‘—çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä½†å¸¸å¸¸å‡ºç°å¹»è§‰ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡å¼•å…¥å¤–éƒ¨çŸ¥è¯†æä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰æ–¹æ³•ä»é¢ä¸´ä¸€äº›é™åˆ¶ï¼šé¢å¤–çš„éƒ¨ç½²æˆæœ¬ã€æ£€ç´¢æ–‡æœ¬å—ä¸­çš„å†—ä½™è¾“å…¥æ ‡è®°ä»¥åŠæ£€ç´¢å’Œç”Ÿæˆçš„è”åˆä¼˜åŒ–ç¼ºä¹ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†RetroLLMï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå°†æ£€ç´¢å’Œç”Ÿæˆæ•´åˆä¸ºå•ä¸€çš„è¿‡ç¨‹ï¼Œä½¿LLMsèƒ½å¤Ÿç›´æ¥ä»è¯­æ–™åº“ä¸­ç”Ÿæˆç»†ç²’åº¦çš„è¯æ®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åˆ†å±‚FM-Indexçº¦æŸå’Œå‰ç»æ€§çº¦æŸè§£ç ç­–ç•¥ï¼Œä»¥å‡å°‘ä¸ç›¸å…³çš„è§£ç ç©ºé—´å¹¶æé«˜è¯æ®å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRetroLLMåœ¨äº”ä¸ªå¼€æ”¾åŸŸé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ä»£ç å¯åœ¨https://github.com/sunnynexus/RetroLLMè·å–ã€‚",
        "title": "RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation",
        "pinyin": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç¤ºäº†æ˜¾è‘—çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä½†å¸¸å¸¸å‡ºç°å¹»è§‰ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡å¼•å…¥å¤–éƒ¨çŸ¥è¯†æä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰æ–¹æ³•ä»é¢ä¸´ä¸€äº›é™åˆ¶ï¼šé¢å¤–çš„éƒ¨ç½²æˆæœ¬ã€æ£€ç´¢æ–‡æœ¬å—ä¸­çš„å†—ä½™è¾“å…¥æ ‡è®°ä»¥åŠæ£€ç´¢å’Œç”Ÿæˆçš„è”åˆä¼˜åŒ–ç¼ºä¹ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†RetroLLMï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå°†æ£€ç´¢å’Œç”Ÿæˆæ•´åˆä¸ºå•ä¸€çš„è¿‡ç¨‹ï¼Œä½¿LLMsèƒ½å¤Ÿç›´æ¥ä»è¯­æ–™åº“ä¸­ç”Ÿæˆç»†ç²’åº¦çš„è¯æ®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åˆ†å±‚FM-Indexçº¦æŸå’Œå‰ç»æ€§çº¦æŸè§£ç ç­–ç•¥ï¼Œä»¥å‡å°‘ä¸ç›¸å…³çš„è§£ç ç©ºé—´å¹¶æé«˜è¯æ®å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRetroLLMåœ¨äº”ä¸ªå¼€æ”¾åŸŸé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ä»£ç å¯åœ¨https://github.com/sunnynexus/RetroLLMè·å–ã€‚\n\ndÃ  xÃ­ng yÇ” yÃ¡n mÃ³ xÃ­ng (LLMs) zhÇn shÃ¬ le xiÇn zhÃ¹ de shÄ“ng chÃ©ng nÃ©ng lÃ¬, dÃ n chÃ¡ng chÃ¡ng chÅ« xiÃ n huÃ n juÃ©. JiÇn suÇ’ zÄ“ng qiÃ¡ng shÄ“ng chÃ©ng (RAG) tÅng guÃ² yÇn rÃ¹ wÃ i bÃ¹ zhÄ« shi tÃ­ gÅng le yÇ’u xiÃ o jiÄ› juÃ© fÄng Än, dÃ n xiÃ n yÇ’u fÄng fÇ rÃ©ng miÃ n lÃ¬ng yÄ« xiÄ“ xiÃ n zhÃ¬: Ã© wÃ i de bÃ¹ shÃ¹ chÃ©ng bÄ›n, jiÇn suÇ’ wÃ©n bÄ›n kuÃ i zhÅng de rÃ³ng yÃ¹ shÅ« rÃ¹ biÄo jÃ¬ yÇ jÃ­ jiÇn suÇ’ hÃ© shÄ“ng chÃ©ng de liÃ¡n hÃ© yÅu huÃ  quÄ“ fÇ. WÃ¨i jiÄ› juÃ© zhÃ¨ xiÄ“ wÃ¨n tÃ­, wÇ’ men tÃ­ chÅ« le RetroLLM, yÄ« gÃ¨ tÇ’ng yÄ« de kuÃ ng jiÃ , jiÄng jiÇn suÇ’ hÃ© shÄ“ng chÃ©ng zhÄ›ng hÃ© wÃ©i dÄn yÄ« de guÃ² chÃ©ng, shÇ LLMs nÃ©ng gÃ²u zhÃ­ jiÄ“ kÃ¹ zhÅng shÄ“ng chÃ©ng xÃ¬ lÃ¬ dÃ¹ de zhÃ¨ng jÃ¹. CÇ wÃ i, wÇ’ men yÇn rÃ¹ le fÄ“n cÃ©ng FM-Index yuÄ“ shuÅ hÃ© qiÃ¡n zhÄn xÃ¬ng yuÄ“ shuÅ jiÄ› mÇ zhuÃ n lÃ¼Ã¨, yÇ jiÇn shÇo bÃ¹ xiÄng guÄn de jiÄ› mÇ kÅng jiÄn yÇng tÃ­ gÄo zhÃ¨ng jÃ¹ zhÇ”n quÃ¨ xÃ¬ng. ShÃ­ yÃ n jiÃ© guÇ’ biÇo mÃ­ng, RetroLLM zÃ i wÇ” gÃ¨ kÄi fÃ ng yÃ¹ qiÃº shÃ¹ jÃ¹ shÃ¹ jÃ¹ shÃ ng biÇo xiÃ n yÅu yÃ¡n. DÃ i mÇ kÄ› zÃ i https://github.com/sunnynexus/RetroLLM huÃ² qÇ”.",
        "vocab": "[{'word': 'å¤§å‹', 'pinyin': 'dÃ xÃ­ng', 'trans': 'large-scale'},\n{'word': 'è¯­è¨€æ¨¡å‹', 'pinyin': 'yÇ”yÃ¡n mÃ³xÃ­ng', 'trans': 'language model'},\n{'word': 'æ˜¾è‘—', 'pinyin': 'xiÇnzhÃ¹', 'trans': 'significant'},\n{'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generation'},\n{'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©nglÃ¬', 'trans': 'ability'},\n{'word': 'å¹»è§‰', 'pinyin': 'huÃ njuÃ©', 'trans': 'hallucination'},\n{'word': 'æ£€ç´¢', 'pinyin': 'jiÇnsuÇ’', 'trans': 'retrieval'},\n{'word': 'å¢å¼º', 'pinyin': 'zÄ“ngqiÃ¡ng', 'trans': 'enhanced'},\n{'word': 'å¼•å…¥', 'pinyin': 'yÇnrÃ¹', 'trans': 'introduce'},\n{'word': 'å¤–éƒ¨', 'pinyin': 'wÃ ibÃ¹', 'trans': 'external'},\n{'word': 'çŸ¥è¯†', 'pinyin': 'zhÄ«shi', 'trans': 'knowledge'},\n{'word': 'æä¾›', 'pinyin': 'tÃ­gÅng', 'trans': 'provide'},\n{'word': 'æœ‰æ•ˆ', 'pinyin': 'yÇ’uxiÃ o', 'trans': 'effective'},\n{'word': 'è§£å†³', 'pinyin': 'jiÄ›juÃ©', 'trans': 'solution'},\n{'word': 'æ–¹æ¡ˆ', 'pinyin': 'fÄngÃ n', 'trans': 'scheme'},\n{'word': 'é¢ä¸´', 'pinyin': 'miÃ nlÃ­n', 'trans': 'face'},\n{'word': 'é™åˆ¶', 'pinyin': 'xiÃ nzhÃ¬', 'trans': 'limitation'},\n{'word': 'é¢å¤–', 'pinyin': 'Ã©wÃ i', 'trans': 'additional'},\n{'word': 'éƒ¨ç½²', 'pinyin': 'bÃ¹shÇ”', 'trans': 'deployment'},\n{'word': 'æˆæœ¬', 'pinyin': 'chÃ©ngbÄ›n', 'trans': 'cost'},\n{'word': 'å†—ä½™', 'pinyin': 'rÃ³ngyÃº', 'trans': 'redundant'},\n{'word': 'è¾“å…¥', 'pinyin': 'shÅ«rÃ¹', 'trans': 'input'},\n{'word': 'æ ‡è®°', 'pinyin': 'biÄojÃ¬', 'trans': 'token'},\n{'word': 'è”åˆ', 'pinyin': 'liÃ¡nhÃ©', 'trans': 'joint'},\n{'word': 'ä¼˜åŒ–', 'pinyin': 'yÅuhuÃ ', 'trans': 'optimization'},\n{'word': 'ç¼ºä¹', 'pinyin': 'quÄ“fÃ¡', 'trans': 'lack'},\n{'word': 'æå‡º', 'pinyin': 'tÃ­chÅ«', 'trans': 'propose'},\n{'word': 'ç»Ÿä¸€', 'pinyin': 'tÇ’ngyÄ«', 'trans': 'unified'},\n{'word': 'æ¡†æ¶', 'pinyin': 'kuÃ ngjiÃ ', 'trans': 'framework'},\n{'word': 'æ•´åˆ', 'pinyin': 'zhÄ›nghÃ©', 'trans': 'integrate'},\n{'word': 'è¿‡ç¨‹', 'pinyin': 'guÃ²chÃ©ng', 'trans': 'process'},\n{'word': 'ä½¿', 'pinyin': 'shÇ', 'trans': 'make'},\n{'word': 'ç›´æ¥', 'pinyin': 'zhÃ­jiÄ“', 'trans': 'directly'},\n{'word': 'è¯­æ–™åº“', 'pinyin': 'yÇ”liÃ o kÃ¹', 'trans': 'corpus'},\n{'word': 'ç»†ç²’åº¦', 'pinyin': 'xÃ¬lÃ¬dÃ¹', 'trans': 'fine-grained'},\n{'word': 'è¯æ®', 'pinyin': 'zhÃ¨ngjÃ¹', 'trans': 'evidence'},\n{'word': 'åˆ†å±‚', 'pinyin': 'fÄ“ncÃ©ng', 'trans': 'hierarchical'},\n{'word': 'FM-Index', 'pinyin': 'FM-Index', 'trans': 'FM-Index'},\n{'word': 'çº¦æŸ', 'pinyin': 'yuÄ“shÃ¹', 'trans': 'constraint'},\n{'word': 'å‰ç»æ€§', 'pinyin': 'qiÃ¡nzhÄnxÃ¬ng', 'trans': 'forward-looking'},\n{'word': 'è§£ç ', 'pinyin': 'jiÄ›mÇ', 'trans': 'decoding'},\n{'word': 'ç­–ç•¥', 'pinyin': 'cÃ¨lÃ¼Ã¨', 'trans': 'strategy'},\n{'word': 'å‡å°‘', 'pinyin': 'jiÇnshÇo', 'trans': 'reduce'},\n{'word': 'ä¸ç›¸å…³', 'pinyin': 'bÃ¹xiÄngguÄn', 'trans': 'irrelevant'},\n{'word': 'ç©ºé—´', 'pinyin': 'kÅngjiÄn', 'trans': 'space'},\n{'word': 'æé«˜', 'pinyin': 'tÃ­gÄo', 'trans': 'improve'},\n{'word': 'å‡†ç¡®æ€§', 'pinyin': 'zhÇ”nquÃ¨xÃ¬ng', 'trans': 'accuracy'},\n{'word': 'å®éªŒ', 'pinyin': 'shÃ­yÃ n', 'trans': 'experiment'},\n{'word': 'ç»“æœ', 'pinyin': 'jiÃ©guÇ’', 'trans': 'result'},\n{'word': 'è¡¨æ˜', 'pinyin': 'biÇomÃ­ng', 'trans': 'indicate'},\n{'word': 'å¼€æ”¾åŸŸ', 'pinyin': 'kÄifÃ ng yÃ¹', 'trans': 'open-domain'},\n{'word': 'é—®ç­”', 'pinyin': 'wÃ¨ndÃ¡', 'trans': 'question-answering'},\n{'word': 'æ•°æ®é›†', 'pinyin': 'shÃ¹jÃ¹jÃ­', 'trans': 'dataset'},\n{'word': 'è¡¨ç°', 'pinyin': 'biÇoxiÃ n', 'trans': 'performance'},\n{'word': 'ä¼˜å¼‚', 'pinyin': 'yÅuyÃ¬', 'trans': 'excellent'},\n{'word': 'ä»£ç ', 'pinyin': 'dÃ imÇ', 'trans': 'code'},\n{'word': 'è·å–', 'pinyin': 'huÃ²qÇ”', 'trans': 'obtain'}]",
        "trans": "Large Language Models (LLMs) have demonstrated significant generative capabilities but often suffer from hallucinations. Retrieval-Augmented Generation (RAG) offers an effective solution by introducing external knowledge; however, existing methods still face several limitations: additional deployment costs, redundant input tokens in retrieved text blocks, and a lack of joint optimization for retrieval and generation. To address these issues, we propose RetroLLM, a unified framework that integrates retrieval and generation into a single process, enabling LLMs to generate fine-grained evidence directly from a corpus. Additionally, we introduce hierarchical FM-Index constraints and look-ahead constraint decoding strategies to reduce irrelevant decoding space and enhance evidence accuracy. Experimental results show that RetroLLM performs exceptionally well on five open-domain question-answering datasets. The code is available at https://github.com/sunnynexus/RetroLLM.",
        "update_ts": "2024-12-17 09:11"
    }
}