{
    "date": {
        "ru": "29 Ğ¸ÑĞ»Ñ",
        "en": "July 29",
        "zh": "7æœˆ29æ—¥"
    },
    "time_utc": "2025-07-29 19:15",
    "weekday": 1,
    "issue_id": 5074,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.19849",
            "title": "Agentic Reinforced Policy Optimization",
            "url": "https://huggingface.co/papers/2507.19849",
            "abstract": "Agentic Reinforced Policy Optimization (ARPO) is a novel RL algorithm that enhances multi-turn LLM-based agents by adaptive uncertainty management and advantage attribution, outperforming trajectory-level RL algorithms with reduced resource usage.  \t\t\t\t\tAI-generated summary \t\t\t\t Large-scale reinforcement learning with verifiable rewards (RLVR) has demonstrated its effectiveness in harnessing the potential of large language models (LLMs) for single-turn reasoning tasks. In realistic reasoning scenarios, LLMs can often utilize external tools to assist in task-solving processes. However, current RL algorithms inadequately balance the models' intrinsic long-horizon reasoning capabilities and their proficiency in multi-turn tool interactions. To bridge this gap, we propose Agentic Reinforced Policy Optimization (ARPO), a novel agentic RL algorithm tailored for training multi-turn LLM-based agents. Through preliminary experiments, we observe that LLMs tend to exhibit highly uncertain behavior, characterized by an increase in the entropy distribution of generated tokens, immediately following interactions with external tools. Motivated by this observation, ARPO incorporates an entropy-based adaptive rollout mechanism, dynamically balancing global trajectory sampling and step-level sampling, thereby promoting exploration at steps with high uncertainty after tool usage. By integrating an advantage attribution estimation, ARPO enables LLMs to internalize advantage differences in stepwise tool-use interactions. Our experiments across 13 challenging benchmarks in computational reasoning, knowledge reasoning, and deep search domains demonstrate ARPO's superiority over trajectory-level RL algorithms. Remarkably, ARPO achieves improved performance using only half of the tool-use budget required by existing methods, offering a scalable solution for aligning LLM-based agents with real-time dynamic environments. Our code and datasets are released at https://github.com/dongguanting/ARPO",
            "score": 67,
            "issue_id": 5058,
            "pub_date": "2025-07-26",
            "pub_date_card": {
                "ru": "26 Ğ¸ÑĞ»Ñ",
                "en": "July 26",
                "zh": "7æœˆ26æ—¥"
            },
            "hash": "a8b71350a642e881",
            "authors": [
                "Guanting Dong",
                "Hangyu Mao",
                "Kai Ma",
                "Licheng Bao",
                "Yifei Chen",
                "Zhongyuan Wang",
                "Zhongxia Chen",
                "Jiazhen Du",
                "Huiyang Wang",
                "Fuzheng Zhang",
                "Guorui Zhou",
                "Yutao Zhu",
                "Ji-Rong Wen",
                "Zhicheng Dou"
            ],
            "affiliations": [
                "Kuaishou Technology",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.19849.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#agi",
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ARPO: Ğ£Ğ¼Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡",
                    "desc": "ARPO - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸. ARPO Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ RL Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¿Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ². ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ» Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° 13 ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°."
                },
                "en": {
                    "title": "Enhancing Multi-Turn LLMs with Adaptive Uncertainty Management",
                    "desc": "Agentic Reinforced Policy Optimization (ARPO) is a new reinforcement learning (RL) algorithm designed to improve multi-turn interactions of large language models (LLMs) by managing uncertainty and attributing advantages effectively. It addresses the limitations of existing RL methods that struggle with balancing long-term reasoning and tool interactions in realistic scenarios. ARPO uses an adaptive rollout mechanism that adjusts sampling strategies based on the uncertainty observed after using external tools, promoting better exploration. Experimental results show that ARPO outperforms traditional trajectory-level RL algorithms while using significantly fewer resources, making it a more efficient choice for training LLM-based agents in dynamic environments."
                },
                "zh": {
                    "title": "ARPOï¼šæå‡å¤šè½®æ™ºèƒ½ä½“çš„å¼ºåŒ–å­¦ä¹ æ–°æ–¹æ³•",
                    "desc": "Agentic Reinforced Policy Optimizationï¼ˆARPOï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨é€šè¿‡è‡ªé€‚åº”ä¸ç¡®å®šæ€§ç®¡ç†å’Œä¼˜åŠ¿å½’å› æ¥å¢å¼ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šè½®æ™ºèƒ½ä½“ã€‚è¯¥ç®—æ³•åœ¨èµ„æºä½¿ç”¨å‡å°‘çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„è½¨è¿¹çº§å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚ARPOé€šè¿‡åŠ¨æ€å¹³è¡¡å…¨å±€è½¨è¿¹é‡‡æ ·å’Œæ­¥çº§é‡‡æ ·ï¼Œä¿ƒè¿›åœ¨å·¥å…·ä½¿ç”¨åé«˜ä¸ç¡®å®šæ€§æ­¥éª¤çš„æ¢ç´¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARPOåœ¨è®¡ç®—æ¨ç†ã€çŸ¥è¯†æ¨ç†å’Œæ·±åº¦æœç´¢ç­‰13ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œä¸”ä»…éœ€ç°æœ‰æ–¹æ³•ä¸€åŠçš„å·¥å…·ä½¿ç”¨é¢„ç®—ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20939",
            "title": "ARC-Hunyuan-Video-7B: Structured Video Comprehension of Real-World\n  Shorts",
            "url": "https://huggingface.co/papers/2507.20939",
            "abstract": "A multimodal model that processes visual, audio, and textual signals for structured comprehension of real-world short videos improves video search, recommendation, and engagement.  \t\t\t\t\tAI-generated summary \t\t\t\t Real-world user-generated short videos, especially those distributed on platforms such as WeChat Channel and TikTok, dominate the mobile internet. However, current large multimodal models lack essential temporally-structured, detailed, and in-depth video comprehension capabilities, which are the cornerstone of effective video search and recommendation, as well as emerging video applications. Understanding real-world shorts is actually challenging due to their complex visual elements, high information density in both visuals and audio, and fast pacing that focuses on emotional expression and viewpoint delivery. This requires advanced reasoning to effectively integrate multimodal information, including visual, audio, and text. In this work, we introduce ARC-Hunyuan-Video, a multimodal model that processes visual, audio, and textual signals from raw video inputs end-to-end for structured comprehension. The model is capable of multi-granularity timestamped video captioning and summarization, open-ended video question answering, temporal video grounding, and video reasoning. Leveraging high-quality data from an automated annotation pipeline, our compact 7B-parameter model is trained through a comprehensive regimen: pre-training, instruction fine-tuning, cold start, reinforcement learning (RL) post-training, and final instruction fine-tuning. Quantitative evaluations on our introduced benchmark ShortVid-Bench and qualitative comparisons demonstrate its strong performance in real-world video comprehension, and it supports zero-shot or fine-tuning with a few samples for diverse downstream applications. The real-world production deployment of our model has yielded tangible and measurable improvements in user engagement and satisfaction, a success supported by its remarkable efficiency, with stress tests indicating an inference time of just 10 seconds for a one-minute video on H20 GPU.",
            "score": 44,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "6531c472054cd026",
            "authors": [
                "Yuying Ge",
                "Yixiao Ge",
                "Chen Li",
                "Teng Wang",
                "Junfu Pu",
                "Yizhuo Li",
                "Lu Qiu",
                "Jin Ma",
                "Lisheng Duan",
                "Xinyu Zuo",
                "Jinwen Luo",
                "Weibo Gu",
                "Zexuan Li",
                "Xiaojing Zhang",
                "Yangyu Tao",
                "Han Hu",
                "Di Wang",
                "Ying Shan"
            ],
            "affiliations": [
                "ARC Lab, Tencent PCG",
                "Big Data Platform Department, Tencent PCG",
                "Search Application Department, Tencent CSIG",
                "Tencent Hunyuan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20939.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#video",
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#multimodal",
                    "#benchmark"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "ĞœÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ˜Ğ˜ Ğ´Ğ»Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾",
                    "desc": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ ARC-Hunyuan-Video Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾. ĞĞ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ, Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ¸, Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑÑ…, Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ²Ğ¾Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²Ğ¸Ğ´ĞµĞ¾."
                },
                "en": {
                    "title": "Revolutionizing Video Comprehension with Multimodal AI",
                    "desc": "This paper presents ARC-Hunyuan-Video, a multimodal model designed to enhance the understanding of short videos by integrating visual, audio, and textual information. The model addresses the challenges of complex video content and fast pacing, enabling structured comprehension through advanced reasoning techniques. It offers capabilities such as timestamped video captioning, summarization, and open-ended question answering, making it suitable for various applications. The model's efficient training process and real-world deployment have shown significant improvements in user engagement and satisfaction."
                },
                "zh": {
                    "title": "å¤šæ¨¡æ€æ¨¡å‹æå‡çŸ­è§†é¢‘ç†è§£ä¸æ¨è",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºARC-Hunyuan-Videoçš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†è§†é¢‘ä¸­çš„è§†è§‰ã€éŸ³é¢‘å’Œæ–‡æœ¬ä¿¡å·ï¼Œä»¥å®ç°å¯¹çŸ­è§†é¢‘çš„ç»“æ„åŒ–ç†è§£ã€‚è¯¥æ¨¡å‹å…·å¤‡å¤šç²’åº¦çš„æ—¶é—´æˆ³è§†é¢‘å­—å¹•ç”Ÿæˆã€è§†é¢‘é—®ç­”ã€æ—¶é—´è§†é¢‘å®šä½å’Œè§†é¢‘æ¨ç†ç­‰åŠŸèƒ½ã€‚é€šè¿‡é«˜è´¨é‡çš„æ•°æ®å’Œå¤šé˜¶æ®µçš„è®­ç»ƒæµç¨‹ï¼Œè¯¥æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œè§†é¢‘ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¹¶åœ¨ç”¨æˆ·å‚ä¸åº¦å’Œæ»¡æ„åº¦ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚å…¶é«˜æ•ˆçš„æ¨ç†èƒ½åŠ›ä½¿å¾—åœ¨H20 GPUä¸Šå¤„ç†ä¸€æ®µä¸€åˆ†é’Ÿçš„è§†é¢‘ä»…éœ€10ç§’ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.21049",
            "title": "Rep-MTL: Unleashing the Power of Representation-level Task Saliency for\n  Multi-Task Learning",
            "url": "https://huggingface.co/papers/2507.21049",
            "abstract": "Rep-MTL optimizes multi-task learning by leveraging task saliency in shared representations to promote complementarity and reduce negative transfer.  \t\t\t\t\tAI-generated summary \t\t\t\t Despite the promise of Multi-Task Learning in leveraging complementary knowledge across tasks, existing multi-task optimization (MTO) techniques remain fixated on resolving conflicts via optimizer-centric loss scaling and gradient manipulation strategies, yet fail to deliver consistent gains. In this paper, we argue that the shared representation space, where task interactions naturally occur, offers rich information and potential for operations complementary to existing optimizers, especially for facilitating the inter-task complementarity, which is rarely explored in MTO. This intuition leads to Rep-MTL, which exploits the representation-level task saliency to quantify interactions between task-specific optimization and shared representation learning. By steering these saliencies through entropy-based penalization and sample-wise cross-task alignment, Rep-MTL aims to mitigate negative transfer by maintaining the effective training of individual tasks instead pure conflict-solving, while explicitly promoting complementary information sharing. Experiments are conducted on four challenging MTL benchmarks covering both task-shift and domain-shift scenarios. The results show that Rep-MTL, even paired with the basic equal weighting policy, achieves competitive performance gains with favorable efficiency. Beyond standard performance metrics, Power Law exponent analysis demonstrates Rep-MTL's efficacy in balancing task-specific learning and cross-task sharing. The project page is available at HERE.",
            "score": 29,
            "issue_id": 5059,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "c419c0691a4c6b57",
            "authors": [
                "Zedong Wang",
                "Siyuan Li",
                "Dan Xu"
            ],
            "affiliations": [
                "The Hong Kong University of Science and Technology",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.21049.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#transfer_learning",
                    "#training",
                    "#benchmark"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ÑÑ…",
                    "desc": "Rep-MTL - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ´Ğ»Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ÑĞ¼. Rep-MTL Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¹Ğ½ÑƒÑ Ğ¿ĞµĞ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ°Ğ¼ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ñ‡ĞµÑ‚Ñ‹Ñ€ĞµÑ… ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Rep-MTL Ğ² Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼ Ğ¸ Ğ¾Ğ±Ğ¼ĞµĞ½Ğ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ½Ğ¸Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Enhancing Multi-Task Learning through Task Saliency",
                    "desc": "Rep-MTL is a novel approach to multi-task learning (MTL) that focuses on improving task interactions by utilizing task saliency in shared representations. Unlike traditional methods that primarily address conflicts through loss scaling and gradient adjustments, Rep-MTL emphasizes the importance of complementarity between tasks. It employs entropy-based penalization and cross-task alignment to reduce negative transfer while enhancing the learning of individual tasks. Experimental results on various benchmarks indicate that Rep-MTL not only improves performance but also maintains efficiency in training across multiple tasks."
                },
                "zh": {
                    "title": "Rep-MTLï¼šä¼˜åŒ–å¤šä»»åŠ¡å­¦ä¹ çš„äº’è¡¥æ€§",
                    "desc": "Rep-MTLæ˜¯ä¸€ç§ä¼˜åŒ–å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨ä»»åŠ¡æ˜¾è‘—æ€§æ¥ä¿ƒè¿›ä»»åŠ¡ä¹‹é—´çš„äº’è¡¥æ€§ï¼Œå‡å°‘è´Ÿè¿ç§»ã€‚ç°æœ‰çš„å¤šä»»åŠ¡ä¼˜åŒ–æŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨é€šè¿‡æŸå¤±ç¼©æ”¾å’Œæ¢¯åº¦æ“ä½œæ¥è§£å†³ä»»åŠ¡å†²çªï¼Œä½†æ•ˆæœå¹¶ä¸ç†æƒ³ã€‚æœ¬æ–‡æå‡ºçš„Rep-MTLåˆ©ç”¨å…±äº«è¡¨ç¤ºç©ºé—´ä¸­çš„ä»»åŠ¡äº¤äº’ä¿¡æ¯ï¼Œé‡åŒ–ä»»åŠ¡ç‰¹å®šä¼˜åŒ–ä¸å…±äº«è¡¨ç¤ºå­¦ä¹ ä¹‹é—´çš„å…³ç³»ã€‚é€šè¿‡ç†µæƒ©ç½šå’Œæ ·æœ¬çº§è·¨ä»»åŠ¡å¯¹é½ï¼ŒRep-MTLæ—¨åœ¨æœ‰æ•ˆè®­ç»ƒå„ä¸ªä»»åŠ¡ï¼ŒåŒæ—¶ä¿ƒè¿›äº’è¡¥ä¿¡æ¯çš„å…±äº«ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20984",
            "title": "SmallThinker: A Family of Efficient Large Language Models Natively\n  Trained for Local Deployment",
            "url": "https://huggingface.co/papers/2507.20984",
            "abstract": "SmallThinker, designed for localdevices with limited resources, uses advanced architectural innovations to achieve high performance without requiring GPU hardware.  \t\t\t\t\tAI-generated summary \t\t\t\t While frontier large language models (LLMs) continue to push capability boundaries, their deployment remains confined to GPU-powered cloud infrastructure. We challenge this paradigm with SmallThinker, a family of LLMs natively designed - not adapted - for the unique constraints of local devices: weak computational power, limited memory, and slow storage. Unlike traditional approaches that mainly compress existing models built for clouds, we architect SmallThinker from the ground up to thrive within these limitations. Our innovation lies in a deployment-aware architecture that transforms constraints into design principles. First, We introduce a two-level sparse structure combining fine-grained Mixture-of-Experts (MoE) with sparse feed-forward networks, drastically reducing computational demands without sacrificing model capacity. Second, to conquer the I/O bottleneck of slow storage, we design a pre-attention router that enables our co-designed inference engine to prefetch expert parameters from storage while computing attention, effectively hiding storage latency that would otherwise cripple on-device inference. Third, for memory efficiency, we utilize NoPE-RoPE hybrid sparse attention mechanism to slash KV cache requirements. We release SmallThinker-4B-A0.6B and SmallThinker-21B-A3B, which achieve state-of-the-art performance scores and even outperform larger LLMs. Remarkably, our co-designed system mostly eliminates the need for expensive GPU hardware: with Q4_0 quantization, both models exceed 20 tokens/s on ordinary consumer CPUs, while consuming only 1GB and 8GB of memory respectively. SmallThinker is publicly available at hf.co/PowerInfer/SmallThinker-4BA0.6B-Instruct and hf.co/PowerInfer/SmallThinker-21BA3B-Instruct.",
            "score": 26,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "1a02f43842725db8",
            "authors": [
                "Yixin Song",
                "Zhenliang Xue",
                "Dongliang Wei",
                "Feiyang Chen",
                "Jianxiang Gao",
                "Junchen Liu",
                "Hangyu Liang",
                "Guangshuo Qin",
                "Chengrong Tian",
                "Bo Wen",
                "Longyu Zhao",
                "Xinrui Zheng",
                "Zeyu Mi",
                "Haibo Chen"
            ],
            "affiliations": [
                "Institute of Parallel and Distributed Systems, Shanghai Jiao Tong University",
                "School of Artificial Intelligence, Shanghai Jiao Tong University",
                "Zenergize AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20984.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#open_source",
                    "#training",
                    "#optimization",
                    "#low_resource",
                    "#inference",
                    "#small_models"
                ],
                "emoji": "ğŸ’¡",
                "ru": {
                    "title": "SmallThinker: ĞœĞ¾Ñ‰Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ÑĞ»Ğ°Ğ±Ñ‹Ñ… ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²",
                    "desc": "SmallThinker - ÑÑ‚Ğ¾ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ² Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ÑƒÑ Ğ´Ğ²ÑƒÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²ÑƒÑ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ñ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸ĞµĞ¹ Mixture-of-Experts Ğ¸ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ñ‹Ñ… ÑĞ»Ğ¾ĞµĞ². SmallThinker Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ NoPE-RoPE Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸. Ğ‘Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ ÑÑ‚Ğ¸Ğ¼ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸ÑĞ¼, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ SmallThinker Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ñ… CPU Ğ±ĞµĞ· Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ² GPU."
                },
                "en": {
                    "title": "Empowering Local Devices with Efficient LLMs",
                    "desc": "SmallThinker is a new family of large language models (LLMs) specifically designed for local devices with limited resources, such as low computational power and memory. Unlike traditional models that are adapted for cloud environments, SmallThinker is built from the ground up to operate efficiently within these constraints. It employs a two-level sparse structure that combines Mixture-of-Experts (MoE) with sparse feed-forward networks to minimize computational demands while maintaining model performance. Additionally, it features a pre-attention router to manage slow storage access and a hybrid sparse attention mechanism to reduce memory usage, allowing it to achieve high performance without the need for expensive GPU hardware."
                },
                "zh": {
                    "title": "å°è®¾å¤‡ä¸Šçš„å¤§è¯­è¨€æ¨¡å‹é©å‘½",
                    "desc": "SmallThinkeræ˜¯ä¸€ç§ä¸“ä¸ºèµ„æºæœ‰é™çš„æœ¬åœ°è®¾å¤‡è®¾è®¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå®ƒé€šè¿‡å…ˆè¿›çš„æ¶æ„åˆ›æ–°å®ç°é«˜æ€§èƒ½ï¼Œè€Œæ— éœ€ä¾èµ–GPUç¡¬ä»¶ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒSmallThinkerä»æ ¹æœ¬ä¸Šè€ƒè™‘äº†æœ¬åœ°è®¾å¤‡çš„è®¡ç®—èƒ½åŠ›ã€å†…å­˜å’Œå­˜å‚¨é™åˆ¶ï¼Œé‡‡ç”¨äº†ä¸¤çº§ç¨€ç–ç»“æ„å’Œæ··åˆä¸“å®¶æœºåˆ¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—éœ€æ±‚ã€‚ä¸ºäº†å…‹æœæ…¢å­˜å‚¨å¸¦æ¥çš„I/Oç“¶é¢ˆï¼ŒSmallThinkerè®¾è®¡äº†é¢„æ³¨æ„åŠ›è·¯ç”±å™¨ï¼Œä½¿å¾—åœ¨è®¡ç®—æ³¨æ„åŠ›çš„åŒæ—¶å¯ä»¥é¢„å–ä¸“å®¶å‚æ•°ï¼Œä»è€Œéšè—å­˜å‚¨å»¶è¿Ÿã€‚æœ€ç»ˆï¼ŒSmallThinkeråœ¨æ™®é€šæ¶ˆè´¹è€…CPUä¸Šå®ç°äº†è¶…è¿‡20ä¸ªtoken/sçš„é€Ÿåº¦ï¼Œä¸”å†…å­˜æ¶ˆè€—ä»…ä¸º1GBå’Œ8GBï¼Œå±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.21045",
            "title": "Reconstructing 4D Spatial Intelligence: A Survey",
            "url": "https://huggingface.co/papers/2507.21045",
            "abstract": "A survey organizes methods for reconstructing 4D spatial intelligence from visual observations into five progressive levels, offering analysis and identifying future research directions.  \t\t\t\t\tAI-generated summary \t\t\t\t Reconstructing 4D spatial intelligence from visual observations has long been a central yet challenging task in computer vision, with broad real-world applications. These range from entertainment domains like movies, where the focus is often on reconstructing fundamental visual elements, to embodied AI, which emphasizes interaction modeling and physical realism. Fueled by rapid advances in 3D representations and deep learning architectures, the field has evolved quickly, outpacing the scope of previous surveys. Additionally, existing surveys rarely offer a comprehensive analysis of the hierarchical structure of 4D scene reconstruction. To address this gap, we present a new perspective that organizes existing methods into five progressive levels of 4D spatial intelligence: (1) Level 1 -- reconstruction of low-level 3D attributes (e.g., depth, pose, and point maps); (2) Level 2 -- reconstruction of 3D scene components (e.g., objects, humans, structures); (3) Level 3 -- reconstruction of 4D dynamic scenes; (4) Level 4 -- modeling of interactions among scene components; and (5) Level 5 -- incorporation of physical laws and constraints. We conclude the survey by discussing the key challenges at each level and highlighting promising directions for advancing toward even richer levels of 4D spatial intelligence. To track ongoing developments, we maintain an up-to-date project page: https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence.",
            "score": 25,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "47424252dbce5de2",
            "authors": [
                "Yukang Cao",
                "Jiahao Lu",
                "Zhisheng Huang",
                "Zhuowei Shen",
                "Chengfeng Zhao",
                "Fangzhou Hong",
                "Zhaoxi Chen",
                "Xin Li",
                "Wenping Wang",
                "Yuan Liu",
                "Ziwei Liu"
            ],
            "affiliations": [
                "Intelligent Graphics Lab, The Hong Kong University of Science and Technology",
                "S-Lab, College of Computing and Data Science, Nanyang Technological University, Singapore 639798",
                "Texas A&M University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.21045.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#3d",
                    "#cv",
                    "#multimodal"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞÑ‚ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹ Ğº Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ: Ğ¿ÑƒÑ‚ÑŒ Ğº 4D Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ñƒ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ğ±Ğ·Ğ¾Ñ€ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ 4D Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ¸Ğ· Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¹, Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ğ¿ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ñ‹Ñ… ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ¾Ñ‚ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… 3D Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ² Ğ¸ Ğ·Ğ°ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¸ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ². ĞĞ±Ğ·Ğ¾Ñ€ Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ ÑĞ¿ĞµĞºÑ‚Ñ€ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ - Ğ¾Ñ‚ Ñ€Ğ°Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ¾ Ğ²Ğ¾Ğ¿Ğ»Ğ¾Ñ‰ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜. Ğ’ Ğ·Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ÑÑ‚ÑÑ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¸ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Progressing Through 4D Spatial Intelligence: A Structured Approach",
                    "desc": "This paper surveys methods for reconstructing 4D spatial intelligence from visual data, categorizing them into five progressive levels. The levels range from basic 3D attribute reconstruction to complex modeling of interactions and physical laws. It highlights the rapid advancements in deep learning and 3D representations that have propelled the field forward. The authors also identify key challenges and future research directions to enhance 4D scene reconstruction."
                },
                "zh": {
                    "title": "é‡å»º4Dç©ºé—´æ™ºèƒ½çš„äº”ä¸ªå±‚æ¬¡",
                    "desc": "æœ¬è®ºæ–‡å¯¹ä»è§†è§‰è§‚å¯Ÿä¸­é‡å»º4Dç©ºé—´æ™ºèƒ½çš„æ–¹æ³•è¿›è¡Œäº†è°ƒæŸ¥ï¼Œå¹¶å°†å…¶ç»„ç»‡ä¸ºäº”ä¸ªé€æ­¥å‘å±•çš„å±‚æ¬¡ã€‚ç ”ç©¶æ¶µç›–äº†ä»ä½çº§3Då±æ€§é‡å»ºåˆ°åŠ¨æ€åœºæ™¯å»ºæ¨¡çš„å„ä¸ªæ–¹é¢ï¼Œå¼ºè°ƒäº†åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦æ€§å’Œåº”ç”¨ã€‚éšç€3Dè¡¨ç¤ºå’Œæ·±åº¦å­¦ä¹ æ¶æ„çš„å¿«é€Ÿå‘å±•ï¼Œè¯¥é¢†åŸŸè¿…é€Ÿæ¼”å˜ï¼Œè¶…è¶Šäº†ä»¥å¾€çš„ç ”ç©¶èŒƒå›´ã€‚æœ€åï¼Œè®ºæ–‡è®¨è®ºäº†æ¯ä¸ªå±‚æ¬¡çš„å…³é”®æŒ‘æˆ˜ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶çš„æœ‰å¸Œæœ›æ–¹å‘ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.21046",
            "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super\n  Intelligence",
            "url": "https://huggingface.co/papers/2507.21046",
            "abstract": "This survey reviews architectures and methods for self-evolving agents in continual learning environments, examining different components, adaptation stages, and design considerations.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have demonstrated strong capabilities but remain fundamentally static, unable to adapt their internal parameters to novel tasks, evolving knowledge domains, or dynamic interaction contexts. As LLMs are increasingly deployed in open-ended, interactive environments, this static nature has become a critical bottleneck, necessitating agents that can adaptively reason, act, and evolve in real time. This paradigm shift -- from scaling static models to developing self-evolving agents -- has sparked growing interest in architectures and methods enabling continual learning and adaptation from data, interactions, and experiences. This survey provides the first systematic and comprehensive review of self-evolving agents, organized around three foundational dimensions -- what to evolve, when to evolve, and how to evolve. We examine evolutionary mechanisms across agent components (e.g., models, memory, tools, architecture), categorize adaptation methods by stages (e.g., intra-test-time, inter-test-time), and analyze the algorithmic and architectural designs that guide evolutionary adaptation (e.g., scalar rewards, textual feedback, single-agent and multi-agent systems). Additionally, we analyze evaluation metrics and benchmarks tailored for self-evolving agents, highlight applications in domains such as coding, education, and healthcare, and identify critical challenges and research directions in safety, scalability, and co-evolutionary dynamics. By providing a structured framework for understanding and designing self-evolving agents, this survey establishes a roadmap for advancing adaptive agentic systems in both research and real-world deployments, ultimately shedding lights to pave the way for the realization of Artificial Super Intelligence (ASI), where agents evolve autonomously, performing at or beyond human-level intelligence across a wide array of tasks.",
            "score": 21,
            "issue_id": 5062,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "b14049ba15e033a3",
            "authors": [
                "Huan-ang Gao",
                "Jiayi Geng",
                "Wenyue Hua",
                "Mengkang Hu",
                "Xinzhe Juan",
                "Hongzhang Liu",
                "Shilong Liu",
                "Jiahao Qiu",
                "Xuan Qi",
                "Yiran Wu",
                "Hongru Wang",
                "Han Xiao",
                "Yuhang Zhou",
                "Shaokun Zhang",
                "Jiayi Zhang",
                "Jinyu Xiang",
                "Yixiong Fang",
                "Qiwen Zhao",
                "Dongrui Liu",
                "Qihan Ren",
                "Cheng Qian",
                "Zhenghailong Wang",
                "Minda Hu",
                "Huazheng Wang",
                "Qingyun Wu",
                "Heng Ji",
                "Mengdi Wang"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Fudan University",
                "Oregon State University",
                "Pennsylvania State University",
                "Princeton AI Lab",
                "Princeton University",
                "Shanghai Jiao Tong University",
                "The Chinese University of Hong Kong",
                "The Hong Kong University of Science and Technology (Guangzhou)",
                "The University of Hong Kong",
                "Tsinghua University",
                "University of California San Diego",
                "University of California, Santa Barbara",
                "University of Illinois Urbana-Champaign",
                "University of Michigan",
                "University of Sydney"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.21046.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#agents",
                    "#healthcare",
                    "#benchmark",
                    "#training",
                    "#agi",
                    "#reasoning"
                ],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "ĞÑ‚ ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº ÑĞ°Ğ¼Ğ¾ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼: Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ğ° Ğ˜Ğ˜",
                    "desc": "Ğ­Ñ‚Ğ¾Ñ‚ Ğ¾Ğ±Ğ·Ğ¾Ñ€ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ´Ğ»Ñ ÑĞ°Ğ¼Ğ¾ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ÑÑ€ĞµĞ´Ğ°Ñ… Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹, ÑÑ‚Ğ°Ğ¿Ñ‹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ°ĞºĞ¸Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². ĞÑĞ¾Ğ±Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ÑƒĞ´ĞµĞ»ÑĞµÑ‚ÑÑ Ñ‚Ñ€ĞµĞ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸ÑĞ¼: Ñ‡Ñ‚Ğ¾ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒĞµÑ‚, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ¸ ĞºĞ°Ğº Ğ¾Ğ½Ğ° Ğ¾ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ»ÑĞµÑ‚ÑÑ. ĞĞ±Ğ·Ğ¾Ñ€ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ğ³Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ ÑĞ°Ğ¼Ğ¾ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Empowering Agents: The Future of Self-Evolving Intelligence",
                    "desc": "This paper surveys the development of self-evolving agents that can learn continuously in dynamic environments. It highlights the limitations of current large language models (LLMs) which are static and cannot adapt to new tasks or contexts. The authors categorize the evolution of agents based on what, when, and how they adapt, examining various components and methods for continual learning. The survey also discusses evaluation metrics and applications in fields like coding and healthcare, aiming to guide future research towards creating more adaptive and intelligent systems."
                },
                "zh": {
                    "title": "è‡ªæˆ‘è¿›åŒ–ä»£ç†ï¼šæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„æœªæ¥",
                    "desc": "è¿™ç¯‡ç»¼è¿°æ–‡ç« æ¢è®¨äº†è‡ªæˆ‘è¿›åŒ–ä»£ç†åœ¨æŒç»­å­¦ä¹ ç¯å¢ƒä¸­çš„æ¶æ„å’Œæ–¹æ³•ã€‚æ–‡ç« åˆ†æäº†ä¸åŒçš„ç»„æˆéƒ¨åˆ†ã€é€‚åº”é˜¶æ®µå’Œè®¾è®¡è€ƒè™‘å› ç´ ï¼Œå¼ºè°ƒäº†ä»é™æ€æ¨¡å‹å‘è‡ªæˆ‘è¿›åŒ–ä»£ç†çš„è½¬å˜ã€‚è‡ªæˆ‘è¿›åŒ–ä»£ç†èƒ½å¤Ÿå®æ—¶é€‚åº”æ–°ä»»åŠ¡å’ŒåŠ¨æ€ç¯å¢ƒï¼Œè§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¼€æ”¾å¼äº¤äº’ç¯å¢ƒä¸­çš„å±€é™æ€§ã€‚é€šè¿‡æä¾›ä¸€ä¸ªç»“æ„åŒ–çš„æ¡†æ¶ï¼Œæ–‡ç« ä¸ºç†è§£å’Œè®¾è®¡è‡ªæˆ‘è¿›åŒ–ä»£ç†å¥ å®šäº†åŸºç¡€ï¼Œæ¨åŠ¨äº†è‡ªé€‚åº”ç³»ç»Ÿçš„ç ”ç©¶å’Œå®é™…åº”ç”¨ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20673",
            "title": "Geometric-Mean Policy Optimization",
            "url": "https://huggingface.co/papers/2507.20673",
            "abstract": "Geometric-Mean Policy Optimization (GMPO) stabilizes policy updates in large language models by maximizing the geometric mean of token-level rewards, improving performance on mathematical and multimodal reasoning benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advancements, such as Group Relative Policy Optimization (GRPO), have enhanced the reasoning capabilities of large language models by optimizing the arithmetic mean of token-level rewards. However, GRPO suffers from unstable policy updates when processing tokens with outlier importance-weighted rewards, which manifests as extreme importance sampling ratios during training, i.e., the ratio between the sampling probabilities assigned to a token by the current and old policies. In this work, we propose Geometric-Mean Policy Optimization (GMPO), a stabilized variant of GRPO. Instead of optimizing the arithmetic mean, GMPO maximizes the geometric mean of token-level rewards, which is inherently less sensitive to outliers and maintains a more stable range of importance sampling ratio. In addition, we provide comprehensive theoretical and experimental analysis to justify the design and stability benefits of GMPO. Beyond improved stability, GMPO-7B outperforms GRPO by an average of 4.1% on multiple mathematical benchmarks and 1.4% on multimodal reasoning benchmark, including AIME24, AMC, MATH500, OlympiadBench, Minerva, and Geometry3K. Code is available at https://github.com/callsys/GMPO.",
            "score": 15,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "44c96360ea6066e6",
            "authors": [
                "Yuzhong Zhao",
                "Yue Liu",
                "Junpeng Liu",
                "Jingye Chen",
                "Xun Wu",
                "Yaru Hao",
                "Tengchao Lv",
                "Shaohan Huang",
                "Lei Cui",
                "Qixiang Ye",
                "Fang Wan",
                "Furu Wei"
            ],
            "affiliations": [
                "CUHK",
                "HKUST",
                "Microsoft Research",
                "UCAS"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20673.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#math",
                    "#rl",
                    "#reasoning",
                    "#multimodal"
                ],
                "emoji": "ğŸ“Š",
                "ru": {
                    "title": "Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑƒÑÑ€ĞµĞ´Ğ½ĞµĞ½Ğ¸Ğµ",
                    "desc": "Ğ“ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ (GMPO) ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½-ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ñ… Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼ GRPO, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑÑ‚Ñ€Ğ°Ğ´Ğ°Ğ» Ğ¾Ñ‚ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ñ Ğ²Ñ‹Ğ±Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ² Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°Ñ…. GMPO Ğ¼ĞµĞ½ĞµĞµ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ĞµĞ½ Ğº Ğ²Ñ‹Ğ±Ñ€Ğ¾ÑĞ°Ğ¼ Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ½Ğ° 4.1% Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ğ¸ Ğ½Ğ° 1.4% Ğ½Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Stabilizing Policy Updates with Geometric-Mean Optimization",
                    "desc": "Geometric-Mean Policy Optimization (GMPO) is a new method that enhances the stability of policy updates in large language models by focusing on the geometric mean of token-level rewards. This approach addresses the issues faced by previous methods like Group Relative Policy Optimization (GRPO), which can become unstable due to outlier rewards. By using the geometric mean, GMPO reduces sensitivity to extreme values, leading to more consistent training outcomes. Experimental results show that GMPO outperforms GRPO on various mathematical and multimodal reasoning tasks, demonstrating its effectiveness in improving model performance."
                },
                "zh": {
                    "title": "å‡ ä½•å‡å€¼ä¼˜åŒ–ï¼Œç¨³å®šç­–ç•¥æ›´æ–°ï¼",
                    "desc": "å‡ ä½•å‡å€¼ç­–ç•¥ä¼˜åŒ–ï¼ˆGMPOï¼‰é€šè¿‡æœ€å¤§åŒ–ä»¤ç‰Œçº§å¥–åŠ±çš„å‡ ä½•å‡å€¼æ¥ç¨³å®šå¤§å‹è¯­è¨€æ¨¡å‹çš„ç­–ç•¥æ›´æ–°ï¼Œä»è€Œæé«˜åœ¨æ•°å­¦å’Œå¤šæ¨¡æ€æ¨ç†åŸºå‡†ä¸Šçš„è¡¨ç°ã€‚ä¸ç®—æœ¯å‡å€¼ä¼˜åŒ–çš„ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ç›¸æ¯”ï¼ŒGMPOå¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿæ€§æ›´ä½ï¼Œèƒ½å¤Ÿä¿æŒæ›´ç¨³å®šçš„é‡è¦æ€§é‡‡æ ·æ¯”ã€‚æœ¬æ–‡æä¾›äº†å…¨é¢çš„ç†è®ºå’Œå®éªŒåˆ†æï¼Œä»¥è¯æ˜GMPOçš„è®¾è®¡å’Œç¨³å®šæ€§ä¼˜åŠ¿ã€‚GMPO-7Båœ¨å¤šä¸ªæ•°å­¦åŸºå‡†ä¸Šå¹³å‡è¶…è¶ŠGRPO 4.1%ï¼Œåœ¨å¤šæ¨¡æ€æ¨ç†åŸºå‡†ä¸Šè¶…è¶Š1.4%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.21033",
            "title": "GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset",
            "url": "https://huggingface.co/papers/2507.21033",
            "abstract": "Recent advancements in large multimodal models like GPT-4o have set a new standard for high-fidelity, instruction-guided image editing. However, the proprietary nature of these models and their training data creates a significant barrier for open-source research. To bridge this gap, we introduce GPT-IMAGE-EDIT-1.5M, a publicly available, large-scale image-editing corpus containing more than 1.5 million high-quality triplets (instruction, source image, edited image). We systematically construct this dataset by leveraging the versatile capabilities of GPT-4o to unify and refine three popular image-editing datasets: OmniEdit, HQ-Edit, and UltraEdit. Specifically, our methodology involves 1) regenerating output images to enhance visual quality and instruction alignment, and 2) selectively rewriting prompts to improve semantic clarity. To validate the efficacy of our dataset, we fine-tune advanced open-source models on GPT-IMAGE-EDIT-1.5M. The empirical results are exciting, e.g., the fine-tuned FluxKontext achieves highly competitive performance across a comprehensive suite of benchmarks, including 7.24 on GEdit-EN, 3.80 on ImgEdit-Full, and 8.78 on Complex-Edit, showing stronger instruction following and higher perceptual quality while maintaining identity. These scores markedly exceed all previously published open-source methods and substantially narrow the gap to leading proprietary models. We hope the full release of GPT-IMAGE-EDIT-1.5M can help to catalyze further open research in instruction-guided image editing.",
            "score": 13,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "7ce17dfe6eea7e71",
            "authors": [
                "Yuhan Wang",
                "Siwei Yang",
                "Bingchen Zhao",
                "Letian Zhang",
                "Qing Liu",
                "Yuyin Zhou",
                "Cihang Xie"
            ],
            "affiliations": [
                "Adobe",
                "The University of Edinburgh",
                "University of California, Santa Cruz"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.21033.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#cv",
                    "#open_source",
                    "#dataset"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ²Ğ° Ğ² Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ¾Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ GPT-IMAGE-EDIT-1.5M - Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ğ¾ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ Ğ±Ğ¾Ğ»ĞµĞµ 1,5 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ¸Ğ¿Ğ»ĞµÑ‚Ğ¾Ğ² (Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ, Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ, Ğ¾Ñ‚Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ). ĞĞ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ‚Ñ€ĞµÑ… Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ² Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ GPT-4o. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ»Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° GPT-IMAGE-EDIT-1.5M, Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ² Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ FluxKontext Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ»Ğ° ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ½Ğ°Ğ´ĞµÑÑ‚ÑÑ, Ñ‡Ñ‚Ğ¾ Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ¿ÑƒÑĞº GPT-IMAGE-EDIT-1.5M Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ¸Ğ¼ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ´ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Empowering Open-Source Image Editing with GPT-IMAGE-EDIT-1.5M",
                    "desc": "This paper presents GPT-IMAGE-EDIT-1.5M, a large-scale, open-source dataset designed for instruction-guided image editing. It consists of over 1.5 million triplets of instructions, source images, and edited images, created by enhancing existing datasets using the capabilities of GPT-4o. The authors demonstrate that fine-tuning open-source models on this dataset leads to significant improvements in performance, surpassing previous methods and approaching the quality of proprietary models. The goal is to promote further research in the field by providing accessible resources for the community."
                },
                "zh": {
                    "title": "æ¨åŠ¨å¼€æºå›¾åƒç¼–è¾‘çš„æ–°é‡Œç¨‹ç¢‘",
                    "desc": "æœ€è¿‘å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å¦‚GPT-4oåœ¨é«˜ä¿çœŸã€æŒ‡ä»¤å¼•å¯¼çš„å›¾åƒç¼–è¾‘æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„ä¸“æœ‰æ€§è´¨å’Œè®­ç»ƒæ•°æ®å¯¹å¼€æºç ”ç©¶æ„æˆäº†é‡å¤§éšœç¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†GPT-IMAGE-EDIT-1.5Mï¼Œè¿™æ˜¯ä¸€ä¸ªå…¬å¼€å¯ç”¨çš„å¤§è§„æ¨¡å›¾åƒç¼–è¾‘æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡150ä¸‡ä¸ªé«˜è´¨é‡çš„ä¸‰å…ƒç»„ï¼ˆæŒ‡ä»¤ã€æºå›¾åƒã€ç¼–è¾‘å›¾åƒï¼‰ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨GPT-4oçš„å¤šåŠŸèƒ½èƒ½åŠ›ï¼Œç³»ç»Ÿæ€§åœ°æ„å»ºäº†è¿™ä¸ªæ•°æ®é›†ï¼Œä»¥ç»Ÿä¸€å’Œä¼˜åŒ–ä¸‰ä¸ªæµè¡Œçš„å›¾åƒç¼–è¾‘æ•°æ®é›†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20025",
            "title": "Region-based Cluster Discrimination for Visual Representation Learning",
            "url": "https://huggingface.co/papers/2507.20025",
            "abstract": "RICE enhances region-level visual and OCR capabilities through a novel Region Transformer and cluster discrimination loss, achieving superior performance across dense prediction and perception tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Learning visual representations is foundational for a broad spectrum of downstream tasks. Although recent vision-language contrastive models, such as CLIP and SigLIP, have achieved impressive zero-shot performance via large-scale vision-language alignment, their reliance on global representations constrains their effectiveness for dense prediction tasks, such as grounding, OCR, and segmentation. To address this gap, we introduce Region-Aware Cluster Discrimination (RICE), a novel method that enhances region-level visual and OCR capabilities. We first construct a billion-scale candidate region dataset and propose a Region Transformer layer to extract rich regional semantics. We further design a unified region cluster discrimination loss that jointly supports object and OCR learning within a single classification framework, enabling efficient and scalable distributed training on large-scale data. Extensive experiments show that RICE consistently outperforms previous methods on tasks, including segmentation, dense detection, and visual perception for Multimodal Large Language Models (MLLMs). The pre-trained models have been released at https://github.com/deepglint/MVT.",
            "score": 12,
            "issue_id": 5058,
            "pub_date": "2025-07-26",
            "pub_date_card": {
                "ru": "26 Ğ¸ÑĞ»Ñ",
                "en": "July 26",
                "zh": "7æœˆ26æ—¥"
            },
            "hash": "f356ee0be3cc35de",
            "authors": [
                "Yin Xie",
                "Kaicheng Yang",
                "Xiang An",
                "Kun Wu",
                "Yongle Zhao",
                "Weimo Deng",
                "Zimin Ran",
                "Yumeng Wang",
                "Ziyong Feng",
                "Roy Miles",
                "Ismail Elezi",
                "Jiankang Deng"
            ],
            "affiliations": [
                "DeepGlint",
                "Huawei London Research Center",
                "Imperial College London",
                "University of Technology Sydney"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20025.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#games",
                    "#dataset",
                    "#training",
                    "#optimization",
                    "#multimodal"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "RICE: ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ",
                    "desc": "RICE - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ Ğ¸ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½Ğ¾Ğ²Ğ°Ñ‚Ğ¾Ñ€ÑĞºĞ¸Ğ¹ Region Transformer Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ¹ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸. RICE Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ¾Ğ³Ñ€Ğ¾Ğ¼Ğ½Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²-Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ ĞµĞ´Ğ¸Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸, Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "RICE: Revolutionizing Region-Level Visual and OCR Learning",
                    "desc": "The paper introduces RICE, a method that improves visual and OCR tasks by focusing on specific regions in images rather than using global representations. It utilizes a Region Transformer to capture detailed regional information and a cluster discrimination loss to enhance learning for both object recognition and OCR in a unified framework. This approach allows for efficient training on large datasets, leading to better performance in tasks like segmentation and dense detection. RICE demonstrates superior results compared to existing models, making it a significant advancement in the field of visual representation learning."
                },
                "zh": {
                    "title": "RICEï¼šæå‡åŒºåŸŸè§†è§‰ä¸OCRèƒ½åŠ›çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "RICEæ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡åŒºåŸŸå˜æ¢å™¨å’Œèšç±»åŒºåˆ†æŸå¤±ï¼Œå¢å¼ºäº†åŒºåŸŸçº§çš„è§†è§‰å’Œå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰èƒ½åŠ›ã€‚è¯¥æ–¹æ³•æ„å»ºäº†ä¸€ä¸ªåäº¿è§„æ¨¡çš„å€™é€‰åŒºåŸŸæ•°æ®é›†ï¼Œå¹¶æå‡ºäº†åŒºåŸŸå˜æ¢å™¨å±‚ï¼Œä»¥æå–ä¸°å¯Œçš„åŒºåŸŸè¯­ä¹‰ã€‚RICEè®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„åŒºåŸŸèšç±»åŒºåˆ†æŸå¤±ï¼Œæ”¯æŒåœ¨å•ä¸€åˆ†ç±»æ¡†æ¶å†…åŒæ—¶è¿›è¡Œç‰©ä½“å’ŒOCRå­¦ä¹ ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRICEåœ¨åˆ†å‰²ã€å¯†é›†æ£€æµ‹å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è§†è§‰æ„ŸçŸ¥ç­‰ä»»åŠ¡ä¸Šï¼Œå§‹ç»ˆä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.19766",
            "title": "UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing\n  Large Language Models' Reasoning Abilities",
            "url": "https://huggingface.co/papers/2507.19766",
            "abstract": "A novel reinforcement learning approach for large language models addresses inefficiencies in handling ultra-long outputs, enhancing performance and training speed through segmentation and dynamic masking techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in large language models (LLMs) have highlighted the potential of reinforcement learning with verifiable rewards (RLVR) to enhance reasoning capabilities through extended output sequences. However, traditional RL frameworks face inefficiencies when handling ultra-long outputs due to long-tail sequence distributions and entropy collapse during training. To address these challenges, we propose an Ultra-Long Output Reinforcement Learning (UloRL) approach for advancing large language models' reasoning abilities. Specifically, we divide ultra long output decoding into short segments, enabling efficient training by mitigating delays caused by long-tail samples. Additionally, we introduce dynamic masking of well-Mastered Positive Tokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the effectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment rollout achieved 2.06x increase in training speed, while RL training with 128k-token outputs improves the model's performance on AIME2025 from 70.9\\% to 85.1\\% and on BeyondAIME from 50.7\\% to 61.9\\%, even surpassing Qwen3-235B-A22B with remarkable gains. These findings underscore the potential of our methods to advance the reasoning capabilities of LLMs with ultra-long sequence generation. We will release our code and model for further use by the community.",
            "score": 8,
            "issue_id": 5062,
            "pub_date": "2025-07-26",
            "pub_date_card": {
                "ru": "26 Ğ¸ÑĞ»Ñ",
                "en": "July 26",
                "zh": "7æœˆ26æ—¥"
            },
            "hash": "08ac12a595460a4b",
            "authors": [
                "Dong Du",
                "Shulin Liu",
                "Tao Yang",
                "Shaohua Chen",
                "Yang Li"
            ],
            "affiliations": [
                "Tencent Hunyuan Team"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.19766.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#training",
                    "#long_context",
                    "#reasoning",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° ÑĞ¾ ÑĞ²ĞµÑ€Ñ…Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°Ğ¼Ğ¸",
                    "desc": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ½ĞµÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ ÑĞ²ĞµÑ€Ñ…Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ UloRL Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ². Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑƒÑĞºĞ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ² 2,06 Ñ€Ğ°Ğ·Ğ° Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡."
                },
                "en": {
                    "title": "Enhancing LLMs with Efficient Ultra-Long Output Learning",
                    "desc": "This paper introduces a new reinforcement learning method called Ultra-Long Output Reinforcement Learning (UloRL) designed to improve large language models (LLMs) when generating very long outputs. The approach tackles inefficiencies in traditional reinforcement learning by breaking down long output sequences into shorter segments, which speeds up training and enhances performance. Additionally, it employs dynamic masking of well-mastered positive tokens to prevent issues like entropy collapse during training. Experimental results show significant improvements in training speed and reasoning capabilities of LLMs, demonstrating the effectiveness of the proposed techniques."
                },
                "zh": {
                    "title": "æå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†è¶…é•¿è¾“å‡ºæ—¶çš„æ•ˆç‡ã€‚é€šè¿‡å°†è¶…é•¿è¾“å‡ºè§£ç åˆ†å‰²ä¸ºçŸ­æ®µï¼Œå‡å°‘äº†é•¿å°¾æ ·æœ¬å¸¦æ¥çš„å»¶è¿Ÿï¼Œä»è€ŒåŠ å¿«äº†è®­ç»ƒé€Ÿåº¦ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†åŠ¨æ€æ©è”½æŠ€æœ¯ï¼Œä»¥é˜²æ­¢ç†µå´©æºƒï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ€§èƒ½å’Œè®­ç»ƒæ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.17189",
            "title": "Met^2Net: A Decoupled Two-Stage Spatio-Temporal Forecasting Model for\n  Complex Meteorological Systems",
            "url": "https://huggingface.co/papers/2507.17189",
            "abstract": "A proposed implicit two-stage training approach with separate encoders and decoders and self-attention for multivariable fusion improves weather prediction performance in end-to-end deep learning models.  \t\t\t\t\tAI-generated summary \t\t\t\t The increasing frequency of extreme weather events due to global climate change urges accurate weather prediction. Recently, great advances have been made by the end-to-end methods, thanks to deep learning techniques, but they face limitations of representation inconsistency in multivariable integration and struggle to effectively capture the dependency between variables, which is required in complex weather systems. Treating different variables as distinct modalities and applying a two-stage training approach from multimodal models can partially alleviate this issue, but due to the inconformity in training tasks between the two stages, the results are often suboptimal. To address these challenges, we propose an implicit two-stage training method, configuring separate encoders and decoders for each variable. In detailed, in the first stage, the Translator is frozen while the Encoders and Decoders learn a shared latent space, in the second stage, the Encoders and Decoders are frozen, and the Translator captures inter-variable interactions for prediction. Besides, by introducing a self-attention mechanism for multivariable fusion in the latent space, the performance achieves further improvements. Empirically, extensive experiments show the state-of-the-art performance of our method. Specifically, it reduces the MSE for near-surface air temperature and relative humidity predictions by 28.82\\% and 23.39\\%, respectively. The source code is available at https://github.com/ShremG/Met2Net.",
            "score": 8,
            "issue_id": 5063,
            "pub_date": "2025-07-23",
            "pub_date_card": {
                "ru": "23 Ğ¸ÑĞ»Ñ",
                "en": "July 23",
                "zh": "7æœˆ23æ—¥"
            },
            "hash": "38ffbf9cc27bae27",
            "authors": [
                "Shaohan Li",
                "Hao Yang",
                "Min Chen",
                "Xiaolin Qin"
            ],
            "affiliations": [
                "Chengdu Institute of Computer Applications, Chinese Academy of Sciences",
                "Chengdu University of Information Technology",
                "University of Chinese Academy of Sciences"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.17189.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#multimodal",
                    "#science",
                    "#optimization"
                ],
                "emoji": "ğŸŒ¦ï¸",
                "ru": {
                    "title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¾Ğ² Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñ‹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñ‹. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ğ¸ Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ ÑĞ°Ğ¼Ğ¾Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ”Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¾Ğ² Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹ Ğ¸ Ğ²Ğ»Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¾Ğ·Ğ´ÑƒÑ…Ğ°."
                },
                "en": {
                    "title": "Enhancing Weather Prediction with Two-Stage Deep Learning",
                    "desc": "This paper presents a novel implicit two-stage training approach for improving weather prediction using deep learning. It utilizes separate encoders and decoders for different weather variables, allowing for better representation and integration of multivariable data. The method incorporates a self-attention mechanism to enhance the fusion of these variables in a shared latent space. Experimental results demonstrate significant improvements in prediction accuracy, achieving state-of-the-art performance in forecasting near-surface air temperature and humidity."
                },
                "zh": {
                    "title": "éšå¼ä¸¤é˜¶æ®µè®­ç»ƒæå‡å¤©æ°”é¢„æµ‹æ€§èƒ½",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§éšå¼çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³•ï¼Œé‡‡ç”¨ç‹¬ç«‹çš„ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå¹¶å¼•å…¥è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥è¿›è¡Œå¤šå˜é‡èåˆï¼Œä»è€Œæé«˜å¤©æ°”é¢„æµ‹çš„æ€§èƒ½ã€‚éšç€å…¨çƒæ°”å€™å˜åŒ–ï¼Œæç«¯å¤©æ°”äº‹ä»¶é¢‘å‘ï¼Œå‡†ç¡®çš„å¤©æ°”é¢„æµ‹å˜å¾—å°¤ä¸ºé‡è¦ã€‚ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å¤šå˜é‡é›†æˆä¸­å­˜åœ¨è¡¨ç¤ºä¸ä¸€è‡´çš„é—®é¢˜ï¼Œéš¾ä»¥æœ‰æ•ˆæ•æ‰å˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚é€šè¿‡å°†ä¸åŒå˜é‡è§†ä¸ºç‹¬ç«‹æ¨¡æ€ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³•ï¼Œæˆ‘ä»¬çš„ç ”ç©¶åœ¨å®éªŒä¸­æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨è¿‘åœ°é¢æ°”æ¸©å’Œç›¸å¯¹æ¹¿åº¦çš„é¢„æµ‹ä¸­ï¼Œå‡æ–¹è¯¯å·®åˆ†åˆ«é™ä½äº†28.82%å’Œ23.39%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.19804",
            "title": "ForCenNet: Foreground-Centric Network for Document Image Rectification",
            "url": "https://huggingface.co/papers/2507.19804",
            "abstract": "A Foreground-Centric Network for document image rectification improves state-of-the-art by effectively handling foreground elements and layout distortions.  \t\t\t\t\tAI-generated summary \t\t\t\t Document image rectification aims to eliminate geometric deformation in photographed documents to facilitate text recognition. However, existing methods often neglect the significance of foreground elements, which provide essential geometric references and layout information for document image correction. In this paper, we introduce Foreground-Centric Network (ForCenNet) to eliminate geometric distortions in document images. Specifically, we initially propose a foreground-centric label generation method, which extracts detailed foreground elements from an undistorted image. Then we introduce a foreground-centric mask mechanism to enhance the distinction between readable and background regions. Furthermore, we design a curvature consistency loss to leverage the detailed foreground labels to help the model understand the distorted geometric distribution. Extensive experiments demonstrate that ForCenNet achieves new state-of-the-art on four real-world benchmarks, such as DocUNet, DIR300, WarpDoc, and DocReal. Quantitative analysis shows that the proposed method effectively undistorts layout elements, such as text lines and table borders. The resources for further comparison are provided at https://github.com/caipeng328/ForCenNet.",
            "score": 7,
            "issue_id": 5058,
            "pub_date": "2025-07-26",
            "pub_date_card": {
                "ru": "26 Ğ¸ÑĞ»Ñ",
                "en": "July 26",
                "zh": "7æœˆ26æ—¥"
            },
            "hash": "171763e95f15cfb1",
            "authors": [
                "Peng Cai",
                "Qiang Li",
                "Kaicheng Yang",
                "Dong Guo",
                "Jia Li",
                "Nan Zhou",
                "Xiang An",
                "Ninghua Yang",
                "Jiankang Deng"
            ],
            "affiliations": [
                "DeepGlint",
                "Imperial College London",
                "Qihoo Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.19804.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#cv"
                ],
                "emoji": "ğŸ“„",
                "ru": {
                    "title": "Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸ÑĞºĞ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ… Ñ Ñ„Ğ¾ĞºÑƒÑĞ¾Ğ¼ Ğ½Ğ° Ğ²Ğ°Ğ¶Ğ½Ñ‹Ñ… ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ…",
                    "desc": "ForCenNet - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ Ğ´Ğ»Ñ ÑƒÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ÑĞºĞ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¾Ñ‚ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ…. ĞĞ½Ğ° Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ… Ğ¿ĞµÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ°, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Ñ‚ĞµĞºÑÑ‚ Ğ¸ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ½ÑÑ‚ÑŒ Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¸ÑĞºĞ°Ğ¶ĞµĞ½Ğ¸Ñ. Ğ¡ĞµÑ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğº Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ĞµĞ¹ Ğ¸ Ñ„Ğ¾Ğ½Ğ°. ForCenNet Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing Document Rectification with Foreground Focus",
                    "desc": "This paper presents the Foreground-Centric Network (ForCenNet), which focuses on improving document image rectification by addressing the importance of foreground elements. Traditional methods often overlook these elements, which are crucial for understanding the layout and geometry of documents. ForCenNet introduces a novel label generation method to extract detailed foreground features and a mask mechanism to differentiate between text and background. The model also employs a curvature consistency loss to better capture geometric distortions, achieving state-of-the-art results on multiple benchmarks."
                },
                "zh": {
                    "title": "ä»¥å‰æ™¯ä¸ºä¸­å¿ƒçš„æ–‡æ¡£å›¾åƒçŸ«æ­£æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»¥å‰æ™¯ä¸ºä¸­å¿ƒçš„ç½‘ç»œï¼ˆForCenNetï¼‰ï¼Œç”¨äºæ–‡æ¡£å›¾åƒçš„çŸ«æ­£ï¼Œæ—¨åœ¨æ¶ˆé™¤æ‹æ‘„æ–‡æ¡£ä¸­çš„å‡ ä½•å˜å½¢ï¼Œä»¥æé«˜æ–‡æœ¬è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†å‰æ™¯å…ƒç´ çš„é‡è¦æ€§ï¼Œè€Œè¿™äº›å…ƒç´ ä¸ºæ–‡æ¡£å›¾åƒçš„æ ¡æ­£æä¾›äº†å¿…è¦çš„å‡ ä½•å‚è€ƒå’Œå¸ƒå±€ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å‰æ™¯ä¸­å¿ƒæ ‡ç­¾ç”Ÿæˆæ–¹æ³•ï¼Œæå–æœªå¤±çœŸå›¾åƒä¸­çš„è¯¦ç»†å‰æ™¯å…ƒç´ ï¼Œå¹¶å¼•å…¥å‰æ™¯ä¸­å¿ƒæ©è†œæœºåˆ¶ï¼Œä»¥å¢å¼ºå¯è¯»åŒºåŸŸä¸èƒŒæ™¯åŒºåŸŸä¹‹é—´çš„åŒºåˆ†ã€‚é€šè¿‡å¤§é‡å®éªŒï¼ŒForCenNetåœ¨å¤šä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œæœ‰æ•ˆåœ°çº æ­£äº†æ–‡æœ¬è¡Œå’Œè¡¨æ ¼è¾¹æ¡†ç­‰å¸ƒå±€å…ƒç´ çš„å¤±çœŸã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.19058",
            "title": "ScenePainter: Semantically Consistent Perpetual 3D Scene Generation with\n  Concept Relation Alignment",
            "url": "https://huggingface.co/papers/2507.19058",
            "abstract": "ScenePainter framework uses a hierarchical graph structure to ensure semantically consistent 3D scene generation by addressing the semantic drift problem in successive view expansion.  \t\t\t\t\tAI-generated summary \t\t\t\t Perpetual 3D scene generation aims to produce long-range and coherent 3D view sequences, which is applicable for long-term video synthesis and 3D scene reconstruction. Existing methods follow a \"navigate-and-imagine\" fashion and rely on outpainting for successive view expansion. However, the generated view sequences suffer from semantic drift issue derived from the accumulated deviation of the outpainting module. To tackle this challenge, we propose ScenePainter, a new framework for semantically consistent 3D scene generation, which aligns the outpainter's scene-specific prior with the comprehension of the current scene. To be specific, we introduce a hierarchical graph structure dubbed SceneConceptGraph to construct relations among multi-level scene concepts, which directs the outpainter for consistent novel views and can be dynamically refined to enhance diversity. Extensive experiments demonstrate that our framework overcomes the semantic drift issue and generates more consistent and immersive 3D view sequences. Project Page: https://xiac20.github.io/ScenePainter/.",
            "score": 6,
            "issue_id": 5062,
            "pub_date": "2025-07-25",
            "pub_date_card": {
                "ru": "25 Ğ¸ÑĞ»Ñ",
                "en": "July 25",
                "zh": "7æœˆ25æ—¥"
            },
            "hash": "81138769af5fca87",
            "authors": [
                "Chong Xia",
                "Shengjun Zhang",
                "Fangfu Liu",
                "Chang Liu",
                "Khodchaphun Hirunyaratsameewong",
                "Yueqi Duan"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.19058.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#graphs"
                ],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 3D-ÑÑ†ĞµĞ½ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²",
                    "desc": "ScenePainter - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-ÑÑ†ĞµĞ½. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ SceneConceptGraph Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ ÑĞ²ÑĞ·ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸ÑĞ¼Ğ¸ ÑÑ†ĞµĞ½Ñ‹ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑƒÑ€Ğ¾Ğ²Ğ½ÑÑ…. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ€Ğ°ĞºÑƒÑ€ÑĞ¾Ğ² Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑÑ‚ÑŒ Ğ³Ñ€Ğ°Ñ„ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ. ScenePainter Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ´Ñ€ĞµĞ¹Ñ„Ğ°, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ°ÑÑ‰ÑƒÑ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğ¸ Ñ€Ğ°ĞºÑƒÑ€ÑĞ¾Ğ² Ğ² ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ñ…."
                },
                "en": {
                    "title": "Consistent 3D Scene Generation with ScenePainter",
                    "desc": "The ScenePainter framework addresses the challenge of generating coherent 3D scenes by using a hierarchical graph structure to maintain semantic consistency. It specifically targets the semantic drift problem that occurs during successive view expansion in 3D scene generation. By aligning the outpainter's scene-specific prior with the current scene understanding, ScenePainter ensures that new views are generated in a consistent manner. The introduction of the SceneConceptGraph allows for the construction of relationships among various scene concepts, enhancing the diversity and quality of the generated 3D view sequences."
                },
                "zh": {
                    "title": "ScenePainterï¼šè§£å†³3Dåœºæ™¯ç”Ÿæˆä¸­çš„è¯­ä¹‰æ¼‚ç§»é—®é¢˜",
                    "desc": "ScenePainteræ¡†æ¶ä½¿ç”¨å±‚æ¬¡å›¾ç»“æ„æ¥ç¡®ä¿3Dåœºæ™¯ç”Ÿæˆçš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œè§£å†³äº†è¿ç»­è§†å›¾æ‰©å±•ä¸­çš„è¯­ä¹‰æ¼‚ç§»é—®é¢˜ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ç”Ÿæˆé•¿æ—¶é—´ä¸”è¿è´¯çš„3Dè§†å›¾åºåˆ—ï¼Œé€‚ç”¨äºé•¿æœŸè§†é¢‘åˆæˆå’Œ3Dåœºæ™¯é‡å»ºã€‚é€šè¿‡å¼•å…¥åä¸ºSceneConceptGraphçš„å±‚æ¬¡å›¾ç»“æ„ï¼Œæ„å»ºå¤šå±‚æ¬¡åœºæ™¯æ¦‚å¿µä¹‹é—´çš„å…³ç³»ï¼Œä»è€ŒæŒ‡å¯¼ç”Ÿæˆå™¨ç”Ÿæˆä¸€è‡´çš„æ–°è§†å›¾ã€‚å®éªŒè¡¨æ˜ï¼ŒScenePainteræœ‰æ•ˆå…‹æœäº†è¯­ä¹‰æ¼‚ç§»é—®é¢˜ï¼Œç”Ÿæˆäº†æ›´ä¸€è‡´å’Œæ²‰æµ¸çš„3Dè§†å›¾åºåˆ—ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20900",
            "title": "Music Arena: Live Evaluation for Text-to-Music",
            "url": "https://huggingface.co/papers/2507.20900",
            "abstract": "Music Arena provides a scalable, interactive platform for evaluating text-to-music models through user-generated preferences and detailed feedback.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Music Arena, an open platform for scalable human preference evaluation of text-to-music (TTM) models. Soliciting human preferences via listening studies is the gold standard for evaluation in TTM, but these studies are expensive to conduct and difficult to compare, as study protocols may differ across systems. Moreover, human preferences might help researchers align their TTM systems or improve automatic evaluation metrics, but an open and renewable source of preferences does not currently exist. We aim to fill these gaps by offering *live* evaluation for TTM. In Music Arena, real-world users input text prompts of their choosing and compare outputs from two TTM systems, and their preferences are used to compile a leaderboard. While Music Arena follows recent evaluation trends in other AI domains, we also design it with key features tailored to music: an LLM-based routing system to navigate the heterogeneous type signatures of TTM systems, and the collection of *detailed* preferences including listening data and natural language feedback. We also propose a rolling data release policy with user privacy guarantees, providing a renewable source of preference data and increasing platform transparency. Through its standardized evaluation protocol, transparent data access policies, and music-specific features, Music Arena not only addresses key challenges in the TTM ecosystem but also demonstrates how live evaluation can be thoughtfully adapted to unique characteristics of specific AI domains.   Music Arena is available at: https://music-arena.org",
            "score": 5,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "53def6d52ac1ffb0",
            "authors": [
                "Yonghyun Kim",
                "Wayne Chi",
                "Anastasios N. Angelopoulos",
                "Wei-Lin Chiang",
                "Koichi Saito",
                "Shinji Watanabe",
                "Yuki Mitsufuji",
                "Chris Donahue"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Georgia Tech",
                "LMArena",
                "Sony AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20900.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#alignment",
                    "#open_source",
                    "#multimodal"
                ],
                "emoji": "ğŸµ",
                "ru": {
                    "title": "Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ°Ñ€ĞµĞ½Ğ° Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ÑƒĞ·Ñ‹ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜",
                    "desc": "Music Arena - ÑÑ‚Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² Ğ¼ÑƒĞ·Ñ‹ĞºÑƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹. ĞĞ½Ğ° Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ´Ğ²ÑƒÑ… ÑĞ¸ÑÑ‚ĞµĞ¼ text-to-music, ÑĞ¾Ğ±Ğ¸Ñ€Ğ°Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑÑ…. ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ñ€Ğ¾Ğ´Ğ½Ñ‹Ğ¼Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼. Music Arena Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑÑ…, ÑĞ¾Ğ±Ğ»ÑĞ´Ğ°Ñ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Empowering Music Creation through User-Driven Evaluation",
                    "desc": "Music Arena is an interactive platform designed to evaluate text-to-music (TTM) models by gathering user preferences and feedback. It addresses the challenges of traditional human preference studies, which are often costly and inconsistent. By allowing users to compare outputs from different TTM systems based on their own text prompts, it creates a leaderboard that reflects real-world preferences. Additionally, Music Arena incorporates features like an LLM-based routing system and detailed feedback collection to enhance the evaluation process while ensuring user privacy."
                },
                "zh": {
                    "title": "éŸ³ä¹è¯„ä¼°æ–°å¹³å°ï¼šMusic Arena",
                    "desc": "Music Arena æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„äº’åŠ¨å¹³å°ï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°éŸ³ä¹ï¼ˆTTMï¼‰æ¨¡å‹çš„ç”¨æˆ·åå¥½å’Œè¯¦ç»†åé¦ˆã€‚è¯¥å¹³å°å…è®¸ç”¨æˆ·è¾“å…¥æ–‡æœ¬æç¤ºï¼Œå¹¶æ¯”è¾ƒä¸¤ä¸ª TTM ç³»ç»Ÿçš„è¾“å‡ºï¼Œä»è€Œæ”¶é›†ç”¨æˆ·çš„åå¥½æ•°æ®ã€‚é€šè¿‡æ ‡å‡†åŒ–çš„è¯„ä¼°åè®®å’Œé€æ˜çš„æ•°æ®è®¿é—®æ”¿ç­–ï¼ŒMusic Arena è§£å†³äº† TTM ç”Ÿæ€ç³»ç»Ÿä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªå¯å†ç”Ÿçš„åå¥½æ•°æ®æºã€‚è¯¥å¹³å°è¿˜è®¾è®¡äº†ä¸“é—¨é’ˆå¯¹éŸ³ä¹çš„åŠŸèƒ½ï¼Œä»¥æé«˜è¯„ä¼°çš„æœ‰æ•ˆæ€§å’Œç”¨æˆ·ä½“éªŒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20880",
            "title": "JAM: A Tiny Flow-based Song Generator with Fine-grained Controllability\n  and Aesthetic Alignment",
            "url": "https://huggingface.co/papers/2507.20880",
            "abstract": "A flow-matching-based model enhances lyrics-to-song generation by providing word-level control over vocal timing and duration, improving quality through aesthetic alignment and surpassing current models in music-specific attributes.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion and flow-matching models have revolutionized automatic text-to-audio generation in recent times. These models are increasingly capable of generating high quality and faithful audio outputs capturing to speech and acoustic events. However, there is still much room for improvement in creative audio generation that primarily involves music and songs. Recent open lyrics-to-song models, such as, DiffRhythm, ACE-Step, and LeVo, have set an acceptable standard in automatic song generation for recreational use. However, these models lack fine-grained word-level controllability often desired by musicians in their workflows. To the best of our knowledge, our flow-matching-based JAM is the first effort toward endowing word-level timing and duration control in song generation, allowing fine-grained vocal control. To enhance the quality of generated songs to better align with human preferences, we implement aesthetic alignment through Direct Preference Optimization, which iteratively refines the model using a synthetic dataset, eliminating the need or manual data annotations. Furthermore, we aim to standardize the evaluation of such lyrics-to-song models through our public evaluation dataset JAME. We show that JAM outperforms the existing models in terms of the music-specific attributes.",
            "score": 3,
            "issue_id": 5058,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "850946325eebad11",
            "authors": [
                "Renhang Liu",
                "Chia-Yu Hung",
                "Navonil Majumder",
                "Taylor Gautreaux",
                "Amir Ali Bagherzadeh",
                "Chuan Li",
                "Dorien Herremans",
                "Soujanya Poria"
            ],
            "affiliations": [
                "Lambda Labs",
                "Singapore University of Technology and Design"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20880.jpg",
            "data": {
                "categories": [
                    "#audio",
                    "#open_source",
                    "#diffusion",
                    "#dataset",
                    "#training",
                    "#data",
                    "#synthetic",
                    "#benchmark"
                ],
                "emoji": "ğŸµ",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ²Ğ¾ĞºĞ°Ğ»Ğ° Ğ² Ğ˜Ğ˜-Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑĞµĞ½",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑĞµĞ½ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ»Ğ¸Ñ€Ğ¸ĞºĞ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ² (flow matching). ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğ°Ğ´ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼ Ğ¸ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ² Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ², Ñ‡Ñ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¿ĞµÑĞµĞ½ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ ÑÑÑ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ (Direct Preference Optimization). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ Ğ¿Ğ¾ Ğ¼ÑƒĞ·Ñ‹ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°Ğ¼."
                },
                "en": {
                    "title": "JAM: Fine-Grained Control for Better Song Generation",
                    "desc": "This paper presents a new model called JAM that improves the generation of songs from lyrics by allowing precise control over the timing and duration of words. By using flow-matching techniques, JAM enhances the quality of the generated music, making it more aesthetically pleasing and aligned with human preferences. The model employs Direct Preference Optimization to refine its outputs without needing manual data annotations, streamlining the creative process for musicians. Additionally, the authors introduce a public evaluation dataset, JAME, to standardize assessments of lyrics-to-song models, demonstrating that JAM surpasses existing models in music-specific qualities."
                },
                "zh": {
                    "title": "æµåŒ¹é…æ¨¡å‹æå‡æ­Œè¯ç”Ÿæˆè´¨é‡",
                    "desc": "è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæµåŒ¹é…çš„æ¨¡å‹ï¼Œæ—¨åœ¨æ”¹å–„æ­Œè¯åˆ°æ­Œæ›²çš„ç”Ÿæˆè¿‡ç¨‹ã€‚è¯¥æ¨¡å‹æä¾›äº†å¯¹è¯æ±‡æ—¶æœºå’ŒæŒç»­æ—¶é—´çš„æ§åˆ¶ï¼Œä½¿å¾—ç”Ÿæˆçš„æ­Œæ›²åœ¨è´¨é‡ä¸Šæ›´ç¬¦åˆäººç±»çš„å®¡ç¾åå¥½ã€‚é€šè¿‡ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨æ²¡æœ‰äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œè¿­ä»£åœ°æå‡ç”Ÿæˆæ­Œæ›²çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¨å‡ºäº†å…¬å…±è¯„ä¼°æ•°æ®é›†JAMEï¼Œä»¥æ ‡å‡†åŒ–æ­Œè¯åˆ°æ­Œæ›²æ¨¡å‹çš„è¯„ä¼°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.16806",
            "title": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty",
            "url": "https://huggingface.co/papers/2507.16806",
            "abstract": "Reward augmented reinforcement learning improves both accuracy and confidence calibration of language models across in-domain and out-of-domain evaluations.  \t\t\t\t\tAI-generated summary \t\t\t\t When language models (LMs) are trained via reinforcement learning (RL) to generate natural language \"reasoning chains\", their performance improves on a variety of difficult question answering tasks. Today, almost all successful applications of RL for reasoning use binary reward functions that evaluate the correctness of LM outputs. Because such reward functions do not penalize guessing or low-confidence outputs, they often have the unintended side-effect of degrading calibration and increasing the rate at which LMs generate incorrect responses (or \"hallucinate\") in other problem domains. This paper describes RLCR (Reinforcement Learning with Calibration Rewards), an approach to training reasoning models that jointly improves accuracy and calibrated confidence estimation. During RLCR, LMs generate both predictions and numerical confidence estimates after reasoning. They are trained to optimize a reward function that augments a binary correctness score with a Brier score -- a scoring rule for confidence estimates that incentivizes calibrated prediction. We first prove that this reward function (or any analogous reward function that uses a bounded, proper scoring rule) yields models whose predictions are both accurate and well-calibrated. We next show that across diverse datasets, RLCR substantially improves calibration with no loss in accuracy, on both in-domain and out-of-domain evaluations -- outperforming both ordinary RL training and classifiers trained to assign post-hoc confidence scores. While ordinary RL hurts calibration, RLCR improves it. Finally, we demonstrate that verbalized confidence can be leveraged at test time to improve accuracy and calibration via confidence-weighted scaling methods. Our results show that explicitly optimizing for calibration can produce more generally reliable reasoning models.",
            "score": 3,
            "issue_id": 5063,
            "pub_date": "2025-07-22",
            "pub_date_card": {
                "ru": "22 Ğ¸ÑĞ»Ñ",
                "en": "July 22",
                "zh": "7æœˆ22æ—¥"
            },
            "hash": "a7c255689a6eaeb1",
            "authors": [
                "Mehul Damani",
                "Isha Puri",
                "Stewart Slocum",
                "Idan Shenfeld",
                "Leshem Choshen",
                "Yoon Kim",
                "Jacob Andreas"
            ],
            "affiliations": [
                "Massachusetts Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.16806.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#hallucinations",
                    "#optimization"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ RLCR (Reinforcement Learning with Calibration Rewards) Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. RLCR Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹ Ğ‘Ñ€Ğ¸ĞµÑ€Ğ° Ğ´Ğ»Ñ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ RLCR Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºÑƒ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğº Ğ½Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸Ğ´Ğ¾Ğ¼ĞµĞ½Ğ½Ñ‹Ñ…, Ñ‚Ğ°Ğº Ğ¸ Ğ½Ğ° Ğ²Ğ½ĞµĞ´Ğ¾Ğ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ñ†ĞµĞ½ĞºĞ°Ñ…. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ‹, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸ÑĞ²Ğ°Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ÑÑ‚Ñ„Ğ°ĞºÑ‚ÑƒĞ¼."
                },
                "en": {
                    "title": "Boosting Accuracy and Confidence in Language Models with RLCR",
                    "desc": "This paper introduces RLCR (Reinforcement Learning with Calibration Rewards), a novel approach that enhances the performance of language models (LMs) in reasoning tasks. By incorporating a Brier score into the reward function, RLCR not only focuses on the accuracy of predictions but also ensures that the confidence estimates of these predictions are well-calibrated. The study demonstrates that this method significantly improves the calibration of confidence without sacrificing accuracy, outperforming traditional reinforcement learning methods. Ultimately, the findings suggest that optimizing for calibration leads to more reliable and effective reasoning models in various evaluation scenarios."
                },
                "zh": {
                    "title": "ä¼˜åŒ–æ ¡å‡†ï¼Œæå‡è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§ä¸ä¿¡å¿ƒ",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç§°ä¸ºRLCRï¼ˆå¸¦æœ‰æ ¡å‡†å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼‰ï¼Œæ—¨åœ¨æé«˜è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§å’Œç½®ä¿¡åº¦æ ¡å‡†ã€‚é€šè¿‡åœ¨ç”Ÿæˆæ¨ç†é“¾æ—¶åŒæ—¶è¾“å‡ºé¢„æµ‹å’Œç½®ä¿¡åº¦ä¼°è®¡ï¼ŒRLCRä¼˜åŒ–äº†ä¸€ç§ç»“åˆäº†äºŒå…ƒæ­£ç¡®æ€§è¯„åˆ†å’ŒBrierè¯„åˆ†çš„å¥–åŠ±å‡½æ•°ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒRLCRåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æ”¹å–„äº†æ¨¡å‹çš„æ ¡å‡†æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å‡†ç¡®æ€§ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ–¹æ³•ã€‚æœ€ç»ˆï¼Œè®ºæ–‡è¿˜å±•ç¤ºäº†å¦‚ä½•åœ¨æµ‹è¯•æ—¶åˆ©ç”¨å£å¤´åŒ–çš„ç½®ä¿¡åº¦æ¥è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„è¡¨ç°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.21035",
            "title": "GenoMAS: A Multi-Agent Framework for Scientific Discovery via\n  Code-Driven Gene Expression Analysis",
            "url": "https://huggingface.co/papers/2507.21035",
            "abstract": "A system using LLM-based agents enhances gene expression analysis by integrating workflow reliability and autonomous adaptability to improve preprocessing and identification accuracy while uncovering biologically meaningful associations.  \t\t\t\t\tAI-generated summary \t\t\t\t Gene expression analysis holds the key to many biomedical discoveries, yet extracting insights from raw transcriptomic data remains formidable due to the complexity of multiple large, semi-structured files and the need for extensive domain expertise. Current automation approaches are often limited by either inflexible workflows that break down in edge cases or by fully autonomous agents that lack the necessary precision for rigorous scientific inquiry. GenoMAS charts a different course by presenting a team of LLM-based scientists that integrates the reliability of structured workflows with the adaptability of autonomous agents. GenoMAS orchestrates six specialized LLM agents through typed message-passing protocols, each contributing complementary strengths to a shared analytic canvas. At the heart of GenoMAS lies a guided-planning framework: programming agents unfold high-level task guidelines into Action Units and, at each juncture, elect to advance, revise, bypass, or backtrack, thereby maintaining logical coherence while bending gracefully to the idiosyncrasies of genomic data.   On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation of 89.13% for data preprocessing and an F_1 of 60.48% for gene identification, surpassing the best prior art by 10.61% and 16.85% respectively. Beyond metrics, GenoMAS surfaces biologically plausible gene-phenotype associations corroborated by the literature, all while adjusting for latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.",
            "score": 1,
            "issue_id": 5062,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "d694c1f330b0cab3",
            "authors": [
                "Haoyang Liu",
                "Yijiang Li",
                "Haohan Wang"
            ],
            "affiliations": [
                "University of California, San Diego",
                "University of Illinois at Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.21035.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#data",
                    "#science",
                    "#healthcare",
                    "#benchmark"
                ],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "GenoMAS: Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ³ĞµĞ½Ğ¾Ğ² Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ˜Ğ˜-ÑƒÑ‡ĞµĞ½Ñ‹Ñ…",
                    "desc": "GenoMAS Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ LLM-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑĞºÑĞ¿Ñ€ĞµÑÑĞ¸Ğ¸ Ğ³ĞµĞ½Ğ¾Ğ². ĞĞ½Ğ° ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑˆĞµÑÑ‚ÑŒ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… LLM-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ñ… Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ñ‹ Ğ¾Ğ±Ğ¼ĞµĞ½Ğ° Ñ‚Ğ¸Ğ¿Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸. GenoMAS Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ³ĞµĞ½Ğ¾Ğ², Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ Ğ±Ğ¸Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ñ‹Ğµ Ğ°ÑÑĞ¾Ñ†Ğ¸Ğ°Ñ†Ğ¸Ğ¸."
                },
                "en": {
                    "title": "GenoMAS: Merging Reliability and Adaptability in Gene Expression Analysis",
                    "desc": "This paper presents GenoMAS, a system that utilizes large language model (LLM)-based agents to enhance gene expression analysis. It combines the reliability of structured workflows with the flexibility of autonomous agents, allowing for improved preprocessing and identification accuracy of genomic data. The system employs a guided-planning framework where agents collaborate through message-passing protocols, adapting to the complexities of the data while maintaining logical coherence. GenoMAS achieves significant performance improvements on the GenoTEX benchmark, demonstrating its ability to uncover biologically meaningful associations in gene-phenotype relationships."
                },
                "zh": {
                    "title": "GenoMASï¼šåŸºäºLLMçš„åŸºå› è¡¨è¾¾åˆ†ææ–°æ–¹æ³•",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºGenoMASçš„ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†æ¥å¢å¼ºåŸºå› è¡¨è¾¾åˆ†æã€‚GenoMASç»“åˆäº†ç»“æ„åŒ–å·¥ä½œæµç¨‹çš„å¯é æ€§å’Œè‡ªä¸»ä»£ç†çš„é€‚åº”æ€§ï¼Œä»è€Œæé«˜äº†æ•°æ®é¢„å¤„ç†å’ŒåŸºå› è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚é€šè¿‡å…­ä¸ªä¸“ä¸šçš„LLMä»£ç†ï¼ŒGenoMASèƒ½å¤Ÿåœ¨åˆ†æè¿‡ç¨‹ä¸­çµæ´»åº”å¯¹åŸºå› ç»„æ•°æ®çš„å¤æ‚æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGenoMASåœ¨æ•°æ®é¢„å¤„ç†å’ŒåŸºå› è¯†åˆ«æ–¹é¢çš„æ€§èƒ½å‡è¶…è¿‡äº†ä¹‹å‰çš„æœ€ä½³æˆæœã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20187",
            "title": "Diversity-Enhanced Reasoning for Subjective Questions",
            "url": "https://huggingface.co/papers/2507.20187",
            "abstract": "A diversity-enhanced framework with multiple role perspectives improves accuracy and diversity in subjective reasoning tasks through unsupervised data construction and reinforcement learning with reward shaping.  \t\t\t\t\tAI-generated summary \t\t\t\t Large reasoning models (LRM) with long chain-of-thought (CoT) capabilities have shown strong performance on objective tasks, such as math reasoning and coding. However, their effectiveness on subjective questions that may have different responses from different perspectives is still limited by a tendency towards homogeneous reasoning, introduced by the reliance on a single ground truth in supervised fine-tuning and verifiable reward in reinforcement learning. Motivated by the finding that increasing role perspectives consistently improves performance, we propose MultiRole-R1, a diversity-enhanced framework with multiple role perspectives, to improve the accuracy and diversity in subjective reasoning tasks. MultiRole-R1 features an unsupervised data construction pipeline that generates reasoning chains that incorporate diverse role perspectives. We further employ reinforcement learning via Group Relative Policy Optimization (GRPO) with reward shaping, by taking diversity as a reward signal in addition to the verifiable reward. With specially designed reward functions, we successfully promote perspective diversity and lexical diversity, uncovering a positive relation between reasoning diversity and accuracy. Our experiment on six benchmarks demonstrates MultiRole-R1's effectiveness and generalizability in enhancing both subjective and objective reasoning, showcasing the potential of diversity-enhanced training in LRMs.",
            "score": 1,
            "issue_id": 5068,
            "pub_date": "2025-07-27",
            "pub_date_card": {
                "ru": "27 Ğ¸ÑĞ»Ñ",
                "en": "July 27",
                "zh": "7æœˆ27æ—¥"
            },
            "hash": "29b178594cfc4a66",
            "authors": [
                "Yumeng Wang",
                "Zhiyuan Fan",
                "Jiayu Liu",
                "Yi R. Fung"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2507.20187.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#data",
                    "#rlhf",
                    "#training",
                    "#rl"
                ],
                "emoji": "ğŸ­",
                "ru": {
                    "title": "Ğ Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ² - ĞºĞ»ÑÑ‡ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ˜",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº MultiRole-R1, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ¸Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ÑÑƒĞ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ»ĞµĞ²Ñ‹Ñ… Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ². ĞœĞµÑ‚Ğ¾Ğ´ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ Ğ½ĞµĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ğ¾Ñ‡ĞºĞ°Ğ¼Ğ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Group Relative Policy Optimization Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° ÑˆĞµÑÑ‚Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ MultiRole-R1 Ğ² ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¸ ĞºĞ°Ğº ÑÑƒĞ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…, Ñ‚Ğ°Ğº Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Enhancing Reasoning with Diverse Perspectives",
                    "desc": "This paper introduces MultiRole-R1, a framework designed to enhance the performance of large reasoning models (LRMs) on subjective reasoning tasks. It addresses the limitations of traditional supervised fine-tuning by incorporating multiple role perspectives, which helps to generate diverse reasoning chains. The framework utilizes unsupervised data construction and reinforcement learning with a focus on diversity as a reward signal, promoting both perspective and lexical diversity. Experimental results show that MultiRole-R1 significantly improves accuracy and diversity in reasoning tasks, highlighting the benefits of diversity-enhanced training in machine learning models."
                },
                "zh": {
                    "title": "å¤šæ ·æ€§å¢å¼ºï¼Œæå‡æ¨ç†å‡†ç¡®æ€§ä¸å¤šæ ·æ€§",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMultiRole-R1çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¤šè§’è‰²è§†è§’æ¥æé«˜ä¸»è§‚æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§å’Œå¤šæ ·æ€§ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ— ç›‘ç£æ•°æ®æ„å»ºç”ŸæˆåŒ…å«å¤šæ ·åŒ–è§’è‰²è§†è§’çš„æ¨ç†é“¾ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±å¡‘é€ æ¥ä¼˜åŒ–æ¨¡å‹ã€‚ç ”ç©¶å‘ç°ï¼Œå¢åŠ è§’è‰²è§†è§’èƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨ç†çš„å¤šæ ·æ€§å’Œå‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMultiRole-R1åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜äº†å¤šæ ·æ€§å¢å¼ºè®­ç»ƒåœ¨å¤§å‹æ¨ç†æ¨¡å‹ä¸­çš„æ½œåŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.20527",
            "title": "SAND-Math: Using LLMs to Generate Novel, Difficult and Useful\n  Mathematics Questions and Answers",
            "url": "https://huggingface.co/papers/2507.20527",
            "abstract": "A pipeline called SAND-Math generates and complexifies synthetic mathematics problems, enhancing the performance of large language models in mathematical reasoning tasks beyond existing datasets.  \t\t\t\t\tAI-generated summary \t\t\t\t The demand for Large Language Models (LLMs) capable of sophisticated mathematical reasoning is growing across industries. However, the development of performant mathematical LLMs is critically bottlenecked by the scarcity of difficult, novel training data. We introduce SAND-Math (Synthetic Augmented Novel and Difficult Mathematics problems and solutions), a pipeline that addresses this by first generating high-quality problems from scratch and then systematically elevating their complexity via a new Difficulty Hiking step. We demonstrate the effectiveness of our approach through two key findings. First, augmenting a strong baseline with SAND-Math data significantly boosts performance, outperforming the next-best synthetic dataset by uparrow 17.85 absolute points on the AIME25 benchmark. Second, in a dedicated ablation study, we show our Difficulty Hiking process is highly effective: by increasing average problem difficulty from 5.02 to 5.98, this step lifts AIME25 performance from 46.38\\% to 49.23\\%. The full generation pipeline, final dataset, and a fine-tuned model form a practical and scalable toolkit for building more capable and efficient mathematical reasoning LLMs. SAND-Math dataset is released here: https://huggingface.co/datasets/amd/SAND-MATH{https://huggingface.co/datasets/amd/SAND-MATH}",
            "score": 0,
            "issue_id": 5071,
            "pub_date": "2025-07-28",
            "pub_date_card": {
                "ru": "28 Ğ¸ÑĞ»Ñ",
                "en": "July 28",
                "zh": "7æœˆ28æ—¥"
            },
            "hash": "7191a2ca864f2e6c",
            "authors": [
                "Chaitanya Manem",
                "Pratik Prabhanjan Brahma",
                "Prakamya Mishra",
                "Zicheng Liu",
                "Emad Barsoum"
            ],
            "affiliations": [
                "Advanced Micro Devices, Inc. (AMD)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.20527.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#math",
                    "#reasoning",
                    "#dataset",
                    "#data",
                    "#synthetic"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "SAND-Math: Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ˜Ğ˜",
                    "desc": "SAND-Math - ÑÑ‚Ğ¾ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑƒÑĞ»Ğ¾Ğ¶Ğ½ĞµĞ½Ğ¸Ñ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞĞ½ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ° ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. SAND-Math Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ½ÑƒĞ»Ñ Ğ¸ Ğ¸Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑƒÑĞ»Ğ¾Ğ¶Ğ½ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑˆĞ°Ğ³Ğ° 'Difficulty Hiking'. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ SAND-Math Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° 17.85 Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ñ‹Ñ… Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ² Ñ‚ĞµÑÑ‚Ğµ AIME25."
                },
                "en": {
                    "title": "Boosting Mathematical Reasoning with SAND-Math",
                    "desc": "The paper presents SAND-Math, a novel pipeline designed to generate and increase the complexity of synthetic mathematics problems. This approach addresses the challenge of limited training data for Large Language Models (LLMs) in mathematical reasoning tasks. By creating high-quality problems and applying a Difficulty Hiking method, SAND-Math significantly enhances the performance of LLMs on benchmarks like AIME25. The results show that using SAND-Math data can improve model accuracy by over 17 points, demonstrating its effectiveness in training more capable mathematical reasoning models."
                },
                "zh": {
                    "title": "SAND-Mathï¼šæå‡æ•°å­¦æ¨ç†èƒ½åŠ›çš„åˆ›æ–°å·¥å…·",
                    "desc": "SAND-Mathæ˜¯ä¸€ä¸ªç”Ÿæˆå’Œå¤æ‚åŒ–åˆæˆæ•°å­¦é—®é¢˜çš„ç®¡é“ï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»é›¶å¼€å§‹ç”Ÿæˆé«˜è´¨é‡çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡æ–°çš„éš¾åº¦æå‡æ­¥éª¤ç³»ç»Ÿåœ°å¢åŠ å…¶å¤æ‚æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨SAND-Mathæ•°æ®å¢å¼ºçš„åŸºçº¿æ¨¡å‹åœ¨AIME25åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æ˜¾è‘—æå‡ï¼Œè¶…å‡ºä¸‹ä¸€ä¸ªæœ€ä½³åˆæˆæ•°æ®é›†17.85ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œéš¾åº¦æå‡è¿‡ç¨‹æœ‰æ•ˆåœ°å°†å¹³å‡é—®é¢˜éš¾åº¦ä»5.02æé«˜åˆ°5.98ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-07-28.html",
    "link_next": "2025-07-30.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "28.07",
        "en": "07/28",
        "zh": "7æœˆ28æ—¥"
    },
    "short_date_next": {
        "ru": "30.07",
        "en": "07/30",
        "zh": "7æœˆ30æ—¥"
    },
    "categories": {
        "#dataset": 4,
        "#data": 4,
        "#benchmark": 9,
        "#agents": 3,
        "#cv": 4,
        "#rl": 5,
        "#rlhf": 2,
        "#rag": 0,
        "#plp": 0,
        "#inference": 2,
        "#3d": 2,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 6,
        "#math": 2,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 2,
        "#training": 13,
        "#robotics": 0,
        "#agi": 2,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 8,
        "#transfer_learning": 1,
        "#graphs": 1,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 10,
        "#survey": 2,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 2,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 5,
        "#small_models": 1,
        "#science": 2,
        "#low_resource": 1
    }
}