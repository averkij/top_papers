{
    "date": {
        "ru": "25 ноября",
        "en": "November 25",
        "zh": "11月25日"
    },
    "time_utc": "2024-11-25 02:20",
    "weekday": 0,
    "issue_id": 751,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.14793",
            "title": "Style-Friendly SNR Sampler for Style-Driven Generation",
            "url": "https://huggingface.co/papers/2411.14793",
            "abstract": "Recent large-scale diffusion models generate high-quality images but struggle to learn new, personalized artistic styles, which limits the creation of unique style templates. Fine-tuning with reference images is the most promising approach, but it often blindly utilizes objectives and noise level distributions used for pre-training, leading to suboptimal style alignment. We propose the Style-friendly SNR sampler, which aggressively shifts the signal-to-noise ratio (SNR) distribution toward higher noise levels during fine-tuning to focus on noise levels where stylistic features emerge. This enables models to better capture unique styles and generate images with higher style alignment. Our method allows diffusion models to learn and share new \"style templates\", enhancing personalized content creation. We demonstrate the ability to generate styles such as personal watercolor paintings, minimal flat cartoons, 3D renderings, multi-panel images, and memes with text, thereby broadening the scope of style-driven generation.",
            "score": 9,
            "issue_id": 751,
            "pub_date": "2024-11-22",
            "pub_date_card": {
                "ru": "22 ноября",
                "en": "November 22",
                "zh": "11月22日"
            },
            "hash": "03859b57f29683ab",
            "authors": [
                "Jooyoung Choi",
                "Chaehun Shin",
                "Yeongtak Oh",
                "Heeseung Kim",
                "Sungroh Yoon"
            ],
            "affiliations": [
                "AIIS, ASRI, INMC, ISRC, and Interdisciplinary Program in AI, Seoul National University",
                "Data Science and AI Laboratory, ECE, Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14793.jpg",
            "data": {
                "error": "Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}"
            }
        }
    ],
    "link_prev": "2024-11-22.html",
    "link_next": "2024-11-26.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "22.11",
        "en": "11/22",
        "zh": "11月22日"
    },
    "short_date_next": {
        "ru": "26.11",
        "en": "11/26",
        "zh": "11月26日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了现有开源多模态大语言模型（MLLMs）的训练过程及其在分布偏移上的局限性。为了提升多模态推理能力，作者引入了偏好优化（PO）过程。他们创建了一个高质量的多模态推理偏好数据集MMPR，并开发了一种混合偏好优化（MPO）方法。结果显示，这种方法在多个基准测试中表现出色，特别是在多模态推理任务中。作者希望这项研究能激发更多进展。代码、数据和模型将公开发布。",
        "title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization",
        "pinyin": "这篇文章讨论了现有开源多模态大语言模型（MLLMs）的训练过程及其在分布偏移上的局限性。\nZhè piān wénzhāng tǎolùn le xiànyǒu kāiyuán duō móshì dà yǔyán móxíng (MLLMs) de xùnliàn guòchéng jí qí zài fēnbù piānyí shàng de júxìanxìng.\n\n为了提升多模态推理能力，作者引入了偏好优化（PO）过程。\nWèile tíshēng duō móshì tuīlǐ nénglì, zuòzhě yǐnrù le piānhào yōuhuà (PO) guòchéng.\n\n他们创建了一个高质量的多模态推理偏好数据集MMPR，并开发了一种混合偏好优化（MPO）方法。\nTāmen chuàngjiàn le yīgè gāo zhìliàng de duō móshì tuīlǐ piānhào shùjùjí MMPR, bìng kāifā le yīzhǒng hùnhé piānhào yōuhuà (MPO) fāngfǎ.\n\n结果显示，这种方法在多个基准测试中表现出色，特别是在多模态推理任务中。\nJiégǔo xiǎnshì, zhè zhǒng fāngfǎ zài duō gè jīzhǔn cèshì zhōng biǎoxiàn chūsè, tèbié shì zài duō móshì tuīlǐ rènwù zhōng.\n\n作者希望这项研究能激发更多进展。\nZuòzhě xīwàng zhè xiàng yánjiū néng jīfā gèng duō jìnzhǎn.\n\n代码、数据和模型将公开发布。\nDàimǎ, shùjù hé móxíng jiāng gōngkāi fābù.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'},\n{'word': '现有', 'pinyin': 'xiàn yǒu', 'trans': 'existing'},\n{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'},\n{'word': '多模态', 'pinyin': 'duō mó tài', 'trans': 'multimodal'},\n{'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'},\n{'word': '训练', 'pinyin': 'xùn liàn', 'trans': 'train'},\n{'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'},\n{'word': '局限性', 'pinyin': 'jú xiàn xìng', 'trans': 'limitations'},\n{'word': '提升', 'pinyin': 'tí shēng', 'trans': 'enhance'},\n{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'},\n{'word': '能力', 'pinyin': 'néng lì', 'trans': 'ability'},\n{'word': '引入', 'pinyin': 'yǐn rù', 'trans': 'introduce'},\n{'word': '偏好', 'pinyin': 'piān hào', 'trans': 'preference'},\n{'word': '优化', 'pinyin': 'yōu huà', 'trans': 'optimization'},\n{'word': '创建', 'pinyin': 'chuàng jiàn', 'trans': 'create'},\n{'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high-quality'},\n{'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'},\n{'word': '开发', 'pinyin': 'kāi fā', 'trans': 'develop'},\n{'word': '混合', 'pinyin': 'hùn hé', 'trans': 'hybrid'},\n{'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'},\n{'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'},\n{'word': '出色', 'pinyin': 'chū sè', 'trans': 'outstanding'},\n{'word': '特别', 'pinyin': 'tè bié', 'trans': 'particularly'},\n{'word': '任务', 'pinyin': 'rèn wu', 'trans': 'task'},\n{'word': '激发', 'pinyin': 'jī fā', 'trans': 'inspire'},\n{'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'},\n{'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'},\n{'word': '发布', 'pinyin': 'fā bù', 'trans': 'release'}]",
        "trans": "This article discusses the training process of existing open-source multimodal large language models (MLLMs) and their limitations in distribution shifts. To enhance multimodal reasoning capabilities, the authors introduce a preference optimization (PO) process. They created a high-quality multimodal reasoning preference dataset called MMPR and developed a hybrid preference optimization (MPO) method. The results show that this method performs excellently on multiple benchmark tests, particularly in multimodal reasoning tasks. The authors hope that this research will inspire further advancements. The code, data, and models will be publicly released.",
        "update_ts": "2024-11-24 09:32"
    }
}