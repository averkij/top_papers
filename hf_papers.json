{
    "date": {
        "ru": "6 ноября",
        "en": "November 6",
        "zh": "11月6日"
    },
    "time_utc": "2024-11-06 02:41",
    "weekday": 2,
    "issue_id": 437,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.02359",
            "title": "DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution",
            "url": "https://huggingface.co/papers/2411.02359",
            "abstract": "MLLMs have demonstrated remarkable comprehension and reasoning capabilities with complex language and visual data. These advances have spurred the vision of establishing a generalist robotic MLLM proficient in understanding complex human instructions and accomplishing various embodied tasks. However, developing MLLMs for real-world robots is challenging due to the typically limited computation and memory capacities available on robotic platforms. In contrast, the inference of MLLMs involves storing billions of parameters and performing tremendous computation, imposing significant hardware demands. In our paper, we propose a Dynamic Early-Exit Framework for Robotic Vision-Language-Action Model (DeeR-VLA, or simply DeeR) that automatically adjusts the size of the activated MLLM based on each situation at hand. The approach leverages a multi-exit architecture in MLLMs, which allows the model to terminate processing once a proper size of the model has been activated for a specific situation, thus avoiding further redundant computation. Additionally, we develop novel algorithms that establish early-termination criteria for DeeR, conditioned on predefined demands such as average computational cost (i.e., power consumption), as well as peak computational consumption (i.e., latency) and GPU memory usage. These enhancements ensure that DeeR operates efficiently under varying resource constraints while maintaining competitive performance. On the CALVIN robot manipulation benchmark, DeeR demonstrates significant reductions in computational costs of LLM by 5.2-6.5x and GPU memory of LLM by 2-6x without compromising performance. Code and checkpoints are available at https://github.com/yueyang130/DeeR-VLA.",
            "score": 4,
            "issue_id": 437,
            "pub_date": "2024-11-04",
            "pub_date_card": {
                "ru": "4 ноября",
                "en": "November 4",
                "zh": "11月4日"
            },
            "hash": "08c45469caff5fa0",
            "data": {
                "categories": [
                    "#agents",
                    "#inference",
                    "#robots",
                    "#optimization",
                    "#benchmark"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Эффективные языковые модели для роботов: меньше ресурсов, та же мощность",
                    "desc": "Статья представляет Dynamic Early-Exit Framework для робототехнических моделей зрения, языка и действия (DeeR-VLA). Эта система автоматически регулирует размер активированной мультимодальной языковой модели (MLLM) в зависимости от ситуации, используя архитектуру с множественными выходами. DeeR разработан для эффективной работы в условиях ограниченных вычислительных ресурсов роботов. На бенчмарке CALVIN система показала значительное снижение вычислительных затрат и использования памяти GPU без ущерба для производительности."
                },
                "en": {
                    "title": "Efficient Robotic Intelligence with Dynamic Early-Exit MLLMs",
                    "desc": "This paper introduces a new framework called DeeR for improving the efficiency of robotic vision-language-action models (MLLMs). DeeR uses a Dynamic Early-Exit approach that allows the model to adjust its size based on the specific task, reducing unnecessary computations. By implementing a multi-exit architecture, the model can stop processing once it has enough information, which helps save power and memory. The results show that DeeR can significantly lower computational costs and memory usage while still performing well on tasks, making it suitable for real-world robotic applications."
                },
                "zh": {
                    "title": "动态调整，智能机器人更高效！",
                    "desc": "本论文提出了一种动态早期退出框架（DeeR-VLA），旨在解决机器人视觉-语言-动作模型（MLLM）在实际应用中的计算和内存限制问题。该框架通过多出口架构，能够根据具体情况自动调整激活的模型大小，从而避免冗余计算。我们还开发了新算法，设定早期终止标准，以满足预定义的计算需求，如功耗和延迟。实验结果表明，DeeR在CALVIN机器人操作基准上显著降低了计算成本和GPU内存使用，同时保持了竞争力的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.02959",
            "title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
            "url": "https://huggingface.co/papers/2411.02959",
            "abstract": "Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and pruning strategies, to shorten the HTML while minimizing the loss of information. Specifically, we design a two-step block-tree-based pruning method that prunes useless HTML blocks and keeps only the relevant part of the HTML. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems.",
            "score": 4,
            "issue_id": 437,
            "pub_date": "2024-11-05",
            "pub_date_card": {
                "ru": "5 ноября",
                "en": "November 5",
                "zh": "11月5日"
            },
            "hash": "6fb8684374e5fdcb",
            "data": {
                "categories": [
                    "#rag",
                    "#data",
                    "#training"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "HtmlRAG: Улучшение RAG-систем с помощью структурированной веб-информации",
                    "desc": "Статья представляет новый подход к генерации с извлечением информации (RAG), названный HtmlRAG. В отличие от традиционных систем RAG, использующих простой текст, HtmlRAG сохраняет структурную и семантическую информацию HTML-документов. Авторы предлагают методы очистки, сжатия и обрезки HTML для уменьшения шума и сокращения входных токенов. Эксперименты на шести наборах данных для вопросно-ответных систем подтверждают превосходство использования HTML в системах RAG."
                },
                "en": {
                    "title": "Harnessing HTML for Enhanced Knowledge Retrieval in RAG Systems",
                    "desc": "This paper introduces HtmlRAG, a novel approach to Retrieval-Augmented Generation (RAG) that utilizes HTML instead of plain text for knowledge retrieval. By leveraging the structural and semantic information present in HTML, HtmlRAG aims to enhance the performance of large language models (LLMs) and reduce the hallucination problem. The authors address the challenges posed by HTML, such as excess tokens and noise, by implementing cleaning, compression, and pruning techniques to streamline the input. Experimental results demonstrate that HtmlRAG outperforms traditional plain-text-based RAG systems across multiple question-answering datasets."
                },
                "zh": {
                    "title": "用HTML提升检索增强生成的能力",
                    "desc": "本文提出了一种新的检索增强生成（RAG）方法，称为HtmlRAG，旨在改善大语言模型（LLMs）的知识能力并减少幻觉问题。HtmlRAG使用HTML格式而非纯文本来增强生成过程，从而保留更多的结构和语义信息。为了应对HTML中多余内容带来的挑战，本文提出了HTML清理、压缩和修剪策略，以减少输入的冗余信息。实验结果表明，HtmlRAG在六个问答数据集上的表现优于传统的纯文本RAG系统。"
                }
            }
        }
    ],
    "link_prev": "2024-11-05.html",
    "link_next": "2024-11-07.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "05.11",
        "en": "11/05",
        "zh": "11月5日"
    },
    "short_date_next": {
        "ru": "07.11",
        "en": "11/07",
        "zh": "11月7日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#medicine": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#translation": 0,
        "#robots": 0
    },
    "zh": {
        "text": "这篇文章讨论了自主代理在现实世界交互中的重要性，特别是Android代理。文章指出，现有研究缺乏对开源和闭源模型的系统研究。作者提出了AndroidLab，一个系统的Android代理框架，包含多种模态的操作环境和可重复的基准测试。该框架支持大型语言模型和多模态模型。通过使用AndroidLab环境，作者开发了一个Android指令数据集，并训练了六个开源的大型语言模型和多模态模型，显著提高了任务成功率。AndroidLab是开源的，可在GitHub上获取。",
        "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents",
        "pinyin": "Zhè piān wénzhāng tǎolùn le zìzhǔ dàilǐ zài xiànshí shìjiè jiāohù zhōng de zhòngyàoxìng, tèbié shì Android dàilǐ. Wénzhāng zhǐchū, xiànyǒu yánjiū quēfá duì kāiyuán hé bìyuán móxíng de xìtǒng yánjiū. Zuòzhě tíchū le AndroidLab, yīgè xìtǒng de Android dàilǐ kuàngjià, bāohán duōzhǒng mótài de cāozuò huánjìng hé kě chóngfù de jīzhǔn cèshì. Gāi kuàngjià zhīchí dàxíng yǔyán móxíng hé duō mótài móxíng. Tōngguò shǐyòng AndroidLab huánjìng, zuòzhě kāifā le yīgè Android zhǐlǐng shùjùjí, bìng xùnliàn le liù gè kāiyuán de dàxíng yǔyán móxíng hé duō mótài móxíng, xiǎnzhù tígāo le rènwù chénggōnglǜ. AndroidLab shì kāiyuán de, kě zài GitHub shàng huòqǔ.",
        "vocab": "[\n    {\"word\": \"自主代理\", \"pinyin\": \"zìzhǔ dàilǐ\", \"trans\": \"autonomous agent\"},\n    {\"word\": \"现实世界\", \"pinyin\": \"xiànshí shìjiè\", \"trans\": \"real world\"},\n    {\"word\": \"交互\", \"pinyin\": \"jiāohù\", \"trans\": \"interaction\"},\n    {\"word\": \"Android代理\", \"pinyin\": \"Android dàilǐ\", \"trans\": \"Android agent\"},\n    {\"word\": \"现有研究\", \"pinyin\": \"xiànyǒu yánjiū\", \"trans\": \"existing research\"},\n    {\"word\": \"缺乏\", \"pinyin\": \"quēfá\", \"trans\": \"lack\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāiyuán\", \"trans\": \"open source\"},\n    {\"word\": \"闭源\", \"pinyin\": \"bìyuán\", \"trans\": \"closed source\"},\n    {\"word\": \"系统研究\", \"pinyin\": \"xìtǒng yánjiū\", \"trans\": \"systematic study\"},\n    {\"word\": \"AndroidLab\", \"pinyin\": \"AndroidLab\", \"trans\": \"AndroidLab\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàngjià\", \"trans\": \"framework\"},\n    {\"word\": \"多种模态\", \"pinyin\": \"duōzhǒng móshì\", \"trans\": \"multimodal\"},\n    {\"word\": \"操作环境\", \"pinyin\": \"cāozuò huánjìng\", \"trans\": \"operating environment\"},\n    {\"word\": \"可重复\", \"pinyin\": \"kě chóngfù\", \"trans\": \"reproducible\"},\n    {\"word\": \"基准测试\", \"pinyin\": \"jīzhǔn cèshì\", \"trans\": \"benchmark test\"},\n    {\"word\": \"支持\", \"pinyin\": \"zhīchí\", \"trans\": \"support\"},\n    {\"word\": \"大型语言模型\", \"pinyin\": \"dàxíng yǔyán móxíng\", \"trans\": \"large language model\"},\n    {\"word\": \"多模态模型\", \"pinyin\": \"duō móshì móxíng\", \"trans\": \"multimodal model\"},\n    {\"word\": \"使用\", \"pinyin\": \"shǐyòng\", \"trans\": \"use\"},\n    {\"word\": \"环境\", \"pinyin\": \"huánjìng\", \"trans\": \"environment\"},\n    {\"word\": \"开发\", \"pinyin\": \"kāifā\", \"trans\": \"develop\"},\n    {\"word\": \"Android指令数据集\", \"pinyin\": \"Android zhǐlìng shùjùjí\", \"trans\": \"Android command dataset\"},\n    {\"word\": \"训练\", \"pinyin\": \"xùnliàn\", \"trans\": \"train\"},\n    {\"word\": \"六个\", \"pinyin\": \"liù gè\", \"trans\": \"six\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎnzhù\", \"trans\": \"significant\"},\n    {\"word\": \"提高\", \"pinyin\": \"tígāo\", \"trans\": \"improve\"},\n    {\"word\": \"任务成功率\", \"pinyin\": \"rènwù chénggōnglǜ\", \"trans\": \"task success rate\"},\n    {\"word\": \"GitHub\", \"pinyin\": \"GitHub\", \"trans\": \"GitHub\"}\n]",
        "trans": "This article discusses the importance of autonomous agents in real-world interactions, particularly Android agents. The article notes that existing research lacks systematic studies on open-source and closed-source models. The authors introduce AndroidLab, a systematic Android agent framework that includes multi-modal operation environments and reproducible benchmark tests. This framework supports large language models and multi-modal models. By using the AndroidLab environment, the authors developed an Android instruction dataset and trained six open-source large language models and multi-modal models, significantly improving task success rates. AndroidLab is open-source and available on GitHub.",
        "update_ts": "2024-11-05 10:13"
    }
}