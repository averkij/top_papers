{
    "date": {
        "ru": "25 Ğ¸ÑĞ»Ñ",
        "en": "July 25",
        "zh": "7æœˆ25æ—¥"
    },
    "time_utc": "2025-07-25 02:57",
    "weekday": 4,
    "issue_id": 5005,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.18537",
            "title": "TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive\n  Generation",
            "url": "https://huggingface.co/papers/2507.18537",
            "abstract": "TTS-VAR, a test-time scaling framework for visual auto-regressive models, improves generation quality by dynamically adjusting batch sizes and using clustering and resampling techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Scaling visual generation models is essential for real-world content creation, yet requires substantial training and computational expenses. Alternatively, test-time scaling has garnered growing attention due to resource efficiency and promising performance. In this work, we present TTS-VAR, the first general test-time scaling framework for visual auto-regressive (VAR) models, modeling the generation process as a path searching problem. To dynamically balance computational efficiency with exploration capacity, we first introduce an adaptive descending batch size schedule throughout the causal generation process. Besides, inspired by VAR's hierarchical coarse-to-fine multi-scale generation, our framework integrates two key components: (i) At coarse scales, we observe that generated tokens are hard for evaluation, possibly leading to erroneous acceptance of inferior samples or rejection of superior samples. Noticing that the coarse scales contain sufficient structural information, we propose clustering-based diversity search. It preserves structural variety through semantic feature clustering, enabling later selection on samples with higher potential. (ii) In fine scales, resampling-based potential selection prioritizes promising candidates using potential scores, which are defined as reward functions incorporating multi-scale generation history. Experiments on the powerful VAR model Infinity show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights reveal that early-stage structural features effectively influence final quality, and resampling efficacy varies across generation scales. Code is available at https://github.com/ali-vilab/TTS-VAR.",
            "score": 1,
            "issue_id": 5005,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 Ğ¸ÑĞ»Ñ",
                "en": "July 24",
                "zh": "7æœˆ24æ—¥"
            },
            "hash": "acf3b32f27e7342b",
            "authors": [
                "Zhekai Chen",
                "Ruihang Chu",
                "Yukang Chen",
                "Shiwei Zhang",
                "Yujie Wei",
                "Yingya Zhang",
                "Xihui Liu"
            ],
            "affiliations": [
                "CUHK",
                "HKU MMLab",
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18537.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#training",
                    "#optimization"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
                    "desc": "TTS-VAR - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. ĞĞ½Ğ° ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ñ€ĞµĞ³ÑƒĞ»Ğ¸Ñ€ÑƒÑ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ±Ğ°Ñ‚Ñ‡ĞµĞ¹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ€ĞµÑÑĞ¼Ğ¿Ğ»Ğ¸Ğ½Ğ³Ğ°. TTS-VAR Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ°Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿ÑƒÑ‚Ğ¸, Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€ÑƒÑ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğº Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ GenEval Ğ½Ğ° 8.7% Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Infinity."
                },
                "en": {
                    "title": "Dynamic Scaling for Enhanced Visual Generation Quality",
                    "desc": "TTS-VAR is a novel framework designed to enhance the quality of visual auto-regressive (VAR) models during the generation process. It introduces a dynamic batch size adjustment strategy that balances computational efficiency with the ability to explore diverse outputs. The framework employs clustering techniques at coarse scales to maintain structural diversity and resampling methods at fine scales to prioritize high-potential candidates based on their generation history. Experiments demonstrate a significant improvement in generation quality, highlighting the importance of early-stage features in the overall output."
                },
                "zh": {
                    "title": "åŠ¨æ€è°ƒæ•´ï¼Œæå‡ç”Ÿæˆè´¨é‡çš„åˆ›æ–°æ¡†æ¶",
                    "desc": "TTS-VARæ˜¯ä¸€ä¸ªç”¨äºè§†è§‰è‡ªå›å½’æ¨¡å‹çš„æµ‹è¯•æ—¶é—´ç¼©æ”¾æ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´æ‰¹é‡å¤§å°å’Œä½¿ç”¨èšç±»ä¸é‡é‡‡æ ·æŠ€æœ¯æ¥æé«˜ç”Ÿæˆè´¨é‡ã€‚è¯¥æ¡†æ¶å°†ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸ºè·¯å¾„æœç´¢é—®é¢˜ï¼Œæ—¨åœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡ä¸æ¢ç´¢èƒ½åŠ›ã€‚å®ƒåœ¨ç²—å°ºåº¦ä¸Šé‡‡ç”¨åŸºäºèšç±»çš„å¤šæ ·æ€§æœç´¢ï¼Œä»¥ä¿ç•™ç»“æ„å¤šæ ·æ€§ï¼Œå¹¶åœ¨ç»†å°ºåº¦ä¸Šé€šè¿‡é‡é‡‡æ ·ä¼˜å…ˆé€‰æ‹©æ½œåœ¨çš„ä¼˜è´¨æ ·æœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTTS-VARåœ¨å¼ºå¤§çš„VARæ¨¡å‹Infinityä¸Šå®ç°äº†8.7%çš„GenEvalåˆ†æ•°æå‡ï¼Œæ˜¾ç¤ºå‡ºæ—©æœŸç»“æ„ç‰¹å¾å¯¹æœ€ç»ˆè´¨é‡çš„æœ‰æ•ˆå½±å“ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.16535",
            "title": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent\n  Diffusion",
            "url": "https://huggingface.co/papers/2507.16535",
            "abstract": "Despite the remarkable developments achieved by recent 3D generation works, scaling these methods to geographic extents, such as modeling thousands of square kilometers of Earth's surface, remains an open challenge. We address this through a dual innovation in data infrastructure and model architecture. First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date, consisting of 50k curated scenes (each measuring 600m x 600m) captured across the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene provides pose-annotated multi-view images, depth maps, normals, semantic segmentation, and camera poses, with explicit quality control to ensure terrain diversity. Building on this foundation, we propose EarthCrafter, a tailored framework for large-scale 3D Earth generation via sparse-decoupled latent diffusion. Our architecture separates structural and textural generation: 1) Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the costly computation suffering from vast geographic scales while preserving critical information. 2) We propose condition-aware flow matching models trained on mixed inputs (semantics, images, or neither) to flexibly model latent geometry and texture features independently. Extensive experiments demonstrate that EarthCrafter performs substantially better in extremely large-scale generation. The framework further supports versatile applications, from semantic-guided urban layout generation to unconditional terrain synthesis, while maintaining geographic plausibility through our rich data priors from Aerial-Earth3D. Our project page is available at https://whiteinblue.github.io/earthcrafter/",
            "score": 1,
            "issue_id": 5005,
            "pub_date": "2025-07-22",
            "pub_date_card": {
                "ru": "22 Ğ¸ÑĞ»Ñ",
                "en": "July 22",
                "zh": "7æœˆ22æ—¥"
            },
            "hash": "7ee137161bbe047e",
            "authors": [
                "Shang Liu",
                "Chenjie Cao",
                "Chaohui Yu",
                "Wen Qian",
                "Jing Wang",
                "Fan Wang"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group",
                "Fudan University",
                "Hupan Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.16535.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#architecture",
                    "#synthetic",
                    "#3d",
                    "#dataset"
                ],
                "emoji": "ğŸŒ",
                "ru": {
                    "title": "EarthCrafter: Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ğ¾Ğ¼ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ—ĞµĞ¼Ğ»Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Aerial-Earth3D - ĞºÑ€ÑƒĞ¿Ğ½ĞµĞ¹ÑˆĞ¸Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… 3D Ğ°ÑÑ€Ğ¾ÑÑŠĞµĞ¼ĞºĞ¸, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ 50 Ñ‚Ñ‹ÑÑÑ‡ ÑÑ†ĞµĞ½ Ğ¿Ğ¾ Ğ²ÑĞµĞ¹ Ñ‚ĞµÑ€Ñ€Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¡Ğ¨Ğ. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº EarthCrafter Ğ´Ğ»Ñ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ·ĞµĞ¼Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° EarthCrafter Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ñ‹, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€ Ğ² ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºÑ€ÑƒĞ¿Ğ½Ğ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ñ… 3D-ÑÑ†ĞµĞ½ Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ³ĞµĞ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ."
                },
                "en": {
                    "title": "Revolutionizing Large-Scale 3D Earth Generation",
                    "desc": "This paper presents a solution to the challenge of generating large-scale 3D models of Earth's surface by introducing a new dataset and a novel model architecture. The Aerial-Earth3D dataset is the largest of its kind, containing 50,000 scenes with detailed annotations that support diverse terrain representation. The EarthCrafter framework utilizes a dual approach with sparse-decoupled latent diffusion, allowing for efficient generation of 3D structures and textures while managing computational costs. The results show significant improvements in generating realistic and plausible large-scale 3D environments, with applications in urban planning and terrain synthesis."
                },
                "zh": {
                    "title": "å¤§è§„æ¨¡3Dåœ°çƒç”Ÿæˆçš„æ–°çªç ´",
                    "desc": "å°½ç®¡æœ€è¿‘çš„3Dç”ŸæˆæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°†è¿™äº›æ–¹æ³•æ‰©å±•åˆ°å¤§è§„æ¨¡åœ°ç†èŒƒå›´ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬é€šè¿‡æ•°æ®åŸºç¡€è®¾æ–½å’Œæ¨¡å‹æ¶æ„çš„åŒé‡åˆ›æ–°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬ä»‹ç»äº†Aerial-Earth3Dï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„3Dèˆªç©ºæ•°æ®é›†ï¼ŒåŒ…å«50,000ä¸ªåœºæ™¯ï¼Œæ”¯æŒå¤§è§„æ¨¡çš„3Dåœ°çƒç”Ÿæˆã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†EarthCrafteræ¡†æ¶ï¼Œé€šè¿‡ç¨€ç–è§£è€¦çš„æ½œåœ¨æ‰©æ•£æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ•ˆçš„åœ°å½¢ç”Ÿæˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.14988",
            "title": "DMOSpeech 2: Reinforcement Learning for Duration Prediction in\n  Metric-Optimized Speech Synthesis",
            "url": "https://huggingface.co/papers/2507.14988",
            "abstract": "DMOSpeech 2 optimizes duration prediction and introduces teacher-guided sampling to enhance speech synthesis performance and diversity.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion-based text-to-speech (TTS) systems have made remarkable progress in zero-shot speech synthesis, yet optimizing all components for perceptual metrics remains challenging. Prior work with DMOSpeech demonstrated direct metric optimization for speech generation components, but duration prediction remained unoptimized. This paper presents DMOSpeech 2, which extends metric optimization to the duration predictor through a reinforcement learning approach. The proposed system implements a novel duration policy framework using group relative preference optimization (GRPO) with speaker similarity and word error rate as reward signals. By optimizing this previously unoptimized component, DMOSpeech 2 creates a more complete metric-optimized synthesis pipeline. Additionally, this paper introduces teacher-guided sampling, a hybrid approach leveraging a teacher model for initial denoising steps before transitioning to the student model, significantly improving output diversity while maintaining efficiency. Comprehensive evaluations demonstrate superior performance across all metrics compared to previous systems, while reducing sampling steps by half without quality degradation. These advances represent a significant step toward speech synthesis systems with metric optimization across multiple components. The audio samples, code and pre-trained models are available at https://dmospeech2.github.io/.",
            "score": 0,
            "issue_id": 5005,
            "pub_date": "2025-07-20",
            "pub_date_card": {
                "ru": "20 Ğ¸ÑĞ»Ñ",
                "en": "July 20",
                "zh": "7æœˆ20æ—¥"
            },
            "hash": "27df664b6cc093b4",
            "authors": [
                "Yinghao Aaron Li",
                "Xilin Jiang",
                "Fei Tao",
                "Cheng Niu",
                "Kaifeng Xu",
                "Juntong Song",
                "Nima Mesgarani"
            ],
            "affiliations": [
                "Columbia University",
                "NewsBreak"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.14988.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#training",
                    "#rl",
                    "#audio",
                    "#optimization"
                ],
                "emoji": "ğŸ™ï¸",
                "ru": {
                    "title": "ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ñ€ĞµÑ‡Ğ¸ Ğ½Ğ° Ğ²ÑĞµÑ… ÑƒÑ€Ğ¾Ğ²Ğ½ÑÑ…",
                    "desc": "DMOSpeech 2 - ÑÑ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ñ€ĞµÑ‡Ğ¸, Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰Ğ°Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ²ÑƒĞºĞ¾Ğ² Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞµ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¾Ğ²Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ (GRPO) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸ Ğ³Ğ¾Ğ»Ğ¾ÑĞ° Ğ´Ğ¸ĞºÑ‚Ğ¾Ñ€Ğ° Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ² Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ. DMOSpeech 2 Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¼ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸. ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Optimizing Duration for Diverse Speech Synthesis",
                    "desc": "DMOSpeech 2 enhances speech synthesis by optimizing duration prediction, which was previously unaddressed. It employs a reinforcement learning strategy with group relative preference optimization (GRPO) to improve the duration predictor using metrics like speaker similarity and word error rate. Additionally, the paper introduces teacher-guided sampling, which combines a teacher model for initial processing with a student model for efficiency, leading to greater output diversity. Overall, DMOSpeech 2 achieves superior performance in speech synthesis while reducing the number of sampling steps needed, marking a significant advancement in metric-optimized TTS systems."
                },
                "zh": {
                    "title": "ä¼˜åŒ–è¯­éŸ³åˆæˆï¼Œæå‡å¤šæ ·æ€§ä¸æ•ˆç‡",
                    "desc": "DMOSpeech 2 æ˜¯ä¸€ç§ä¼˜åŒ–è¯­éŸ³åˆæˆä¸­æŒç»­æ—¶é—´é¢„æµ‹çš„æ–°æ–¹æ³•ï¼Œé‡‡ç”¨äº†å¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥æ¥æå‡åˆæˆæ•ˆæœã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†åŸºäºç»„ç›¸å¯¹åå¥½çš„ä¼˜åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨è¯´è¯è€…ç›¸ä¼¼æ€§å’Œè¯é”™è¯¯ç‡ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œä»è€Œä¼˜åŒ–äº†ä¹‹å‰æœªä¼˜åŒ–çš„æŒç»­æ—¶é—´é¢„æµ‹ç»„ä»¶ã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒDMOSpeech 2 è¿˜é‡‡ç”¨äº†æ•™å¸ˆå¼•å¯¼é‡‡æ ·çš„æ–¹æ³•ï¼Œé€šè¿‡æ•™å¸ˆæ¨¡å‹è¿›è¡Œåˆæ­¥å»å™ªï¼Œå†è½¬å‘å­¦ç”Ÿæ¨¡å‹ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†è¾“å‡ºçš„å¤šæ ·æ€§ã€‚ç»¼åˆè¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºä¹‹å‰çš„ç³»ç»Ÿï¼ŒåŒæ—¶å°†é‡‡æ ·æ­¥éª¤å‡å°‘äº†ä¸€åŠï¼Œä¸”æ²¡æœ‰é™ä½è´¨é‡ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-07-24.html",
    "link_next": "2025-07-28.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "24.07",
        "en": "07/24",
        "zh": "7æœˆ24æ—¥"
    },
    "short_date_next": {
        "ru": "28.07",
        "en": "07/28",
        "zh": "7æœˆ28æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 1,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}