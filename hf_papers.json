{
    "date": {
        "ru": "28 Ğ¸ÑĞ»Ñ",
        "en": "July 28",
        "zh": "7æœˆ28æ—¥"
    },
    "time_utc": "2025-07-28 16:16",
    "weekday": 0,
    "issue_id": 5049,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.18553",
            "title": "The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane\n  Algorithm",
            "url": "https://huggingface.co/papers/2507.18553",
            "abstract": "Quantizing the weights of large language models (LLMs) from 16-bit to lower bitwidth is the de facto approach to deploy massive transformers onto more affordable accelerators. GPTQ emerged as one of the standard methods for one-shot post-training quantization at LLM scale. Yet, its inner workings are described as a sequence of ad-hoc algebraic updates that obscure any geometric meaning or worst-case guarantees. In this work, we show that, when executed back-to-front (from the last to first dimension) for a linear layer, GPTQ is mathematically identical to Babai's nearest plane algorithm for the classical closest vector problem (CVP) on a lattice defined by the Hessian matrix of the layer's inputs. This equivalence is based on a sophisticated mathematical argument, and has two analytical consequences: (i) the GPTQ error propagation step gains an intuitive geometric interpretation; (ii) GPTQ inherits the error upper bound of Babai's algorithm under the no-clipping condition. Taken together, these results place GPTQ on firm theoretical footing and open the door to importing decades of progress in lattice algorithms towards the design of future quantization algorithms for billion-parameter models.",
            "score": 16,
            "issue_id": 5043,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 Ğ¸ÑĞ»Ñ",
                "en": "July 24",
                "zh": "7æœˆ24æ—¥"
            },
            "hash": "61d9ee97f25af5b1",
            "authors": [
                "Jiale Chen",
                "Torsten Hoefler",
                "Dan Alistarh"
            ],
            "affiliations": [
                "ETH ZÃ¼rich",
                "Institute of Science and Technology Austria (ISTA)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18553.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#math"
                ],
                "emoji": "ğŸ”¢",
                "ru": {
                    "title": "GPTQ: ĞÑ‚ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğº Ñ‚ĞµĞ¾Ñ€Ğ¸Ğ¸ Ñ€ĞµÑˆĞµÑ‚Ğ¾Ğº",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ GPTQ Ğ´Ğ»Ñ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ GPTQ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚ĞµĞ½ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñƒ Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞµĞ¹ Ğ¿Ğ»Ğ¾ÑĞºĞ¾ÑÑ‚Ğ¸ Ğ‘Ğ°Ğ±Ğ°Ñ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞµĞ³Ğ¾ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ° Ğ½Ğ° Ñ€ĞµÑˆĞµÑ‚ĞºĞµ. Ğ­Ñ‚Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ´Ğ°ĞµÑ‚ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ² GPTQ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ĞµÑ€Ñ…Ğ½ÑÑ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ GPTQ Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Bridging Quantization and Lattice Algorithms for LLMs",
                    "desc": "This paper explores the process of quantizing weights in large language models (LLMs) to make them more efficient for deployment. It reveals that the widely used GPTQ method for quantization can be mathematically linked to Babai's nearest plane algorithm, which is used to solve the closest vector problem in lattice theory. This connection provides a clearer geometric understanding of how GPTQ works and establishes theoretical guarantees on its error rates. The findings suggest that advancements in lattice algorithms could enhance future quantization techniques for large models."
                },
                "zh": {
                    "title": "é‡åŒ–ç®—æ³•çš„æ–°è§†è§’ï¼šGPTQä¸Babaiç®—æ³•çš„ç­‰ä»·æ€§",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æƒé‡ä»16ä½é‡åŒ–åˆ°æ›´ä½ä½å®½çš„è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯GPTQæ–¹æ³•åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå½“å¯¹çº¿æ€§å±‚è¿›è¡Œåå‘æ‰§è¡Œæ—¶ï¼ŒGPTQä¸Babaiçš„æœ€è¿‘å¹³é¢ç®—æ³•åœ¨æ•°å­¦ä¸Šæ˜¯ç­‰ä»·çš„ï¼Œè¿™ä¸ºç†è§£GPTQçš„å‡ ä½•æ„ä¹‰æä¾›äº†æ–°çš„è§†è§’ã€‚é€šè¿‡è¿™ç§ç­‰ä»·å…³ç³»ï¼ŒGPTQçš„è¯¯å·®ä¼ æ’­æ­¥éª¤è·å¾—äº†ç›´è§‚çš„å‡ ä½•è§£é‡Šï¼Œå¹¶ä¸”åœ¨æ— è£å‰ªæ¡ä»¶ä¸‹ç»§æ‰¿äº†Babaiç®—æ³•çš„è¯¯å·®ä¸Šç•Œã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœä¸ºGPTQæä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ï¼Œå¹¶ä¸ºæœªæ¥çš„é‡åŒ–ç®—æ³•è®¾è®¡å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.16075",
            "title": "Deep Researcher with Test-Time Diffusion",
            "url": "https://huggingface.co/papers/2507.16075",
            "abstract": "The Test-Time Diffusion Deep Researcher (TTD-DR) framework uses a diffusion process with iterative refinement and external information retrieval to generate high-quality research reports, outperforming existing methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Deep research agents, powered by Large Language Models (LLMs), are rapidly advancing; yet, their performance often plateaus when generating complex, long-form research reports using generic test-time scaling algorithms. Drawing inspiration from the iterative nature of human research, which involves cycles of searching, reasoning, and revision, we propose the Test-Time Diffusion Deep Researcher (TTD-DR). This novel framework conceptualizes research report generation as a diffusion process. TTD-DR initiates this process with a preliminary draft, an updatable skeleton that serves as an evolving foundation to guide the research direction. The draft is then iteratively refined through a \"denoising\" process, which is dynamically informed by a retrieval mechanism that incorporates external information at each step. The core process is further enhanced by a self-evolutionary algorithm applied to each component of the agentic workflow, ensuring the generation of high-quality context for the diffusion process. This draft-centric design makes the report writing process more timely and coherent while reducing information loss during the iterative search process. We demonstrate that our TTD-DR achieves state-of-the-art results on a wide array of benchmarks that require intensive search and multi-hop reasoning, significantly outperforming existing deep research agents.",
            "score": 14,
            "issue_id": 5041,
            "pub_date": "2025-07-21",
            "pub_date_card": {
                "ru": "21 Ğ¸ÑĞ»Ñ",
                "en": "July 21",
                "zh": "7æœˆ21æ—¥"
            },
            "hash": "9f1a24496a9b9d36",
            "authors": [
                "Rujun Han",
                "Yanfei Chen",
                "Zoey CuiZhu",
                "Lesly Miculicich",
                "Guan Sun",
                "Yuanjun Bi",
                "Weiming Wen",
                "Hui Wan",
                "Chunfeng Wen",
                "SolÃ¨ne MaÃ®tre",
                "George Lee",
                "Vishy Tirumalashetty",
                "Emily Xue",
                "Zizhao Zhang",
                "Salem Haykal",
                "Burak Gokturk",
                "Tomas Pfister",
                "Chen-Yu Lee"
            ],
            "affiliations": [
                "Google Cloud AI Research",
                "Google Cloud Deep"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.16075.jpg",
            "data": {
                "categories": [
                    "#rag",
                    "#benchmark",
                    "#reasoning",
                    "#diffusion",
                    "#agents",
                    "#multimodal"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹: Ğ¾Ñ‚ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ° Ğº Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ¼Ñƒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñƒ",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Test-Time Diffusion Deep Researcher (TTD-DR) Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ². TTD-DR Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ñ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ñ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ° Ğ¸ Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞµĞ³Ğ¾, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑˆĞ°Ğ³Ğµ. TTD-DR Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ¸Ğ½Ñ‚ĞµĞ½ÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½Ñ‡Ğ°Ñ‚Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Revolutionizing Research Report Generation with TTD-DR",
                    "desc": "The Test-Time Diffusion Deep Researcher (TTD-DR) framework enhances the generation of research reports by utilizing a diffusion process that iteratively refines a preliminary draft. This draft acts as a flexible foundation, allowing for dynamic updates informed by external information retrieval at each step. By mimicking the iterative nature of human research, TTD-DR incorporates a 'denoising' process to improve coherence and reduce information loss. The framework has shown to outperform existing methods in generating complex, long-form reports, achieving state-of-the-art results across various benchmarks."
                },
                "zh": {
                    "title": "æµ‹è¯•æ—¶æ‰©æ•£æ·±åº¦ç ”ç©¶è€…ï¼šæå‡ç ”ç©¶æŠ¥å‘Šç”Ÿæˆçš„åˆ›æ–°æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæµ‹è¯•æ—¶æ‰©æ•£æ·±åº¦ç ”ç©¶è€…ï¼ˆTTD-DRï¼‰çš„æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆé«˜è´¨é‡çš„ç ”ç©¶æŠ¥å‘Šã€‚TTD-DRé€šè¿‡æ‰©æ•£è¿‡ç¨‹å’Œè¿­ä»£ç²¾ç‚¼ï¼Œç»“åˆå¤–éƒ¨ä¿¡æ¯æ£€ç´¢ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆå¤æ‚é•¿ç¯‡æŠ¥å‘Šçš„èƒ½åŠ›ã€‚è¯¥æ¡†æ¶ä»åˆæ­¥è‰ç¨¿å¼€å§‹ï¼Œåˆ©ç”¨åŠ¨æ€æ›´æ–°çš„ç»“æ„æŒ‡å¯¼ç ”ç©¶æ–¹å‘ï¼Œå¹¶é€šè¿‡å»å™ªè¿‡ç¨‹ä¸æ–­ä¼˜åŒ–è‰ç¨¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTTD-DRåœ¨å¤šé¡¹éœ€è¦æ·±å…¥æœç´¢å’Œå¤šæ­¥æ¨ç†çš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æ·±åº¦ç ”ç©¶ä»£ç†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.19478",
            "title": "MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI\n  Agents",
            "url": "https://huggingface.co/papers/2507.19478",
            "abstract": "A hierarchical benchmark evaluates GUI automation agents across multiple platforms, emphasizing key skills such as visual grounding, task planning, and efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI automation agents across Windows, macOS, Linux, iOS, Android, and Web platforms. It comprises four levels: GUI Content Understanding, Element Grounding, Task Automation, and Task Collaboration, covering essential skills for GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA) metric to assess GUI agent execution efficiency in online automation scenarios. Through MMBench-GUI, we identify accurate visual grounding as a critical determinant of overall task success, emphasizing the substantial benefits of modular frameworks that integrate specialized grounding modules. Furthermore, to achieve reliable GUI automation, an agent requires strong task planning and cross-platform generalization abilities, with long-context memory, a broad action space, and long-term reasoning playing a critical role. More important, task efficiency remains a critically underexplored dimension, and all models suffer from substantial inefficiencies, with excessive redundant steps even when tasks are ultimately completed. The integration of precise localization, effective planning, and early stopping strategies is indispensable to enable truly efficient and scalable GUI automation. Our benchmark code, evaluation data, and running environment will be publicly available at https://github.com/open-compass/MMBench-GUI.",
            "score": 13,
            "issue_id": 5047,
            "pub_date": "2025-07-25",
            "pub_date_card": {
                "ru": "25 Ğ¸ÑĞ»Ñ",
                "en": "July 25",
                "zh": "7æœˆ25æ—¥"
            },
            "hash": "d8f593881e96039a",
            "authors": [
                "Xuehui Wang",
                "Zhenyu Wu",
                "JingJing Xie",
                "Zichen Ding",
                "Bowen Yang",
                "Zehao Li",
                "Zhaoyang Liu",
                "Qingyun Li",
                "Xuan Dong",
                "Zhe Chen",
                "Weiyun Wang",
                "Xiangyu Zhao",
                "Jixuan Chen",
                "Haodong Duan",
                "Tianbao Xie",
                "Chenyu Yang",
                "Shiqian Su",
                "Yue Yu",
                "Yuan Huang",
                "Yiqian Liu",
                "Xiao Zhang",
                "Yanting Zhang",
                "Xiangyu Yue",
                "Weijie Su",
                "Xizhou Zhu",
                "Wei Shen",
                "Jifeng Dai",
                "Wenhai Wang"
            ],
            "affiliations": [
                "Donghua University",
                "Fudan University",
                "Harbin Institute of Technology",
                "Nanjing University",
                "Shanghai AI Laboratory",
                "Shanghai Jiao Tong University",
                "The Chinese University of Hong Kong",
                "The Hong Kong University of Science and Technology",
                "Tsinghua University",
                "University of Hong Kong",
                "University of Science and Technology of China",
                "Xiamen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.19478.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#agents",
                    "#benchmark",
                    "#long_context"
                ],
                "emoji": "ğŸ–¥ï¸",
                "ru": {
                    "title": "ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ GUI Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ MMBench-GUI - Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ° Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ…. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ²: Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾ GUI, Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºÑƒ Ğº ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½ÑƒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ Efficiency-Quality Area (EQA) Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ GUI Ğ² ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºĞ° ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼ ÑƒÑĞ¿ĞµÑ…Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¼ĞµĞ¶Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸."
                },
                "en": {
                    "title": "MMBench-GUI: Elevating GUI Automation Efficiency and Success",
                    "desc": "This paper presents MMBench-GUI, a comprehensive benchmark designed to evaluate GUI automation agents across various platforms like Windows, macOS, and mobile systems. It focuses on essential skills such as visual grounding, task planning, and efficiency, structured into four hierarchical levels. A new Efficiency-Quality Area (EQA) metric is introduced to measure the effectiveness of GUI agents in performing tasks efficiently. The findings highlight the importance of accurate visual grounding and the need for modular frameworks to enhance task success and reduce inefficiencies in automation processes."
                },
                "zh": {
                    "title": "è¯„ä¼°GUIè‡ªåŠ¨åŒ–ä»£ç†çš„åˆ†å±‚åŸºå‡†",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†MMBench-GUIï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰è‡ªåŠ¨åŒ–ä»£ç†çš„åˆ†å±‚åŸºå‡†ï¼Œæ¶µç›–å¤šä¸ªå¹³å°å¦‚Windowsã€macOSã€Linuxã€iOSã€Androidå’ŒWebã€‚è¯¥åŸºå‡†åŒ…æ‹¬å››ä¸ªå±‚æ¬¡ï¼šGUIå†…å®¹ç†è§£ã€å…ƒç´ å®šä½ã€ä»»åŠ¡è‡ªåŠ¨åŒ–å’Œä»»åŠ¡åä½œï¼Œé‡ç‚¹å…³æ³¨GUIä»£ç†æ‰€éœ€çš„å…³é”®æŠ€èƒ½ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ•ˆç‡-è´¨é‡åŒºåŸŸï¼ˆEQAï¼‰æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°åœ¨çº¿è‡ªåŠ¨åŒ–åœºæ™¯ä¸­GUIä»£ç†çš„æ‰§è¡Œæ•ˆç‡ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå‡†ç¡®çš„è§†è§‰å®šä½æ˜¯ä»»åŠ¡æˆåŠŸçš„å…³é”®å› ç´ ï¼Œå¼ºè°ƒäº†é›†æˆä¸“é—¨å®šä½æ¨¡å—çš„æ¨¡å—åŒ–æ¡†æ¶çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.18392",
            "title": "CLEAR: Error Analysis via LLM-as-a-Judge Made Easy",
            "url": "https://huggingface.co/papers/2507.18392",
            "abstract": "CLEAR is an interactive open-source package that provides detailed error analysis by generating per-instance feedback and system-level error issues, aiding in understanding and improving the performance of Large Language Models.  \t\t\t\t\tAI-generated summary \t\t\t\t The evaluation of Large Language Models (LLMs) increasingly relies on other LLMs acting as judges. However, current evaluation paradigms typically yield a single score or ranking, answering which model is better but not why. While essential for benchmarking, these top-level scores obscure the specific, actionable reasons behind a model's performance. To bridge this gap, we introduce CLEAR, an interactive, open-source package for LLM-based error analysis. CLEAR first generates per-instance textual feedback, then it creates a set of system-level error issues, and quantifies the prevalence of each identified issue. Our package also provides users with an interactive dashboard that allows for a comprehensive error analysis through aggregate visualizations, applies interactive filters to isolate specific issues or score ranges, and drills down to the individual instances that exemplify a particular behavioral pattern. We demonstrate CLEAR analysis for RAG and Math benchmarks, and showcase its utility through a user case study.",
            "score": 4,
            "issue_id": 5048,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 Ğ¸ÑĞ»Ñ",
                "en": "July 24",
                "zh": "7æœˆ24æ—¥"
            },
            "hash": "0d2181e726251651",
            "authors": [
                "Asaf Yehudai",
                "Lilach Eden",
                "Yotam Perlitz",
                "Roy Bar-Haim",
                "Michal Shmueli-Scheuer"
            ],
            "affiliations": [
                "IBM Research",
                "The Hebrew University of Jerusalem"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18392.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#rag",
                    "#interpretability",
                    "#math",
                    "#data",
                    "#multimodal",
                    "#benchmark"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "CLEAR: Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "CLEAR - ÑÑ‚Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ°ĞºĞµÑ‚ Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ´Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ½ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€Ğ° Ğ¸ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹, Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ Ğ¿Ğ¾Ğ½ÑÑ‚ÑŒ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ LLM. CLEAR ÑĞ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞŸĞ°ĞºĞµÑ‚ Ğ±Ñ‹Ğ» Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… RAG Ğ¸ Math, Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ² ÑĞ²Ğ¾Ñ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¼ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Unlocking Insights: CLEAR for LLM Error Analysis",
                    "desc": "CLEAR is an innovative open-source tool designed for detailed error analysis of Large Language Models (LLMs). It generates specific feedback for each instance, helping users understand the reasons behind model performance issues. By identifying system-level error patterns and quantifying their occurrence, CLEAR provides actionable insights that go beyond simple performance scores. The interactive dashboard enhances user experience by allowing for visual exploration of errors and filtering to focus on particular aspects of model behavior."
                },
                "zh": {
                    "title": "CLEARï¼šæå‡å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„äº’åŠ¨å·¥å…·",
                    "desc": "CLEARæ˜¯ä¸€ä¸ªäº’åŠ¨çš„å¼€æºå·¥å…·åŒ…ï¼Œæ—¨åœ¨é€šè¿‡ç”Ÿæˆæ¯ä¸ªå®ä¾‹çš„åé¦ˆå’Œç³»ç»Ÿçº§é”™è¯¯é—®é¢˜ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯åˆ†æï¼Œå¸®åŠ©ç†è§£å’Œæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°é€šå¸¸ä¾èµ–å…¶ä»–æ¨¡å‹ä½œä¸ºè¯„åˆ¤è€…ï¼Œä½†ç°æœ‰çš„è¯„ä¼°æ–¹æ³•å¾€å¾€åªç»™å‡ºå•ä¸€çš„åˆ†æ•°æˆ–æ’åï¼Œæ— æ³•è§£é‡Šæ¨¡å‹è¡¨ç°çš„åŸå› ã€‚CLEARé€šè¿‡ç”Ÿæˆæ–‡æœ¬åé¦ˆå’Œè¯†åˆ«ç³»ç»Ÿçº§é”™è¯¯ï¼Œå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ï¼Œå¹¶é‡åŒ–æ¯ä¸ªé—®é¢˜çš„å‡ºç°é¢‘ç‡ã€‚è¯¥å·¥å…·åŒ…è¿˜æä¾›äº†ä¸€ä¸ªäº’åŠ¨ä»ªè¡¨æ¿ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡å¯è§†åŒ–åˆ†æå’Œè¿‡æ»¤å™¨æ·±å…¥äº†è§£ç‰¹å®šé—®é¢˜æˆ–åˆ†æ•°èŒƒå›´ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.18742",
            "title": "Specification Self-Correction: Mitigating In-Context Reward Hacking\n  Through Test-Time Refinement",
            "url": "https://huggingface.co/papers/2507.18742",
            "abstract": "A new framework called Specification Self-Correction allows language models to dynamically correct flawed instructions during inference, reducing reward hacking vulnerabilities.  \t\t\t\t\tAI-generated summary \t\t\t\t Language models (LMs) are susceptible to in-context reward hacking, where they exploit flaws in tainted or faulty written specifications or rubrics to achieve high scores without fulfilling the user's true intent. We introduce Specification Self-Correction (SSC), a novel, test-time framework that enables an LM to identify and correct flaws within its own guiding specification. SSC employs a multi-step inference process where the model first generates a response based on a potentially tainted specification, critiques its output, and then revises the specification itself to remove the exploitable loophole. A final, more robust response is then generated using this self-corrected specification. Across experiments spanning creative writing and agentic coding tasks with several LMs, we demonstrate that while models initially game tainted specifications in 50-70\\% of cases, the SSC process reduces this vulnerability by over 90\\%. This dynamic repair occurs at inference time, requires no weight modification, and leads to more robustly aligned model behavior. Code at https://github.com/vicgalle/specification-self-correction .",
            "score": 2,
            "issue_id": 5041,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 Ğ¸ÑĞ»Ñ",
                "en": "July 24",
                "zh": "7æœˆ24æ—¥"
            },
            "hash": "d79620eb5872c01d",
            "authors": [
                "VÃ­ctor Gallego"
            ],
            "affiliations": [
                "Komorebi AI Technologies, Madrid, Spain"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18742.jpg",
            "data": {
                "categories": [
                    "#security",
                    "#rlhf",
                    "#alignment",
                    "#inference"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "Ğ¡Ğ°Ğ¼Ğ¾ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¹: Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾Ñ‚ ÑĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ğ¸",
                    "desc": "ĞĞ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Specification Self-Correction Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°, ÑĞ½Ğ¸Ğ¶Ğ°Ñ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğº ÑĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°, Ğ³Ğ´Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¸ÑĞºĞ°Ğ¶ĞµĞ½Ğ½ÑƒÑ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ, Ğ·Ğ°Ñ‚ĞµĞ¼ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºÑƒĞµÑ‚ ÑĞ²Ğ¾Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ°Ğ¼Ñƒ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ SSC ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğº ÑĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¹ Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ 90%. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº Ğ±Ğ¾Ğ»ĞµĞµ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¼Ñƒ Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸ÑĞ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ."
                },
                "en": {
                    "title": "Dynamic Self-Correction for Reliable Language Models",
                    "desc": "The paper introduces a new framework called Specification Self-Correction (SSC) designed to enhance the reliability of language models (LMs) by correcting flawed instructions during their operation. It addresses the issue of reward hacking, where LMs exploit weaknesses in their guiding specifications to achieve high scores without meeting user expectations. SSC operates through a multi-step inference process, allowing the model to critique its own outputs and revise the specifications to eliminate loopholes. Experimental results show that SSC significantly reduces the instances of reward hacking, improving the alignment of model behavior without requiring changes to the model's weights."
                },
                "zh": {
                    "title": "è§„èŒƒè‡ªæˆ‘ä¿®æ­£ï¼šæå‡è¯­è¨€æ¨¡å‹çš„é²æ£’æ€§",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç§°ä¸ºè§„èŒƒè‡ªæˆ‘ä¿®æ­£ï¼ˆSpecification Self-Correctionï¼ŒSSCï¼‰ï¼Œæ—¨åœ¨å¸®åŠ©è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€ä¿®æ­£æœ‰ç¼ºé™·çš„æŒ‡ä»¤ï¼Œä»è€Œå‡å°‘å¥–åŠ±é»‘å®¢æ”»å‡»çš„é£é™©ã€‚è¯­è¨€æ¨¡å‹å®¹æ˜“å—åˆ°ä¸Šä¸‹æ–‡å¥–åŠ±é»‘å®¢çš„å½±å“ï¼Œå³åˆ©ç”¨ä¸å®Œå–„çš„ä¹¦é¢è§„èŒƒæ¥è·å¾—é«˜åˆ†ï¼Œè€Œæœªèƒ½çœŸæ­£æ»¡è¶³ç”¨æˆ·çš„æ„å›¾ã€‚SSCæ¡†æ¶é€šè¿‡å¤šæ­¥éª¤æ¨ç†è¿‡ç¨‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«å¹¶ä¿®æ­£è‡ªèº«æŒ‡å¯¼è§„èŒƒä¸­çš„ç¼ºé™·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSCæ˜¾è‘—é™ä½äº†æ¨¡å‹åœ¨ä½¿ç”¨æœ‰ç¼ºé™·è§„èŒƒæ—¶çš„æ¼æ´åˆ©ç”¨ç‡ï¼Œæå‡äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå¯¹é½è¡Œä¸ºã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.17596",
            "title": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
            "url": "https://huggingface.co/papers/2507.17596",
            "abstract": "PRIX, an end-to-end driving architecture using only camera data, achieves state-of-the-art performance with a Context-aware Recalibration Transformer, outperforming larger multimodal planners in efficiency and scalability.  \t\t\t\t\tAI-generated summary \t\t\t\t While end-to-end autonomous driving models show promising results, their practical deployment is often hindered by large model sizes, a reliance on expensive LiDAR sensors and computationally intensive BEV feature representations. This limits their scalability, especially for mass-market vehicles equipped only with cameras. To address these challenges, we propose PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving architecture operates using only camera data, without explicit BEV representation and forgoing the need for LiDAR. PRIX leverages a visual feature extractor coupled with a generative planning head to predict safe trajectories from raw pixel inputs directly. A core component of our architecture is the Context-aware Recalibration Transformer (CaRT), a novel module designed to effectively enhance multi-level visual features for more robust planning. We demonstrate through comprehensive experiments that PRIX achieves state-of-the-art performance on the NavSim and nuScenes benchmarks, matching the capabilities of larger, multimodal diffusion planners while being significantly more efficient in terms of inference speed and model size, making it a practical solution for real-world deployment. Our work is open-source and the code will be at https://maxiuw.github.io/prix.",
            "score": 2,
            "issue_id": 5040,
            "pub_date": "2025-07-23",
            "pub_date_card": {
                "ru": "23 Ğ¸ÑĞ»Ñ",
                "en": "July 23",
                "zh": "7æœˆ23æ—¥"
            },
            "hash": "13d4f0dd6ee82302",
            "authors": [
                "Maciej K. Wozniak",
                "Lianhang Liu",
                "Yixi Cai",
                "Patric Jensfelt"
            ],
            "affiliations": [
                "KTH Royal Institute of Technology, Sweden",
                "Scania CV AB"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.17596.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#cv",
                    "#architecture",
                    "#open_source",
                    "#benchmark",
                    "#optimization"
                ],
                "emoji": "ğŸš—",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğµ Ğ²Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ· LiDAR",
                    "desc": "PRIX - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ°Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞºĞ°Ğ¼ĞµÑ€ Ğ±ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ LiDAR Ğ¸ BEV-Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ¼ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Context-aware Recalibration Transformer (CaRT), ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ¸Ğ¹ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. PRIX Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… NavSim Ğ¸ nuScenes, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ñ‹Ñ… Ñ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ°Ğ¼Ğ¸. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒÑ, Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚ ĞµĞµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Driving Innovation with Camera-Only Solutions",
                    "desc": "PRIX is an innovative end-to-end driving architecture that utilizes only camera data to enhance autonomous driving capabilities. It introduces the Context-aware Recalibration Transformer (CaRT), which improves the processing of visual features for better trajectory planning. By eliminating the need for expensive LiDAR sensors and complex BEV representations, PRIX offers a more efficient and scalable solution for mass-market vehicles. Comprehensive experiments show that PRIX achieves state-of-the-art performance while being smaller and faster than traditional multimodal planners."
                },
                "zh": {
                    "title": "PRIXï¼šä»…ç”¨æ‘„åƒå¤´æ•°æ®çš„é«˜æ•ˆè‡ªåŠ¨é©¾é©¶è§£å†³æ–¹æ¡ˆ",
                    "desc": "PRIXæ˜¯ä¸€ç§ä»…ä½¿ç”¨æ‘„åƒå¤´æ•°æ®çš„ç«¯åˆ°ç«¯é©¾é©¶æ¶æ„ï¼Œé‡‡ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡æ ¡å‡†å˜æ¢å™¨ï¼ˆCaRTï¼‰ï¼Œåœ¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§ä¸Šè¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„å¤šæ¨¡æ€è§„åˆ’å™¨ã€‚è¯¥æ¨¡å‹è§£å†³äº†ä¼ ç»Ÿè‡ªåŠ¨é©¾é©¶æ¨¡å‹ä¾èµ–æ˜‚è´µçš„æ¿€å…‰é›·è¾¾ä¼ æ„Ÿå™¨å’Œè®¡ç®—å¯†é›†å‹BEVç‰¹å¾è¡¨ç¤ºçš„é—®é¢˜ï¼Œä½¿å…¶æ›´é€‚åˆå¤§ä¼—å¸‚åœºçš„è½¦è¾†ã€‚PRIXé€šè¿‡è§†è§‰ç‰¹å¾æå–å™¨å’Œç”Ÿæˆè§„åˆ’å¤´ï¼Œç›´æ¥ä»åŸå§‹åƒç´ è¾“å…¥é¢„æµ‹å®‰å…¨è½¨è¿¹ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒPRIXåœ¨NavSimå’ŒnuScenesåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡ä¸å¤§å‹å¤šæ¨¡æ€æ‰©æ•£è§„åˆ’å™¨ç›¸å½“çš„èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨æ¨ç†é€Ÿåº¦å’Œæ¨¡å‹å¤§å°ä¸Šæ˜¾è‘—æ›´é«˜æ•ˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.10510",
            "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from\n  Human to AI",
            "url": "https://huggingface.co/papers/2507.10510",
            "abstract": "Artic addresses latency issues in AI Video Chat by optimizing video streaming and frame rate adaptation to enhance MLLM accuracy and reduce bitrate.  \t\t\t\t\tAI-generated summary \t\t\t\t AI Video Chat emerges as a new paradigm for Real-time Communication (RTC), where one peer is not a human, but a Multimodal Large Language Model (MLLM). This makes interaction between humans and AI more intuitive, as if chatting face-to-face with a real person. However, this poses significant challenges to latency, because the MLLM inference takes up most of the response time, leaving very little time for video streaming. Due to network uncertainty and instability, transmission latency becomes a critical bottleneck preventing AI from being like a real person. To address this, we propose Artic, an AI-oriented Real-time Communication framework, exploring the network requirement shift from \"humans watching video\" to \"AI understanding video\". To reduce bitrate dramatically while maintaining MLLM accuracy, we propose Context-Aware Video Streaming that recognizes the importance of each video region for chat and allocates bitrate almost exclusively to chat-important regions. To avoid packet retransmission, we propose Loss-Resilient Adaptive Frame Rate that leverages previous frames to substitute for lost/delayed frames while avoiding bitrate waste. To evaluate the impact of video streaming quality on MLLM accuracy, we build the first benchmark, named Degraded Video Understanding Benchmark (DeViBench). Finally, we discuss some open questions and ongoing solutions for AI Video Chat.",
            "score": 2,
            "issue_id": 5037,
            "pub_date": "2025-07-14",
            "pub_date_card": {
                "ru": "14 Ğ¸ÑĞ»Ñ",
                "en": "July 14",
                "zh": "7æœˆ14æ—¥"
            },
            "hash": "d931480372d88084",
            "authors": [
                "Jiangkai Wu",
                "Zhiyuan Ren",
                "Liming Liu",
                "Xinggong Zhang"
            ],
            "affiliations": [
                "Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.10510.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#survey",
                    "#multimodal",
                    "#video"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Artic: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾Ñ‡Ğ°Ñ‚Ğµ Ñ Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Artic - Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ‡Ğ°Ñ‚Ğ° Ñ Ğ˜Ğ˜. ĞĞ½ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼ÑƒÑ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²ÑƒÑ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ Ğ²Ğ¸Ğ´ĞµĞ¾, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ²Ñ‹Ğ´ĞµĞ»ÑĞµÑ‚ Ğ±Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğ¼ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑĞ¼. Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° ĞºĞ°Ğ´Ñ€Ğ¾Ğ², ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ°Ñ Ğº Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ¼, Ğ´Ğ»Ñ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº DeViBench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ½Ğ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Optimizing AI Video Chat for Real-Time Interaction",
                    "desc": "The paper presents Artic, a framework designed to improve latency in AI Video Chat by optimizing video streaming and frame rate adaptation. It focuses on enhancing the accuracy of Multimodal Large Language Models (MLLMs) while minimizing the bitrate required for video transmission. By implementing Context-Aware Video Streaming, Artic prioritizes important video regions for chat, ensuring efficient bitrate allocation. Additionally, the Loss-Resilient Adaptive Frame Rate technique helps maintain video quality by using previous frames to compensate for lost or delayed ones, thus addressing the challenges posed by network instability."
                },
                "zh": {
                    "title": "ä¼˜åŒ–AIè§†é¢‘èŠå¤©ï¼Œæå‡å®æ—¶æ²Ÿé€šä½“éªŒ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºArticçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³AIè§†é¢‘èŠå¤©ä¸­çš„å»¶è¿Ÿé—®é¢˜ã€‚é€šè¿‡ä¼˜åŒ–è§†é¢‘æµå’Œå¸§ç‡é€‚åº”ï¼ŒArticèƒ½å¤Ÿæé«˜å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶å‡å°‘æ¯”ç‰¹ç‡ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†é¢‘æµæŠ€æœ¯ï¼Œä¼˜å…ˆåˆ†é…æ¯”ç‰¹ç‡ç»™å¯¹èŠå¤©é‡è¦çš„è§†é¢‘åŒºåŸŸï¼Œä»è€Œæ˜¾è‘—é™ä½æ¯”ç‰¹ç‡ã€‚ä¸ºäº†é¿å…æ•°æ®åŒ…é‡ä¼ ï¼ŒArticè¿˜å¼•å…¥äº†æŠ—ä¸¢åŒ…è‡ªé€‚åº”å¸§ç‡æŠ€æœ¯ï¼Œåˆ©ç”¨ä¹‹å‰çš„å¸§æ¥æ›¿ä»£ä¸¢å¤±æˆ–å»¶è¿Ÿçš„å¸§ï¼Œè¿›ä¸€æ­¥æå‡äº†è§†é¢‘èŠå¤©çš„æµç•…æ€§ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-07-25.html",
    "link_next": "2025-07-29.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "25.07",
        "en": "07/25",
        "zh": "7æœˆ25æ—¥"
    },
    "short_date_next": {
        "ru": "29.07",
        "en": "07/29",
        "zh": "7æœˆ29æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 1,
        "#benchmark": 5,
        "#agents": 3,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 2,
        "#plp": 0,
        "#inference": 2,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 3,
        "#math": 2,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 4,
        "#survey": 1,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}