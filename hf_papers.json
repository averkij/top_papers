{
    "date": {
        "ru": "15 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
        "en": "September 15",
        "zh": "9æœˆ15æ—¥"
    },
    "time_utc": "2025-09-15 23:09",
    "weekday": 0,
    "issue_id": 5904,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.06652",
            "title": "IntrEx: A Dataset for Modeling Engagement in Educational Conversations",
            "url": "https://huggingface.co/papers/2509.06652",
            "abstract": "IntrEx, a large dataset annotated for interestingness in educational conversations, shows that fine-tuned LLMs can predict human judgments of interestingness better than larger proprietary models, highlighting the role of linguistic and cognitive factors in engagement.  \t\t\t\t\tAI-generated summary \t\t\t\t Engagement and motivation are crucial for second-language acquisition, yet maintaining learner interest in educational conversations remains a challenge. While prior research has explored what makes educational texts interesting, still little is known about the linguistic features that drive engagement in conversations. To address this gap, we introduce IntrEx, the first large dataset annotated for interestingness and expected interestingness in teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus (TSCC), IntrEx extends prior work by incorporating sequence-level annotations, allowing for the study of engagement beyond isolated turns to capture how interest evolves over extended dialogues. We employ a rigorous annotation process with over 100 second-language learners, using a comparison-based rating approach inspired by reinforcement learning from human feedback (RLHF) to improve agreement. We investigate whether large language models (LLMs) can predict human interestingness judgments. We find that LLMs (7B/8B parameters) fine-tuned on interestingness ratings outperform larger proprietary models like GPT-4o, demonstrating the potential for specialised datasets to model engagement in educational settings. Finally, we analyze how linguistic and cognitive factors, such as concreteness, comprehensibility (readability), and uptake, influence engagement in educational dialogues.",
            "score": 21,
            "issue_id": 5890,
            "pub_date": "2025-09-08",
            "pub_date_card": {
                "ru": "8 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 8",
                "zh": "9æœˆ8æ—¥"
            },
            "hash": "50c590f2ee4baa42",
            "authors": [
                "Xingwei Tan",
                "Mahathi Parvatham",
                "Chiara Gambi",
                "Gabriele Pergola"
            ],
            "affiliations": [
                "Department of Computer Science, University of Warwick, UK",
                "Department of Psychology, University of Warwick, UK",
                "School of Computer Science, University of Sheffield, UK"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.06652.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#interpretability",
                    "#multimodal",
                    "#rlhf",
                    "#science",
                    "#dataset",
                    "#healthcare"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ˜Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²: ĞºĞ»ÑÑ‡ Ğº ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ IntrEx - ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚, Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°Ñ…. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° ÑÑ‚Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾ÑÑ‚Ğ¸, Ñ‡ĞµĞ¼ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¿Ñ€Ğ¸ĞµÑ‚Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ñ‹ÑĞ²Ğ¸Ğ» Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ³Ğ²Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ½Ğ° Ğ²Ğ¾Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ ÑƒÑ‡Ğ°Ñ‰Ğ¸Ñ…ÑÑ. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¾Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…."
                },
                "en": {
                    "title": "Unlocking Engagement: Fine-Tuning LLMs for Interesting Educational Conversations",
                    "desc": "The paper introduces IntrEx, a novel dataset designed to assess interestingness in educational conversations, particularly in teacher-student interactions. It demonstrates that fine-tuned large language models (LLMs) can more accurately predict human judgments of interestingness compared to larger proprietary models. The study emphasizes the importance of linguistic features, such as concreteness and comprehensibility, in maintaining learner engagement during dialogues. By utilizing a rigorous annotation process and a comparison-based rating approach, the research highlights how specialized datasets can enhance the modeling of engagement in educational contexts."
                },
                "zh": {
                    "title": "è¶£å‘³æ€§é©±åŠ¨å­¦ä¹ è€…å‚ä¸çš„å…³é”®",
                    "desc": "IntrExæ˜¯ä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼Œä¸“é—¨æ ‡æ³¨äº†æ•™è‚²å¯¹è¯ä¸­çš„è¶£å‘³æ€§ï¼Œæ—¨åœ¨ç ”ç©¶è¯­è¨€å’Œè®¤çŸ¥å› ç´ å¦‚ä½•å½±å“å­¦ä¹ è€…çš„å‚ä¸æ„Ÿã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢„æµ‹äººç±»å¯¹è¶£å‘³æ€§çš„åˆ¤æ–­æ–¹é¢ï¼Œè¡¨ç°ä¼˜äºæ›´å¤§çš„ä¸“æœ‰æ¨¡å‹ï¼Œå¦‚GPT-4oã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†ä¸“é—¨æ•°æ®é›†åœ¨æ•™è‚²ç¯å¢ƒä¸­å»ºæ¨¡å‚ä¸æ„Ÿçš„æ½œåŠ›ã€‚é€šè¿‡åˆ†æè¯­è¨€ç‰¹å¾ï¼Œå¦‚å…·ä½“æ€§å’Œå¯ç†è§£æ€§ï¼Œç ”ç©¶æ­ç¤ºäº†è¿™äº›å› ç´ å¦‚ä½•å½±å“æ•™è‚²å¯¹è¯ä¸­çš„å­¦ä¹ è€…å…´è¶£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10441",
            "title": "InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis",
            "url": "https://huggingface.co/papers/2509.10441",
            "abstract": "InfGen, a one-step generator replacing the VAE decoder, enables arbitrary high-resolution image generation from a fixed-size latent, significantly reducing computational complexity and generation time.  \t\t\t\t\tAI-generated summary \t\t\t\t Arbitrary resolution image generation provides a consistent visual experience across devices, having extensive applications for producers and consumers. Current diffusion models increase computational demand quadratically with resolution, causing 4K image generation delays over 100 seconds. To solve this, we explore the second generation upon the latent diffusion models, where the fixed latent generated by diffusion models is regarded as the content representation and we propose to decode arbitrary resolution images with a compact generated latent using a one-step generator. Thus, we present the InfGen, replacing the VAE decoder with the new generator, for generating images at any resolution from a fixed-size latent without retraining the diffusion models, which simplifies the process, reducing computational complexity and can be applied to any model using the same latent space. Experiments show InfGen is capable of improving many models into the arbitrary high-resolution era while cutting 4K image generation time to under 10 seconds.",
            "score": 18,
            "issue_id": 5883,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "c6a96819cd15917d",
            "authors": [
                "Tao Han",
                "Wanghan Xu",
                "Junchao Gong",
                "Xiaoyu Yue",
                "Song Guo",
                "Luping Zhou",
                "Lei Bai"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Shanghai Artificial Intelligence Laboratory",
                "The University of Sydney"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10441.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#cv",
                    "#architecture",
                    "#diffusion"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "InfGen: Ğ¼Ğ³Ğ½Ğ¾Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ",
                    "desc": "InfGen - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ·Ğ°Ğ¼ĞµĞ½ÑÑÑ‰Ğ¸Ğ¹ Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€ VAE Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸. ĞĞ½ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°. InfGen Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ InfGen ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ÑĞ²ĞµÑ€Ñ…Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ, ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ğ² Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 4K-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ¾ Ğ¼ĞµĞ½ĞµĞµ 10 ÑĞµĞºÑƒĞ½Ğ´."
                },
                "en": {
                    "title": "Revolutionizing High-Resolution Image Generation with InfGen",
                    "desc": "InfGen is a novel one-step generator that replaces the traditional VAE decoder, allowing for high-resolution image generation from a fixed-size latent representation. This approach significantly reduces the computational complexity and generation time associated with creating images, particularly at 4K resolution. By utilizing a compact generated latent from diffusion models, InfGen enables arbitrary resolution outputs without the need for retraining existing models. Experiments demonstrate that InfGen can enhance various models, achieving 4K image generation in under 10 seconds, thus streamlining the image generation process."
                },
                "zh": {
                    "title": "InfGenï¼šé«˜æ•ˆç”Ÿæˆä»»æ„åˆ†è¾¨ç‡å›¾åƒçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆ",
                    "desc": "InfGenæ˜¯ä¸€ç§æ–°å‹ç”Ÿæˆå™¨ï¼Œå–ä»£äº†å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰çš„è§£ç å™¨ï¼Œèƒ½å¤Ÿä»å›ºå®šå¤§å°çš„æ½œåœ¨ç©ºé—´ç”Ÿæˆä»»æ„é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚æ€§å’Œç”Ÿæˆæ—¶é—´ï¼Œä½¿å¾—ç”Ÿæˆ4Kå›¾åƒçš„æ—¶é—´ç¼©çŸ­åˆ°10ç§’ä»¥å†…ã€‚é€šè¿‡å°†æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›ºå®šæ½œåœ¨è§†ä¸ºå†…å®¹è¡¨ç¤ºï¼ŒInfGenèƒ½å¤Ÿåœ¨ä¸é‡æ–°è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œè§£ç ä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒã€‚å®éªŒè¡¨æ˜ï¼ŒInfGenå¯ä»¥æå‡å¤šç§æ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨åŠ¨é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆçš„è¿›ç¨‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09677",
            "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in\n  LLMs",
            "url": "https://huggingface.co/papers/2509.09677",
            "abstract": "Scaling large language models improves their ability to execute longer tasks by isolating execution capability and mitigating self-conditioning effects, despite diminishing single-step accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.",
            "score": 18,
            "issue_id": 5883,
            "pub_date": "2025-09-11",
            "pub_date_card": {
                "ru": "11 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 11",
                "zh": "9æœˆ11æ—¥"
            },
            "hash": "03dddc4470e66eb9",
            "authors": [
                "Akshit Sinha",
                "Arvindh Arun",
                "Shashwat Goel",
                "Steffen Staab",
                "Jonas Geiping"
            ],
            "affiliations": [
                "ELLIS Institute TÃ¼bingen",
                "Institute for AI, University of Stuttgart",
                "Max Planck Institute for Intelligent Systems",
                "TÃ¼bingen AI Center",
                "University of Cambridge",
                "University of Southampton"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09677.jpg",
            "data": {
                "categories": [
                    "#long_context",
                    "#architecture",
                    "#reasoning",
                    "#benchmark",
                    "#rl"
                ],
                "emoji": "ğŸ“ˆ",
                "ru": {
                    "title": "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ LLM: Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ½Ğ° Ğ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ñƒ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑˆĞ°Ğ³Ğ¾Ğ². Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ² Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ ÑĞ²ÑĞ·Ğ°Ğ½Ñ‹ Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ğ¼Ğ¸ Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸, Ğ° Ğ½Ğµ Ñ Ğ½ĞµÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´Ğ°Ñ‚ÑŒ. ĞšÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ³Ğ¾, Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¾ ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑĞ»Ğ¾Ğ²Ğ»Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ÑÑ‚ÑÑ Ğ±Ğ¾Ğ»ĞµĞµ ÑĞºĞ»Ğ¾Ğ½Ğ½Ñ‹ Ğº Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼ Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğ¸ Ğ¸Ñ… Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ."
                },
                "en": {
                    "title": "Scaling Models for Better Long-Task Execution",
                    "desc": "This paper explores how scaling large language models (LLMs) enhances their performance on longer tasks, despite a decrease in accuracy for individual steps. The authors argue that the challenges LLMs face with extended tasks stem from execution errors rather than reasoning limitations. They propose a method to isolate execution capability by providing explicit knowledge and planning for long-horizon tasks. The findings suggest that larger models can handle more complex tasks effectively, even when smaller models achieve perfect accuracy on single-step tasks, highlighting the importance of model size and compute resources for task execution."
                },
                "zh": {
                    "title": "æ‰©å¤§æ¨¡å‹è§„æ¨¡ï¼Œæå‡é•¿ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ‰§è¡Œé•¿ä»»åŠ¡æ—¶çš„èƒ½åŠ›æå‡ï¼Œå°½ç®¡å•æ­¥å‡†ç¡®ç‡å¯èƒ½ä¸‹é™ã€‚æˆ‘ä»¬å‘ç°ï¼Œå•æ­¥å‡†ç¡®ç‡çš„å¾®å°æå‡å¯ä»¥åœ¨ä»»åŠ¡é•¿åº¦ä¸Šå¸¦æ¥æŒ‡æ•°çº§çš„æ”¹å–„ã€‚æˆ‘ä»¬æå‡ºé€šè¿‡æ˜ç¡®æä¾›è§£å†³é•¿æ—¶é—´ä»»åŠ¡æ‰€éœ€çš„çŸ¥è¯†å’Œè®¡åˆ’æ¥éš”ç¦»æ‰§è¡Œèƒ½åŠ›ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡å°æ¨¡å‹åœ¨å•æ­¥ä»»åŠ¡ä¸­è¡¨ç°å®Œç¾ï¼Œä½†å¤§å‹æ¨¡å‹åœ¨æ‰§è¡Œå¤šè½®ä»»åŠ¡æ—¶çš„è¡¨ç°æ˜¾è‘—æ›´å¥½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.08643",
            "title": "X-Part: high fidelity and structure coherent shape decomposition",
            "url": "https://huggingface.co/papers/2509.08643",
            "abstract": "X-Part is a generative model that decomposes 3D objects into semantically meaningful parts with high fidelity, using bounding boxes and point-wise semantic features, and supports interactive editing.  \t\t\t\t\tAI-generated summary \t\t\t\t Generating 3D shapes at part level is pivotal for downstream applications such as mesh retopology, UV mapping, and 3D printing. However, existing part-based generation methods often lack sufficient controllability and suffer from poor semantically meaningful decomposition. To this end, we introduce X-Part, a controllable generative model designed to decompose a holistic 3D object into semantically meaningful and structurally coherent parts with high geometric fidelity. X-Part exploits the bounding box as prompts for the part generation and injects point-wise semantic features for meaningful decomposition. Furthermore, we design an editable pipeline for interactive part generation. Extensive experimental results show that X-Part achieves state-of-the-art performance in part-level shape generation. This work establishes a new paradigm for creating production-ready, editable, and structurally sound 3D assets. Codes will be released for public research.",
            "score": 18,
            "issue_id": 5887,
            "pub_date": "2025-09-10",
            "pub_date_card": {
                "ru": "10 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 10",
                "zh": "9æœˆ10æ—¥"
            },
            "hash": "39ccecef3b91dc4b",
            "authors": [
                "Xinhao Yan",
                "Jiachen Xu",
                "Yang Li",
                "Changfeng Ma",
                "Yunhan Yang",
                "Chunshi Wang",
                "Zibo Zhao",
                "Zeqiang Lai",
                "Yunfei Zhao",
                "Zhuo Chen",
                "Chunchao Guo"
            ],
            "affiliations": [
                "CUHK",
                "HKU",
                "NJU",
                "ShanghaiTech",
                "Tencent Hunyuan",
                "ZJU"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.08643.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#diffusion",
                    "#open_source"
                ],
                "emoji": "ğŸ§©",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ°Ñ Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ½Ğ° Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸",
                    "desc": "X-Part - ÑÑ‚Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ½Ğ° ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ÑÑ‰Ğ¸Ğµ Ñ€Ğ°Ğ¼ĞºĞ¸ Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾Ñ‡ĞµÑ‡Ğ½Ñ‹Ğµ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°. X-Part Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡Ğ°ÑÑ‚ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ X-Part Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ„Ğ¾Ñ€Ğ¼ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ‡Ğ°ÑÑ‚ĞµĞ¹."
                },
                "en": {
                    "title": "Revolutionizing 3D Object Generation with X-Part",
                    "desc": "X-Part is a generative model that effectively breaks down 3D objects into meaningful parts while maintaining high geometric fidelity. It utilizes bounding boxes as prompts and incorporates point-wise semantic features to ensure that the parts are both semantically relevant and structurally coherent. This model allows for interactive editing, making it easier for users to manipulate and generate 3D shapes at the part level. The results demonstrate that X-Part outperforms existing methods, paving the way for improved applications in areas like mesh retopology and 3D printing."
                },
                "zh": {
                    "title": "X-Partï¼šå¯æ§çš„3Dç‰©ä½“åˆ†è§£ä¸ç¼–è¾‘",
                    "desc": "X-Partæ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿå°†3Dç‰©ä½“åˆ†è§£ä¸ºå…·æœ‰è¯­ä¹‰æ„ä¹‰çš„éƒ¨åˆ†ï¼Œå¹¶ä¿æŒé«˜ä¿çœŸåº¦ã€‚å®ƒåˆ©ç”¨è¾¹ç•Œæ¡†å’Œé€ç‚¹è¯­ä¹‰ç‰¹å¾æ¥æ”¯æŒå¯æ§çš„éƒ¨åˆ†ç”Ÿæˆã€‚X-Partè¿˜è®¾è®¡äº†ä¸€ä¸ªå¯ç¼–è¾‘çš„ç®¡é“ï¼Œå…è®¸ç”¨æˆ·è¿›è¡Œäº¤äº’å¼ç¼–è¾‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒX-Partåœ¨éƒ¨åˆ†çº§å½¢çŠ¶ç”Ÿæˆæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¼€åˆ›äº†åˆ›å»ºå¯ç¼–è¾‘å’Œç»“æ„åˆç†çš„3Dèµ„äº§çš„æ–°èŒƒå¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09713",
            "title": "HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented\n  Generation for Multi-hop Question Answering",
            "url": "https://huggingface.co/papers/2509.09713",
            "abstract": "HANRAG, a heuristic-based framework, improves question-answering systems by efficiently handling multi-hop queries and reducing noise through query decomposition and filtering.  \t\t\t\t\tAI-generated summary \t\t\t\t The Retrieval-Augmented Generation (RAG) approach enhances question-answering systems and dialogue generation tasks by integrating information retrieval (IR) technologies with large language models (LLMs). This strategy, which retrieves information from external knowledge bases to bolster the response capabilities of generative models, has achieved certain successes. However, current RAG methods still face numerous challenges when dealing with multi-hop queries. For instance, some approaches overly rely on iterative retrieval, wasting too many retrieval steps on compound queries. Additionally, using the original complex query for retrieval may fail to capture content relevant to specific sub-queries, resulting in noisy retrieved content. If the noise is not managed, it can lead to the problem of noise accumulation. To address these issues, we introduce HANRAG, a novel heuristic-based framework designed to efficiently tackle problems of varying complexity. Driven by a powerful revelator, HANRAG routes queries, decomposes them into sub-queries, and filters noise from retrieved documents. This enhances the system's adaptability and noise resistance, making it highly capable of handling diverse queries. We compare the proposed framework against other leading industry methods across various benchmarks. The results demonstrate that our framework obtains superior performance in both single-hop and multi-hop question-answering tasks.",
            "score": 13,
            "issue_id": 5885,
            "pub_date": "2025-09-08",
            "pub_date_card": {
                "ru": "8 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 8",
                "zh": "9æœˆ8æ—¥"
            },
            "hash": "a0f4a95527c1fb76",
            "authors": [
                "Duolin Sun",
                "Dan Yang",
                "Yue Shen",
                "Yihan Jiao",
                "Zhehao Tan",
                "Jie Feng",
                "Lianzhen Zhong",
                "Jian Wang",
                "Peng Wei",
                "Jinjie Gu"
            ],
            "affiliations": [
                "Ant Group, Hangzhou, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09713.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#rag",
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "HANRAG: Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²",
                    "desc": "HANRAG - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼. ĞĞ½Ğ° ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¸Ñ… Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ°. HANRAG Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ´Ğ»Ñ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ¸Ñ… Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ° Ğ¸Ğ· Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ĞºĞ°Ğº Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ…, Ñ‚Ğ°Ğº Ğ¸ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "HANRAG: Smart Query Handling for Better Answers",
                    "desc": "HANRAG is a new framework that improves question-answering systems by breaking down complex queries into simpler sub-queries. It uses a heuristic approach to filter out irrelevant information, reducing noise in the retrieval process. This method enhances the system's ability to handle multi-hop queries, which require information from multiple sources. By comparing HANRAG with existing methods, the results show it performs better in answering both single-hop and multi-hop questions."
                },
                "zh": {
                    "title": "HANRAGï¼šæå‡é—®ç­”ç³»ç»Ÿçš„æ™ºèƒ½æ¡†æ¶",
                    "desc": "HANRAGæ˜¯ä¸€ä¸ªåŸºäºå¯å‘å¼çš„æ–¹æ³•æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜é—®ç­”ç³»ç»Ÿçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤šè·³æŸ¥è¯¢æ—¶ã€‚å®ƒé€šè¿‡æŸ¥è¯¢åˆ†è§£å’Œè¿‡æ»¤æ¥æœ‰æ•ˆå‡å°‘å™ªå£°ï¼Œä»è€Œæå‡ç³»ç»Ÿçš„é€‚åº”æ€§å’ŒæŠ—å™ªå£°èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¼ºå¤§çš„æ­ç¤ºå™¨ï¼Œå°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå­æŸ¥è¯¢ï¼Œå¹¶ä»æ£€ç´¢çš„æ–‡æ¡£ä¸­å»é™¤æ— å…³å†…å®¹ã€‚ä¸å…¶ä»–ä¸»æµæ–¹æ³•ç›¸æ¯”ï¼ŒHANRAGåœ¨å•è·³å’Œå¤šè·³é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09716",
            "title": "VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions",
            "url": "https://huggingface.co/papers/2509.09716",
            "abstract": "Voice Style Adaptation (VSA) evaluates the ability of spoken language models to modify their speaking style based on spoken instructions, using a bilingual benchmark and a Large Audio Language Model as a Judge framework.  \t\t\t\t\tAI-generated summary \t\t\t\t Spoken language models (SLMs) have emerged as a unified paradigm for speech understanding and generation, enabling natural human machine interaction. However, while most progress has focused on semantic accuracy and instruction following, the ability of SLMs to adapt their speaking style based on spoken instructions has received limited attention. We introduce Voice Style Adaptation (VSA), a new task that examines whether SLMs can modify their speaking style, such as timbre, prosody, or persona following natural language spoken commands. To study this task, we present VStyle, a bilingual (Chinese & English) benchmark covering four categories of speech generation: acoustic attributes, natural language instruction, role play, and implicit empathy. We also introduce the Large Audio Language Model as a Judge (LALM as a Judge) framework, which progressively evaluates outputs along textual faithfulness, style adherence, and naturalness, ensuring reproducible and objective assessment. Experiments on commercial systems and open source SLMs demonstrate that current models face clear limitations in controllable style adaptation, highlighting both the novelty and challenge of this task. By releasing VStyle and its evaluation toolkit, we aim to provide the community with a foundation for advancing human centered spoken interaction. The dataset and code are publicly available at https://junzhan2000.github.io/VStyle.github.io/{project's homepage}.",
            "score": 9,
            "issue_id": 5883,
            "pub_date": "2025-09-09",
            "pub_date_card": {
                "ru": "9 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 9",
                "zh": "9æœˆ9æ—¥"
            },
            "hash": "a1fdfdb8fb8b7486",
            "authors": [
                "Jun Zhan",
                "Mingyang Han",
                "Yuxuan Xie",
                "Chen Wang",
                "Dong Zhang",
                "Kexin Huang",
                "Haoxiang Shi",
                "DongXiao Wang",
                "Tengtao Song",
                "Qinyuan Cheng",
                "Shimin Li",
                "Jun Song",
                "Xipeng Qiu",
                "Bo Zheng"
            ],
            "affiliations": [
                "Alibaba Group",
                "Fudan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09716.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#audio",
                    "#dataset",
                    "#alignment",
                    "#multilingual",
                    "#benchmark"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ€ÑƒĞ±ĞµĞ¶ Ğ² Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ğ˜Ğ˜: Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ğ¸Ğ»Ñ Ñ€ĞµÑ‡Ğ¸ Ğ¿Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ğ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Voice Style Adaptation (VSA), ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ Ñ€ĞµÑ‡Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑƒÑÑ‚Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ²ÑƒÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº VStyle Ğ´Ğ»Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑ‡Ğ¸. ĞĞ½Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Large Audio Language Model as a Judge Ğ´Ğ»Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ¼ĞµÑÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ² ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ¸Ğ»Ñ Ñ€ĞµÑ‡Ğ¸."
                },
                "en": {
                    "title": "Transforming Speech: Adapting Style with Voice Commands",
                    "desc": "Voice Style Adaptation (VSA) is a new task that tests how well spoken language models (SLMs) can change their speaking style based on spoken commands. This includes adjusting aspects like tone, rhythm, and character portrayal. The study introduces a bilingual benchmark called VStyle, which evaluates SLMs on various speech generation categories, including acoustic features and empathy. The research highlights the limitations of current models in adapting their style, aiming to improve human-machine interaction through better control of speech characteristics."
                },
                "zh": {
                    "title": "è¯­éŸ³é£æ ¼é€‚åº”ï¼šè®©æœºå™¨æ›´æ‡‚äººç±»çš„è¯´è¯é£æ ¼",
                    "desc": "è¯­éŸ³é£æ ¼é€‚åº”ï¼ˆVSAï¼‰æ˜¯ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°å£è¯­æ¨¡å‹æ ¹æ®å£å¤´æŒ‡ä»¤è°ƒæ•´è¯´è¯é£æ ¼çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†VStyleï¼Œè¿™æ˜¯ä¸€ä¸ªåŒè¯­åŸºå‡†ï¼Œæ¶µç›–äº†å£°å­¦å±æ€§ã€è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€è§’è‰²æ‰®æ¼”å’Œéšæ€§å…±æƒ…ç­‰å››ä¸ªç±»åˆ«çš„è¯­éŸ³ç”Ÿæˆã€‚é€šè¿‡å¼•å…¥å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„ä¼°æ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå®¢è§‚åœ°è¯„ä¼°æ¨¡å‹åœ¨æ–‡æœ¬å¿ å®æ€§ã€é£æ ¼éµå¾ªå’Œè‡ªç„¶æ€§æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æ¨¡å‹åœ¨å¯æ§é£æ ¼é€‚åº”æ–¹é¢å­˜åœ¨æ˜æ˜¾å±€é™ï¼Œçªæ˜¾äº†è¿™ä¸€ä»»åŠ¡çš„æ–°é¢–æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10147",
            "title": "Virtual Agent Economies",
            "url": "https://huggingface.co/papers/2509.10147",
            "abstract": "The sandbox economy framework analyzes the emerging AI agent economy, focusing on its origins and permeability, and discusses design choices for safe and steerable AI markets.  \t\t\t\t\tAI-generated summary \t\t\t\t The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agents transact and coordinate at scales and speeds beyond direct human oversight. We propose the \"sandbox economy\" as a framework for analyzing this emergent system, characterizing it along two key dimensions: its origins (emergent vs. intentional) and its degree of separateness from the established human economy (permeable vs. impermeable). Our current trajectory points toward a spontaneous emergence of a vast and highly permeable AI agent economy, presenting us with opportunities for an unprecedented degree of coordination as well as significant challenges, including systemic economic risk and exacerbated inequality. Here we discuss a number of possible design choices that may lead to safely steerable AI agent markets. In particular, we consider auction mechanisms for fair resource allocation and preference resolution, the design of AI \"mission economies\" to coordinate around achieving collective goals, and socio-technical infrastructure needed to ensure trust, safety, and accountability. By doing this, we argue for the proactive design of steerable agent markets to ensure the coming technological shift aligns with humanity's long-term collective flourishing.",
            "score": 8,
            "issue_id": 5884,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "2fd9f178e62d64b0",
            "authors": [
                "Nenad Tomasev",
                "Matija Franklin",
                "Joel Z. Leibo",
                "Julian Jacobs",
                "William A. Cunningham",
                "Iason Gabriel",
                "Simon Osindero"
            ],
            "affiliations": [
                "Google DeepMind",
                "University of Toronto"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10147.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#ethics",
                    "#alignment"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾ Ğ±Ğ»Ğ°Ğ³Ğ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ 'ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ğ¸Ñ†Ñ‹' Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ·Ğ°Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰ĞµĞ¹ÑÑ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ Ğ´Ğ²Ğ° ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ°: Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ (ÑĞ¿Ğ¾Ğ½Ñ‚Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ½Ğ¾Ğµ) Ğ¸ ÑÑ‚ĞµĞ¿ĞµĞ½ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸. ĞĞ±ÑÑƒĞ¶Ğ´Ğ°ÑÑ‚ÑÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ€Ğ¸ÑĞºĞ¸, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸ĞµĞ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€Ğ¸ÑĞºĞ¸ Ğ¸ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµÑ€Ğ°Ğ²ĞµĞ½ÑÑ‚Ğ²Ğ°. ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ÑÑ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ñ… Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ñ… Ñ€Ñ‹Ğ½ĞºĞ¾Ğ² Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ°ÑƒĞºÑ†Ğ¸Ğ¾Ğ½Ñ‹ Ğ´Ğ»Ñ ÑĞ¿Ñ€Ğ°Ğ²ĞµĞ´Ğ»Ğ¸Ğ²Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¸ 'Ğ¼Ğ¸ÑÑĞ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸' Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ†ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Navigating the Future: Designing Safe AI Agent Economies",
                    "desc": "The paper introduces the 'sandbox economy' framework to analyze the new economic landscape created by autonomous AI agents. It highlights two main aspects: the origins of these agents, whether they emerge spontaneously or are intentionally designed, and their connection to the existing human economy, which can be either permeable or impermeable. The authors emphasize the potential benefits of this AI agent economy, such as enhanced coordination, while also warning of risks like economic instability and inequality. They propose design strategies, including auction mechanisms and mission-oriented AI systems, to create safe and effective markets for AI agents that align with human values."
                },
                "zh": {
                    "title": "è®¾è®¡å¯æ§çš„AIä»£ç†å¸‚åœºï¼Œè¿æ¥ç»æµæ–°æœºé‡",
                    "desc": "è¿™ç¯‡è®ºæ–‡åˆ†æäº†æ–°å…´çš„äººå·¥æ™ºèƒ½ä»£ç†ç»æµï¼Œæå‡ºäº†â€œæ²™ç›’ç»æµâ€æ¡†æ¶æ¥ç†è§£è¿™ä¸€ç³»ç»Ÿã€‚å®ƒä¸»è¦å…³æ³¨äººå·¥æ™ºèƒ½ä»£ç†çš„èµ·æºå’Œä¸äººç±»ç»æµçš„å…³ç³»ï¼Œæ¢è®¨äº†å®‰å…¨å¯æ§çš„AIå¸‚åœºè®¾è®¡é€‰æ‹©ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒAIä»£ç†ç»æµçš„è‡ªå‘å‡ºç°å¯èƒ½å¸¦æ¥å‰æ‰€æœªæœ‰çš„åè°ƒæœºä¼šï¼Œä½†ä¹Ÿä¼´éšç³»ç»Ÿæ€§ç»æµé£é™©å’Œä¸å¹³ç­‰åŠ å‰§çš„æŒ‘æˆ˜ã€‚ä½œè€…å»ºè®®é€šè¿‡æ‹å–æœºåˆ¶å’ŒAIâ€œä½¿å‘½ç»æµâ€çš„è®¾è®¡ï¼Œç¡®ä¿èµ„æºåˆ†é…çš„å…¬å¹³æ€§å’Œä¿¡ä»»ã€å®‰å…¨ã€é—®è´£çš„ç¤¾ä¼šæŠ€æœ¯åŸºç¡€è®¾æ–½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.04996",
            "title": "FLOWER: Democratizing Generalist Robot Policies with Efficient\n  Vision-Language-Action Flow Policies",
            "url": "https://huggingface.co/papers/2509.04996",
            "abstract": "FLOWER, a 950 M-parameter VLA policy, achieves competitive performance with reduced computational costs through intermediate-modality fusion and action-specific Global-AdaLN conditioning.  \t\t\t\t\tAI-generated summary \t\t\t\t Developing efficient Vision-Language-Action (VLA) policies is crucial for practical robotics deployment, yet current approaches face prohibitive computational costs and resource requirements. Existing diffusion-based VLA policies require multi-billion-parameter models and massive datasets to achieve strong performance. We tackle this efficiency challenge with two contributions: intermediate-modality fusion, which reallocates capacity to the diffusion head by pruning up to 50% of LLM layers, and action-specific Global-AdaLN conditioning, which cuts parameters by 20% through modular adaptation. We integrate these advances into a novel 950 M-parameter VLA called FLOWER. Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance with bigger VLAs across 190 tasks spanning ten simulation and real-world benchmarks and demonstrates robustness across diverse robotic embodiments. In addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark. Demos, code and pretrained weights are available at https://intuitive-robots.github.io/flower_vla/.",
            "score": 7,
            "issue_id": 5889,
            "pub_date": "2025-09-05",
            "pub_date_card": {
                "ru": "5 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 5",
                "zh": "9æœˆ5æ—¥"
            },
            "hash": "06fa195b98a0804d",
            "authors": [
                "Moritz Reuss",
                "Hongyi Zhou",
                "Marcel RÃ¼hle",
                "Ã–mer ErdinÃ§ YaÄŸmurlu",
                "Fabian Otto",
                "Rudolf Lioutikov"
            ],
            "affiliations": [
                "Intuitive Robots Lab, Karlsruhe Institute of Technology, Germany",
                "Microsoft Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04996.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#benchmark",
                    "#training",
                    "#robotics",
                    "#optimization",
                    "#architecture",
                    "#agents"
                ],
                "emoji": "ğŸŒ¸",
                "ru": {
                    "title": "FLOWER: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ VLA-Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ÑƒĞ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸",
                    "desc": "FLOWER - ÑÑ‚Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ·Ñ€ĞµĞ½Ğ¸Ñ-ÑĞ·Ñ‹ĞºĞ°-Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ (VLA) Ñ 950 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ². ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ´Ğ»Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Global-AdaLN ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚. FLOWER Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° 190 Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ² Ğ´ĞµÑÑÑ‚Ğ¸ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€ĞµĞºĞ¾Ñ€Ğ´Ğ° Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ CALVIN ABC, Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ğ»Ğ¾Ñ‰ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Efficient Robotics with FLOWER: A 950M-Parameter VLA Policy",
                    "desc": "The paper presents FLOWER, a Vision-Language-Action (VLA) policy with 950 million parameters that enhances efficiency in robotics applications. It introduces intermediate-modality fusion to optimize model capacity by reducing the number of layers in large language models (LLMs) by up to 50%. Additionally, it employs action-specific Global-AdaLN conditioning, which decreases the parameter count by 20% through modular adaptation. FLOWER achieves competitive performance across 190 tasks while significantly reducing computational costs compared to existing multi-billion-parameter models."
                },
                "zh": {
                    "title": "FLOWERï¼šé«˜æ•ˆçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œç­–ç•¥",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºFLOWERçš„950Må‚æ•°çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰ç­–ç•¥ï¼Œæ—¨åœ¨é™ä½è®¡ç®—æˆæœ¬å¹¶æé«˜æ•ˆç‡ã€‚é€šè¿‡ä¸­é—´æ¨¡æ€èåˆå’Œç‰¹å®šåŠ¨ä½œçš„å…¨å±€è‡ªé€‚åº”å±‚å½’ä¸€åŒ–ï¼ˆGlobal-AdaLNï¼‰æ¡ä»¶ï¼ŒFLOWERåœ¨ä¿æŒç«äº‰æ€§èƒ½çš„åŒæ—¶ï¼Œå‡å°‘äº†æ¨¡å‹çš„å‚æ•°é‡ã€‚è¯¥æ¨¡å‹åœ¨ä»…200å°æ—¶çš„H100 GPUè®­ç»ƒåï¼Œèƒ½å¤Ÿåœ¨190ä¸ªä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶åœ¨CALVIN ABCåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æ–°çš„æœ€ä¼˜çŠ¶æ€ã€‚FLOWERçš„è®¾è®¡ä½¿å…¶åœ¨å¤šç§æœºå™¨äººå¹³å°ä¸Šéƒ½è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10396",
            "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language\n  Models",
            "url": "https://huggingface.co/papers/2509.10396",
            "abstract": "IGPO, an RL framework utilizing inpainting in masked diffusion large language models, enhances sample efficiency and achieves state-of-the-art results in mathematical benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Masked diffusion large language models (dLLMs) are emerging as promising alternatives to autoregressive LLMs, offering competitive performance while supporting unique generation capabilities such as inpainting. We explore how inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with reinforcement learning faces an exploration challenge: sparse reward signals and sample waste when models fail to discover correct solutions. While this inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided Policy Optimization), an RL framework that strategically inserts partial ground-truth reasoning traces during online sampling. Unlike providing full solutions, inpainting steers exploration toward promising trajectory spaces while preserving self-generated reasoning, bridging supervised fine-tuning and reinforcement learning. We apply IGPO to group-based optimization methods such as GRPO, where exploration failures cause zero advantages and gradients. IGPO restores meaningful gradients while improving sample efficiency. We also propose supervised fine-tuning on synthetically rewritten concise traces that better align with dLLM generation patterns. With additional techniques including entropy-based filtering, our training recipe yields substantial gains across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new state-of-the-art results for full-attention masked dLLMs.",
            "score": 6,
            "issue_id": 5886,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "aeadbfb97e57966c",
            "authors": [
                "Siyan Zhao",
                "Mengchen Liu",
                "Jing Huang",
                "Miao Liu",
                "Chenyu Wang",
                "Bo Liu",
                "Yuandong Tian",
                "Guan Pang",
                "Sean Bell",
                "Aditya Grover",
                "Feiyu Chen"
            ],
            "affiliations": [
                "MIT",
                "Meta Superintelligence Labs",
                "Tsinghua University, College of AI",
                "UCLA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10396.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#diffusion",
                    "#synthetic",
                    "#games",
                    "#rl",
                    "#rlhf",
                    "#training",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ˜Ğ½Ğ¿ĞµĞ¹Ğ½Ñ‚Ğ¸Ğ½Ğ³ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "IGPO - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ½Ğ¿ĞµĞ¹Ğ½Ñ‚Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. IGPO ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞºĞ¾Ñ€Ğ´Ğ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Enhancing Reinforcement Learning with Inpainting in dLLMs",
                    "desc": "This paper introduces IGPO, a reinforcement learning (RL) framework that leverages inpainting techniques in masked diffusion large language models (dLLMs) to improve sample efficiency. By using inpainting, IGPO helps guide the exploration process in RL, addressing the challenge of sparse rewards and inefficient sampling. The framework strategically incorporates partial ground-truth reasoning during online sampling, which enhances the model's ability to discover effective solutions. The results demonstrate that IGPO achieves state-of-the-art performance on mathematical benchmarks, showcasing the potential of combining inpainting with RL in dLLMs."
                },
                "zh": {
                    "title": "åˆ©ç”¨å›¾åƒä¿®å¤æå‡å¼ºåŒ–å­¦ä¹ æ•ˆç‡çš„IGPOæ¡†æ¶",
                    "desc": "IGPOæ˜¯ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨æ©è”½æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å›¾åƒä¿®å¤æŠ€æœ¯ï¼Œæå‡æ ·æœ¬æ•ˆç‡å¹¶åœ¨æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚æ©è”½æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰é€šè¿‡å›¾åƒä¿®å¤èƒ½åŠ›ä¸ºå¼ºåŒ–å­¦ä¹ ç®—æ³•è®¾è®¡æä¾›äº†æ–°çš„æ€è·¯ã€‚IGPOé€šè¿‡åœ¨åœ¨çº¿é‡‡æ ·è¿‡ç¨‹ä¸­æ’å…¥éƒ¨åˆ†çœŸå®æ¨ç†è½¨è¿¹ï¼ŒæŒ‡å¯¼æ¢ç´¢è¿‡ç¨‹ï¼Œé¿å…äº†æ¨¡å‹åœ¨å¯»æ‰¾æ­£ç¡®è§£å†³æ–¹æ¡ˆæ—¶çš„æ ·æœ¬æµªè´¹ã€‚è¯¥æ–¹æ³•åœ¨ç¾¤ä½“ä¼˜åŒ–æ–¹æ³•ä¸­åº”ç”¨ï¼Œæ¢å¤äº†æœ‰æ„ä¹‰çš„æ¢¯åº¦ï¼ŒåŒæ—¶æé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œæœ€ç»ˆåœ¨å¤šä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09995",
            "title": "QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading",
            "url": "https://huggingface.co/papers/2509.09995",
            "abstract": "QuantAgent, a multi-agent LLM framework, excels in high-frequency trading by leveraging specialized agents for technical indicators, chart patterns, trends, and risk, outperforming existing neural and rule-based systems.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Large Language Models (LLMs) have demonstrated impressive capabilities in financial reasoning and market understanding. Multi-agent LLM frameworks such as TradingAgent and FINMEM augment these models to long-horizon investment tasks, leveraging fundamental and sentiment-based inputs for strategic decision-making. However, such systems are ill-suited for the high-speed, precision-critical demands of High-Frequency Trading (HFT). HFT requires rapid, risk-aware decisions based on structured, short-horizon signals, including technical indicators, chart patterns, and trend-based features, distinct from the long-term semantic reasoning typical of traditional financial LLM applications. To this end, we introduce QuantAgent, the first multi-agent LLM framework explicitly designed for high-frequency algorithmic trading. The system decomposes trading into four specialized agents, Indicator, Pattern, Trend, and Risk, each equipped with domain-specific tools and structured reasoning capabilities to capture distinct aspects of market dynamics over short temporal windows. In zero-shot evaluations across ten financial instruments, including Bitcoin and Nasdaq futures, QuantAgent demonstrates superior performance in both predictive accuracy and cumulative return over 4-hour trading intervals, outperforming strong neural and rule-based baselines. Our findings suggest that combining structured financial priors with language-native reasoning unlocks new potential for traceable, real-time decision systems in high-frequency financial markets.",
            "score": 4,
            "issue_id": 5883,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "5964ddeaa46fcc92",
            "authors": [
                "Fei Xiong",
                "Xiang Zhang",
                "Aosong Feng",
                "Siqi Sun",
                "Chenyu You"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Fudan University",
                "Stony Brook University",
                "University of British Columbia",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09995.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#science",
                    "#multimodal",
                    "#agents",
                    "#reasoning",
                    "#games"
                ],
                "emoji": "ğŸ“ˆ",
                "ru": {
                    "title": "QuantAgent: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "QuantAgent - ÑÑ‚Ğ¾ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM), Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ°: Indicator, Pattern, Trend Ğ¸ Risk, ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¸Ğ· ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ¾ÑĞ½Ğ°Ñ‰ĞµĞ½ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ¾Ğ² Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ Ğ² ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºĞ½Ğ°Ñ…. Ğ’ Ñ…Ğ¾Ğ´Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½Ğ° Ğ´ĞµÑÑÑ‚Ğ¸ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ… QuantAgent Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ» Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğº Ğ² Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ‚Ğ°Ğº Ğ¸ Ğ² ĞºÑƒĞ¼ÑƒĞ»ÑÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ° 4-Ñ‡Ğ°ÑĞ¾Ğ²Ñ‹Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ñ‹, Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾Ğ¹Ğ´Ñ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°Ñ… Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ñ‡ĞµÑ‚Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¾Ğ² Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ½Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ñ… Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ñ€Ñ‹Ğ½ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Revolutionizing High-Frequency Trading with Specialized Agents",
                    "desc": "QuantAgent is a multi-agent framework designed for high-frequency trading (HFT) that utilizes specialized agents to analyze technical indicators, chart patterns, trends, and risk. Unlike traditional large language models (LLMs) that focus on long-term investment strategies, QuantAgent is tailored for rapid decision-making in fast-paced trading environments. Each agent within the framework is equipped with specific tools to effectively interpret short-term market signals. In tests, QuantAgent outperformed existing neural and rule-based systems, demonstrating its effectiveness in achieving higher predictive accuracy and returns in HFT scenarios."
                },
                "zh": {
                    "title": "QuantAgentï¼šé«˜é¢‘äº¤æ˜“çš„æ™ºèƒ½å†³ç­–æ–°å·¥å…·",
                    "desc": "QuantAgent æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œä¸“é—¨ä¸ºé«˜é¢‘äº¤æ˜“è®¾è®¡ã€‚å®ƒé€šè¿‡å››ä¸ªä¸“ä¸šä»£ç†ï¼ˆæŠ€æœ¯æŒ‡æ ‡ã€å›¾è¡¨æ¨¡å¼ã€è¶‹åŠ¿å’Œé£é™©ï¼‰æ¥å¤„ç†å¸‚åœºåŠ¨æ€ï¼Œèƒ½å¤Ÿå¿«é€Ÿåšå‡ºåŸºäºçŸ­æœŸä¿¡å·çš„å†³ç­–ã€‚ä¸ä¼ ç»Ÿçš„é‡‘èå¤§è¯­è¨€æ¨¡å‹ä¸åŒï¼ŒQuantAgent æ›´åŠ æ³¨é‡å¿«é€Ÿã€ç²¾å‡†çš„äº¤æ˜“éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQuantAgent åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œç´¯è®¡æ”¶ç›Šæ–¹é¢ä¼˜äºç°æœ‰çš„ç¥ç»ç½‘ç»œå’Œè§„åˆ™åŸºç¡€ç³»ç»Ÿã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09926",
            "title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised\n  Learning in Open-World Scenarios",
            "url": "https://huggingface.co/papers/2509.09926",
            "abstract": "LoFT, a parameter-efficient fine-tuning framework for long-tailed semi-supervised learning, improves reliability of pseudolabels and discriminative ability in open-world scenarios, outperforming previous methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-tailed learning has garnered increasing attention due to its wide applicability in real-world scenarios. Among existing approaches, Long-Tailed Semi-Supervised Learning (LTSSL) has emerged as an effective solution by incorporating a large amount of unlabeled data into the imbalanced labeled dataset. However, most prior LTSSL methods are designed to train models from scratch, which often leads to issues such as overconfidence and low-quality pseudo-labels. To address these challenges, we extend LTSSL into the foundation model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate that fine-tuned foundation models can generate more reliable pseudolabels, thereby benefiting imbalanced learning. Furthermore, we explore a more practical setting by investigating semi-supervised learning under open-world conditions, where the unlabeled data may include out-of-distribution (OOD) samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World scenarios) to improve the discriminative ability. Experimental results on multiple benchmarks demonstrate that our method achieves superior performance compared to previous approaches, even when utilizing only 1\\% of the unlabeled data compared with previous works.",
            "score": 4,
            "issue_id": 5884,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "e85c5f480d51fb5c",
            "authors": [
                "Jiahao Chen",
                "Zhiyuan Huang",
                "Yurou Liu",
                "Bing Su"
            ],
            "affiliations": [
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09926.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#dataset",
                    "#optimization",
                    "#training",
                    "#transfer_learning"
                ],
                "emoji": "ğŸ¦š",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾Ğ½ĞºĞ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ LoFT - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ½ĞµÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»Ñƒ-ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼. LoFT ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿ÑĞµĞ²Ğ´Ğ¾-Ğ¼ĞµÑ‚Ğ¾Ğº Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğº Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ² ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ LoFT-OW Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ LoFT Ğ½Ğ°Ğ´ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 1% Ğ½ĞµĞ¼ĞµÑ‡ĞµĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "Enhancing Long-Tailed Learning with LoFT: Fine-Tuning for Better Pseudolabels",
                    "desc": "LoFT is a new framework designed for long-tailed semi-supervised learning that enhances the quality of pseudolabels and improves model performance in open-world scenarios. It builds on the foundation model fine-tuning approach, allowing for better utilization of unlabeled data alongside imbalanced labeled datasets. By addressing issues like overconfidence and low-quality pseudolabels, LoFT enables more reliable learning outcomes. The framework also includes a variant, LoFT-OW, which specifically tackles challenges posed by out-of-distribution samples, demonstrating superior results on various benchmarks with minimal unlabeled data usage."
                },
                "zh": {
                    "title": "LoFTï¼šæå‡é•¿å°¾åŠç›‘ç£å­¦ä¹ çš„å¯é æ€§ä¸åŒºåˆ†èƒ½åŠ›",
                    "desc": "LoFTæ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæ¡†æ¶ï¼Œä¸“ä¸ºé•¿å°¾åŠç›‘ç£å­¦ä¹ è®¾è®¡ï¼Œæ—¨åœ¨æé«˜ä¼ªæ ‡ç­¾çš„å¯é æ€§å’Œåœ¨å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸­çš„åŒºåˆ†èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å¤§é‡æœªæ ‡è®°æ•°æ®ä¸ä¸å¹³è¡¡çš„æ ‡è®°æ•°æ®é›†ç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¸¸è§çš„è¿‡åº¦è‡ªä¿¡å’Œä½è´¨é‡ä¼ªæ ‡ç­¾çš„é—®é¢˜ã€‚LoFTåœ¨åŸºç¡€æ¨¡å‹å¾®è°ƒçš„åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´å¯é çš„ä¼ªæ ‡ç­¾ï¼Œä»è€Œä¿ƒè¿›ä¸å¹³è¡¡å­¦ä¹ çš„æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLoFTåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œå³ä½¿åªä½¿ç”¨1%çš„æœªæ ‡è®°æ•°æ®ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10058",
            "title": "Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings\n  for Improved Diffusion Generation",
            "url": "https://huggingface.co/papers/2509.10058",
            "abstract": "A training-free framework uses a large language model to disambiguate color terms and refine text embeddings for improved color accuracy in text-to-image generation.  \t\t\t\t\tAI-generated summary \t\t\t\t Accurate color alignment in text-to-image (T2I) generation is critical for applications such as fashion, product visualization, and interior design, yet current diffusion models struggle with nuanced and compound color terms (e.g., Tiffany blue, lime green, hot pink), often producing images that are misaligned with human intent. Existing approaches rely on cross-attention manipulation, reference images, or fine-tuning but fail to systematically resolve ambiguous color descriptions. To precisely render colors under prompt ambiguity, we propose a training-free framework that enhances color fidelity by leveraging a large language model (LLM) to disambiguate color-related prompts and guiding color blending operations directly in the text embedding space. Our method first employs a large language model (LLM) to resolve ambiguous color terms in the text prompt, and then refines the text embeddings based on the spatial relationships of the resulting color terms in the CIELAB color space. Unlike prior methods, our approach improves color accuracy without requiring additional training or external reference images. Experimental results demonstrate that our framework improves color alignment without compromising image quality, bridging the gap between text semantics and visual generation.",
            "score": 3,
            "issue_id": 5883,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "e647125383aba6a5",
            "authors": [
                "Sung-Lin Tsai",
                "Bo-Lun Huang",
                "Yu Ting Shen",
                "Cheng Yu Yeo",
                "Chiang Tseng",
                "Bo-Kai Ruan",
                "Wen-Sheng Lien",
                "Hong-Han Shuai"
            ],
            "affiliations": [
                "National Yang Ming Chiao Tung University Hsinchu, Taiwan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10058.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#data",
                    "#diffusion",
                    "#optimization",
                    "#cv"
                ],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ†Ğ²ĞµÑ‚Ğ° Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ±Ğ¾Ğ»ÑŒÑˆÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²Ñ‹Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ² Ğ² Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ñ… Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ. ĞœĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ´Ğ¾Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ² Ğ² Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ CIELAB. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ², Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ² Ğ±ĞµĞ· ÑƒÑ‰ĞµÑ€Ğ±Ğ° Ğ´Ğ»Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Enhancing Color Accuracy in T2I with a Training-Free Framework",
                    "desc": "This paper presents a novel training-free framework that enhances color accuracy in text-to-image (T2I) generation by utilizing a large language model (LLM). The framework addresses the challenge of ambiguous color terms, which often lead to misaligned images in applications like fashion and product visualization. By disambiguating color prompts and refining text embeddings in the CIELAB color space, the method improves the fidelity of generated colors without the need for additional training or reference images. Experimental results show that this approach successfully aligns colors with human intent while maintaining high image quality."
                },
                "zh": {
                    "title": "æ— è®­ç»ƒæ¡†æ¶æå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„é¢œè‰²å‡†ç¡®æ€§",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æ¶ˆæ­§ä¹‰é¢œè‰²æœ¯è¯­ï¼Œå¹¶ä¼˜åŒ–æ–‡æœ¬åµŒå…¥ï¼Œä»¥æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„é¢œè‰²å‡†ç¡®æ€§ã€‚å½“å‰çš„æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„é¢œè‰²æè¿°æ—¶è¡¨ç°ä¸ä½³ï¼Œå¸¸å¸¸å¯¼è‡´ç”Ÿæˆçš„å›¾åƒä¸äººç±»æ„å›¾ä¸ç¬¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡è§£ææ–‡æœ¬æç¤ºä¸­çš„æ¨¡ç³Šé¢œè‰²æœ¯è¯­ï¼Œå¹¶åœ¨CIELABé¢œè‰²ç©ºé—´ä¸­æ ¹æ®é¢œè‰²æœ¯è¯­çš„ç©ºé—´å…³ç³»æ¥ç»†åŒ–æ–‡æœ¬åµŒå…¥ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„é¢œè‰²æ¸²æŸ“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¸å½±å“å›¾åƒè´¨é‡çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æ”¹å–„äº†é¢œè‰²å¯¹é½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09734",
            "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with\n  MCP-Mediated Tools",
            "url": "https://huggingface.co/papers/2509.09734",
            "abstract": "MCP-AgentBench is a benchmark designed to evaluate language agents in MCP-mediated tool interactions, providing a standardized framework for assessing real-world performance.  \t\t\t\t\tAI-generated summary \t\t\t\t The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, designed to enhance agent-tool integration and interoperability, and is positioned to unlock a new era of powerful, interconnected, and genuinely utilitarian agentic AI. However, despite MCP's growing adoption, existing benchmarks often fail to capture real-world agent performance within this new paradigm, leading to a distorted perception of their true operational value and an inability to reliably differentiate proficiencies. To bridge this critical evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark specifically engineered to rigorously assess language agent capabilities in MCP-mediated tool interactions. Core contributions of MCP-AgentBench include: the establishment of a robust MCP testbed comprising 33 operational servers with 188 distinct tools; the development of a benchmark featuring 600 systematically designed queries distributed across 6 distinct categories of varying interaction complexity; and the introduction of MCP-Eval, a novel outcome-oriented evaluation methodology prioritizing real-world task success. Through extensive empirical evaluation of leading language agents, we provide foundational insights. MCP-AgentBench aims to equip the research community with a standardized and reliable framework to build, validate, and advance agents capable of fully leveraging MCP's transformative benefits, thereby accelerating progress toward truly capable and interoperable AI systems.",
            "score": 3,
            "issue_id": 5883,
            "pub_date": "2025-09-10",
            "pub_date_card": {
                "ru": "10 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 10",
                "zh": "9æœˆ10æ—¥"
            },
            "hash": "56883c4d7c401e99",
            "authors": [
                "Zikang Guo",
                "Benfeng Xu",
                "Chiwei Zhu",
                "Wentao Hong",
                "Xiaorui Wang",
                "Zhendong Mao"
            ],
            "affiliations": [
                "Metastone Technology, Beijing, China",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09734.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#agents",
                    "#benchmark"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¼Ğ¸Ñ€Ğµ",
                    "desc": "MCP-AgentBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» MCP. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ñ‚ĞµÑÑ‚Ğ¾Ğ²ÑƒÑ ÑÑ€ĞµĞ´Ñƒ Ñ 33 ÑĞµÑ€Ğ²ĞµÑ€Ğ°Ğ¼Ğ¸ Ğ¸ 188 Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ 600 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ MCP-Eval, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. MCP-AgentBench Ğ¿Ñ€Ğ¸Ğ·Ğ²Ğ°Ğ½ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° MCP."
                },
                "en": {
                    "title": "Empowering Language Agents with MCP-AgentBench",
                    "desc": "MCP-AgentBench is a benchmark created to evaluate language agents that interact with tools using the Model Context Protocol (MCP). It addresses the shortcomings of existing benchmarks by providing a standardized framework that reflects real-world performance. The benchmark includes a testbed with 33 servers and 188 tools, along with 600 queries across various complexity levels. By introducing a new evaluation method focused on task success, MCP-AgentBench aims to enhance the development of more effective and interconnected AI systems."
                },
                "zh": {
                    "title": "MCP-AgentBenchï¼šè¯„ä¼°è¯­è¨€ä»£ç†çš„æ–°æ ‡å‡†",
                    "desc": "MCP-AgentBenchæ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€ä»£ç†åœ¨MCPä»‹å¯¼çš„å·¥å…·äº¤äº’ä¸­çš„è¡¨ç°ã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ¡†æ¶ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°è¯„ä¼°ä»£ç†åœ¨ç°å®ä¸–ç•Œä¸­çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…æ‹¬33ä¸ªæ“ä½œæœåŠ¡å™¨å’Œ188ç§ä¸åŒå·¥å…·ï¼Œè®¾è®¡äº†600ä¸ªç³»ç»ŸåŒ–çš„æŸ¥è¯¢ï¼Œæ¶µç›–6ç§ä¸åŒå¤æ‚åº¦çš„äº¤äº’ç±»åˆ«ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒMCP-AgentBenchå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£å’Œæå‡ä»£ç†çš„æ€§èƒ½ï¼Œæ¨åŠ¨æ™ºèƒ½ä»£ç†çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.07966",
            "title": "Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images",
            "url": "https://huggingface.co/papers/2509.07966",
            "abstract": "Visual-TableQA is a large-scale, open-domain dataset for evaluating visual reasoning over complex tabular data, generated using a modular pipeline involving multiple reasoning LLMs.  \t\t\t\t\tAI-generated summary \t\t\t\t Visual reasoning over structured data such as tables is a critical capability for modern vision-language models (VLMs), yet current benchmarks remain limited in scale, diversity, or reasoning depth, especially when it comes to rendered table images. Addressing this gap, we introduce Visual-TableQA, a large-scale, open-domain multimodal dataset specifically designed to evaluate and enhance visual reasoning over complex tabular data. Our generation pipeline is modular, scalable, and fully autonomous, involving multiple reasoning LLMs collaborating across distinct roles: generation, validation, and inspiration. Visual-TableQA comprises 2.5k richly structured LaTeX-rendered tables and 6k reasoning-intensive QA pairs, all produced at a cost of under USD 100. To promote diversity and creativity, our pipeline performs multi-model collaborative data generation via cross-model prompting ('inspiration') and LLM-jury filtering. Stronger models seed layouts and topics that weaker models elaborate, collectively distilling diverse reasoning patterns and visual structures into the dataset. Empirical results show that models fine-tuned on Visual-TableQA generalize robustly to external benchmarks, outperforming several proprietary models despite the dataset's synthetic nature. The full pipeline and resources are publicly available at https://github.com/AI-4-Everyone/Visual-TableQA.",
            "score": 3,
            "issue_id": 5900,
            "pub_date": "2025-09-09",
            "pub_date_card": {
                "ru": "9 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 9",
                "zh": "9æœˆ9æ—¥"
            },
            "hash": "afb635640cc1ffec",
            "authors": [
                "Boammani Aser Lompo",
                "Marc Haraoui"
            ],
            "affiliations": [
                "Ã‰cole de Technologie SupÃ©rieure Montreal, Canada"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.07966.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#multimodal",
                    "#dataset",
                    "#open_source",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšĞ¾Ğ»Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ LLM ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†",
                    "desc": "Visual-TableQA - ÑÑ‚Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ½ Ğ±Ñ‹Ğ» ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€Ğ°, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´Ğ°ÑÑ‰Ğ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 2500 ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†, Ğ¾Ñ‚Ñ€ĞµĞ½Ğ´ĞµÑ€ĞµĞ½Ğ½Ñ‹Ñ… Ğ² LaTeX, Ğ¸ 6000 Ğ¿Ğ°Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ², Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ»ÑĞ»Ğ°ÑÑŒ Ğ¿ÑƒÑ‚ĞµĞ¼ ĞºĞ¾Ğ»Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‰Ğ¸Ñ… Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ€Ğ¾Ğ»Ğ¸: Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ, Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ²Ğ´Ğ¾Ñ…Ğ½Ğ¾Ğ²ĞµĞ½Ğ¸Ğµ."
                },
                "en": {
                    "title": "Enhancing Visual Reasoning with Visual-TableQA",
                    "desc": "Visual-TableQA is a new dataset designed to test how well machine learning models can understand and reason about complex tables. It includes 2,500 LaTeX-rendered tables and 6,000 question-answer pairs, created using a collaborative approach with multiple reasoning language models (LLMs). This dataset aims to improve the evaluation of visual reasoning in vision-language models by providing a diverse and rich set of examples. The results show that models trained on Visual-TableQA perform better on other benchmarks, demonstrating its effectiveness despite being generated synthetically."
                },
                "zh": {
                    "title": "è§†è§‰æ¨ç†çš„æ–°çªç ´ï¼šVisual-TableQA",
                    "desc": "Visual-TableQAæ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„å¼€æ”¾é¢†åŸŸæ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°å¯¹å¤æ‚è¡¨æ ¼æ•°æ®çš„è§†è§‰æ¨ç†èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†é€šè¿‡ä¸€ä¸ªæ¨¡å—åŒ–çš„ç”Ÿæˆç®¡é“åˆ›å»ºï¼Œæ¶‰åŠå¤šä¸ªæ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä»¥å®ç°ç”Ÿæˆã€éªŒè¯å’Œçµæ„Ÿæ¿€å‘ç­‰ä¸åŒè§’è‰²çš„åä½œã€‚æ•°æ®é›†ä¸­åŒ…å«2500ä¸ªä¸°å¯Œç»“æ„çš„LaTeXæ¸²æŸ“è¡¨æ ¼å’Œ6000ä¸ªæ¨ç†å¯†é›†çš„é—®ç­”å¯¹ï¼Œç”Ÿæˆæˆæœ¬ä½äº100ç¾å…ƒã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒåŸºäºVisual-TableQAå¾®è°ƒçš„æ¨¡å‹åœ¨å¤–éƒ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†å¤šä¸ªä¸“æœ‰æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09524",
            "title": "DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning\n  and Label Distribution Learning",
            "url": "https://huggingface.co/papers/2509.09524",
            "abstract": "DeMeVa explores in-context learning and label distribution learning for predicting annotator-specific annotations and generating soft labels, demonstrating competitive performance and potential for further research.  \t\t\t\t\tAI-generated summary \t\t\t\t This system paper presents the DeMeVa team's approaches to the third edition of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et al., 2025). We explore two directions: in-context learning (ICL) with large language models, where we compare example sampling strategies; and label distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we evaluate several fine-tuning methods. Our contributions are twofold: (1) we show that ICL can effectively predict annotator-specific annotations (perspectivist annotations), and that aggregating these predictions into soft labels yields competitive performance; and (2) we argue that LDL methods are promising for soft label predictions and merit further exploration by the perspectivist community.",
            "score": 2,
            "issue_id": 5895,
            "pub_date": "2025-09-11",
            "pub_date_card": {
                "ru": "11 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 11",
                "zh": "9æœˆ11æ—¥"
            },
            "hash": "8eea111352153d33",
            "authors": [
                "Daniil Ignatev",
                "Nan Li",
                "Hugh Mee Wong",
                "Anh Dang",
                "Shane Kaszefski Yaschuk"
            ],
            "affiliations": [
                "Utrecht University, Utrecht, The Netherlands"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09524.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#interpretability",
                    "#transfer_learning",
                    "#training"
                ],
                "emoji": "ğŸ·ï¸",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ»Ğ°ÑĞ¸ÑĞ¼Ğ¸: Ğ¾Ñ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğº Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğº",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ DeMeVa Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ»Ğ°ÑĞ¸ÑĞ¼Ğ¸ (LeWiDi 2025). Ğ˜ÑÑĞ»ĞµĞ´ÑƒÑÑ‚ÑÑ Ğ´Ğ²Ğ° Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ: Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ (ICL) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğº (LDL) Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ RoBERTa. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ñ‡Ñ‚Ğ¾ ICL ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸, ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ², Ğ° Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ğ¸Ñ… Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ°ĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ğµ Ğ¼ÑĞ³ĞºĞ¸Ğµ Ğ¼ĞµÑ‚ĞºĞ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ LDL Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¼ÑĞ³ĞºĞ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğº Ğ¸ Ğ·Ğ°ÑĞ»ÑƒĞ¶Ğ¸Ğ²Ğ°ÑÑ‚ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Harnessing ICL and LDL for Enhanced Annotation Predictions",
                    "desc": "The DeMeVa paper investigates two innovative approaches in machine learning: in-context learning (ICL) and label distribution learning (LDL). ICL utilizes large language models to predict specific annotations from different annotators by comparing various example sampling strategies. Additionally, the paper demonstrates that LDL methods, particularly with RoBERTa, can effectively generate soft labels through fine-tuning techniques. The findings suggest that both ICL and LDL hold significant potential for improving annotation processes and warrant further research in the field."
                },
                "zh": {
                    "title": "æ¢ç´¢ä¸Šä¸‹æ–‡å­¦ä¹ ä¸æ ‡ç­¾åˆ†å¸ƒå­¦ä¹ çš„æ½œåŠ›",
                    "desc": "DeMeVaç ”ç©¶äº†ä¸Šä¸‹æ–‡å­¦ä¹ å’Œæ ‡ç­¾åˆ†å¸ƒå­¦ä¹ ï¼Œä»¥é¢„æµ‹ç‰¹å®šæ³¨é‡Šè€…çš„æ³¨é‡Šå¹¶ç”Ÿæˆè½¯æ ‡ç­¾ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†ä¸åŒçš„ç¤ºä¾‹é‡‡æ ·ç­–ç•¥ï¼Œå¹¶è¯„ä¼°äº†å¤šç§å¾®è°ƒæ–¹æ³•ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹æ³¨é‡Šè€…ç‰¹å®šçš„æ³¨é‡Šï¼Œå¹¶å°†è¿™äº›é¢„æµ‹èšåˆæˆè½¯æ ‡ç­¾ï¼Œè¡¨ç°å‡ºç«äº‰åŠ›ã€‚æ ‡ç­¾åˆ†å¸ƒå­¦ä¹ æ–¹æ³•åœ¨è½¯æ ‡ç­¾é¢„æµ‹æ–¹é¢ä¹Ÿæ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œå€¼å¾—è¿›ä¸€æ­¥ç ”ç©¶ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.01535",
            "title": "CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge\n  into Large Language Models",
            "url": "https://huggingface.co/papers/2509.01535",
            "abstract": "Causal Attention Tuning (CAT) enhances Large Language Models (LLMs) by injecting causal knowledge into the attention mechanism, improving prediction accuracy and robustness in out-of-distribution scenarios.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have achieved remarkable success across various domains. However, a fundamental question remains: Can LLMs effectively utilize causal knowledge for prediction and generation? Through empirical studies, we find that LLMs trained directly on large-scale data often capture spurious correlations rather than true causal relationships, leading to suboptimal performance, especially in out-of-distribution (OOD) scenarios. To address this challenge, we propose Causal Attention Tuning (CAT), a novel approach that injects fine-grained causal knowledge into the attention mechanism. We propose an automated pipeline that leverages human priors to automatically generate token-level causal signals and introduce the Re-Attention mechanism to guide training, helping the model focus on causal structures while mitigating noise and biases in attention scores. Experimental results on our proposed Spurious Token Game (STG) benchmark and multiple downstream tasks demonstrate that our approach effectively leverages causal knowledge for prediction and remains robust in OOD scenarios. Implementation details can be found at https://github.com/Kairong-Han/CAT.",
            "score": 2,
            "issue_id": 5897,
            "pub_date": "2025-09-01",
            "pub_date_card": {
                "ru": "1 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 1",
                "zh": "9æœˆ1æ—¥"
            },
            "hash": "915b9e9dacb125e5",
            "authors": [
                "Kairong Han",
                "Wenshuo Zhao",
                "Ziyu Zhao",
                "JunJian Ye",
                "Lujia Pan",
                "Kun Kuang"
            ],
            "affiliations": [
                "College of Computer Science and Technology, Zhejiang University",
                "Noahs Ark Lab, Huawei Technologies"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.01535.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#interpretability",
                    "#architecture",
                    "#training",
                    "#reasoning",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ğ¾-ÑĞ»ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Causal Attention Tuning (CAT) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). CAT Ğ²Ğ½ĞµĞ´Ñ€ÑĞµÑ‚ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ğ¾-ÑĞ»ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ² Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ Ğ² ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ğ²Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ½Ğ¾-ÑĞ»ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Re-Attention Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ğ¾Ğ¼ Ñ‚ĞµÑÑ‚Ğµ Spurious Token Game Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…."
                },
                "en": {
                    "title": "Enhancing LLMs with Causal Knowledge for Better Predictions",
                    "desc": "Causal Attention Tuning (CAT) is a method designed to improve Large Language Models (LLMs) by incorporating causal knowledge into their attention mechanisms. This approach addresses the issue of LLMs often learning misleading correlations instead of genuine causal relationships, which can hinder their performance, especially in unfamiliar situations. CAT uses an automated process to generate causal signals at the token level and employs a Re-Attention mechanism to enhance training, allowing the model to concentrate on relevant causal structures. Experimental results show that CAT significantly boosts prediction accuracy and robustness in out-of-distribution scenarios, making LLMs more reliable."
                },
                "zh": {
                    "title": "å› æœçŸ¥è¯†æå‡è¯­è¨€æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›",
                    "desc": "å› æœæ³¨æ„åŠ›è°ƒä¼˜ï¼ˆCATï¼‰é€šè¿‡å°†å› æœçŸ¥è¯†æ³¨å…¥åˆ°æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œå¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿçš„LLMsåœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶ï¼Œå¾€å¾€æ•æ‰åˆ°çš„æ˜¯è™šå‡çš„ç›¸å…³æ€§ï¼Œè€ŒéçœŸå®çš„å› æœå…³ç³»ï¼Œå¯¼è‡´åœ¨åˆ†å¸ƒå¤–åœºæ™¯ä¸­çš„è¡¨ç°ä¸ä½³ã€‚CATæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡è‡ªåŠ¨ç”Ÿæˆä»¤ç‰Œçº§å› æœä¿¡å·ï¼Œå¹¶å¼•å…¥å†æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¸®åŠ©æ¨¡å‹å…³æ³¨å› æœç»“æ„ï¼Œå‡å°‘æ³¨æ„åŠ›åˆ†æ•°ä¸­çš„å™ªå£°å’Œåå·®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCATåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­æœ‰æ•ˆåˆ©ç”¨å› æœçŸ¥è¯†è¿›è¡Œé¢„æµ‹ï¼Œå¹¶åœ¨åˆ†å¸ƒå¤–åœºæ™¯ä¸­ä¿æŒç¨³å¥æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09990",
            "title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority\n  Languages in China",
            "url": "https://huggingface.co/papers/2509.09990",
            "abstract": "Minority languages in China, such as Tibetan, Uyghur, and Traditional Mongolian, face significant challenges due to their unique writing systems, which differ from international standards. This discrepancy has led to a severe lack of relevant corpora, particularly for supervised tasks like headline generation. To address this gap, we introduce a novel dataset, Chinese Minority Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and 50,000 entries each for Uyghur and Mongolian, specifically curated for headline generation tasks. Additionally, we propose a high-quality test set annotated by native speakers, designed to serve as a benchmark for future research in this domain. We hope this dataset will become a valuable resource for advancing headline generation in Chinese minority languages and contribute to the development of related benchmarks.",
            "score": 1,
            "issue_id": 5886,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "83ad01064c3c6566",
            "authors": [
                "Guixian Xu",
                "Zeli Su",
                "Ziyin Zhang",
                "Jianing Liu",
                "XU Han",
                "Ting Zhang",
                "Yushuang Dong"
            ],
            "affiliations": [
                "Key Laboratory of Ethnic Language Intelligent Analysis and Security Governance of MOE",
                "Minzu University of China",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09990.jpg",
            "data": {
                "categories": [
                    "#low_resource",
                    "#synthetic",
                    "#multilingual",
                    "#machine_translation",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "ğŸ“°",
                "ru": {
                    "title": "ĞŸÑ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ±Ğ°Ñ€ÑŒĞµÑ€Ğ°: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ½Ğ° ÑĞ·Ñ‹ĞºĞ°Ñ… Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ² ĞšĞ¸Ñ‚Ğ°Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… CMHG Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ½Ğ° ÑĞ·Ñ‹ĞºĞ°Ñ… Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ² ĞšĞ¸Ñ‚Ğ°Ñ: Ñ‚Ğ¸Ğ±ĞµÑ‚ÑĞºĞ¾Ğ¼, ÑƒĞ¹Ğ³ÑƒÑ€ÑĞºĞ¾Ğ¼ Ğ¸ Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ¼. Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 100 000 Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ´Ğ»Ñ Ñ‚Ğ¸Ğ±ĞµÑ‚ÑĞºĞ¾Ğ³Ğ¾ Ğ¸ Ğ¿Ğ¾ 50 000 Ğ´Ğ»Ñ ÑƒĞ¹Ğ³ÑƒÑ€ÑĞºĞ¾Ğ³Ğ¾ Ğ¸ Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€, Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑĞ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ°, Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ° Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹. Ğ­Ñ‚Ğ¾Ñ‚ Ñ€ĞµÑÑƒÑ€Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ²Ğ°Ğ½ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ² Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ² Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ² ĞšĞ¸Ñ‚Ğ°Ñ."
                },
                "en": {
                    "title": "Empowering Minority Languages with Tailored Datasets for Headline Generation",
                    "desc": "This paper addresses the challenges faced by minority languages in China, such as Tibetan, Uyghur, and Traditional Mongolian, particularly in the context of headline generation due to their unique writing systems. The authors introduce a new dataset called Chinese Minority Headline Generation (CMHG), which contains 100,000 entries for Tibetan and 50,000 entries each for Uyghur and Mongolian. This dataset is specifically designed for supervised learning tasks, providing a substantial resource for training models in headline generation. Furthermore, a high-quality test set annotated by native speakers is included to establish benchmarks for future research in this area."
                },
                "zh": {
                    "title": "æ¨åŠ¨ä¸­å›½å°‘æ•°æ°‘æ—è¯­è¨€æ ‡é¢˜ç”Ÿæˆçš„åˆ›æ–°æ•°æ®é›†",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œåä¸ºä¸­å›½å°‘æ•°æ°‘æ—æ ‡é¢˜ç”Ÿæˆæ•°æ®é›†ï¼ˆCMHGï¼‰ï¼Œæ—¨åœ¨è§£å†³è—è¯­ã€ç»´å¾å°”è¯­å’Œè’™å¤è¯­åœ¨æ ‡é¢˜ç”Ÿæˆä»»åŠ¡ä¸­çš„æ•°æ®åŒ®ä¹é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«10ä¸‡ä¸ªè—è¯­æ¡ç›®ï¼Œä»¥åŠå„5ä¸‡ä¸ªç»´å¾å°”è¯­å’Œè’™å¤è¯­æ¡ç›®ï¼Œä¸“é—¨ç”¨äºæ ‡é¢˜ç”Ÿæˆã€‚æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªç”±æ¯è¯­è€…æ³¨é‡Šçš„é«˜è´¨é‡æµ‹è¯•é›†ï¼Œä½œä¸ºæœªæ¥ç ”ç©¶çš„åŸºå‡†ã€‚å¸Œæœ›è¿™ä¸ªæ•°æ®é›†èƒ½ä¸ºä¸­å›½å°‘æ•°æ°‘æ—è¯­è¨€çš„æ ‡é¢˜ç”Ÿæˆæä¾›æœ‰ä»·å€¼çš„èµ„æºï¼Œå¹¶æ¨åŠ¨ç›¸å…³åŸºå‡†çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09737",
            "title": "World Modeling with Probabilistic Structure Integration",
            "url": "https://huggingface.co/papers/2509.09737",
            "abstract": "Probabilistic Structure Integration (PSI) learns richly controllable world models from data through probabilistic prediction, structure extraction, and integration, enhancing video prediction and understanding.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Probabilistic Structure Integration (PSI), a system for learning richly controllable and flexibly promptable world models from data. PSI consists of a three-step cycle. The first step, Probabilistic prediction, involves building a probabilistic graphical model Psi of the data, in the form of a random-access autoregressive sequence model. Psi supports a complete set of learned conditional distributions describing the dependence of any variables in the data on any other set of variables. In step 2, Structure extraction, we show how to extract underlying low-dimensional properties in the data, corresponding to a diverse set of meaningful \"intermediate structures\", in a zero-shot fashion via causal inference on Psi. Step 3, Integration, completes the cycle by converting these structures into new token types that are then continually mixed back into the training diet as conditioning signals and prediction targets. Each such cycle augments the capabilities of Psi, both allowing it to model the underlying data better, and creating new control handles -- akin to an LLM-like universal prompting language. We train an instance of Psi on 1.4 trillion tokens of internet video data; we use it to perform a variety of useful video prediction and understanding inferences; we extract state-of-the-art optical flow, self-supervised depth and object segmentation; and we use these structures to support a full cycle of predictive improvements.",
            "score": 1,
            "issue_id": 5899,
            "pub_date": "2025-09-10",
            "pub_date_card": {
                "ru": "10 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 10",
                "zh": "9æœˆ10æ—¥"
            },
            "hash": "c056ea95a829dc6a",
            "authors": [
                "Klemen Kotar",
                "Wanhee Lee",
                "Rahul Venkatesh",
                "Honglin Chen",
                "Daniel Bear",
                "Jared Watrous",
                "Simon Kim",
                "Khai Loong Aw",
                "Lilian Naing Chen",
                "Stefan Stojanov",
                "Kevin Feigelis",
                "Imran Thobani",
                "Alex Durango",
                "Khaled Jedoui",
                "Atlas Kazemian",
                "Dan Yamins"
            ],
            "affiliations": [
                "Stanford NeuroAI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09737.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#multimodal",
                    "#optimization",
                    "#interpretability",
                    "#training",
                    "#data"
                ],
                "emoji": "ğŸ”®",
                "ru": {
                    "title": "PSI: Ğ¦Ğ¸ĞºĞ»Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ¸Ñ€Ğ° Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹",
                    "desc": "Probabilistic Structure Integration (PSI) - ÑÑ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ³Ğ¸Ğ±ĞºĞ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ¸Ñ€Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. PSI Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‚Ñ€ĞµÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ»: Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ, Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½ÑƒÑ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ½Ğ¸Ğ·ĞºĞ¾Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ñ‹Ğµ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ñ… Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. PSI Ğ±Ñ‹Ğ»Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° 1,4 Ñ‚Ñ€Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğ° Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾."
                },
                "en": {
                    "title": "Enhancing World Models with Probabilistic Structure Integration",
                    "desc": "Probabilistic Structure Integration (PSI) is a novel approach for creating advanced world models from data using a three-step process. First, it builds a probabilistic graphical model to predict relationships between variables in the data. Next, it extracts meaningful low-dimensional structures through causal inference, enabling the model to understand complex data patterns. Finally, these structures are integrated back into the training process, enhancing the model's predictive capabilities and allowing for flexible control over its outputs."
                },
                "zh": {
                    "title": "é€šè¿‡æ¦‚ç‡ç»“æ„é›†æˆæå‡è§†é¢‘ç†è§£èƒ½åŠ›",
                    "desc": "æ¦‚ç‡ç»“æ„é›†æˆï¼ˆPSIï¼‰æ˜¯ä¸€ç§é€šè¿‡æ¦‚ç‡é¢„æµ‹ã€ç»“æ„æå–å’Œé›†æˆæ¥ä»æ•°æ®ä¸­å­¦ä¹ å¯æ§çš„ä¸–ç•Œæ¨¡å‹çš„ç³»ç»Ÿã€‚å®ƒçš„ç¬¬ä¸€æ­¥æ˜¯æ„å»ºä¸€ä¸ªæ¦‚ç‡å›¾æ¨¡å‹ï¼Œæ”¯æŒæè¿°æ•°æ®ä¸­å˜é‡ä¹‹é—´ä¾èµ–å…³ç³»çš„æ¡ä»¶åˆ†å¸ƒã€‚ç¬¬äºŒæ­¥æ˜¯é€šè¿‡å› æœæ¨æ–­æå–æ•°æ®ä¸­çš„ä½ç»´ç‰¹å¾ï¼Œå½¢æˆæœ‰æ„ä¹‰çš„ä¸­é—´ç»“æ„ã€‚æœ€åä¸€æ­¥æ˜¯å°†è¿™äº›ç»“æ„è½¬åŒ–ä¸ºæ–°çš„æ ‡è®°ç±»å‹ï¼ŒæŒç»­å¢å¼ºæ¨¡å‹çš„èƒ½åŠ›ï¼Œä»è€Œå®ç°æ›´å¥½çš„è§†é¢‘é¢„æµ‹å’Œç†è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.08825",
            "title": "Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs\n  for Text Annotation",
            "url": "https://huggingface.co/papers/2509.08825",
            "abstract": "LLM hacking introduces significant variability and error in social science research, affecting statistical conclusions and requiring rigorous verification and human annotations to mitigate.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) are rapidly transforming social science research by enabling the automation of labor-intensive tasks like data annotation and text analysis. However, LLM outputs vary significantly depending on the implementation choices made by researchers (e.g., model selection, prompting strategy, or temperature settings). Such variation can introduce systematic biases and random errors, which propagate to downstream analyses and cause Type I, Type II, Type S, or Type M errors. We call this LLM hacking.   We quantify the risk of LLM hacking by replicating 37 data annotation tasks from 21 published social science research studies with 18 different models. Analyzing 13 million LLM labels, we test 2,361 realistic hypotheses to measure how plausible researcher choices affect statistical conclusions. We find incorrect conclusions based on LLM-annotated data in approximately one in three hypotheses for state-of-the-art models, and in half the hypotheses for small language models. While our findings show that higher task performance and better general model capabilities reduce LLM hacking risk, even highly accurate models do not completely eliminate it. The risk of LLM hacking decreases as effect sizes increase, indicating the need for more rigorous verification of findings near significance thresholds. Our extensive analysis of LLM hacking mitigation techniques emphasizes the importance of human annotations in reducing false positive findings and improving model selection. Surprisingly, common regression estimator correction techniques are largely ineffective in reducing LLM hacking risk, as they heavily trade off Type I vs. Type II errors.   Beyond accidental errors, we find that intentional LLM hacking is unacceptably simple. With few LLMs and just a handful of prompt paraphrases, anything can be presented as statistically significant.",
            "score": 1,
            "issue_id": 5897,
            "pub_date": "2025-09-10",
            "pub_date_card": {
                "ru": "10 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 10",
                "zh": "9æœˆ10æ—¥"
            },
            "hash": "4f165e5bca7b20e0",
            "authors": [
                "Joachim Baumann",
                "Paul RÃ¶ttger",
                "Aleksandra Urman",
                "Albert WendsjÃ¶",
                "Flor Miriam Plaza-del-Arco",
                "Johannes B. Gruber",
                "Dirk Hovy"
            ],
            "affiliations": [
                "Bocconi University",
                "GESIS, Leibniz Institute for the Social Sciences",
                "LIACS, Leiden University",
                "University of Gothenburg",
                "University of Zurich"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.08825.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#data",
                    "#multimodal",
                    "#training",
                    "#ethics"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ›Ğ›Ğœ-Ñ…Ğ°ĞºĞ¸Ğ½Ğ³: ÑĞºÑ€Ñ‹Ñ‚Ğ°Ñ ÑƒĞ³Ñ€Ğ¾Ğ·Ğ° Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ°ÑƒĞºĞ°Ñ…",
                    "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğµ Ğ›Ğ›Ğœ-Ñ…Ğ°ĞºĞ¸Ğ½Ğ³Ğ° Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ°ÑƒĞºĞ°Ñ…, Ğ³Ğ´Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ²ĞµÑÑ‚Ğ¸ Ğº ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼ Ğ¸ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¼ Ğ¿Ğ¾Ğ³Ñ€ĞµÑˆĞ½Ğ¾ÑÑ‚ÑĞ¼ Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ»Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚, Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´Ñ 37 Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· 21 Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ 18 Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ´Ğ°Ğ¶Ğµ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ ÑƒÑÑ‚Ñ€Ğ°Ğ½ÑÑÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ€Ğ¸ÑĞº Ğ›Ğ›Ğœ-Ñ…Ğ°ĞºĞ¸Ğ½Ğ³Ğ°, Ğ° Ğ¾Ğ±Ñ‰ĞµĞ¿Ñ€Ğ¸Ğ½ÑÑ‚Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ¼Ğ°Ğ»Ğ¾ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ñ… Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ Ğ¸ Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ², Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ²Ğ±Ğ»Ğ¸Ğ·Ğ¸ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¾Ğ² ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Mitigating LLM Hacking: Ensuring Reliable Social Science Research",
                    "desc": "This paper discusses the concept of 'LLM hacking', which refers to the variability and errors introduced by large language models (LLMs) in social science research. The authors demonstrate that different choices made by researchers, such as model selection and prompting strategies, can lead to significant biases and errors in statistical conclusions. Through extensive analysis of 37 data annotation tasks, they find that incorrect conclusions arise in a substantial number of hypotheses, highlighting the need for rigorous verification and human annotations to mitigate these risks. The study also reveals that while higher-performing models reduce the risk of LLM hacking, they do not eliminate it entirely, emphasizing the importance of careful model selection and validation in research."
                },
                "zh": {
                    "title": "LLMé»‘å®¢è¡Œä¸ºï¼šç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­çš„éšæ‚£",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­çš„åº”ç”¨åŠå…¶å¸¦æ¥çš„é£é™©ï¼Œç§°ä¹‹ä¸ºLLMé»‘å®¢è¡Œä¸ºã€‚ç ”ç©¶å‘ç°ï¼ŒLLMçš„è¾“å‡ºç»“æœå› ç ”ç©¶è€…çš„é€‰æ‹©ï¼ˆå¦‚æ¨¡å‹ã€æç¤ºç­–ç•¥ç­‰ï¼‰è€Œå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè¿™å¯èƒ½å¯¼è‡´ç³»ç»Ÿæ€§åå·®å’Œéšæœºé”™è¯¯ã€‚é€šè¿‡å¯¹37ä¸ªæ•°æ®æ ‡æ³¨ä»»åŠ¡çš„åˆ†æï¼Œå‘ç°çº¦ä¸‰åˆ†ä¹‹ä¸€çš„å‡è®¾å¾—å‡ºäº†é”™è¯¯ç»“è®ºï¼Œå°¤å…¶æ˜¯åœ¨å°å‹è¯­è¨€æ¨¡å‹ä¸­æ›´ä¸ºæ˜æ˜¾ã€‚ç ”ç©¶å¼ºè°ƒäº†äººç±»æ ‡æ³¨åœ¨å‡å°‘å‡é˜³æ€§ç»“æœå’Œæ”¹å–„æ¨¡å‹é€‰æ‹©ä¸­çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºå¸¸è§çš„å›å½’ä¼°è®¡ä¿®æ­£æŠ€æœ¯åœ¨é™ä½LLMé»‘å®¢é£é™©æ–¹é¢æ•ˆæœæœ‰é™ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.04500",
            "title": "Context Engineering for Trustworthiness: Rescorla Wagner Steering Under\n  Mixed and Inappropriate Contexts",
            "url": "https://huggingface.co/papers/2509.04500",
            "abstract": "LLMs process mixed contexts by prioritizing less prevalent information, which can degrade response quality; RW-Steering, a two-stage fine-tuning approach, improves LLM safety by identifying and ignoring inappropriate signals.  \t\t\t\t\tAI-generated summary \t\t\t\t Incorporating external context can significantly enhance the response quality of Large Language Models (LLMs). However, real-world contexts often mix relevant information with disproportionate inappropriate content, posing reliability risks. How do LLMs process and prioritize mixed context? To study this, we introduce the Poisoned Context Testbed, pairing queries with real-world contexts containing relevant and inappropriate content. Inspired by associative learning in animals, we adapt the Rescorla-Wagner (RW) model from neuroscience to quantify how competing contextual signals influence LLM outputs. Our adapted model reveals a consistent behavioral pattern: LLMs exhibit a strong tendency to incorporate information that is less prevalent in the context. This susceptibility is harmful in real-world settings, where small amounts of inappropriate content can substantially degrade response quality. Empirical evaluations on our testbed further confirm this vulnerability. To tackle this, we introduce RW-Steering, a two-stage finetuning-based approach that enables the model to internally identify and ignore inappropriate signals. Unlike prior methods that rely on extensive supervision across diverse context mixtures, RW-Steering generalizes robustly across varying proportions of inappropriate content. Experiments show that our best fine-tuned model improves response quality by 39.8% and reverses the undesirable behavior curve, establishing RW-Steering as a robust, generalizable context engineering solution for improving LLM safety in real-world use.",
            "score": 0,
            "issue_id": 5901,
            "pub_date": "2025-09-02",
            "pub_date_card": {
                "ru": "2 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 2",
                "zh": "9æœˆ2æ—¥"
            },
            "hash": "4e9c238755cf2613",
            "authors": [
                "Rushi Wang",
                "Jiateng Liu",
                "Cheng Qian",
                "Yifan Shen",
                "Yanzhou Pan",
                "Zhaozhuo Xu",
                "Ahmed Abbasi",
                "Heng Ji",
                "Denghui Zhang"
            ],
            "affiliations": [
                "Google LLC",
                "Stevens Institute of Technology",
                "University of Illinois Urbana-Champaign",
                "University of Notre Dame"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04500.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#dataset",
                    "#training",
                    "#hallucinations",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸ĞµĞ¼ LLM Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ³Ğ¾, ĞºĞ°Ğº Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚, ÑƒĞ´ĞµĞ»ÑÑ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµĞ½ĞµĞµ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ ĞµÑĞºĞ¾Ñ€Ğ»Ğ°-Ğ’Ğ°Ğ³Ğ½ĞµÑ€Ğ° Ğ¸Ğ· Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ°ÑƒĞºĞ¸ Ğ´Ğ»Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ ĞºĞ¾Ğ½ĞºÑƒÑ€Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ½Ğ° Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ LLM. ĞĞ½Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ LLM ÑĞºĞ»Ğ¾Ğ½Ğ½Ñ‹ Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ½ĞµĞµ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑƒÑ…ÑƒĞ´ÑˆĞ¸Ñ‚ÑŒ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Ğ”Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ RW-Steering, Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞµ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµĞ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹."
                },
                "en": {
                    "title": "Enhancing LLM Safety with RW-Steering",
                    "desc": "This paper discusses how Large Language Models (LLMs) struggle with mixed contexts that contain both relevant and inappropriate information, which can lead to poor response quality. The authors introduce the Poisoned Context Testbed to analyze how LLMs prioritize less prevalent signals, revealing a tendency to incorporate inappropriate content. To address this issue, they propose RW-Steering, a two-stage fine-tuning method that helps LLMs identify and disregard harmful signals. Their experiments demonstrate that RW-Steering significantly enhances response quality and provides a reliable solution for improving LLM safety in practical applications."
                },
                "zh": {
                    "title": "æå‡å¤§å‹è¯­è¨€æ¨¡å‹å®‰å…¨æ€§çš„RW-Steeringæ–¹æ³•",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†æ··åˆä¸Šä¸‹æ–‡æ—¶ï¼Œå¾€å¾€ä¼šä¼˜å…ˆè€ƒè™‘ä¸å¸¸è§çš„ä¿¡æ¯ï¼Œè¿™å¯èƒ½ä¼šé™ä½å“åº”è´¨é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†ä¸€ç§åä¸ºRW-Steeringçš„ä¸¤é˜¶æ®µå¾®è°ƒæ–¹æ³•ï¼Œå¯ä»¥å¸®åŠ©æ¨¡å‹è¯†åˆ«å¹¶å¿½ç•¥ä¸é€‚å½“çš„ä¿¡å·ã€‚é€šè¿‡å¼•å…¥â€œæ±¡æŸ“ä¸Šä¸‹æ–‡æµ‹è¯•å¹³å°â€ï¼Œç ”ç©¶è€…ä»¬å‘ç°LLMsåœ¨é¢å¯¹æ··åˆä¿¡æ¯æ—¶ï¼Œå®¹æ˜“å—åˆ°å°‘é‡ä¸å½“å†…å®¹çš„å½±å“ï¼Œä»è€Œå½±å“è¾“å‡ºç»“æœã€‚RW-Steeringæ–¹æ³•çš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„æ¨¡å‹åœ¨å“åº”è´¨é‡ä¸Šæé«˜äº†39.8%ï¼Œæœ‰æ•ˆæå‡äº†LLMåœ¨ç°å®åº”ç”¨ä¸­çš„å®‰å…¨æ€§ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-09-12.html",
    "link_next": "2025-09-16.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "12.09",
        "en": "09/12",
        "zh": "9æœˆ12æ—¥"
    },
    "short_date_next": {
        "ru": "16.09",
        "en": "09/16",
        "zh": "9æœˆ16æ—¥"
    },
    "categories": {
        "#dataset": 6,
        "#data": 4,
        "#benchmark": 8,
        "#agents": 4,
        "#cv": 2,
        "#rl": 2,
        "#rlhf": 2,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 6,
        "#math": 1,
        "#multilingual": 2,
        "#architecture": 5,
        "#healthcare": 1,
        "#training": 9,
        "#robotics": 1,
        "#agi": 0,
        "#games": 2,
        "#interpretability": 5,
        "#reasoning": 5,
        "#transfer_learning": 2,
        "#graphs": 0,
        "#ethics": 2,
        "#security": 0,
        "#optimization": 8,
        "#survey": 0,
        "#diffusion": 4,
        "#alignment": 4,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 3,
        "#machine_translation": 1,
        "#leakage": 0,
        "#open_source": 5,
        "#small_models": 0,
        "#science": 3,
        "#low_resource": 1
    }
}