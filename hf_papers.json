{
    "date": {
        "ru": "6 ноября",
        "en": "November 6",
        "zh": "11月6日"
    },
    "time_utc": "2024-11-06 06:46",
    "weekday": 2,
    "issue_id": 441,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.02959",
            "title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
            "url": "https://huggingface.co/papers/2411.02959",
            "abstract": "Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and pruning strategies, to shorten the HTML while minimizing the loss of information. Specifically, we design a two-step block-tree-based pruning method that prunes useless HTML blocks and keeps only the relevant part of the HTML. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems.",
            "score": 17,
            "issue_id": 437,
            "pub_date": "2024-11-05",
            "pub_date_card": {
                "ru": "5 ноября",
                "en": "November 5",
                "zh": "11月5日"
            },
            "hash": "6fb8684374e5fdcb",
            "data": {
                "categories": [
                    "#rag",
                    "#data",
                    "#training"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "HtmlRAG: Улучшение RAG-систем с помощью структурированной веб-информации",
                    "desc": "Статья представляет новый подход к генерации с извлечением информации (RAG), названный HtmlRAG. В отличие от традиционных систем RAG, использующих простой текст, HtmlRAG сохраняет структурную и семантическую информацию HTML-документов. Авторы предлагают методы очистки, сжатия и обрезки HTML для уменьшения шума и сокращения входных токенов. Эксперименты на шести наборах данных для вопросно-ответных систем подтверждают превосходство использования HTML в системах RAG."
                },
                "en": {
                    "title": "Harnessing HTML for Enhanced Knowledge Retrieval in RAG Systems",
                    "desc": "This paper introduces HtmlRAG, a novel approach to Retrieval-Augmented Generation (RAG) that utilizes HTML instead of plain text for knowledge retrieval. By leveraging the structural and semantic information present in HTML, HtmlRAG aims to enhance the performance of large language models (LLMs) and reduce the hallucination problem. The authors address the challenges posed by HTML, such as excess tokens and noise, by implementing cleaning, compression, and pruning techniques to streamline the input. Experimental results demonstrate that HtmlRAG outperforms traditional plain-text-based RAG systems across multiple question-answering datasets."
                },
                "zh": {
                    "title": "用HTML提升检索增强生成的能力",
                    "desc": "本文提出了一种新的检索增强生成（RAG）方法，称为HtmlRAG，旨在改善大语言模型（LLMs）的知识能力并减少幻觉问题。HtmlRAG使用HTML格式而非纯文本来增强生成过程，从而保留更多的结构和语义信息。为了应对HTML中多余内容带来的挑战，本文提出了HTML清理、压缩和修剪策略，以减少输入的冗余信息。实验结果表明，HtmlRAG在六个问答数据集上的表现优于传统的纯文本RAG系统。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.00871",
            "title": "LLaMo: Large Language Model-based Molecular Graph Assistant",
            "url": "https://huggingface.co/papers/2411.00871",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization and instruction-following capabilities with instruction tuning. The advancements in LLMs and instruction tuning have led to the development of Large Vision-Language Models (LVLMs). However, the competency of the LLMs and instruction tuning have been less explored in the molecular domain. Thus, we propose LLaMo: Large Language Model-based Molecular graph assistant, which is an end-to-end trained large molecular graph-language model. To bridge the discrepancy between the language and graph modalities, we present the multi-level graph projector that transforms graph representations into graph tokens by abstracting the output representations of each GNN layer and motif representations with the cross-attention mechanism. We also introduce machine-generated molecular graph instruction data to instruction-tune the large molecular graph-language model for general-purpose molecule and language understanding. Our extensive experiments demonstrate that LLaMo shows the best performance on diverse tasks, such as molecular description generation, property prediction, and IUPAC name prediction. The code of LLaMo is available at https://github.com/mlvlab/LLaMo.",
            "score": 12,
            "issue_id": 439,
            "pub_date": "2024-10-31",
            "pub_date_card": {
                "ru": "31 октября",
                "en": "October 31",
                "zh": "10月31日"
            },
            "hash": "d1284691dab4e739",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#agents",
                    "#architecture",
                    "#training"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "LLaMo: Революция в понимании молекулярных структур с помощью ИИ",
                    "desc": "Исследователи представили LLaMo - ассистента для работы с молекулярными графами, основанного на большой языковой модели. LLaMo использует многоуровневый графовый проектор для преобразования графовых представлений в токены, что позволяет объединить языковую и графовую модальности. Модель обучена на инструкциях, сгенерированных машинным способом, для понимания молекул и языка. Эксперименты показывают, что LLaMo превосходит существующие решения в задачах генерации описаний молекул, предсказания свойств и определения названий по IUPAC."
                },
                "en": {
                    "title": "Bridging Language and Molecules with LLaMo",
                    "desc": "This paper introduces LLaMo, a Large Language Model-based Molecular graph assistant designed to enhance understanding in the molecular domain. It utilizes a multi-level graph projector to convert molecular graph representations into tokens, facilitating better interaction between language and graph data. The model is instruction-tuned using machine-generated molecular graph instruction data, enabling it to perform various tasks like molecular description generation and property prediction. Experimental results show that LLaMo outperforms existing models in these tasks, highlighting its effectiveness in bridging language and molecular graph understanding."
                },
                "zh": {
                    "title": "LLaMo：连接语言与分子的桥梁",
                    "desc": "大型语言模型（LLMs）在指令调优方面展现了出色的泛化能力和遵循指令的能力。本文提出了LLaMo，一个基于大型语言模型的分子图助手，旨在填补语言和图形模态之间的差距。我们引入了多层图投影器，通过跨注意力机制将图表示转换为图标记，并使用机器生成的分子图指令数据对模型进行指令调优。实验结果表明，LLaMo在分子描述生成、属性预测和IUPAC名称预测等多项任务中表现最佳。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.02359",
            "title": "DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution",
            "url": "https://huggingface.co/papers/2411.02359",
            "abstract": "MLLMs have demonstrated remarkable comprehension and reasoning capabilities with complex language and visual data. These advances have spurred the vision of establishing a generalist robotic MLLM proficient in understanding complex human instructions and accomplishing various embodied tasks. However, developing MLLMs for real-world robots is challenging due to the typically limited computation and memory capacities available on robotic platforms. In contrast, the inference of MLLMs involves storing billions of parameters and performing tremendous computation, imposing significant hardware demands. In our paper, we propose a Dynamic Early-Exit Framework for Robotic Vision-Language-Action Model (DeeR-VLA, or simply DeeR) that automatically adjusts the size of the activated MLLM based on each situation at hand. The approach leverages a multi-exit architecture in MLLMs, which allows the model to terminate processing once a proper size of the model has been activated for a specific situation, thus avoiding further redundant computation. Additionally, we develop novel algorithms that establish early-termination criteria for DeeR, conditioned on predefined demands such as average computational cost (i.e., power consumption), as well as peak computational consumption (i.e., latency) and GPU memory usage. These enhancements ensure that DeeR operates efficiently under varying resource constraints while maintaining competitive performance. On the CALVIN robot manipulation benchmark, DeeR demonstrates significant reductions in computational costs of LLM by 5.2-6.5x and GPU memory of LLM by 2-6x without compromising performance. Code and checkpoints are available at https://github.com/yueyang130/DeeR-VLA.",
            "score": 7,
            "issue_id": 437,
            "pub_date": "2024-11-04",
            "pub_date_card": {
                "ru": "4 ноября",
                "en": "November 4",
                "zh": "11月4日"
            },
            "hash": "08c45469caff5fa0",
            "data": {
                "categories": [
                    "#agents",
                    "#inference",
                    "#robots",
                    "#optimization",
                    "#benchmark"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Эффективные языковые модели для роботов: меньше ресурсов, та же мощность",
                    "desc": "Статья представляет Dynamic Early-Exit Framework для робототехнических моделей зрения, языка и действия (DeeR-VLA). Эта система автоматически регулирует размер активированной мультимодальной языковой модели (MLLM) в зависимости от ситуации, используя архитектуру с множественными выходами. DeeR разработан для эффективной работы в условиях ограниченных вычислительных ресурсов роботов. На бенчмарке CALVIN система показала значительное снижение вычислительных затрат и использования памяти GPU без ущерба для производительности."
                },
                "en": {
                    "title": "Efficient Robotic Intelligence with Dynamic Early-Exit MLLMs",
                    "desc": "This paper introduces a new framework called DeeR for improving the efficiency of robotic vision-language-action models (MLLMs). DeeR uses a Dynamic Early-Exit approach that allows the model to adjust its size based on the specific task, reducing unnecessary computations. By implementing a multi-exit architecture, the model can stop processing once it has enough information, which helps save power and memory. The results show that DeeR can significantly lower computational costs and memory usage while still performing well on tasks, making it suitable for real-world robotic applications."
                },
                "zh": {
                    "title": "动态调整，智能机器人更高效！",
                    "desc": "本论文提出了一种动态早期退出框架（DeeR-VLA），旨在解决机器人视觉-语言-动作模型（MLLM）在实际应用中的计算和内存限制问题。该框架通过多出口架构，能够根据具体情况自动调整激活的模型大小，从而避免冗余计算。我们还开发了新算法，设定早期终止标准，以满足预定义的计算需求，如功耗和延迟。实验结果表明，DeeR在CALVIN机器人操作基准上显著降低了计算成本和GPU内存使用，同时保持了竞争力的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.01493",
            "title": "Sample-Efficient Alignment for LLMs",
            "url": "https://huggingface.co/papers/2411.01493",
            "abstract": "We study methods for efficiently aligning large language models (LLMs) with human preferences given budgeted online feedback. We first formulate the LLM alignment problem in the frame of contextual dueling bandits. This formulation, subsuming recent paradigms such as online RLHF and online DPO, inherently quests for sample-efficient algorithms that incorporate online active exploration. Leveraging insights from bandit theory, we introduce a unified algorithm based on Thompson sampling and highlight its applications in two distinct LLM alignment scenarios. The practical agent that efficiently implements this algorithm, named SEA (Sample-Efficient Alignment), is empirically validated through extensive experiments across three model scales (1B, 2.8B, 6.9B) and three preference learning algorithms (DPO, IPO, SLiC). The results demonstrate that SEA achieves highly sample-efficient alignment with oracle's preferences, outperforming recent active exploration methods for LLMs. Additionally, we release the implementation of SEA together with an efficient codebase designed for online alignment of LLMs, aiming to accelerate future research in this field.",
            "score": 5,
            "issue_id": 440,
            "pub_date": "2024-11-03",
            "pub_date_card": {
                "ru": "3 ноября",
                "en": "November 3",
                "zh": "11月3日"
            },
            "hash": "c5bb9727a6ba6119",
            "data": {
                "categories": [
                    "#rlhf",
                    "#alignment",
                    "#agents"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Эффективное согласование языковых моделей с помощью контекстных дуэльных бандитов",
                    "desc": "Исследователи изучают методы эффективного согласования больших языковых моделей (LLM) с человеческими предпочтениями при ограниченной онлайн-обратной связи. Они формулируют проблему согласования LLM в рамках контекстных дуэльных бандитов и предлагают унифицированный алгоритм на основе выборки Томпсона. Практический агент SEA (Sample-Efficient Alignment), реализующий этот алгоритм, показывает высокую эффективность выборки при согласовании с предпочтениями оракула. Исследователи также выпускают реализацию SEA вместе с эффективной кодовой базой для онлайн-согласования LLM."
                },
                "en": {
                    "title": "Efficiently Aligning LLMs with Human Preferences Using SEA",
                    "desc": "This paper explores how to align large language models (LLMs) with human preferences using limited online feedback. It frames the alignment challenge as a contextual dueling bandits problem, which seeks efficient algorithms that can learn from active exploration. The authors propose a new algorithm called SEA (Sample-Efficient Alignment) based on Thompson sampling, which is tested across various model sizes and preference learning methods. The results show that SEA is highly effective in aligning LLMs with human preferences while using fewer samples compared to existing methods."
                },
                "zh": {
                    "title": "高效对齐大型语言模型与人类偏好",
                    "desc": "本文研究了如何在有限的在线反馈下高效地将大型语言模型（LLMs）与人类偏好对齐。我们将LLM对齐问题框定为上下文对抗赌博者问题，提出了一种基于汤普森采样的统一算法，并在两个不同的LLM对齐场景中进行了应用。通过大量实验验证，名为SEA（样本高效对齐）的实用代理在不同规模的模型和偏好学习算法中表现出色，显示出其在对齐方面的高样本效率。我们还发布了SEA的实现和高效代码库，以促进该领域未来的研究。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.01602",
            "title": "DreamPolish: Domain Score Distillation With Progressive Geometry Generation",
            "url": "https://huggingface.co/papers/2411.01602",
            "abstract": "We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a view-conditioned diffusion prior in the novel sampled views, which often leads to undesired artifacts in the geometric surface, we incorporate an additional normal estimator to polish the geometry details, conditioned on viewpoints with varying field-of-views. We propose to add a surface polishing stage with only a few training steps, which can effectively refine the artifacts attributed to limited guidance from previous stages and produce 3D objects with more desirable geometry. The key topic of texture generation using pretrained text-to-image models is to find a suitable domain in the vast latent distribution of these models that contains photorealistic and consistent renderings. In the texture generation phase, we introduce a novel score distillation objective, namely domain score distillation (DSD), to guide neural representations toward such a domain. We draw inspiration from the classifier-free guidance (CFG) in textconditioned image generation tasks and show that CFG and variational distribution guidance represent distinct aspects in gradient guidance and are both imperative domains for the enhancement of texture quality. Extensive experiments show our proposed model can produce 3D assets with polished surfaces and photorealistic textures, outperforming existing state-of-the-art methods.",
            "score": 1,
            "issue_id": 439,
            "pub_date": "2024-11-03",
            "pub_date_card": {
                "ru": "3 ноября",
                "en": "November 3",
                "zh": "11月3日"
            },
            "hash": "403fd08e60540a0a",
            "data": {
                "categories": [
                    "#3d",
                    "#cv"
                ],
                "emoji": "🎨",
                "ru": {
                    "title": "DreamPolish: Революция в генерации 3D-объектов с идеальной геометрией и текстурами",
                    "desc": "DreamPolish - это модель генерации 3D-объектов из текста, которая превосходит существующие методы в создании утонченной геометрии и высококачественных текстур. Модель использует множественные нейронные представления и дополнительный оценщик нормалей для улучшения стабильности синтеза геометрии. Для генерации текстур авторы предлагают новый метод дистилляции оценок в определенном домене (DSD), используя предобученные модели text-to-image. Эксперименты показывают, что DreamPolish создает 3D-объекты с отполированными поверхностями и фотореалистичными текстурами, превосходя современные методы."
                },
                "en": {
                    "title": "DreamPolish: Elevating 3D Generation with Refined Geometry and Textures",
                    "desc": "DreamPolish is a text-to-3D generation model that focuses on creating high-quality 3D objects with refined geometry and textures. It improves the geometry construction by using multiple neural representations and an additional normal estimator to reduce artifacts caused by limited guidance. The model also introduces a surface polishing stage that requires minimal training to enhance the geometric details further. For texture generation, it employs a novel domain score distillation (DSD) method, inspired by classifier-free guidance, to achieve photorealistic and consistent textures in the generated 3D assets."
                },
                "zh": {
                    "title": "DreamPolish：生成高质量3D资产的创新模型",
                    "desc": "本文介绍了一种名为DreamPolish的文本到3D生成模型，能够生成精细的几何形状和高质量的纹理。在几何构建阶段，我们利用多种神经表示来增强合成过程的稳定性，并引入额外的法线估计器来改善几何细节。纹理生成阶段采用了一种新的评分蒸馏目标，称为领域评分蒸馏（DSD），以引导神经表示朝向包含真实感和一致性渲染的适当领域。实验表明，我们的模型能够生成表面光滑且具有真实感纹理的3D资产，超越了现有的最先进方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.02657",
            "title": "Zebra-Llama: A Context-Aware Large Language Model for Democratizing Rare Disease Knowledge",
            "url": "https://huggingface.co/papers/2411.02657",
            "abstract": "Rare diseases present unique challenges in healthcare, often suffering from delayed diagnosis and fragmented information landscapes. The scarcity of reliable knowledge in these conditions poses a distinct challenge for Large Language Models (LLMs) in supporting clinical management and delivering precise patient information underscoring the need for focused training on these 'zebra' cases. We present Zebra-Llama, a specialized context-aware language model with high precision Retrieval Augmented Generation (RAG) capability, focusing on Ehlers-Danlos Syndrome (EDS) as our case study. EDS, affecting 1 in 5,000 individuals, exemplifies the complexities of rare diseases with its diverse symptoms, multiple subtypes, and evolving diagnostic criteria. By implementing a novel context-aware fine-tuning methodology trained on questions derived from medical literature, patient experiences, and clinical resources, along with expertly curated responses, Zebra-Llama demonstrates unprecedented capabilities in handling EDS-related queries. On a test set of real-world questions collected from EDS patients and clinicians, medical experts evaluated the responses generated by both models, revealing Zebra-Llama's substantial improvements over base model (Llama 3.1-8B-Instruct) in thoroughness (77.5% vs. 70.1%), accuracy (83.0% vs. 78.8%), clarity (74.7% vs. 72.0%) and citation reliability (70.6% vs. 52.3%). Released as an open-source resource, Zebra-Llama not only provides more accessible and reliable EDS information but also establishes a framework for developing specialized AI solutions for other rare conditions. This work represents a crucial step towards democratizing expert-level knowledge in rare disease management, potentially transforming how healthcare providers and patients navigate the complex landscape of rare diseases.",
            "score": 1,
            "issue_id": 439,
            "pub_date": "2024-11-04",
            "pub_date_card": {
                "ru": "4 ноября",
                "en": "November 4",
                "zh": "11月4日"
            },
            "hash": "26c0b7bc39488945",
            "data": {
                "categories": [
                    "#rag",
                    "#medicine",
                    "#training",
                    "#alignment"
                ],
                "emoji": "🦓",
                "ru": {
                    "title": "Zebra-Llama: ИИ-эксперт по редким заболеваниям",
                    "desc": "Статья представляет Zebra-Llama - специализированную языковую модель для редких заболеваний, используя синдром Элерса-Данлоса (EDS) как пример. Модель использует контекстно-зависимую настройку и усиленную генерацию с извлечением (RAG) для обработки запросов, связанных с EDS. Zebra-Llama показала значительные улучшения по сравнению с базовой моделью в полноте, точности, ясности и надежности цитирования при ответе на реальные вопросы пациентов и врачей. Эта работа открывает путь к созданию специализированных ИИ-решений для других редких заболеваний, демократизируя экспертные знания в этой области."
                },
                "en": {
                    "title": "Zebra-Llama: Transforming Rare Disease Management with AI",
                    "desc": "This paper introduces Zebra-Llama, a specialized language model designed to improve the management of rare diseases, specifically Ehlers-Danlos Syndrome (EDS). It addresses the challenges posed by limited information and delayed diagnoses in rare conditions by utilizing a context-aware fine-tuning approach. The model employs Retrieval Augmented Generation (RAG) to enhance the precision of responses to EDS-related queries, outperforming the base model in various evaluation metrics. By making Zebra-Llama an open-source resource, the authors aim to democratize access to expert knowledge in rare disease management, paving the way for similar advancements in other rare conditions."
                },
                "zh": {
                    "title": "Zebra-Llama：罕见疾病管理的新突破",
                    "desc": "罕见疾病在医疗保健中面临独特挑战，常常导致诊断延迟和信息碎片化。针对这些罕见病例，本文提出了一种名为Zebra-Llama的专门语言模型，具备高精度的检索增强生成能力，重点关注Ehlers-Danlos综合症（EDS）。通过一种新颖的上下文感知微调方法，Zebra-Llama在处理与EDS相关的问题时表现出前所未有的能力，显著提高了回答的全面性、准确性和清晰度。该模型作为开源资源发布，不仅提供了更易获取和可靠的EDS信息，还为其他罕见疾病开发专门的人工智能解决方案奠定了基础。"
                }
            }
        }
    ],
    "link_prev": "2024-11-05.html",
    "link_next": "2024-11-07.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "05.11",
        "en": "11/05",
        "zh": "11月5日"
    },
    "short_date_next": {
        "ru": "07.11",
        "en": "11/07",
        "zh": "11月7日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 3,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 2,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#medicine": 1,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#translation": 0,
        "#robots": 0
    },
    "zh": {
        "text": "这篇文章讨论了自主代理在现实世界交互中的重要性，特别是Android代理。文章指出，现有研究缺乏对开源和闭源模型的系统研究。作者提出了AndroidLab，一个系统的Android代理框架，包含多种模态的操作环境和可重复的基准测试。该框架支持大型语言模型和多模态模型。通过使用AndroidLab环境，作者开发了一个Android指令数据集，并训练了六个开源的大型语言模型和多模态模型，显著提高了任务成功率。AndroidLab是开源的，可在GitHub上获取。",
        "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents",
        "pinyin": "Zhè piān wénzhāng tǎolùn le zìzhǔ dàilǐ zài xiànshí shìjiè jiāohù zhōng de zhòngyàoxìng, tèbié shì Android dàilǐ. Wénzhāng zhǐchū, xiànyǒu yánjiū quēfá duì kāiyuán hé bìyuán móxíng de xìtǒng yánjiū. Zuòzhě tíchū le AndroidLab, yīgè xìtǒng de Android dàilǐ kuàngjià, bāohán duōzhǒng mótài de cāozuò huánjìng hé kě chóngfù de jīzhǔn cèshì. Gāi kuàngjià zhīchí dàxíng yǔyán móxíng hé duō mótài móxíng. Tōngguò shǐyòng AndroidLab huánjìng, zuòzhě kāifā le yīgè Android zhǐlǐng shùjùjí, bìng xùnliàn le liù gè kāiyuán de dàxíng yǔyán móxíng hé duō mótài móxíng, xiǎnzhù tígāo le rènwù chénggōnglǜ. AndroidLab shì kāiyuán de, kě zài GitHub shàng huòqǔ.",
        "vocab": "[\n    {\"word\": \"自主代理\", \"pinyin\": \"zìzhǔ dàilǐ\", \"trans\": \"autonomous agent\"},\n    {\"word\": \"现实世界\", \"pinyin\": \"xiànshí shìjiè\", \"trans\": \"real world\"},\n    {\"word\": \"交互\", \"pinyin\": \"jiāohù\", \"trans\": \"interaction\"},\n    {\"word\": \"Android代理\", \"pinyin\": \"Android dàilǐ\", \"trans\": \"Android agent\"},\n    {\"word\": \"现有研究\", \"pinyin\": \"xiànyǒu yánjiū\", \"trans\": \"existing research\"},\n    {\"word\": \"缺乏\", \"pinyin\": \"quēfá\", \"trans\": \"lack\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāiyuán\", \"trans\": \"open source\"},\n    {\"word\": \"闭源\", \"pinyin\": \"bìyuán\", \"trans\": \"closed source\"},\n    {\"word\": \"系统研究\", \"pinyin\": \"xìtǒng yánjiū\", \"trans\": \"systematic study\"},\n    {\"word\": \"AndroidLab\", \"pinyin\": \"AndroidLab\", \"trans\": \"AndroidLab\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàngjià\", \"trans\": \"framework\"},\n    {\"word\": \"多种模态\", \"pinyin\": \"duōzhǒng móshì\", \"trans\": \"multimodal\"},\n    {\"word\": \"操作环境\", \"pinyin\": \"cāozuò huánjìng\", \"trans\": \"operating environment\"},\n    {\"word\": \"可重复\", \"pinyin\": \"kě chóngfù\", \"trans\": \"reproducible\"},\n    {\"word\": \"基准测试\", \"pinyin\": \"jīzhǔn cèshì\", \"trans\": \"benchmark test\"},\n    {\"word\": \"支持\", \"pinyin\": \"zhīchí\", \"trans\": \"support\"},\n    {\"word\": \"大型语言模型\", \"pinyin\": \"dàxíng yǔyán móxíng\", \"trans\": \"large language model\"},\n    {\"word\": \"多模态模型\", \"pinyin\": \"duō móshì móxíng\", \"trans\": \"multimodal model\"},\n    {\"word\": \"使用\", \"pinyin\": \"shǐyòng\", \"trans\": \"use\"},\n    {\"word\": \"环境\", \"pinyin\": \"huánjìng\", \"trans\": \"environment\"},\n    {\"word\": \"开发\", \"pinyin\": \"kāifā\", \"trans\": \"develop\"},\n    {\"word\": \"Android指令数据集\", \"pinyin\": \"Android zhǐlìng shùjùjí\", \"trans\": \"Android command dataset\"},\n    {\"word\": \"训练\", \"pinyin\": \"xùnliàn\", \"trans\": \"train\"},\n    {\"word\": \"六个\", \"pinyin\": \"liù gè\", \"trans\": \"six\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎnzhù\", \"trans\": \"significant\"},\n    {\"word\": \"提高\", \"pinyin\": \"tígāo\", \"trans\": \"improve\"},\n    {\"word\": \"任务成功率\", \"pinyin\": \"rènwù chénggōnglǜ\", \"trans\": \"task success rate\"},\n    {\"word\": \"GitHub\", \"pinyin\": \"GitHub\", \"trans\": \"GitHub\"}\n]",
        "trans": "This article discusses the importance of autonomous agents in real-world interactions, particularly Android agents. The article notes that existing research lacks systematic studies on open-source and closed-source models. The authors introduce AndroidLab, a systematic Android agent framework that includes multi-modal operation environments and reproducible benchmark tests. This framework supports large language models and multi-modal models. By using the AndroidLab environment, the authors developed an Android instruction dataset and trained six open-source large language models and multi-modal models, significantly improving task success rates. AndroidLab is open-source and available on GitHub.",
        "update_ts": "2024-11-05 10:13"
    }
}