
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 14 papers. February 7.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["–º–∏–Ω—É—Ç—É", "–º–∏–Ω—É—Ç—ã", "–º–∏–Ω—É—Ç"],
                hour: ["—á–∞—Å", "—á–∞—Å–∞", "—á–∞—Å–æ–≤"],
                day: ["–¥–µ–Ω—å", "–¥–Ω—è", "–¥–Ω–µ–π"],
                justNow: "—Ç–æ–ª—å–∫–æ —á—Ç–æ",
                ago: "–Ω–∞–∑–∞–¥"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["ÂàÜÈíü", "ÂàÜÈíü", "ÂàÜÈíü"],
                hour: ["Â∞èÊó∂", "Â∞èÊó∂", "Â∞èÊó∂"],
                day: ["Â§©", "Â§©", "Â§©"],
                justNow: "ÂàöÂàö",
                ago: "Ââç"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "—Å—Ç–∞—Ç–µ–π";
            } else if (lastDigit === 1) {
                word = "—Å—Ç–∞—Ç—å—è";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "—Å—Ç–∞—Ç—å–∏";
            } else {
                word = "—Å—Ç–∞—Ç–µ–π";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "ÁØáËÆ∫Êñá"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">üî∫</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">7 —Ñ–µ–≤—Ä–∞–ª—è</span> | <span id="title-articles-count">14 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-02-06.html">‚¨ÖÔ∏è <span id="prev-date">06.02</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-02-10.html">‚û°Ô∏è <span id="next-date">10.02</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-02.html">üìà <span id='top-month-label'>–ú–µ—Å—è—Ü</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">üîÄ <span id="sort-label-text">–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">—Ä–µ–π—Ç–∏–Ω–≥—É</option>
                    <option value="pub_date">–¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏</option>
                    <option value="issue_id">–¥–æ–±–∞–≤–ª–µ–Ω–∏—é –Ω–∞ HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">üè∑Ô∏è –§–∏–ª—å—Ç—Ä</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A‚à™B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A‚à©B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">üßπ</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ‚úñÔ∏è <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '7 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 7', 'zh': '2Êúà7Êó•'};
        let feedDateNext = {'ru': '10.02', 'en': '02/10', 'zh': '2Êúà10Êó•'};
        let feedDatePrev = {'ru': '06.02', 'en': '02/06', 'zh': '2Êúà6Êó•'};
        let filterLabel = {'ru': '–§–∏–ª—å—Ç—Ä', 'en': 'Topics', 'zh': '‰∏ªÈ¢òÁ≠õÈÄâ'}
        let publishedLabel = {'ru': '—Å—Ç–∞—Ç—å—è –æ—Ç ', 'en': 'published on ', 'zh': 'ÂèëË°®‰∫é'}
        let sortLabel = {'ru': '–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ', 'en': 'Sort by', 'zh': 'ÊéíÂ∫èÊñπÂºè'}
        let paperLabel = {'ru': '–°—Ç–∞—Ç—å—è', 'en': 'Paper', 'zh': 'ËÆ∫Êñá'}
        let topMonthLabel = {'ru': '–ú–µ—Å—è—Ü', 'en': 'Month', 'zh': 'ÊúàÂ∫¶ËÆ∫Êñá'}
        let topDayLabel = {'ru': '–î–µ–Ω—å', 'en': 'Day', 'zh': 'Êó•Â∫¶ËÆ∫Êñá'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2502.02737', 'title': 'SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model', 'url': 'https://huggingface.co/papers/2502.02737', 'abstract': 'While large language models have facilitated breakthroughs in many applications of artificial intelligence, their inherent largeness makes them computationally expensive and challenging to deploy in resource-constrained settings. In this paper, we document the development of SmolLM2, a state-of-the-art "small" (1.7 billion parameter) language model (LM). To attain strong performance, we overtrain SmolLM2 on ~11 trillion tokens of data using a multi-stage training process that mixes web text with specialized math, code, and instruction-following data. We additionally introduce new specialized datasets (FineMath, Stack-Edu, and SmolTalk) at stages where we found existing datasets to be problematically small or low-quality. To inform our design decisions, we perform both small-scale ablations as well as a manual refinement process that updates the dataset mixing rates at each stage based on the performance at the previous stage. Ultimately, we demonstrate that SmolLM2 outperforms other recent small LMs including Qwen2.5-1.5B and Llama3.2-1B. To facilitate future research on LM development as well as applications of small LMs, we release both SmolLM2 as well as all of the datasets we prepared in the course of this project.', 'score': 93, 'issue_id': 2066, 'pub_date': '2025-02-04', 'pub_date_card': {'ru': '4 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 4', 'zh': '2Êúà4Êó•'}, 'hash': 'c78fe4c39300443d', 'authors': ['Loubna Ben Allal', 'Anton Lozhkov', 'Elie Bakouch', 'Gabriel Mart√≠n Bl√°zquez', 'Guilherme Penedo', 'Lewis Tunstall', 'Andr√©s Marafioti', 'Hynek Kydl√≠ƒçek', 'Agust√≠n Piqueres Lajar√≠n', 'Vaibhav Srivastav', 'Joshua Lochner', 'Caleb Fahlgren', 'Xuan-Son Nguyen', 'Cl√©mentine Fourrier', 'Ben Burtenshaw', 'Hugo Larcher', 'Haojun Zhao', 'Cyril Zakka', 'Mathieu Morlon', 'Colin Raffel', 'Leandro von Werra', 'Thomas Wolf'], 'affiliations': ['HuggingFaceTB'], 'pdf_title_img': 'assets/pdf/title_img/2502.02737.jpg', 'data': {'categories': ['#open_source', '#dataset', '#low_resource', '#training', '#small_models'], 'emoji': 'ü§è', 'ru': {'title': '–ë–æ–ª—å—à–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ –º–∞–ª–µ–Ω—å–∫–æ–º –ø–∞–∫–µ—Ç–µ: SmolLM2 - –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –≤–ø–µ—á–∞—Ç–ª—è—é—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é', 'desc': "–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É SmolLM2 - —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π '–º–∞–ª–µ–Ω—å–∫–æ–π' —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å 1,7 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ ~11 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞, —Å–æ—á–µ—Ç–∞—é—â–µ–≥–æ –≤–µ–±-—Ç–µ–∫—Å—Ç—ã —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ, –∫–æ–¥—É –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–≤–µ–ª–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ SmolLM2 –ø—Ä–µ–≤–∑–æ—à–ª–∞ –¥—Ä—É–≥–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–∞–ª—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ Qwen2.5-1.5B –∏ Llama3.2-1B."}, 'en': {'title': 'SmolLM2: Efficient Language Modeling for Resource-Constrained Environments', 'desc': 'This paper presents SmolLM2, a compact language model with 1.7 billion parameters designed to be efficient for deployment in resource-limited environments. The model is trained on an extensive dataset of approximately 11 trillion tokens, utilizing a multi-stage training approach that incorporates diverse data sources, including web text and specialized datasets for math and coding. The authors introduce new datasets to enhance training quality and perform systematic evaluations to optimize dataset mixing based on performance feedback. SmolLM2 demonstrates superior performance compared to other recent small language models, and the authors provide access to the model and datasets for further research.'}, 'zh': {'title': 'Â∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂº∫Â§ßÁ™ÅÁ†¥', 'desc': 'Êú¨ËÆ∫Êñá‰ªãÁªç‰∫ÜSmolLM2ÁöÑÂºÄÂèëÔºåËøôÊòØ‰∏Ä‰∏™ÂÖ∑Êúâ17‰∫øÂèÇÊï∞ÁöÑÂ∞èÂûãËØ≠Ë®ÄÊ®°Âûã„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Âº∫Â§ßÁöÑÊÄßËÉΩÔºåÊàë‰ª¨Âú®Á∫¶11‰∏á‰∫ø‰∏™Êï∞ÊçÆ‰∏äËøõË°å‰∫ÜËøáÂ∫¶ËÆ≠ÁªÉÔºåÈááÁî®‰∫ÜÂ§öÈò∂ÊÆµËÆ≠ÁªÉËøáÁ®ãÔºåÁªìÂêà‰∫ÜÁΩëÁªúÊñáÊú¨„ÄÅÊï∞Â≠¶„ÄÅ‰ª£Á†ÅÂíåÊåá‰ª§Ë∑üÈöèÊï∞ÊçÆ„ÄÇÊàë‰ª¨ËøòÂºïÂÖ•‰∫ÜÊñ∞ÁöÑ‰∏ìÁî®Êï∞ÊçÆÈõÜÔºå‰ª•Ëß£ÂÜ≥Áé∞ÊúâÊï∞ÊçÆÈõÜËßÑÊ®°Â∞èÊàñË¥®Èáè‰ΩéÁöÑÈóÆÈ¢ò„ÄÇÊúÄÁªàÔºåÊàë‰ª¨ËØÅÊòéSmolLM2Âú®ÊÄßËÉΩ‰∏äË∂ÖË∂ä‰∫ÜÂÖ∂‰ªñËøëÊúüÁöÑÂ∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂ¶ÇQwen2.5-1.5BÂíåLlama3.2-1B„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.01506', 'title': 'TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets', 'url': 'https://huggingface.co/papers/2502.01506', 'abstract': 'The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.', 'score': 27, 'issue_id': 2063, 'pub_date': '2025-02-03', 'pub_date_card': {'ru': '3 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 3', 'zh': '2Êúà3Êó•'}, 'hash': 'f5ec0450054af574', 'authors': ['Yuzhe Yang', 'Yifei Zhang', 'Minghao Wu', 'Kaidi Zhang', 'Yunmiao Zhang', 'Honghai Yu', 'Yan Hu', 'Benyou Wang'], 'affiliations': ['Nanjing University', 'The Chinese University of Hong Kong, Shenzhen'], 'pdf_title_img': 'assets/pdf/title_img/2502.01506.jpg', 'data': {'categories': ['#multimodal', '#agents'], 'emoji': 'üìä', 'ru': {'title': 'LLM-–∞–≥–µ–Ω—Ç—ã —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç —Ç–∞–π–Ω—ã —Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π –¥–∏–Ω–∞–º–∏–∫–∏', 'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ TwinMarket –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –ê–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç LLM-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã. –í —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö –Ω–∞ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ–Ω–¥–æ–≤–æ–º —Ä—ã–Ω–∫–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è, –∫–∞–∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –≥—Ä—É–ø–ø–æ–≤–æ–º—É –ø–æ–≤–µ–¥–µ–Ω–∏—é –∏ —ç–º–µ—Ä–≥–µ–Ω—Ç–Ω—ã–º —è–≤–ª–µ–Ω–∏—è–º. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –º–µ–∂–¥—É –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –ø—Ä–∏–Ω—è—Ç–∏–µ–º —Ä–µ—à–µ–Ω–∏–π –∏ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–º–∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏.'}, 'en': {'title': 'Harnessing LLMs for Realistic Socio-Economic Simulations', 'desc': 'This paper presents TwinMarket, a new framework that uses large language models (LLMs) to simulate socio-economic systems. Unlike traditional Agent-Based Models, TwinMarket captures the complexity of human behavior, including cognitive biases and emotional influences. The framework allows for the exploration of how individual actions can lead to collective dynamics, such as financial bubbles and recessions, in a simulated stock market. By leveraging LLMs, the study provides deeper insights into the interactions between individual decision-making and broader socio-economic patterns.'}, 'zh': {'title': 'Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊ®°ÊãüÁ§æ‰ºöÁªèÊµéÁ≥ªÁªüÁöÑÊ∂åÁé∞Áé∞Ë±°', 'desc': 'Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÁ§æ‰ºöÊ∂åÁé∞Áé∞Ë±°Ôºå‰º†ÁªüÁöÑÂü∫‰∫éËßÑÂàôÁöÑ‰ª£ÁêÜÊ®°ÂûãÔºàABMÔºâÈöæ‰ª•ÊçïÊçâ‰∫∫Á±ªË°å‰∏∫ÁöÑÂ§öÊ†∑ÊÄßÂíåÂ§çÊùÇÊÄßÔºåÂ∞§ÂÖ∂ÊòØË°å‰∏∫ÁªèÊµéÂ≠¶‰∏≠Âº∫Ë∞ÉÁöÑÈùûÁêÜÊÄßÂõ†Á¥†„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂ§ö‰ª£ÁêÜÊ°ÜÊû∂TwinMarketÔºåÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊù•Ê®°ÊãüÁ§æ‰ºöÁªèÊµéÁ≥ªÁªü„ÄÇÈÄöËøáÊ®°ÊãüËÇ°Á•®Â∏ÇÂú∫ÁéØÂ¢ÉÁöÑÂÆûÈ™åÔºåÊàë‰ª¨Â±ïÁ§∫‰∫Ü‰∏™‰ΩìË°å‰∏∫Â¶Ç‰ΩïÈÄöËøá‰∫íÂä®ÂíåÂèçÈ¶àÊú∫Âà∂ÂºïÂèëÈõÜ‰ΩìÂä®ÊÄÅÔºåÂØºËá¥ÈáëËûçÊ≥°Ê≤´ÂíåÁªèÊµéË°∞ÈÄÄÁ≠âÊ∂åÁé∞Áé∞Ë±°„ÄÇËØ•ÊñπÊ≥ï‰∏∫‰∏™‰ΩìÂÜ≥Á≠ñ‰∏éÈõÜ‰ΩìÁ§æ‰ºöÁªèÊµéÊ®°Âºè‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ªÊèê‰æõ‰∫ÜÂÆùË¥µÁöÑËßÅËß£„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.03373', 'title': 'Demystifying Long Chain-of-Thought Reasoning in LLMs', 'url': 'https://huggingface.co/papers/2502.03373', 'abstract': 'Scaling inference compute enhances reasoning in large language models (LLMs), with long chains-of-thought (CoTs) enabling strategies like backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we present four main findings: (1) While SFT is not strictly necessary, it simplifies training and improves efficiency; (2) Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We find that leveraging noisy, web-extracted solutions with filtering mechanisms shows strong potential, particularly for out-of-distribution (OOD) tasks such as STEM reasoning; and (4) Core abilities like error correction are inherently present in base models, but incentivizing these skills effectively for complex tasks via RL demands significant compute, and measuring their emergence requires a nuanced approach. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs. Our code is available at: https://github.com/eddycmu/demystify-long-cot.', 'score': 26, 'issue_id': 2064, 'pub_date': '2025-02-05', 'pub_date_card': {'ru': '5 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 5', 'zh': '2Êúà5Êó•'}, 'hash': 'a1d00a6c8452131a', 'authors': ['Edward Yeo', 'Yuxuan Tong', 'Morry Niu', 'Graham Neubig', 'Xiang Yue'], 'affiliations': ['Carnegie Mellon University', 'IN.AI', 'Tsinghua University'], 'pdf_title_img': 'assets/pdf/title_img/2502.03373.jpg', 'data': {'categories': ['#optimization', '#reasoning', '#rl', '#training', '#long_context'], 'emoji': 'üß†', 'ru': {'title': '–†–∞—Å–∫—Ä—ã–≤–∞—è —Å–µ–∫—Ä–µ—Ç—ã –¥–ª–∏–Ω–Ω—ã—Ö —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –ò–ò', 'desc': '–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º—ã –¥–ª–∏–Ω–Ω—ã—Ö —Ü–µ–ø–æ—á–µ–∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (CoT) –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM). –ê–≤—Ç–æ—Ä—ã –≤—ã—è–≤–ª—è—é—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ CoT —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —á–µ—Ä–µ–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) –∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤, —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞–≥—Ä–∞–¥ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ–±-–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è –¥–ª–∏–Ω–Ω—ã—Ö CoT —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ LLM.'}, 'en': {'title': 'Unlocking Reasoning Power in Large Language Models', 'desc': 'This paper explores how to improve reasoning in large language models (LLMs) by enhancing their inference capabilities through long chains-of-thought (CoTs). It highlights the importance of reinforcement learning (RL) in developing these reasoning skills, while also addressing the unclear conditions for the emergence of long CoTs. The study presents four key findings, including the role of supervised fine-tuning (SFT) in simplifying training, the necessity of reward shaping for stabilizing CoT growth, and the significance of scaling reward signals for effective RL. Overall, the research provides valuable insights for optimizing training strategies to boost long CoT reasoning in LLMs.'}, 'zh': {'title': '‰ºòÂåñËÆ≠ÁªÉÁ≠ñÁï•ÔºåÊèêÂçáÈïøÊé®ÁêÜÈìæËÉΩÂäõ', 'desc': 'Êú¨Á†îÁ©∂Êé¢ËÆ®‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ‰∏≠ÈïøÊé®ÁêÜÈìæÔºàCoTsÔºâÁöÑÁîüÊàêÊú∫Âà∂ÔºåÊè≠Á§∫‰∫ÜÂΩ±ÂìçÊ®°ÂûãÁîüÊàêÈïøÊé®ÁêÜÈìæÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåËôΩÁÑ∂ÁõëÁù£ÂæÆË∞ÉÔºàSFTÔºâ‰∏çÊòØÁªùÂØπÂøÖË¶ÅÁöÑÔºå‰ΩÜÂÆÉÂèØ‰ª•ÁÆÄÂåñËÆ≠ÁªÉËøáÁ®ãÂπ∂ÊèêÈ´òÊïàÁéá„ÄÇÈöèÁùÄËÆ≠ÁªÉËÆ°ÁÆóËÉΩÂäõÁöÑÂ¢ûÂä†ÔºåÊé®ÁêÜËÉΩÂäõÊúâÂèØËÉΩÂá∫Áé∞Ôºå‰ΩÜÂÖ∂ÂèëÂ±ïÂπ∂‰∏çÊÄªÊòØ‰øùËØÅÔºåÂõ†Ê≠§Â•ñÂä±ËÆæËÆ°ÂØπ‰∫éÁ®≥ÂÆöÊé®ÁêÜÈìæÁöÑÈïøÂ∫¶Â¢ûÈïøËá≥ÂÖ≥ÈáçË¶Å„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂‰∏∫‰ºòÂåñËÆ≠ÁªÉÁ≠ñÁï•‰ª•Â¢ûÂº∫LLMs‰∏≠ÁöÑÈïøÊé®ÁêÜÈìæÊèê‰æõ‰∫ÜÂÆûÁî®ÊåáÂØº„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.03387', 'title': 'LIMO: Less is More for Reasoning', 'url': 'https://huggingface.co/papers/2502.03387', 'abstract': 'We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (>100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models\' 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model\'s encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as "cognitive templates" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at https://github.com/GAIR-NLP/LIMO.', 'score': 24, 'issue_id': 2066, 'pub_date': '2025-02-05', 'pub_date_card': {'ru': '5 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 5', 'zh': '2Êúà5Êó•'}, 'hash': 'ad1fa98bc3904527', 'authors': ['Yixin Ye', 'Zhen Huang', 'Yang Xiao', 'Ethan Chern', 'Shijie Xia', 'Pengfei Liu'], 'affiliations': ['SJTU, SII, GAIR'], 'pdf_title_img': 'assets/pdf/title_img/2502.03387.jpg', 'data': {'categories': ['#open_source', '#dataset', '#reasoning', '#training', '#math'], 'emoji': 'üß†', 'ru': {'title': '–ú–µ–Ω—å—à–µ –∑–Ω–∞—á–∏—Ç –±–æ–ª—å—à–µ: —Ä–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–ª–æ–∂–Ω—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º', 'desc': '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ —Å–ª–æ–∂–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö –º–æ–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤. –ò—Ö –º–æ–¥–µ–ª—å LIMO –¥–æ—Å—Ç–∏–≥–ª–∞ –≤–ø–µ—á–∞—Ç–ª—è—é—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å–µ–≥–æ 817 –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ, —á–µ–º —É –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤. LIMO —Ç–∞–∫–∂–µ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–∞ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –æ–±–æ–±—â–µ–Ω–∏—é –≤–Ω–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –ø—Ä–µ–≤–∑–æ–π–¥—è –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ–º –æ–±—ä–µ–º–µ –¥–∞–Ω–Ω—ã—Ö. –ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –≥–∏–ø–æ—Ç–µ–∑—É LIMO, —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ—Ç–æ—Ä–æ–π —Å–ª–æ–∂–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–∞—Ç—å —á–µ—Ä–µ–∑ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ, –Ω–æ —Ç–æ—á–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –≤ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö.'}, 'en': {'title': 'Less Data, More Reasoning: The LIMO Hypothesis', 'desc': 'This paper reveals a surprising finding about how large language models can perform complex reasoning tasks. It shows that instead of needing a lot of training data, a model called LIMO can achieve high accuracy in mathematical reasoning with only a small number of examples. LIMO outperforms previous models that used much more data, indicating that less can be more when it comes to training for reasoning tasks. The authors introduce the Less-Is-More Reasoning Hypothesis, suggesting that a well-prepared model can effectively learn complex reasoning from minimal, well-structured examples.'}, 'zh': {'title': 'Â∞ëÂç≥ÊòØÂ§öÔºåÊé®ÁêÜËÉΩÂäõÁöÑÊñ∞ÂèëÁé∞', 'desc': 'Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÈ°πÈáçË¶ÅÂèëÁé∞ÔºåÊåëÊàò‰∫ÜÊàë‰ª¨ÂØπÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏≠Â§çÊùÇÊé®ÁêÜËÉΩÂäõ‰∫ßÁîüÊú∫Âà∂ÁöÑÁêÜËß£„ÄÇ‰º†ÁªüËßÇÁÇπËÆ§‰∏∫ÔºåÂ§çÊùÇÊé®ÁêÜ‰ªªÂä°ÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰ΩÜÊàë‰ª¨ËØÅÊòéÂè™ÈúÄÂ∞ëÈáèÁ§∫‰æãÂç≥ÂèØÊúâÊïàÂºïÂèëÂ§çÊùÇÁöÑÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãLIMOÂú®Êï∞Â≠¶Êé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫ÂâçÊâÄÊú™ÊúâÁöÑÊÄßËÉΩÔºå‰ΩøÁî®‰ªÖ817‰∏™ËÆ≠ÁªÉÊ†∑Êú¨ÔºåÂàÜÂà´Âú®AIMEÂíåMATH‰∏äËææÂà∞‰∫Ü57.1%Âíå94.8%ÁöÑÂáÜÁ°ÆÁéá„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑ‚ÄúÂ∞ëÂç≥ÊòØÂ§öÊé®ÁêÜÂÅáËÆæ‚ÄùË°®ÊòéÔºåÂú®Âü∫Á°ÄÊ®°Âûã‰∏≠ÔºåÁªèËøáÂÖÖÂàÜÁºñÁ†ÅÁöÑÈ¢ÜÂüüÁü•ËØÜÂèØ‰ª•ÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÂ∞ëÈáèÁ§∫‰æãÊù•ÊøÄÂèëÂ§çÊùÇÊé®ÁêÜËÉΩÂäõ„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.02339', 'title': 'Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking', 'url': 'https://huggingface.co/papers/2502.02339', 'abstract': "Multimodal large language models (MLLMs) exhibit impressive capabilities but still face challenges in complex visual reasoning. While recent efforts attempt to enhance MLLMs' reasoning by incorporating OpenAI o1-like structured thinking through explicit search structures or teacher-guided distillation, they often struggle to balance performance and efficiency. A critical limitation is their heavy reliance on extensive data and search spaces, resulting in low-efficiency implicit insight extraction and data utilization. To address this, we propose AStar, an Automated Structured thinking paradigm for multimodal reasoning via Monte Carlo Tree Search (MCTS). AStar automatically derives high-level cognitive reasoning patterns from limited data using MCTS-powered hierarchical structures. Building on these explicit patterns, we design a unified reasoning framework that seamlessly integrates models' internal reasoning capabilities and external reasoning guidelines, enabling efficient inference with minimal tree iterations. This novel paradigm strikes a compelling balance between performance and efficiency. Extensive experiments demonstrate AStar's effectiveness, achieving superior accuracy (54.0%) on the MathVerse benchmark with a 7B backbone, surpassing GPT-4o (50.2%) while maintaining substantial data and computational efficiency.", 'score': 10, 'issue_id': 2063, 'pub_date': '2025-02-04', 'pub_date_card': {'ru': '4 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 4', 'zh': '2Êúà4Êó•'}, 'hash': '3f3413717efb32f6', 'authors': ['Jinyang Wu', 'Mingkuan Feng', 'Shuai Zhang', 'Ruihan Jin', 'Feihu Che', 'Zengqi Wen', 'Jianhua Tao'], 'affiliations': ['Beijing', 'Department of Automation, Tsinghua University, Beijing, China'], 'pdf_title_img': 'assets/pdf/title_img/2502.02339.jpg', 'data': {'categories': ['#optimization', '#reasoning', '#benchmark', '#multimodal', '#architecture', '#training'], 'emoji': 'üß†', 'ru': {'title': 'AStar: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ò–ò', 'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —É–ª—É—á—à–µ–Ω–∏—é –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLM). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –º–µ—Ç–æ–¥ AStar, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–∞ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –ø–æ –¥–µ—Ä–µ–≤—É (MCTS). AStar –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —É–∫–∞–∑–∞–Ω–∏—è–º–∏. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ AStar –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ 54.0% –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ MathVerse, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è GPT-4o –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.'}, 'en': {'title': 'AStar: Enhancing Multimodal Reasoning with Efficient Structured Thinking', 'desc': "This paper introduces AStar, a new approach to improve the reasoning abilities of multimodal large language models (MLLMs) using Monte Carlo Tree Search (MCTS). AStar focuses on deriving high-level cognitive reasoning patterns from limited data, which helps in enhancing the models' performance without requiring extensive data sets. The framework integrates internal reasoning capabilities of the models with external guidelines, allowing for efficient inference with fewer iterations. Experimental results show that AStar outperforms existing models like GPT-4o in accuracy while being more data and computationally efficient."}, 'zh': {'title': 'AStarÔºöÈ´òÊïàÁöÑÂ§öÊ®°ÊÄÅÊé®ÁêÜÊñ∞ËåÉÂºè', 'desc': 'Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®Â§çÊùÇËßÜËßâÊé®ÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜ‰ªçÈù¢‰∏¥ÊåëÊàò„ÄÇÂ∞ΩÁÆ°ÊúÄËøëÁöÑÁ†îÁ©∂Â∞ùËØïÈÄöËøáÂºïÂÖ•ÁªìÊûÑÂåñÊÄùÁª¥ÂíåÊïôÂ∏àÊåáÂØºÊù•Â¢ûÂº∫Êé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂú®ÊÄßËÉΩÂíåÊïàÁéá‰πãÈó¥ÁöÑÂπ≥Ë°°‰ªçÁÑ∂Âõ∞Èöæ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫AStarÁöÑËá™Âä®ÂåñÁªìÊûÑÂåñÊÄùÁª¥ËåÉÂºèÔºåÂà©Áî®ËíôÁâπÂç°Ê¥õÊ†ëÊêúÁ¥¢ÔºàMCTSÔºâ‰ªéÊúâÈôêÊï∞ÊçÆ‰∏≠Ëá™Âä®Êé®ÂØºÈ´òÂ±ÇÊ¨°ÁöÑËÆ§Áü•Êé®ÁêÜÊ®°Âºè„ÄÇAStarÈÄöËøáÁªü‰∏ÄÁöÑÊé®ÁêÜÊ°ÜÊû∂ÔºåÁªìÂêàÊ®°ÂûãÁöÑÂÜÖÈÉ®Êé®ÁêÜËÉΩÂäõÂíåÂ§ñÈÉ®Êé®ÁêÜÊåáÂØºÔºåÂÆûÁé∞È´òÊïàÊé®ÁêÜÔºåÊòæËëóÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÂíåÊï∞ÊçÆÂà©Áî®ÊïàÁéá„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.01105', 'title': 'LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer', 'url': 'https://huggingface.co/papers/2502.01105', 'abstract': "Generating cognitive-aligned layered SVGs remains challenging due to existing methods' tendencies toward either oversimplified single-layer outputs or optimization-induced shape redundancies. We propose LayerTracer, a diffusion transformer based framework that bridges this gap by learning designers' layered SVG creation processes from a novel dataset of sequential design operations. Our approach operates in two phases: First, a text-conditioned DiT generates multi-phase rasterized construction blueprints that simulate human design workflows. Second, layer-wise vectorization with path deduplication produces clean, editable SVGs. For image vectorization, we introduce a conditional diffusion mechanism that encodes reference images into latent tokens, guiding hierarchical reconstruction while preserving structural integrity. Extensive experiments demonstrate LayerTracer's superior performance against optimization-based and neural baselines in both generation quality and editability, effectively aligning AI-generated vectors with professional design cognition.", 'score': 7, 'issue_id': 2067, 'pub_date': '2025-02-03', 'pub_date_card': {'ru': '3 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 3', 'zh': '2Êúà3Êó•'}, 'hash': 'b4eb829c549c6a2e', 'authors': ['Yiren Song', 'Danze Chen', 'Mike Zheng Shou'], 'affiliations': ['Show Lab, National University of Singapore, Singapore'], 'pdf_title_img': 'assets/pdf/title_img/2502.01105.jpg', 'data': {'categories': ['#optimization', '#multimodal', '#diffusion', '#cv', '#dataset'], 'emoji': 'üé®', 'ru': {'title': 'LayerTracer: –ò–ò-–¥–∏–∑–∞–π–Ω–µ—Ä –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫–∏', 'desc': 'LayerTracer - —ç—Ç–æ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã—Ö SVG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ. –û–Ω –∏–º–∏—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–±–æ—Ç—ã –¥–∏–∑–∞–π–Ω–µ—Ä–∞, –≥–µ–Ω–µ—Ä–∏—Ä—É—è –ø–æ—à–∞–≥–æ–≤—ã–µ —Ä–∞—Å—Ç—Ä–æ–≤—ã–µ —á–µ—Ä—Ç–µ–∂–∏, –∞ –∑–∞—Ç–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑—É—è –∏—Ö –ø–æ —Å–ª–æ—è–º. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É—Å–ª–æ–≤–Ω—ã–π –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ LayerTracer –Ω–∞–¥ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫–∏.'}, 'en': {'title': 'LayerTracer: Bridging the Gap in Layered SVG Generation', 'desc': 'This paper introduces LayerTracer, a new framework that improves the generation of layered SVGs by learning from how designers create them. It uses a two-phase process: first, it generates rasterized blueprints that mimic human design steps, and then it converts these into clean, editable SVGs while removing duplicate paths. The framework employs a conditional diffusion mechanism to ensure that the generated images maintain their structure and quality. Experiments show that LayerTracer outperforms existing methods in both the quality of the generated designs and their ease of editing, aligning better with professional design practices.'}, 'zh': {'title': 'LayerTracerÔºöÊô∫ËÉΩÁîüÊàêÂèØÁºñËæëÁöÑÂàÜÂ±ÇSVGÂõæÂΩ¢', 'desc': 'Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫LayerTracerÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÁîüÊàêËÆ§Áü•ÂØπÈΩêÁöÑÂàÜÂ±ÇSVGÂõæÂΩ¢„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÂ≠¶‰π†ËÆæËÆ°Â∏àÁöÑÂàÜÂ±ÇSVGÂàõÂª∫ËøáÁ®ãÔºåÂà©Áî®‰∏Ä‰∏™Êñ∞È¢ñÁöÑÈ°∫Â∫èËÆæËÆ°Êìç‰ΩúÊï∞ÊçÆÈõÜ„ÄÇLayerTracerÂàÜ‰∏∫‰∏§‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÔºåÂü∫‰∫éÊñáÊú¨ÁöÑÊâ©Êï£ÂèòÊç¢Âô®ÁîüÊàêÂ§öÈò∂ÊÆµÁöÑÂÖâÊ†ÖÂåñÊûÑÂª∫ËìùÂõæÔºõÂÖ∂Ê¨°ÔºåÈÄöËøáË∑ØÂæÑÂéªÈáçÂÆûÁé∞ÂàÜÂ±ÇÁü¢ÈáèÂåñÔºåÁîüÊàêÂπ≤ÂáÄ‰∏îÂèØÁºñËæëÁöÑSVGÊñá‰ª∂„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLayerTracerÂú®ÁîüÊàêË¥®ÈáèÂíåÂèØÁºñËæëÊÄßÊñπÈù¢‰ºò‰∫éÂü∫‰∫é‰ºòÂåñÂíåÁ•ûÁªèÁΩëÁªúÁöÑÂü∫Á∫øÊñπÊ≥ïÔºåÊúâÊïàÂú∞Â∞ÜAIÁîüÊàêÁöÑÁü¢ÈáèÂõæ‰∏é‰∏ì‰∏öËÆæËÆ°ËÆ§Áü•ÂØπÈΩê„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.02671', 'title': 'On Teacher Hacking in Language Model Distillation', 'url': 'https://huggingface.co/papers/2502.02671', 'abstract': "Post-training of language models (LMs) increasingly relies on the following two stages: (i) knowledge distillation, where the LM is trained to imitate a larger teacher LM, and (ii) reinforcement learning from human feedback (RLHF), where the LM is aligned by optimizing a reward model. In the second RLHF stage, a well-known challenge is reward hacking, where the LM over-optimizes the reward model. Such phenomenon is in line with Goodhart's law and can lead to degraded performance on the true objective. In this paper, we investigate whether a similar phenomenon, that we call teacher hacking, can occur during knowledge distillation. This could arise because the teacher LM is itself an imperfect approximation of the true distribution. To study this, we propose a controlled experimental setup involving: (i) an oracle LM representing the ground-truth distribution, (ii) a teacher LM distilled from the oracle, and (iii) a student LM distilled from the teacher. Our experiments reveal the following insights. When using a fixed offline dataset for distillation, teacher hacking occurs; moreover, we can detect it by observing when the optimization process deviates from polynomial convergence laws. In contrast, employing online data generation techniques effectively mitigates teacher hacking. More precisely, we identify data diversity as the key factor in preventing hacking. Overall, our findings provide a deeper understanding of the benefits and limitations of distillation for building robust and efficient LMs.", 'score': 6, 'issue_id': 2072, 'pub_date': '2025-02-04', 'pub_date_card': {'ru': '4 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 4', 'zh': '2Êúà4Êó•'}, 'hash': 'defca87e9bf06d0b', 'authors': ['Daniil Tiapkin', 'Daniele Calandriello', 'Johan Ferret', 'Sarah Perrin', 'Nino Vieillard', 'Alexandre Ram√©', 'Mathieu Blondel'], 'affiliations': ['Ecole 1CMAP, France; Polytechnique', 'Google DeepMind'], 'pdf_title_img': 'assets/pdf/title_img/2502.02671.jpg', 'data': {'categories': ['#alignment', '#optimization', '#rlhf', '#training', '#data'], 'emoji': 'üß†', 'ru': {'title': "–ë–æ—Ä—å–±–∞ —Å 'teacher hacking': –∫–ª—é—á –∫ robust —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º", 'desc': "–°—Ç–∞—Ç—å—è –∏—Å—Å–ª–µ–¥—É–µ—Ç —Ñ–µ–Ω–æ–º–µ–Ω 'teacher hacking' –ø—Ä–∏ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É —Å –æ—Ä–∞–∫—É–ª–æ–º, —É—á–∏—Ç–µ–ª–µ–º –∏ —É—á–µ–Ω–∏–∫–æ–º –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è —ç—Ç–æ–≥–æ —è–≤–ª–µ–Ω–∏—è. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ 'teacher hacking' –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ñ–ª–∞–π–Ω-–¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–º—è–≥—á–µ–Ω —Å –ø–æ–º–æ—â—å—é –æ–Ω–ª–∞–π–Ω-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è 'hacking' –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–∞–¥–µ–∂–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π."}, 'en': {'title': 'Preventing Teacher Hacking: The Key Role of Data Diversity in Distillation', 'desc': "This paper explores the concept of 'teacher hacking' in the context of knowledge distillation for language models (LMs). Teacher hacking occurs when a student LM overly optimizes based on an imperfect teacher LM, leading to poor performance on the actual task. The authors conducted experiments using an oracle LM as the ground truth, a teacher LM distilled from it, and a student LM distilled from the teacher. They found that using diverse online data can prevent teacher hacking, highlighting the importance of data diversity in the distillation process."}, 'zh': {'title': 'Èò≤Ê≠¢ÊïôÂ∏àÈªëÂÆ¢ÔºåÊèêÂçáËØ≠Ë®ÄÊ®°ÂûãÁöÑËí∏È¶èÊïàÊûú', 'desc': 'Êú¨ÊñáÊé¢ËÆ®‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÔºàLMÔºâÂú®Áü•ËØÜËí∏È¶èÈò∂ÊÆµÂèØËÉΩÂá∫Áé∞ÁöÑ‚ÄúÊïôÂ∏àÈªëÂÆ¢‚ÄùÁé∞Ë±°„ÄÇÊïôÂ∏àÈªëÂÆ¢ÊòØÊåáÂ≠¶ÁîüÊ®°ÂûãÂú®Ê®°‰ªøÊïôÂ∏àÊ®°ÂûãÊó∂ÔºåËøáÂ∫¶‰ºòÂåñÂØºËá¥ÊÄßËÉΩ‰∏ãÈôçÁöÑÊÉÖÂÜµ„ÄÇËøôÁßçÁé∞Ë±°‰∏éÂè§Âæ∑ÂìàÁâπÊ≥ïÂàôÁõ∏Á¨¶ÔºåÂèØËÉΩÊ∫ê‰∫éÊïôÂ∏àÊ®°ÂûãÂØπÁúüÂÆûÂàÜÂ∏ÉÁöÑ‰∏çÂÆåÁæéËøë‰ºº„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºå‰ΩøÁî®Âõ∫ÂÆöÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÈõÜËøõË°åËí∏È¶èÊó∂ÔºåÊïôÂ∏àÈªëÂÆ¢Áé∞Ë±°‰ºöÂèëÁîüÔºåËÄåÈááÁî®Âú®Á∫øÊï∞ÊçÆÁîüÊàêÊäÄÊúØÂàôËÉΩÊúâÊïàÁºìËß£Ëøô‰∏ÄÈóÆÈ¢òÔºåÊï∞ÊçÆÂ§öÊ†∑ÊÄßÊòØÈò≤Ê≠¢ÊïôÂ∏àÈªëÂÆ¢ÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.02928', 'title': 'Large Language Model Guided Self-Debugging Code Generation', 'url': 'https://huggingface.co/papers/2502.02928', 'abstract': 'Automated code generation is gaining significant importance in intelligent computer programming and system deployment. However, current approaches often face challenges in computational efficiency and lack robust mechanisms for code parsing and error correction. In this work, we propose a novel framework, PyCapsule, with a simple yet effective two-agent pipeline and efficient self-debugging modules for Python code generation. PyCapsule features sophisticated prompt inference, iterative error handling, and case testing, ensuring high generation stability, safety, and correctness. Empirically, PyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3% on HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art methods. We also observe a decrease in normalized success rate given more self-debugging attempts, potentially affected by limited and noisy error feedback in retention. PyCapsule demonstrates broader impacts on advancing lightweight and efficient code generation for artificial intelligence systems.', 'score': 5, 'issue_id': 2075, 'pub_date': '2025-02-05', 'pub_date_card': {'ru': '5 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 5', 'zh': '2Êúà5Êó•'}, 'hash': 'dc7aaadeeee7e1e7', 'authors': ['Muntasir Adnan', 'Zhiwei Xu', 'Carlos C. N. Kuhn'], 'affiliations': ['Open Source Institute, Faculty of Science and Technology, University of Canberra, Australia'], 'pdf_title_img': 'assets/pdf/title_img/2502.02928.jpg', 'data': {'categories': ['#agents', '#plp', '#training'], 'emoji': 'üêç', 'ru': {'title': 'PyCapsule: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è Python-–∫–æ–¥–∞ —Å —Å–∞–º–æ–æ—Ç–ª–∞–¥–∫–æ–π', 'desc': 'PyCapsule - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –Ω–∞ Python, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –¥–≤—É—Ö–∞–≥–µ–Ω—Ç–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –∏ –º–æ–¥—É–ª–∏ —Å–∞–º–æ–æ—Ç–ª–∞–¥–∫–∏. –°–∏—Å—Ç–µ–º–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —Å–ª–æ–∂–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ–º–ø—Ç–æ–≤, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. PyCapsule –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏. –û–¥–Ω–∞–∫–æ –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è —Å–Ω–∏–∂–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –ø–æ–ø—ã—Ç–æ–∫ —Å–∞–º–æ–æ—Ç–ª–∞–¥–∫–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –∏ –∑–∞—à—É–º–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ–± –æ—à–∏–±–∫–∞—Ö.'}, 'en': {'title': 'Revolutionizing Python Code Generation with PyCapsule', 'desc': 'This paper introduces PyCapsule, a new framework designed to enhance automated code generation, particularly for Python. It employs a two-agent pipeline that focuses on efficient self-debugging and robust error handling, addressing common issues in existing methods. The framework utilizes advanced prompt inference and iterative testing to improve the stability and correctness of generated code. Empirical results show that PyCapsule outperforms current state-of-the-art techniques in various benchmarks, highlighting its potential for more efficient AI-driven programming solutions.'}, 'zh': {'title': 'PyCapsuleÔºöÈ´òÊïàÁöÑËá™Âä®Âåñ‰ª£Á†ÅÁîüÊàêÊ°ÜÊû∂', 'desc': 'Ëá™Âä®Âåñ‰ª£Á†ÅÁîüÊàêÂú®Êô∫ËÉΩËÆ°ÁÆóÊú∫ÁºñÁ®ãÂíåÁ≥ªÁªüÈÉ®ÁΩ≤‰∏≠ÂèòÂæóË∂äÊù•Ë∂äÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊñπÊ≥ïÂú®ËÆ°ÁÆóÊïàÁéá‰∏äÂ∏∏Â∏∏Èù¢‰∏¥ÊåëÊàòÔºåÂπ∂‰∏îÁº∫‰πèÂº∫Â§ßÁöÑ‰ª£Á†ÅËß£ÊûêÂíåÈîôËØØ‰øÆÊ≠£Êú∫Âà∂„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ°ÜÊû∂PyCapsuleÔºåÈááÁî®ÁÆÄÂçïËÄåÊúâÊïàÁöÑÂèå‰ª£ÁêÜÁÆ°ÈÅìÂíåÈ´òÊïàÁöÑËá™ÊàëË∞ÉËØïÊ®°ÂùóÊù•ÁîüÊàêPython‰ª£Á†Å„ÄÇPyCapsuleÈÄöËøáÂ§çÊùÇÁöÑÊèêÁ§∫Êé®ÁêÜ„ÄÅËø≠‰ª£ÈîôËØØÂ§ÑÁêÜÂíåÊ°à‰æãÊµãËØïÔºåÁ°Æ‰øù‰∫ÜÈ´òÁîüÊàêÁ®≥ÂÆöÊÄß„ÄÅÂÆâÂÖ®ÊÄßÂíåÊ≠£Á°ÆÊÄß„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.01618', 'title': 'A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods', 'url': 'https://huggingface.co/papers/2502.01618', 'abstract': 'Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code and further information is available at https://probabilistic-inference-scaling.github.io.', 'score': 5, 'issue_id': 2065, 'pub_date': '2025-02-03', 'pub_date_card': {'ru': '3 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 3', 'zh': '2Êúà3Êó•'}, 'hash': 'c9971916eb027101', 'authors': ['Isha Puri', 'Shivchander Sudalairaj', 'Guangxuan Xu', 'Kai Xu', 'Akash Srivastava'], 'affiliations': ['MIT CSAIL', 'Red Hat AI Innovation'], 'pdf_title_img': 'assets/pdf/title_img/2502.01618.jpg', 'data': {'categories': ['#reasoning', '#optimization', '#math', '#inference'], 'emoji': 'üé≤', 'ru': {'title': '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é –≤—ã–≤–æ–¥–∞ LLM', 'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º—è –≤—ã–≤–æ–¥–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM). –í–º–µ—Å—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –∞–≤—Ç–æ—Ä—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –∑–∞–¥–∞—á—É –∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –≤—ã–≤–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥—ã –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–∏—Ü. –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –∏–º–µ–µ—Ç –≤ 4-16 —Ä–∞–∑ –ª—É—á—à—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∞–Ω–∞–ª–æ–≥–∞–º–∏ –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, –∫–∞–∫ –Ω–µ–±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –¥–æ—Å—Ç–∏—á—å —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫—Ä—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –º–µ–Ω—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–æ–≥–æ–Ω–æ–≤.'}, 'en': {'title': 'Revolutionizing Inference: Probabilistic Scaling for LLMs', 'desc': 'This paper addresses the limitations of scaling large language models (LLMs) by focusing on improving inference time rather than just increasing model size or data. The authors propose a new approach that treats inference-time scaling as a probabilistic inference task, using sampling techniques to better explore the state distribution. By applying particle-based Monte Carlo methods, their method shows significant improvements in scaling rates compared to traditional deterministic search methods. The results indicate that their approach can achieve higher accuracy with fewer rollouts, demonstrating a promising direction for enhancing LLM performance.'}, 'zh': {'title': 'Êé®ÁêÜÊó∂Èó¥Êâ©Â±ïÁöÑÊñ∞ÊñπÊ≥ïÔºöÊ¶ÇÁéáÊé®ÁêÜ‰∏éÁ≤íÂ≠êÈááÊ†∑ÁªìÂêà', 'desc': 'Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÈÄöËøáÂ¢ûÂä†Ê®°ÂûãËßÑÊ®°ÂíåÊï∞ÊçÆÈáèÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåËøôÁßçÊñπÊ≥ïÁöÑÊî∂ÁõäÈÄíÂáèÔºå‰øÉ‰ΩøÊàë‰ª¨ËÄÉËôëÂú®Êé®ÁêÜÊó∂Â¢ûÂä†ËÆ°ÁÆóÈáè„ÄÇÁé∞ÊúâÁöÑÊé®ÁêÜÊó∂Èó¥Êâ©Â±ïÊñπÊ≥ïÈÄöÂ∏∏Â∞Ü‰ªªÂä°ËßÜ‰∏∫ÊêúÁ¥¢ÈóÆÈ¢òÔºåÂÆπÊòìÂèóÂà∞Â•ñÂä±Ê®°ÂûãÁöÑËøë‰ººËØØÂ∑ÆÂΩ±ÂìçËÄåÂØºËá¥Â•ñÂä±ÊìçÊéß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÊé®ÁêÜÊó∂Èó¥Êâ©Â±ïÊñπÊ≥ïÔºåÈÄöËøáÈÄÇÂ∫îÂü∫‰∫éÁ≤íÂ≠êÁöÑËíôÁâπÂç°Ê¥õÊñπÊ≥ïÔºåÂ∞ÜÊé®ÁêÜÊó∂Èó¥Êâ©Â±ïËßÜ‰∏∫Ê¶ÇÁéáÊé®ÁêÜ‰ªªÂä°Ôºå‰ªéËÄåÂú®ÂêÑÁßçÊï∞Â≠¶Êé®ÁêÜ‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊâ©Â±ïÁéá„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.01154', 'title': 'Jailbreaking with Universal Multi-Prompts', 'url': 'https://huggingface.co/papers/2502.01154', 'abstract': 'Large language models (LLMs) have seen rapid development in recent years, revolutionizing various applications and significantly enhancing convenience and productivity. However, alongside their impressive capabilities, ethical concerns and new types of attacks, such as jailbreaking, have emerged. While most prompting techniques focus on optimizing adversarial inputs for individual cases, resulting in higher computational costs when dealing with large datasets. Less research has addressed the more general setting of training a universal attacker that can transfer to unseen tasks. In this paper, we introduce JUMP, a prompt-based method designed to jailbreak LLMs using universal multi-prompts. We also adapt our approach for defense, which we term DUMP. Experimental results demonstrate that our method for optimizing universal multi-prompts outperforms existing techniques.', 'score': 4, 'issue_id': 2068, 'pub_date': '2025-02-03', 'pub_date_card': {'ru': '3 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 3', 'zh': '2Êúà3Êó•'}, 'hash': 'aa9860c81d83ac21', 'authors': ['Yu-Ling Hsu', 'Hsuan Su', 'Shang-Tse Chen'], 'affiliations': ['National Taiwan University'], 'pdf_title_img': 'assets/pdf/title_img/2502.01154.jpg', 'data': {'categories': ['#security', '#rl', '#data', '#optimization', '#transfer_learning', '#training', '#ethics'], 'emoji': 'üîì', 'ru': {'title': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤–∑–ª–æ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ JUMP', 'desc': '–°—Ç–∞—Ç—å—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º JUMP –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –≤–∑–ª–æ–º–∞ (jailbreak) –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –º—É–ª—å—Ç–∏-–ø—Ä–æ–º–ø—Ç–æ–≤. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞ –¥–ª—è –∑–∞—â–∏—Ç—ã, –Ω–∞–∑—ã–≤–∞–µ–º—É—é DUMP. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –º—É–ª—å—Ç–∏-–ø—Ä–æ–º–ø—Ç–æ–≤. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç –≤–∞–∂–Ω—É—é —Ç–µ–º—É —ç—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –∏ –Ω–æ–≤—ã—Ö —Ç–∏–ø–æ–≤ –∞—Ç–∞–∫ –Ω–∞ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏.'}, 'en': {'title': 'JUMP: Universal Multi-Prompts for Jailbreaking LLMs', 'desc': 'This paper presents JUMP, a novel method for jailbreaking large language models (LLMs) using universal multi-prompts. Unlike traditional prompting techniques that focus on specific adversarial inputs, JUMP aims to create a universal attacker that can adapt to various unseen tasks, reducing computational costs. Additionally, the authors propose a defense mechanism called DUMP, which leverages the same principles to protect against such attacks. Experimental results indicate that JUMP significantly outperforms existing methods in optimizing these universal multi-prompts.'}, 'zh': {'title': 'ÈÄöÁî®Â§öÊèêÁ§∫ÔºöÁ†¥Ëß£‰∏éÈò≤Âæ°ÁöÑÂàõÊñ∞ÊñπÊ≥ï', 'desc': 'Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËøëÂπ¥Êù•ËøÖÈÄüÂèëÂ±ïÔºåÊîπÂèò‰∫ÜËÆ∏Â§öÂ∫îÁî®ÔºåÊòæËëóÊèêÈ´ò‰∫Ü‰æøÂà©ÊÄßÂíåÁîü‰∫ßÂäõ„ÄÇÁÑ∂ËÄåÔºåÈöèÁùÄÂÖ∂Âº∫Â§ßËÉΩÂäõÁöÑÊèêÂçáÔºå‰º¶ÁêÜÈóÆÈ¢òÂíåÊñ∞ÂûãÊîªÂáªÔºàÂ¶ÇË∂äÁã±ÊîªÂáªÔºâ‰πüÈöè‰πãÂá∫Áé∞„ÄÇÂ§ßÂ§öÊï∞ÊèêÁ§∫ÊäÄÊúØ‰∏ìÊ≥®‰∫é‰ºòÂåñÂçï‰∏™Ê°à‰æãÁöÑÂØπÊäóËæìÂÖ•ÔºåËøôÂú®Â§ÑÁêÜÂ§ßÊï∞ÊçÆÈõÜÊó∂‰ºöÂØºËá¥Êõ¥È´òÁöÑËÆ°ÁÆóÊàêÊú¨„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÂêç‰∏∫JUMPÁöÑÊñπÊ≥ïÔºåÊó®Âú®‰ΩøÁî®ÈÄöÁî®Â§öÊèêÁ§∫ÂØπLLMsËøõË°åË∂äÁã±ÔºåÂêåÊó∂Êàë‰ª¨ËøòÊèêÂá∫‰∫ÜÈò≤Âæ°ÊñπÊ≥ïDUMPÔºåÂÆûÈ™åÁªìÊûúË°®ÊòéÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰ºòÂåñÈÄöÁî®Â§öÊèêÁ§∫ÊñπÈù¢‰ºò‰∫éÁé∞ÊúâÊäÄÊúØ„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.03275', 'title': 'Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning', 'url': 'https://huggingface.co/papers/2502.03275', 'abstract': 'Large Language Models (LLMs) excel at reasoning and planning when trained on chainof-thought (CoT) data, where the step-by-step thought process is explicitly outlined by text tokens. However, this results in lengthy inputs where many words support textual coherence rather than core reasoning information, and processing these inputs consumes substantial computation resources. In this work, we propose a hybrid representation of the reasoning process, where we partially abstract away the initial reasoning steps using latent discrete tokens generated by VQ-VAE, significantly reducing the length of reasoning traces. We explore the use of latent trace abstractions in two scenarios: 1) training the model from scratch for the Keys-Finding Maze problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary including unseen latent tokens, for both logical and mathematical reasoning problems. To facilitate effective learning, we introduce a simple training procedure that randomly mixes latent and text tokens, which enables fast adaptation to new latent tokens. Our approach consistently outperforms the baselines methods in various benchmarks.', 'score': 4, 'issue_id': 2066, 'pub_date': '2025-02-05', 'pub_date_card': {'ru': '5 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 5', 'zh': '2Êúà5Êó•'}, 'hash': 'f94d674e0f57dcf9', 'authors': ['DiJia Su', 'Hanlin Zhu', 'Yingchen Xu', 'Jiantao Jiao', 'Yuandong Tian', 'Qinqing Zheng'], 'affiliations': ['Meta AI', 'UC Berkeley', 'UCL'], 'pdf_title_img': 'assets/pdf/title_img/2502.03275.jpg', 'data': {'categories': ['#dataset', '#reasoning', '#optimization', '#training', '#benchmark', '#math'], 'emoji': 'üß†', 'ru': {'title': '–ì–∏–±—Ä–∏–¥–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—é', 'desc': '–î–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLM). –ê–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ VQ-VAE, –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–π –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —à–∞–≥–æ–≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ú–µ—Ç–æ–¥ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ —Å –Ω—É–ª—è, —Ç–∞–∫ –∏ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö LLM –Ω–∞ –≥–∏–±—Ä–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Å–ª–æ–≤–∞—Ä–µ–º. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.'}, 'en': {'title': 'Streamlining Reasoning with Hybrid Token Representations', 'desc': 'This paper presents a new method to improve reasoning in Large Language Models (LLMs) by using a hybrid representation of reasoning processes. Instead of relying solely on lengthy text inputs, the authors introduce latent discrete tokens generated by VQ-VAE to simplify the reasoning steps. This approach reduces the input length and computational resources needed while maintaining effective reasoning capabilities. The proposed method shows superior performance in training and fine-tuning scenarios for logical and mathematical reasoning tasks compared to traditional methods.'}, 'zh': {'title': '‰ºòÂåñÊé®ÁêÜËøáÁ®ãÔºåÊèêÂçáÊ®°ÂûãÊïàÁéá', 'desc': 'Êú¨ÊñáÊé¢ËÆ®‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Êé®ÁêÜÂíåËßÑÂàí‰∏≠ÁöÑÂ∫îÁî®ÔºåÁâπÂà´ÊòØÂú®ÈìæÂºèÊÄùÁª¥ÔºàCoTÔºâÊï∞ÊçÆËÆ≠ÁªÉÊó∂ÁöÑË°®Áé∞„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑ÂêàË°®Á§∫Ê≥ïÔºåÈÄöËøá‰ΩøÁî®VQ-VAEÁîüÊàêÁöÑÊΩúÂú®Á¶ªÊï£Ê†áËÆ∞ÔºåÈÉ®ÂàÜÊäΩË±°ÂåñÂàùÂßãÊé®ÁêÜÊ≠•È™§Ôºå‰ªéËÄåÊòæËëóÂáèÂ∞ëÊé®ÁêÜËøáÁ®ãÁöÑÈïøÂ∫¶„ÄÇÊàë‰ª¨Âú®‰∏§‰∏™Âú∫ÊôØ‰∏≠Êé¢Á¥¢‰∫ÜÊΩúÂú®ËøΩË∏™ÊäΩË±°ÁöÑ‰ΩøÁî®Ôºö‰∏ÄÊòØ‰ªéÂ§¥ÂºÄÂßãËÆ≠ÁªÉÊ®°ÂûãËß£ÂÜ≥Èí•ÂåôÂØªÊâæËø∑ÂÆ´ÈóÆÈ¢òÔºå‰∫åÊòØÂØπLLMsËøõË°åÂæÆË∞É‰ª•Â§ÑÁêÜÈÄªËæëÂíåÊï∞Â≠¶Êé®ÁêÜÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÁöÑËÆ≠ÁªÉÊñπÊ≥ïÈÄöËøáÈöèÊú∫Ê∑∑ÂêàÊΩúÂú®Ê†áËÆ∞ÂíåÊñáÊú¨Ê†áËÆ∞Ôºå‰øÉËøõ‰∫ÜÂØπÊñ∞ÊΩúÂú®Ê†áËÆ∞ÁöÑÂø´ÈÄüÈÄÇÂ∫îÔºå‰∏îÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ï„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.02421', 'title': 'Activation-Informed Merging of Large Language Models', 'url': 'https://huggingface.co/papers/2502.02421', 'abstract': 'Model merging, a method that combines the parameters and embeddings of multiple fine-tuned large language models (LLMs), offers a promising approach to enhance model performance across various tasks while maintaining computational efficiency. This paper introduces Activation-Informed Merging (AIM), a technique that integrates the information from the activation space of LLMs into the merging process to improve performance and robustness. AIM is designed as a flexible, complementary solution that is applicable to any existing merging method. It aims to preserve critical weights from the base model, drawing on principles from continual learning~(CL) and model compression. Utilizing a task-agnostic calibration set, AIM selectively prioritizes essential weights during merging. We empirically demonstrate that AIM significantly enhances the performance of merged models across multiple benchmarks. Our findings suggest that considering the activation-space information can provide substantial advancements in the model merging strategies for LLMs with up to 40\\% increase in benchmark performance.', 'score': 2, 'issue_id': 2079, 'pub_date': '2025-02-04', 'pub_date_card': {'ru': '4 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 4', 'zh': '2Êúà4Êó•'}, 'hash': '90e80efaaef789ec', 'authors': ['Amin Heyrani Nobari', 'Kaveh Alimohammadi', 'Ali ArjomandBigdeli', 'Akash Srivastava', 'Faez Ahmed', 'Navid Azizan'], 'affiliations': ['Massachusetts Institute of Technology', 'RedHat AI Innovation & MIT-IBM Watson AI Lab', 'Stony Brook University'], 'pdf_title_img': 'assets/pdf/title_img/2502.02421.jpg', 'data': {'categories': ['#benchmark', '#architecture', '#optimization', '#training'], 'emoji': 'üß†', 'ru': {'title': 'AIM: –£–º–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏', 'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Activation-Informed Merging (AIM). AIM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ú–µ—Ç–æ–¥ –ø—Ä–∏–º–µ–Ω–∏–º –∫ –ª—é–±–æ–º—É —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Å–ø–æ—Å–æ–±—É —Å–ª–∏—è–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ —Å–∂–∞—Ç–∏—è –º–æ–¥–µ–ª–µ–π. –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö, —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –¥–æ 40%.'}, 'en': {'title': 'Boosting Model Performance with Activation-Informed Merging', 'desc': 'This paper presents Activation-Informed Merging (AIM), a novel technique for merging large language models (LLMs) that leverages activation space information to improve model performance. AIM enhances the merging process by selectively prioritizing essential weights from the base models, which helps maintain robustness and efficiency. The method is flexible and can be integrated with existing merging techniques, making it widely applicable. Empirical results show that AIM can lead to significant performance improvements, achieving up to a 40% increase in benchmark scores for merged models.'}, 'zh': {'title': 'ÊøÄÊ¥ª‰ø°ÊÅØÂêàÂπ∂ÔºöÊèêÂçáÊ®°ÂûãÂêàÂπ∂ÊÄßËÉΩÁöÑÊñ∞ÊñπÊ≥ï', 'desc': 'Ê®°ÂûãÂêàÂπ∂ÊòØ‰∏ÄÁßçÂ∞ÜÂ§ö‰∏™ÂæÆË∞ÉÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÂèÇÊï∞ÂíåÂµåÂÖ•ÁªìÂêàËµ∑Êù•ÁöÑÊñπÊ≥ïÔºåËÉΩÂ§üÂú®‰øùÊåÅËÆ°ÁÆóÊïàÁéáÁöÑÂêåÊó∂ÊèêÂçáÊ®°ÂûãÂú®ÂêÑÁßç‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ÊøÄÊ¥ª‰ø°ÊÅØÂêàÂπ∂ÔºàAIMÔºâÁöÑÊäÄÊúØÔºåÂÆÉÂ∞ÜLLMsÁöÑÊøÄÊ¥ªÁ©∫Èó¥‰ø°ÊÅØÊï¥ÂêàÂà∞ÂêàÂπ∂ËøáÁ®ã‰∏≠Ôºå‰ª•ÊèêÈ´òÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß„ÄÇAIMÊó®Âú®‰Ωú‰∏∫‰∏ÄÁßçÁÅµÊ¥ªÁöÑË°•ÂÖÖËß£ÂÜ≥ÊñπÊ°àÔºåÈÄÇÁî®‰∫é‰ªª‰ΩïÁé∞ÊúâÁöÑÂêàÂπ∂ÊñπÊ≥ïÔºåÂπ∂ÈÄöËøáÊåÅÁª≠Â≠¶‰π†ÂíåÊ®°ÂûãÂéãÁº©ÁöÑÂéüÂàôÊù•‰øùÁïôÂü∫Á°ÄÊ®°Âûã‰∏≠ÁöÑÂÖ≥ÈîÆÊùÉÈáç„ÄÇÈÄöËøá‰ΩøÁî®‰∏é‰ªªÂä°Êó†ÂÖ≥ÁöÑÊ†°ÂáÜÈõÜÔºåAIMÂú®ÂêàÂπ∂ËøáÁ®ã‰∏≠‰ºòÂÖàËÄÉËôëÈáçË¶ÅÊùÉÈáçÔºåÂÆûÈ™åËØÅÊòéAIMÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÊòæËëóÊèêÂçá‰∫ÜÂêàÂπ∂Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.00306', 'title': 'Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation', 'url': 'https://huggingface.co/papers/2502.00306', 'abstract': "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.", 'score': 2, 'issue_id': 2076, 'pub_date': '2025-02-01', 'pub_date_card': {'ru': '1 —Ñ–µ–≤—Ä–∞–ª—è', 'en': 'February 1', 'zh': '2Êúà1Êó•'}, 'hash': '4987f380f5ddb7af', 'authors': ['Ali Naseh', 'Yuefeng Peng', 'Anshuman Suri', 'Harsh Chaudhari', 'Alina Oprea', 'Amir Houmansadr'], 'affiliations': ['Northeastern University', 'University of Massachusetts Amherst'], 'pdf_title_img': 'assets/pdf/title_img/2502.00306.jpg', 'data': {'categories': ['#inference', '#rag', '#leakage', '#security'], 'emoji': 'üïµÔ∏è', 'ru': {'title': '–ù–µ–∑–∞–º–µ—Ç–Ω–∞—è –∞—Ç–∞–∫–∞ –Ω–∞ RAG-—Å–∏—Å—Ç–µ–º—ã: –∫–∞–∫ –≤—ã—è–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π', 'desc': "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –∞—Ç–∞–∫–∏ –Ω–∞ —Å–∏—Å—Ç–µ–º—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (RAG). –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ç–µ—Ö–Ω–∏–∫—É –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º 'Interrogation Attack', –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π RAG-—Å–∏—Å—Ç–µ–º—ã. –ú–µ—Ç–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ü–µ–ª–µ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –∞—Ç–∞–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –∏ —Ç—Ä—É–¥–Ω–æ –æ–±–Ω–∞—Ä—É–∂–∏–º–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞–º–∏."}, 'en': {'title': 'Stealthy Inference: Unveiling Membership in RAG Systems', 'desc': 'This paper introduces a new method called Interrogation Attack (IA) for membership inference in Retrieval-Augmented Generation (RAG) systems. RAG allows Large Language Models (LLMs) to generate responses using external knowledge without changing their internal parameters, but this can be exploited by adversaries. The IA technique uses natural-text queries that can only be answered if a specific document is present, making it harder to detect than previous methods. The authors demonstrate that their approach is more effective and stealthy, achieving better performance with fewer queries and lower costs compared to existing techniques.'}, 'zh': {'title': 'ÈöêËîΩÁöÑ‰ºöÂëòÊé®Êñ≠ÊîªÂáªÔºöRAGÁ≥ªÁªüÁöÑÊñ∞ÊåëÊàò', 'desc': 'Êú¨ËÆ∫Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑ‰ºöÂëòÊé®Êñ≠ÊäÄÊúØÔºåÁß∞‰∏∫ÂÆ°ÈóÆÊîªÂáªÔºàInterrogation Attack, IAÔºâÔºåÊó®Âú®ÈíàÂØπRAGÊï∞ÊçÆÂ≠òÂÇ®‰∏≠ÁöÑÊñáÊ°£ËøõË°åÊîªÂáª„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÊûÑÈÄ†Ëá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢Ôºå‰ªÖÂú®ÁõÆÊ†áÊñáÊ°£Â≠òÂú®Êó∂ÊâçËÉΩÂæóÂà∞Á≠îÊ°àÔºå‰ªéËÄåÂÆûÁé∞ÊúâÊïàÁöÑÊé®Êñ≠„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑÊîªÂáªÂú®‰ªÖ‰ΩøÁî®30‰∏™Êü•ËØ¢ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊàêÂäüÁéáÊèêÈ´ò‰∫Ü2ÂÄçÔºåÂêåÊó∂‰øùÊåÅÈöêËîΩÊÄß„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåIAÂú®Â§öÁßçRAGÈÖçÁΩÆ‰∏ãÁöÑË°®Áé∞‰ºò‰∫é‰ª•ÂæÄÁöÑÊé®Êñ≠ÊîªÂáªÔºå‰∏îÊØè‰∏™ÊñáÊ°£ÁöÑÊé®Êñ≠ÊàêÊú¨‰Ωé‰∫é0.02ÁæéÂÖÉ„ÄÇ'}}}, {'id': 'https://huggingface.co/papers/2502.00226', 'title': 'HackerRank-ASTRA: Evaluating Correctness & Consistency of Large Language Models on cross-domain multi-file project problems', 'url': 'https://huggingface.co/papers/2502.00226', 'abstract': 'Evaluating the real-world applicability of large language models (LLMs) provides valuable insights for their development and use in software development tasks. Existing benchmarks often focus on standalone coding problems or specific libraries, overlooking multi-file, project-based scenarios and lacking a rigorous evaluation of consistency. The HackerRank-ASTRA Benchmark introduces project-based coding problems that mirror real-world scenarios. It evaluates model consistency through 32 runs (k = 32) and median standard deviation while incorporating taxonomy-level analysis to assess sub-skill capabilities. Initial evaluations on 65 problems show that the top three models -- o1, o1-preview, and Claude-3.5-Sonnet-1022 -- achieved comparable average scores of 75%, with no statistically significant differences in performance. Notably, Claude-3.5-Sonnet-1022 demonstrated the highest consistency across problems, with low variability (SD = 0.0497), which was statistically significant compared to other models, highlighting its reliability for real-world software development tasks.', 'score': 0, 'issue_id': 2079, 'pub_date': '2025-01-31', 'pub_date_card': {'ru': '31 —è–Ω–≤–∞—Ä—è', 'en': 'January 31', 'zh': '1Êúà31Êó•'}, 'hash': 'c9615b5d00a42037', 'authors': ['Jun Xing', 'Mayur Bhatia', 'Sahil Phulwani', 'Darshan Suresh', 'Rafik Matta'], 'affiliations': [], 'pdf_title_img': 'assets/pdf/title_img/2502.00226.jpg', 'data': {'categories': ['#benchmark', '#science', '#training'], 'emoji': 'üß†', 'ru': {'title': '–ù–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª LLM –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ü–û', 'desc': '–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. HackerRank-ASTRA Benchmark –≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, –∏–º–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏, –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ 32 –∑–∞–ø—É—Å–∫–∞. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ, —á—Ç–æ —Ç—Ä–∏ –≤–µ–¥—É—â–∏–µ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ —Å—Ä–∞–≤–Ω–∏–º—ã—Ö —Å—Ä–µ–¥–Ω–∏—Ö –æ—Ü–µ–Ω–æ–∫ –≤ 75%. –ú–æ–¥–µ–ª—å Claude-3.5-Sonnet-1022 –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–∞ –Ω–∞–∏–≤—ã—Å—à—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏ –Ω–∏–∑–∫—É—é –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.'}, 'en': {'title': 'Benchmarking LLMs for Real-World Coding Consistency', 'desc': 'This paper evaluates the effectiveness of large language models (LLMs) in real-world software development tasks using the HackerRank-ASTRA Benchmark. Unlike previous benchmarks that focus on isolated coding problems, this benchmark introduces project-based scenarios that require multi-file handling and assesses model consistency through extensive testing. The study analyzes the performance of top models, revealing that while they achieved similar average scores, one model, Claude-3.5-Sonnet-1022, stood out for its high consistency and low variability in results. This research emphasizes the importance of rigorous evaluation methods to ensure LLMs are reliable for practical applications in coding.'}, 'zh': {'title': 'ËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ËΩØ‰ª∂ÂºÄÂèë‰∏≠ÁöÑÁúüÂÆûÂ∫îÁî®ÊÄß', 'desc': 'ËøôÁØáËÆ∫ÊñáËØÑ‰º∞‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®ÂÆûÈôÖËΩØ‰ª∂ÂºÄÂèë‰ªªÂä°‰∏≠ÁöÑÈÄÇÁî®ÊÄß„ÄÇÁé∞ÊúâÁöÑÂü∫ÂáÜÊµãËØïÈÄöÂ∏∏Âè™ÂÖ≥Ê≥®Âçï‰∏ÄÁöÑÁºñÁ†ÅÈóÆÈ¢òÊàñÁâπÂÆöÂ∫ìÔºåÂøΩËßÜ‰∫ÜÂ§öÊñá‰ª∂„ÄÅÂü∫‰∫éÈ°πÁõÆÁöÑÂú∫ÊôØÔºåÂπ∂Áº∫‰πèÂØπ‰∏ÄËá¥ÊÄßÁöÑ‰∏•Ê†ºËØÑ‰º∞„ÄÇHackerRank-ASTRAÂü∫ÂáÜÂºïÂÖ•‰∫ÜÊ®°ÊãüÁúüÂÆûÂú∫ÊôØÁöÑÈ°πÁõÆÂü∫Á°ÄÁºñÁ†ÅÈóÆÈ¢òÔºåÂπ∂ÈÄöËøá32Ê¨°ËøêË°åËØÑ‰º∞Ê®°ÂûãÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂàùÊ≠•ËØÑ‰º∞ÊòæÁ§∫ÔºåClaude-3.5-Sonnet-1022Âú®ÈóÆÈ¢ò‰∏ÄËá¥ÊÄßÊñπÈù¢Ë°®Áé∞ÊúÄ‰Ω≥ÔºåÂÖ∑ÊúâËæÉ‰ΩéÁöÑÂèòÂºÇÊÄßÔºåÁ™ÅÊòæ‰∫ÜÂÖ∂Âú®ÂÆûÈôÖËΩØ‰ª∂ÂºÄÂèë‰ªªÂä°‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents (2)', '#agi', '#alignment (1)', '#architecture (2)', '#audio', '#benchmark (4)', '#cv (1)', '#data (2)', '#dataset (4)', '#diffusion (1)', '#ethics (1)', '#games', '#graphs', '#hallucinations', '#healthcare', '#inference (2)', '#interpretability', '#leakage (1)', '#long_context (1)', '#low_resource (1)', '#machine_translation', '#math (3)', '#multilingual', '#multimodal (3)', '#open_source (2)', '#optimization (8)', '#plp (1)', '#rag (1)', '#reasoning (5)', '#rl (2)', '#rlhf (1)', '#robotics', '#science (1)', '#security (2)', '#small_models (1)', '#story_generation', '#survey', '#synthetic', '#training (10)', '#transfer_learning (1)', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `üè∑Ô∏è ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `üè∑Ô∏è ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            üî∫ ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'üîÑ ' + getTimeDiff('2025-02-07 03:14',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "—Ä–µ–π—Ç–∏–Ω–≥—É",
                    pub_date: "–¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏",
                    issue_id: "–¥–æ–±–∞–≤–ª–µ–Ω–∏—é –Ω–∞ HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "ËØÑÂàÜ",
                    pub_date: "ÂèëÂ∏ÉÊó•Êúü",
                    issue_id: "HF‰∏ä‰º†Êó•Êúü"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-02-07 03:14')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-02-07 03:14')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    