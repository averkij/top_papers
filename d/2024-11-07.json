{
    "date": {
        "ru": "7 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
        "en": "November 7",
        "zh": "11æœˆ7æ—¥"
    },
    "time_utc": "2024-11-07 16:15",
    "weekday": 3,
    "issue_id": 459,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.03823",
            "title": "Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination",
            "url": "https://huggingface.co/papers/2411.03823",
            "abstract": "The rapid progression of multimodal large language models (MLLMs) has demonstrated superior performance on various multimodal benchmarks. However, the issue of data contamination during training creates challenges in performance evaluation and comparison. While numerous methods exist for detecting dataset contamination in large language models (LLMs), they are less effective for MLLMs due to their various modalities and multiple training phases. In this study, we introduce a multimodal data contamination detection framework, MM-Detect, designed for MLLMs. Our experimental results indicate that MM-Detect is sensitive to varying degrees of contamination and can highlight significant performance improvements due to leakage of the training set of multimodal benchmarks. Furthermore, We also explore the possibility of contamination originating from the pre-training phase of LLMs used by MLLMs and the fine-tuning phase of MLLMs, offering new insights into the stages at which contamination may be introduced.",
            "score": 29,
            "issue_id": 457,
            "pub_date": "2024-11-06",
            "pub_date_card": {
                "ru": "6 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
                "en": "November 6",
                "zh": "11æœˆ6æ—¥"
            },
            "hash": "3f0a02ee67213e17",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "ğŸ•µï¸",
                "ru": {
                    "title": "Ğ§Ğ¸ÑÑ‚Ğ¾Ñ‚Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… - Ğ·Ğ°Ğ»Ğ¾Ğ³ Ğ½Ğ°Ğ´Ñ‘Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ˜Ğ˜-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğµ Ğ·Ğ°Ğ³Ñ€ÑĞ·Ğ½ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (MLLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº MM-Detect Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ³Ñ€ÑĞ·Ğ½ĞµĞ½Ğ¸Ñ Ğ² MLLM. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ MM-Detect Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ĞµĞ½ Ğº Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼ ÑÑ‚ĞµĞ¿ĞµĞ½ÑĞ¼ Ğ·Ğ°Ğ³Ñ€ÑĞ·Ğ½ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ²Ñ‹ÑĞ²Ğ»ÑÑ‚ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ·-Ğ·Ğ° ÑƒÑ‚ĞµÑ‡ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºĞ¶Ğµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ·Ğ°Ğ³Ñ€ÑĞ·Ğ½ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Detecting Contamination in Multimodal Language Models",
                    "desc": "This paper addresses the challenge of data contamination in multimodal large language models (MLLMs), which can affect their performance evaluation. The authors propose a new framework called MM-Detect, specifically designed to identify contamination in MLLMs across different modalities and training phases. Their experiments show that MM-Detect can effectively detect varying levels of contamination and reveal how training set leakage impacts performance. Additionally, the study investigates contamination sources during both the pre-training and fine-tuning phases of MLLMs, providing valuable insights into potential contamination points."
                },
                "zh": {
                    "title": "å¤šæ¨¡æ€æ•°æ®æ±¡æŸ“æ£€æµ‹çš„æ–°çªç ´",
                    "desc": "æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æ•°æ®æ±¡æŸ“æ£€æµ‹çš„æ–°æ¡†æ¶MM-Detectã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„æ•°æ®æ±¡æŸ“é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMM-Detectå¯¹ä¸åŒç¨‹åº¦çš„æ•°æ®æ±¡æŸ“éå¸¸æ•æ„Ÿï¼Œå¹¶èƒ½æ˜¾è‘—æå‡æ€§èƒ½è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†æ•°æ®æ±¡æŸ“å¯èƒ½æºè‡ªLLMsçš„é¢„è®­ç»ƒé˜¶æ®µå’ŒMLLMsçš„å¾®è°ƒé˜¶æ®µï¼Œä¸ºç†è§£æ±¡æŸ“å¼•å…¥çš„æ—¶æœºæä¾›äº†æ–°çš„è§†è§’ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.03562",
            "title": "Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level",
            "url": "https://huggingface.co/papers/2411.03562",
            "abstract": "We introduce Agent K v1.0, an end-to-end autonomous data science agent designed to automate, optimise, and generalise across diverse data science tasks. Fully automated, Agent K v1.0 manages the entire data science life cycle by learning from experience. It leverages a highly flexible structured reasoning framework to enable it to dynamically process memory in a nested structure, effectively learning from accumulated experience stored to handle complex reasoning tasks. It optimises long- and short-term memory by selectively storing and retrieving key information, guiding future decisions based on environmental rewards. This iterative approach allows it to refine decisions without fine-tuning or backpropagation, achieving continuous improvement through experiential learning. We evaluate our agent's apabilities using Kaggle competitions as a case study. Following a fully automated protocol, Agent K v1.0 systematically addresses complex and multimodal data science tasks, employing Bayesian optimisation for hyperparameter tuning and feature engineering. Our new evaluation framework rigorously assesses Agent K v1.0's end-to-end capabilities to generate and send submissions starting from a Kaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\\% success rate across tasks, spanning tabular, computer vision, NLP, and multimodal domains. When benchmarking against 5,856 human Kaggle competitors by calculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\\%, demonstrating an overall skill level comparable to Expert-level users. Notably, its Elo-MMR score falls between the first and third quartiles of scores achieved by human Grandmasters. Furthermore, our results indicate that Agent K v1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a record of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's progression system.",
            "score": 23,
            "issue_id": 457,
            "pub_date": "2024-11-05",
            "pub_date_card": {
                "ru": "5 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
                "en": "November 5",
                "zh": "11æœˆ5æ—¥"
            },
            "hash": "1db584382b826315",
            "data": {
                "categories": [
                    "#agents",
                    "#benchmark",
                    "#cv",
                    "#multimodal",
                    "#training"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Agent K v1.0: ĞĞ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ½Ğ°ÑƒĞºĞ¸ Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Agent K v1.0 - Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ½Ğ°ÑƒĞºĞ¸ Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¾Ğ¿Ñ‹Ñ‚Ğ°. Agent K v1.0 Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½ÑƒÑ Ğ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ÑÑ€Ğ¾Ñ‡Ğ½ÑƒÑ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ĞµĞ¼Ñƒ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸. ĞÑ†ĞµĞ½ĞºĞ° Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ğ»Ğ°ÑÑŒ Ğ½Ğ° ÑĞ¾Ñ€ĞµĞ²Ğ½Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ… Kaggle, Ğ³Ğ´Ğµ Ğ¾Ğ½ Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ» 92.5% ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡."
                },
                "en": {
                    "title": "Agent K v1.0: Your Autonomous Data Science Expert!",
                    "desc": "Agent K v1.0 is an autonomous data science agent that automates the entire data science life cycle, learning from its experiences to improve over time. It uses a structured reasoning framework to manage memory and handle complex tasks without the need for traditional fine-tuning methods. By employing Bayesian optimization for hyperparameter tuning and feature engineering, it effectively addresses a variety of data science challenges. The agent's performance has been validated through Kaggle competitions, where it achieved a high success rate and ranked competitively against human experts, demonstrating its advanced capabilities in multiple domains."
                },
                "zh": {
                    "title": "Agent K v1.0ï¼šè‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦çš„æœªæ¥",
                    "desc": "æˆ‘ä»¬ä»‹ç»äº†Agent K v1.0ï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„è‡ªä¸»æ•°æ®ç§‘å­¦ä»£ç†ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–ã€ä¼˜åŒ–å’Œæ³›åŒ–å„ç§æ•°æ®ç§‘å­¦ä»»åŠ¡ã€‚Agent K v1.0 å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œèƒ½å¤Ÿç®¡ç†æ•´ä¸ªæ•°æ®ç§‘å­¦ç”Ÿå‘½å‘¨æœŸï¼Œå¹¶é€šè¿‡ç»éªŒå­¦ä¹ æ¥æå‡èƒ½åŠ›ã€‚å®ƒåˆ©ç”¨çµæ´»çš„ç»“æ„åŒ–æ¨ç†æ¡†æ¶ï¼ŒåŠ¨æ€å¤„ç†åµŒå¥—ç»“æ„ä¸­çš„è®°å¿†ï¼Œæœ‰æ•ˆåœ°ä»ç§¯ç´¯çš„ç»éªŒä¸­å­¦ä¹ ï¼Œä»¥åº”å¯¹å¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚é€šè¿‡é€‰æ‹©æ€§å­˜å‚¨å’Œæ£€ç´¢å…³é”®ä¿¡æ¯ï¼ŒAgent K v1.0 ä¼˜åŒ–äº†çŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼ŒåŸºäºç¯å¢ƒå¥–åŠ±æŒ‡å¯¼æœªæ¥å†³ç­–ï¼Œå±•ç°å‡ºä¸äººç±»ä¸“å®¶ç›¸å½“çš„æŠ€èƒ½æ°´å¹³ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.03884",
            "title": "Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models",
            "url": "https://huggingface.co/papers/2411.03884",
            "abstract": "Transformers have found extensive applications across various domains due to the powerful fitting capabilities. This success can be partially attributed to their inherent nonlinearity. Thus, in addition to the ReLU function employed in the original transformer architecture, researchers have explored alternative modules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment representational capacity. In this paper, we propose a novel category of polynomial composition activations (PolyCom), designed to optimize the dynamics of transformers. Theoretically, we provide a comprehensive mathematical analysis of PolyCom, highlighting its enhanced expressivity and efficacy relative to other activation functions. Notably, we demonstrate that networks incorporating PolyCom achieve the optimal approximation rate, indicating that PolyCom networks require minimal parameters to approximate general smooth functions in Sobolev spaces. We conduct empirical experiments on the pre-training configurations of large language models (LLMs), including both dense and sparse architectures. By substituting conventional activation functions with PolyCom, we enable LLMs to capture higher-order interactions within the data, thus improving performance metrics in terms of accuracy and convergence rates. Extensive experimental results demonstrate the effectiveness of our method, showing substantial improvements over other activation functions. Code is available at https://github.com/BryceZhuo/PolyCom.",
            "score": 5,
            "issue_id": 459,
            "pub_date": "2024-11-06",
            "pub_date_card": {
                "ru": "6 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
                "en": "November 6",
                "zh": "11æœˆ6æ—¥"
            },
            "hash": "6ed1524392784244",
            "data": {
                "categories": [
                    "#math",
                    "#architecture",
                    "#training"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "PolyCom: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑÑ… Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ², Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ÑƒÑ PolyCom (Ğ¿Ğ¾Ğ»Ğ¸Ğ½Ğ¾Ğ¼Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ½Ñ‹Ğµ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ PolyCom Ğ¾Ğ±Ğ»Ğ°Ğ´Ğ°ĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ñ€Ğ°Ğ·Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ PolyCom Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM) Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸Ğ¼ Ğ»ÑƒÑ‡ÑˆĞµ ÑƒĞ»Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞ° Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ² Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼Ğ¸."
                },
                "en": {
                    "title": "Unlocking Transformer Potential with Polynomial Activations",
                    "desc": "This paper introduces a new type of activation function called Polynomial Composition Activations (PolyCom) for transformer models. The authors argue that PolyCom enhances the nonlinearity of transformers, which is crucial for improving their representational capacity. Through mathematical analysis, they show that networks using PolyCom can approximate complex functions more efficiently than those using traditional activation functions. Empirical tests on large language models reveal that PolyCom leads to better performance in terms of accuracy and convergence, demonstrating its potential as a superior alternative in machine learning applications."
                },
                "zh": {
                    "title": "å¤šé¡¹å¼ç»„åˆæ¿€æ´»å‡½æ•°ï¼šæå‡å˜æ¢å™¨æ€§èƒ½çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šé¡¹å¼ç»„åˆæ¿€æ´»å‡½æ•°ï¼ˆPolyComï¼‰ï¼Œæ—¨åœ¨ä¼˜åŒ–å˜æ¢å™¨çš„åŠ¨æ€æ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡æ•°å­¦åˆ†æè¯æ˜äº†PolyComåœ¨è¡¨è¾¾èƒ½åŠ›å’Œæ•ˆç‡æ–¹é¢ä¼˜äºå…¶ä»–æ¿€æ´»å‡½æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨PolyComçš„ç½‘ç»œåœ¨é€¼è¿‘å…‰æ»‘å‡½æ•°æ—¶æ‰€éœ€çš„å‚æ•°æ›´å°‘ï¼Œä¸”åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒé…ç½®ä¸­è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼ŒPolyComèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ•°æ®ä¸­çš„é«˜é˜¶äº¤äº’ï¼Œä»è€Œæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.04109",
            "title": "Self-Consistency Preference Optimization",
            "url": "https://huggingface.co/papers/2411.04109",
            "abstract": "Self-alignment, whereby models learn to improve themselves without human annotation, is a rapidly growing research area. However, existing techniques often fail to improve complex reasoning tasks due to the difficulty of assigning correct rewards. An orthogonal approach that is known to improve correctness is self-consistency, a method applied at inference time based on multiple sampling in order to find the most consistent answer. In this work, we extend the self-consistency concept to help train models. We thus introduce self-consistency preference optimization (ScPO), which iteratively trains consistent answers to be preferred over inconsistent ones on unsupervised new problems. We show ScPO leads to large improvements over conventional reward model training on reasoning tasks such as GSM8K and MATH, closing the gap with supervised training with gold answers or preferences, and that combining ScPO with standard supervised learning improves results even further. On ZebraLogic, ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and Claude-3 Haiku.",
            "score": 1,
            "issue_id": 459,
            "pub_date": "2024-11-06",
            "pub_date_card": {
                "ru": "6 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
                "en": "November 6",
                "zh": "11æœˆ6æ—¥"
            },
            "hash": "213f2796c0bc72ae",
            "data": {
                "categories": [
                    "#rlhf",
                    "#reasoning",
                    "#training",
                    "#math"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ¡Ğ°Ğ¼Ğ¾ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğº ĞºĞ»ÑÑ‡ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ˜Ğ˜ Ğ±ĞµĞ· ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ (ScPO) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑĞµÑ‚ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ÑƒÑ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°, Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ScPO Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ°Ğ´ Ğ½ĞµÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ±ĞµĞ· ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»Ñ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº GSM8K Ğ¸ MATH, ÑĞ¾ĞºÑ€Ğ°Ñ‰Ğ°Ñ Ñ€Ğ°Ğ·Ñ€Ñ‹Ğ² Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼."
                },
                "en": {
                    "title": "Empowering Models with Self-Consistency for Better Reasoning",
                    "desc": "This paper introduces a new method called self-consistency preference optimization (ScPO) to enhance the training of machine learning models without human annotations. ScPO focuses on improving the consistency of answers by iteratively training the model to prefer consistent responses over inconsistent ones. The authors demonstrate that ScPO significantly outperforms traditional reward model training on complex reasoning tasks, such as GSM8K and MATH, and even approaches the performance of supervised training. Additionally, when combined with standard supervised learning, ScPO further boosts the model's performance, achieving superior results on various benchmarks."
                },
                "zh": {
                    "title": "è‡ªæˆ‘ä¸€è‡´æ€§ä¼˜åŒ–ï¼Œæå‡æ¨¡å‹æ¨ç†èƒ½åŠ›ï¼",
                    "desc": "è‡ªæˆ‘å¯¹é½æ˜¯æŒ‡æ¨¡å‹åœ¨æ²¡æœ‰äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹è‡ªæˆ‘æ”¹è¿›çš„è¿‡ç¨‹ï¼Œè¿‘å¹´æ¥è¿™ä¸€ç ”ç©¶é¢†åŸŸè¿…é€Ÿå‘å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æŠ€æœ¯åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å¸¸å¸¸æ— æ³•æœ‰æ•ˆæå‡æ€§èƒ½ï¼Œå› ä¸ºå¾ˆéš¾åˆ†é…æ­£ç¡®çš„å¥–åŠ±ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”è‡ªæˆ‘ä¸€è‡´æ€§åå¥½ä¼˜åŒ–ï¼ˆScPOï¼‰ï¼Œå®ƒé€šè¿‡è¿­ä»£è®­ç»ƒä¸€è‡´çš„ç­”æ¡ˆï¼Œä½¿å…¶ä¼˜äºä¸ä¸€è‡´çš„ç­”æ¡ˆï¼Œä»è€Œè§£å†³æ— ç›‘ç£æ–°é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒScPOåœ¨æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼Œä¸”ä¸æ ‡å‡†ç›‘ç£å­¦ä¹ ç»“åˆåæ•ˆæœæ›´ä½³ã€‚"
                }
            }
        }
    ],
    "link_prev": "2024-11-06.html",
    "link_next": "2024-11-08.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "06.11",
        "en": "11/06",
        "zh": "11æœˆ6æ—¥"
    },
    "short_date_next": {
        "ru": "08.11",
        "en": "11/08",
        "zh": "11æœˆ8æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 1,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 2,
        "#multilingual": 0,
        "#architecture": 1,
        "#medicine": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#translation": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚",
        "title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ”¹è¿›çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œç§°ä¸ºHtmlRAGã€‚ä¼ ç»Ÿçš„RAGç³»ç»Ÿä»ç½‘é¡µæ£€ç´¢ä¿¡æ¯ï¼Œæå–çº¯æ–‡æœ¬å–‚ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œè¿™ä¼šä¸¢å¤±HTMLä¸­çš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚HtmlRAGç›´æ¥ä½¿ç”¨HTMLæ ¼å¼çš„çŸ¥è¯†ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯ã€‚ä½†HTMLåŒ…å«é¢å¤–çš„æ ‡ç­¾å’Œå™ªå£°ï¼Œä½œè€…æå‡ºäº†æ¸…ç†å’Œå‹ç¼©ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHtmlRAGåœ¨å…­ä¸ªé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ã€‚\n\nzhÃ¨ piÄn wÃ©n zhÄng jiÃ¨ shÃ o le yÄ« zhÇ’ng gÇi jÃ¬n de jiÇn suÇ’ zÄ“ng qiÃ¡ng shÄ“ng chÃ©ng (RAG) fÄng fÇ, chÄ“ng wÃ©i HtmlRAG. chuÃ¡ntÇ’ng de RAG xÃ¬ tÇ’ng cÃ³ng wÇng yÃ¨ jiÇn suÇ’ xÃ¬n xÄ«, tÄ« qÇ” chÃºn wÃ©n bÄ›n wÃ¨i gÄ›i dÃ  yÇ” yÃ¡n mÃ³ xÃ¬ng (LLMs). rÃ¡n Ã©r, zhÃ¨ huÃ¬ diÅ« shÄ« HTML zhÅng de jiÃ¨ gÃ²u hÃ© yÇ” yÃ¬ xÃ¬n xÄ«. HtmlRAG zhÃ­ jiÄ“ shÇ yÃ²ng HTML gÄ“ shÃ¬ de zhÄ« shÃ¬, bÇo liÃº gÃ¨ng duÅ xÃ¬n xÄ«. dÃ n HTML bÄo hÃ¡n Ã© xiÇo de biÇo qiÄn hÃ© zÃ o shÄ“ng, zuÃ² zhÄ› tÃ­ chÅ« le qÄ«ng lÇ hÃ© yÄ suÅ cÃ¨ lÃ¼Ã¨ lÃ¡i jiÄ› juÃ© zhÃ¨ gÃ¨ wÃ¨n tÃ­. shÃ­ yÃ n zhÃ¨ng mÃ­ng, HtmlRAG zÃ i liÃ¹ gÃ¨ wÃ¨n dÃ¡ shÃ¹ jÃ¹ zhÅng biÇo xiÃ n gÃ¨ng hÇo.",
        "vocab": "[\n    {\"word\": \"æ”¹è¿›\", \"pinyin\": \"gÇi jÃ¬n\", \"trans\": \"improvement\"},\n    {\"word\": \"æ£€ç´¢\", \"pinyin\": \"jiÇn suÇ’\", \"trans\": \"retrieval\"},\n    {\"word\": \"å¢å¼º\", \"pinyin\": \"zÄ“ng qiÃ¡ng\", \"trans\": \"enhancement\"},\n    {\"word\": \"ç”Ÿæˆ\", \"pinyin\": \"shÄ“ng chÃ©ng\", \"trans\": \"generation\"},\n    {\"word\": \"æ–¹æ³•\", \"pinyin\": \"fÄng fÇ\", \"trans\": \"method\"},\n    {\"word\": \"ç§°ä¸º\", \"pinyin\": \"chÄ“ng wÃ©i\", \"trans\": \"called\"},\n    {\"word\": \"ä¼ ç»Ÿ\", \"pinyin\": \"chuÃ¡n tÇ’ng\", \"trans\": \"traditional\"},\n    {\"word\": \"ç³»ç»Ÿ\", \"pinyin\": \"xÃ¬ tÇ’ng\", \"trans\": \"system\"},\n    {\"word\": \"ç½‘é¡µ\", \"pinyin\": \"wÇng yÃ¨\", \"trans\": \"webpage\"},\n    {\"word\": \"æå–\", \"pinyin\": \"tÃ­ qu\", \"trans\": \"extract\"},\n    {\"word\": \"çº¯æ–‡æœ¬\", \"pinyin\": \"chÃºn wÃ©n bÄ›n\", \"trans\": \"pure text\"},\n    {\"word\": \"å–‚ç»™\", \"pinyin\": \"wÃ¨i gÄ›i\", \"trans\": \"feed\"},\n    {\"word\": \"å¤§è¯­è¨€æ¨¡å‹\", \"pinyin\": \"dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng\", \"trans\": \"large language model\"},\n    {\"word\": \"ä¸¢å¤±\", \"pinyin\": \"diÅ« shÄ«\", \"trans\": \"lose\"},\n    {\"word\": \"ç»“æ„\", \"pinyin\": \"jiÃ© gÃ²u\", \"trans\": \"structure\"},\n    {\"word\": \"è¯­ä¹‰\", \"pinyin\": \"yÇ” yÃ¬\", \"trans\": \"semantics\"},\n    {\"word\": \"ä¿¡æ¯\", \"pinyin\": \"xÃ¬n xÄ«\", \"trans\": \"information\"},\n    {\"word\": \"ç›´æ¥\", \"pinyin\": \"zhÃ­ jiÄ“\", \"trans\": \"directly\"},\n    {\"word\": \"æ ¼å¼\", \"pinyin\": \"gÃ© shÃ¬\", \"trans\": \"format\"},\n    {\"word\": \"çŸ¥è¯†\", \"pinyin\": \"zhÄ« shÃ¬\", \"trans\": \"knowledge\"},\n    {\"word\": \"ä¿ç•™\", \"pinyin\": \"bÇo liÃº\", \"trans\": \"retain\"},\n    {\"word\": \"é¢å¤–\", \"pinyin\": \"Ã© wÃ i\", \"trans\": \"extra\"},\n    {\"word\": \"æ ‡ç­¾\", \"pinyin\": \"biÄo qiÄn\", \"trans\": \"tag\"},\n    {\"word\": \"å™ªå£°\", \"pinyin\": \"zÃ o shÄ“ng\", \"trans\": \"noise\"},\n    {\"word\": \"æå‡º\", \"pinyin\": \"tÃ­ chÅ«\", \"trans\": \"propose\"},\n    {\"word\": \"æ¸…ç†\", \"pinyin\": \"qÄ«ng lÇ\", \"trans\": \"clean\"},\n    {\"word\": \"å‹ç¼©\", \"pinyin\": \"yÄ suÅ\", \"trans\": \"compress\"},\n    {\"word\": \"ç­–ç•¥\", \"pinyin\": \"cÃ¨ lÃ¼Ã¨\", \"trans\": \"strategy\"},\n    {\"word\": \"è§£å†³\", \"pinyin\": \"jiÄ› juÃ©\", \"trans\": \"solve\"},\n    {\"word\": \"é—®é¢˜\", \"pinyin\": \"wÃ¨n tÃ­\", \"trans\": \"problem\"},\n    {\"word\": \"å®éªŒ\", \"pinyin\": \"shÃ­ yÃ n\", \"trans\": \"experiment\"},\n    {\"word\": \"è¯æ˜\", \"pinyin\": \"zhÃ¨ng mÃ­ng\", \"trans\": \"prove\"},\n    {\"word\": \"è¡¨ç°\", \"pinyin\": \"biÇo xiÃ n\", \"trans\": \"performance\"},\n    {\"word\": \"æ•°æ®é›†\", \"pinyin\": \"shÃ¹ jÃ¹ jÃ­\", \"trans\": \"dataset\"}\n]",
        "trans": "This article introduces an improved Retrieval-Augmented Generation (RAG) method called HtmlRAG. Traditional RAG systems retrieve information from web pages and extract plain text to feed into large language models (LLMs). However, this approach loses the structural and semantic information present in HTML. HtmlRAG directly uses knowledge in HTML format, preserving more information. But since HTML contains additional tags and noise, the authors propose cleaning and compression strategies to address this issue. Experiments show that HtmlRAG performs better on six question-answering datasets.",
        "update_ts": "2024-11-07 10:12"
    }
}