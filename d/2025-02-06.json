{
    "date": {
        "ru": "6 февраля",
        "en": "February 6",
        "zh": "2月6日"
    },
    "time_utc": "2025-02-06 05:10",
    "weekday": 3,
    "issue_id": 2065,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.01506",
            "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
            "url": "https://huggingface.co/papers/2502.01506",
            "abstract": "The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.",
            "score": 15,
            "issue_id": 2063,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "f5ec0450054af574",
            "authors": [
                "Yuzhe Yang",
                "Yifei Zhang",
                "Minghao Wu",
                "Kaidi Zhang",
                "Yunmiao Zhang",
                "Honghai Yu",
                "Yan Hu",
                "Benyou Wang"
            ],
            "affiliations": [
                "Nanjing University",
                "The Chinese University of Hong Kong, Shenzhen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01506.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#agents"
                ],
                "emoji": "📊",
                "ru": {
                    "title": "LLM-агенты раскрывают тайны социально-экономической динамики",
                    "desc": "Статья представляет новый фреймворк TwinMarket для моделирования социально-экономических систем с использованием больших языковых моделей (LLM). Авторы применяют LLM-агентов для более реалистичного моделирования человеческого поведения, учитывая когнитивные искажения и эмоциональные факторы. В экспериментах на симулированном фондовом рынке демонстрируется, как индивидуальные действия приводят к групповому поведению и эмергентным явлениям. Этот подход позволяет лучше понять взаимосвязь между индивидуальным принятием решений и коллективными социально-экономическими паттернами."
                },
                "en": {
                    "title": "Harnessing LLMs for Realistic Socio-Economic Simulations",
                    "desc": "This paper presents TwinMarket, a new framework that uses large language models (LLMs) to simulate socio-economic systems. Unlike traditional Agent-Based Models, TwinMarket captures the complexity of human behavior, including cognitive biases and emotional influences. The framework allows for the exploration of how individual actions can lead to collective dynamics, such as financial bubbles and recessions, in a simulated stock market. By leveraging LLMs, the study provides deeper insights into the interactions between individual decision-making and broader socio-economic patterns."
                },
                "zh": {
                    "title": "利用大型语言模型模拟社会经济系统的涌现现象",
                    "desc": "本研究探讨了社会涌现现象，传统的基于规则的代理模型（ABM）难以捕捉人类行为的多样性和复杂性，尤其是行为经济学中强调的非理性因素。我们提出了一种新的多代理框架TwinMarket，利用大型语言模型（LLM）来模拟社会经济系统。通过模拟股票市场环境的实验，我们展示了个体行为如何通过互动和反馈机制引发集体动态，导致金融泡沫和经济衰退等涌现现象。该方法为个体决策与集体社会经济模式之间的复杂关系提供了宝贵的见解。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.03373",
            "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
            "url": "https://huggingface.co/papers/2502.03373",
            "abstract": "Scaling inference compute enhances reasoning in large language models (LLMs), with long chains-of-thought (CoTs) enabling strategies like backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we present four main findings: (1) While SFT is not strictly necessary, it simplifies training and improves efficiency; (2) Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We find that leveraging noisy, web-extracted solutions with filtering mechanisms shows strong potential, particularly for out-of-distribution (OOD) tasks such as STEM reasoning; and (4) Core abilities like error correction are inherently present in base models, but incentivizing these skills effectively for complex tasks via RL demands significant compute, and measuring their emergence requires a nuanced approach. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs. Our code is available at: https://github.com/eddycmu/demystify-long-cot.",
            "score": 5,
            "issue_id": 2064,
            "pub_date": "2025-02-05",
            "pub_date_card": {
                "ru": "5 февраля",
                "en": "February 5",
                "zh": "2月5日"
            },
            "hash": "a1d00a6c8452131a",
            "authors": [
                "Edward Yeo",
                "Yuxuan Tong",
                "Morry Niu",
                "Graham Neubig",
                "Xiang Yue"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "IN.AI",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.03373.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#training",
                    "#long_context"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Раскрывая секреты длинных цепочек рассуждений в ИИ",
                    "desc": "Статья исследует механизмы длинных цепочек рассуждений (CoT) в больших языковых моделях (LLM). Авторы выявляют ключевые факторы, влияющие на способность моделей генерировать длинные CoT траектории через эксперименты с обучением с подкреплением (RL) и тонкой настройкой. Исследование показывает важность масштабирования вычислительных ресурсов, формирования наград и использования веб-данных для улучшения рассуждений. Результаты предоставляют практические рекомендации по оптимизации стратегий обучения для усиления длинных CoT рассуждений в LLM."
                },
                "en": {
                    "title": "Unlocking Reasoning Power in Large Language Models",
                    "desc": "This paper explores how to improve reasoning in large language models (LLMs) by enhancing their inference capabilities through long chains-of-thought (CoTs). It highlights the importance of reinforcement learning (RL) in developing these reasoning skills, while also addressing the unclear conditions for the emergence of long CoTs. The study presents four key findings, including the role of supervised fine-tuning (SFT) in simplifying training, the necessity of reward shaping for stabilizing CoT growth, and the significance of scaling reward signals for effective RL. Overall, the research provides valuable insights for optimizing training strategies to boost long CoT reasoning in LLMs."
                },
                "zh": {
                    "title": "优化训练策略，提升长推理链能力",
                    "desc": "本研究探讨了大型语言模型（LLMs）中长推理链（CoTs）的生成机制，揭示了影响模型生成长推理链的关键因素。我们发现，虽然监督微调（SFT）不是绝对必要的，但它可以简化训练过程并提高效率。随着训练计算能力的增加，推理能力有可能出现，但其发展并不总是保证，因此奖励设计对于稳定推理链的长度增长至关重要。最后，我们的研究为优化训练策略以增强LLMs中的长推理链提供了实用指导。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.02339",
            "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
            "url": "https://huggingface.co/papers/2502.02339",
            "abstract": "Multimodal large language models (MLLMs) exhibit impressive capabilities but still face challenges in complex visual reasoning. While recent efforts attempt to enhance MLLMs' reasoning by incorporating OpenAI o1-like structured thinking through explicit search structures or teacher-guided distillation, they often struggle to balance performance and efficiency. A critical limitation is their heavy reliance on extensive data and search spaces, resulting in low-efficiency implicit insight extraction and data utilization. To address this, we propose AStar, an Automated Structured thinking paradigm for multimodal reasoning via Monte Carlo Tree Search (MCTS). AStar automatically derives high-level cognitive reasoning patterns from limited data using MCTS-powered hierarchical structures. Building on these explicit patterns, we design a unified reasoning framework that seamlessly integrates models' internal reasoning capabilities and external reasoning guidelines, enabling efficient inference with minimal tree iterations. This novel paradigm strikes a compelling balance between performance and efficiency. Extensive experiments demonstrate AStar's effectiveness, achieving superior accuracy (54.0%) on the MathVerse benchmark with a 7B backbone, surpassing GPT-4o (50.2%) while maintaining substantial data and computational efficiency.",
            "score": 5,
            "issue_id": 2063,
            "pub_date": "2025-02-04",
            "pub_date_card": {
                "ru": "4 февраля",
                "en": "February 4",
                "zh": "2月4日"
            },
            "hash": "3f3413717efb32f6",
            "authors": [
                "Jinyang Wu",
                "Mingkuan Feng",
                "Shuai Zhang",
                "Ruihan Jin",
                "Feihu Che",
                "Zengqi Wen",
                "Jianhua Tao"
            ],
            "affiliations": [
                "Beijing",
                "Department of Automation, Tsinghua University, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.02339.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#benchmark",
                    "#multimodal",
                    "#architecture",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "AStar: Эффективное структурированное мышление для мультимодальных ИИ",
                    "desc": "Статья представляет новый подход к улучшению визуального рассуждения мультимодальных больших языковых моделей (MLLM). Авторы предлагают метод AStar, использующий автоматизированное структурированное мышление на основе поиска Монте-Карло по дереву (MCTS). AStar автоматически извлекает высокоуровневые паттерны рассуждений из ограниченных данных и интегрирует внутренние способности модели с внешними указаниями. Эксперименты показывают, что AStar достигает точности 54.0% на бенчмарке MathVerse, превосходя GPT-4o при высокой эффективности использования данных и вычислений."
                },
                "en": {
                    "title": "AStar: Enhancing Multimodal Reasoning with Efficient Structured Thinking",
                    "desc": "This paper introduces AStar, a new approach to improve the reasoning abilities of multimodal large language models (MLLMs) using Monte Carlo Tree Search (MCTS). AStar focuses on deriving high-level cognitive reasoning patterns from limited data, which helps in enhancing the models' performance without requiring extensive data sets. The framework integrates internal reasoning capabilities of the models with external guidelines, allowing for efficient inference with fewer iterations. Experimental results show that AStar outperforms existing models like GPT-4o in accuracy while being more data and computationally efficient."
                },
                "zh": {
                    "title": "AStar：高效的多模态推理新范式",
                    "desc": "多模态大型语言模型（MLLMs）在复杂视觉推理方面表现出色，但仍面临挑战。尽管最近的研究尝试通过引入结构化思维和教师指导来增强推理能力，但在性能和效率之间的平衡仍然困难。本文提出了一种名为AStar的自动化结构化思维范式，利用蒙特卡洛树搜索（MCTS）从有限数据中自动推导高层次的认知推理模式。AStar通过统一的推理框架，结合模型的内部推理能力和外部推理指导，实现高效推理，显著提高了准确性和数据利用效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01618",
            "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
            "url": "https://huggingface.co/papers/2502.01618",
            "abstract": "Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code and further information is available at https://probabilistic-inference-scaling.github.io.",
            "score": 0,
            "issue_id": 2065,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "c9971916eb027101",
            "authors": [
                "Isha Puri",
                "Shivchander Sudalairaj",
                "Guangxuan Xu",
                "Kai Xu",
                "Akash Srivastava"
            ],
            "affiliations": [
                "MIT CSAIL",
                "Red Hat AI Innovation"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01618.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#math",
                    "#inference"
                ],
                "emoji": "🎲",
                "ru": {
                    "title": "Вероятностный подход к масштабированию вывода LLM",
                    "desc": "Статья представляет новый подход к масштабированию вычислений во время вывода для больших языковых моделей (LLM). Вместо оптимизации с помощью моделей вознаграждения, авторы рассматривают задачу как вероятностный вывод, используя методы Монте-Карло на основе частиц. Эмпирическая оценка показывает, что предложенный метод имеет в 4-16 раз лучшую скорость масштабирования по сравнению с детерминированными аналогами на сложных задачах математических рассуждений. Исследование демонстрирует, как небольшие модели могут достичь точности крупных моделей при меньшем количестве прогонов."
                },
                "en": {
                    "title": "Revolutionizing Inference: Probabilistic Scaling for LLMs",
                    "desc": "This paper addresses the limitations of scaling large language models (LLMs) by focusing on improving inference time rather than just increasing model size or data. The authors propose a new approach that treats inference-time scaling as a probabilistic inference task, using sampling techniques to better explore the state distribution. By applying particle-based Monte Carlo methods, their method shows significant improvements in scaling rates compared to traditional deterministic search methods. The results indicate that their approach can achieve higher accuracy with fewer rollouts, demonstrating a promising direction for enhancing LLM performance."
                },
                "zh": {
                    "title": "推理时间扩展的新方法：概率推理与粒子采样结合",
                    "desc": "大型语言模型（LLMs）通过增加模型规模和数据量取得了显著的性能提升。然而，最近的研究表明，这种方法的收益递减，促使我们考虑在推理时增加计算量。现有的推理时间扩展方法通常将任务视为搜索问题，容易受到奖励模型的近似误差影响而导致奖励操控。本文提出了一种新的推理时间扩展方法，通过适应基于粒子的蒙特卡洛方法，将推理时间扩展视为概率推理任务，从而在各种数学推理任务中实现了更好的扩展率。"
                }
            }
        }
    ],
    "link_prev": "2025-02-05.html",
    "link_next": "2025-02-07.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "05.02",
        "en": "02/05",
        "zh": "2月5日"
    },
    "short_date_next": {
        "ru": "07.02",
        "en": "02/07",
        "zh": "2月7日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 3,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了扩散桥模型（DBMs）在图像到图像翻译中的应用。DBMs虽然有前景，但推理速度慢。作者提出了一种新的蒸馏技术，可以加速DBMs的推理过程。这种方法可以处理有条件和无条件的DBMs，并且只需要使用受损图像进行训练。实验结果显示，这种技术可以将DBMs的推理速度提高4到100倍，并在某些情况下提供比原始模型更好的生成质量。",
        "title": "Inverse Bridge Matching Distillation",
        "pinyin": "这篇文章讨论了扩散桥模型（DBMs）在图像到图像翻译中的应用。DBMs虽然有前景，但推理速度慢。作者提出了一种新的蒸馏技术，可以加速DBMs的推理过程。这种方法可以处理有条件和无条件的DBMs，并且只需要使用受损图像进行训练。实验结果显示，这种技术可以将DBMs的推理速度提高4到100倍，并在某些情况下提供比原始模型更好的生成质量。\n\nZhè piān wénzhāng tǎolùn le kuòsàn qiáo móxíng (DBMs) zài túxiàng dào túxiàng fānyì zhōng de yìngyòng. DBMs suīrán yǒu qiánjǐng, dàn tuīlǐ sùdù màn. Zuòzhě tíchū le yīzhǒng xīn de zhēngliù jìshù, kěyǐ jiāsù DBMs de tuīlǐ guòchéng. Zhè zhǒng fāngfǎ kěyǐ chǔlǐ yǒu tiáojiàn hé wú tiáojiàn de DBMs, bìngqiě zhǐ xūyào shǐyòng shòusǔn túxiàng jìnxíng xùnliàn. Shíyàn jiéguǒ xiǎnshì, zhè zhǒng jìshù kěyǐ jiāng DBMs de tuīlǐ sùdù tígāo 4 dào 100 bèi, bìng zài mǒuxiē qíngkuàng xià tígōng bǐ yuánshǐ móxíng gèng hǎo de shēngchéng zhìliàng.",
        "vocab": "[{'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '桥', 'pinyin': 'qiáo', 'trans': 'bridge'}, {'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'}, {'word': '翻译', 'pinyin': 'fān yì', 'trans': 'translation'}, {'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'inference'}, {'word': '蒸馏', 'pinyin': 'zhēng liú', 'trans': 'distillation'}, {'word': '加速', 'pinyin': 'jiā sù', 'trans': 'accelerate'}, {'word': '处理', 'pinyin': 'chǔ lǐ', 'trans': 'process'}, {'word': '有条件', 'pinyin': 'yǒu tiáo jiàn', 'trans': 'conditional'}, {'word': '无条件', 'pinyin': 'wú tiáo jiàn', 'trans': 'unconditional'}, {'word': '受损', 'pinyin': 'shòu sǔn', 'trans': 'damaged'}, {'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generation'}, {'word': '质量', 'pinyin': 'zhì liàng', 'trans': 'quality'}]",
        "trans": "This article discusses the application of Diffusion Bridge Models (DBMs) in image-to-image translation. While DBMs hold promise, they suffer from slow inference speeds. The authors propose a new distillation technique that can accelerate the inference process of DBMs. This method can handle both conditional and unconditional DBMs and requires only the use of corrupted images for training. Experimental results show that this technique can increase the inference speed of DBMs by 4 to 100 times and, in some cases, provide better generation quality than the original model.",
        "update_ts": "2025-02-05 09:11"
    }
}