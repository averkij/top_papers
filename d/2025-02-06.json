{
    "date": {
        "ru": "6 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
        "en": "February 6",
        "zh": "2æœˆ6æ—¥"
    },
    "time_utc": "2025-02-06 05:10",
    "weekday": 3,
    "issue_id": 2065,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.01506",
            "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
            "url": "https://huggingface.co/papers/2502.01506",
            "abstract": "The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.",
            "score": 15,
            "issue_id": 2063,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 3",
                "zh": "2æœˆ3æ—¥"
            },
            "hash": "f5ec0450054af574",
            "authors": [
                "Yuzhe Yang",
                "Yifei Zhang",
                "Minghao Wu",
                "Kaidi Zhang",
                "Yunmiao Zhang",
                "Honghai Yu",
                "Yan Hu",
                "Benyou Wang"
            ],
            "affiliations": [
                "Nanjing University",
                "The Chinese University of Hong Kong, Shenzhen"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01506.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#agents"
                ],
                "emoji": "ğŸ“Š",
                "ru": {
                    "title": "LLM-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ Ñ‚Ğ°Ğ¹Ğ½Ñ‹ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾-ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº TwinMarket Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾-ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ LLM-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¸ÑĞºĞ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹. Ğ’ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ñ… Ğ½Ğ° ÑĞ¸Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ñ„Ğ¾Ğ½Ğ´Ğ¾Ğ²Ğ¾Ğ¼ Ñ€Ñ‹Ğ½ĞºĞµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ, ĞºĞ°Ğº Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´ÑÑ‚ Ğº Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ¼ĞµÑ€Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ ÑĞ²Ğ»ĞµĞ½Ğ¸ÑĞ¼. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿Ğ¾Ğ½ÑÑ‚ÑŒ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾ÑĞ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸ĞµĞ¼ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ¸ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾-ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Harnessing LLMs for Realistic Socio-Economic Simulations",
                    "desc": "This paper presents TwinMarket, a new framework that uses large language models (LLMs) to simulate socio-economic systems. Unlike traditional Agent-Based Models, TwinMarket captures the complexity of human behavior, including cognitive biases and emotional influences. The framework allows for the exploration of how individual actions can lead to collective dynamics, such as financial bubbles and recessions, in a simulated stock market. By leveraging LLMs, the study provides deeper insights into the interactions between individual decision-making and broader socio-economic patterns."
                },
                "zh": {
                    "title": "åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿç¤¾ä¼šç»æµç³»ç»Ÿçš„æ¶Œç°ç°è±¡",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†ç¤¾ä¼šæ¶Œç°ç°è±¡ï¼Œä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„ä»£ç†æ¨¡å‹ï¼ˆABMï¼‰éš¾ä»¥æ•æ‰äººç±»è¡Œä¸ºçš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯è¡Œä¸ºç»æµå­¦ä¸­å¼ºè°ƒçš„éç†æ€§å› ç´ ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¤šä»£ç†æ¡†æ¶TwinMarketï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æ¨¡æ‹Ÿç¤¾ä¼šç»æµç³»ç»Ÿã€‚é€šè¿‡æ¨¡æ‹Ÿè‚¡ç¥¨å¸‚åœºç¯å¢ƒçš„å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸ªä½“è¡Œä¸ºå¦‚ä½•é€šè¿‡äº’åŠ¨å’Œåé¦ˆæœºåˆ¶å¼•å‘é›†ä½“åŠ¨æ€ï¼Œå¯¼è‡´é‡‘èæ³¡æ²«å’Œç»æµè¡°é€€ç­‰æ¶Œç°ç°è±¡ã€‚è¯¥æ–¹æ³•ä¸ºä¸ªä½“å†³ç­–ä¸é›†ä½“ç¤¾ä¼šç»æµæ¨¡å¼ä¹‹é—´çš„å¤æ‚å…³ç³»æä¾›äº†å®è´µçš„è§è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.03373",
            "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
            "url": "https://huggingface.co/papers/2502.03373",
            "abstract": "Scaling inference compute enhances reasoning in large language models (LLMs), with long chains-of-thought (CoTs) enabling strategies like backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we present four main findings: (1) While SFT is not strictly necessary, it simplifies training and improves efficiency; (2) Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We find that leveraging noisy, web-extracted solutions with filtering mechanisms shows strong potential, particularly for out-of-distribution (OOD) tasks such as STEM reasoning; and (4) Core abilities like error correction are inherently present in base models, but incentivizing these skills effectively for complex tasks via RL demands significant compute, and measuring their emergence requires a nuanced approach. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs. Our code is available at: https://github.com/eddycmu/demystify-long-cot.",
            "score": 5,
            "issue_id": 2064,
            "pub_date": "2025-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "a1d00a6c8452131a",
            "authors": [
                "Edward Yeo",
                "Yuxuan Tong",
                "Morry Niu",
                "Graham Neubig",
                "Xiang Yue"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "IN.AI",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.03373.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#training",
                    "#long_context"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°Ñ ÑĞµĞºÑ€ĞµÑ‚Ñ‹ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ˜Ğ˜",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (CoT) Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ»ÑÑÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹, Ğ²Ğ»Ğ¸ÑÑÑ‰Ğ¸Ğµ Ğ½Ğ° ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ CoT Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ğ¸ Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¾Ğ¹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ², Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´ Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²ĞµĞ±-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… CoT Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² LLM."
                },
                "en": {
                    "title": "Unlocking Reasoning Power in Large Language Models",
                    "desc": "This paper explores how to improve reasoning in large language models (LLMs) by enhancing their inference capabilities through long chains-of-thought (CoTs). It highlights the importance of reinforcement learning (RL) in developing these reasoning skills, while also addressing the unclear conditions for the emergence of long CoTs. The study presents four key findings, including the role of supervised fine-tuning (SFT) in simplifying training, the necessity of reward shaping for stabilizing CoT growth, and the significance of scaling reward signals for effective RL. Overall, the research provides valuable insights for optimizing training strategies to boost long CoT reasoning in LLMs."
                },
                "zh": {
                    "title": "ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼Œæå‡é•¿æ¨ç†é“¾èƒ½åŠ›",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­é•¿æ¨ç†é“¾ï¼ˆCoTsï¼‰çš„ç”Ÿæˆæœºåˆ¶ï¼Œæ­ç¤ºäº†å½±å“æ¨¡å‹ç”Ÿæˆé•¿æ¨ç†é“¾çš„å…³é”®å› ç´ ã€‚æˆ‘ä»¬å‘ç°ï¼Œè™½ç„¶ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä¸æ˜¯ç»å¯¹å¿…è¦çš„ï¼Œä½†å®ƒå¯ä»¥ç®€åŒ–è®­ç»ƒè¿‡ç¨‹å¹¶æé«˜æ•ˆç‡ã€‚éšç€è®­ç»ƒè®¡ç®—èƒ½åŠ›çš„å¢åŠ ï¼Œæ¨ç†èƒ½åŠ›æœ‰å¯èƒ½å‡ºç°ï¼Œä½†å…¶å‘å±•å¹¶ä¸æ€»æ˜¯ä¿è¯ï¼Œå› æ­¤å¥–åŠ±è®¾è®¡å¯¹äºç¨³å®šæ¨ç†é“¾çš„é•¿åº¦å¢é•¿è‡³å…³é‡è¦ã€‚æœ€åï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä¸ºä¼˜åŒ–è®­ç»ƒç­–ç•¥ä»¥å¢å¼ºLLMsä¸­çš„é•¿æ¨ç†é“¾æä¾›äº†å®ç”¨æŒ‡å¯¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.02339",
            "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
            "url": "https://huggingface.co/papers/2502.02339",
            "abstract": "Multimodal large language models (MLLMs) exhibit impressive capabilities but still face challenges in complex visual reasoning. While recent efforts attempt to enhance MLLMs' reasoning by incorporating OpenAI o1-like structured thinking through explicit search structures or teacher-guided distillation, they often struggle to balance performance and efficiency. A critical limitation is their heavy reliance on extensive data and search spaces, resulting in low-efficiency implicit insight extraction and data utilization. To address this, we propose AStar, an Automated Structured thinking paradigm for multimodal reasoning via Monte Carlo Tree Search (MCTS). AStar automatically derives high-level cognitive reasoning patterns from limited data using MCTS-powered hierarchical structures. Building on these explicit patterns, we design a unified reasoning framework that seamlessly integrates models' internal reasoning capabilities and external reasoning guidelines, enabling efficient inference with minimal tree iterations. This novel paradigm strikes a compelling balance between performance and efficiency. Extensive experiments demonstrate AStar's effectiveness, achieving superior accuracy (54.0%) on the MathVerse benchmark with a 7B backbone, surpassing GPT-4o (50.2%) while maintaining substantial data and computational efficiency.",
            "score": 5,
            "issue_id": 2063,
            "pub_date": "2025-02-04",
            "pub_date_card": {
                "ru": "4 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 4",
                "zh": "2æœˆ4æ—¥"
            },
            "hash": "3f3413717efb32f6",
            "authors": [
                "Jinyang Wu",
                "Mingkuan Feng",
                "Shuai Zhang",
                "Ruihan Jin",
                "Feihu Che",
                "Zengqi Wen",
                "Jianhua Tao"
            ],
            "affiliations": [
                "Beijing",
                "Department of Automation, Tsinghua University, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.02339.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#benchmark",
                    "#multimodal",
                    "#architecture",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "AStar: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ˜Ğ˜",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ AStar, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾ Ğ¿Ğ¾ Ğ´ĞµÑ€ĞµĞ²Ñƒ (MCTS). AStar Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ AStar Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ 54.0% Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ MathVerse, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ GPT-4o Ğ¿Ñ€Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "AStar: Enhancing Multimodal Reasoning with Efficient Structured Thinking",
                    "desc": "This paper introduces AStar, a new approach to improve the reasoning abilities of multimodal large language models (MLLMs) using Monte Carlo Tree Search (MCTS). AStar focuses on deriving high-level cognitive reasoning patterns from limited data, which helps in enhancing the models' performance without requiring extensive data sets. The framework integrates internal reasoning capabilities of the models with external guidelines, allowing for efficient inference with fewer iterations. Experimental results show that AStar outperforms existing models like GPT-4o in accuracy while being more data and computationally efficient."
                },
                "zh": {
                    "title": "AStarï¼šé«˜æ•ˆçš„å¤šæ¨¡æ€æ¨ç†æ–°èŒƒå¼",
                    "desc": "å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤æ‚è§†è§‰æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ä»é¢ä¸´æŒ‘æˆ˜ã€‚å°½ç®¡æœ€è¿‘çš„ç ”ç©¶å°è¯•é€šè¿‡å¼•å…¥ç»“æ„åŒ–æ€ç»´å’Œæ•™å¸ˆæŒ‡å¯¼æ¥å¢å¼ºæ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´çš„å¹³è¡¡ä»ç„¶å›°éš¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºAStarçš„è‡ªåŠ¨åŒ–ç»“æ„åŒ–æ€ç»´èŒƒå¼ï¼Œåˆ©ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ä»æœ‰é™æ•°æ®ä¸­è‡ªåŠ¨æ¨å¯¼é«˜å±‚æ¬¡çš„è®¤çŸ¥æ¨ç†æ¨¡å¼ã€‚AStaré€šè¿‡ç»Ÿä¸€çš„æ¨ç†æ¡†æ¶ï¼Œç»“åˆæ¨¡å‹çš„å†…éƒ¨æ¨ç†èƒ½åŠ›å’Œå¤–éƒ¨æ¨ç†æŒ‡å¯¼ï¼Œå®ç°é«˜æ•ˆæ¨ç†ï¼Œæ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å’Œæ•°æ®åˆ©ç”¨æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01618",
            "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
            "url": "https://huggingface.co/papers/2502.01618",
            "abstract": "Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code and further information is available at https://probabilistic-inference-scaling.github.io.",
            "score": 0,
            "issue_id": 2065,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 3",
                "zh": "2æœˆ3æ—¥"
            },
            "hash": "c9971916eb027101",
            "authors": [
                "Isha Puri",
                "Shivchander Sudalairaj",
                "Guangxuan Xu",
                "Kai Xu",
                "Akash Srivastava"
            ],
            "affiliations": [
                "MIT CSAIL",
                "Red Hat AI Innovation"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01618.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#math",
                    "#inference"
                ],
                "emoji": "ğŸ²",
                "ru": {
                    "title": "Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° LLM",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ ĞºĞ°Ğº Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ†. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸Ğ¼ĞµĞµÑ‚ Ğ² 4-16 Ñ€Ğ°Ğ· Ğ»ÑƒÑ‡ÑˆÑƒÑ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°Ğ¼Ğ¸ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚, ĞºĞ°Ğº Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ´Ğ¾ÑÑ‚Ğ¸Ñ‡ÑŒ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€Ğ¸ Ğ¼ĞµĞ½ÑŒÑˆĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¿Ñ€Ğ¾Ğ³Ğ¾Ğ½Ğ¾Ğ²."
                },
                "en": {
                    "title": "Revolutionizing Inference: Probabilistic Scaling for LLMs",
                    "desc": "This paper addresses the limitations of scaling large language models (LLMs) by focusing on improving inference time rather than just increasing model size or data. The authors propose a new approach that treats inference-time scaling as a probabilistic inference task, using sampling techniques to better explore the state distribution. By applying particle-based Monte Carlo methods, their method shows significant improvements in scaling rates compared to traditional deterministic search methods. The results indicate that their approach can achieve higher accuracy with fewer rollouts, demonstrating a promising direction for enhancing LLM performance."
                },
                "zh": {
                    "title": "æ¨ç†æ—¶é—´æ‰©å±•çš„æ–°æ–¹æ³•ï¼šæ¦‚ç‡æ¨ç†ä¸ç²’å­é‡‡æ ·ç»“åˆ",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å¢åŠ æ¨¡å‹è§„æ¨¡å’Œæ•°æ®é‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•çš„æ”¶ç›Šé€’å‡ï¼Œä¿ƒä½¿æˆ‘ä»¬è€ƒè™‘åœ¨æ¨ç†æ—¶å¢åŠ è®¡ç®—é‡ã€‚ç°æœ‰çš„æ¨ç†æ—¶é—´æ‰©å±•æ–¹æ³•é€šå¸¸å°†ä»»åŠ¡è§†ä¸ºæœç´¢é—®é¢˜ï¼Œå®¹æ˜“å—åˆ°å¥–åŠ±æ¨¡å‹çš„è¿‘ä¼¼è¯¯å·®å½±å“è€Œå¯¼è‡´å¥–åŠ±æ“æ§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†æ—¶é—´æ‰©å±•æ–¹æ³•ï¼Œé€šè¿‡é€‚åº”åŸºäºç²’å­çš„è’™ç‰¹å¡æ´›æ–¹æ³•ï¼Œå°†æ¨ç†æ—¶é—´æ‰©å±•è§†ä¸ºæ¦‚ç‡æ¨ç†ä»»åŠ¡ï¼Œä»è€Œåœ¨å„ç§æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å®ç°äº†æ›´å¥½çš„æ‰©å±•ç‡ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-02-05.html",
    "link_next": "2025-02-07.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "05.02",
        "en": "02/05",
        "zh": "2æœˆ5æ—¥"
    },
    "short_date_next": {
        "ru": "07.02",
        "en": "02/07",
        "zh": "2æœˆ7æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 3,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†æ‰©æ•£æ¡¥æ¨¡å‹ï¼ˆDBMsï¼‰åœ¨å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„åº”ç”¨ã€‚DBMsè™½ç„¶æœ‰å‰æ™¯ï¼Œä½†æ¨ç†é€Ÿåº¦æ…¢ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„è’¸é¦æŠ€æœ¯ï¼Œå¯ä»¥åŠ é€ŸDBMsçš„æ¨ç†è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•å¯ä»¥å¤„ç†æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„DBMsï¼Œå¹¶ä¸”åªéœ€è¦ä½¿ç”¨å—æŸå›¾åƒè¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ç§æŠ€æœ¯å¯ä»¥å°†DBMsçš„æ¨ç†é€Ÿåº¦æé«˜4åˆ°100å€ï¼Œå¹¶åœ¨æŸäº›æƒ…å†µä¸‹æä¾›æ¯”åŸå§‹æ¨¡å‹æ›´å¥½çš„ç”Ÿæˆè´¨é‡ã€‚",
        "title": "Inverse Bridge Matching Distillation",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†æ‰©æ•£æ¡¥æ¨¡å‹ï¼ˆDBMsï¼‰åœ¨å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„åº”ç”¨ã€‚DBMsè™½ç„¶æœ‰å‰æ™¯ï¼Œä½†æ¨ç†é€Ÿåº¦æ…¢ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„è’¸é¦æŠ€æœ¯ï¼Œå¯ä»¥åŠ é€ŸDBMsçš„æ¨ç†è¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•å¯ä»¥å¤„ç†æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„DBMsï¼Œå¹¶ä¸”åªéœ€è¦ä½¿ç”¨å—æŸå›¾åƒè¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ç§æŠ€æœ¯å¯ä»¥å°†DBMsçš„æ¨ç†é€Ÿåº¦æé«˜4åˆ°100å€ï¼Œå¹¶åœ¨æŸäº›æƒ…å†µä¸‹æä¾›æ¯”åŸå§‹æ¨¡å‹æ›´å¥½çš„ç”Ÿæˆè´¨é‡ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le kuÃ²sÃ n qiÃ¡o mÃ³xÃ­ng (DBMs) zÃ i tÃºxiÃ ng dÃ o tÃºxiÃ ng fÄnyÃ¬ zhÅng de yÃ¬ngyÃ²ng. DBMs suÄ«rÃ¡n yÇ’u qiÃ¡njÇng, dÃ n tuÄ«lÇ sÃ¹dÃ¹ mÃ n. ZuÃ²zhÄ› tÃ­chÅ« le yÄ«zhÇ’ng xÄ«n de zhÄ“ngliÃ¹ jÃ¬shÃ¹, kÄ›yÇ jiÄsÃ¹ DBMs de tuÄ«lÇ guÃ²chÃ©ng. ZhÃ¨ zhÇ’ng fÄngfÇ kÄ›yÇ chÇ”lÇ yÇ’u tiÃ¡ojiÃ n hÃ© wÃº tiÃ¡ojiÃ n de DBMs, bÃ¬ngqiÄ› zhÇ xÅ«yÃ o shÇyÃ²ng shÃ²usÇ”n tÃºxiÃ ng jÃ¬nxÃ­ng xÃ¹nliÃ n. ShÃ­yÃ n jiÃ©guÇ’ xiÇnshÃ¬, zhÃ¨ zhÇ’ng jÃ¬shÃ¹ kÄ›yÇ jiÄng DBMs de tuÄ«lÇ sÃ¹dÃ¹ tÃ­gÄo 4 dÃ o 100 bÃ¨i, bÃ¬ng zÃ i mÇ’uxiÄ“ qÃ­ngkuÃ ng xiÃ  tÃ­gÅng bÇ yuÃ¡nshÇ mÃ³xÃ­ng gÃ¨ng hÇo de shÄ“ngchÃ©ng zhÃ¬liÃ ng.",
        "vocab": "[{'word': 'æ‰©æ•£', 'pinyin': 'kuÃ² sÃ n', 'trans': 'diffusion'}, {'word': 'æ¡¥', 'pinyin': 'qiÃ¡o', 'trans': 'bridge'}, {'word': 'æ¨¡å‹', 'pinyin': 'mÃ³ xÃ­ng', 'trans': 'model'}, {'word': 'ç¿»è¯‘', 'pinyin': 'fÄn yÃ¬', 'trans': 'translation'}, {'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'inference'}, {'word': 'è’¸é¦', 'pinyin': 'zhÄ“ng liÃº', 'trans': 'distillation'}, {'word': 'åŠ é€Ÿ', 'pinyin': 'jiÄ sÃ¹', 'trans': 'accelerate'}, {'word': 'å¤„ç†', 'pinyin': 'chÇ” lÇ', 'trans': 'process'}, {'word': 'æœ‰æ¡ä»¶', 'pinyin': 'yÇ’u tiÃ¡o jiÃ n', 'trans': 'conditional'}, {'word': 'æ— æ¡ä»¶', 'pinyin': 'wÃº tiÃ¡o jiÃ n', 'trans': 'unconditional'}, {'word': 'å—æŸ', 'pinyin': 'shÃ²u sÇ”n', 'trans': 'damaged'}, {'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ng chÃ©ng', 'trans': 'generation'}, {'word': 'è´¨é‡', 'pinyin': 'zhÃ¬ liÃ ng', 'trans': 'quality'}]",
        "trans": "This article discusses the application of Diffusion Bridge Models (DBMs) in image-to-image translation. While DBMs hold promise, they suffer from slow inference speeds. The authors propose a new distillation technique that can accelerate the inference process of DBMs. This method can handle both conditional and unconditional DBMs and requires only the use of corrupted images for training. Experimental results show that this technique can increase the inference speed of DBMs by 4 to 100 times and, in some cases, provide better generation quality than the original model.",
        "update_ts": "2025-02-05 09:11"
    }
}