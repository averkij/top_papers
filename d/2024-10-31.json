{
    "date": {
        "ru": "31 октября",
        "en": "October 31",
        "zh": "10月31日"
    },
    "time_utc": "2024-10-31 04:16",
    "weekday": 3,
    "issue_id": 348,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2410.23090",
            "title": "CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation",
            "url": "https://huggingface.co/papers/2410.23090",
            "abstract": "Retrieval-Augmented Generation (RAG) has become a powerful paradigm for enhancing large language models (LLMs) through external knowledge retrieval. Despite its widespread attention, existing academic research predominantly focuses on single-turn RAG, leaving a significant gap in addressing the complexities of multi-turn conversations found in real-world applications. To bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess RAG systems in realistic multi-turn conversational settings. CORAL includes diverse information-seeking conversations automatically derived from Wikipedia and tackles key challenges such as open-domain coverage, knowledge intensity, free-form responses, and topic shifts. It supports three core tasks of conversational RAG: passage retrieval, response generation, and citation labeling. We propose a unified framework to standardize various conversational RAG methods and conduct a comprehensive evaluation of these methods on CORAL, demonstrating substantial opportunities for improving existing approaches.",
            "score": 26,
            "issue_id": 348,
            "pub_date": "2024-10-30",
            "pub_date_card": {
                "ru": "30 октября",
                "en": "October 30",
                "zh": "10月30日"
            },
            "hash": "d3cb6da7b94ee077",
            "data": {
                "categories": [
                    "#rag",
                    "#benchmark"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "CORAL: Новый стандарт для оценки многоходовых диалоговых систем с RAG",
                    "desc": "Статья представляет новый бенчмарк CORAL для оценки систем генерации с дополнительной информацией (RAG) в многоходовых диалогах. CORAL включает в себя разнообразные информационно-поисковые беседы, автоматически созданные на основе Википедии, и охватывает ключевые задачи, такие как открытый домен, интенсивное использование знаний и смена тем. Бенчмарк поддерживает три основные задачи: поиск релевантных отрывков текста, генерация ответов и маркировка цитат. Авторы также предлагают унифицированную структуру для стандартизации различных методов RAG в диалоговых системах."
                },
                "en": {
                    "title": "Enhancing Multi-Turn Conversations with CORAL Benchmark",
                    "desc": "This paper introduces CORAL, a benchmark aimed at improving Retrieval-Augmented Generation (RAG) systems for multi-turn conversations, which are more complex than single-turn interactions. It highlights the need for RAG models to effectively handle diverse and dynamic information-seeking dialogues, addressing challenges like open-domain coverage and topic shifts. The benchmark includes tasks such as passage retrieval, response generation, and citation labeling, providing a structured way to evaluate RAG performance. By proposing a unified framework, the authors aim to enhance the effectiveness of conversational RAG methods and identify areas for future improvement."
                },
                "zh": {
                    "title": "提升多轮对话的检索增强生成能力",
                    "desc": "本论文介绍了一种新的基准CORAL，用于评估检索增强生成（RAG）系统在多轮对话中的表现。现有研究主要集中在单轮对话上，缺乏对复杂多轮对话的深入探讨。CORAL基于维基百科自动生成多样的信息寻求对话，解决开放域覆盖、知识密集度、自由形式响应和话题转移等关键挑战。我们提出了一个统一框架，以标准化不同的对话RAG方法，并在CORAL上进行全面评估，展示了改进现有方法的巨大潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.20050",
            "title": "AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels",
            "url": "https://huggingface.co/papers/2410.20050",
            "abstract": "Medical information retrieval (MIR) is essential for retrieving relevant medical knowledge from diverse sources, including electronic health records, scientific literature, and medical databases. However, achieving effective zero-shot dense retrieval in the medical domain poses substantial challenges due to the lack of relevance-labeled data. In this paper, we introduce a novel approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to tackle this issue. SL-HyDE leverages large language models (LLMs) as generators to generate hypothetical documents based on a given query. These generated documents encapsulate key medical context, guiding a dense retriever in identifying the most relevant documents. The self-learning framework progressively refines both pseudo-document generation and retrieval, utilizing unlabeled medical corpora without requiring any relevance-labeled data. Additionally, we present the Chinese Medical Information Retrieval Benchmark (CMIRB), a comprehensive evaluation framework grounded in real-world medical scenarios, encompassing five tasks and ten datasets. By benchmarking ten models on CMIRB, we establish a rigorous standard for evaluating medical information retrieval systems. Experimental results demonstrate that SL-HyDE significantly surpasses existing methods in retrieval accuracy while showcasing strong generalization and scalability across various LLM and retriever configurations. CMIRB data and evaluation code are publicly available at: https://github.com/CMIRB-benchmark/CMIRB.",
            "score": 1,
            "issue_id": 347,
            "pub_date": "2024-10-26",
            "pub_date_card": {
                "ru": "26 октября",
                "en": "October 26",
                "zh": "10月26日"
            },
            "hash": "57721469df67a2f9",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#benchmark",
                    "#medicine"
                ],
                "emoji": "🩺",
                "ru": {
                    "title": "Революция в медицинском поиске: SL-HyDE и CMIRB открывают новые горизонты",
                    "desc": "Статья представляет новый подход к медицинскому информационному поиску под названием SL-HyDE. Этот метод использует большие языковые модели для генерации гипотетических документов на основе запроса, что помогает плотностному ретриверу находить наиболее релевантные документы. Авторы также представляют CMIRB - комплексную систему оценки для медицинского информационного поиска. Экспериментальные результаты показывают, что SL-HyDE значительно превосходит существующие методы по точности поиска."
                },
                "en": {
                    "title": "Revolutionizing Medical Retrieval with Self-Learning Hypothetical Documents",
                    "desc": "This paper addresses the challenges of zero-shot dense retrieval in medical information retrieval (MIR) due to the scarcity of labeled data. It introduces a new method called Self-Learning Hypothetical Document Embeddings (SL-HyDE), which uses large language models to create hypothetical documents that provide essential medical context for retrieval tasks. The self-learning approach refines the generation of these documents and the retrieval process using unlabeled medical data. Additionally, the authors present the Chinese Medical Information Retrieval Benchmark (CMIRB) to evaluate the performance of various models in real-world medical scenarios, demonstrating that SL-HyDE outperforms existing methods in accuracy and adaptability."
                },
                "zh": {
                    "title": "自学习假设文档嵌入：提升医学信息检索的有效性",
                    "desc": "医学信息检索（MIR）在从多种来源获取相关医学知识中至关重要，但在医学领域实现有效的零样本密集检索面临重大挑战，因为缺乏相关性标记的数据。本文提出了一种新方法，称为自学习假设文档嵌入（SL-HyDE），旨在解决这一问题。SL-HyDE利用大型语言模型（LLMs）生成基于给定查询的假设文档，这些文档包含关键的医学背景，帮助密集检索器识别最相关的文档。我们还提出了中国医学信息检索基准（CMIRB），为医学信息检索系统提供了一个全面的评估框架。"
                }
            }
        }
    ],
    "link_prev": "2024-10-30.html",
    "link_next": "2024-11-01.html",
    "short_date_prev": {
        "ru": "30.10",
        "en": "10/30",
        "zh": "10月30日"
    },
    "short_date_next": {
        "ru": "01.11",
        "en": "11/01",
        "zh": "11月1日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#medicine": 1,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0
    },
    "zh": {
        "text": "这篇文章讨论了机器取消学习（MU）在深度学习模型中增强隐私和安全的重要性，特别是在大型多模态语言模型（MLLMs）中。虽然MU在文本和视觉模态上取得了显著进展，但多模态取消学习（MMU）仍然没有得到充分研究，部分原因是缺乏合适的开源基准。为了解决这个问题，作者引入了CLEAR，一个新的基准，用于评估MMU方法。CLEAR包含200个虚构个体和3700张图片，并附有相应的问答对，可以进行跨模态的全面评估。作者评估了10种MU方法，并指出了多模态遗忘的新挑战。他们还展示了简单的ell_1正则化可以显著减轻灾难性遗忘，保持模型在保留数据上的性能。数据集可在https://huggingface.co/datasets/therem/CLEAR获取。",
        "title": "CLEAR: Character Unlearning in Textual and Visual Modalities",
        "pinyin": "这篇文章讨论了机器取消学习（MU）在深度学习模型中增强隐私和安全的重要性，特别是在大型多模态语言模型（MLLMs）中。虽然MU在文本和视觉模态上取得了显著进展，但多模态取消学习（MMU）仍然没有得到充分研究，部分原因是缺乏合适的开源基准。为了解决这个问题，作者引入了CLEAR，一个新的基准，用于评估MMU方法。CLEAR包含200个虚构个体和3700张图片，并附有相应的问答对，可以进行跨模态的全面评估。作者评估了10种MU方法，并指出了多模态遗忘的新挑战。他们还展示了简单的ell_1正则化可以显著减轻灾难性遗忘，保持模型在保留数据上的性能。数据集可在https://huggingface.co/datasets/therem/CLEAR获取。\n\nzhè piān wén zhāng tǎo lùn le jī qì qǔ xiāo xué (MU) zài shēn dù xué xí mó xìng zhōng zēng qiáng yǐn sī hé ān quán de zhòng yào xìng, tè bié shì zài dà xíng duō mó shuài yǔ yán mó xìng (MLLMs) zhōng. suī rán MU zài wén běn hé shì jué mó tài shàng qu dé le xiǎn zhù jìn zhǎn, dàn duō mó shuài qǔ xiāo xué (MMU) réng rán méi yǒu dé dào chóng fèn yán jiū, bù fèn yuán yīn shì quē fá hé shì de kāi yuán jī zhǔn. wèi le jiě jué zhè gè wèn tí, zuò zhě yǐn rù le CLEAR, yī gè xīn de jī zhǔn, yòng yú píng guā MMU fāng fǎ. CLEAR bāo hán 200 gè xū gòu gè tǐ hé 3700 zhāng tú piàn, bìng fù yǒu xiāng yìng de wèn dá duì, kě yǐ jìn xíng kuà mó shuài de quán miàn píng guā. zuò zhě píng guā le 10 zhǒng MU fāng fǎ, bìng zhǐ chū le duō mó shuài yí wàng de xīn tiǎo zhàn. tā men hái zhǎn shì le jiǎn dān de ell_1 zhèng guī huà kě yǐ xiǎn zhù jiǎn qīng zāi nàn xìng yí wàng, bǎo chí mó xìng zài bǎo liú shù jù shàng de xiào nèng. shù jù jí kě zài https://huggingface.co/datasets/therem/CLEAR huò qǔ.",
        "vocab": "[\n    {\"word\": \"讨论\", \"pinyin\": \"tǎo lùn\", \"trans\": \"discuss\"},\n    {\"word\": \"机器取消学习\", \"pinyin\": \"jī qì qǔ xiāo xué xí\", \"trans\": \"machine unlearning\"},\n    {\"word\": \"增强\", \"pinyin\": \"zēng qiáng\", \"trans\": \"enhance\"},\n    {\"word\": \"隐私\", \"pinyin\": \"yǐn sī\", \"trans\": \"privacy\"},\n    {\"word\": \"安全\", \"pinyin\": \"ān quán\", \"trans\": \"security\"},\n    {\"word\": \"深度学习模型\", \"pinyin\": \"shēn dù xué xí mó xíng\", \"trans\": \"deep learning model\"},\n    {\"word\": \"多模态语言模型\", \"pinyin\": \"duō mó shuài yǔ yán mó xíng\", \"trans\": \"multimodal language model\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"进展\", \"pinyin\": \"jìn zhǎn\", \"trans\": \"progress\"},\n    {\"word\": \"多模态取消学习\", \"pinyin\": \"duō mó shuài qǔ xiāo xué xí\", \"trans\": \"multimodal unlearning\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"合适\", \"pinyin\": \"hé shì\", \"trans\": \"suitable\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāi yuán\", \"trans\": \"open-source\"},\n    {\"word\": \"基准\", \"pinyin\": \"jī zhǔn\", \"trans\": \"benchmark\"},\n    {\"word\": \"引入\", \"pinyin\": \"yǐn rù\", \"trans\": \"introduce\"},\n    {\"word\": \"评估\", \"pinyin\": \"píng gū\", \"trans\": \"evaluate\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāng fǎ\", \"trans\": \"method\"},\n    {\"word\": \"虚构\", \"pinyin\": \"xū gòu\", \"trans\": \"fictional\"},\n    {\"word\": \"个体\", \"pinyin\": \"gè tǐ\", \"trans\": \"individual\"},\n    {\"word\": \"图片\", \"pinyin\": \"tú piàn\", \"trans\": \"image\"},\n    {\"word\": \"问答对\", \"pinyin\": \"wèn dá duì\", \"trans\": \"question-answer pair\"},\n    {\"word\": \"跨模态\", \"pinyin\": \"kuà mó shuài\", \"trans\": \"cross-modal\"},\n    {\"word\": \"全面\", \"pinyin\": \"quán miàn\", \"trans\": \"comprehensive\"},\n    {\"word\": \"遗忘\", \"pinyin\": \"yí wàng\", \"trans\": \"forgetting\"},\n    {\"word\": \"挑战\", \"pinyin\": \"tiǎo zhàn\", \"trans\": \"challenge\"},\n    {\"word\": \"正则化\", \"pinyin\": \"zhèng zé huà\", \"trans\": \"regularization\"},\n    {\"word\": \"减轻\", \"pinyin\": \"jiǎn qīng\", \"trans\": \"alleviate\"},\n    {\"word\": \"灾难性\", \"pinyin\": \"zāi nàn xìng\", \"trans\": \"catastrophic\"},\n    {\"word\": \"保持\", \"pinyin\": \"bǎo chí\", \"trans\": \"maintain\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shù jù jí\", \"trans\": \"dataset\"}\n]",
        "trans": "This article discusses the importance of machine unlearning (MU) in enhancing privacy and security in deep learning models, particularly in large multimodal language models (MLLMs). Although MU has made significant progress in text and visual modalities, multimodal unlearning (MMU) remains under-researched, partly due to the lack of suitable open-source benchmarks. To address this issue, the authors introduce CLEAR, a new benchmark for evaluating MMU methods. CLEAR contains 200 fictional individuals and 3,700 images, along with corresponding question-answer pairs, allowing for comprehensive cross-modal evaluation. The authors evaluated 10 MU methods and highlighted new challenges in multimodal forgetting. They also demonstrated that simple ell_1 regularization can significantly mitigate catastrophic forgetting, maintaining the model's performance on retained data. The dataset is available at https://huggingface.co/datasets/therem/CLEAR.",
        "update_ts": "2024-10-30 10:13"
    }
}