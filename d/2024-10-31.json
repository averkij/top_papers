{
    "date": {
        "ru": "31 октября",
        "en": "October 31",
        "zh": "10月31日"
    },
    "time_utc": "2024-10-31 10:13",
    "weekday": 3,
    "issue_id": 352,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2410.23090",
            "title": "CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation",
            "url": "https://huggingface.co/papers/2410.23090",
            "abstract": "Retrieval-Augmented Generation (RAG) has become a powerful paradigm for enhancing large language models (LLMs) through external knowledge retrieval. Despite its widespread attention, existing academic research predominantly focuses on single-turn RAG, leaving a significant gap in addressing the complexities of multi-turn conversations found in real-world applications. To bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess RAG systems in realistic multi-turn conversational settings. CORAL includes diverse information-seeking conversations automatically derived from Wikipedia and tackles key challenges such as open-domain coverage, knowledge intensity, free-form responses, and topic shifts. It supports three core tasks of conversational RAG: passage retrieval, response generation, and citation labeling. We propose a unified framework to standardize various conversational RAG methods and conduct a comprehensive evaluation of these methods on CORAL, demonstrating substantial opportunities for improving existing approaches.",
            "score": 38,
            "issue_id": 348,
            "pub_date": "2024-10-30",
            "pub_date_card": {
                "ru": "30 октября",
                "en": "October 30",
                "zh": "10月30日"
            },
            "hash": "d3cb6da7b94ee077",
            "data": {
                "categories": [
                    "#rag",
                    "#benchmark"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "CORAL: Новый стандарт для оценки многоходовых диалоговых систем с RAG",
                    "desc": "Статья представляет новый бенчмарк CORAL для оценки систем генерации с дополнительной информацией (RAG) в многоходовых диалогах. CORAL включает в себя разнообразные информационно-поисковые беседы, автоматически созданные на основе Википедии, и охватывает ключевые задачи, такие как открытый домен, интенсивное использование знаний и смена тем. Бенчмарк поддерживает три основные задачи: поиск релевантных отрывков текста, генерация ответов и маркировка цитат. Авторы также предлагают унифицированную структуру для стандартизации различных методов RAG в диалоговых системах."
                },
                "en": {
                    "title": "Enhancing Multi-Turn Conversations with CORAL Benchmark",
                    "desc": "This paper introduces CORAL, a benchmark aimed at improving Retrieval-Augmented Generation (RAG) systems for multi-turn conversations, which are more complex than single-turn interactions. It highlights the need for RAG models to effectively handle diverse and dynamic information-seeking dialogues, addressing challenges like open-domain coverage and topic shifts. The benchmark includes tasks such as passage retrieval, response generation, and citation labeling, providing a structured way to evaluate RAG performance. By proposing a unified framework, the authors aim to enhance the effectiveness of conversational RAG methods and identify areas for future improvement."
                },
                "zh": {
                    "title": "提升多轮对话的检索增强生成能力",
                    "desc": "本论文介绍了一种新的基准CORAL，用于评估检索增强生成（RAG）系统在多轮对话中的表现。现有研究主要集中在单轮对话上，缺乏对复杂多轮对话的深入探讨。CORAL基于维基百科自动生成多样的信息寻求对话，解决开放域覆盖、知识密集度、自由形式响应和话题转移等关键挑战。我们提出了一个统一框架，以标准化不同的对话RAG方法，并在CORAL上进行全面评估，展示了改进现有方法的巨大潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.22391",
            "title": "A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks",
            "url": "https://huggingface.co/papers/2410.22391",
            "abstract": "In recent years, there has been a trend in the field of Reinforcement Learning (RL) towards large action models trained offline on large-scale datasets via sequence modeling. Existing models are primarily based on the Transformer architecture, which result in powerful agents. However, due to slow inference times, Transformer-based approaches are impractical for real-time applications, such as robotics. Recently, modern recurrent architectures, such as xLSTM and Mamba, have been proposed that exhibit parallelization benefits during training similar to the Transformer architecture while offering fast inference. In this work, we study the aptitude of these modern recurrent architectures for large action models. Consequently, we propose a Large Recurrent Action Model (LRAM) with an xLSTM at its core that comes with linear-time inference complexity and natural sequence length extrapolation abilities. Experiments on 432 tasks from 6 domains show that LRAM compares favorably to Transformers in terms of performance and speed.",
            "score": 6,
            "issue_id": 350,
            "pub_date": "2024-10-29",
            "pub_date_card": {
                "ru": "29 октября",
                "en": "October 29",
                "zh": "10月29日"
            },
            "hash": "876c89e8fc188dd3",
            "data": {
                "categories": [
                    "#rl",
                    "#agents",
                    "#architecture"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "LRAM: Быстрее трансформеров, эффективнее в реальном времени",
                    "desc": "В статье представлена новая модель LRAM (Large Recurrent Action Model) для обучения с подкреплением, основанная на архитектуре xLSTM. LRAM предлагает линейную сложность вывода и способность к экстраполяции длины последовательности, что делает её более практичной для приложений реального времени по сравнению с моделями на основе трансформеров. Эксперименты на 432 задачах из 6 доменов показали, что LRAM не уступает трансформерам по производительности и скорости. Это исследование демонстрирует потенциал современных рекуррентных архитектур для моделей с большим пространством действий в обучении с подкреплением."
                },
                "en": {
                    "title": "Fast and Effective: LRAM for Real-Time Reinforcement Learning",
                    "desc": "This paper explores the use of modern recurrent architectures, specifically xLSTM, for creating large action models in Reinforcement Learning (RL). Traditional Transformer models are powerful but suffer from slow inference times, making them unsuitable for real-time applications like robotics. The proposed Large Recurrent Action Model (LRAM) leverages the benefits of xLSTM to achieve linear-time inference complexity while maintaining strong performance. Experimental results demonstrate that LRAM outperforms Transformer-based models in both speed and effectiveness across a variety of tasks."
                },
                "zh": {
                    "title": "快速推理的强化学习新选择",
                    "desc": "近年来，强化学习（RL）领域出现了一个趋势，即使用大型离线数据集通过序列建模训练大型动作模型。现有模型主要基于Transformer架构，虽然能够生成强大的智能体，但由于推理速度慢，难以应用于实时场景，如机器人技术。最近提出的现代递归架构，如xLSTM和Mamba，具有与Transformer相似的训练并行化优势，同时提供快速推理能力。本文研究了这些现代递归架构在大型动作模型中的适用性，并提出了一种以xLSTM为核心的大型递归动作模型（LRAM），其推理复杂度为线性时间，且具有自然的序列长度外推能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.20050",
            "title": "AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels",
            "url": "https://huggingface.co/papers/2410.20050",
            "abstract": "Medical information retrieval (MIR) is essential for retrieving relevant medical knowledge from diverse sources, including electronic health records, scientific literature, and medical databases. However, achieving effective zero-shot dense retrieval in the medical domain poses substantial challenges due to the lack of relevance-labeled data. In this paper, we introduce a novel approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to tackle this issue. SL-HyDE leverages large language models (LLMs) as generators to generate hypothetical documents based on a given query. These generated documents encapsulate key medical context, guiding a dense retriever in identifying the most relevant documents. The self-learning framework progressively refines both pseudo-document generation and retrieval, utilizing unlabeled medical corpora without requiring any relevance-labeled data. Additionally, we present the Chinese Medical Information Retrieval Benchmark (CMIRB), a comprehensive evaluation framework grounded in real-world medical scenarios, encompassing five tasks and ten datasets. By benchmarking ten models on CMIRB, we establish a rigorous standard for evaluating medical information retrieval systems. Experimental results demonstrate that SL-HyDE significantly surpasses existing methods in retrieval accuracy while showcasing strong generalization and scalability across various LLM and retriever configurations. CMIRB data and evaluation code are publicly available at: https://github.com/CMIRB-benchmark/CMIRB.",
            "score": 3,
            "issue_id": 347,
            "pub_date": "2024-10-26",
            "pub_date_card": {
                "ru": "26 октября",
                "en": "October 26",
                "zh": "10月26日"
            },
            "hash": "57721469df67a2f9",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#benchmark",
                    "#medicine"
                ],
                "emoji": "🩺",
                "ru": {
                    "title": "Революция в медицинском поиске: SL-HyDE и CMIRB открывают новые горизонты",
                    "desc": "Статья представляет новый подход к медицинскому информационному поиску под названием SL-HyDE. Этот метод использует большие языковые модели для генерации гипотетических документов на основе запроса, что помогает плотностному ретриверу находить наиболее релевантные документы. Авторы также представляют CMIRB - комплексную систему оценки для медицинского информационного поиска. Экспериментальные результаты показывают, что SL-HyDE значительно превосходит существующие методы по точности поиска."
                },
                "en": {
                    "title": "Revolutionizing Medical Retrieval with Self-Learning Hypothetical Documents",
                    "desc": "This paper addresses the challenges of zero-shot dense retrieval in medical information retrieval (MIR) due to the scarcity of labeled data. It introduces a new method called Self-Learning Hypothetical Document Embeddings (SL-HyDE), which uses large language models to create hypothetical documents that provide essential medical context for retrieval tasks. The self-learning approach refines the generation of these documents and the retrieval process using unlabeled medical data. Additionally, the authors present the Chinese Medical Information Retrieval Benchmark (CMIRB) to evaluate the performance of various models in real-world medical scenarios, demonstrating that SL-HyDE outperforms existing methods in accuracy and adaptability."
                },
                "zh": {
                    "title": "自学习假设文档嵌入：提升医学信息检索的有效性",
                    "desc": "医学信息检索（MIR）在从多种来源获取相关医学知识中至关重要，但在医学领域实现有效的零样本密集检索面临重大挑战，因为缺乏相关性标记的数据。本文提出了一种新方法，称为自学习假设文档嵌入（SL-HyDE），旨在解决这一问题。SL-HyDE利用大型语言模型（LLMs）生成基于给定查询的假设文档，这些文档包含关键的医学背景，帮助密集检索器识别最相关的文档。我们还提出了中国医学信息检索基准（CMIRB），为医学信息检索系统提供了一个全面的评估框架。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.22884",
            "title": "Stealing User Prompts from Mixture of Experts",
            "url": "https://huggingface.co/papers/2410.22884",
            "abstract": "Mixture-of-Experts (MoE) models improve the efficiency and scalability of dense language models by routing each token to a small number of experts in each layer. In this paper, we show how an adversary that can arrange for their queries to appear in the same batch of examples as a victim's queries can exploit Expert-Choice-Routing to fully disclose a victim's prompt. We successfully demonstrate the effectiveness of this attack on a two-layer Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA implementation. Our results show that we can extract the entire prompt using O({VM}^2) queries (with vocabulary size V and prompt length M) or 100 queries on average per token in the setting we consider. This is the first attack to exploit architectural flaws for the purpose of extracting user prompts, introducing a new class of LLM vulnerabilities.",
            "score": 2,
            "issue_id": 351,
            "pub_date": "2024-10-30",
            "pub_date_card": {
                "ru": "30 октября",
                "en": "October 30",
                "zh": "10月30日"
            },
            "hash": "50ec28e1ed4db1bb",
            "data": {
                "categories": [
                    "#security",
                    "#architecture"
                ],
                "emoji": "🕵️",
                "ru": {
                    "title": "Уязвимость в MoE моделях: как архитектурные особенности могут раскрыть ваш промпт",
                    "desc": "Статья описывает уязвимость в моделях Mixture-of-Experts (MoE), использующих маршрутизацию Expert-Choice-Routing. Авторы демонстрируют, как злоумышленник может эксплуатировать эту уязвимость для раскрытия промпта жертвы, если запросы обрабатываются в одном батче. Эксперимент проводился на двухслойной модели Mixtral, используя особенности реализации torch.topk CUDA. Это первая атака, эксплуатирующая архитектурные недостатки для извлечения пользовательских промптов, что открывает новый класс уязвимостей в больших языковых моделях."
                },
                "en": {
                    "title": "Exposing Prompts: A New Vulnerability in Mixture-of-Experts Models",
                    "desc": "This paper discusses a vulnerability in Mixture-of-Experts (MoE) models, which are designed to enhance the efficiency of language models by directing tokens to specific experts. The authors demonstrate that an adversary can exploit the Expert-Choice-Routing mechanism to reveal a victim's input prompt by cleverly arranging queries in the same batch. They successfully execute this attack on a two-layer Mixtral model, taking advantage of the tie-handling behavior in the torch.topk CUDA implementation. The findings indicate that the entire prompt can be extracted with a relatively small number of queries, highlighting a new class of vulnerabilities in large language models (LLMs)."
                },
                "zh": {
                    "title": "利用架构缺陷提取用户提示的攻击",
                    "desc": "混合专家模型（MoE）通过将每个令牌路由到每层的小部分专家，提高了密集语言模型的效率和可扩展性。本文展示了一个对手如何利用专家选择路由，完全泄露受害者的提示，只需将其查询与受害者的查询放在同一批次中。我们在一个两层的Mixtral模型上成功演示了这一攻击，利用了torch.topk CUDA实现中的平局处理行为。我们的结果表明，在考虑的设置中，我们可以使用O({VM}^2)的查询（其中V是词汇大小，M是提示长度）或平均每个令牌100个查询来提取整个提示，这是首次利用架构缺陷提取用户提示的攻击，介绍了一类新的大型语言模型脆弱性。"
                }
            }
        }
    ],
    "link_prev": "2024-10-30.html",
    "link_next": "2024-11-01.html",
    "short_date_prev": {
        "ru": "30.10",
        "en": "10/30",
        "zh": "10月30日"
    },
    "short_date_next": {
        "ru": "01.11",
        "en": "11/01",
        "zh": "11月1日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 1,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 2,
        "#medicine": 1,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#edge_computing": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0
    },
    "zh": {
        "text": "这篇文章介绍了检索增强生成（RAG），一种通过外部知识检索增强大型语言模型的强大范式。尽管RAG受到广泛关注，但现有研究主要集中在单轮对话上，忽略了现实应用中复杂的多轮对话。为填补这一空白，作者提出了CORAL，一个大规模基准数据集，用于评估多轮对话中的RAG系统。CORAL包含多样的信息寻求对话，涵盖开放域、知识密集度、自由形式回复和话题转换等挑战。它支持对话RAG的三个核心任务：段落检索、回复生成和引用标记。作者提出了一个统一框架，并在CORAL上对各种对话RAG方法进行了综合评估，展示了改进现有方法的巨大潜力。",
        "title": "CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation",
        "pinyin": "zhè piān wén zhāng jiè shào le jiǎn suǒ zēng qiáng shēng chéng (RAG), yī zhǒng tōng guò wài bù zhī shi jiǎn suǒ zēng qiáng dà xíng yǔ yán mó xíng de qiáng dà fàn shì. jǐn guǎn RAG shòu dào guǎng fàn zhòng zhù, dàn xiàn yǒu yán jiū zhǔ yào jí zhōng zài dān lún duì huà shàng, hū lüe le xiàn shí yìng yòng zhōng fú zà de duō lún duì huà. wèi tián bǔ zhè yī kòng bái, zuò zhě tí chū le CORAL, yī gè dà guī mó bǐ zhǔn shù jù, yòng yú píng guā duō lún duì huà zhōng de RAG xì tǒng. CORAL bāo hán duō yàng de xìn xī xún qiú duì huà, hán gài kāi fàng yù, zhī shi mì dù, zì yóu xíng shì huí fù hé huà tí zhuǎn huàn děng tiǎo zhàn. tā zhī chí duì huà RAG de sān gè hé xīn rèn wù: duàn luó jiǎn suǒ, huí fù shēng chéng hé yǐn yòng biāo jì. zuò zhě tí chū le yī gè tǒng yī kuàng jià, bìng zài CORAL shàng duì zhǒng zhòng duì huà RAG fāng fǎ jìn xíng le zōng hé píng guā, zhǎn shì le gǎi jìn xiàn yǒu fāng fǎ de jù dà qián lì.",
        "vocab": "[\n    {\"word\": \"检索增强生成\", \"pinyin\": \"jiǎnsuǒ zēngqiáng shēngchéng\", \"trans\": \"Retrieval-Augmented Generation\"},\n    {\"word\": \"范式\", \"pinyin\": \"fànshì\", \"trans\": \"paradigm\"},\n    {\"word\": \"广泛\", \"pinyin\": \"guǎngfàn\", \"trans\": \"extensive\"},\n    {\"word\": \"单轮\", \"pinyin\": \"dānlún\", \"trans\": \"single-turn\"},\n    {\"word\": \"对话\", \"pinyin\": \"duìhuà\", \"trans\": \"dialogue\"},\n    {\"word\": \"复杂\", \"pinyin\": \"fùzá\", \"trans\": \"complex\"},\n    {\"word\": \"多轮\", \"pinyin\": \"duōlún\", \"trans\": \"multi-turn\"},\n    {\"word\": \"填补\", \"pinyin\": \"tiánbǔ\", \"trans\": \"fill\"},\n    {\"word\": \"空白\", \"pinyin\": \"kòngbái\", \"trans\": \"gap\"},\n    {\"word\": \"基准\", \"pinyin\": \"jīzhǔn\", \"trans\": \"benchmark\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shùjùjí\", \"trans\": \"dataset\"},\n    {\"word\": \"评估\", \"pinyin\": \"pínggū\", \"trans\": \"evaluate\"},\n    {\"word\": \"信息寻求\", \"pinyin\": \"xìnxī xúnqiú\", \"trans\": \"information-seeking\"},\n    {\"word\": \"开放域\", \"pinyin\": \"kāifàng yù\", \"trans\": \"open-domain\"},\n    {\"word\": \"知识密集度\", \"pinyin\": \"zhīshi mìjīdù\", \"trans\": \"knowledge intensity\"},\n    {\"word\": \"自由形式\", \"pinyin\": \"zìyóu xíngshì\", \"trans\": \"free-form\"},\n    {\"word\": \"回复\", \"pinyin\": \"huífù\", \"trans\": \"response\"},\n    {\"word\": \"话题转换\", \"pinyin\": \"huàtí zhuǎnhuàn\", \"trans\": \"topic switching\"},\n    {\"word\": \"段落检索\", \"pinyin\": \"duànluò jiǎnsuǒ\", \"trans\": \"paragraph retrieval\"},\n    {\"word\": \"引用标记\", \"pinyin\": \"yǐnyòng biāojì\", \"trans\": \"citation marking\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàngjià\", \"trans\": \"framework\"},\n    {\"word\": \"综合\", \"pinyin\": \"zōnghé\", \"trans\": \"comprehensive\"},\n    {\"word\": \"潜力\", \"pinyin\": \"qiánlì\", \"trans\": \"potential\"}\n]",
        "trans": "This article introduces Retrieval-Augmented Generation (RAG), a powerful paradigm that enhances large language models through external knowledge retrieval. Although RAG has received widespread attention, existing research primarily focuses on single-turn conversations, overlooking the complex multi-turn conversations encountered in real-world applications. To address this gap, the authors propose CORAL, a large-scale benchmark dataset for evaluating RAG systems in multi-turn conversations. CORAL includes diverse information-seeking dialogues, encompassing challenges such as open domains, knowledge intensity, free-form responses, and topic shifts. It supports three core tasks for conversational RAG: paragraph retrieval, response generation, and citation marking. The authors present a unified framework and conduct a comprehensive evaluation of various conversational RAG methods on CORAL, demonstrating the significant potential for improving existing methods.",
        "update_ts": "2024-10-31 09:22"
    }
}