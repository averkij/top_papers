{
    "date": {
        "ru": "26 июня",
        "en": "June 26",
        "zh": "6月26日"
    },
    "time_utc": "2025-06-26 03:44",
    "weekday": 3,
    "issue_id": 4494,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2506.18403",
            "title": "The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs",
            "url": "https://huggingface.co/papers/2506.18403",
            "abstract": "The Debugging Decay Index (DDI) quantifies and optimizes the effectiveness of iterative AI debugging by predicting intervention points to revive and enhance debugging capability.  \t\t\t\t\tAI-generated summary \t\t\t\t The effectiveness of AI debugging follows a predictable exponential decay pattern; most models lose 60-80% of their debugging capability within just 2-3 attempts, despite iterative debugging being a critical capability for practical code generation systems. We introduce the Debugging Decay Index (DDI), a mathematical framework that quantifies when debugging becomes ineffective and predicts intervention points. Our strategic fresh start approach shifts from exploitation to exploration at strategic points in the debugging process, demonstrating that well-timed interventions can rescue the effectiveness of debugging. DDI reveals a fundamental limitation in current AI debugging and provides the first quantitative framework for optimising iterative code generation strategies.",
            "score": 1,
            "issue_id": 4494,
            "pub_date": "2025-06-23",
            "pub_date_card": {
                "ru": "23 июня",
                "en": "June 23",
                "zh": "6月23日"
            },
            "hash": "30aa788d94afe45d",
            "authors": [
                "Muntasir Adnan",
                "Carlos C. N. Kuhn"
            ],
            "affiliations": [
                "Open Source Institute, University of Canberra, Bruce, Canberra, Australia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.18403.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#math"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Оптимизация отладки ИИ: измерение и преодоление затухания эффективности",
                    "desc": "Статья представляет Индекс Затухания Отладки (DDI), который количественно оценивает эффективность итеративной отладки ИИ. Авторы обнаружили, что способность моделей к отладке быстро снижается, следуя экспоненциальному паттерну затухания. DDI позволяет предсказать оптимальные точки вмешательства для восстановления эффективности отладки. Предложенный подход стратегического свежего старта демонстрирует, что своевременные вмешательства могут значительно улучшить процесс отладки кода."
                },
                "en": {
                    "title": "Reviving AI Debugging with Strategic Interventions",
                    "desc": "The Debugging Decay Index (DDI) is a new method that measures how quickly AI debugging abilities decline over time. It shows that most AI models lose a significant portion of their debugging skills after just a few attempts, which is a major issue for systems that generate code. By using DDI, developers can identify the best moments to intervene and improve the debugging process, shifting from refining existing solutions to exploring new ones. This approach not only highlights a key limitation in current AI debugging methods but also offers a way to enhance the effectiveness of iterative code generation."
                },
                "zh": {
                    "title": "优化AI调试的关键：调试衰减指数",
                    "desc": "调试衰减指数（DDI）量化并优化了迭代AI调试的有效性，通过预测干预点来恢复和增强调试能力。研究表明，AI调试的有效性遵循可预测的指数衰减模式，大多数模型在仅仅2-3次尝试后就会失去60-80%的调试能力。我们提出的DDI框架可以量化调试失效的时机，并预测干预点，从而在调试过程中实现从利用到探索的战略转变。DDI揭示了当前AI调试的基本局限性，并提供了优化迭代代码生成策略的首个定量框架。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.19502",
            "title": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility\n  Applications",
            "url": "https://huggingface.co/papers/2506.19502",
            "abstract": "MATE, a multimodal accessibility multi-agent system, converts data into understandable formats based on user needs, supporting various disabilities and integrating with institutional technologies.  \t\t\t\t\tAI-generated summary \t\t\t\t Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at https://github.com/AlgazinovAleksandr/Multi-Agent-MATE.",
            "score": 0,
            "issue_id": 4494,
            "pub_date": "2025-06-24",
            "pub_date_card": {
                "ru": "24 июня",
                "en": "June 24",
                "zh": "6月24日"
            },
            "hash": "85d844ff6061cc93",
            "authors": [
                "Aleksandr Algazinov",
                "Matt Laing",
                "Paul Laban"
            ],
            "affiliations": [
                "Dept. of Comp. Sci. & Tech. Tsinghua University Beijing, China",
                "Dept. of Psych. & Cog. Sci. Tsinghua University Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.19502.jpg",
            "data": {
                "categories": [
                    "#healthcare",
                    "#agents",
                    "#multimodal",
                    "#ethics",
                    "#open_source"
                ],
                "emoji": "♿",
                "ru": {
                    "title": "MATE: Интеллектуальная система для преодоления барьеров доступности",
                    "desc": "MATE - это мультимодальная система мультиагентов для обеспечения доступности, которая преобразует данные в понятные форматы в зависимости от потребностей пользователя. Система поддерживает различные виды инвалидности и может интегрироваться с институциональными технологиями. MATE использует широкий спектр моделей, от вызовов API больших языковых моделей до пользовательских классификаторов машинного обучения. Система включает в себя ModCon-Task-Identifier - модель, способную точно определять задачу преобразования модальности из пользовательского ввода."
                },
                "en": {
                    "title": "Empowering Accessibility Through Intelligent Data Conversion",
                    "desc": "MATE is a multimodal accessibility multi-agent system designed to convert data into formats that are understandable for users with disabilities. It addresses the limitations of existing multi-agent systems by providing customizable solutions that adapt to individual user needs. The system can perform tasks like converting images to audio descriptions, making digital content more accessible. Additionally, MATE integrates with institutional technologies and ensures user privacy by running locally, while its ModCon-Task-Identifier model excels in identifying specific modality conversion tasks."
                },
                "zh": {
                    "title": "MATE：为每个人提供无障碍的智能助手",
                    "desc": "MATE是一个多模态无障碍多代理系统，旨在根据用户需求将数据转换为可理解的格式，以支持各种残疾人士。该系统通过执行模态转换，帮助用户更好地与数字环境互动，例如将图像转换为音频描述，以满足视觉障碍者的需求。MATE具有灵活性，支持多种模型和硬件，确保能够适应不同的用户需求，并保护敏感信息的隐私和安全。通过与机构技术的有效集成，MATE能够提供实时的用户支持，提升无障碍服务的质量。"
                }
            }
        }
    ],
    "link_prev": "2025-06-25.html",
    "link_next": "2025-06-27.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "25.06",
        "en": "06/25",
        "zh": "6月25日"
    },
    "short_date_next": {
        "ru": "27.06",
        "en": "06/27",
        "zh": "6月27日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}