
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 9 papers. October 6.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">6 октября</span> | <span id="title-articles-count">9 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-10-03.html">⬅️ <span id="prev-date">03.10</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-10-07.html">➡️ <span id="next-date">07.10</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-10.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '6 октября', 'en': 'October 6', 'zh': '10月6日'};
        let feedDateNext = {'ru': '07.10', 'en': '10/07', 'zh': '10月7日'};
        let feedDatePrev = {'ru': '03.10', 'en': '10/03', 'zh': '10月3日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2510.01068', 'title': 'Compose Your Policies! Improving Diffusion-based or Flow-based Robot\n  Policies via Test-time Distribution-level Composition', 'url': 'https://huggingface.co/papers/2510.01068', 'abstract': 'General Policy Composition (GPC) enhances robotic control performance by combining pre-trained diffusion-based policies without additional training, leading to superior results across various benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion-based models for robotic control, including vision-language-action (VLA) and vision-action (VA) policies, have demonstrated significant capabilities. Yet their advancement is constrained by the high cost of acquiring large-scale interaction datasets. This work introduces an alternative paradigm for enhancing policy performance without additional model training. Perhaps surprisingly, we demonstrate that the composed policies can exceed the performance of either parent policy. Our contribution is threefold. First, we establish a theoretical foundation showing that the convex composition of distributional scores from multiple diffusion models can yield a superior one-step functional objective compared to any individual score. A Gr\\"onwall-type bound is then used to show that this single-step improvement propagates through entire generation trajectories, leading to systemic performance gains. Second, motivated by these results, we propose General Policy Composition (GPC), a training-free method that enhances performance by combining the distributional scores of multiple pre-trained policies via a convex combination and test-time search. GPC is versatile, allowing for the plug-and-play composition of heterogeneous policies, including VA and VLA models, as well as those based on diffusion or flow-matching, irrespective of their input visual modalities. Third, we provide extensive empirical validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside real-world robotic evaluations, confirm that GPC consistently improves performance and adaptability across a diverse set of tasks. Further analysis of alternative composition operators and weighting strategies offers insights into the mechanisms underlying the success of GPC. These results establish GPC as a simple yet effective method for improving control performance by leveraging existing policies.', 'score': 6, 'issue_id': 6252, 'pub_date': '2025-10-01', 'pub_date_card': {'ru': '1 октября', 'en': 'October 1', 'zh': '10月1日'}, 'hash': 'f7a26368ff58e67e', 'authors': ['Jiahang Cao', 'Yize Huang', 'Hanzhong Guo', 'Rui Zhang', 'Mu Nan', 'Weijian Mai', 'Jiaxu Wang', 'Hao Cheng', 'Jingkai Sun', 'Gang Han', 'Wen Zhao', 'Qiang Zhang', 'Yijie Guo', 'Qihao Zheng', 'Chunfeng Song', 'Xiao Li', 'Ping Luo', 'Andrew F. Luo'], 'affiliations': ['Beijing Innovation Center of Humanoid Robotics', 'Shanghai AI Lab', 'Shanghai Jiaotong University', 'The Hong Kong University of Science and Technology', 'The University of Hong Kong'], 'pdf_title_img': 'assets/pdf/title_img/2510.01068.jpg', 'data': {'categories': ['#training', '#robotics', '#optimization', '#benchmark', '#diffusion', '#agents'], 'emoji': '🤝', 'ru': {'title': 'Композиция policy без обучения превосходит отдельные модели', 'desc': 'Статья представляет метод General Policy Composition (GPC), который позволяет улучшить производительность робототехнических систем путём композиции нескольких предобученных diffusion-моделей без дополнительного обучения. Авторы доказывают теоретически, что выпуклая комбинация распределений от разных моделей может превзойти каждую отдельную policy. GPC работает с гетерогенными моделями — vision-language-action (VLA) и vision-action (VA), основанными на diffusion или flow-matching. Эксперименты на бенчмарках Robomimic, PushT, RoboTwin и реальных роботах подтверждают стабильное улучшение качества управления.'}, 'en': {'title': 'Enhancing Robotic Control with Policy Composition', 'desc': 'General Policy Composition (GPC) is a novel approach that enhances robotic control by combining pre-trained diffusion-based policies without the need for additional training. This method leverages the strengths of multiple policies, including vision-language-action and vision-action models, to achieve superior performance on various benchmarks. The theoretical foundation of GPC shows that combining distributional scores from different models can lead to better outcomes than using any single model alone. Extensive experiments demonstrate that GPC not only improves performance but also increases adaptability across diverse robotic tasks, making it a versatile tool in the field of robotic control.'}, 'zh': {'title': '通用策略组合：提升机器人控制性能的新方法', 'desc': '本文提出了一种名为通用策略组合（GPC）的方法，旨在通过结合预训练的扩散模型策略来提升机器人控制性能，而无需额外的训练。研究表明，组合后的策略在多个基准测试中表现优于单独的父策略。GPC利用凸组合的方式，将多个策略的分布得分进行结合，从而实现系统性的性能提升。通过在多个机器人任务上的实验证明，GPC在提高适应性和性能方面表现出色。'}}}, {'id': 'https://huggingface.co/papers/2510.02665', 'title': 'Self-Improvement in Multimodal Large Language Models: A Survey', 'url': 'https://huggingface.co/papers/2510.02665', 'abstract': 'A survey of self-improvement methods in Multimodal Large Language Models (MLLMs) from data collection, organization, and model optimization perspectives.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advancements in self-improvement for Large Language Models (LLMs) have efficiently enhanced model capabilities without significantly increasing costs, particularly in terms of human effort. While this area is still relatively young, its extension to the multimodal domain holds immense potential for leveraging diverse data sources and developing more general self-improving models. This survey is the first to provide a comprehensive overview of self-improvement in Multimodal LLMs (MLLMs). We provide a structured overview of the current literature and discuss methods from three perspectives: 1) data collection, 2) data organization, and 3) model optimization, to facilitate the further development of self-improvement in MLLMs. We also include commonly used evaluations and downstream applications. Finally, we conclude by outlining open challenges and future research directions.', 'score': 4, 'issue_id': 6252, 'pub_date': '2025-10-03', 'pub_date_card': {'ru': '3 октября', 'en': 'October 3', 'zh': '10月3日'}, 'hash': 'a7980db6477e39f7', 'authors': ['Shijian Deng', 'Kai Wang', 'Tianyu Yang', 'Harsh Singh', 'Yapeng Tian'], 'affiliations': ['Mohamed bin Zayed University of Artificial Intelligence', 'The University of Texas at Dallas', 'University of Notre Dame', 'University of Toronto'], 'pdf_title_img': 'assets/pdf/title_img/2510.02665.jpg', 'data': {'categories': ['#training', '#survey', '#optimization', '#multimodal', '#data', '#dataset'], 'emoji': '🔄', 'ru': {'title': 'Мультимодальные LLM учатся сами: обзор методов самосовершенствования', 'desc': 'Статья представляет первый комплексный обзор методов самосовершенствования мультимодальных LLM. Авторы систематизируют существующие подходы с трёх ключевых точек зрения: сбор данных, организация данных и оптимизация моделей. Самосовершенствование позволяет улучшать возможности моделей без значительного увеличения затрат и человеческих усилий. В работе также обсуждаются методы оценки, практические применения и открытые проблемы в этой развивающейся области исследований.'}, 'en': {'title': 'Unlocking Potential: Self-Improvement in Multimodal Language Models', 'desc': 'This paper surveys self-improvement methods in Multimodal Large Language Models (MLLMs), focusing on how to enhance model performance through better data handling and optimization techniques. It highlights the importance of efficiently collecting and organizing diverse data sources to improve model capabilities without incurring high costs. The authors provide a structured overview of existing literature and categorize methods into three main areas: data collection, data organization, and model optimization. Additionally, the paper discusses evaluation metrics and potential applications, while identifying challenges and future research opportunities in the field.'}, 'zh': {'title': '多模态语言模型的自我改进潜力', 'desc': '本论文对多模态大型语言模型（MLLMs）中的自我改进方法进行了全面调查。我们从数据收集、数据组织和模型优化三个角度，系统性地回顾了当前文献，探讨了如何有效提升模型能力。尽管这一领域仍在发展中，但其在多模态领域的扩展具有巨大的潜力，可以利用多样的数据源。最后，我们总结了当前面临的挑战和未来的研究方向。'}}}, {'id': 'https://huggingface.co/papers/2510.01879', 'title': 'REPAIR: Robust Editing via Progressive Adaptive Intervention and\n  Reintegration', 'url': 'https://huggingface.co/papers/2510.01879', 'abstract': 'REPAIR is a lifelong editing framework for large language models that enhances editing accuracy and reduces knowledge forgetting through progressive adaptive intervention and reintegration.  \t\t\t\t\tAI-generated summary \t\t\t\t Post-training for large language models (LLMs) is constrained by the high cost of acquiring new knowledge or correcting errors and by the unintended side effects that frequently arise from retraining. To address these issues, we introduce REPAIR (Robust Editing via Progressive Adaptive Intervention and Reintegration), a lifelong editing framework designed to support precise and low-cost model updates while preserving non-target knowledge. REPAIR mitigates the instability and conflicts of large-scale sequential edits through a closed-loop feedback mechanism coupled with dynamic memory management. Furthermore, by incorporating frequent knowledge fusion and enforcing strong locality guards, REPAIR effectively addresses the shortcomings of traditional distribution-agnostic approaches that often overlook unintended ripple effects. Our experiments demonstrate that REPAIR boosts editing accuracy by 10%-30% across multiple model families and significantly reduces knowledge forgetting. This work introduces a robust framework for developing reliable, scalable, and continually evolving LLMs.', 'score': 2, 'issue_id': 6253, 'pub_date': '2025-10-02', 'pub_date_card': {'ru': '2 октября', 'en': 'October 2', 'zh': '10月2日'}, 'hash': '6a90da50c87cca3c', 'authors': ['Yisu Wang', 'Ming Wang', 'Haoyuan Song', 'Wenjie Huang', 'Chaozheng Wang', 'Yi Xie', 'Xuming Ran'], 'affiliations': ['ContiAI Research'], 'pdf_title_img': 'assets/pdf/title_img/2510.01879.jpg', 'data': {'categories': ['#optimization', '#training', '#inference'], 'emoji': '🔧', 'ru': {'title': 'Непрерывное обучение языковых моделей без забывания знаний', 'desc': 'В статье представлен фреймворк REPAIR для редактирования больших языковых моделей (LLM), который позволяет исправлять ошибки и добавлять новые знания без дорогостоящего переобучения. Метод использует механизм обратной связи и динамическое управление памятью для последовательного внесения изменений без конфликтов. Частое слияние знаний и строгий контроль локальности изменений помогают избежать нежелательных побочных эффектов при обновлении модели. Эксперименты показали повышение точности редактирования на 10-30% и значительное снижение забывания ранее изученной информации.'}, 'en': {'title': 'Enhancing Language Models with REPAIR: Accurate, Cost-effective, and Knowledge-preserving Editing', 'desc': 'REPAIR is a framework designed to improve the editing process of large language models (LLMs) by making it more accurate and cost-effective. It allows models to learn new information or correct mistakes without losing previously learned knowledge. The framework uses a feedback system and manages memory dynamically to handle multiple edits without causing conflicts. Experiments show that REPAIR increases editing accuracy significantly while minimizing knowledge loss, making it a valuable tool for evolving LLMs.'}, 'zh': {'title': 'REPAIR：提升语言模型编辑准确性的终身框架', 'desc': 'REPAIR是一个针对大型语言模型的终身编辑框架，旨在提高编辑的准确性并减少知识遗忘。它通过渐进式的适应性干预和再整合来实现低成本的模型更新，同时保护非目标知识。REPAIR采用闭环反馈机制和动态记忆管理，缓解了大规模顺序编辑带来的不稳定性和冲突。实验结果表明，REPAIR在多个模型家族中提高了10%-30%的编辑准确性，并显著减少了知识遗忘。'}}}, {'id': 'https://huggingface.co/papers/2510.03230', 'title': 'Improving GUI Grounding with Explicit Position-to-Coordinate Mapping', 'url': 'https://huggingface.co/papers/2510.03230', 'abstract': 'Explicit coordinate markers and improved spatial encoding enhance GUI grounding accuracy across diverse resolutions and platforms.  \t\t\t\t\tAI-generated summary \t\t\t\t GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains difficult for current VLMs. The core bottleneck is reliable patch-to-pixel mapping, which breaks when extrapolating to high-resolution displays unseen during training. Current approaches generate coordinates as text tokens directly from visual features, forcing the model to infer complex position-to-pixel mappings implicitly; as a result, accuracy degrades and failures proliferate on new resolutions. We address this with two complementary innovations. First, RULER tokens serve as explicit coordinate markers, letting the model reference positions similar to gridlines on a map and adjust rather than generate coordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial encoding by ensuring that width and height dimensions are represented equally, addressing the asymmetry of standard positional schemes. Experiments on ScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in grounding accuracy, with the largest improvements on high-resolution interfaces. By providing explicit spatial guidance rather than relying on implicit learning, our approach enables more reliable GUI automation across diverse resolutions and platforms.', 'score': 1, 'issue_id': 6252, 'pub_date': '2025-10-03', 'pub_date_card': {'ru': '3 октября', 'en': 'October 3', 'zh': '10月3日'}, 'hash': '8911479d98450376', 'authors': ['Suyuchen Wang', 'Tianyu Zhang', 'Ahmed Masry', 'Christopher Pal', 'Spandana Gella', 'Bang Liu', 'Perouz Taslakian'], 'affiliations': ['CIFAR AI Chair', 'McGill University', 'Mila - Quebec AI Institute', 'Polytechnique Montreal', 'ServiceNow', 'Universite de Montreal', 'York University'], 'pdf_title_img': 'assets/pdf/title_img/2510.03230.jpg', 'data': {'categories': ['#interpretability', '#agents', '#cv', '#optimization'], 'emoji': '🎯', 'ru': {'title': 'Явные координаты вместо угадывания: как научить модели точно находить элементы интерфейса', 'desc': 'Статья посвящена проблеме GUI grounding — задаче сопоставления текстовых инструкций с координатами пикселей на экране, что критично для автономных AI-агентов. Основная сложность заключается в том, что современные vision-language модели плохо экстраполируют на высокие разрешения экранов, не встреченные при обучении. Авторы предлагают два решения: RULER tokens — явные маркеры координат, работающие как линии сетки на карте, и Interleaved MRoPE (I-MRoPE) — улучшенное позиционное кодирование, которое равномерно представляет ширину и высоту. Эксперименты показывают значительное улучшение точности определения элементов интерфейса, особенно на экранах высокого разрешения.'}, 'en': {'title': 'Enhancing GUI Grounding with Explicit Spatial Markers', 'desc': 'This paper focuses on improving GUI grounding, which is the process of translating natural language commands into specific pixel locations on a screen. The authors identify that existing vision-language models (VLMs) struggle with high-resolution displays due to their reliance on implicit mappings from visual features to pixel coordinates. To overcome this, they introduce RULER tokens as explicit coordinate markers, allowing the model to reference positions more accurately. Additionally, they propose Interleaved MRoPE (I-MRoPE) to enhance spatial encoding, ensuring that both width and height are treated equally, leading to significant improvements in grounding accuracy across various resolutions.'}, 'zh': {'title': '提升GUI定位准确性的创新方法', 'desc': '本文探讨了图形用户界面（GUI）定位的挑战，尤其是在高分辨率显示器上的准确性问题。当前的视觉语言模型（VLMs）在将自然语言指令映射到像素坐标时，面临着可靠的补丁到像素映射的瓶颈。为了解决这个问题，作者提出了两种创新方法：使用RULER标记作为明确的坐标标记，以及改进空间编码的交错MRoPE（I-MRoPE）。实验结果表明，这些方法在不同分辨率和平台上显著提高了GUI定位的准确性。'}}}, {'id': 'https://huggingface.co/papers/2510.03204', 'title': 'FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of\n  Web Agents', 'url': 'https://huggingface.co/papers/2510.03204', 'abstract': 'FocusAgent uses a lightweight LLM retriever to extract relevant content from web page observations, improving efficiency and security in web agents.  \t\t\t\t\tAI-generated summary \t\t\t\t Web agents powered by large language models (LLMs) must process lengthy web page observations to complete user goals; these pages often exceed tens of thousands of tokens. This saturates context limits and increases computational cost processing; moreover, processing full pages exposes agents to security risks such as prompt injection. Existing pruning strategies either discard relevant content or retain irrelevant context, leading to suboptimal action prediction. We introduce FocusAgent, a simple yet effective approach that leverages a lightweight LLM retriever to extract the most relevant lines from accessibility tree (AxTree) observations, guided by task goals. By pruning noisy and irrelevant content, FocusAgent enables efficient reasoning while reducing vulnerability to injection attacks. Experiments on WorkArena and WebArena benchmarks show that FocusAgent matches the performance of strong baselines, while reducing observation size by over 50%. Furthermore, a variant of FocusAgent significantly reduces the success rate of prompt-injection attacks, including banner and pop-up attacks, while maintaining task success performance in attack-free settings. Our results highlight that targeted LLM-based retrieval is a practical and robust strategy for building web agents that are efficient, effective, and secure.', 'score': 1, 'issue_id': 6252, 'pub_date': '2025-10-03', 'pub_date_card': {'ru': '3 октября', 'en': 'October 3', 'zh': '10月3日'}, 'hash': 'cff617954ead65b4', 'authors': ['Imene Kerboua', 'Sahar Omidi Shayegan', 'Megh Thakkar', 'Xing Han Lù', 'Léo Boisvert', 'Massimo Caccia', 'Jérémy Espinas', 'Alexandre Aussem', 'Véronique Eglin', 'Alexandre Lacoste'], 'affiliations': ['Esker', 'LIRIS - CNRS, INSA Lyon, Universite Claude Bernard Lyon 1', 'McGill University', 'Mila - Quebec AI Institute', 'Polytechnique Montréal', 'ServiceNow Research'], 'pdf_title_img': 'assets/pdf/title_img/2510.03204.jpg', 'data': {'categories': ['#long_context', '#inference', '#benchmark', '#agents', '#security', '#reasoning'], 'emoji': '🎯', 'ru': {'title': 'Фокусировка внимания веб-агентов для эффективности и безопасности', 'desc': 'FocusAgent — это подход для создания веб-агентов на основе LLM, который использует лёгкий retriever для извлечения релевантного контента из веб-страниц. Проблема в том, что веб-страницы часто содержат десятки тысяч токенов, что создаёт нагрузку на контекст и увеличивает вычислительные затраты, а также открывает уязвимости для prompt injection атак. FocusAgent фильтрует accessibility tree наблюдений, оставляя только важные строки согласно цели задачи, сокращая размер наблюдений более чем на 50% без потери качества. Эксперименты показывают, что метод не только сохраняет производительность на бенчмарках WorkArena и WebArena, но и значительно повышает защищённость от инъекций промптов.'}, 'en': {'title': 'Efficient and Secure Web Agents with FocusAgent', 'desc': 'FocusAgent is a novel approach that enhances the efficiency and security of web agents using a lightweight LLM retriever. It extracts the most relevant information from lengthy web page observations, which often contain excessive tokens that can overwhelm processing capabilities. By focusing on task-specific content and eliminating irrelevant data, FocusAgent minimizes computational costs and reduces the risk of security threats like prompt injection. Experimental results demonstrate that it not only maintains performance comparable to existing methods but also significantly decreases the amount of data processed, leading to safer and more effective web interactions.'}, 'zh': {'title': 'FocusAgent：高效安全的网页代理解决方案', 'desc': 'FocusAgent 是一种轻量级的 LLM 检索器，旨在从网页观察中提取相关内容，从而提高网络代理的效率和安全性。传统的大型语言模型在处理长达数万标记的网页时，容易导致上下文限制饱和和计算成本增加，同时也增加了安全风险。FocusAgent 通过从可访问性树（AxTree）观察中提取最相关的行，减少了噪声和无关内容，使推理过程更加高效，并降低了注入攻击的脆弱性。实验结果表明，FocusAgent 在保持任务成功率的同时，观察大小减少超过 50%，并显著降低了提示注入攻击的成功率。'}}}, {'id': 'https://huggingface.co/papers/2510.03160', 'title': 'SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the\n  SpineMed-450k Corpus', 'url': 'https://huggingface.co/papers/2510.03160', 'abstract': "SpineMed, an ecosystem with SpineMed-450k and SpineBench, addresses the lack of level-aware, multimodal datasets and benchmarks for AI-assisted diagnosis of spine disorders, improving model performance through fine-grained, level-specific reasoning.  \t\t\t\t\tAI-generated summary \t\t\t\t Spine disorders affect 619 million people globally and are a leading cause of disability, yet AI-assisted diagnosis remains limited by the lack of level-aware, multimodal datasets. Clinical decision-making for spine disorders requires sophisticated reasoning across X-ray, CT, and MRI at specific vertebral levels. However, progress has been constrained by the absence of traceable, clinically-grounded instruction data and standardized, spine-specific benchmarks. To address this, we introduce SpineMed, an ecosystem co-designed with practicing spine surgeons. It features SpineMed-450k, the first large-scale dataset explicitly designed for vertebral-level reasoning across imaging modalities with over 450,000 instruction instances, and SpineBench, a clinically-grounded evaluation framework. SpineMed-450k is curated from diverse sources, including textbooks, guidelines, open datasets, and ~1,000 de-identified hospital cases, using a clinician-in-the-loop pipeline with a two-stage LLM generation method (draft and revision) to ensure high-quality, traceable data for question-answering, multi-turn consultations, and report generation. SpineBench evaluates models on clinically salient axes, including level identification, pathology assessment, and surgical planning. Our comprehensive evaluation of several recently advanced large vision-language models (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained, level-specific reasoning. In contrast, our model fine-tuned on SpineMed-450k demonstrates consistent and significant improvements across all tasks. Clinician assessments confirm the diagnostic clarity and practical utility of our model's outputs.", 'score': 1, 'issue_id': 6253, 'pub_date': '2025-10-03', 'pub_date_card': {'ru': '3 октября', 'en': 'October 3', 'zh': '10月3日'}, 'hash': 'bd9504c9850d0415', 'authors': ['Ming Zhao', 'Wenhui Dong', 'Yang Zhang', 'Xiang Zheng', 'Zhonghao Zhang', 'Zian Zhou', 'Yunzhi Guan', 'Liukun Xu', 'Wei Peng', 'Zhaoyang Gong', 'Zhicheng Zhang', 'Dachuan Li', 'Xiaosheng Ma', 'Yuli Ma', 'Jianing Ni', 'Changjiang Jiang', 'Lixia Tian', 'Qixin Chen', 'Kaishun Xia', 'Pingping Liu', 'Tongshun Zhang', 'Zhiqiang Liu', 'Zhongan Bi', 'Chenyang Si', 'Tiansheng Sun', 'Caifeng Shan'], 'affiliations': ['Beijing Jiaotong University', 'Institute of Automation, Chinese Academy of Sciences', 'Jilin University', 'Nanjing University', 'Ningxia University', 'Stanford University', 'The General Hospital of the Peoples Liberation Army', 'Wuhan University', 'Zhejiang University', 'π3 Lab'], 'pdf_title_img': 'assets/pdf/title_img/2510.03160.jpg', 'data': {'categories': ['#reasoning', '#training', '#healthcare', '#benchmark', '#dataset', '#multimodal', '#science'], 'emoji': '🦴', 'ru': {'title': 'SpineMed: AI-система для точной диагностики позвоночника на уровне отдельных позвонков', 'desc': 'Статья представляет SpineMed — экосистему для AI-диагностики заболеваний позвоночника, включающую датасет SpineMed-450k с 450 тысячами примеров и бенчмарк SpineBench. Ключевая особенность — способность моделей анализировать конкретные уровни позвонков на рентгене, КТ и МРТ, что критично для клинической диагностики. Датасет создан при участии практикующих хирургов с использованием двухэтапной генерации данных через LLM (черновик и ревизия). Эксперименты показали, что современные vision-language модели плохо справляются с детальным анализом конкретных позвонков, но файн-тюнинг на SpineMed-450k значительно улучшает качество диагностики.'}, 'en': {'title': 'Revolutionizing Spine Disorder Diagnosis with Level-Aware AI', 'desc': 'The paper introduces SpineMed, an innovative ecosystem designed to enhance AI-assisted diagnosis of spine disorders by providing level-aware, multimodal datasets and benchmarks. It features SpineMed-450k, a large-scale dataset with over 450,000 instances specifically curated for vertebral-level reasoning using a clinician-in-the-loop approach. The accompanying SpineBench framework allows for comprehensive evaluation of AI models on critical clinical tasks such as level identification and pathology assessment. Results show that models fine-tuned on SpineMed-450k significantly outperform existing large vision-language models in fine-grained reasoning, demonstrating improved diagnostic clarity and utility in clinical settings.'}, 'zh': {'title': '脊柱疾病AI诊断的新突破', 'desc': 'SpineMed是一个针对脊柱疾病的人工智能辅助诊断生态系统，包含SpineMed-450k数据集和SpineBench评估框架。该系统解决了缺乏针对脊柱特定层次的多模态数据集的问题，提供了超过45万个高质量的指令实例。通过与脊柱外科医生合作，SpineMed确保了数据的临床相关性和可追溯性。我们的研究表明，基于SpineMed-450k微调的模型在各项任务中表现出显著的性能提升。'}}}, {'id': 'https://huggingface.co/papers/2510.03120', 'title': 'SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?', 'url': 'https://huggingface.co/papers/2510.03120', 'abstract': "A new evaluation framework, SurveyBench, assesses the quality of automatically generated academic surveys using a quiz-driven approach, revealing deficiencies in current LLM4Survey methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Academic survey writing, which distills vast literature into a coherent and insightful narrative, remains a labor-intensive and intellectually demanding task. While recent approaches, such as general DeepResearch agents and survey-specialized methods, can generate surveys automatically (a.k.a. LLM4Survey), their outputs often fall short of human standards and there lacks a rigorous, reader-aligned benchmark for thoroughly revealing their deficiencies. To fill the gap, we propose a fine-grained, quiz-driven evaluation framework SurveyBench, featuring (1) typical survey topics source from recent 11,343 arXiv papers and corresponding 4,947 high-quality surveys; (2) a multifaceted metric hierarchy that assesses the outline quality (e.g., coverage breadth, logical coherence), content quality (e.g., synthesis granularity, clarity of insights), and non-textual richness; and (3) a dual-mode evaluation protocol that includes content-based and quiz-based answerability tests, explicitly aligned with readers' informational needs. Results show SurveyBench effectively challenges existing LLM4Survey approaches (e.g., on average 21% lower than human in content-based evaluation).", 'score': 1, 'issue_id': 6252, 'pub_date': '2025-10-03', 'pub_date_card': {'ru': '3 октября', 'en': 'October 3', 'zh': '10月3日'}, 'hash': '9114023adb7490f9', 'authors': ['Zhaojun Sun', 'Xuzhou Zhu', 'Xuanhe Zhou', 'Xin Tong', 'Shuo Wang', 'Jie Fu', 'Guoliang Li', 'Zhiyuan Liu', 'Fan Wu'], 'affiliations': ['Shanghai AI Laboratory', 'Shanghai Jiao Tong University', 'Tsinghua University'], 'pdf_title_img': 'assets/pdf/title_img/2510.03120.jpg', 'data': {'categories': ['#survey', '#benchmark'], 'emoji': '📊', 'ru': {'title': 'SurveyBench: бенчмарк для проверки AI-генерации научных обзоров через викторины', 'desc': 'Исследователи представили SurveyBench — новый фреймворк для оценки качества автоматически сгенерированных научных обзоров с помощью LLM. Система использует quiz-driven подход и оценивает структуру обзора, качество контента и наличие нетекстовых элементов на основе 11,343 статей с arXiv и 4,947 высококачественных обзоров. Результаты показывают, что современные LLM4Survey методы в среднем на 21% хуже справляются с задачей по сравнению с человеком. Фреймворк включает двухрежимную оценку, которая проверяет способность сгенерированных обзоров отвечать на вопросы читателей.'}, 'en': {'title': 'SurveyBench: Elevating AI-Generated Academic Surveys', 'desc': 'The paper introduces SurveyBench, a new evaluation framework designed to assess the quality of automatically generated academic surveys. It highlights the limitations of current LLM4Survey methods, which often fail to meet human standards in survey writing. SurveyBench utilizes a quiz-driven approach and a comprehensive metric hierarchy to evaluate both outline and content quality, ensuring alignment with reader needs. The results demonstrate that existing methods significantly underperform compared to human-generated surveys, with an average score 21% lower in content-based evaluations.'}, 'zh': {'title': 'SurveyBench：提升自动生成学术调查的评估标准', 'desc': '本论文提出了一种新的评估框架SurveyBench，用于评估自动生成的学术调查的质量。该框架采用基于测验的方法，揭示了当前LLM4Survey方法的不足之处。SurveyBench通过分析来自11,343篇arXiv论文的典型调查主题和4,947篇高质量调查，建立了多层次的评估指标体系。研究结果表明，SurveyBench在内容评估中平均比人类低21%，有效挑战了现有的LLM4Survey方法。'}}}, {'id': 'https://huggingface.co/papers/2510.02571', 'title': 'How Confident are Video Models? Empowering Video Models to Express their\n  Uncertainty', 'url': 'https://huggingface.co/papers/2510.02571', 'abstract': 'A framework for uncertainty quantification in generative video models is introduced, including a metric for calibration, a black-box method called S-QUBED, and a benchmark dataset, demonstrating improved uncertainty estimates and task accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Generative video models demonstrate impressive text-to-video capabilities, spurring widespread adoption in many real-world applications. However, like large language models (LLMs), video generation models tend to hallucinate, producing plausible videos even when they are factually wrong. Although uncertainty quantification (UQ) of LLMs has been extensively studied in prior work, no UQ method for video models exists, raising critical safety concerns. To our knowledge, this paper represents the first work towards quantifying the uncertainty of video models. We present a framework for uncertainty quantification of generative video models, consisting of: (i) a metric for evaluating the calibration of video models based on robust rank correlation estimation with no stringent modeling assumptions; (ii) a black-box UQ method for video models (termed S-QUBED), which leverages latent modeling to rigorously decompose predictive uncertainty into its aleatoric and epistemic components; and (iii) a UQ dataset to facilitate benchmarking calibration in video models. By conditioning the generation task in the latent space, we disentangle uncertainty arising due to vague task specifications from that arising from lack of knowledge. Through extensive experiments on benchmark video datasets, we demonstrate that S-QUBED computes calibrated total uncertainty estimates that are negatively correlated with the task accuracy and effectively computes the aleatoric and epistemic constituents.', 'score': 1, 'issue_id': 6252, 'pub_date': '2025-10-02', 'pub_date_card': {'ru': '2 октября', 'en': 'October 2', 'zh': '10月2日'}, 'hash': '6e5849ca43586c8a', 'authors': ['Zhiting Mei', 'Ola Shorinwa', 'Anirudha Majumdar'], 'affiliations': ['Princeton University'], 'pdf_title_img': 'assets/pdf/title_img/2510.02571.jpg', 'data': {'categories': ['#optimization', '#benchmark', '#hallucinations', '#dataset', '#video'], 'emoji': '🎬', 'ru': {'title': 'Когда AI не уверен в своём видео', 'desc': 'Исследователи представили первый фреймворк для количественной оценки неопределённости в генеративных видеомоделях, которые, как и LLM, склонны к галлюцинациям. Разработан метод S-QUBED, разделяющий неопределённость на алеаторную (из-за неясных формулировок задачи) и эпистемическую (из-за недостатка знаний модели) компоненты через моделирование в латентном пространстве. Предложена метрика калибровки на основе ранговой корреляции и создан специальный benchmark-датасет для оценки. Эксперименты показали, что метод даёт калиброванные оценки неопределённости, которые коррелируют с точностью выполнения задач.'}, 'en': {'title': 'Quantifying Uncertainty in Generative Video Models for Safer AI', 'desc': "This paper introduces a new framework for measuring uncertainty in generative video models, which is crucial for ensuring their reliability in real-world applications. It presents a novel metric for assessing how well these models predict uncertainty, along with a black-box method called S-QUBED that separates different types of uncertainty. The framework also includes a benchmark dataset to evaluate the performance of video models in terms of their uncertainty calibration. Through experiments, the authors show that S-QUBED provides accurate uncertainty estimates that correlate with the models' task performance, addressing safety concerns in video generation."}, 'zh': {'title': '生成视频模型的不确定性量化新框架', 'desc': '本文提出了一种用于生成视频模型的不确定性量化框架，包括一个用于校准的度量标准、一种称为S-QUBED的黑箱方法，以及一个基准数据集。生成视频模型在文本到视频的能力上表现出色，但也存在幻觉现象，即生成的内容可能在事实上一无是处。尽管对大型语言模型的不确定性量化已有大量研究，但目前尚无针对视频模型的不确定性量化方法，这引发了安全隐患。我们的研究首次量化了视频模型的不确定性，并通过实验验证了S-QUBED在校准总不确定性估计方面的有效性。'}}}, {'id': 'https://huggingface.co/papers/2509.25771', 'title': 'Free Lunch Alignment of Text-to-Image Diffusion Models without\n  Preference Image Pairs', 'url': 'https://huggingface.co/papers/2509.25771', 'abstract': 'A new framework, Text Preference Optimization (TPO), aligns text-to-image models with human preferences without requiring paired image preference data, improving text-to-image alignment and human preference scores.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in diffusion-based text-to-image (T2I) models have led to remarkable success in generating high-quality images from textual prompts. However, ensuring accurate alignment between the text and the generated image remains a significant challenge for state-of-the-art diffusion models. To address this, existing studies employ reinforcement learning with human feedback (RLHF) to align T2I outputs with human preferences. These methods, however, either rely directly on paired image preference data or require a learned reward function, both of which depend heavily on costly, high-quality human annotations and thus face scalability limitations. In this work, we introduce Text Preference Optimization (TPO), a framework that enables "free-lunch" alignment of T2I models, achieving alignment without the need for paired image preference data. TPO works by training the model to prefer matched prompts over mismatched prompts, which are constructed by perturbing original captions using a large language model. Our framework is general and compatible with existing preference-based algorithms. We extend both DPO and KTO to our setting, resulting in TDPO and TKTO. Quantitative and qualitative evaluations across multiple benchmarks show that our methods consistently outperform their original counterparts, delivering better human preference scores and improved text-to-image alignment. Our Open-source code is available at https://github.com/DSL-Lab/T2I-Free-Lunch-Alignment.', 'score': 1, 'issue_id': 6253, 'pub_date': '2025-09-30', 'pub_date_card': {'ru': '30 сентября', 'en': 'September 30', 'zh': '9月30日'}, 'hash': '6c93440c081695bd', 'authors': ['Jia Jun Cheng Xian', 'Muchen Li', 'Haotian Yang', 'Xin Tao', 'Pengfei Wan', 'Leonid Sigal', 'Renjie Liao'], 'affiliations': ['Canada CIFAR AI Chair', 'Kling Team, Kuaishou Technology', 'University of British Columbia', 'Vector Institute for AI'], 'pdf_title_img': 'assets/pdf/title_img/2509.25771.jpg', 'data': {'categories': ['#open_source', '#alignment', '#benchmark', '#rlhf', '#multimodal', '#diffusion'], 'emoji': '🎯', 'ru': {'title': 'Бесплатное выравнивание: обучение без парных предпочтений', 'desc': 'Представлен фреймворк Text Preference Optimization (TPO) для выравнивания text-to-image моделей с человеческими предпочтениями без использования парных данных о предпочтениях изображений. Метод обучает модель предпочитать правильные текстовые промпты перед искажёнными версиями, которые создаются с помощью LLM. TPO совместим с существующими алгоритмами на основе предпочтений, такими как DPO и KTO, расширяя их до версий TDPO и TKTO. Эксперименты показывают стабильное улучшение качества выравнивания текста с изображением и более высокие оценки человеческих предпочтений по сравнению с оригинальными методами.'}, 'en': {'title': 'Aligning Text and Images: A Free-Lunch Approach!', 'desc': 'The paper introduces a new framework called Text Preference Optimization (TPO) that enhances the alignment of text-to-image (T2I) models with human preferences without needing paired image preference data. This approach addresses the limitations of existing methods that rely on costly human annotations and reinforcement learning with human feedback (RLHF). TPO trains models to prefer correctly matched text-image pairs over mismatched ones, using perturbations generated by a large language model. The results demonstrate that TPO significantly improves human preference scores and T2I alignment compared to traditional methods, making it a scalable solution for better image generation.'}, 'zh': {'title': '文本偏好优化：无须配对数据的对齐新方法', 'desc': '本文提出了一种新的框架，称为文本偏好优化（TPO），旨在在不需要配对图像偏好数据的情况下，使文本到图像模型与人类偏好对齐。该框架通过训练模型更倾向于匹配的提示，而不是通过扰动原始标题生成的不匹配提示，从而实现对齐。TPO与现有的基于偏好的算法兼容，并扩展了DPO和KTO，形成了TDPO和TKTO。实验结果表明，TPO在多个基准测试中表现优于传统方法，提供了更好的文本到图像对齐和人类偏好评分。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents (3)', '#agi', '#alignment (1)', '#architecture', '#audio', '#benchmark (6)', '#cv (1)', '#data (1)', '#dataset (3)', '#diffusion (2)', '#ethics', '#games', '#graphs', '#hallucinations (1)', '#healthcare (1)', '#inference (2)', '#interpretability (1)', '#leakage', '#long_context (1)', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal (3)', '#open_source (1)', '#optimization (5)', '#plp', '#rag', '#reasoning (2)', '#rl', '#rlhf (1)', '#robotics (1)', '#science (1)', '#security (1)', '#small_models', '#story_generation', '#survey (2)', '#synthetic', '#training (4)', '#transfer_learning', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-10-06 03:30',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-10-06 03:30')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-10-06 03:30')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    