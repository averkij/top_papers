{
    "date": {
        "ru": "13 марта",
        "en": "March 13",
        "zh": "3月13日"
    },
    "time_utc": "2025-03-13 03:22",
    "weekday": 3,
    "issue_id": 2677,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.09427",
            "title": "Multimodal Language Modeling for High-Accuracy Single Cell\n  Transcriptomics Analysis and Generation",
            "url": "https://huggingface.co/papers/2503.09427",
            "abstract": "Pre-trained language models (PLMs) have revolutionized scientific research, yet their application to single-cell analysis remains limited. Text PLMs cannot process single-cell RNA sequencing data, while cell PLMs lack the ability to handle free text, restricting their use in multimodal tasks. Existing efforts to bridge these modalities often suffer from information loss or inadequate single-modal pre-training, leading to suboptimal performances. To address these challenges, we propose Single-Cell MultiModal Generative Pre-trained Transformer (scMMGPT), a unified PLM for joint cell and text modeling. scMMGPT effectively integrates the state-of-the-art cell and text PLMs, facilitating cross-modal knowledge sharing for improved performance. To bridge the text-cell modality gap, scMMGPT leverages dedicated cross-modal projectors, and undergoes extensive pre-training on 27 million cells -- the largest dataset for multimodal cell-text PLMs to date. This large-scale pre-training enables scMMGPT to excel in joint cell-text tasks, achieving an 84\\% relative improvement of textual discrepancy for cell description generation, 20.5\\% higher accuracy for cell type annotation, and 4\\% improvement in k-NN accuracy for text-conditioned pseudo-cell generation, outperforming baselines.",
            "score": 1,
            "issue_id": 2677,
            "pub_date": "2025-03-12",
            "pub_date_card": {
                "ru": "12 марта",
                "en": "March 12",
                "zh": "3月12日"
            },
            "hash": "491beb48064068d2",
            "authors": [
                "Yaorui Shi",
                "Jiaqi Yang",
                "Sihang Li",
                "Junfeng Fang",
                "Xiang Wang",
                "Zhiyuan Liu",
                "Yang Zhang"
            ],
            "affiliations": [
                "National University of Singapore",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.09427.jpg",
            "data": {
                "categories": [
                    "#plp",
                    "#transfer_learning",
                    "#science",
                    "#multimodal",
                    "#dataset",
                    "#training"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "Единая модель для анализа клеток и текста",
                    "desc": "scMMGPT - это новая языковая модель, объединяющая анализ одиночных клеток и текста. Она решает проблему ограниченности существующих моделей, которые специализируются только на одной из этих модальностей. scMMGPT использует специальные проекторы для преодоления разрыва между клеточными и текстовыми данными. Модель была предобучена на 27 миллионах клеток, что является крупнейшим датасетом для мультимодальных клеточно-текстовых моделей на сегодняшний день."
                },
                "en": {
                    "title": "Bridging Cells and Text: The Power of scMMGPT",
                    "desc": "This paper introduces the Single-Cell MultiModal Generative Pre-trained Transformer (scMMGPT), a novel model designed to integrate single-cell RNA sequencing data with textual information. Traditional pre-trained language models struggle with this integration due to their inability to process both modalities effectively. scMMGPT addresses these limitations by utilizing cross-modal projectors and extensive pre-training on a large dataset of 27 million cells, enhancing its performance in joint tasks. The results demonstrate significant improvements in cell description generation, cell type annotation accuracy, and text-conditioned pseudo-cell generation compared to existing models."
                },
                "zh": {
                    "title": "单细胞多模态生成预训练变换器的创新应用",
                    "desc": "预训练语言模型（PLMs）在科学研究中带来了革命性的变化，但在单细胞分析中的应用仍然有限。现有的文本PLMs无法处理单细胞RNA测序数据，而细胞PLMs又无法处理自由文本，这限制了它们在多模态任务中的使用。为了解决这些问题，我们提出了单细胞多模态生成预训练变换器（scMMGPT），这是一个用于细胞和文本联合建模的统一PLM。scMMGPT通过专门的跨模态投影器和在2700万个细胞上进行的大规模预训练，显著提高了细胞描述生成和细胞类型注释的准确性。"
                }
            }
        }
    ],
    "link_prev": "2025-03-12.html",
    "link_next": "2025-03-14.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "12.03",
        "en": "03/12",
        "zh": "3月12日"
    },
    "short_date_next": {
        "ru": "14.03",
        "en": "03/14",
        "zh": "3月14日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 1,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了YuE，一种基于LLaMA2架构的开放基础模型。它能生成长达五分钟的音乐，保持歌词对齐、连贯的音乐结构和引人入胜的歌唱旋律。YuE通过多任务、多阶段的预训练方法实现这一点。它还能进行风格转换和双向生成。实验显示，YuE在音乐性和声乐灵活性上匹敌或超越一些专有系统。此外，YuE在音乐理解任务中也表现出色。",
        "title": "YuE: Scaling Open Foundation Models for Long-Form Music Generation",
        "pinyin": "这篇文章介绍了YuE，一种基于LLaMA2架构的开放基础模型。它能生成长达五分钟的音乐，保持歌词对齐、连贯的音乐结构和引人入胜的歌唱旋律。YuE通过多任务、多阶段的预训练方法实现这一点。它还能进行风格转换和双向生成。实验显示，YuE在音乐性和声乐灵活性上匹敌或超越一些专有系统。此外，YuE在音乐理解任务中也表现出色。\n\nZhè piān wénzhāng jièshào le YuE, yī zhǒng jīyú LLaMA2 jiàgòu de kāifàng jīchǔ móxíng. Tā néng shēngchéng cháng dá wǔ fēnzhōng de yīnyuè, bǎochí gēcí duìqí, liánhé de yīnyuè jiégòu hé yǐnrénrùshèng de gēchàng xuánlǜ. YuE tōngguò duō rènwù, duō jiēduàn de yùxùnliàn fāngfǎ shíxiàn zhè yīdiǎn. Tā hái néng jìnxíng fēnggé zhuǎnhuàn hé shuāngxiàng shēngchéng. Shíyàn xiǎnshì, YuE zài yīnyuèxìng hé shēngyuè línghuóxìng shàng pǐdí huò chāoyuè yīxiē zhuānyǒu xìtǒng. Cǐwài,YuE zài yīnyuè lǐjiě rènwù zhōng yě biǎoxiàn chūsè.\n\nHere is the pinyin transcription for the given text.",
        "vocab": "[\n    {\"word\": \"基于\", \"pinyin\": \"jī yú\", \"trans\": \"based on\"},\n    {\"word\": \"架构\", \"pinyin\": \"jià gòu\", \"trans\": \"architecture\"},\n    {\"word\": \"开放\", \"pinyin\": \"kāi fàng\", \"trans\": \"open\"},\n    {\"word\": \"基础\", \"pinyin\": \"jī chǔ\", \"trans\": \"foundation\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"生成\", \"pinyin\": \"shēng chéng\", \"trans\": \"generate\"},\n    {\"word\": \"保持\", \"pinyin\": \"bǎo chí\", \"trans\": \"maintain\"},\n    {\"word\": \"对齐\", \"pinyin\": \"duì qí\", \"trans\": \"alignment\"},\n    {\"word\": \"连贯\", \"pinyin\": \"lián guàn\", \"trans\": \"coherent\"},\n    {\"word\": \"结构\", \"pinyin\": \"jié gòu\", \"trans\": \"structure\"},\n    {\"word\": \"引人入胜\", \"pinyin\": \"yǐn rén rù shèng\", \"trans\": \"fascinating\"},\n    {\"word\": \"旋律\", \"pinyin\": \"xuán lǜ\", \"trans\": \"melody\"},\n    {\"word\": \"多任务\", \"pinyin\": \"duō rèn wù\", \"trans\": \"multi-task\"},\n    {\"word\": \"多阶段\", \"pinyin\": \"duō jiē duàn\", \"trans\": \"multi-stage\"},\n    {\"word\": \"预训练\", \"pinyin\": \"yù xùn liàn\", \"trans\": \"pre-training\"},\n    {\"word\": \"实现\", \"pinyin\": \"shí xiàn\", \"trans\": \"achieve\"},\n    {\"word\": \"风格\", \"pinyin\": \"fēng gé\", \"trans\": \"style\"},\n    {\"word\": \"转换\", \"pinyin\": \"zhuǎn huàn\", \"trans\": \"conversion\"},\n    {\"word\": \"双向\", \"pinyin\": \"shuāng xiàng\", \"trans\": \"bidirectional\"},\n    {\"word\": \"匹敌\", \"pinyin\": \"pǐ dí\", \"trans\": \"match\"},\n    {\"word\": \"超越\", \"pinyin\": \"chāo yuè\", \"trans\": \"surpass\"},\n    {\"word\": \"专有\", \"pinyin\": \"zhuān yǒu\", \"trans\": \"proprietary\"},\n    {\"word\": \"系统\", \"pinyin\": \"xì tǒng\", \"trans\": \"system\"},\n    {\"word\": \"灵活性\", \"pinyin\": \"líng huó xìng\", \"trans\": \"flexibility\"},\n    {\"word\": \"此外\", \"pinyin\": \"cǐ wài\", \"trans\": \"moreover\"},\n    {\"word\": \"理解\", \"pinyin\": \"lǐ jiě\", \"trans\": \"understanding\"},\n    {\"word\": \"任务\", \"pinyin\": \"rèn wù\", \"trans\": \"task\"},\n    {\"word\": \"表现\", \"pinyin\": \"biǎo xiàn\", \"trans\": \"performance\"},\n    {\"word\": \"出色\", \"pinyin\": \"chū sè\", \"trans\": \"outstanding\"}\n]",
        "trans": "This article introduces YuE, an open-source foundational model based on the LLaMA2 architecture. It can generate music up to five minutes long, maintaining lyric alignment, coherent musical structure, and captivating vocal melodies. YuE achieves this through a multi-task, multi-stage pre-training method. It is also capable of style transfer and bidirectional generation. Experiments show that YuE matches or surpasses some proprietary systems in terms of musicality and vocal flexibility. Additionally, YuE performs excellently in music understanding tasks.",
        "update_ts": "2025-03-12 09:11"
    }
}