
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 8 papers. August 1.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ", "Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹", "Ğ¼Ğ¸Ğ½ÑƒÑ‚"],
                hour: ["Ñ‡Ğ°Ñ", "Ñ‡Ğ°ÑĞ°", "Ñ‡Ğ°ÑĞ¾Ğ²"],
                day: ["Ğ´ĞµĞ½ÑŒ", "Ğ´Ğ½Ñ", "Ğ´Ğ½ĞµĞ¹"],
                justNow: "Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾",
                ago: "Ğ½Ğ°Ğ·Ğ°Ğ´"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["åˆ†é’Ÿ", "åˆ†é’Ÿ", "åˆ†é’Ÿ"],
                hour: ["å°æ—¶", "å°æ—¶", "å°æ—¶"],
                day: ["å¤©", "å¤©", "å¤©"],
                justNow: "åˆšåˆš",
                ago: "å‰"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            } else if (lastDigit === 1) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒÑ";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒĞ¸";
            } else {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "ç¯‡è®ºæ–‡"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">ğŸ”º</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">1 Ğ°Ğ²Ğ³ÑƒÑÑ‚Ğ°</span> | <span id="title-articles-count">8 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-07-31.html">â¬…ï¸ <span id="prev-date">31.07</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-08-04.html">â¡ï¸ <span id="next-date">04.08</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-08.html">ğŸ“ˆ <span id='top-month-label'>ĞœĞµÑÑÑ†</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">ğŸ”€ <span id="sort-label-text">Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ</option>
                    <option value="pub_date">Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸</option>
                    <option value="issue_id">Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">ğŸ·ï¸ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> AâˆªB</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> Aâˆ©B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">ğŸ§¹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> âœ–ï¸ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '1 Ğ°Ğ²Ğ³ÑƒÑÑ‚Ğ°', 'en': 'August 1', 'zh': '8æœˆ1æ—¥'};
        let feedDateNext = {'ru': '04.08', 'en': '08/04', 'zh': '8æœˆ4æ—¥'};
        let feedDatePrev = {'ru': '31.07', 'en': '07/31', 'zh': '7æœˆ31æ—¥'};
        let filterLabel = {'ru': 'Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€', 'en': 'Topics', 'zh': 'ä¸»é¢˜ç­›é€‰'}
        let publishedLabel = {'ru': 'ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ñ‚ ', 'en': 'published on ', 'zh': 'å‘è¡¨äº'}
        let sortLabel = {'ru': 'Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾', 'en': 'Sort by', 'zh': 'æ’åºæ–¹å¼'}
        let paperLabel = {'ru': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ', 'en': 'Paper', 'zh': 'è®ºæ–‡'}
        let topMonthLabel = {'ru': 'ĞœĞµÑÑÑ†', 'en': 'Month', 'zh': 'æœˆåº¦è®ºæ–‡'}
        let topDayLabel = {'ru': 'Ğ”ĞµĞ½ÑŒ', 'en': 'Day', 'zh': 'æ—¥åº¦è®ºæ–‡'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2507.23726', 'title': 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving', 'url': 'https://huggingface.co/papers/2507.23726', 'abstract': 'Seed-Prover, a lemma-style reasoning model using Lean, achieves high performance in formal theorem proving and automated mathematical reasoning through iterative refinement and specialized geometry support.  \t\t\t\t\tAI-generated summary \t\t\t\t LLMs have demonstrated strong mathematical reasoning abilities by leveraging reinforcement learning with long chain-of-thought, yet they continue to struggle with theorem proving due to the lack of clear supervision signals when solely using natural language. Dedicated domain-specific languages like Lean provide clear supervision via formal verification of proofs, enabling effective training through reinforcement learning. In this work, we propose Seed-Prover, a lemma-style whole-proof reasoning model. Seed-Prover can iteratively refine its proof based on Lean feedback, proved lemmas, and self-summarization. To solve IMO-level contest problems, we design three test-time inference strategies that enable both deep and broad reasoning. Seed-Prover proves 78.1% of formalized past IMO problems, saturates MiniF2F, and achieves over 50\\% on PutnamBench, outperforming the previous state-of-the-art by a large margin. To address the lack of geometry support in Lean, we introduce a geometry reasoning engine Seed-Geometry, which outperforms previous formal geometry engines. We use these two systems to participate in IMO 2025 and fully prove 5 out of 6 problems. This work represents a significant advancement in automated mathematical reasoning, demonstrating the effectiveness of formal verification with long chain-of-thought reasoning.', 'score': 37, 'issue_id': 5124, 'pub_date': '2025-07-31', 'pub_date_card': {'ru': '31 Ğ¸ÑĞ»Ñ', 'en': 'July 31', 'zh': '7æœˆ31æ—¥'}, 'hash': 'ab5bfbdad68eb6bf', 'authors': ['Luoxin Chen', 'Jinming Gu', 'Liankai Huang', 'Wenhao Huang', 'Zhicheng Jiang', 'Allan Jie', 'Xiaoran Jin', 'Xing Jin', 'Chenggang Li', 'Kaijing Ma', 'Cheng Ren', 'Jiawei Shen', 'Wenlei Shi', 'Tong Sun', 'He Sun', 'Jiahui Wang', 'Siran Wang', 'Zhihong Wang', 'Chenrui Wei', 'Shufa Wei', 'Yonghui Wu', 'Yuchen Wu', 'Yihang Xia', 'Huajian Xin', 'Fan Yang', 'Huaiyuan Ying', 'Hongyi Yuan', 'Zheng Yuan', 'Tianyang Zhan', 'Chi Zhang', 'Yue Zhang', 'Ge Zhang', 'Tianyun Zhao', 'Jianqiu Zhao', 'Yichi Zhou', 'Thomas Hanwen Zhu'], 'affiliations': ['ByteDance'], 'pdf_title_img': 'assets/pdf/title_img/2507.23726.jpg', 'data': {'categories': ['#optimization', '#training', '#math', '#reasoning', '#rl'], 'emoji': 'ğŸ§ ', 'ru': {'title': 'ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğµ Ñ‚ĞµĞ¾Ñ€ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜', 'desc': 'Seed-Prover - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ° Ñ‚ĞµĞ¾Ñ€ĞµĞ¼, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ ÑĞ·Ñ‹Ğº Lean. ĞĞ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ² Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºÑƒ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğµ Ñ‚ĞµĞ¾Ñ€ĞµĞ¼ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ…. Seed-Prover Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ ĞœĞµĞ¶Ğ´ÑƒĞ½Ğ°Ñ€Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ğ»Ğ¸Ğ¼Ğ¿Ğ¸Ğ°Ğ´Ñ‹.'}, 'en': {'title': 'Seed-Prover: Revolutionizing Theorem Proving with Iterative Refinement', 'desc': 'The paper introduces Seed-Prover, a model designed for formal theorem proving and automated mathematical reasoning using the Lean programming language. It leverages iterative refinement and specialized geometry support to enhance its proof capabilities. By employing reinforcement learning and clear supervision from formal verification, Seed-Prover achieves impressive results on challenging mathematical problems. The model outperforms previous systems, proving a high percentage of formalized IMO problems and demonstrating significant advancements in automated reasoning.'}, 'zh': {'title': 'Seed-Proverï¼šè‡ªåŠ¨åŒ–æ•°å­¦æ¨ç†çš„æ–°çªç ´', 'desc': 'Seed-Proveræ˜¯ä¸€ç§åŸºäºLeançš„å¼•ç†é£æ ¼æ¨ç†æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å½¢å¼å®šç†è¯æ˜å’Œè‡ªåŠ¨æ•°å­¦æ¨ç†ä¸­å®ç°é«˜æ€§èƒ½ã€‚è¯¥æ¨¡å‹é€šè¿‡è¿­ä»£ä¼˜åŒ–å’Œä¸“é—¨çš„å‡ ä½•æ”¯æŒï¼Œå…‹æœäº†ä¼ ç»Ÿè‡ªç„¶è¯­è¨€æ¨ç†çš„å±€é™æ€§ã€‚Seed-Proveråˆ©ç”¨Leançš„åé¦ˆå’Œè‡ªæˆ‘æ€»ç»“æ¥ä¸æ–­æ”¹è¿›å…¶è¯æ˜è¿‡ç¨‹ï¼Œå¹¶è®¾è®¡äº†ä¸‰ç§æ¨ç†ç­–ç•¥ä»¥åº”å¯¹å›½é™…æ•°å­¦å¥¥æ—åŒ¹å…‹ï¼ˆIMOï¼‰çº§åˆ«çš„é—®é¢˜ã€‚é€šè¿‡å¼•å…¥Seed-Geometryå‡ ä½•æ¨ç†å¼•æ“ï¼ŒSeed-Proveråœ¨å‡ ä½•é—®é¢˜ä¸Šä¹Ÿå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå±•ç¤ºäº†å½¢å¼éªŒè¯ä¸é•¿é“¾æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.22879', 'title': 'RecGPT Technical Report', 'url': 'https://huggingface.co/papers/2507.22879', 'abstract': "RecGPT integrates large language models into recommender systems to focus on user intent, improving content diversity and satisfaction while enhancing merchant and platform performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Recommender systems are among the most impactful applications of artificial intelligence, serving as critical infrastructure connecting users, merchants, and platforms. However, most current industrial systems remain heavily reliant on historical co-occurrence patterns and log-fitting objectives, i.e., optimizing for past user interactions without explicitly modeling user intent. This log-fitting approach often leads to overfitting to narrow historical preferences, failing to capture users' evolving and latent interests. As a result, it reinforces filter bubbles and long-tail phenomena, ultimately harming user experience and threatening the sustainability of the whole recommendation ecosystem.   To address these challenges, we rethink the overall design paradigm of recommender systems and propose RecGPT, a next-generation framework that places user intent at the center of the recommendation pipeline. By integrating large language models (LLMs) into key stages of user interest mining, item retrieval, and explanation generation, RecGPT transforms log-fitting recommendation into an intent-centric process. To effectively align general-purpose LLMs to the above domain-specific recommendation tasks at scale, RecGPT incorporates a multi-stage training paradigm, which integrates reasoning-enhanced pre-alignment and self-training evolution, guided by a Human-LLM cooperative judge system. Currently, RecGPT has been fully deployed on the Taobao App. Online experiments demonstrate that RecGPT achieves consistent performance gains across stakeholders: users benefit from increased content diversity and satisfaction, merchants and the platform gain greater exposure and conversions. These comprehensive improvement results across all stakeholders validates that LLM-driven, intent-centric design can foster a more sustainable and mutually beneficial recommendation ecosystem.", 'score': 12, 'issue_id': 5124, 'pub_date': '2025-07-30', 'pub_date_card': {'ru': '30 Ğ¸ÑĞ»Ñ', 'en': 'July 30', 'zh': '7æœˆ30æ—¥'}, 'hash': '2bd5536810f1694b', 'authors': ['Chao Yi', 'Dian Chen', 'Gaoyang Guo', 'Jiakai Tang', 'Jian Wu', 'Jing Yu', 'Mao Zhang', 'Sunhao Dai', 'Wen Chen', 'Wenjun Yang', 'Yuning Jiang', 'Zhujin Gao', 'Bo Zheng', 'Chi Li', 'Dimin Wang', 'Dixuan Wang', 'Fan Li', 'Fan Zhang', 'Haibin Chen', 'Haozhuang Liu', 'Jialin Zhu', 'Jiamang Wang', 'Jiawei Wu', 'Jin Cui', 'Ju Huang', 'Kai Zhang', 'Kan Liu', 'Lang Tian', 'Liang Rao', 'Longbin Li', 'Lulu Zhao', 'Na He', 'Peiyang Wang', 'Qiqi Huang', 'Tao Luo', 'Wenbo Su', 'Xiaoxiao He', 'Xin Tong', 'Xu Chen', 'Xunke Xi', 'Yang Li', 'Yaxuan Wu', 'Yeqiu Yang', 'Yi Hu', 'Yinnan Song', 'Yuchen Li', 'Yujie Luo', 'Yujin Yuan', 'Yuliang Yan', 'Zhengyang Wang', 'Zhibo Xiao', 'Zhixin Ma', 'Zile Zhou', 'Ziqi Zhang'], 'affiliations': [], 'pdf_title_img': 'assets/pdf/title_img/2507.22879.jpg', 'data': {'categories': ['#optimization', '#training', '#reasoning', '#alignment', '#multimodal'], 'emoji': 'ğŸ¯', 'ru': {'title': 'RecGPT: Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹', 'desc': 'RecGPT - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹, Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒÑÑ‰Ğ°Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ğ´Ğ»Ñ Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ½Ğ° Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸ÑÑ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹. ĞĞ½Ğ° ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ¸ ÑƒĞ´Ğ¾Ğ²Ğ»ĞµÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ¾Ğ² Ğ¸ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹. RecGPT Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ÑƒÑ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ ÑĞ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒĞ¶Ğµ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ° Ğ² Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ Taobao Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ¾ÑÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ·Ğ°Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½.'}, 'en': {'title': 'Empowering Recommendations with User Intent', 'desc': 'RecGPT is a new framework that enhances recommender systems by focusing on user intent rather than just historical data. It integrates large language models (LLMs) to better understand and predict user interests, which helps in retrieving more relevant items and generating clearer explanations. This approach reduces the risk of overfitting to past preferences, thereby improving content diversity and user satisfaction. By deploying RecGPT on the Taobao App, the system has shown significant performance improvements for users, merchants, and the platform itself, creating a more sustainable recommendation ecosystem.'}, 'zh': {'title': 'ä»¥ç”¨æˆ·æ„å›¾ä¸ºä¸­å¿ƒçš„æ¨èç³»ç»Ÿæ–°èŒƒå¼', 'desc': 'RecGPT æ˜¯ä¸€ç§å°†å¤§å‹è¯­è¨€æ¨¡å‹æ•´åˆåˆ°æ¨èç³»ç»Ÿä¸­çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨å…³æ³¨ç”¨æˆ·æ„å›¾ã€‚é€šè¿‡é‡æ–°è®¾è®¡æ¨èæµç¨‹ï¼ŒRecGPT ä½¿æ¨èè¿‡ç¨‹ä»å•çº¯ä¾èµ–å†å²æ•°æ®è½¬å˜ä¸ºä»¥ç”¨æˆ·æ„å›¾ä¸ºä¸­å¿ƒã€‚è¯¥ç³»ç»Ÿé€šè¿‡å¤šé˜¶æ®µè®­ç»ƒæ–¹æ³•ï¼Œç»“åˆæ¨ç†å¢å¼ºçš„é¢„å¯¹é½å’Œè‡ªæˆ‘è®­ç»ƒï¼Œæå‡äº†æ¨èçš„å‡†ç¡®æ€§å’Œå¤šæ ·æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRecGPT åœ¨ç”¨æˆ·æ»¡æ„åº¦ã€å•†å®¶æ›å…‰ç‡å’Œå¹³å°è½¬åŒ–ç‡ç­‰æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.23682', 'title': 'villa-X: Enhancing Latent Action Modeling in Vision-Language-Action\n  Models', 'url': 'https://huggingface.co/papers/2507.23682', 'abstract': 'The ViLLA framework enhances VLA models by incorporating latent actions, improving performance in both simulated and real-world robot manipulation tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Visual-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies that can follow language instructions and generalize to novel scenarios. Recent work has begun to explore the incorporation of latent actions, an abstract representation of visual change between two frames, into VLA pre-training. In this paper, we introduce villa-X, a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent action modeling for learning generalizable robot manipulation policies. Our approach improves both how latent actions are learned and how they are incorporated into VLA pre-training. Together, these contributions enable villa-X to achieve superior performance across simulated environments including SIMPLER and LIBERO, as well as on two real-world robot setups including gripper and dexterous hand manipulation. We believe the ViLLA paradigm holds significant promise, and that our villa-X provides a strong foundation for future research.', 'score': 9, 'issue_id': 5124, 'pub_date': '2025-07-31', 'pub_date_card': {'ru': '31 Ğ¸ÑĞ»Ñ', 'en': 'July 31', 'zh': '7æœˆ31æ—¥'}, 'hash': 'baa73e4730b01a97', 'authors': ['Xiaoyu Chen', 'Hangxing Wei', 'Pushi Zhang', 'Chuheng Zhang', 'Kaixin Wang', 'Yanjiang Guo', 'Rushuai Yang', 'Yucen Wang', 'Xinquan Xiao', 'Li Zhao', 'Jianyu Chen', 'Jiang Bian'], 'affiliations': ['Hong Kong University of Science and Technology', 'Microsoft Research', 'Nanjing University', 'Tsinghua University', 'Wuhan University'], 'pdf_title_img': 'assets/pdf/title_img/2507.23682.jpg', 'data': {'categories': ['#optimization', '#agents', '#agi', '#games', '#robotics', '#architecture'], 'emoji': 'ğŸ¤–', 'ru': {'title': 'ViLLA: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹', 'desc': 'Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº ViLLA ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ (VLA) Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğº Ğ² ÑĞ¸Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ…, Ñ‚Ğ°Ğº Ğ¸ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ villa-X ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²ÑƒĞµÑ‚ ĞºĞ°Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑĞ¼, Ñ‚Ğ°Ğº Ğ¸ Ğ¸Ñ… Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ VLA. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² ÑĞ¸Ğ¼ÑƒĞ»ÑÑ‚Ğ¾Ñ€Ğ°Ñ… SIMPLER Ğ¸ LIBERO, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°Ñ… Ñ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ Ğ»Ğ¾Ğ²ĞºĞ¸Ğ¼Ğ¸ Ñ€ÑƒĞºĞ°Ğ¼Ğ¸.'}, 'en': {'title': 'Enhancing Robot Manipulation with Latent Actions in ViLLA Framework', 'desc': 'The ViLLA framework enhances Visual-Language-Action (VLA) models by integrating latent actions, which represent abstract visual changes between frames. This integration improves the learning of robot manipulation policies that can effectively follow language instructions and adapt to new situations. The proposed villa-X model advances the way latent actions are learned and utilized during VLA pre-training, leading to better performance in both simulated and real-world tasks. Overall, the ViLLA paradigm shows great potential for future advancements in robot manipulation research.'}, 'zh': {'title': 'ViLLAæ¡†æ¶ï¼šæå‡æœºå™¨äººæ“ä½œçš„æ½œåŠ›', 'desc': 'ViLLAæ¡†æ¶é€šè¿‡å¼•å…¥æ½œåœ¨åŠ¨ä½œæ¥å¢å¼ºè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œä»è€Œæé«˜æœºå™¨äººæ“ä½œä»»åŠ¡çš„æ€§èƒ½ã€‚æ½œåœ¨åŠ¨ä½œæ˜¯ä¸€ç§æŠ½è±¡è¡¨ç¤ºï¼Œèƒ½å¤Ÿæ•æ‰ä¸¤ä¸ªå¸§ä¹‹é—´çš„è§†è§‰å˜åŒ–ã€‚æœ¬æ–‡ä»‹ç»çš„villa-Xæ˜¯ä¸€ä¸ªæ–°é¢–çš„è§†è§‰-è¯­è¨€-æ½œåœ¨åŠ¨ä½œæ¡†æ¶ï¼Œæ—¨åœ¨æ”¹è¿›æ½œåœ¨åŠ¨ä½œå»ºæ¨¡ï¼Œä»¥å­¦ä¹ å¯æ¨å¹¿çš„æœºå™¨äººæ“ä½œç­–ç•¥ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œvilla-Xåœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒçœŸå®æœºå™¨äººè®¾ç½®ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†ViLLAèŒƒå¼çš„å·¨å¤§æ½œåŠ›ã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.22968', 'title': 'C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring\n  Challenges in Complex Conversations', 'url': 'https://huggingface.co/papers/2507.22968', 'abstract': "A benchmark dataset for Spoken Dialogue Models (SDMs) in English and Chinese is presented to evaluate their performance in understanding and emulating human spoken conversations, addressing challenges like ambiguity and context-dependency.  \t\t\t\t\tAI-generated summary \t\t\t\t Spoken Dialogue Models (SDMs) have recently attracted significant attention for their ability to generate voice responses directly to users' spoken queries. Despite their increasing popularity, there exists a gap in research focused on comprehensively understanding their practical effectiveness in comprehending and emulating human conversations. This is especially true compared to text-based Large Language Models (LLMs), which benefit from extensive benchmarking. Human voice interactions are inherently more complex than text due to characteristics unique to spoken dialogue. Ambiguity poses one challenge, stemming from semantic factors like polysemy, as well as phonological aspects such as heterograph, heteronyms, and stress patterns. Additionally, context-dependency, like omission, coreference, and multi-turn interaction, adds further complexity to human conversational dynamics. To illuminate the current state of SDM development and to address these challenges, we present a benchmark dataset in this paper, which comprises 1,079 instances in English and Chinese. Accompanied by an LLM-based evaluation method that closely aligns with human judgment, this dataset facilitates a comprehensive exploration of the performance of SDMs in tackling these practical challenges.", 'score': 7, 'issue_id': 5124, 'pub_date': '2025-07-30', 'pub_date_card': {'ru': '30 Ğ¸ÑĞ»Ñ', 'en': 'July 30', 'zh': '7æœˆ30æ—¥'}, 'hash': '3a2f5273d610d5d6', 'authors': ['Chengqian Ma', 'Wei Tao', 'Yiwen Guo'], 'affiliations': ['Independent Researcher', 'LIGHTSPEED', 'Peking University'], 'pdf_title_img': 'assets/pdf/title_img/2507.22968.jpg', 'data': {'categories': ['#survey', '#long_context', '#benchmark', '#dataset', '#multimodal'], 'emoji': 'ğŸ—£ï¸', 'ru': {'title': 'Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ˜Ğ˜-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ…', 'desc': 'Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ Ğ¸ ĞºĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞ°Ñ…. Ğ­Ñ‚Ğ¾Ñ‚ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ¸ Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğµ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ Ñ‚Ğ°ĞºĞ¸Ğµ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğº Ğ½ĞµĞ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ°Ñ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ. ĞĞ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 1079 Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¸ ÑĞ¾Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ¶Ğ´Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ¼ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ ĞºĞ¾Ñ€Ñ€ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼Ğ¸. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğµ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡.'}, 'en': {'title': 'Benchmarking Spoken Dialogue Models for Real-World Conversations', 'desc': "This paper introduces a benchmark dataset designed for evaluating Spoken Dialogue Models (SDMs) in both English and Chinese. The dataset aims to address the complexities of human spoken conversations, such as ambiguity and context-dependency, which are more pronounced in voice interactions compared to text. It includes 1,079 instances that reflect real-world dialogue scenarios, allowing for a thorough assessment of SDM performance. Additionally, the paper presents an evaluation method based on Large Language Models (LLMs) that aligns closely with human judgment, enhancing the understanding of SDMs' effectiveness."}, 'zh': {'title': 'æå‡å£è¯­å¯¹è¯æ¨¡å‹çš„è¯„ä¼°æ ‡å‡†', 'desc': 'æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºè¯„ä¼°å£è¯­å¯¹è¯æ¨¡å‹ï¼ˆSDMsï¼‰æ€§èƒ½çš„åŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–è‹±è¯­å’Œä¸­æ–‡ï¼Œæ—¨åœ¨ç†è§£å’Œæ¨¡æ‹Ÿäººç±»å£è¯­å¯¹è¯ã€‚å£è¯­å¯¹è¯çš„å¤æ‚æ€§ä½“ç°åœ¨æ­§ä¹‰æ€§å’Œä¸Šä¸‹æ–‡ä¾èµ–æ€§ç­‰æŒ‘æˆ˜ä¸Šï¼Œè¿™äº›å› ç´ ä½¿å¾—ä¸æ–‡æœ¬åŸºç¡€çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç›¸æ¯”ï¼ŒSDMsçš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚æ•°æ®é›†ä¸­åŒ…å«1079ä¸ªå®ä¾‹ï¼Œå¹¶é…å¤‡äº†ä¸€ç§åŸºäºLLMçš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥æ›´å¥½åœ°ä¸äººç±»åˆ¤æ–­ç›¸ä¸€è‡´ã€‚é€šè¿‡è¿™ä¸ªæ•°æ®é›†ï¼Œç ”ç©¶è€…å¯ä»¥å…¨é¢æ¢è®¨SDMsåœ¨åº”å¯¹å®é™…å¯¹è¯æŒ‘æˆ˜ä¸­çš„è¡¨ç°ã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.23698', 'title': 'Scalable Multi-Task Reinforcement Learning for Generalizable Spatial\n  Intelligence in Visuomotor Agents', 'url': 'https://huggingface.co/papers/2507.23698', 'abstract': "Reinforcement Learning enhances generalizable spatial reasoning and interaction in 3D environments through cross-view goal specification and automated task synthesis, achieving zero-shot generalization and improved interaction success rates.  \t\t\t\t\tAI-generated summary \t\t\t\t While Reinforcement Learning (RL) has achieved remarkable success in language modeling, its triumph hasn't yet fully translated to visuomotor agents. A primary challenge in RL models is their tendency to overfit specific tasks or environments, thereby hindering the acquisition of generalizable behaviors across diverse settings. This paper provides a preliminary answer to this challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can achieve zero-shot generalization to unseen worlds. Specifically, we explore RL's potential to enhance generalizable spatial reasoning and interaction capabilities in 3D worlds. To address challenges in multi-task RL representation, we analyze and establish cross-view goal specification as a unified multi-task goal space for visuomotor policies. Furthermore, to overcome the significant bottleneck of manual task design, we propose automated task synthesis within the highly customizable Minecraft environment for large-scale multi-task RL training, and we construct an efficient distributed RL framework to support this. Experimental results show RL significantly boosts interaction success rates by 4times and enables zero-shot generalization of spatial reasoning across diverse environments, including real-world settings. Our findings underscore the immense potential of RL training in 3D simulated environments, especially those amenable to large-scale task generation, for significantly advancing visuomotor agents' spatial reasoning.", 'score': 3, 'issue_id': 5125, 'pub_date': '2025-07-31', 'pub_date_card': {'ru': '31 Ğ¸ÑĞ»Ñ', 'en': 'July 31', 'zh': '7æœˆ31æ—¥'}, 'hash': '4cb697aecb943154', 'authors': ['Shaofei Cai', 'Zhancun Mu', 'Haiwen Xia', 'Bowei Zhang', 'Anji Liu', 'Yitao Liang'], 'affiliations': ['Institute for Artificial Intelligence, Peking University', 'School of Computing, National University of Singapore'], 'pdf_title_img': 'assets/pdf/title_img/2507.23698.jpg', 'data': {'categories': ['#training', '#reasoning', '#optimization', '#games', '#3d', '#rl'], 'emoji': 'ğŸ§ ', 'ru': {'title': 'RL Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ˜Ğ˜', 'desc': 'Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² 3D-ÑÑ€ĞµĞ´Ğ°Ñ… Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºÑ€Ğ¾ÑÑ-Ğ²Ğ¸Ğ´Ğ¾Ğ²ÑƒÑ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ†ĞµĞ»ĞµĞ¹ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ½Ñ‚ĞµĞ· Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ğ»Ğ¸ÑÑŒ Ğ² ÑÑ€ĞµĞ´Ğµ Minecraft Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-Ğ¼Ğ¾Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ².'}, 'en': {'title': 'Empowering 3D Agents with Reinforcement Learning for Generalized Interaction', 'desc': 'This paper discusses how Reinforcement Learning (RL) can improve the ability of agents to understand and interact in 3D environments, like Minecraft. It addresses the problem of RL models overfitting to specific tasks, which limits their ability to generalize to new situations. By using cross-view goal specification and automated task synthesis, the authors show that RL can help agents achieve zero-shot generalization, meaning they can perform well in unseen environments without prior training. The results indicate that RL can significantly enhance interaction success rates and spatial reasoning in diverse settings, including real-world applications.'}, 'zh': {'title': 'å¼ºåŒ–å­¦ä¹ ï¼šæå‡3Dç¯å¢ƒä¸­çš„ç©ºé—´æ¨ç†ä¸äº¤äº’èƒ½åŠ›', 'desc': 'å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨3Dç¯å¢ƒä¸­é€šè¿‡è·¨è§†è§’ç›®æ ‡æŒ‡å®šå’Œè‡ªåŠ¨åŒ–ä»»åŠ¡åˆæˆï¼Œå¢å¼ºäº†å¯æ¨å¹¿çš„ç©ºé—´æ¨ç†å’Œäº¤äº’èƒ½åŠ›ï¼Œå®ç°äº†é›¶æ ·æœ¬æ³›åŒ–å’Œæé«˜çš„äº¤äº’æˆåŠŸç‡ã€‚æœ¬æ–‡æ¢è®¨äº†RLåœ¨Minecraftä¸­å¾®è°ƒçš„è§†è§‰è¿åŠ¨ä»£ç†å¦‚ä½•åœ¨æœªè§è¿‡çš„ä¸–ç•Œä¸­å®ç°é›¶æ ·æœ¬æ³›åŒ–ã€‚æˆ‘ä»¬åˆ†æå¹¶å»ºç«‹äº†è·¨è§†è§’ç›®æ ‡æŒ‡å®šä½œä¸ºè§†è§‰è¿åŠ¨ç­–ç•¥çš„ç»Ÿä¸€å¤šä»»åŠ¡ç›®æ ‡ç©ºé—´ï¼Œä»¥åº”å¯¹å¤šä»»åŠ¡RLè¡¨ç¤ºä¸­çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºåœ¨é«˜åº¦å¯å®šåˆ¶çš„Minecraftç¯å¢ƒä¸­è¿›è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡åˆæˆï¼Œä»¥æ”¯æŒå¤§è§„æ¨¡å¤šä»»åŠ¡RLè®­ç»ƒã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.23632', 'title': 'On the Expressiveness of Softmax Attention: A Recurrent Neural Network\n  Perspective', 'url': 'https://huggingface.co/papers/2507.23632', 'abstract': 'Softmax attention is more expressive than linear attention due to its recurrent form, which can be analyzed using RNN components.  \t\t\t\t\tAI-generated summary \t\t\t\t Since its introduction, softmax attention has become the backbone of modern transformer architectures due to its expressiveness and scalability across a wide range of tasks. However, the main drawback of softmax attention is the quadratic memory requirement and computational complexity with respect to the sequence length. By replacing the softmax nonlinearity, linear attention and similar methods have been introduced to avoid the quadratic bottleneck of softmax attention. Despite these linear forms of attention being derived from the original softmax formulation, they typically lag in terms of downstream accuracy. While strong intuition of the softmax nonlinearity on the query and key inner product suggests that it has desirable properties compared to other nonlinearities, the question of why this discrepancy exists still remains unanswered. This work demonstrates that linear attention is an approximation of softmax attention by deriving the recurrent form of softmax attention. Using this form, each part of softmax attention can be described in the language of recurrent neural networks (RNNs). Describing softmax attention as an RNN allows for the ablation of the components of softmax attention to understand the importance of each part and how they interact. In this way, our work helps explain why softmax attention is more expressive than its counterparts.', 'score': 1, 'issue_id': 5124, 'pub_date': '2025-07-31', 'pub_date_card': {'ru': '31 Ğ¸ÑĞ»Ñ', 'en': 'July 31', 'zh': '7æœˆ31æ—¥'}, 'hash': 'b07ddf6cb6b8bee8', 'authors': ['Gabriel Mongaras', 'Eric C. Larson'], 'affiliations': ['Lyle School of Engineering Southern Methodist University Dallas, TX 75205'], 'pdf_title_img': 'assets/pdf/title_img/2507.23632.jpg', 'data': {'categories': ['#optimization', '#architecture', '#interpretability'], 'emoji': 'ğŸ”', 'ru': {'title': 'Ğ Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°Ñ ÑĞ¸Ğ»Ñƒ ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ-Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¸Ğ·Ğ¼Ñƒ RNN', 'desc': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ-Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ-Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğµ, Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¼ ÑĞµÑ‚ÑĞ¼ (RNN). Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ²ĞµÑÑ‚Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ² ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ-Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚ÑŒ ĞµĞ³Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆÑƒÑ Ğ²Ñ‹Ñ€Ğ°Ğ·Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°Ğ¼Ğ¸. Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ½ÑÑ‚ÑŒ, Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ ÑĞ¾Ñ„Ñ‚Ğ¼Ğ°ĞºÑ-Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¾ÑÑ‚Ğ°ĞµÑ‚ÑÑ Ğ¾ÑĞ½Ğ¾Ğ²Ğ¾Ğ¹ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€, Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½ÑƒÑ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ.'}, 'en': {'title': 'Unlocking the Power of Softmax Attention', 'desc': "This paper explores the differences between softmax attention and linear attention in machine learning models, particularly in transformers. It shows that softmax attention, which is more expressive, can be understood through the lens of recurrent neural networks (RNNs). By analyzing softmax attention as an RNN, the authors can break down its components to see how they contribute to its performance. The findings clarify why softmax attention outperforms linear attention in terms of accuracy despite the latter's computational efficiency."}, 'zh': {'title': 'è½¯maxæ³¨æ„åŠ›çš„ä¼˜åŠ¿è§£æ', 'desc': 'æœ¬æ–‡æ¢è®¨äº†softmaxæ³¨æ„åŠ›ä¸çº¿æ€§æ³¨æ„åŠ›çš„åŒºåˆ«ã€‚softmaxæ³¨æ„åŠ›å› å…¶è¡¨è¾¾èƒ½åŠ›å¼ºè€Œæˆä¸ºç°ä»£å˜æ¢å™¨æ¶æ„çš„åŸºç¡€ï¼Œä½†å…¶åœ¨åºåˆ—é•¿åº¦ä¸Šçš„è®¡ç®—å¤æ‚åº¦å’Œå†…å­˜éœ€æ±‚æ˜¯ä¸€ä¸ªä¸»è¦ç¼ºç‚¹ã€‚é€šè¿‡å°†softmaxéçº¿æ€§æ›¿æ¢ä¸ºçº¿æ€§æ³¨æ„åŠ›ï¼Œç ”ç©¶è€…ä»¬è¯•å›¾è§£å†³è¿™ä¸€ç“¶é¢ˆã€‚æœ¬æ–‡è¡¨æ˜ï¼Œçº¿æ€§æ³¨æ„åŠ›å®é™…ä¸Šæ˜¯softmaxæ³¨æ„åŠ›çš„ä¸€ç§è¿‘ä¼¼ï¼Œå¹¶é€šè¿‡é€’å½’ç¥ç»ç½‘ç»œçš„è¯­è¨€æ¥æè¿°softmaxæ³¨æ„åŠ›çš„å„ä¸ªéƒ¨åˆ†ï¼Œä»è€Œæ­ç¤ºå…¶æ›´å¼ºè¡¨è¾¾èƒ½åŠ›çš„åŸå› ã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.20519', 'title': 'AgroBench: Vision-Language Model Benchmark in Agriculture', 'url': 'https://huggingface.co/papers/2507.20519', 'abstract': 'AgroBench evaluates vision-language models across agricultural tasks, revealing areas for improvement in fine-grained identification, particularly weed identification, with expert-annotated categories.  \t\t\t\t\tAI-generated summary \t\t\t\t Precise automated understanding of agricultural tasks such as disease identification is essential for sustainable crop production. Recent advances in vision-language models (VLMs) are expected to further expand the range of agricultural tasks by facilitating human-model interaction through easy, text-based communication. Here, we introduce AgroBench (Agronomist AI Benchmark), a benchmark for evaluating VLM models across seven agricultural topics, covering key areas in agricultural engineering and relevant to real-world farming. Unlike recent agricultural VLM benchmarks, AgroBench is annotated by expert agronomists. Our AgroBench covers a state-of-the-art range of categories, including 203 crop categories and 682 disease categories, to thoroughly evaluate VLM capabilities. In our evaluation on AgroBench, we reveal that VLMs have room for improvement in fine-grained identification tasks. Notably, in weed identification, most open-source VLMs perform close to random. With our wide range of topics and expert-annotated categories, we analyze the types of errors made by VLMs and suggest potential pathways for future VLM development. Our dataset and code are available at https://dahlian00.github.io/AgroBenchPage/ .', 'score': 1, 'issue_id': 5125, 'pub_date': '2025-07-28', 'pub_date_card': {'ru': '28 Ğ¸ÑĞ»Ñ', 'en': 'July 28', 'zh': '7æœˆ28æ—¥'}, 'hash': 'efa19cc739cbe95e', 'authors': ['Risa Shinoda', 'Nakamasa Inoue', 'Hirokatsu Kataoka', 'Masaki Onishi', 'Yoshitaka Ushiku'], 'affiliations': ['Kyoto University', 'National Institute of Advanced Industrial Science and Technology (AIST)', 'OMRON SINIC', 'The University of Osaka', 'Tokyo Institute of Technology', 'Visual Geometry Group, University of Oxford'], 'pdf_title_img': 'assets/pdf/title_img/2507.20519.jpg', 'data': {'categories': ['#cv', '#open_source', '#science', '#dataset', '#benchmark'], 'emoji': 'ğŸŒ¾', 'ru': {'title': 'AgroBench: ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ˜Ğ˜ Ğ² ÑĞµĞ»ÑŒÑĞºĞ¾Ğ¼ Ñ…Ğ¾Ğ·ÑĞ¹ÑÑ‚Ğ²Ğµ', 'desc': 'AgroBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° Ğ² ÑĞµĞ»ÑŒÑĞºĞ¾Ñ…Ğ¾Ğ·ÑĞ¹ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. ĞĞ½ Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞµĞ¼ÑŒ ÑĞµĞ»ÑŒÑĞºĞ¾Ñ…Ğ¾Ğ·ÑĞ¹ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞ¼ Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ 203 ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ ĞºÑƒĞ»ÑŒÑ‚ÑƒÑ€ Ğ¸ 682 ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ĞµĞ·Ğ½ĞµĞ¹, Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°Ğ¼Ğ¸-Ğ°Ğ³Ñ€Ğ¾Ğ½Ğ¾Ğ¼Ğ°Ğ¼Ğ¸. Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ¼ĞµÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğ¸ ÑĞ¾Ñ€Ğ½ÑĞºĞ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¿ÑƒÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¸Ñ… Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ.'}, 'en': {'title': 'Enhancing Agricultural AI: The AgroBench Benchmark', 'desc': 'AgroBench is a benchmark designed to evaluate vision-language models (VLMs) specifically in the context of agricultural tasks. It focuses on fine-grained identification, such as accurately recognizing different types of weeds and diseases in crops, using categories annotated by expert agronomists. The benchmark includes a comprehensive set of 203 crop categories and 682 disease categories, highlighting the current limitations of VLMs in these areas. The findings indicate that many existing VLMs struggle with precise identification, particularly in weed detection, suggesting significant opportunities for improvement in future model development.'}, 'zh': {'title': 'æå‡å†œä¸šä»»åŠ¡ä¸­çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¡¨ç°', 'desc': 'AgroBenchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨å†œä¸šä»»åŠ¡ä¸­çš„è¡¨ç°çš„åŸºå‡†ã€‚å®ƒæ¶µç›–äº†ä¸ƒä¸ªå†œä¸šä¸»é¢˜ï¼Œå¹¶ç”±ä¸“å®¶å†œå­¦å®¶è¿›è¡Œæ ‡æ³¨ï¼Œç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰çš„VLMåœ¨ç»†ç²’åº¦è¯†åˆ«ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯æ‚è‰è¯†åˆ«æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œè®¸å¤šå¼€æºæ¨¡å‹çš„è¡¨ç°æ¥è¿‘éšæœºã€‚é€šè¿‡åˆ†æVLMçš„é”™è¯¯ç±»å‹ï¼ŒAgroBenchä¸ºæœªæ¥çš„æ¨¡å‹å‘å±•æä¾›äº†æ”¹è¿›çš„æ–¹å‘ã€‚'}}}, {'id': 'https://huggingface.co/papers/2507.14793', 'title': 'Flow Equivariant Recurrent Neural Networks', 'url': 'https://huggingface.co/papers/2507.14793', 'abstract': "Equivariant neural network architectures are extended to handle time-parameterized transformations, improving performance in sequence models like RNNs.  \t\t\t\t\tAI-generated summary \t\t\t\t Data arrives at our senses as a continuous stream, smoothly transforming from one instant to the next. These smooth transformations can be viewed as continuous symmetries of the environment that we inhabit, defining equivalence relations between stimuli over time. In machine learning, neural network architectures that respect symmetries of their data are called equivariant and have provable benefits in terms of generalization ability and sample efficiency. To date, however, equivariance has been considered only for static transformations and feed-forward networks, limiting its applicability to sequence models, such as recurrent neural networks (RNNs), and corresponding time-parameterized sequence transformations. In this work, we extend equivariant network theory to this regime of `flows' -- one-parameter Lie subgroups capturing natural transformations over time, such as visual motion. We begin by showing that standard RNNs are generally not flow equivariant: their hidden states fail to transform in a geometrically structured manner for moving stimuli. We then show how flow equivariance can be introduced, and demonstrate that these models significantly outperform their non-equivariant counterparts in terms of training speed, length generalization, and velocity generalization, on both next step prediction and sequence classification. We present this work as a first step towards building sequence models that respect the time-parameterized symmetries which govern the world around us.", 'score': 0, 'issue_id': 5126, 'pub_date': '2025-07-20', 'pub_date_card': {'ru': '20 Ğ¸ÑĞ»Ñ', 'en': 'July 20', 'zh': '7æœˆ20æ—¥'}, 'hash': 'eb29bf11c603c730', 'authors': ['T. Anderson Keller'], 'affiliations': ['The Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University, Cambridge, MA 15213'], 'pdf_title_img': 'assets/pdf/title_img/2507.14793.jpg', 'data': {'categories': ['#training', '#architecture', '#optimization'], 'emoji': 'â³', 'ru': {'title': 'Ğ­ĞºĞ²Ğ¸Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹', 'desc': "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑĞµÑ‚ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ ÑĞºĞ²Ğ¸Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹, Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸. Ğ­Ñ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹ (RNN) Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ğµ 'Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²' - Ğ¾Ğ´Ğ½Ğ¾Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ¾Ğ´Ğ³Ñ€ÑƒĞ¿Ğ¿ Ğ›Ğ¸, Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ÑÑ‰Ğ¸Ñ… ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾-ÑĞºĞ²Ğ¸Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ RNN Ğ¿Ğ¾ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ."}, 'en': {'title': 'Enhancing RNNs with Time-Parameter Equivariance', 'desc': 'This paper extends equivariant neural network architectures to include time-parameterized transformations, which enhances their performance in sequence models like recurrent neural networks (RNNs). It highlights that traditional RNNs do not adequately account for the smooth, continuous changes in data over time, leading to inefficiencies. By introducing flow equivariance, the authors demonstrate that these new models can better handle temporal symmetries, resulting in improved training speed and generalization capabilities. This work aims to create sequence models that align more closely with the natural transformations observed in the real world.'}, 'zh': {'title': 'æå‡åºåˆ—æ¨¡å‹æ€§èƒ½çš„æ—¶é—´ç­‰å˜ç½‘ç»œ', 'desc': 'æœ¬æ–‡æ‰©å±•äº†ç­‰å˜ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä»¥å¤„ç†æ—¶é—´å‚æ•°åŒ–çš„å˜æ¢ï¼Œä»è€Œæé«˜åºåˆ—æ¨¡å‹ï¼ˆå¦‚RNNï¼‰çš„æ€§èƒ½ã€‚æˆ‘ä»¬å‘ç°æ ‡å‡†çš„RNNé€šå¸¸ä¸å…·å¤‡æµç­‰å˜æ€§ï¼Œæ— æ³•ä»¥å‡ ä½•ç»“æ„çš„æ–¹å¼å¯¹ç§»åŠ¨åˆºæ¿€è¿›è¡Œå˜æ¢ã€‚é€šè¿‡å¼•å…¥æµç­‰å˜æ€§ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒé€Ÿåº¦ã€é•¿åº¦æ³›åŒ–å’Œé€Ÿåº¦æ³›åŒ–ç­‰æ–¹é¢æ˜¾è‘—ä¼˜äºéç­‰å˜æ¨¡å‹ã€‚æ­¤ç ”ç©¶ä¸ºæ„å»ºå°Šé‡æ—¶é—´å‚æ•°åŒ–å¯¹ç§°æ€§çš„åºåˆ—æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (1)', '#agents (1)', '#agi (1)', '#alignment (1)', '#architecture (3)', '#audio', '#benchmark (2)', '#cv (1)', '#data', '#dataset (2)', '#diffusion', '#ethics', '#games (2)', '#graphs', '#hallucinations', '#healthcare', '#inference', '#interpretability (1)', '#leakage', '#long_context (1)', '#low_resource', '#machine_translation', '#math (1)', '#multilingual', '#multimodal (2)', '#open_source (1)', '#optimization (6)', '#plp', '#rag', '#reasoning (3)', '#rl (2)', '#rlhf', '#robotics (1)', '#science (1)', '#security', '#small_models', '#story_generation', '#survey (1)', '#synthetic', '#training (4)', '#transfer_learning', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            ğŸ”º ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'ğŸ”„ ' + getTimeDiff('2025-08-01 05:25',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ",
                    pub_date: "Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸",
                    issue_id: "Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "è¯„åˆ†",
                    pub_date: "å‘å¸ƒæ—¥æœŸ",
                    issue_id: "HFä¸Šä¼ æ—¥æœŸ"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-08-01 05:25')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-08-01 05:25')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    