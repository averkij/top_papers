
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>MergeVQ: A Unified Framework for Visual Generation and Representation
  with Disentangled Token Merging and Quantization</h1>
                <div><p class='zh-text'>1. 这篇文章介绍了一种新的图像生成模型，叫做 MergeVQ。</p>
<p class='zh-text'>2. 它结合了向量量化和 token 合并技术，旨在解决图像生成质量和表示学习效率之间的平衡问题。</p>
<p class='zh-text'>3. MergeVQ 在预训练阶段通过 token 合并模块提取语义信息，并在解码阶段恢复细节。</p>
<p class='zh-text'>4. 实验结果显示，MergeVQ 在图像生成和表示学习任务中都表现出色，且效率高。</p>
<p class='zh-text'>5. 代码和模型将在网上公开。</p></div>
                <div class="pinyin">
                    <p>1. 这篇文章介绍了一种新的图像生成模型，叫做 MergeVQ。它结合了向量量化和 token 合并技术，旨在解决图像生成质量和表示学习效率之间的平衡问题。MergeVQ 在预训练阶段通过 token 合并模块提取语义信息，并在解码阶段恢复细节。实验结果显示，MergeVQ 在图像生成和表示学习任务中都表现出色，且效率高。代码和模型将在网上公开。

Zhè piān wénzhāng jièshào le yīzhǒng xīn de túxiàng shēngchéng móxíng, jiàozuò MergeVQ</p>
<p>2.  Tā jiēhé le xiàngliàng liànggéhuà hé token hébìng jìshù, zhǐyú jiějué túxiàng shēngchéng zhìliàng hé biǎoshì xuéxí xiàoyì zhījiān de pínghéng wèntí</p>
<p>3.  MergeVQ zài yùxùnliàn jiēduàn tōngguò token hébìng mókuài tíqǔ yǔyì xìnxī, bìng zài jiěmǎ jiēduàn huīfù xìjiè</p>
<p>4.  Shíyàn jiéguǒ xiǎnshì, MergeVQ zài túxiàng shēngchéng hé biǎoshì xuéxí rènwù zhōng dōu biǎoxiàn chūsè, qiě xiàoyì gāo</p>
<p>5.  Dàimǎ hé móxíng jiāng zài wǎngshàng gōngkāi</p>
                </div>
                <div><p>1. This article introduces a new image generation model called MergeVQ.</p>
<p>2.  It combines vector quantization and token merging techniques to address the balance between image generation quality and representation learning efficiency.</p>
<p>3.  MergeVQ extracts semantic information through a token merging module during the pre-training phase and recovers details during the decoding phase.</p>
<p>4.  Experimental results show that MergeVQ performs excellently in both image generation and representation learning tasks, with high efficiency.</p>
<p>5.  The code and model will be made publicly available online.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">向量量化</td>
                            <td>xiàngliàng liàngzhì</td>
                            <td>vector quantization</td>
                        </tr>
            
                        <tr>
                            <td class="zh">token</td>
                            <td>tōukèn</td>
                            <td>token</td>
                        </tr>
            
                        <tr>
                            <td class="zh">合并</td>
                            <td>hébìng</td>
                            <td>merge</td>
                        </tr>
            
                        <tr>
                            <td class="zh">旨在</td>
                            <td>zhǐzài</td>
                            <td>aim to</td>
                        </tr>
            
                        <tr>
                            <td class="zh">平衡</td>
                            <td>pínghéng</td>
                            <td>balance</td>
                        </tr>
            
                        <tr>
                            <td class="zh">预训练</td>
                            <td>yù xùnliàn</td>
                            <td>pre-training</td>
                        </tr>
            
                        <tr>
                            <td class="zh">语义</td>
                            <td>yǔyì</td>
                            <td>semantic</td>
                        </tr>
            
                        <tr>
                            <td class="zh">解码</td>
                            <td>jiěmǎ</td>
                            <td>decode</td>
                        </tr>
            
                        <tr>
                            <td class="zh">恢复</td>
                            <td>huīfù</td>
                            <td>recover</td>
                        </tr>
            
                        <tr>
                            <td class="zh">细节</td>
                            <td>xìjié</td>
                            <td>detail</td>
                        </tr>
            
                        <tr>
                            <td class="zh">表现</td>
                            <td>biǎoxiàn</td>
                            <td>performance</td>
                        </tr>
            
                        <tr>
                            <td class="zh">出色</td>
                            <td>chūsè</td>
                            <td>outstanding</td>
                        </tr>
            
                        <tr>
                            <td class="zh">效率</td>
                            <td>xiàolǜ</td>
                            <td>efficiency</td>
                        </tr>
            
                        <tr>
                            <td class="zh">公开</td>
                            <td>gōngkāi</td>
                            <td>public</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        