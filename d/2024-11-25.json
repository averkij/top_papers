{
    "date": {
        "ru": "25 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
        "en": "November 25",
        "zh": "11æœˆ25æ—¥"
    },
    "time_utc": "2024-11-25 03:26",
    "weekday": 0,
    "issue_id": 752,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.14793",
            "title": "Style-Friendly SNR Sampler for Style-Driven Generation",
            "url": "https://huggingface.co/papers/2411.14793",
            "abstract": "Recent large-scale diffusion models generate high-quality images but struggle to learn new, personalized artistic styles, which limits the creation of unique style templates. Fine-tuning with reference images is the most promising approach, but it often blindly utilizes objectives and noise level distributions used for pre-training, leading to suboptimal style alignment. We propose the Style-friendly SNR sampler, which aggressively shifts the signal-to-noise ratio (SNR) distribution toward higher noise levels during fine-tuning to focus on noise levels where stylistic features emerge. This enables models to better capture unique styles and generate images with higher style alignment. Our method allows diffusion models to learn and share new \"style templates\", enhancing personalized content creation. We demonstrate the ability to generate styles such as personal watercolor paintings, minimal flat cartoons, 3D renderings, multi-panel images, and memes with text, thereby broadening the scope of style-driven generation.",
            "score": 10,
            "issue_id": 752,
            "pub_date": "2024-11-22",
            "pub_date_card": {
                "ru": "22 Ğ½Ğ¾ÑĞ±Ñ€Ñ",
                "en": "November 22",
                "zh": "11æœˆ22æ—¥"
            },
            "hash": "03859b57f29683ab",
            "authors": [
                "Jooyoung Choi",
                "Chaehun Shin",
                "Yeongtak Oh",
                "Heeseung Kim",
                "Sungroh Yoon"
            ],
            "affiliations": [
                "AIIS, ASRI, INMC, ISRC, and Interdisciplinary Program in AI, Seoul National University",
                "Data Science and AI Laboratory, ECE, Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14793.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#3d",
                    "#multimodal",
                    "#cv",
                    "#diffusion"
                ],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ° Ğ² Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾Ğ¼ ÑÑ‚Ğ¸Ğ»Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Style-friendly SNR sampler, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞ¼ĞµÑ‰Ğ°ĞµÑ‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ñ ÑĞ¸Ğ³Ğ½Ğ°Ğ»-ÑˆÑƒĞ¼ Ğ² ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñƒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ñ… ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¹ ÑˆÑƒĞ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞµ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ¸Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ ÑÑ‚Ğ¸Ğ»Ñ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑÑ‚Ğ¸Ğ»Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ°ĞºĞ²Ğ°Ñ€ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ¸ÑÑƒĞ½ĞºĞ¸, Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ñ„Ğ¸Ğ»ÑŒĞ¼Ñ‹, 3D-Ñ€ĞµĞ½Ğ´ĞµÑ€Ñ‹ Ğ¸ Ğ¼ĞµĞ¼Ñ‹ Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼."
                },
                "en": {
                    "title": "Unlocking Unique Artistic Styles with Style-friendly SNR Sampler",
                    "desc": "This paper addresses the challenge of adapting large-scale diffusion models to generate personalized artistic styles. The authors introduce the Style-friendly SNR sampler, which modifies the signal-to-noise ratio (SNR) during fine-tuning to emphasize higher noise levels where stylistic features are more prominent. By doing so, the model improves its ability to capture unique styles, resulting in images that align better with the desired artistic expression. The proposed method expands the creative possibilities for generating diverse styles, including watercolor paintings and cartoons, thus enhancing personalized content creation."
                },
                "zh": {
                    "title": "æå‡ä¸ªæ€§åŒ–è‰ºæœ¯é£æ ¼ç”Ÿæˆçš„ä¿¡å™ªæ¯”æ–¹æ³•",
                    "desc": "æœ€è¿‘çš„å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œä½†åœ¨å­¦ä¹ æ–°çš„ä¸ªæ€§åŒ–è‰ºæœ¯é£æ ¼æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œè¿™é™åˆ¶äº†ç‹¬ç‰¹é£æ ¼æ¨¡æ¿çš„åˆ›å»ºã€‚å¾®è°ƒå‚è€ƒå›¾åƒæ˜¯æœ€æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œä½†é€šå¸¸ç›²ç›®ä½¿ç”¨é¢„è®­ç»ƒæ—¶çš„ç›®æ ‡å’Œå™ªå£°æ°´å¹³åˆ†å¸ƒï¼Œå¯¼è‡´é£æ ¼å¯¹é½ä¸ç†æƒ³ã€‚æˆ‘ä»¬æå‡ºäº†é£æ ¼å‹å¥½çš„ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰é‡‡æ ·å™¨ï¼Œåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ç§¯æå°†ä¿¡å™ªæ¯”åˆ†å¸ƒå‘æ›´é«˜çš„å™ªå£°æ°´å¹³è½¬ç§»ï¼Œä»¥ä¸“æ³¨äºé£æ ¼ç‰¹å¾å‡ºç°çš„å™ªå£°æ°´å¹³ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ç‹¬ç‰¹é£æ ¼ï¼Œå¹¶ç”Ÿæˆå…·æœ‰æ›´é«˜é£æ ¼å¯¹é½çš„å›¾åƒã€‚"
                }
            }
        }
    ],
    "link_prev": "2024-11-22.html",
    "link_next": "2024-11-26.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "22.11",
        "en": "11/22",
        "zh": "11æœˆ22æ—¥"
    },
    "short_date_next": {
        "ru": "26.11",
        "en": "11/26",
        "zh": "11æœˆ26æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†ç°æœ‰å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è®­ç»ƒè¿‡ç¨‹åŠå…¶åœ¨åˆ†å¸ƒåç§»ä¸Šçš„å±€é™æ€§ã€‚ä¸ºäº†æå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œä½œè€…å¼•å…¥äº†åå¥½ä¼˜åŒ–ï¼ˆPOï¼‰è¿‡ç¨‹ã€‚ä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªé«˜è´¨é‡çš„å¤šæ¨¡æ€æ¨ç†åå¥½æ•°æ®é›†MMPRï¼Œå¹¶å¼€å‘äº†ä¸€ç§æ··åˆåå¥½ä¼˜åŒ–ï¼ˆMPOï¼‰æ–¹æ³•ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ä¸­ã€‚ä½œè€…å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½æ¿€å‘æ›´å¤šè¿›å±•ã€‚ä»£ç ã€æ•°æ®å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒã€‚",
        "title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†ç°æœ‰å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è®­ç»ƒè¿‡ç¨‹åŠå…¶åœ¨åˆ†å¸ƒåç§»ä¸Šçš„å±€é™æ€§ã€‚\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le xiÃ nyÇ’u kÄiyuÃ¡n duÅ mÃ³shÃ¬ dÃ  yÇ”yÃ¡n mÃ³xÃ­ng (MLLMs) de xÃ¹nliÃ n guÃ²chÃ©ng jÃ­ qÃ­ zÃ i fÄ“nbÃ¹ piÄnyÃ­ shÃ ng de jÃºxÃ¬anxÃ¬ng.\n\nä¸ºäº†æå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œä½œè€…å¼•å…¥äº†åå¥½ä¼˜åŒ–ï¼ˆPOï¼‰è¿‡ç¨‹ã€‚\nWÃ¨ile tÃ­shÄ“ng duÅ mÃ³shÃ¬ tuÄ«lÇ nÃ©nglÃ¬, zuÃ²zhÄ› yÇnrÃ¹ le piÄnhÃ o yÅuhuÃ  (PO) guÃ²chÃ©ng.\n\nä»–ä»¬åˆ›å»ºäº†ä¸€ä¸ªé«˜è´¨é‡çš„å¤šæ¨¡æ€æ¨ç†åå¥½æ•°æ®é›†MMPRï¼Œå¹¶å¼€å‘äº†ä¸€ç§æ··åˆåå¥½ä¼˜åŒ–ï¼ˆMPOï¼‰æ–¹æ³•ã€‚\nTÄmen chuÃ ngjiÃ n le yÄ«gÃ¨ gÄo zhÃ¬liÃ ng de duÅ mÃ³shÃ¬ tuÄ«lÇ piÄnhÃ o shÃ¹jÃ¹jÃ­ MMPR, bÃ¬ng kÄifÄ le yÄ«zhÇ’ng hÃ¹nhÃ© piÄnhÃ o yÅuhuÃ  (MPO) fÄngfÇ.\n\nç»“æœæ˜¾ç¤ºï¼Œè¿™ç§æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ä¸­ã€‚\nJiÃ©gÇ”o xiÇnshÃ¬, zhÃ¨ zhÇ’ng fÄngfÇ zÃ i duÅ gÃ¨ jÄ«zhÇ”n cÃ¨shÃ¬ zhÅng biÇoxiÃ n chÅ«sÃ¨, tÃ¨biÃ© shÃ¬ zÃ i duÅ mÃ³shÃ¬ tuÄ«lÇ rÃ¨nwÃ¹ zhÅng.\n\nä½œè€…å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½æ¿€å‘æ›´å¤šè¿›å±•ã€‚\nZuÃ²zhÄ› xÄ«wÃ ng zhÃ¨ xiÃ ng yÃ¡njiÅ« nÃ©ng jÄ«fÄ gÃ¨ng duÅ jÃ¬nzhÇn.\n\nä»£ç ã€æ•°æ®å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒã€‚\nDÃ imÇ, shÃ¹jÃ¹ hÃ© mÃ³xÃ­ng jiÄng gÅngkÄi fÄbÃ¹.",
        "vocab": "[{'word': 'è®¨è®º', 'pinyin': 'tÇo lÃ¹n', 'trans': 'discuss'},\n{'word': 'ç°æœ‰', 'pinyin': 'xiÃ n yÇ’u', 'trans': 'existing'},\n{'word': 'å¼€æº', 'pinyin': 'kÄi yuÃ¡n', 'trans': 'open-source'},\n{'word': 'å¤šæ¨¡æ€', 'pinyin': 'duÅ mÃ³ tÃ i', 'trans': 'multimodal'},\n{'word': 'å¤§è¯­è¨€æ¨¡å‹', 'pinyin': 'dÃ  yÇ” yÃ¡n mÃ³ xÃ­ng', 'trans': 'large language model'},\n{'word': 'è®­ç»ƒ', 'pinyin': 'xÃ¹n liÃ n', 'trans': 'train'},\n{'word': 'è¿‡ç¨‹', 'pinyin': 'guÃ² chÃ©ng', 'trans': 'process'},\n{'word': 'å±€é™æ€§', 'pinyin': 'jÃº xiÃ n xÃ¬ng', 'trans': 'limitations'},\n{'word': 'æå‡', 'pinyin': 'tÃ­ shÄ“ng', 'trans': 'enhance'},\n{'word': 'æ¨ç†', 'pinyin': 'tuÄ« lÇ', 'trans': 'reasoning'},\n{'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©ng lÃ¬', 'trans': 'ability'},\n{'word': 'å¼•å…¥', 'pinyin': 'yÇn rÃ¹', 'trans': 'introduce'},\n{'word': 'åå¥½', 'pinyin': 'piÄn hÃ o', 'trans': 'preference'},\n{'word': 'ä¼˜åŒ–', 'pinyin': 'yÅu huÃ ', 'trans': 'optimization'},\n{'word': 'åˆ›å»º', 'pinyin': 'chuÃ ng jiÃ n', 'trans': 'create'},\n{'word': 'é«˜è´¨é‡', 'pinyin': 'gÄo zhÃ¬ liÃ ng', 'trans': 'high-quality'},\n{'word': 'æ•°æ®é›†', 'pinyin': 'shÃ¹ jÃ¹ jÃ­', 'trans': 'dataset'},\n{'word': 'å¼€å‘', 'pinyin': 'kÄi fÄ', 'trans': 'develop'},\n{'word': 'æ··åˆ', 'pinyin': 'hÃ¹n hÃ©', 'trans': 'hybrid'},\n{'word': 'æ–¹æ³•', 'pinyin': 'fÄng fÇ', 'trans': 'method'},\n{'word': 'è¡¨ç°', 'pinyin': 'biÇo xiÃ n', 'trans': 'performance'},\n{'word': 'å‡ºè‰²', 'pinyin': 'chÅ« sÃ¨', 'trans': 'outstanding'},\n{'word': 'ç‰¹åˆ«', 'pinyin': 'tÃ¨ biÃ©', 'trans': 'particularly'},\n{'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨n wu', 'trans': 'task'},\n{'word': 'æ¿€å‘', 'pinyin': 'jÄ« fÄ', 'trans': 'inspire'},\n{'word': 'è¿›å±•', 'pinyin': 'jÃ¬n zhÇn', 'trans': 'progress'},\n{'word': 'å…¬å¼€', 'pinyin': 'gÅng kÄi', 'trans': 'public'},\n{'word': 'å‘å¸ƒ', 'pinyin': 'fÄ bÃ¹', 'trans': 'release'}]",
        "trans": "This article discusses the training process of existing open-source multimodal large language models (MLLMs) and their limitations in distribution shifts. To enhance multimodal reasoning capabilities, the authors introduce a preference optimization (PO) process. They created a high-quality multimodal reasoning preference dataset called MMPR and developed a hybrid preference optimization (MPO) method. The results show that this method performs excellently on multiple benchmark tests, particularly in multimodal reasoning tasks. The authors hope that this research will inspire further advancements. The code, data, and models will be publicly released.",
        "update_ts": "2024-11-24 09:32"
    }
}