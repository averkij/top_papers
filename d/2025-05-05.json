{
    "date": {
        "ru": "5 мая",
        "en": "May 5",
        "zh": "5月5日"
    },
    "time_utc": "2025-05-05 16:14",
    "weekday": 0,
    "issue_id": 3593,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2504.20438",
            "title": "PixelHacker: Image Inpainting with Structural and Semantic Consistency",
            "url": "https://huggingface.co/papers/2504.20438",
            "abstract": "Image inpainting is a fundamental research area between image editing and image generation. Recent state-of-the-art (SOTA) methods have explored novel attention mechanisms, lightweight architectures, and context-aware modeling, demonstrating impressive performance. However, they often struggle with complex structure (e.g., texture, shape, spatial relations) and semantics (e.g., color consistency, object restoration, and logical correctness), leading to artifacts and inappropriate generation. To address this challenge, we design a simple yet effective inpainting paradigm called latent categories guidance, and further propose a diffusion-based model named PixelHacker. Specifically, we first construct a large dataset containing 14 million image-mask pairs by annotating foreground and background (potential 116 and 21 categories, respectively). Then, we encode potential foreground and background representations separately through two fixed-size embeddings, and intermittently inject these features into the denoising process via linear attention. Finally, by pre-training on our dataset and fine-tuning on open-source benchmarks, we obtain PixelHacker. Extensive experiments show that PixelHacker comprehensively outperforms the SOTA on a wide range of datasets (Places2, CelebA-HQ, and FFHQ) and exhibits remarkable consistency in both structure and semantics. Project page at https://hustvl.github.io/PixelHacker.",
            "score": 23,
            "issue_id": 3584,
            "pub_date": "2025-04-29",
            "pub_date_card": {
                "ru": "29 апреля",
                "en": "April 29",
                "zh": "4月29日"
            },
            "hash": "987ce511e3c86e06",
            "authors": [
                "Ziyang Xu",
                "Kangsheng Duan",
                "Xiaolei Shen",
                "Zhifeng Ding",
                "Wenyu Liu",
                "Xiaohu Ruan",
                "Xiaoxin Chen",
                "Xinggang Wang"
            ],
            "affiliations": [
                "Huazhong University of Science and Technology",
                "VIVO AI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.20438.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#dataset",
                    "#training",
                    "#open_source",
                    "#optimization",
                    "#diffusion",
                    "#cv"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "PixelHacker: Революционный подход к восстановлению изображений с помощью латентных категорий",
                    "desc": "В статье представлен новый подход к задаче восстановления изображений под названием PixelHacker. Авторы разработали метод латентного категориального управления, используя большой набор данных из 14 миллионов пар изображение-маска с аннотациями переднего и заднего плана. PixelHacker применяет диффузионную модель с внедрением признаков через линейное внимание. Эксперименты показывают, что PixelHacker превосходит современные методы на различных наборах данных, демонстрируя высокую согласованность структуры и семантики изображений."
                },
                "en": {
                    "title": "PixelHacker: Revolutionizing Image Inpainting with Latent Categories Guidance",
                    "desc": "This paper presents a new approach to image inpainting called PixelHacker, which aims to improve the quality of generated images by addressing issues with complex structures and semantics. The authors introduce a large dataset of 14 million image-mask pairs to train their model, focusing on distinguishing between foreground and background categories. They utilize a diffusion-based model that incorporates linear attention to enhance the denoising process, ensuring better consistency in texture and color. Experimental results demonstrate that PixelHacker significantly outperforms existing state-of-the-art methods across various datasets, achieving superior image restoration results."
                },
                "zh": {
                    "title": "PixelHacker：图像修复的新突破",
                    "desc": "图像修复是图像编辑与生成之间的一个重要研究领域。最近的最先进方法探索了新颖的注意力机制、轻量级架构和上下文感知建模，取得了显著的性能。然而，这些方法在处理复杂结构和语义时常常面临挑战，导致生成的图像出现伪影和不当生成。为了解决这个问题，我们设计了一种简单而有效的修复范式，称为潜在类别引导，并提出了一种基于扩散的模型PixelHacker。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.01079",
            "title": "Improving Editability in Image Generation with Layer-wise Memory",
            "url": "https://huggingface.co/papers/2505.01079",
            "abstract": "Most real-world image editing tasks require multiple sequential edits to achieve desired results. Current editing approaches, primarily designed for single-object modifications, struggle with sequential editing: especially with maintaining previous edits along with adapting new objects naturally into the existing content. These limitations significantly hinder complex editing scenarios where multiple objects need to be modified while preserving their contextual relationships. We address this fundamental challenge through two key proposals: enabling rough mask inputs that preserve existing content while naturally integrating new elements and supporting consistent editing across multiple modifications. Our framework achieves this through layer-wise memory, which stores latent representations and prompt embeddings from previous edits. We propose Background Consistency Guidance that leverages memorized latents to maintain scene coherence and Multi-Query Disentanglement in cross-attention that ensures natural adaptation to existing content. To evaluate our method, we present a new benchmark dataset incorporating semantic alignment metrics and interactive editing scenarios. Through comprehensive experiments, we demonstrate superior performance in iterative image editing tasks with minimal user effort, requiring only rough masks while maintaining high-quality results throughout multiple editing steps.",
            "score": 17,
            "issue_id": 3582,
            "pub_date": "2025-05-02",
            "pub_date_card": {
                "ru": "2 мая",
                "en": "May 2",
                "zh": "5月2日"
            },
            "hash": "e1aa83ea7926943e",
            "authors": [
                "Daneul Kim",
                "Jaeah Lee",
                "Jaesik Park"
            ],
            "affiliations": [
                "Seoul National University, Republic of Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.01079.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#cv"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Умное последовательное редактирование изображений: сохраняем прошлое, добавляем новое",
                    "desc": "Статья представляет новый подход к последовательному редактированию изображений с использованием нейронных сетей. Авторы предлагают метод, позволяющий сохранять предыдущие изменения и естественно интегрировать новые элементы в существующий контент. Ключевые инновации включают использование приблизительных масок, послойную память для хранения латентных представлений и применение техник Background Consistency Guidance и Multi-Query Disentanglement. Эффективность метода подтверждается экспериментами на новом наборе данных с метриками семантического выравнивания."
                },
                "en": {
                    "title": "Seamless Sequential Image Editing with Context Preservation",
                    "desc": "This paper addresses the challenges of sequential image editing, where multiple edits are needed while keeping previous changes intact. Current methods struggle with integrating new objects into existing images without disrupting the overall context. The authors propose a framework that uses layer-wise memory to store previous edits and ensure consistency across modifications. Their approach includes Background Consistency Guidance and Multi-Query Disentanglement to enhance the natural integration of new elements, leading to improved performance in complex editing tasks with minimal user input."
                },
                "zh": {
                    "title": "实现自然连续的图像编辑",
                    "desc": "本论文探讨了图像编辑中的多次连续编辑问题，现有方法在处理多个对象的修改时存在困难，尤其是在保持之前编辑内容的同时自然地融入新对象。我们提出了两项关键方案：一是支持粗略的掩膜输入，以保留现有内容并自然整合新元素；二是支持多次修改的一致性编辑。我们的框架通过层级记忆存储先前编辑的潜在表示和提示嵌入，利用背景一致性引导保持场景的连贯性。实验结果表明，我们的方法在迭代图像编辑任务中表现优越，用户只需提供粗略掩膜即可实现高质量的编辑效果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.21117",
            "title": "Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG\n  Evaluation Prompts",
            "url": "https://huggingface.co/papers/2504.21117",
            "abstract": "Evaluating natural language generation (NLG) systems is challenging due to the diversity of valid outputs. While human evaluation is the gold standard, it suffers from inconsistencies, lack of standardisation, and demographic biases, limiting reproducibility. LLM-based evaluation offers a scalable alternative but is highly sensitive to prompt design, where small variations can lead to significant discrepancies. In this work, we propose an inversion learning method that learns effective reverse mappings from model outputs back to their input instructions, enabling the automatic generation of highly effective, model-specific evaluation prompts. Our method requires only a single evaluation sample and eliminates the need for time-consuming manual prompt engineering, thereby improving both efficiency and robustness. Our work contributes toward a new direction for more robust and efficient LLM-based evaluation.",
            "score": 11,
            "issue_id": 3587,
            "pub_date": "2025-04-29",
            "pub_date_card": {
                "ru": "29 апреля",
                "en": "April 29",
                "zh": "4月29日"
            },
            "hash": "2a43e27932acf80e",
            "authors": [
                "Hanhua Hong",
                "Chenghao Xiao",
                "Yang Wang",
                "Yiqi Liu",
                "Wenge Rong",
                "Chenghua Lin"
            ],
            "affiliations": [
                "Beihang University",
                "Durham University",
                "The University of Manchester"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.21117.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#optimization",
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Автоматическая генерация промптов для надежной оценки NLG систем",
                    "desc": "Статья посвящена проблеме оценки систем генерации естественного языка (NLG) и предлагает новый метод на основе обучения инверсии. Этот подход позволяет автоматически создавать эффективные промпты для оценки, специфичные для конкретной модели, используя только один образец. Метод устраняет необходимость в трудоемкой ручной разработке промптов, повышая эффективность и надежность оценки. Работа открывает новое направление для более надежной и эффективной оценки с использованием языковых моделей (LLM)."
                },
                "en": {
                    "title": "Revolutionizing NLG Evaluation with Inversion Learning",
                    "desc": "This paper addresses the difficulties in evaluating natural language generation (NLG) systems, particularly the inconsistencies and biases in human evaluations. It introduces an inversion learning method that creates effective prompts for evaluating models by learning from their outputs. This approach allows for automatic generation of tailored evaluation prompts, requiring only one sample, which enhances efficiency. The proposed method aims to improve the robustness of LLM-based evaluations, paving the way for more standardized assessment in NLG."
                },
                "zh": {
                    "title": "提升自然语言生成评估的效率与稳健性",
                    "desc": "评估自然语言生成（NLG）系统是一个具有挑战性的任务，因为有效输出的多样性使得标准化评估变得困难。虽然人工评估被认为是金标准，但其存在不一致性、缺乏标准化和人口偏见等问题，限制了可重复性。基于大型语言模型（LLM）的评估提供了一种可扩展的替代方案，但对提示设计非常敏感，微小的变化可能导致显著的差异。我们提出了一种反演学习方法，可以有效地从模型输出反向映射到输入指令，从而自动生成高效的、特定于模型的评估提示，提升了评估的效率和稳健性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00949",
            "title": "Llama-Nemotron: Efficient Reasoning Models",
            "url": "https://huggingface.co/papers/2505.00949",
            "abstract": "We introduce the Llama-Nemotron series of models, an open family of heterogeneous reasoning models that deliver exceptional reasoning capabilities, inference efficiency, and an open license for enterprise use. The family comes in three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs competitively with state-of-the-art reasoning models such as DeepSeek-R1 while offering superior inference throughput and memory efficiency. In this report, we discuss the training procedure for these models, which entails using neural architecture search from Llama 3 models for accelerated inference, knowledge distillation, and continued pretraining, followed by a reasoning-focused post-training stage consisting of two main parts: supervised fine-tuning and large scale reinforcement learning. Llama-Nemotron models are the first open-source models to support a dynamic reasoning toggle, allowing users to switch between standard chat and reasoning modes during inference. To further support open research and facilitate model development, we provide the following resources: 1. We release the Llama-Nemotron reasoning models -- LN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA Open Model License Agreement. 2. We release the complete post-training dataset: Llama-Nemotron-Post-Training-Dataset. 3. We also release our training codebases: NeMo, NeMo-Aligner, and Megatron-LM.",
            "score": 7,
            "issue_id": 3587,
            "pub_date": "2025-05-02",
            "pub_date_card": {
                "ru": "2 мая",
                "en": "May 2",
                "zh": "5月2日"
            },
            "hash": "cbc28025b0c6bde3",
            "authors": [
                "Akhiad Bercovich",
                "Itay Levy",
                "Izik Golan",
                "Mohammad Dabbah",
                "Ran El-Yaniv",
                "Omri Puny",
                "Ido Galil",
                "Zach Moshe",
                "Tomer Ronen",
                "Najeeb Nabwani",
                "Ido Shahaf",
                "Oren Tropp",
                "Ehud Karpas",
                "Ran Zilberstein",
                "Jiaqi Zeng",
                "Soumye Singhal",
                "Alexander Bukharin",
                "Yian Zhang",
                "Tugrul Konuk",
                "Gerald Shen",
                "Ameya Sunil Mahabaleshwarkar",
                "Bilal Kartal",
                "Yoshi Suhara",
                "Olivier Delalleau",
                "Zijia Chen",
                "Zhilin Wang",
                "David Mosallanezhad",
                "Adi Renduchintala",
                "Haifeng Qian",
                "Dima Rekesh",
                "Fei Jia",
                "Somshubra Majumdar",
                "Vahid Noroozi",
                "Wasi Uddin Ahmad",
                "Sean Narenthiran",
                "Aleksander Ficek",
                "Mehrzad Samadi",
                "Jocelyn Huang",
                "Siddhartha Jain",
                "Igor Gitman",
                "Ivan Moshkov",
                "Wei Du",
                "Shubham Toshniwal",
                "George Armstrong",
                "Branislav Kisacanin",
                "Matvei Novikov",
                "Daria Gitman",
                "Evelina Bakhturina",
                "Jane Polak Scowcroft",
                "John Kamalu",
                "Dan Su",
                "Kezhi Kong",
                "Markus Kliegl",
                "Rabeeh Karimi",
                "Ying Lin",
                "Sanjeev Satheesh",
                "Jupinder Parmar",
                "Pritam Gundecha",
                "Brandon Norick",
                "Joseph Jennings",
                "Shrimai Prabhumoye",
                "Syeda Nahida Akter",
                "Mostofa Patwary",
                "Abhinav Khattar",
                "Deepak Narayanan",
                "Roger Waleffe",
                "Jimmy Zhang",
                "Bor-Yiing Su",
                "Guyue Huang",
                "Terry Kong",
                "Parth Chadha",
                "Sahil Jain",
                "Christine Harvey",
                "Elad Segal",
                "Jining Huang",
                "Sergey Kashirsky",
                "Robert McQueen",
                "Izzy Putterman",
                "George Lam",
                "Arun Venkatesan",
                "Sherry Wu",
                "Vinh Nguyen",
                "Manoj Kilaru",
                "Andrew Wang",
                "Anna Warno",
                "Abhilash Somasamudramath",
                "Sandip Bhaskar",
                "Maka Dong",
                "Nave Assaf",
                "Shahar Mor",
                "Omer Ullman Argov",
                "Scot Junkin",
                "Oleksandr Romanenko",
                "Pedro Larroy",
                "Monika Katariya",
                "Marco Rovinelli",
                "Viji Balas",
                "Nicholas Edelman",
                "Anahita Bhiwandiwalla",
                "Muthu Subramaniam",
                "Smita Ithape",
                "Karthik Ramamoorthy",
                "Yuting Wu",
                "Suguna Varshini Velury",
                "Omri Almog",
                "Joyjit Daw",
                "Denys Fridman",
                "Erick Galinkin",
                "Michael Evans",
                "Katherine Luna",
                "Leon Derczynski",
                "Nikki Pope",
                "Eileen Long",
                "Seth Schneider",
                "Guillermo Siman",
                "Tomasz Grzegorzek",
                "Pablo Ribalta",
                "Monika Katariya",
                "Joey Conway",
                "Trisha Saar",
                "Ann Guan",
                "Krzysztof Pawelec",
                "Shyamala Prayaga",
                "Oleksii Kuchaiev",
                "Boris Ginsburg",
                "Oluwatobi Olabiyi",
                "Kari Briski",
                "Jonathan Cohen",
                "Bryan Catanzaro",
                "Jonah Alben",
                "Yonatan Geifman",
                "Eric Chung"
            ],
            "affiliations": [
                "NVIDIA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00949.jpg",
            "data": {
                "categories": [
                    "#agi",
                    "#training",
                    "#rl",
                    "#open_source",
                    "#architecture",
                    "#dataset",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Открытые модели рассуждений нового поколения",
                    "desc": "Представлена серия моделей Llama-Nemotron - семейство гетерогенных моделей рассуждений с открытым исходным кодом. Модели доступны в трех размерах (8B, 49B, 253B) и обеспечивают высокую производительность и эффективность использования памяти. Обучение включает нейроархитектурный поиск, дистилляцию знаний и дообучение, а также этап постобработки с акцентом на рассуждения. Модели поддерживают динамическое переключение между режимами обычного чата и рассуждений."
                },
                "en": {
                    "title": "Unlocking Reasoning with Open-Source Efficiency",
                    "desc": "The Llama-Nemotron series introduces a new family of reasoning models designed for efficient inference and strong reasoning capabilities. These models come in three sizes, allowing flexibility for different applications while maintaining competitive performance against leading models. The training process involves advanced techniques like neural architecture search, knowledge distillation, and reinforcement learning to enhance reasoning abilities. Additionally, these models are open-source, providing resources for further research and development in the machine learning community."
                },
                "zh": {
                    "title": "开放推理模型，提升推理效率！",
                    "desc": "Llama-Nemotron系列模型是一种开放的异构推理模型，具有卓越的推理能力和高效的推理性能。该系列包括三种不同规模的模型：Nano（8B）、Super（49B）和Ultra（253B），在推理速度和内存效率上优于现有的最先进模型。模型的训练过程采用了神经架构搜索、知识蒸馏和持续预训练，最后通过监督微调和大规模强化学习进行推理专注的后训练阶段。Llama-Nemotron模型是首个支持动态推理切换的开源模型，用户可以在推理过程中在标准聊天模式和推理模式之间切换。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00174",
            "title": "Real-World Gaps in AI Governance Research",
            "url": "https://huggingface.co/papers/2505.00174",
            "abstract": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI papers (January 2020 - March 2025), we compare research outputs of leading AI companies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI universities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of Washington). We find that corporate AI research increasingly concentrates on pre-deployment areas -- model alignment and testing & evaluation -- while attention to deployment-stage issues such as model bias has waned. Significant research gaps exist in high-risk deployment domains, including healthcare, finance, misinformation, persuasive and addictive features, hallucinations, and copyright. Without improved observability into deployed AI, growing corporate concentration could deepen knowledge deficits. We recommend expanding external researcher access to deployment data and systematic observability of in-market AI behaviors.",
            "score": 5,
            "issue_id": 3582,
            "pub_date": "2025-04-30",
            "pub_date_card": {
                "ru": "30 апреля",
                "en": "April 30",
                "zh": "4月30日"
            },
            "hash": "7618edbafcee6b13",
            "authors": [
                "Ilan Strauss",
                "Isobel Moure",
                "Tim O'Reilly",
                "Sruly Rosenblat"
            ],
            "affiliations": [
                "AI Disclosures Project, Social Science Research Council",
                "Institute for Innovation and Public Purpose, University College London",
                "OReilly Media"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00174.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#ethics",
                    "#alignment",
                    "#healthcare",
                    "#hallucinations",
                    "#data"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Корпоративные исследования ИИ: пробелы в безопасности и необходимость прозрачности",
                    "desc": "Статья анализирует 1178 работ по безопасности и надежности из 9439 статей по генеративному ИИ за период с января 2020 по март 2025 года. Исследователи сравнивают результаты ведущих компаний и университетов в области ИИ. Обнаружено, что корпоративные исследования ИИ все больше концентрируются на предварительном развертывании, включая выравнивание моделей и тестирование, в то время как внимание к проблемам этапа развертывания, таким как смещение модели, ослабевает. Авторы рекомендуют расширить доступ внешних исследователей к данным развертывания и систематическое наблюдение за поведением ИИ на рынке."
                },
                "en": {
                    "title": "Bridging the Gap: Enhancing AI Safety in Deployment",
                    "desc": "This paper analyzes the trends in safety and reliability research within generative AI by examining 1,178 papers from major AI companies and universities. It highlights a shift in focus towards pre-deployment concerns like model alignment and evaluation, while issues related to deployment, such as model bias, are receiving less attention. The authors identify critical research gaps in high-risk areas like healthcare and finance, where the implications of AI deployment can be significant. They advocate for better access to deployment data and enhanced observability of AI systems in real-world applications to address these gaps."
                },
                "zh": {
                    "title": "关注人工智能部署阶段的研究缺口",
                    "desc": "本研究分析了1178篇安全性和可靠性论文与9439篇生成式人工智能论文，比较了主要人工智能公司和大学的研究成果。研究发现，企业的人工智能研究越来越集中在模型对齐和测试评估等预部署领域，而对部署阶段问题如模型偏见的关注有所减少。高风险部署领域（如医疗、金融、虚假信息等）存在显著的研究空白。为了改善对已部署人工智能的可观察性，建议扩大外部研究人员对部署数据的访问，并系统化市场中人工智能行为的可观察性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00023",
            "title": "CORG: Generating Answers from Complex, Interrelated Contexts",
            "url": "https://huggingface.co/papers/2505.00023",
            "abstract": "In a real-world corpus, knowledge frequently recurs across documents but often contains inconsistencies due to ambiguous naming, outdated information, or errors, leading to complex interrelationships between contexts. Previous research has shown that language models struggle with these complexities, typically focusing on single factors in isolation. We classify these relationships into four types: distracting, ambiguous, counterfactual, and duplicated. Our analysis reveals that no single approach effectively addresses all these interrelationships simultaneously. Therefore, we introduce Context Organizer (CORG), a framework that organizes multiple contexts into independently processed groups. This design allows the model to efficiently find all relevant answers while ensuring disambiguation. CORG consists of three key components: a graph constructor, a reranker, and an aggregator. Our results demonstrate that CORG balances performance and efficiency effectively, outperforming existing grouping methods and achieving comparable results to more computationally intensive, single-context approaches.",
            "score": 5,
            "issue_id": 3582,
            "pub_date": "2025-04-25",
            "pub_date_card": {
                "ru": "25 апреля",
                "en": "April 25",
                "zh": "4月25日"
            },
            "hash": "46da290a5c894311",
            "authors": [
                "Hyunji Lee",
                "Franck Dernoncourt",
                "Trung Bui",
                "Seunghyun Yoon"
            ],
            "affiliations": [
                "Adobe Research",
                "KAIST AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00023.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#multimodal",
                    "#graphs",
                    "#architecture",
                    "#data"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "CORG: Умная организация контекста для улучшения работы языковых моделей",
                    "desc": "Статья представляет новый фреймворк под названием Context Organizer (CORG) для обработки сложных взаимосвязей между контекстами в корпусах реального мира. CORG организует множественные контексты в независимо обрабатываемые группы, что позволяет эффективно находить все релевантные ответы и обеспечивать устранение неоднозначности. Фреймворк состоит из трех ключевых компонентов: конструктора графов, ранжировщика и агрегатора. Результаты показывают, что CORG эффективно балансирует производительность и эффективность, превосходя существующие методы группировки."
                },
                "en": {
                    "title": "Organizing Contexts for Better Language Understanding",
                    "desc": "This paper addresses the challenges faced by language models when dealing with complex interrelationships in real-world data, which often contain inconsistencies. It categorizes these relationships into four types: distracting, ambiguous, counterfactual, and duplicated, highlighting that existing methods typically fail to handle them all at once. To tackle this issue, the authors propose a new framework called Context Organizer (CORG), which organizes contexts into separate groups for independent processing. CORG includes a graph constructor, a reranker, and an aggregator, and it demonstrates improved performance and efficiency compared to traditional methods."
                },
                "zh": {
                    "title": "上下文组织，提升模型效率与准确性",
                    "desc": "在现实世界的语料库中，知识经常在文档中重复出现，但由于命名模糊、信息过时或错误，导致上下文之间存在复杂的相互关系。以往的研究表明，语言模型在处理这些复杂性时通常只关注单一因素。我们将这些关系分为四种类型：干扰、模糊、反事实和重复。为了解决这些问题，我们提出了上下文组织器（CORG），它将多个上下文组织成独立处理的组，从而提高模型的效率和准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.00562",
            "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
            "url": "https://huggingface.co/papers/2505.00562",
            "abstract": "Learning to solve complex tasks with signal temporal logic (STL) specifications is crucial to many real-world applications. However, most previous works only consider fixed or parametrized STL specifications due to the lack of a diverse STL dataset and encoders to effectively extract temporal logic information for downstream tasks. In this paper, we propose TeLoGraF, Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN) encoder and flow-matching to learn solutions for general STL specifications. We identify four commonly used STL templates and collect a total of 200K specifications with paired demonstrations. We conduct extensive experiments in five simulation environments ranging from simple dynamical models in the 2D space to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped navigation. Results show that our method outperforms other baselines in the STL satisfaction rate. Compared to classical STL planning algorithms, our approach is 10-100X faster in inference and can work on any system dynamics. Besides, we show our graph-encoding method's capability to solve complex STLs and robustness to out-distribution STL specifications. Code is available at https://github.com/mengyuest/TeLoGraF",
            "score": 2,
            "issue_id": 3583,
            "pub_date": "2025-05-01",
            "pub_date_card": {
                "ru": "1 мая",
                "en": "May 1",
                "zh": "5月1日"
            },
            "hash": "bf5b246f5848fa6e",
            "authors": [
                "Yue Meng",
                "Chuchu Fan"
            ],
            "affiliations": [
                "Department of Aeronautics and Astronautics, MIT, Cambridge, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.00562.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#inference",
                    "#agents",
                    "#robotics",
                    "#graphs",
                    "#optimization"
                ],
                "emoji": "⏱️",
                "ru": {
                    "title": "Графовые нейросети для эффективного решения задач темпоральной логики",
                    "desc": "Статья представляет TeLoGraF - новый метод для решения задач с темпоральной логикой сигналов (STL). Авторы используют графовые нейронные сети и технику flow-matching для обучения на разнообразном наборе STL-спецификаций. Эксперименты проводились в пяти симуляционных средах, от простых 2D-моделей до сложных роботов. Результаты показывают превосходство TeLoGraF над базовыми методами по скорости и универсальности применения."
                },
                "en": {
                    "title": "TeLoGraF: Fast and Robust Solutions for Complex Temporal Logic Tasks",
                    "desc": "This paper introduces TeLoGraF, a novel approach that leverages Graph Neural Networks (GNN) to effectively learn solutions for complex tasks defined by signal temporal logic (STL) specifications. The authors address the limitations of previous methods that relied on fixed STL templates by creating a diverse dataset of 200,000 STL specifications paired with demonstrations. Through extensive experiments across various simulation environments, TeLoGraF demonstrates superior performance in STL satisfaction rates and significantly faster inference times compared to traditional STL planning algorithms. Additionally, the graph-encoding technique shows robustness in handling complex and out-of-distribution STL specifications, making it a versatile tool for real-world applications."
                },
                "zh": {
                    "title": "TeLoGraF：高效解决复杂时序逻辑任务的创新方法",
                    "desc": "本文提出了一种新的方法TeLoGraF，用于解决复杂任务的信号时序逻辑（STL）规范。我们利用图神经网络（GNN）编码器和流匹配技术，学习通用STL规范的解决方案。通过收集20万个配对示例，我们在多个仿真环境中进行了广泛实验，结果表明该方法在STL满足率上优于其他基线。与传统的STL规划算法相比，我们的方法在推理速度上快10到100倍，并且能够适应任何系统动态。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.20859",
            "title": "X-Cross: Dynamic Integration of Language Models for Cross-Domain\n  Sequential Recommendation",
            "url": "https://huggingface.co/papers/2504.20859",
            "abstract": "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents ``X-Cross'' -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA). Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models. These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains. Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25% of the additional parameters. In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50%-75% less fine-tuning data than LoRA to make fine-tuning effective. Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines. Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments.",
            "score": 2,
            "issue_id": 3583,
            "pub_date": "2025-04-29",
            "pub_date_card": {
                "ru": "29 апреля",
                "en": "April 29",
                "zh": "4月29日"
            },
            "hash": "2102f697cfc2375e",
            "authors": [
                "Guy Hadad",
                "Haggai Roitman",
                "Yotam Eshel",
                "Bracha Shapira",
                "Lior Rokach"
            ],
            "affiliations": [
                "Ben-Gurion University of the Negev Beer Sheva, Israel",
                "eBay Netanya, Israel"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.20859.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#transfer_learning",
                    "#low_resource",
                    "#training",
                    "#multimodal"
                ],
                "emoji": "🔀",
                "ru": {
                    "title": "X-Cross: эффективные кросс-доменные рекомендации без обширного переобучения",
                    "desc": "Статья представляет модель X-Cross для кросс-доменных последовательных рекомендаций, использующую несколько доменно-специфичных языковых моделей с низкоранговыми адаптерами (LoRA). X-Cross динамически улучшает представления каждой исходной языковой модели, интегрируя знания из всех других моделей. Эксперименты на данных Amazon показывают, что X-Cross достигает производительности, сравнимой с моделью, дообученной с LoRA, используя лишь 25% дополнительных параметров. Модель демонстрирует надежную производительность в кросс-доменных задачах, требуя на 50-75% меньше данных для эффективной донастройки."
                },
                "en": {
                    "title": "X-Cross: Efficient Cross-Domain Recommendations with Minimal Data",
                    "desc": "The paper introduces 'X-Cross', a new model designed for cross-domain sequential recommendations that can quickly adapt to new product categories without extensive retraining. It utilizes multiple domain-specific language models, each fine-tuned with low-rank adapters (LoRA), to enhance the recommendation process. By refining the representations of these models layer by layer, X-Cross effectively integrates knowledge from different domains while maintaining their unique characteristics. The model shows strong performance on Amazon datasets, requiring significantly less fine-tuning data and parameters compared to traditional methods, making it efficient for data-limited scenarios."
                },
                "zh": {
                    "title": "X-Cross：高效的跨领域推荐解决方案",
                    "desc": "随着新产品的不断涌现，推荐系统需要快速适应新领域，而无需大量重新训练。本文提出了“X-Cross”模型，这是一种新颖的跨领域序列推荐模型，通过整合多个特定领域的语言模型来推荐新领域的产品。X-Cross通过逐层操作动态地优化每个源语言模型的表示，确保在跨领域适应时保留领域特有的细微差别。实验结果表明，X-Cross在跨领域任务中表现出色，且所需的微调数据量显著低于传统方法。"
                }
            }
        }
    ],
    "link_prev": "2025-05-02.html",
    "link_next": "2025-05-06.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "02.05",
        "en": "05/02",
        "zh": "5月2日"
    },
    "short_date_next": {
        "ru": "06.05",
        "en": "05/06",
        "zh": "5月6日"
    },
    "categories": {
        "#dataset": 4,
        "#data": 2,
        "#benchmark": 3,
        "#agents": 1,
        "#cv": 2,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 1,
        "#training": 3,
        "#robotics": 1,
        "#agi": 1,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 1,
        "#transfer_learning": 1,
        "#graphs": 2,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 4,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "图像修复是图像编辑与生成之间的重要研究领域。最新方法在注意力机制、轻量架构和上下文感知建模方面取得了显著进展，但在处理复杂结构和语义时仍面临挑战，导致伪影和不恰当的生成。为解决这一问题，我们设计了一种称为潜在类别指导的简单有效范式，并提出了一种基于扩散的模型，命名为PixelHacker。我们通过构建包含1400万张图像-掩码对的大型数据集，分别编码前景和背景表示，并在去噪过程中注入这些特征。实验表明，PixelHacker在多个数据集上表现优异，结构和语义一致性显著。项目页面：https://hustvl.github.io/PixelHacker。",
        "title": "PixelHacker: Image Inpainting with Structural and Semantic Consistency",
        "pinyin": "图像修复是图像编辑与生成之间的重要研究领域。最新方法在注意力机制、轻量架构和上下文感知建模方面取得了显著进展，但在处理复杂结构和语义时仍面临挑战，导致伪影和不恰当的生成。为解决这一问题，我们设计了一种称为潜在类别指导的简单有效范式，并提出了一种基于扩散的模型，命名为PixelHacker。我们通过构建包含1400万张图像-掩码对的大型数据集，分别编码前景和背景表示，并在去噪过程中注入这些特征。实验表明，PixelHacker在多个数据集上表现优异，结构和语义一致性显著。项目页面：https://hustvl.github.io/PixelHacker。\n\ntú xiàng xiū fù shì tú xiàng biān jí yǔ shēng chéng zhī jiān de zhòng yào yán jiū lǐng yù. zuì xīn fāng fǎ zài zhù yì lì jī zhì, qīng liàng jià gòu hé shàng xià tíng gǎn zhī jiàn móu mó fāng miàn zhuō dào le xiǎn zhù jìn zhǎn, dàn zài chǔ lǐ fú zà jiè gòu hé yǔ yì shí réng miàn duì zhàn, dǎo zhì wěi yǐng hé bù qià dāng de shēng chéng. wèi jiě jué zhè yī wèn tí, wǒ men shè jì le yī zhǒng chēng wéi qián zài lèi bié zhǐ dǎo de jiǎn dān yǒu xiào fàn shì, bìng tí chū le yī zhǒng jī yú kuò sàn de mó xíng, mìng míng wéi PixelHacker. wǒ men tōng guò gòu jiàn bāo hán 1400 wàn zhāng tú xiàng-mó zhào duì de dà xíng shù jù jī, fēn bié biān mǎ qián jǐng hé bèi jǐng biǎo shì, bìng zài qù zào guò chéng zhōng zhù yǐn zhè xiē tè zhèng. shí yàn biǎo míng, PixelHacker zài duō gè shù jù shàng biǎo xiàn yōu yán, jiè gòu hé yǔ yì yī zhì xíng xiǎn zhù. xiàng mù yè miàn: https://hustvl.github.io/PixelHacker.",
        "vocab": "[{'word': '图像修复', 'pinyin': 'tú xiàng xiū fù', 'trans': 'image inpainting'},\n{'word': '领域', 'pinyin': 'lǐng yù', 'trans': 'field'},\n{'word': '注意力机制', 'pinyin': 'zhù yì lì jī zhì', 'trans': 'attention mechanism'},\n{'word': '轻量架构', 'pinyin': 'qīng liàng jià gòu', 'trans': 'lightweight architecture'},\n{'word': '上下文感知', 'pinyin': 'shàng xià wén gǎn zhī', 'trans': 'context-aware'},\n{'word': '建模', 'pinyin': 'jiàn mó', 'trans': 'modeling'},\n{'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'},\n{'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'},\n{'word': '复杂结构', 'pinyin': 'fù zá jié gòu', 'trans': 'complex structures'},\n{'word': '语义', 'pinyin': 'yǔ yì', 'trans': 'semantics'},\n{'word': '挑战', 'pinyin': 'tiǎo zhàn', 'trans': 'challenge'},\n{'word': '伪影', 'pinyin': 'wěi yǐng', 'trans': 'artifacts'},\n{'word': '不恰当', 'pinyin': 'bù qià dàng', 'trans': 'inappropriate'},\n{'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generation'},\n{'word': '潜在类别', 'pinyin': 'qián zài lèi bié', 'trans': 'latent category'},\n{'word': '指导', 'pinyin': 'zhǐ dǎo', 'trans': 'guidance'},\n{'word': '范式', 'pinyin': 'fàn shì', 'trans': 'paradigm'},\n{'word': '简单有效', 'pinyin': 'jiǎn dān yǒu xiào', 'trans': 'simple and effective'},\n{'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'},\n{'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'},\n{'word': '命名', 'pinyin': 'mìng míng', 'trans': 'named'},\n{'word': '前景', 'pinyin': 'qián jǐng', 'trans': 'foreground'},\n{'word': '背景', 'pinyin': 'bèi jǐng', 'trans': 'background'},\n{'word': '表示', 'pinyin': 'biǎo shì', 'trans': 'representation'},\n{'word': '注入', 'pinyin': 'zhù rù', 'trans': 'inject'},\n{'word': '特征', 'pinyin': 'tè zhēng', 'trans': 'features'},\n{'word': '去噪', 'pinyin': 'qù zào', 'trans': 'denoising'},\n{'word': '过程', 'pinyin': 'guò chéng', 'trans': 'process'},\n{'word': '编码', 'pinyin': 'biān mǎ', 'trans': 'encode'},\n{'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'},\n{'word': '表现', 'pinyin': 'biǎo xiàn', 'trans': 'performance'},\n{'word': '优异', 'pinyin': 'yōu yì', 'trans': 'excellent'},\n{'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'},\n{'word': '项目', 'pinyin': 'xiàng mù', 'trans': 'project'},\n{'word': '页面', 'pinyin': 'yè miàn', 'trans': 'page'}]",
        "trans": "Image inpainting is an important research area in image editing and generation. Recent methods have made significant progress in attention mechanisms, lightweight architectures, and context-aware modeling, but they still face challenges in handling complex structures and semantics, leading to artifacts and inappropriate generation. To address this issue, we designed a simple and effective paradigm called latent category guidance and proposed a diffusion-based model named PixelHacker. We constructed a large dataset containing 14 million image-mask pairs, encoding foreground and background representations separately, and injected these features during the denoising process. Experiments demonstrated that PixelHacker performs excellently on multiple datasets, with significant structural and semantic consistency. Project page: https://hustvl.github.io/PixelHacker.",
        "update_ts": "2025-05-05 09:12"
    }
}