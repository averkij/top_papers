
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>YuLan-Mini: An Open Data-efficient Language Model</h1>
                <div><p class='zh-text'>1. 这篇文章介绍了一个名为YuLan-Mini的大型语言模型。</p>
<p class='zh-text'>2. 该模型有2.42B参数，性能卓越。</p>
<p class='zh-text'>3. 研究团队通过三种技术贡献提高了训练效率：数据管道、优化方法和退火方法。</p>
<p class='zh-text'>4. YuLan-Mini在1.08T tokens上训练，性能与需要更多数据的行业领先模型相当。</p>
<p class='zh-text'>5. 项目细节可以在GitHub上找到。</p></div>
                <div class="pinyin">
                    <p>1. 这篇文章介绍了一个名为YuLan-Mini的大型语言模型。
Zhè piān wénzhāng jièshào le yīgè míngwèi YuLan-Mini de dàxíng yǔyán móxíng</p>
<p>2. 

该模型有2</p>
<p>3. 42B参数，性能卓越。
Gǎi móxíng yǒu 2</p>
<p>4. 42B cānshù, xìngnéng zhuóyuè</p>
<p>5. 

研究团队通过三种技术贡献提高了训练效率：数据管道、优化方法和退火方法。
Yánjiū tuánduì tōngguò sān zhǒng jìshù gòngxiàn tígāo le xùnliàn xiàolǜ: shùjù guǎndào, yōuhuà fāngfǎ hé tuìhuǒ fāngfǎ</p>
<p>6. 

YuLan-Mini在1</p>
<p>7. 08T tokens上训练，性能与需要更多数据的行业领先模型相当。
YuLan-Mini zài 1</p>
<p>8. 08T tokens shàng xùnliàn, xìngnéng yǔ xūyào gèng duō shùjù de hángyè lǐngxiān móxíng xiāngdāng</p>
<p>9. 

项目细节可以在GitHub上找到。
Xiàngmù xìjié kěyǐ zài GitHub shàng zhǎo dào</p>
                </div>
                <div><p>1. This article introduces a large language model named YuLan-Mini.</p>
<p>2.  The model has 2.</p>
<p>3. 42B parameters and delivers outstanding performance.</p>
<p>4.  The research team enhanced training efficiency through three technical contributions: data pipelines, optimization methods, and annealing techniques.</p>
<p>5.  YuLan-Mini was trained on 1.</p>
<p>6. 08T tokens and performs comparably to industry-leading models that require more data.</p>
<p>7.  Project details can be found on GitHub.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">语言模型</td>
                            <td>yǔyán móxíng</td>
                            <td>language model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">参数</td>
                            <td>cānshù</td>
                            <td>parameters</td>
                        </tr>
            
                        <tr>
                            <td class="zh">性能</td>
                            <td>xìngnéng</td>
                            <td>performance</td>
                        </tr>
            
                        <tr>
                            <td class="zh">卓越</td>
                            <td>zhuóyuè</td>
                            <td>outstanding</td>
                        </tr>
            
                        <tr>
                            <td class="zh">研究团队</td>
                            <td>yánjiū tuánduì</td>
                            <td>research team</td>
                        </tr>
            
                        <tr>
                            <td class="zh">技术贡献</td>
                            <td>jìshù gòngxiàn</td>
                            <td>technical contributions</td>
                        </tr>
            
                        <tr>
                            <td class="zh">提高</td>
                            <td>tígāo</td>
                            <td>improve</td>
                        </tr>
            
                        <tr>
                            <td class="zh">效率</td>
                            <td>xiàolǜ</td>
                            <td>efficiency</td>
                        </tr>
            
                        <tr>
                            <td class="zh">数据管道</td>
                            <td>shùjù guǎndào</td>
                            <td>data pipeline</td>
                        </tr>
            
                        <tr>
                            <td class="zh">优化方法</td>
                            <td>yōuhuà fāngfǎ</td>
                            <td>optimization methods</td>
                        </tr>
            
                        <tr>
                            <td class="zh">退火方法</td>
                            <td>tuìhuǒ fāngfǎ</td>
                            <td>annealing methods</td>
                        </tr>
            
                        <tr>
                            <td class="zh">tokens</td>
                            <td>tokens</td>
                            <td>tokens</td>
                        </tr>
            
                        <tr>
                            <td class="zh">行业领先</td>
                            <td>hángyè lǐngxiān</td>
                            <td>industry-leading</td>
                        </tr>
            
                        <tr>
                            <td class="zh">项目细节</td>
                            <td>xiàngmù xìjié</td>
                            <td>project details</td>
                        </tr>
            
                        <tr>
                            <td class="zh">GitHub</td>
                            <td>GitHub</td>
                            <td>GitHub</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        