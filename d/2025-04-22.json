{
    "date": {
        "ru": "22 апреля",
        "en": "April 22",
        "zh": "4月22日"
    },
    "time_utc": "2025-04-22 02:23",
    "weekday": 1,
    "issue_id": 3357,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2504.14603",
            "title": "UFO2: The Desktop AgentOS",
            "url": "https://huggingface.co/papers/2504.14603",
            "abstract": "Recent Computer-Using Agents (CUAs), powered by multimodal large language models (LLMs), offer a promising direction for automating complex desktop workflows through natural language. However, most existing CUAs remain conceptual prototypes, hindered by shallow OS integration, fragile screenshot-based interaction, and disruptive execution.   We present UFO2, a multiagent AgentOS for Windows desktops that elevates CUAs into practical, system-level automation. UFO2 features a centralized HostAgent for task decomposition and coordination, alongside a collection of application-specialized AppAgent equipped with native APIs, domain-specific knowledge, and a unified GUI--API action layer. This architecture enables robust task execution while preserving modularity and extensibility. A hybrid control detection pipeline fuses Windows UI Automation (UIA) with vision-based parsing to support diverse interface styles. Runtime efficiency is further enhanced through speculative multi-action planning, reducing per-step LLM overhead. Finally, a Picture-in-Picture (PiP) interface enables automation within an isolated virtual desktop, allowing agents and users to operate concurrently without interference.   We evaluate UFO2 across over 20 real-world Windows applications, demonstrating substantial improvements in robustness and execution accuracy over prior CUAs. Our results show that deep OS integration unlocks a scalable path toward reliable, user-aligned desktop automation.",
            "score": 3,
            "issue_id": 3357,
            "pub_date": "2025-04-20",
            "pub_date_card": {
                "ru": "20 апреля",
                "en": "April 20",
                "zh": "4月20日"
            },
            "hash": "81eea84c9d10e4d0",
            "authors": [
                "Chaoyun Zhang",
                "He Huang",
                "Chiming Ni",
                "Jian Mu",
                "Si Qin",
                "Shilin He",
                "Lu Wang",
                "Fangkai Yang",
                "Pu Zhao",
                "Chao Du",
                "Liqun Li",
                "Yu Kang",
                "Zhao Jiang",
                "Suzhen Zheng",
                "Rujia Wang",
                "Jiaxu Qian",
                "Minghua Ma",
                "Jian-Guang Lou",
                "Qingwei Lin",
                "Saravan Rajmohan",
                "Dongmei Zhang"
            ],
            "affiliations": [
                "Microsoft",
                "Nanjing University",
                "Peking University",
                "ZJU-UIUC Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.14603.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#architecture",
                    "#multimodal"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "UFO2: Надежная автоматизация Windows с помощью мультиагентной системы и глубокой интеграции с ОС",
                    "desc": "UFO2 - это многоагентная система для автоматизации рабочего стола Windows, использующая мультимодальные большие языковые модели. Она включает централизованный HostAgent для декомпозиции задач и набор специализированных AppAgent с нативными API и предметными знаниями. UFO2 использует гибридный подход для обнаружения элементов управления, сочетая Windows UI Automation и компьютерное зрение. Система демонстрирует значительное улучшение надежности и точности выполнения задач по сравнению с предыдущими решениями."
                },
                "en": {
                    "title": "UFO2: Elevating Desktop Automation with Intelligent Agents",
                    "desc": "The paper introduces UFO2, a multiagent system designed to enhance the functionality of Computer-Using Agents (CUAs) on Windows desktops. It addresses limitations of existing CUAs by integrating a centralized HostAgent for better task management and specialized AppAgents that utilize native APIs for improved interaction. The system employs a hybrid control detection pipeline that combines UI Automation with vision-based techniques, allowing it to handle various interface styles effectively. Evaluation results indicate that UFO2 significantly improves the robustness and accuracy of desktop automation tasks compared to previous models, showcasing the benefits of deep OS integration."
                },
                "zh": {
                    "title": "UFO2：提升桌面自动化的智能代理系统",
                    "desc": "本文介绍了一种名为UFO2的多代理AgentOS，旨在通过自然语言实现Windows桌面的复杂工作流程自动化。UFO2采用集中式的HostAgent进行任务分解和协调，并配备了应用专用的AppAgent，利用本地API和领域特定知识来增强系统集成。该架构支持强大的任务执行，同时保持模块化和可扩展性，结合了Windows UI自动化和视觉解析技术，以适应多样化的界面风格。通过在20多个真实Windows应用程序中的评估，UFO2在鲁棒性和执行准确性方面显著优于之前的CUA，展示了深度操作系统集成的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.15047",
            "title": "RainbowPlus: Enhancing Adversarial Prompt Generation via Evolutionary\n  Quality-Diversity Search",
            "url": "https://huggingface.co/papers/2504.15047",
            "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities but are susceptible to adversarial prompts that exploit vulnerabilities to produce unsafe or biased outputs. Existing red-teaming methods often face scalability challenges, resource-intensive requirements, or limited diversity in attack strategies. We propose RainbowPlus, a novel red-teaming framework rooted in evolutionary computation, enhancing adversarial prompt generation through an adaptive quality-diversity (QD) search that extends classical evolutionary algorithms like MAP-Elites with innovations tailored for language models. By employing a multi-element archive to store diverse high-quality prompts and a comprehensive fitness function to evaluate multiple prompts concurrently, RainbowPlus overcomes the constraints of single-prompt archives and pairwise comparisons in prior QD methods like Rainbow Teaming. Experiments comparing RainbowPlus to QD methods across six benchmark datasets and four open-source LLMs demonstrate superior attack success rate (ASR) and diversity (Diverse-Score approx 0.84), generating up to 100 times more unique prompts (e.g., 10,418 vs. 100 for Ministral-8B-Instruct-2410). Against nine state-of-the-art methods on the HarmBench dataset with twelve LLMs (ten open-source, two closed-source), RainbowPlus achieves an average ASR of 81.1%, surpassing AutoDAN-Turbo by 3.9%, and is 9 times faster (1.45 vs. 13.50 hours). Our open-source implementation fosters further advancements in LLM safety, offering a scalable tool for vulnerability assessment. Code and resources are publicly available at https://github.com/knoveleng/rainbowplus, supporting reproducibility and future research in LLM red-teaming.",
            "score": 1,
            "issue_id": 3357,
            "pub_date": "2025-04-21",
            "pub_date_card": {
                "ru": "21 апреля",
                "en": "April 21",
                "zh": "4月21日"
            },
            "hash": "834479c504a9e5f7",
            "authors": [
                "Quy-Anh Dang",
                "Chris Ngo",
                "Truong-Son Hy"
            ],
            "affiliations": [
                "Knovel Engineering Lab, Singapore",
                "University of Alabama at Birmingham, United States",
                "VNU University of Science, Vietnam"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.15047.jpg",
            "data": {
                "categories": [
                    "#security",
                    "#benchmark",
                    "#data",
                    "#open_source",
                    "#dataset"
                ],
                "emoji": "🌈",
                "ru": {
                    "title": "RainbowPlus: Эволюционный подход к повышению безопасности языковых моделей",
                    "desc": "Статья представляет RainbowPlus - новый фреймворк для тестирования безопасности крупных языковых моделей (LLM), основанный на эволюционных вычислениях. RainbowPlus использует адаптивный поиск качества-разнообразия для генерации разнообразных высококачественных провокационных запросов, преодолевая ограничения существующих методов. Эксперименты показывают, что RainbowPlus превосходит современные методы по успешности атак и разнообразию генерируемых запросов на различных наборах данных и моделях. Фреймворк предоставляет масштабируемый инструмент для оценки уязвимостей LLM, способствуя повышению их безопасности."
                },
                "en": {
                    "title": "RainbowPlus: Evolving Safer Language Models with Diverse Adversarial Prompts",
                    "desc": "This paper introduces RainbowPlus, a new framework for testing the safety of Large Language Models (LLMs) against adversarial prompts. It uses evolutionary computation techniques to generate diverse and high-quality prompts that can exploit vulnerabilities in LLMs. By employing a multi-element archive and a comprehensive fitness function, RainbowPlus significantly improves the efficiency and effectiveness of prompt generation compared to previous methods. Experiments show that it achieves a higher attack success rate and generates many more unique prompts, making it a valuable tool for enhancing LLM safety."
                },
                "zh": {
                    "title": "RainbowPlus：提升大型语言模型安全性的创新红队框架",
                    "desc": "大型语言模型（LLMs）具有出色的能力，但容易受到对抗性提示的影响，这些提示利用了模型的脆弱性，导致不安全或有偏见的输出。现有的红队方法常常面临可扩展性挑战、资源密集型要求或攻击策略的多样性有限。我们提出了RainbowPlus，这是一种基于进化计算的新型红队框架，通过自适应质量多样性（QD）搜索增强对抗性提示生成，扩展了经典的进化算法。实验结果表明，RainbowPlus在攻击成功率和多样性方面优于现有方法，生成的独特提示数量显著增加，展示了其在大型语言模型安全性评估中的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.14396",
            "title": "SphereDiff: Tuning-free Omnidirectional Panoramic Image and Video\n  Generation via Spherical Latent Representation",
            "url": "https://huggingface.co/papers/2504.14396",
            "abstract": "The increasing demand for AR/VR applications has highlighted the need for high-quality 360-degree panoramic content. However, generating high-quality 360-degree panoramic images and videos remains a challenging task due to the severe distortions introduced by equirectangular projection (ERP). Existing approaches either fine-tune pretrained diffusion models on limited ERP datasets or attempt tuning-free methods that still rely on ERP latent representations, leading to discontinuities near the poles. In this paper, we introduce SphereDiff, a novel approach for seamless 360-degree panoramic image and video generation using state-of-the-art diffusion models without additional tuning. We define a spherical latent representation that ensures uniform distribution across all perspectives, mitigating the distortions inherent in ERP. We extend MultiDiffusion to spherical latent space and propose a spherical latent sampling method to enable direct use of pretrained diffusion models. Moreover, we introduce distortion-aware weighted averaging to further improve the generation quality in the projection process. Our method outperforms existing approaches in generating 360-degree panoramic content while maintaining high fidelity, making it a robust solution for immersive AR/VR applications. The code is available here. https://github.com/pmh9960/SphereDiff",
            "score": 1,
            "issue_id": 3357,
            "pub_date": "2025-04-19",
            "pub_date_card": {
                "ru": "19 апреля",
                "en": "April 19",
                "zh": "4月19日"
            },
            "hash": "9688d3d72143f02c",
            "authors": [
                "Minho Park",
                "Taewoong Kang",
                "Jooyeol Yun",
                "Sungwon Hwang",
                "Jaegul Choo"
            ],
            "affiliations": [
                "Korea Advanced Institute of Science and Technology (KAIST)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.14396.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#diffusion",
                    "#multimodal",
                    "#open_source",
                    "#video"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "SphereDiff: Бесшовная генерация панорам 360° с помощью диффузионных моделей",
                    "desc": "SphereDiff - это новый подход к созданию панорамных изображений и видео с обзором 360 градусов, используя современные диффузионные модели без дополнительной настройки. Метод определяет сферическое латентное представление, которое обеспечивает равномерное распределение по всем ракурсам, уменьшая искажения, присущие эквидистантной проекции. SphereDiff расширяет MultiDiffusion на сферическое латентное пространство и предлагает метод сферической латентной выборки для прямого использования предобученных диффузионных моделей. Кроме того, авторы вводят взвешенное усреднение с учетом искажений для дальнейшего улучшения качества генерации в процессе проекции."
                },
                "en": {
                    "title": "SphereDiff: Seamless 360-Degree Content Generation for AR/VR",
                    "desc": "This paper presents SphereDiff, a new method for generating high-quality 360-degree panoramic images and videos using diffusion models. It addresses the challenges of distortions caused by equirectangular projection (ERP) by introducing a spherical latent representation that provides a uniform perspective distribution. SphereDiff enhances the existing MultiDiffusion framework by allowing direct use of pretrained models without the need for additional tuning. The method also incorporates distortion-aware weighted averaging to improve the quality of the generated content, outperforming previous techniques in fidelity and robustness for AR/VR applications."
                },
                "zh": {
                    "title": "SphereDiff：无缝生成360度全景内容的创新方法",
                    "desc": "随着增强现实和虚拟现实应用的需求增加，高质量的360度全景内容变得尤为重要。然而，由于等距矩形投影（ERP）引入的严重失真，生成高质量的360度全景图像和视频仍然是一个挑战。本文提出了一种名为SphereDiff的新方法，利用最先进的扩散模型实现无缝的360度全景图像和视频生成，且无需额外调优。我们定义了一种球形潜在表示，确保各个视角的均匀分布，从而减轻ERP固有的失真，显著提高生成质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13941",
            "title": "NEMOTRON-CROSSTHINK: Scaling Self-Learning beyond Math Reasoning",
            "url": "https://huggingface.co/papers/2504.13941",
            "abstract": "Large Language Models (LLMs) have shown strong reasoning capabilities, particularly when enhanced through Reinforcement Learning (RL). While prior work has successfully applied RL to mathematical reasoning -- where rules and correctness are well-defined -- generalizing these methods to broader reasoning domains remains challenging due to limited data, the lack of verifiable reward structures, and diverse task requirements. In this work, we propose NEMOTRON-CROSSTHINK, a framework that systematically incorporates multi-domain corpora, including both synthetic and real-world question-answer pairs, into RL training to improve generalization across diverse reasoning tasks. NEMOTRON-CROSSTHINK addresses key challenges by (1) incorporating data from varied sources spanning STEM, humanities, social sciences, etc.; (2) applying structured templates (e.g., multiple-choice and open-ended) to control answer-space complexity; (3) filtering for verifiable answers; and (4) optimizing data blending strategies that utilizes data from multiple sources effectively. Our approach enables scalable and verifiable reward modeling beyond mathematics and demonstrates improved accuracies on both math (MATH-500: +30.1%, AMC23:+27.5%) and non-math reasoning benchmarks (MMLU-PRO: +12.8%, GPQA-DIAMOND: +11.3%, AGIEVAL: +15.1%, SUPERGPQA: +3.8%). Moreover, NEMOTRON-CROSSTHINK exhibits significantly improved response efficiency -- using 28% fewer tokens for correct answers -- highlighting more focused and effective reasoning. Through NEMOTRON-CROSSTHINK, we demonstrate that integrating multi-domain, multi-format data in RL leads to more accurate, efficient, and generalizable LLMs.",
            "score": 1,
            "issue_id": 3357,
            "pub_date": "2025-04-15",
            "pub_date_card": {
                "ru": "15 апреля",
                "en": "April 15",
                "zh": "4月15日"
            },
            "hash": "df91b810ea243fdc",
            "authors": [
                "Syeda Nahida Akter",
                "Shrimai Prabhumoye",
                "Matvei Novikov",
                "Seungju Han",
                "Ying Lin",
                "Evelina Bakhturi",
                "Eric Nyberg",
                "Yejin Choi",
                "Mostofa Patwary",
                "Mohammad Shoeybi",
                "Bryan Catanzaro"
            ],
            "affiliations": [
                "Boston University",
                "Carnegie Mellon University",
                "NVIDIA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13941.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#reasoning",
                    "#data",
                    "#rl",
                    "#transfer_learning",
                    "#math"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Многодоменное обучение с подкреплением для улучшения рассуждений ИИ",
                    "desc": "Статья представляет NEMOTRON-CROSSTHINK - фреймворк для улучшения способностей крупных языковых моделей к рассуждению с помощью обучения с подкреплением. Авторы используют разнообразные наборы данных из различных областей знаний и применяют структурированные шаблоны для контроля сложности пространства ответов. Подход демонстрирует улучшение точности как на математических, так и на нематематических тестах рассуждений. NEMOTRON-CROSSTHINK также показывает повышенную эффективность ответов, используя меньше токенов для правильных ответов."
                },
                "en": {
                    "title": "Enhancing LLM Reasoning with Multi-Domain Reinforcement Learning",
                    "desc": "This paper introduces NEMOTRON-CROSSTHINK, a new framework that enhances the reasoning abilities of Large Language Models (LLMs) using Reinforcement Learning (RL). It tackles the challenge of generalizing RL methods across various reasoning tasks by incorporating diverse datasets from multiple domains, including STEM and humanities. The framework employs structured templates to manage answer complexity and ensures the use of verifiable answers, leading to improved reward modeling. As a result, NEMOTRON-CROSSTHINK achieves significant accuracy gains on both mathematical and non-mathematical reasoning tasks while also improving response efficiency by reducing token usage."
                },
                "zh": {
                    "title": "多领域数据助力推理能力提升",
                    "desc": "大型语言模型（LLMs）在推理能力方面表现出色，特别是通过强化学习（RL）进行增强。以往的研究成功地将RL应用于数学推理，但将这些方法推广到更广泛的推理领域仍然面临挑战。本文提出了NEMOTRON-CROSSTHINK框架，系统地将多领域语料库纳入RL训练，以提高在不同推理任务中的泛化能力。该方法通过多样化数据源、结构化模板、可验证答案过滤和优化数据混合策略，显著提升了模型在数学和非数学推理基准上的准确性和响应效率。"
                }
            }
        }
    ],
    "link_prev": "2025-04-21.html",
    "link_next": "2025-04-23.html",
    "link_month": "2025-04.html",
    "short_date_prev": {
        "ru": "21.04",
        "en": "04/21",
        "zh": "4月21日"
    },
    "short_date_next": {
        "ru": "23.04",
        "en": "04/23",
        "zh": "4月23日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 2,
        "#benchmark": 2,
        "#agents": 1,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了构建有效指令调整数据集的关键因素：数据质量和多样性。随着开源数据集的增加，自动选择高质量且多样的子集变得重要。现有方法主要关注实例质量，使用启发式规则维持多样性，但 often 效果不佳。作者提出了一种新方法，通过构建标签图来模拟语义空间，并基于图中的信息分布量化多样性。实验显示，这种方法在多个数据集和基础模型上都优于现有方法。",
        "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing\n  Information Gain in Semantic Space",
        "pinyin": "这篇文章讨论了构建有效指令调整数据集的关键因素：数据质量和多样性。\nzhè piān wén zhāng tǎo lùn le gòu jiàn yǒu xiào zhǐ lìng tiáo zhěng shù jù de guǎn jiàn yīn sù: shù jù zhì liàng hé duō yàng xìng.\n\n随着开源数据集的增加，自动选择高质量且多样的子集变得重要。\nsuí zhe kāi yuán shù jù jí de zēng jiā, zì dòng xuǎn zé gāo zhì liàng qiě duō yàng de zǐ jí biàn de zhòng yào.\n\n现有方法主要关注实例质量，使用启发式规则维持多样性，但 often 效果不佳。\nxiàn yǒu fāng fǎ zhǔ yào guān zhù shí lì zhì liàng, shǐ yòng qǐ fā shì guī zé wéi chí duō yàng xìng, dàn often xiào guǒ bù jiā.\n\n作者提出了一种新方法，通过构建标签图来模拟语义空间，并基于图中的信息分布量化多样性。\nzuò zhě tí chū le yī zhǒng xīn fāng fǎ, tōng guò gòu jiàn biāo qiān tú lái mó nǐ yǔ yì kōng jiān, bìng jī yú tú zhōng de xìn xī fēn bù liàng huà duō yàng xìng.\n\n实验显示，这种方法在多个数据集和基础模型上都优于现有方法。\nshí yàn xiǎn shì, zhè zhǒng fāng fǎ zài duō gè shù jù jí hé jī chǔ mó xíng shàng dōu yōu yú xiàn yǒu fāng fǎ.",
        "vocab": "[\n    {\"word\": \"构建\", \"pinyin\": \"gòujiàn\", \"trans\": \"construct\"},\n    {\"word\": \"有效\", \"pinyin\": \"yǒuxiào\", \"trans\": \"effective\"},\n    {\"word\": \"指令\", \"pinyin\": \"zhǐlìng\", \"trans\": \"instruction\"},\n    {\"word\": \"调整\", \"pinyin\": \"tiáozhěng\", \"trans\": \"adjust\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shùjùjí\", \"trans\": \"dataset\"},\n    {\"word\": \"关键因素\", \"pinyin\": \"guǎnjiàn yīnsù\", \"trans\": \"key factors\"},\n    {\"word\": \"质量\", \"pinyin\": \"zhìliàng\", \"trans\": \"quality\"},\n    {\"word\": \"多样性\", \"pinyin\": \"duōyàngxìng\", \"trans\": \"diversity\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāiyuán\", \"trans\": \"open-source\"},\n    {\"word\": \"自动\", \"pinyin\": \"zìdòng\", \"trans\": \"automatic\"},\n    {\"word\": \"选择\", \"pinyin\": \"xuǎnzé\", \"trans\": \"select\"},\n    {\"word\": \"子集\", \"pinyin\": \"zǐjí\", \"trans\": \"subset\"},\n    {\"word\": \"变得\", \"pinyin\": \"biàndé\", \"trans\": \"become\"},\n    {\"word\": \"重要\", \"pinyin\": \"zhòngyào\", \"trans\": \"important\"},\n    {\"word\": \"现有\", \"pinyin\": \"xiànyǒu\", \"trans\": \"existing\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāngfǎ\", \"trans\": \"method\"},\n    {\"word\": \"主要\", \"pinyin\": \"zhǔyào\", \"trans\": \"main\"},\n    {\"word\": \"关注\", \"pinyin\": \"guānzhù\", \"trans\": \"focus on\"},\n    {\"word\": \"实例\", \"pinyin\": \"shílì\", \"trans\": \"instance\"},\n    {\"word\": \"启发式\", \"pinyin\": \"qǐfāshì\", \"trans\": \"heuristic\"},\n    {\"word\": \"规则\", \"pinyin\": \"guīzé\", \"trans\": \"rule\"},\n    {\"word\": \"维持\", \"pinyin\": \"wéichí\", \"trans\": \"maintain\"},\n    {\"word\": \"效果\", \"pinyin\": \"xiàoguǒ\", \"trans\": \"effect\"},\n    {\"word\": \"不佳\", \"pinyin\": \"bùjiā\", \"trans\": \"poor\"},\n    {\"word\": \"作者\", \"pinyin\": \"zuòzhě\", \"trans\": \"author\"},\n    {\"word\": \"提出\", \"pinyin\": \"tíchū\", \"trans\": \"propose\"},\n    {\"word\": \"新方法\", \"pinyin\": \"xīn fāngfǎ\", \"trans\": \"new method\"},\n    {\"word\": \"通过\", \"pinyin\": \"tōngguò\", \"trans\": \"through\"},\n    {\"word\": \"标签\", \"pinyin\": \"biāoqiān\", \"trans\": \"label\"},\n    {\"word\": \"图\", \"pinyin\": \"tú\", \"trans\": \"graph\"},\n    {\"word\": \"模拟\", \"pinyin\": \"mónǐ\", \"trans\": \"simulate\"},\n    {\"word\": \"语义\", \"pinyin\": \"yǔyì\", \"trans\": \"semantic\"},\n    {\"word\": \"空间\", \"pinyin\": \"kōngjiān\", \"trans\": \"space\"},\n    {\"word\": \"基于\", \"pinyin\": \"jīyú\", \"trans\": \"based on\"},\n    {\"word\": \"信息\", \"pinyin\": \"xìnxī\", \"trans\": \"information\"},\n    {\"word\": \"分布\", \"pinyin\": \"fēnbù\", \"trans\": \"distribution\"},\n    {\"word\": \"量化\", \"pinyin\": \"liànghuà\", \"trans\": \"quantify\"},\n    {\"word\": \"实验\", \"pinyin\": \"shíyàn\", \"trans\": \"experiment\"},\n    {\"word\": \"显示\", \"pinyin\": \"xiǎnshì\", \"trans\": \"show\"},\n    {\"word\": \"优于\", \"pinyin\": \"yōuyú\", \"trans\": \"superior to\"},\n    {\"word\": \"基础\", \"pinyin\": \"jīchǔ\", \"trans\": \"foundation\"},\n    {\"word\": \"模型\", \"pinyin\": \"móxíng\", \"trans\": \"model\"}\n]",
        "trans": "This article discusses the key factors in constructing an effective dataset for instruction tuning: data quality and diversity. As the number of open-source datasets increases, it becomes important to automatically select high-quality and diverse subsets. Existing methods primarily focus on instance quality, using heuristic rules to maintain diversity, but often with limited effectiveness. The authors propose a new method that constructs a label graph to simulate semantic space and quantifies diversity based on the distribution of information in the graph. Experiments show that this method outperforms existing methods across multiple datasets and base models.",
        "update_ts": "2025-04-21 09:12"
    }
}