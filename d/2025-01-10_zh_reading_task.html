
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>An Empirical Study of Autoregressive Pre-training from Videos</h1>
                <div><p class='zh-text'>1. 我们通过实验研究了从视频中进行自回归预训练的方法。</p>
<p class='zh-text'>2. 为了进行研究，我们构建了一系列自回归视频模型，称为Toto。</p>
<p class='zh-text'>3. 我们将视频视为视觉标记的序列，并训练变压器模型自回归地预测未来的标记。</p>
<p class='zh-text'>4. 我们的模型在包含超过1万亿视觉标记的多样化视频和图像数据集上进行了预训练。</p>
<p class='zh-text'>5. 我们探索了不同的架构、训练和推理设计选择。</p>
<p class='zh-text'>6. 我们在包括图像识别、视频分类、目标跟踪和机器人技术在内的多个下游任务上评估了学习到的视觉表示。</p>
<p class='zh-text'>7. 我们的结果表明，尽管存在最小的归纳偏差，自回归预训练在所有基准测试中都表现出竞争力。</p>
<p class='zh-text'>8. 最后，我们发现扩展我们的视频模型会产生类似于语言模型的扩展曲线，只是速率不同。</p>
<p class='zh-text'>9. 更多细节请访问 https://brjathu.github.io/toto/。</p></div>
                <div class="pinyin">
                    <p>1. Wǒmen tōngguò shíyàn yánjiūle cóng shìpín zhōng jìnxíng zìhuíguī yùxùnliàn de fāngfǎ</p>
<p>2.  Wèile jìnxíng yánjiū, wǒmen gòujiànle yī xìliè zìhuíguī shìpín móxíng, chēngwéi Toto</p>
<p>3.  Wǒmen jiāng shìpín shìwéi shìjué biāojì de xùliè, bìng xùnliàn biànshùqì móxíng zìhuíguī de yùcè wèilái de biāojì</p>
<p>4.  Wǒmen de móxíng zài bāohán chāoguò 1 wàn yì shìjué biāojì de duōyànghuà shìpín hé túxiàng shùjùjí shàng jìnxíngle yùxùnliàn</p>
<p>5.  Wǒmen tuànsuǒle bùtóng de jiàgòu, xùnliàn hé tuīlǐ shèjì xuǎnzé</p>
<p>6.  Wǒmen zài bāokuò túxiàng shíbié, shìpín fēnlèi, mùbiāo gēnzōng hé jīqìrén jìshù zài nèi de duōgè xiàyóu rènwù shàng pínggūle xuéxí dào de shìjué biǎoshì</p>
<p>7.  Wǒmen de jiéguǒ biǎomíng, jīnshǐ yǒu zuìshǎo de guīnà piānchá, zìhuíguī yùxùnliàn zài suǒyǒu jīzhǔn cèshì zhōng dōu biǎoxiàn chū jìngzhēnglì</p>
<p>8.  Zuìhòu, wǒmen fāxiàn kuòzhǎn wǒmen de shìpín móxíng huì chǎnshēng xiàng yǔyán móxíng de kuòzhǎn qǔxiàn, zhǐshì sùlǜ bùtóng</p>
<p>9.  Gèng duō xìjiè qǐng fǎngwèn https://brjathu</p>
<p>10. github</p>
<p>11. io/toto/。</p>
                </div>
                <div><p>1. We investigated methods for autoregressive pretraining from videos through experimental research.</p>
<p>2.  To conduct the study, we constructed a series of autoregressive video models called Toto.</p>
<p>3.  We treated videos as sequences of visual tokens and trained transformer models to autoregressively predict future tokens.</p>
<p>4.  Our models were pretrained on diverse video and image datasets containing over 1 trillion visual tokens.</p>
<p>5.  We explored various architectural, training, and inference design choices.</p>
<p>6.  We evaluated the learned visual representations on multiple downstream tasks, including image recognition, video classification, object tracking, and robotics.</p>
<p>7.  Our results indicate that, despite minimal inductive bias, autoregressive pretraining performs competitively on all benchmarks.</p>
<p>8.  Finally, we found that scaling our video models produces scaling curves similar to those of language models, albeit at different rates.</p>
<p>9.  For more details, please visit https://brjathu.</p>
<p>10. github.</p>
<p>11. io/toto/.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">自回归</td>
                            <td>zì huí guī</td>
                            <td>autoregressive</td>
                        </tr>
            
                        <tr>
                            <td class="zh">预训练</td>
                            <td>yù xùn liàn</td>
                            <td>pretraining</td>
                        </tr>
            
                        <tr>
                            <td class="zh">视觉</td>
                            <td>shì jué</td>
                            <td>visual</td>
                        </tr>
            
                        <tr>
                            <td class="zh">标记</td>
                            <td>biāo jì</td>
                            <td>token</td>
                        </tr>
            
                        <tr>
                            <td class="zh">变压器</td>
                            <td>biàn yā qì</td>
                            <td>transformer</td>
                        </tr>
            
                        <tr>
                            <td class="zh">多样化</td>
                            <td>duō yàng huà</td>
                            <td>diversified</td>
                        </tr>
            
                        <tr>
                            <td class="zh">数据集</td>
                            <td>shù jù jí</td>
                            <td>dataset</td>
                        </tr>
            
                        <tr>
                            <td class="zh">归纳</td>
                            <td>guī nà</td>
                            <td>inductive</td>
                        </tr>
            
                        <tr>
                            <td class="zh">偏差</td>
                            <td>piān chā</td>
                            <td>bias</td>
                        </tr>
            
                        <tr>
                            <td class="zh">基准</td>
                            <td>jī zhǔn</td>
                            <td>benchmark</td>
                        </tr>
            
                        <tr>
                            <td class="zh">竞争力</td>
                            <td>jìng zhēng lì</td>
                            <td>competitive</td>
                        </tr>
            
                        <tr>
                            <td class="zh">扩展</td>
                            <td>kuò zhǎn</td>
                            <td>scaling</td>
                        </tr>
            
                        <tr>
                            <td class="zh">曲线</td>
                            <td>qǔ xiàn</td>
                            <td>curve</td>
                        </tr>
            
                        <tr>
                            <td class="zh">速率</td>
                            <td>sù lǜ</td>
                            <td>rate</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        