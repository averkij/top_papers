{
    "date": {
        "ru": "4 сентября",
        "en": "September 4",
        "zh": "9月4日"
    },
    "time_utc": "2025-09-04 03:22",
    "weekday": 3,
    "issue_id": 5707,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.01106",
            "title": "Robix: A Unified Model for Robot Interaction, Reasoning and Planning",
            "url": "https://huggingface.co/papers/2509.01106",
            "abstract": "Robix, a unified vision-language model, integrates robot reasoning, task planning, and natural language interaction, demonstrating superior performance in interactive task execution through chain-of-thought reasoning and a three-stage training strategy.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Robix, a unified model that integrates robot reasoning, task planning, and natural language interaction within a single vision-language architecture. Acting as the high-level cognitive layer in a hierarchical robot system, Robix dynamically generates atomic commands for the low-level controller and verbal responses for human interaction, enabling robots to follow complex instructions, plan long-horizon tasks, and interact naturally with human within an end-to-end framework. Robix further introduces novel capabilities such as proactive dialogue, real-time interruption handling, and context-aware commonsense reasoning during task execution. At its core, Robix leverages chain-of-thought reasoning and adopts a three-stage training strategy: (1) continued pretraining to enhance foundational embodied reasoning abilities including 3D spatial understanding, visual grounding, and task-centric reasoning; (2) supervised finetuning to model human-robot interaction and task planning as a unified reasoning-action sequence; and (3) reinforcement learning to improve reasoning-action consistency and long-horizon task coherence. Extensive experiments demonstrate that Robix outperforms both open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in interactive task execution, demonstrating strong generalization across diverse instruction types (e.g., open-ended, multi-stage, constrained, invalid, and interrupted) and various user-involved tasks such as table bussing, grocery shopping, and dietary filtering.",
            "score": 19,
            "issue_id": 5707,
            "pub_date": "2025-09-01",
            "pub_date_card": {
                "ru": "1 сентября",
                "en": "September 1",
                "zh": "9月1日"
            },
            "hash": "d0766d32afe23fec",
            "authors": [
                "Huang Fang",
                "Mengxi Zhang",
                "Heng Dong",
                "Wei Li",
                "Zixuan Wang",
                "Qifeng Zhang",
                "Xueyun Tian",
                "Yucheng Hu",
                "Hang Li"
            ],
            "affiliations": [
                "bytedance.com"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.01106.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rl",
                    "#reasoning",
                    "#alignment",
                    "#robotics",
                    "#multimodal",
                    "#agents",
                    "#optimization"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Robix: Единый интеллект для роботов нового поколения",
                    "desc": "Robix - это унифицированная модель машинного обучения, объединяющая рассуждения робота, планирование задач и взаимодействие на естественном языке в единой архитектуре. Модель использует цепочку рассуждений и трехэтапную стратегию обучения, включающую дообучение, тонкую настройку и обучение с подкреплением. Robix демонстрирует превосходную производительность в выполнении интерактивных задач, превосходя как открытые, так и коммерческие базовые модели. Модель обладает новыми возможностями, такими как проактивный диалог, обработка прерываний в реальном времени и рассуждения на основе здравого смысла."
                },
                "en": {
                    "title": "Robix: Revolutionizing Robot Interaction and Task Execution",
                    "desc": "Robix is a unified vision-language model designed to enhance robot reasoning, task planning, and natural language interaction. It operates as a cognitive layer in robotic systems, generating commands and responses that allow robots to execute complex tasks and interact with humans effectively. The model employs chain-of-thought reasoning and a three-stage training strategy, which includes pretraining, supervised finetuning, and reinforcement learning to improve its performance. Experiments show that Robix significantly outperforms existing models in executing diverse interactive tasks, showcasing its ability to generalize across various instruction types."
                },
                "zh": {
                    "title": "Robix：智能机器人交互的新纪元",
                    "desc": "Robix是一种统一的视觉-语言模型，结合了机器人推理、任务规划和自然语言交互。它通过链式思维推理和三阶段训练策略，展示了在交互任务执行中的优越性能。Robix能够动态生成原子命令和人机交互的语言响应，使机器人能够执行复杂指令并进行自然互动。实验表明，Robix在多种指令类型和用户参与的任务中表现优于现有的开源和商业模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.00375",
            "title": "Open Data Synthesis For Deep Research",
            "url": "https://huggingface.co/papers/2509.00375",
            "abstract": "InfoSeek is a scalable framework for generating complex Deep Research tasks by synthesizing hierarchical constraint satisfaction problems, enabling models to outperform larger baselines on challenging benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) are increasingly expected to go beyond simple factual queries toward Deep Research-tasks that require decomposing questions into sub-problems, coordinating multi-step reasoning, and synthesizing evidence from diverse sources. We formalize Deep Research tasks with verifiable answers as Hierarchical Constraint Satisfaction Problems (HCSPs), which are fundamentally different from single-constraint, multi-hop, or flat CSP formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA) fail to capture this complexity, while recent synthetic datasets often introduce shortcut reasoning, knowledge leakage, or lack sufficient structural depth. To address this gap, we introduce InfoSeek, a scalable framework for synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to recursively build a Research Tree from large-scale webpages, blurring intermediate nodes into valid sub-problems, and converting these trees into natural language questions that require traversing the full hierarchy. It also enables rapid scaling, yielding over 50K training examples, a curated test set, and reasoning trajectories generated via reject sampling. Experiments show that models trained on InfoSeek consistently outperform strong baselines. On a challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash), while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro). By preserving meta-information such as intermediate steps and retrieval labels, InfoSeek further supports advanced optimization strategies, including compound reward design and trajectory-level exploration. We provide our codes and datasets in https://github.com/VectorSpaceLab/InfoSeek{this repository}.",
            "score": 4,
            "issue_id": 5707,
            "pub_date": "2025-08-30",
            "pub_date_card": {
                "ru": "30 августа",
                "en": "August 30",
                "zh": "8月30日"
            },
            "hash": "d7d79c964b418fac",
            "pdf_title_img": "assets/pdf/title_img/2509.00375.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#synthetic",
                    "#reasoning",
                    "#benchmark",
                    "#multimodal",
                    "#optimization"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "InfoSeek: Новый уровень глубокого исследования для языковых моделей",
                    "desc": "InfoSeek - это масштабируемая система для создания сложных задач глубокого исследования путем синтеза иерархических задач удовлетворения ограничений. Она использует двухагентную систему для рекурсивного построения дерева исследований из веб-страниц, преобразуя его в вопросы на естественном языке. Модели, обученные на InfoSeek, превосходят сильные базовые линии на сложных бенчмарках. InfoSeek позволяет быстро масштабировать генерацию данных и поддерживает продвинутые стратегии оптимизации."
                },
                "en": {
                    "title": "Unlocking Deep Research with Hierarchical Constraints",
                    "desc": "InfoSeek is a novel framework designed to tackle complex Deep Research tasks by structuring them as Hierarchical Constraint Satisfaction Problems (HCSPs). This approach allows models to break down intricate questions into manageable sub-problems, facilitating multi-step reasoning and evidence synthesis from various sources. Unlike traditional benchmarks, InfoSeek generates a large dataset of over 50,000 training examples that reflect the complexity of real-world queries without shortcut reasoning. Experiments demonstrate that models trained with InfoSeek significantly outperform larger models on challenging benchmarks, showcasing its effectiveness in enhancing the capabilities of large language models."
                },
                "zh": {
                    "title": "InfoSeek：深度研究任务的新框架",
                    "desc": "InfoSeek是一个可扩展的框架，用于生成复杂的深度研究任务，通过合成层次约束满足问题，使模型在具有挑战性的基准测试中超越更大的基线。该框架使用双代理系统，从大规模网页递归构建研究树，将中间节点模糊化为有效的子问题，并将这些树转换为需要遍历完整层次的自然语言问题。InfoSeek能够快速扩展，生成超过50,000个训练示例，并提供经过策划的测试集和通过拒绝采样生成的推理轨迹。实验表明，基于InfoSeek训练的模型在多个基准测试中表现优异，超越了许多大型模型和商业API。"
                }
            }
        }
    ],
    "link_prev": "2025-09-03.html",
    "link_next": "2025-09-05.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "03.09",
        "en": "09/03",
        "zh": "9月3日"
    },
    "short_date_next": {
        "ru": "05.09",
        "en": "09/05",
        "zh": "9月5日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 1,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}