
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 9 papers. February 14.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">14 февраля</span> | <span id="title-articles-count">9 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-02-13.html">⬅️ <span id="prev-date">13.02</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-02-17.html">➡️ <span id="next-date">17.02</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-02.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '14 февраля', 'en': 'February 14', 'zh': '2月14日'};
        let feedDateNext = {'ru': '17.02', 'en': '02/17', 'zh': '2月17日'};
        let feedDatePrev = {'ru': '13.02', 'en': '02/13', 'zh': '2月13日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2502.08910', 'title': 'InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU', 'url': 'https://huggingface.co/papers/2502.08910', 'abstract': 'In modern large language models (LLMs), handling very long context lengths presents significant challenges as it causes slower inference speeds and increased memory costs. Additionally, most existing pre-trained LLMs fail to generalize beyond their original training sequence lengths. To enable efficient and practical long-context utilization, we introduce InfiniteHiP, a novel, and practical LLM inference framework that accelerates processing by dynamically eliminating irrelevant context tokens through a modular hierarchical token pruning algorithm. Our method also allows generalization to longer sequences by selectively applying various RoPE adjustment methods according to the internal attention patterns within LLMs. Furthermore, we offload the key-value cache to host memory during inference, significantly reducing GPU memory pressure. As a result, InfiniteHiP enables the processing of up to 3 million tokens on a single L40s 48GB GPU -- 3x larger -- without any permanent loss of context information. Our framework achieves an 18.95x speedup in attention decoding for a 1 million token context without requiring additional training. We implement our method in the SGLang framework and demonstrate its effectiveness and practicality through extensive evaluations.', 'score': 26, 'issue_id': 2210, 'pub_date': '2025-02-13', 'pub_date_card': {'ru': '13 февраля', 'en': 'February 13', 'zh': '2月13日'}, 'hash': 'eed812d17aeec57e', 'authors': ['Heejun Lee', 'Geon Park', 'Jaduk Suh', 'Sung Ju Hwang'], 'affiliations': ['DeepAuto.ai, Seoul, Korea', 'Graduate School of AI, KAIST, Seoul, Korea'], 'pdf_title_img': 'assets/pdf/title_img/2502.08910.jpg', 'data': {'categories': ['#training', '#architecture', '#optimization', '#long_context', '#inference'], 'emoji': '🚀', 'ru': {'title': 'Преодоление барьера длинного контекста в LLM', 'desc': 'InfiniteHiP - это новая система для обработки больших языковых моделей (LLM) с длинным контекстом. Она ускоряет обработку, удаляя неважные токены контекста с помощью иерархического алгоритма. Система позволяет обобщать на более длинные последовательности, применяя методы настройки RoPE. InfiniteHiP достигает 18.95-кратного ускорения в декодировании внимания для контекста в 1 миллион токенов без дополнительного обучения.'}, 'en': {'title': 'InfiniteHiP: Unlocking Long Contexts in Language Models Efficiently', 'desc': "This paper presents InfiniteHiP, a new framework designed to improve the efficiency of large language models (LLMs) when processing very long contexts. It addresses the issues of slow inference speeds and high memory costs by using a hierarchical token pruning algorithm to remove irrelevant tokens dynamically. Additionally, InfiniteHiP enhances the model's ability to generalize to longer sequences by adjusting the relative positional encodings based on attention patterns. The framework allows for processing up to 3 million tokens on a single GPU while achieving significant speed improvements without the need for extra training."}, 'zh': {'title': 'InfiniteHiP：高效处理超长上下文的LLM框架', 'desc': '在现代大型语言模型（LLMs）中，处理非常长的上下文长度面临显著挑战，导致推理速度变慢和内存成本增加。现有的大多数预训练LLMs无法超出其原始训练序列长度进行泛化。为了解决这一问题，我们提出了InfiniteHiP，这是一种新颖且实用的LLM推理框架，通过模块化的分层令牌修剪算法动态消除无关的上下文令牌，从而加速处理。我们的框架能够在不需要额外训练的情况下，实现对长达300万令牌的处理，并在1百万令牌上下文中实现18.95倍的注意力解码加速。'}}}, {'id': 'https://huggingface.co/papers/2502.09604', 'title': 'SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models', 'url': 'https://huggingface.co/papers/2502.09604', 'abstract': 'We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks.', 'score': 14, 'issue_id': 2209, 'pub_date': '2025-02-13', 'pub_date_card': {'ru': '13 февраля', 'en': 'February 13', 'zh': '2月13日'}, 'hash': '7aa5ce3731848736', 'authors': ['Yung-Sung Chuang', 'Benjamin Cohen-Wang', 'Shannon Zejiang Shen', 'Zhaofeng Wu', 'Hu Xu', 'Xi Victoria Lin', 'James Glass', 'Shang-Wen Li', 'Wen-tau Yih'], 'affiliations': ['Massachusetts Institute of Technology', 'Meta FAIR'], 'pdf_title_img': 'assets/pdf/title_img/2502.09604.jpg', 'data': {'categories': ['#optimization', '#long_context', '#training', '#alignment', '#rlhf', '#benchmark'], 'emoji': '📚', 'ru': {'title': 'SelfCite: Самообучение ИИ искусству цитирования', 'desc': 'SelfCite - это новый подход к самообучению больших языковых моделей (LLM) для генерации качественных цитат на уровне предложений. Метод использует сигнал награды, предоставляемый самой моделью через абляцию контекста, что позволяет избежать дорогостоящей ручной разметки. SelfCite применяет стратегию выборки best-of-N во время вывода и оптимизацию предпочтений для точной настройки моделей. Эффективность подхода подтверждается увеличением F1-меры цитирования до 5.3 пунктов на бенчмарке LongBench-Cite.'}, 'en': {'title': 'Enhancing Citation Quality with SelfCite', 'desc': 'SelfCite is a self-supervised method designed to enhance the citation quality in responses generated by large language models (LLMs). It uses a unique reward signal derived from the LLM itself, which assesses the necessity of citations by analyzing the impact of removing or retaining cited text. This approach not only improves the citation generation process during inference but also allows for fine-tuning the models to produce better citations through preference optimization. The results show a significant increase in citation accuracy, as evidenced by a 5.3 point improvement in citation F1 scores on the LongBench-Cite benchmark.'}, 'zh': {'title': '自监督引用生成的创新方法', 'desc': 'SelfCite是一种新颖的自监督方法，旨在使大型语言模型（LLM）生成高质量、细粒度的句子级引用。该方法通过上下文消融提供的奖励信号，减少对昂贵和劳动密集型注释的依赖。具体来说，如果引用是必要的，移除被引用文本应防止相同的响应；如果足够，保留被引用文本应保持相同的响应。SelfCite在LongBench-Cite基准测试中显示出有效性，使引用的F1分数提高了5.3个百分点。'}}}, {'id': 'https://huggingface.co/papers/2502.08690', 'title': 'Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation', 'url': 'https://huggingface.co/papers/2502.08690', 'abstract': 'Large-scale text encoders in text-to-image (T2I) diffusion models have demonstrated exceptional performance in generating high-quality images from textual prompts. Unlike denoising modules that rely on multiple iterative steps, text encoders require only a single forward pass to produce text embeddings. However, despite their minimal contribution to total inference time and floating-point operations (FLOPs), text encoders demand significantly higher memory usage, up to eight times more than denoising modules. To address this inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet effective pruning strategy specifically designed for text encoders in T2I diffusion models. Skrr exploits the inherent redundancy in transformer blocks by selectively skipping or reusing certain layers in a manner tailored for T2I tasks, thereby reducing memory consumption without compromising performance. Extensive experiments demonstrate that Skrr maintains image quality comparable to the original model even under high sparsity levels, outperforming existing blockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory efficiency while preserving performance across multiple evaluation metrics, including the FID, CLIP, DreamSim, and GenEval scores.', 'score': 13, 'issue_id': 2210, 'pub_date': '2025-02-12', 'pub_date_card': {'ru': '12 февраля', 'en': 'February 12', 'zh': '2月12日'}, 'hash': 'c7734d31994dcb35', 'authors': ['Hoigi Seo', 'Wongi Jeong', 'Jae-sun Seo', 'Se Young Chun'], 'affiliations': ['Dept. of Electrical and Computer Engineering, Seoul National University, Republic of Korea', 'INMC & IPAI, Seoul National University, Republic of Korea', 'School of Electrical and Computer Engineering, Cornell Tech, USA'], 'pdf_title_img': 'assets/pdf/title_img/2502.08690.jpg', 'data': {'categories': ['#training', '#architecture', '#optimization', '#inference', '#diffusion'], 'emoji': '✂️', 'ru': {'title': 'Эффективное сжатие текстовых энкодеров для генерации изображений без потери качества', 'desc': 'Статья представляет новый метод оптимизации текстовых энкодеров в моделях диффузии текст-в-изображение (T2I). Авторы предлагают стратегию прунинга под названием Skip and Re-use layers (Skrr), которая позволяет значительно сократить потребление памяти без ущерба для качества генерируемых изображений. Метод Skrr избирательно пропускает или повторно использует определенные слои в трансформерных блоках, учитывая специфику задач T2I. Эксперименты показывают, что Skrr превосходит существующие методы поблочного прунинга и достигает наилучших показателей эффективности использования памяти при сохранении производительности по различным метрикам оценки.'}, 'en': {'title': 'Efficient Memory Use in Text-to-Image Models with Skrr', 'desc': 'This paper introduces a new method called Skip and Re-use layers (Skrr) to improve the efficiency of text encoders in text-to-image diffusion models. Text encoders are crucial for generating images from text but use a lot of memory compared to denoising modules. Skrr reduces memory usage by selectively skipping or reusing layers in the transformer architecture, which helps maintain performance while lowering resource demands. The results show that Skrr achieves high image quality and outperforms other pruning methods, making it a significant advancement in memory efficiency for T2I tasks.'}, 'zh': {'title': '提升文本编码器的内存效率', 'desc': '本文提出了一种名为Skip and Re-use layers（Skrr）的新策略，旨在提高文本到图像扩散模型中文本编码器的内存效率。尽管文本编码器在推理时间和浮点运算方面的贡献较小，但它们的内存需求却高达去噪模块的八倍。Skrr通过选择性跳过或重用某些变换器层，利用了变换器块中的冗余性，从而在不影响性能的情况下减少内存消耗。实验结果表明，Skrr在高稀疏度下仍能保持与原始模型相当的图像质量，并在多个评估指标上实现了最先进的内存效率。'}}}, {'id': 'https://huggingface.co/papers/2502.09560', 'title': 'EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents', 'url': 'https://huggingface.co/papers/2502.09560', 'abstract': 'Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning. Through extensive experiments, we evaluated 13 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code is available at https://embodiedbench.github.io.', 'score': 9, 'issue_id': 2211, 'pub_date': '2025-02-13', 'pub_date_card': {'ru': '13 февраля', 'en': 'February 13', 'zh': '2月13日'}, 'hash': '019b4d19788a85cc', 'authors': ['Rui Yang', 'Hanyang Chen', 'Junyu Zhang', 'Mark Zhao', 'Cheng Qian', 'Kangrui Wang', 'Qineng Wang', 'Teja Venkat Koripella', 'Marziyeh Movahedi', 'Manling Li', 'Heng Ji', 'Huan Zhang', 'Tong Zhang'], 'affiliations': ['Northwestern University', 'Toyota Technological Institute at Chicago', 'University of Illinois Urbana-Champaign', 'University of Toronto'], 'pdf_title_img': 'assets/pdf/title_img/2502.09560.jpg', 'data': {'categories': ['#multimodal', '#benchmark', '#open_source', '#games', '#reasoning', '#agents'], 'emoji': '🤖', 'ru': {'title': 'EmbodiedBench: новый стандарт оценки воплощенного ИИ', 'desc': 'В статье представлен EmbodiedBench - комплексный инструмент для оценки мультимодальных языковых моделей (MLLM) в задачах воплощенного искусственного интеллекта. Бенчмарк включает 1128 тестовых заданий в четырех средах, охватывающих как высокоуровневые семантические задачи, так и низкоуровневые действия. Эксперименты с 13 ведущими MLLM показали, что модели успешно справляются с высокоуровневыми задачами, но испытывают трудности с низкоуровневыми манипуляциями. EmbodiedBench предоставляет стандартизированную платформу для оценки и развития воплощенных агентов на основе MLLM.'}, 'en': {'title': 'Empowering Embodied Agents with Comprehensive Evaluation', 'desc': 'This paper discusses the development of EmbodiedBench, a benchmark for evaluating multi-modal large language models (MLLMs) in the context of embodied agents. It highlights the gap in existing evaluation frameworks for MLLM-based agents, which are crucial for performing real-world tasks. The benchmark includes a wide range of tasks that assess various capabilities such as commonsense reasoning and spatial awareness. The results indicate that while MLLMs perform well on high-level tasks, they face significant challenges with low-level manipulation tasks.'}, 'zh': {'title': '多模态大型语言模型助力具身智能体的评估与发展', 'desc': '本论文探讨了多模态大型语言模型（MLLMs）在创建具身智能体方面的应用，旨在解决现实世界任务。我们提出了EmbodiedBench，这是一个全面的基准测试框架，用于评估视觉驱动的具身智能体。EmbodiedBench包含1288个测试任务，涵盖高层语义任务和低层原子动作任务，并评估智能体的常识推理、复杂指令理解、空间意识、视觉感知和长期规划等能力。实验结果表明，尽管MLLMs在高层任务中表现优异，但在低层操作任务上仍然存在挑战，最好的模型GPT-4o的平均得分仅为28.9%。'}}}, {'id': 'https://huggingface.co/papers/2502.09056', 'title': 'An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging', 'url': 'https://huggingface.co/papers/2502.09056', 'abstract': 'This paper investigates data selection and model merging methodologies aimed at incorporating advanced reasoning capabilities such as those of DeepSeek R1 into language-specific large language models (LLMs), with a particular focus on the Thai LLM. Our goal is to enhance the reasoning capabilities of language-specific LLMs while maintaining their target language abilities. DeepSeek R1 excels in reasoning but primarily benefits high-resource languages such as English and Chinese. However, low-resource languages remain underserved due to the dominance of English-centric training data and model optimizations, which limit performance in these languages. This limitation results in unreliable code-switching and diminished effectiveness on tasks in low-resource languages. Meanwhile, local and regional LLM initiatives have attempted to bridge this gap by developing language-specific LLMs that focus on improving local linguistic fidelity. We demonstrate that, with only publicly available datasets and a computational budget of $120, it is possible to enhance the reasoning capabilities of language-specific LLMs to match the level of DeepSeek R1, without compromising their performance on target language tasks.', 'score': 4, 'issue_id': 2209, 'pub_date': '2025-02-13', 'pub_date_card': {'ru': '13 февраля', 'en': 'February 13', 'zh': '2月13日'}, 'hash': '36c3c29072ae279d', 'authors': ['Kunat Pipatanakul', 'Pittawat Taveekitworachai', 'Potsawee Manakul', 'Kasima Tharnpipitchai'], 'affiliations': ['SCB 10X R&D SCBX Group Bangkok, Thailand'], 'pdf_title_img': 'assets/pdf/title_img/2502.09056.jpg', 'data': {'categories': ['#data', '#dataset', '#low_resource', '#multilingual', '#training', '#reasoning'], 'emoji': '🧠', 'ru': {'title': 'Усиление логики локальных языковых моделей', 'desc': 'Данное исследование посвящено методам улучшения способностей к рассуждению у языково-специфичных больших языковых моделей (LLM), в частности для тайского языка. Авторы предлагают подходы к отбору данных и слиянию моделей, чтобы перенести продвинутые навыки рассуждения из модели DeepSeek R1 в локальные LLM. Цель состоит в том, чтобы усилить логические возможности языково-специфичных моделей, сохраняя при этом их способности в целевом языке. Исследователи показывают, что даже с ограниченным бюджетом и общедоступными данными можно значительно улучшить рассуждения локальных LLM до уровня DeepSeek R1.'}, 'en': {'title': 'Empowering Thai LLMs with Enhanced Reasoning Capabilities', 'desc': "This paper explores methods for selecting data and merging models to improve reasoning abilities in language-specific large language models (LLMs), particularly for the Thai language. The authors aim to enhance these models' reasoning skills while ensuring they remain effective in their target languages. They highlight the challenges faced by low-resource languages, which often lack the extensive training data available for high-resource languages like English. The study demonstrates that it is feasible to boost the reasoning capabilities of these LLMs using only publicly available datasets and a modest budget, achieving results comparable to advanced models like DeepSeek R1."}, 'zh': {'title': '提升低资源语言LLM的推理能力', 'desc': '本文研究了数据选择和模型合并的方法，旨在将先进的推理能力（如DeepSeek R1）融入特定语言的大型语言模型（LLMs），特别关注泰语LLM。我们的目标是增强特定语言LLMs的推理能力，同时保持其目标语言的能力。DeepSeek R1在推理方面表现出色，但主要受益于高资源语言，如英语和中文，而低资源语言则受到忽视。我们展示了仅使用公开数据集和120美元的计算预算，就可以提升特定语言LLMs的推理能力，使其达到DeepSeek R1的水平，而不影响其在目标语言任务上的表现。'}}}, {'id': 'https://huggingface.co/papers/2502.08946', 'title': "The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding", 'url': 'https://huggingface.co/papers/2502.08946', 'abstract': 'In a systematic way, we investigate a widely asked question: Do LLMs really understand what they say?, which relates to the more familiar term Stochastic Parrot. To this end, we propose a summative assessment over a carefully designed physical concept understanding task, PhysiCo. Our task alleviates the memorization issue via the usage of grid-format inputs that abstractly describe physical phenomena. The grids represents varying levels of understanding, from the core phenomenon, application examples to analogies to other abstract patterns in the grid world. A comprehensive study on our task demonstrates: (1) state-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag behind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs, as they fail on our grid task but can describe and recognize the same concepts well in natural language; (3) our task challenges the LLMs due to intrinsic difficulties rather than the unfamiliar grid format, as in-context learning and fine-tuning on same formatted data added little to their performance.', 'score': 3, 'issue_id': 2209, 'pub_date': '2025-02-13', 'pub_date_card': {'ru': '13 февраля', 'en': 'February 13', 'zh': '2月13日'}, 'hash': 'daecc7f38306f7b8', 'authors': ['Mo Yu', 'Lemao Liu', 'Junjie Wu', 'Tsz Ting Chung', 'Shunchi Zhang', 'Jiangnan Li', 'Dit-Yan Yeung', 'Jie Zhou'], 'affiliations': ['HKUST', 'JHU', 'WeChat AI, Tencent'], 'pdf_title_img': 'assets/pdf/title_img/2502.08946.jpg', 'data': {'categories': ['#hallucinations', '#dataset', '#training', '#reasoning', '#interpretability'], 'emoji': '🦜', 'ru': {'title': 'Языковые модели: понимание или имитация?', 'desc': "Исследователи изучают вопрос о действительном понимании языковыми моделями (LLM) того, что они говорят. Они разработали задачу PhysiCo для оценки понимания физических концепций, используя абстрактные сетки вместо естественного языка. Результаты показывают, что современные LLM, включая GPT-4 и Gemini 2.0, отстают от людей примерно на 40% в этой задаче. Исследование подтверждает феномен 'стохастического попугая', так как модели не справляются с сеточной задачей, но хорошо описывают те же концепции на естественном языке."}, 'en': {'title': 'Unveiling the Limits of LLM Understanding', 'desc': "This paper investigates whether large language models (LLMs) truly understand the content they generate, addressing the concept of the 'Stochastic Parrot'. The authors introduce a new assessment task called PhysiCo, which uses grid-format inputs to evaluate understanding of physical concepts. Their findings reveal that top-performing LLMs, like GPT-4o and Gemini 2.0, significantly underperform compared to humans, indicating a gap in comprehension. Additionally, the study shows that LLMs struggle with the task due to inherent challenges in understanding rather than just the format of the input data."}, 'zh': {'title': '探究大型语言模型的理解能力', 'desc': '本研究系统性地探讨了一个常见问题：大型语言模型（LLMs）是否真正理解它们所说的内容。我们提出了一种名为PhysiCo的评估任务，旨在通过网格格式的输入来减轻记忆问题，这些输入抽象地描述了物理现象。研究表明，当前最先进的LLMs在理解能力上落后于人类约40%，并且在网格任务中表现不佳，显示出随机鹦鹉现象的存在。我们的任务挑战了LLMs，主要是由于内在的困难，而非网格格式的不熟悉。'}}}, {'id': 'https://huggingface.co/papers/2502.06608', 'title': 'TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models', 'url': 'https://huggingface.co/papers/2502.06608', 'abstract': 'Recent advancements in diffusion techniques have propelled image and video generation to unprece- dented levels of quality, significantly accelerating the deployment and application of generative AI. However, 3D shape generation technology has so far lagged behind, constrained by limitations in 3D data scale, complexity of 3D data process- ing, and insufficient exploration of advanced tech- niques in the 3D domain. Current approaches to 3D shape generation face substantial challenges in terms of output quality, generalization capa- bility, and alignment with input conditions. We present TripoSG, a new streamlined shape diffu- sion paradigm capable of generating high-fidelity 3D meshes with precise correspondence to input images. Specifically, we propose: 1) A large-scale rectified flow transformer for 3D shape generation, achieving state-of-the-art fidelity through training on extensive, high-quality data. 2) A hybrid supervised training strategy combining SDF, normal, and eikonal losses for 3D VAE, achieving high- quality 3D reconstruction performance. 3) A data processing pipeline to generate 2 million high- quality 3D samples, highlighting the crucial rules for data quality and quantity in training 3D gen- erative models. Through comprehensive experi- ments, we have validated the effectiveness of each component in our new framework. The seamless integration of these parts has enabled TripoSG to achieve state-of-the-art performance in 3D shape generation. The resulting 3D shapes exhibit en- hanced detail due to high-resolution capabilities and demonstrate exceptional fidelity to input im- ages. Moreover, TripoSG demonstrates improved versatility in generating 3D models from diverse image styles and contents, showcasing strong gen- eralization capabilities. To foster progress and innovation in the field of 3D generation, we will make our model publicly available.', 'score': 2, 'issue_id': 2210, 'pub_date': '2025-02-10', 'pub_date_card': {'ru': '10 февраля', 'en': 'February 10', 'zh': '2月10日'}, 'hash': '0602cc4a46e4c69c', 'authors': ['Yangguang Li', 'Zi-Xin Zou', 'Zexiang Liu', 'Dehu Wang', 'Yuan Liang', 'Zhipeng Yu', 'Xingchao Liu', 'Yuan-Chen Guo', 'Ding Liang', 'Wanli Ouyang', 'Yan-Pei Cao'], 'affiliations': ['Shanghai AI Laboratory', 'The Chinese University of Hong Kong', 'The University of Texas at Austin', 'VAST'], 'pdf_title_img': 'assets/pdf/title_img/2502.06608.jpg', 'data': {'categories': ['#3d', '#open_source', '#training', '#dataset', '#diffusion'], 'emoji': '🧊', 'ru': {'title': 'TripoSG: Революция в генерации трехмерных форм', 'desc': 'TripoSG - это новая парадигма генерации трехмерных форм, способная создавать высококачественные 3D-модели с точным соответствием входным изображениям. Она использует масштабный трансформер с выпрямленным потоком для генерации 3D-форм, обученный на обширных высококачественных данных. TripoSG применяет гибридную стратегию обучения, сочетающую потери SDF, нормалей и эйконала для 3D VAE. Благодаря интеграции этих компонентов, TripoSG достигает передового уровня в генерации 3D-форм с улучшенной детализацией и верностью входным изображениям.'}, 'en': {'title': 'TripoSG: Revolutionizing 3D Shape Generation with Diffusion Techniques', 'desc': 'This paper introduces TripoSG, a new method for generating high-quality 3D shapes using diffusion techniques. It addresses the challenges of 3D shape generation by employing a large-scale rectified flow transformer and a hybrid supervised training strategy that enhances reconstruction performance. The model is trained on a vast dataset, producing 2 million high-quality 3D samples, which improves the fidelity and detail of the generated shapes. TripoSG not only achieves state-of-the-art results but also shows strong generalization across various input images, making it a significant advancement in 3D generative models.'}, 'zh': {'title': 'TripoSG：高保真3D形状生成的新范式', 'desc': '本论文介绍了一种新的3D形状生成方法TripoSG，旨在提高3D网格的生成质量。我们提出了一种大规模的流动变换器，能够在大量高质量数据上进行训练，从而实现高保真度的3D形状生成。此外，我们采用了一种混合监督训练策略，结合了SDF、法线和Eikonal损失，以提高3D重建性能。通过全面的实验验证，我们的框架在3D形状生成方面达到了最先进的性能，展现了对输入图像的高保真度和多样化的生成能力。'}}}, {'id': 'https://huggingface.co/papers/2502.09100', 'title': 'Logical Reasoning in Large Language Models: A Survey', 'url': 'https://huggingface.co/papers/2502.09100', 'abstract': 'With the emergence of advanced reasoning models like OpenAI o3 and DeepSeek-R1, large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, their ability to perform rigorous logical reasoning remains an open question. This survey synthesizes recent advancements in logical reasoning within LLMs, a critical area of AI research. It outlines the scope of logical reasoning in LLMs, its theoretical foundations, and the benchmarks used to evaluate reasoning proficiency. We analyze existing capabilities across different reasoning paradigms - deductive, inductive, abductive, and analogical - and assess strategies to enhance reasoning performance, including data-centric tuning, reinforcement learning, decoding strategies, and neuro-symbolic approaches. The review concludes with future directions, emphasizing the need for further exploration to strengthen logical reasoning in AI systems.', 'score': 2, 'issue_id': 2209, 'pub_date': '2025-02-13', 'pub_date_card': {'ru': '13 февраля', 'en': 'February 13', 'zh': '2月13日'}, 'hash': '72b32d40c559c7e4', 'authors': ['Hanmeng Liu', 'Zhizhang Fu', 'Mengru Ding', 'Ruoxi Ning', 'Chaoli Zhang', 'Xiaozhang Liu', 'Yue Zhang'], 'affiliations': ['Hainan University', 'Westlake University', 'Zhejiang Normal University'], 'pdf_title_img': 'assets/pdf/title_img/2502.09100.jpg', 'data': {'categories': ['#training', '#survey', '#reasoning', '#rl', '#benchmark'], 'emoji': '🧠', 'ru': {'title': 'Логическое мышление в больших языковых моделях: прогресс и перспективы', 'desc': 'Этот обзор посвящен последним достижениям в области логического рассуждения в больших языковых моделях (LLM). В нем рассматриваются теоретические основы и методы оценки способностей LLM к логическому мышлению. Авторы анализируют существующие возможности в различных парадигмах рассуждений, включая дедуктивное, индуктивное, абдуктивное и аналогическое. Также обсуждаются стратегии улучшения производительности рассуждений, такие как настройка данных, обучение с подкреплением и нейросимволические подходы.'}, 'en': {'title': 'Enhancing Logical Reasoning in Large Language Models', 'desc': 'This paper reviews the progress made in enhancing logical reasoning capabilities of large language models (LLMs) like OpenAI o3 and DeepSeek-R1. It discusses various reasoning paradigms such as deductive, inductive, abductive, and analogical reasoning, highlighting their theoretical foundations and evaluation benchmarks. The authors analyze strategies to improve reasoning performance, including data-centric tuning and neuro-symbolic approaches. The paper concludes by suggesting future research directions to further develop logical reasoning in AI systems.'}, 'zh': {'title': '提升AI系统逻辑推理能力的探索', 'desc': '随着OpenAI o3和DeepSeek-R1等先进推理模型的出现，大型语言模型（LLMs）展现了出色的推理能力。然而，它们在进行严格逻辑推理方面的能力仍然是一个未解之谜。本文综述了LLMs中逻辑推理的最新进展，探讨了逻辑推理的范围、理论基础以及评估推理能力的基准。我们分析了不同推理范式（如演绎、归纳、溯因和类比）的现有能力，并评估了增强推理性能的策略，包括数据中心调优、强化学习、解码策略和神经符号方法。'}}}, {'id': 'https://huggingface.co/papers/2502.08468', 'title': 'mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data', 'url': 'https://huggingface.co/papers/2502.08468', 'abstract': 'Multimodal embedding models have gained significant attention for their ability to map data from different modalities, such as text and images, into a unified representation space. However, the limited labeled multimodal data often hinders embedding performance. Recent approaches have leveraged data synthesis to address this problem, yet the quality of synthetic data remains a critical bottleneck. In this work, we identify three criteria for high-quality synthetic multimodal data. First, broad scope ensures that the generated data covers diverse tasks and modalities, making it applicable to various downstream scenarios. Second, robust cross-modal alignment makes different modalities semantically consistent. Third, high fidelity ensures that the synthetic data maintains realistic details to enhance its reliability. Guided by these principles, we synthesize datasets that: (1) cover a wide range of tasks, modality combinations, and languages, (2) are generated via a deep thinking process within a single pass of a multimodal large language model, and (3) incorporate real-world images with accurate and relevant texts, ensuring fidelity through self-evaluation and refinement. Leveraging these high-quality synthetic and labeled datasets, we train a multimodal multilingual E5 model mmE5. Extensive experiments demonstrate that mmE5 achieves state-of-the-art performance on the MMEB Benchmark and superior multilingual performance on the XTD benchmark. Our codes, datasets and models are released in https://github.com/haon-chen/mmE5.', 'score': 1, 'issue_id': 2211, 'pub_date': '2025-02-12', 'pub_date_card': {'ru': '12 февраля', 'en': 'February 12', 'zh': '2月12日'}, 'hash': 'ac7814f15d1e9616', 'authors': ['Haonan Chen', 'Liang Wang', 'Nan Yang', 'Yutao Zhu', 'Ziliang Zhao', 'Furu Wei', 'Zhicheng Dou'], 'affiliations': ['Gaoling School of Artificial Intelligence, Renmin University of China', 'Microsoft Corporation'], 'pdf_title_img': 'assets/pdf/title_img/2502.08468.jpg', 'data': {'categories': ['#multimodal', '#benchmark', '#open_source', '#synthetic', '#dataset', '#training', '#data', '#multilingual'], 'emoji': '🌐', 'ru': {'title': 'Синтетические данные открывают новые горизонты для мультимодальных эмбеддингов', 'desc': 'В статье представлена новая модель мультимодальных эмбеддингов mmE5, обученная на синтетических данных высокого качества. Авторы определили три критерия для создания таких данных: широкий охват задач и модальностей, надежное кросс-модальное выравнивание и высокая достоверность. Используя эти принципы, они синтезировали наборы данных с помощью мультимодальной большой языковой модели. Эксперименты показали, что mmE5 достигает передовых результатов на бенчмарках MMEB и XTD.'}, 'en': {'title': 'Enhancing Multimodal Learning with High-Quality Synthetic Data', 'desc': 'This paper discusses the development of multimodal embedding models that integrate different types of data, like text and images, into a single representation. It highlights the challenge of limited labeled multimodal data and proposes a solution through high-quality synthetic data generation. The authors establish three key criteria for effective synthetic data: broad scope, robust cross-modal alignment, and high fidelity. By adhering to these principles, they create a multimodal multilingual E5 model, mmE5, which demonstrates exceptional performance on various benchmarks.'}, 'zh': {'title': '高质量合成数据助力多模态模型', 'desc': '多模态嵌入模型能够将文本和图像等不同模态的数据映射到统一的表示空间，但有限的标注多模态数据常常影响嵌入性能。本文提出了高质量合成多模态数据的三个标准：广泛的范围、稳健的跨模态对齐和高保真度。通过这些标准，我们合成了覆盖多种任务和模态组合的数据集，并利用多模态大语言模型进行生成。最终，我们训练的多模态多语言E5模型mmE5在MMEB基准测试中表现出色，并在XTD基准测试中展现了卓越的多语言性能。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (1)', '#agents (1)', '#agi', '#alignment (1)', '#architecture (2)', '#audio', '#benchmark (4)', '#cv', '#data (2)', '#dataset (4)', '#diffusion (2)', '#ethics', '#games (1)', '#graphs', '#hallucinations (1)', '#healthcare', '#inference (2)', '#interpretability (1)', '#leakage', '#long_context (2)', '#low_resource (1)', '#machine_translation', '#math', '#multilingual (2)', '#multimodal (2)', '#open_source (3)', '#optimization (3)', '#plp', '#rag', '#reasoning (4)', '#rl (1)', '#rlhf (1)', '#robotics', '#science', '#security', '#small_models', '#story_generation', '#survey (1)', '#synthetic (1)', '#training (8)', '#transfer_learning', '#video'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-02-14 05:10',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-02-14 05:10')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-02-14 05:10')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    