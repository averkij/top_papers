{
    "date": {
        "ru": "21 января",
        "en": "January 21",
        "zh": "1月21日"
    },
    "time_utc": "2025-01-21 09:10",
    "weekday": 1,
    "issue_id": 1778,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.08325",
            "title": "GameFactory: Creating New Games with Generative Interactive Videos",
            "url": "https://huggingface.co/papers/2501.08325",
            "abstract": "Generative game engines have the potential to revolutionize game development by autonomously creating new content and reducing manual workload. However, existing video-based game generation methods fail to address the critical challenge of scene generalization, limiting their applicability to existing games with fixed styles and scenes. In this paper, we present GameFactory, a framework focused on exploring scene generalization in game video generation. To enable the creation of entirely new and diverse games, we leverage pre-trained video diffusion models trained on open-domain video data. To bridge the domain gap between open-domain priors and small-scale game dataset, we propose a multi-phase training strategy that decouples game style learning from action control, preserving open-domain generalization while achieving action controllability. Using Minecraft as our data source, we release GF-Minecraft, a high-quality and diversity action-annotated video dataset for research. Furthermore, we extend our framework to enable autoregressive action-controllable game video generation, allowing the production of unlimited-length interactive game videos. Experimental results demonstrate that GameFactory effectively generates open-domain, diverse, and action-controllable game videos, representing a significant step forward in AI-driven game generation. Our dataset and project page are publicly available at https://vvictoryuki.github.io/gamefactory/.",
            "score": 40,
            "issue_id": 1773,
            "pub_date": "2025-01-14",
            "pub_date_card": {
                "ru": "14 января",
                "en": "January 14",
                "zh": "1月14日"
            },
            "hash": "0331c9576ced4090",
            "authors": [
                "Jiwen Yu",
                "Yiran Qin",
                "Xintao Wang",
                "Pengfei Wan",
                "Di Zhang",
                "Xihui Liu"
            ],
            "affiliations": [
                "Kuaishou Technology",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.08325.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#video",
                    "#open_source",
                    "#diffusion",
                    "#games",
                    "#training",
                    "#multimodal"
                ],
                "emoji": "🎮",
                "ru": {
                    "title": "GameFactory: ИИ-революция в создании видеоигр",
                    "desc": "GameFactory - это новая система для генерации видео игр с возможностью обобщения на различные сцены. Она использует предобученные модели диффузии видео на общих данных, что позволяет создавать разнообразные новые игры. Авторы предлагают многоэтапную стратегию обучения, которая разделяет изучение стиля игры и контроль действий. Система также поддерживает авторегрессивную генерацию видео игр с контролем действий неограниченной длины."
                },
                "en": {
                    "title": "Revolutionizing Game Development with Scene Generalization",
                    "desc": "This paper introduces GameFactory, a novel framework aimed at enhancing scene generalization in game video generation. It addresses the limitations of current methods that struggle with fixed styles and scenes by utilizing pre-trained video diffusion models on diverse video data. The authors propose a multi-phase training strategy that separates game style learning from action control, allowing for better generalization and controllability. The framework is validated using a new dataset, GF-Minecraft, which supports the generation of diverse and interactive game videos, marking a significant advancement in AI-driven game development."
                },
                "zh": {
                    "title": "GameFactory：革命性的游戏视频生成框架",
                    "desc": "本论文介绍了GameFactory框架，旨在解决游戏视频生成中的场景泛化问题。现有的视频生成方法无法适应不同风格和场景的游戏，限制了其应用。我们利用预训练的视频扩散模型，并提出多阶段训练策略，以实现游戏风格学习与动作控制的解耦。实验结果表明，GameFactory能够有效生成开放域、多样化且可控的游戏视频，推动了AI驱动的游戏生成技术的发展。"
                }
            }
        }
    ],
    "link_prev": "2025-01-20.html",
    "link_next": "2025-01-22.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "20.01",
        "en": "01/20",
        "zh": "1月20日"
    },
    "short_date_next": {
        "ru": "22.01",
        "en": "01/22",
        "zh": "1月22日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 0,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种名为GameFactory的框架，旨在通过生成游戏引擎来革新游戏开发。它使用预训练的视频扩散模型，能够创建全新且多样化的游戏。为了解决现有方法在场景生成上的局限，作者提出了一种多阶段训练策略。他们还发布了一个基于Minecraft的高质量视频数据集，并展示了框架能够生成开放域、多样化和可控的游戏视频。",
        "title": "GameFactory: Creating New Games with Generative Interactive Videos",
        "pinyin": "这篇文章介绍了一种名为GameFactory的框架，旨在通过生成游戏引擎来革新游戏开发。它使用预训练的视频扩散模型，能够创建全新且多样化的游戏。为了解决现有方法在场景生成上的局限，作者提出了一种多阶段训练策略。他们还发布了一个基于Minecraft的高质量视频数据集，并展示了框架能够生成开放域、多样化和可控的游戏视频。\n\nzhè piān wén zhāng jiè shào le yī zhǒng míng wèi GameFactory de kuàng jià, zhǐ zài tōng guò shēng chéng yòu xí yǐn qíng lái gé xīn yòu xí kāi fā. tā shǐ yòng yù xùn liàn de shì pín kuò sàn mó xíng, néng gòu chuàng jiàn quán xīn qiě duō yàng huà de yòu xí. wèi le jiě jué xiàn yǒu fāng fǎ zài chǎng jīng shēng chéng shàng de jú xiàn, zuò zhě tí chū le yī zhǒng duō jiē duàn xùn liàn cè lüè. tā men hái fā bù le yī gè jī yú Minecraft de gāo zhì liàng shì pín shù jù jí, bìng zhàn shì le kuàng jià néng gòu shēng chéng kāi fàng yù, duō yàng huà hé kě kòng de yòu xí shì pín.",
        "vocab": "[{'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'},\n{'word': '旨在', 'pinyin': 'zhǐzài', 'trans': 'aim to'},\n{'word': '革新', 'pinyin': 'géxīn', 'trans': 'innovate'},\n{'word': '引擎', 'pinyin': 'yǐnqíng', 'trans': 'engine'},\n{'word': '预训练', 'pinyin': 'yù xùnliàn', 'trans': 'pre-trained'},\n{'word': '扩散', 'pinyin': 'kuòsàn', 'trans': 'diffusion'},\n{'word': '多样化', 'pinyin': 'duōyànghuà', 'trans': 'diversified'},\n{'word': '局限', 'pinyin': 'júxiàn', 'trans': 'limitation'},\n{'word': '提出', 'pinyin': 'tíchū', 'trans': 'propose'},\n{'word': '策略', 'pinyin': 'cèlüè', 'trans': 'strategy'},\n{'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'},\n{'word': '高质量', 'pinyin': 'gāo zhìliàng', 'trans': 'high quality'},\n{'word': '数据集', 'pinyin': 'shùjù jí', 'trans': 'dataset'},\n{'word': '展示', 'pinyin': 'zhǎnshì', 'trans': 'demonstrate'},\n{'word': '开放域', 'pinyin': 'kāifàng yù', 'trans': 'open domain'},\n{'word': '可控', 'pinyin': 'kěkòng', 'trans': 'controllable'}]",
        "trans": "This article introduces a framework called GameFactory, which aims to revolutionize game development by generating game engines. It utilizes pre-trained video diffusion models to create novel and diverse games. To address the limitations of existing methods in scene generation, the authors propose a multi-stage training strategy. They also release a high-quality video dataset based on Minecraft and demonstrate that the framework can generate open-domain, diverse, and controllable game videos.",
        "update_ts": "2025-01-21 09:10"
    }
}