{
    "date": {
        "ru": "14 ÑĞ½Ğ²Ğ°Ñ€Ñ",
        "en": "January 14",
        "zh": "1æœˆ14æ—¥"
    },
    "time_utc": "2025-01-14 22:09",
    "weekday": 1,
    "issue_id": 1668,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.07301",
            "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
            "url": "https://huggingface.co/papers/2501.07301",
            "abstract": "Process Reward Models (PRMs) emerge as a promising approach for process supervision in mathematical reasoning of Large Language Models (LLMs), which aim to identify and mitigate intermediate errors in the reasoning processes. However, the development of effective PRMs faces significant challenges, particularly in data annotation and evaluation methodologies. In this paper, through extensive experiments, we demonstrate that commonly used Monte Carlo (MC) estimation-based data synthesis for PRMs typically yields inferior performance and generalization compared to LLM-as-a-judge and human annotation methods. MC estimation relies on completion models to evaluate current-step correctness, leading to inaccurate step verification. Furthermore, we identify potential biases in conventional Best-of-N (BoN) evaluation strategies for PRMs: (1) The unreliable policy models generate responses with correct answers but flawed processes, leading to a misalignment between the evaluation criteria of BoN and the PRM objectives of process verification. (2) The tolerance of PRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a significant proportion of minimum scores concentrated on the final answer steps, revealing the shift from process to outcome-based assessment in BoN Optimized PRMs. To address these challenges, we develop a consensus filtering mechanism that effectively integrates MC estimation with LLM-as-a-judge and advocates a more comprehensive evaluation framework that combines response-level and step-level metrics. Based on the mechanisms, we significantly improve both model performance and data efficiency in the BoN evaluation and the step-wise error identification task. Finally, we release a new state-of-the-art PRM that outperforms existing open-source alternatives and provides practical guidelines for future research in building process supervision models.",
            "score": 46,
            "issue_id": 1651,
            "pub_date": "2025-01-13",
            "pub_date_card": {
                "ru": "13 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 13",
                "zh": "1æœˆ13æ—¥"
            },
            "hash": "98f46bb1e2772efc",
            "authors": [
                "Zhenru Zhang",
                "Chujie Zheng",
                "Yangzhen Wu",
                "Beichen Zhang",
                "Runji Lin",
                "Bowen Yu",
                "Dayiheng Liu",
                "Jingren Zhou",
                "Junyang Lin"
            ],
            "affiliations": [
                "Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.07301.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#data",
                    "#reasoning",
                    "#benchmark",
                    "#optimization",
                    "#open_source",
                    "#training"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "Ğ£ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Process Reward Models Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Process Reward Models (PRM) Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ² ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ñ… ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ PRMs, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Monte Carlo Ğ¸ Best-of-N. ĞĞ½Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑĞ°, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‰Ğ¸Ğ¹ MC-Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ñ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼ LLM-as-a-judge. Ğ’ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½ÑƒÑ PRM, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‰ÑƒÑ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ open-source Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ñ‹."
                },
                "en": {
                    "title": "Enhancing Reasoning in LLMs with Process Reward Models",
                    "desc": "This paper introduces Process Reward Models (PRMs) as a method to enhance the reasoning capabilities of Large Language Models (LLMs) by identifying and correcting errors in their reasoning processes. The authors highlight the limitations of traditional Monte Carlo estimation methods for data synthesis, which often lead to poor performance in evaluating reasoning steps. They also point out biases in the Best-of-N evaluation strategies that can misalign with the goals of PRMs, particularly in how they assess the correctness of reasoning processes versus final answers. To overcome these issues, the paper proposes a new consensus filtering mechanism that combines different evaluation methods, resulting in improved model performance and more accurate error identification."
                },
                "zh": {
                    "title": "æå‡è¿‡ç¨‹ç›‘ç£æ¨¡å‹çš„æœ‰æ•ˆæ€§",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ•°å­¦æ¨ç†ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è¯†åˆ«å’Œå‡å°‘æ¨ç†è¿‡ç¨‹ä¸­çš„ä¸­é—´é”™è¯¯ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¼ ç»Ÿçš„åŸºäºè’™ç‰¹å¡æ´›ä¼°è®¡çš„æ•°æ®åˆæˆæ–¹æ³•åœ¨æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ä¸Šä¸å¦‚ä½¿ç”¨LLMä½œä¸ºè¯„åˆ¤è€…å’Œäººå·¥æ ‡æ³¨çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œç°æœ‰çš„æœ€ä½³é€‰æ‹©ï¼ˆBoNï¼‰è¯„ä¼°ç­–ç•¥å­˜åœ¨åå·®ï¼Œå¯¼è‡´è¯„ä¼°æ ‡å‡†ä¸PRMçš„è¿‡ç¨‹éªŒè¯ç›®æ ‡ä¸ä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å…±è¯†è¿‡æ»¤æœºåˆ¶ï¼Œç»“åˆäº†è’™ç‰¹å¡æ´›ä¼°è®¡å’ŒLLMè¯„åˆ¤è€…ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½å’Œæ•°æ®æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06425",
            "title": "Tensor Product Attention Is All You Need",
            "url": "https://huggingface.co/papers/2501.06425",
            "abstract": "Scaling language models to handle longer input sequences typically necessitates large key-value (KV) caches, resulting in substantial memory overhead during inference. In this paper, we propose Tensor Product Attention (TPA), a novel attention mechanism that uses tensor decompositions to represent queries, keys, and values compactly, significantly shrinking KV cache size at inference time. By factorizing these representations into contextual low-rank components (contextual factorization) and seamlessly integrating with RoPE, TPA achieves improved model quality alongside memory efficiency. Based on TPA, we introduce the Tensor ProducT ATTenTion Transformer (T6), a new model architecture for sequence modeling. Through extensive empirical evaluation of language modeling tasks, we demonstrate that T6 exceeds the performance of standard Transformer baselines including MHA, MQA, GQA, and MLA across various metrics, including perplexity and a range of renowned evaluation benchmarks. Notably, TPAs memory efficiency enables the processing of significantly longer sequences under fixed resource constraints, addressing a critical scalability challenge in modern language models. The code is available at https://github.com/tensorgi/T6.",
            "score": 35,
            "issue_id": 1651,
            "pub_date": "2025-01-11",
            "pub_date_card": {
                "ru": "11 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 11",
                "zh": "1æœˆ11æ—¥"
            },
            "hash": "f723487eccf1ccfe",
            "authors": [
                "Yifan Zhang",
                "Yifeng Liu",
                "Huizhuo Yuan",
                "Zhen Qin",
                "Yang Yuan",
                "Quanquan Gu",
                "Andrew Chi-Chih Yao"
            ],
            "affiliations": [
                "IIIS, Tsinghua University",
                "Shanghai Qi Zhi Institute",
                "TapTap",
                "University of California, Los Angeles"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06425.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#long_context",
                    "#optimization",
                    "#inference",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ: ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ - Tensor Product Attention (TPA), Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², ĞºĞ»ÑÑ‡ĞµĞ¹ Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹. TPA Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ĞºÑÑˆĞ° ĞºĞ»ÑÑ‡-Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğµ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ TPA Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ½Ğ¾Ğ²ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ - Tensor ProducT ATTenTion Transformer (T6). Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ T6 Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Transformer Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼. TPA Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ°Ñ…, Ñ€ĞµÑˆĞ°Ñ Ğ²Ğ°Ğ¶Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Efficient Attention for Longer Sequences with TPA",
                    "desc": "This paper introduces Tensor Product Attention (TPA), a new attention mechanism designed to reduce memory usage during inference in language models. TPA achieves this by using tensor decompositions to compactly represent queries, keys, and values, which allows for smaller key-value caches. The authors present the Tensor ProducT ATTenTion Transformer (T6), a model that integrates TPA and shows improved performance on language modeling tasks compared to traditional Transformer architectures. T6 not only enhances model quality but also enables the processing of longer input sequences efficiently, addressing a key limitation in current language models."
                },
                "zh": {
                    "title": "å¼ é‡ä¹˜ç§¯æ³¨æ„åŠ›ï¼šé«˜æ•ˆå¤„ç†é•¿åºåˆ—çš„åˆ›æ–°æ–¹æ¡ˆ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç§°ä¸ºå¼ é‡ä¹˜ç§¯æ³¨æ„åŠ›ï¼ˆTPAï¼‰ï¼Œæ—¨åœ¨è§£å†³é•¿è¾“å…¥åºåˆ—å¤„ç†ä¸­çš„å†…å­˜å¼€é”€é—®é¢˜ã€‚TPAé€šè¿‡å¼ é‡åˆ†è§£æŠ€æœ¯ï¼Œç´§å‡‘åœ°è¡¨ç¤ºæŸ¥è¯¢ã€é”®å’Œå€¼ï¼Œä»è€Œæ˜¾è‘—å‡å°‘æ¨ç†æ—¶çš„KVç¼“å­˜å¤§å°ã€‚è¯¥æœºåˆ¶ç»“åˆäº†ä¸Šä¸‹æ–‡ä½ç§©åˆ†è§£å’ŒRoPEï¼Œæå‡äº†æ¨¡å‹è´¨é‡å’Œå†…å­˜æ•ˆç‡ã€‚åŸºäºTPAï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„æ¨¡å‹æ¶æ„â€”â€”å¼ é‡ä¹˜ç§¯æ³¨æ„åŠ›å˜æ¢å™¨ï¼ˆT6ï¼‰ï¼Œåœ¨è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„TransformeråŸºçº¿ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06252",
            "title": "$\\text{Transformer}^2$: Self-adaptive LLMs",
            "url": "https://huggingface.co/papers/2501.06252",
            "abstract": "Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce \\implname, a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting only the singular components of their weight matrices. During inference, \\implname employs a two-pass mechanism: first, a dispatch system identifies the task properties, and then task-specific \"expert\" vectors, trained using reinforcement learning, are dynamically mixed to obtain targeted behavior for the incoming prompt. Our method outperforms ubiquitous approaches such as LoRA, with fewer parameters and greater efficiency. \\implname demonstrates versatility across different LLM architectures and modalities, including vision-language tasks. \\implname represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems.",
            "score": 19,
            "issue_id": 1651,
            "pub_date": "2025-01-09",
            "pub_date_card": {
                "ru": "9 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 9",
                "zh": "1æœˆ9æ—¥"
            },
            "hash": "935c31e095aeeec8",
            "authors": [
                "Qi Sun",
                "Edoardo Cetin",
                "Yujin Tang"
            ],
            "affiliations": [
                "Institute of Science Tokyo, Japan",
                "Sakana AI, Japan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06252.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#agi",
                    "#rl",
                    "#optimization",
                    "#training",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ¡Ğ°Ğ¼Ğ¾Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº ÑĞ°Ğ¼Ğ¾Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğº Ğ½Ğ¾Ğ²Ñ‹Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑÑÑ‚ÑÑ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ²Ñ€Ğ¾Ğ´Ğµ LoRA, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ĞµĞµ. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€ LLM Ğ¸ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Dynamic Adaptation for Language Models",
                    "desc": "This paper presents a new framework called \textit{implname} that enhances large language models (LLMs) by allowing them to adapt to new tasks in real-time without the heavy computational costs of traditional fine-tuning. Instead of adjusting the entire model, \textit{implname} selectively modifies specific components of the model's weight matrices, making it more efficient. The framework uses a two-step process during inference: first, it identifies the task requirements, and then it combines specialized 'expert' vectors, which are optimized through reinforcement learning, to tailor the model's response. This approach not only improves performance compared to existing methods like LoRA but also works across various LLM architectures and tasks, including those involving both text and images."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”LLMsï¼šé«˜æ•ˆåº”å¯¹å¤šæ ·åŒ–ä»»åŠ¡çš„æœªæ¥",
                    "desc": "è‡ªé€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¨åœ¨è§£å†³ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•çš„æŒ‘æˆ˜ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸è®¡ç®—å¯†é›†ä¸”åœ¨å¤„ç†å¤šæ ·åŒ–ä»»åŠ¡æ—¶èƒ½åŠ›æœ‰é™ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„è‡ªé€‚åº”æ¡†æ¶\textit{implname}ï¼Œå®ƒé€šè¿‡é€‰æ‹©æ€§è°ƒæ•´æƒé‡çŸ©é˜µçš„å•ä¸ªç»„ä»¶ï¼Œå®æ—¶é€‚åº”LLMsä»¥åº”å¯¹æœªè§è¿‡çš„ä»»åŠ¡ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œ\textit{implname}é‡‡ç”¨åŒé‡æœºåˆ¶ï¼šé¦–å…ˆï¼Œè°ƒåº¦ç³»ç»Ÿè¯†åˆ«ä»»åŠ¡å±æ€§ï¼Œç„¶ååŠ¨æ€æ··åˆç»è¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„ä»»åŠ¡ç‰¹å®šâ€œä¸“å®¶â€å‘é‡ï¼Œä»¥è·å¾—é’ˆå¯¹è¾“å…¥æç¤ºçš„ç›®æ ‡è¡Œä¸ºã€‚æˆ‘ä»¬çš„ç ”ç©¶æ–¹æ³•åœ¨å‚æ•°æ›´å°‘ä¸”æ•ˆç‡æ›´é«˜çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•ï¼Œå¦‚LoRAï¼Œå±•ç¤ºäº†åœ¨ä¸åŒLLMæ¶æ„å’Œæ¨¡æ€ï¼ˆåŒ…æ‹¬è§†è§‰-è¯­è¨€ä»»åŠ¡ï¼‰ä¸­çš„å¤šæ ·æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06173",
            "title": "VideoAuteur: Towards Long Narrative Video Generation",
            "url": "https://huggingface.co/papers/2501.06173",
            "abstract": "Recent video generation models have shown promising results in producing high-quality video clips lasting several seconds. However, these models face challenges in generating long sequences that convey clear and informative events, limiting their ability to support coherent narrations. In this paper, we present a large-scale cooking video dataset designed to advance long-form narrative generation in the cooking domain. We validate the quality of our proposed dataset in terms of visual fidelity and textual caption accuracy using state-of-the-art Vision-Language Models (VLMs) and video generation models, respectively. We further introduce a Long Narrative Video Director to enhance both visual and semantic coherence in generated videos and emphasize the role of aligning visual embeddings to achieve improved overall video quality. Our method demonstrates substantial improvements in generating visually detailed and semantically aligned keyframes, supported by finetuning techniques that integrate text and image embeddings within the video generation process. Project page: https://videoauteur.github.io/",
            "score": 18,
            "issue_id": 1653,
            "pub_date": "2025-01-10",
            "pub_date_card": {
                "ru": "10 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 10",
                "zh": "1æœˆ10æ—¥"
            },
            "hash": "e110fbe840c50afa",
            "authors": [
                "Junfei Xiao",
                "Feng Cheng",
                "Lu Qi",
                "Liangke Gui",
                "Jiepeng Cen",
                "Zhibei Ma",
                "Alan Yuille",
                "Lu Jiang"
            ],
            "affiliations": [
                "ByteDance",
                "ByteDance Seed",
                "Johns Hopkins University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06173.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#story_generation",
                    "#dataset",
                    "#long_context",
                    "#training",
                    "#multimodal",
                    "#alignment"
                ],
                "emoji": "ğŸ³",
                "ru": {
                    "title": "Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ°Ñ€Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ€Ğ¾Ğ»Ğ¸ĞºĞ¾Ğ² Ğ¾ Ğ¿Ñ€Ğ¸Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ğ¿Ğ¸Ñ‰Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾. ĞĞ½Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Long Narrative Video Director Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ĞºĞ°Ğ´Ñ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing Long-Form Video Generation with Coherent Narratives",
                    "desc": "This paper addresses the limitations of current video generation models in creating long, coherent videos, particularly in the cooking domain. It introduces a large-scale dataset specifically designed for generating long-form cooking videos, ensuring high visual quality and accurate textual descriptions. The authors propose a Long Narrative Video Director that improves both the visual and semantic coherence of the generated content by aligning visual embeddings. Their approach shows significant advancements in producing detailed keyframes and enhancing overall video quality through the integration of text and image embeddings."
                },
                "zh": {
                    "title": "æ¨åŠ¨çƒ¹é¥ªè§†é¢‘çš„é•¿ç¯‡å™äº‹ç”Ÿæˆ",
                    "desc": "æœ€è¿‘çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨ç”ŸæˆæŒç»­å‡ ç§’çš„é«˜è´¨é‡è§†é¢‘ç‰‡æ®µæ–¹é¢å–å¾—äº†è‰¯å¥½æ•ˆæœã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨ç”Ÿæˆé•¿åºåˆ—æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œéš¾ä»¥ä¼ è¾¾æ¸…æ™°ä¸”ä¿¡æ¯ä¸°å¯Œçš„äº‹ä»¶ï¼Œé™åˆ¶äº†å®ƒä»¬æ”¯æŒè¿è´¯å™è¿°çš„èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„çƒ¹é¥ªè§†é¢‘æ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨çƒ¹é¥ªé¢†åŸŸçš„é•¿ç¯‡å™äº‹ç”Ÿæˆã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é•¿å™äº‹è§†é¢‘å¯¼æ¼”ï¼Œå¢å¼ºç”Ÿæˆè§†é¢‘çš„è§†è§‰å’Œè¯­ä¹‰ä¸€è‡´æ€§ï¼Œå¹¶å¼ºè°ƒå¯¹é½è§†è§‰åµŒå…¥åœ¨æé«˜æ•´ä½“è§†é¢‘è´¨é‡ä¸­çš„é‡è¦æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.07572",
            "title": "WebWalker: Benchmarking LLMs in Web Traversal",
            "url": "https://huggingface.co/papers/2501.07572",
            "abstract": "Retrieval-augmented generation (RAG) demonstrates remarkable performance across tasks in open-domain question-answering. However, traditional search engines may retrieve shallow content, limiting the ability of LLMs to handle complex, multi-layered information. To address it, we introduce WebWalkerQA, a benchmark designed to assess the ability of LLMs to perform web traversal. It evaluates the capacity of LLMs to traverse a website's subpages to extract high-quality data systematically. We propose WebWalker, which is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm. Extensive experimental results show that WebWalkerQA is challenging and demonstrates the effectiveness of RAG combined with WebWalker, through the horizontal and vertical integration in real-world scenarios.",
            "score": 14,
            "issue_id": 1651,
            "pub_date": "2025-01-13",
            "pub_date_card": {
                "ru": "13 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 13",
                "zh": "1æœˆ13æ—¥"
            },
            "hash": "1dd4e60432c1ca54",
            "authors": [
                "Jialong Wu",
                "Wenbiao Yin",
                "Yong Jiang",
                "Zhenglin Wang",
                "Zekun Xi",
                "Runnan Fang",
                "Deyu Zhou",
                "Pengjun Xie",
                "Fei Huang"
            ],
            "affiliations": [
                "Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.07572.jpg",
            "data": {
                "categories": [
                    "#rag",
                    "#reasoning",
                    "#benchmark",
                    "#agi",
                    "#optimization",
                    "#games",
                    "#interpretability",
                    "#agents",
                    "#survey"
                ],
                "emoji": "ğŸ•¸ï¸",
                "ru": {
                    "title": "WebWalker: ÑƒĞ¼Ğ½Ğ°Ñ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ²ĞµĞ±-ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ğ¼ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° - WebWalkerQA. Ğ­Ñ‚Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ²ĞµĞ±-ÑĞ°Ğ¹Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº WebWalker, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ²ĞµĞ±-ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ğ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ RAG Ğ¸ WebWalker Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Enhancing LLMs with Human-like Web Navigation for Better Information Retrieval",
                    "desc": "This paper introduces WebWalkerQA, a benchmark for evaluating large language models (LLMs) in open-domain question-answering tasks. It addresses the limitations of traditional search engines that often retrieve superficial content, which hinders LLMs from accessing complex information. The proposed WebWalker framework uses a multi-agent system that simulates human-like web navigation, allowing LLMs to systematically traverse subpages of a website to gather high-quality data. Experimental results indicate that combining retrieval-augmented generation (RAG) with WebWalker enhances the models' performance in real-world scenarios by enabling deeper information extraction."
                },
                "zh": {
                    "title": "WebWalkerQAï¼šæå‡é—®ç­”ç³»ç»Ÿçš„ç½‘é¡µå¯¼èˆªèƒ½åŠ›",
                    "desc": "æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨å¼€æ”¾é¢†åŸŸé—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä¼ ç»Ÿæœç´¢å¼•æ“å¯èƒ½åªæ£€ç´¢åˆ°è¡¨é¢å†…å®¹ï¼Œé™åˆ¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤„ç†å¤æ‚ä¿¡æ¯çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†WebWalkerQAï¼Œè¿™æ˜¯ä¸€ä¸ªè¯„ä¼°LLMsè¿›è¡Œç½‘é¡µéå†èƒ½åŠ›çš„åŸºå‡†ã€‚å®ƒè¯„ä¼°LLMsç³»ç»Ÿæ€§åœ°éå†ç½‘ç«™å­é¡µé¢ä»¥æå–é«˜è´¨é‡æ•°æ®çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†WebWalkerï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šä»£ç†æ¡†æ¶ï¼Œé€šè¿‡æ¢ç´¢-è¯„ä¼°èŒƒå¼æ¨¡æ‹Ÿäººç±»çš„ç½‘é¡µå¯¼èˆªã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06458",
            "title": "O1 Replication Journey -- Part 3: Inference-time Scaling for Medical Reasoning",
            "url": "https://huggingface.co/papers/2501.06458",
            "abstract": "Building upon our previous investigations of O1 replication (Part 1: Journey Learning [Qin et al., 2024] and Part 2: Distillation [Huang et al., 2024]), this work explores the potential of inference-time scaling in large language models (LLMs) for medical reasoning tasks, ranging from diagnostic decision-making to treatment planning. Through extensive experiments on medical benchmarks of varying complexity (MedQA, Medbullets, and JAMA Clinical Challenges), our investigation reveals several key insights: (1) Increasing inference time does lead to improved performance. With a modest training set of 500 samples, our model yields substantial performance improvements of 6%-11%. (2) Task complexity directly correlates with the required length of reasoning chains, confirming the necessity of extended thought processes for challenging problems. (3) The differential diagnoses generated by our model adhere to the principles of the hypothetico-deductive method, producing a list of potential conditions that may explain a patient's symptoms and systematically narrowing these possibilities by evaluating the evidence. These findings demonstrate the promising synergy between inference-time scaling and journey learning in advancing LLMs' real-world clinical reasoning capabilities.",
            "score": 14,
            "issue_id": 1651,
            "pub_date": "2025-01-11",
            "pub_date_card": {
                "ru": "11 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 11",
                "zh": "1æœˆ11æ—¥"
            },
            "hash": "c95817afd181bd85",
            "authors": [
                "Zhongzhen Huang",
                "Gui Geng",
                "Shengyi Hua",
                "Zhen Huang",
                "Haoyang Zou",
                "Shaoting Zhang",
                "Pengfei Liu",
                "Xiaofan Zhang"
            ],
            "affiliations": [
                "Generative AI Research Lab (GAIR)",
                "SII",
                "SPIRAL Lab",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06458.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#inference",
                    "#healthcare",
                    "#reasoning"
                ],
                "emoji": "ğŸ©º",
                "ru": {
                    "title": "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° LLM ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM) Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ ĞºĞ¾Ñ€Ñ€ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ñ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ğ¾Ğ¹ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ”Ğ¸Ñ„Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾Ğ·Ñ‹, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ°Ğ¼ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµÑ‚Ğ¸ĞºĞ¾-Ğ´ĞµĞ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°."
                },
                "en": {
                    "title": "Enhancing Medical Reasoning in LLMs through Inference-Time Scaling",
                    "desc": "This paper investigates how increasing inference time can enhance the performance of large language models (LLMs) in medical reasoning tasks. The authors conducted experiments on various medical benchmarks and found that longer inference times lead to significant performance improvements, even with a small training dataset. They also discovered that more complex tasks require longer reasoning chains, highlighting the importance of extended thought processes. Additionally, the model's differential diagnoses align with the hypothetico-deductive method, showcasing its ability to systematically evaluate potential conditions based on patient symptoms."
                },
                "zh": {
                    "title": "æ¨ç†æ—¶é—´æ‰©å±•åŠ©åŠ›åŒ»å­¦æ¨ç†èƒ½åŠ›æå‡",
                    "desc": "æœ¬ç ”ç©¶åŸºäºæˆ‘ä»¬ä¹‹å‰å¯¹O1å¤åˆ¶çš„ç ”ç©¶ï¼Œæ¢è®¨äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ¨ç†æ—¶é—´æ‰©å±•å¯¹åŒ»å­¦æ¨ç†ä»»åŠ¡çš„æ½œåŠ›ã€‚é€šè¿‡åœ¨ä¸åŒå¤æ‚åº¦çš„åŒ»å­¦åŸºå‡†ï¼ˆå¦‚MedQAã€Medbulletså’ŒJAMAä¸´åºŠæŒ‘æˆ˜ï¼‰ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å‘ç°å¢åŠ æ¨ç†æ—¶é—´ç¡®å®èƒ½æé«˜æ¨¡å‹æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ä»…æœ‰500ä¸ªæ ·æœ¬çš„è®­ç»ƒé›†ä¸Šï¼Œæ€§èƒ½æå‡å¯è¾¾6%-11%ã€‚æ­¤å¤–ï¼Œä»»åŠ¡çš„å¤æ‚æ€§ä¸æ‰€éœ€æ¨ç†é“¾çš„é•¿åº¦ç›´æ¥ç›¸å…³ï¼Œè¡¨æ˜å¯¹äºå¤æ‚é—®é¢˜éœ€è¦æ›´é•¿çš„æ€è€ƒè¿‡ç¨‹ã€‚æœ€åï¼Œæˆ‘ä»¬çš„æ¨¡å‹ç”Ÿæˆçš„å·®å¼‚æ€§è¯Šæ–­éµå¾ªå‡è®¾æ¼”ç»æ³•çš„åŸåˆ™ï¼Œç³»ç»Ÿåœ°è¯„ä¼°è¯æ®ä»¥ç¼©å°å¯èƒ½çš„ç—…ç—‡èŒƒå›´ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06282",
            "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction",
            "url": "https://huggingface.co/papers/2501.06282",
            "abstract": "Recent advancements in large language models (LLMs) and multimodal speech-text models have laid the groundwork for seamless voice interactions, enabling real-time, natural, and human-like conversations. Previous models for voice interactions are categorized as native and aligned. Native models integrate speech and text processing in one framework but struggle with issues like differing sequence lengths and insufficient pre-training. Aligned models maintain text LLM capabilities but are often limited by small datasets and a narrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal Large Language Model with approximately 8B parameters for seamless voice interaction. We address the main limitations of prior aligned multimodal models. We train MinMo through multiple stages of speech-to-text alignment, text-to-speech alignment, speech-to-speech alignment, and duplex interaction alignment, on 1.4 million hours of diverse speech data and a broad range of speech tasks. After the multi-stage training, MinMo achieves state-of-the-art performance across various benchmarks for voice comprehension and generation while maintaining the capabilities of text LLMs, and also facilitates full-duplex conversation, that is, simultaneous two-way communication between the user and the system. Moreover, we propose a novel and simple voice decoder that outperforms prior models in voice generation. The enhanced instruction-following capabilities of MinMo supports controlling speech generation based on user instructions, with various nuances including emotions, dialects, and speaking rates, and mimicking specific voices. For MinMo, the speech-to-text latency is approximately 100ms, full-duplex latency is approximately 600ms in theory and 800ms in practice. The MinMo project web page is https://funaudiollm.github.io/minmo, and the code and models will be released soon.",
            "score": 13,
            "issue_id": 1651,
            "pub_date": "2025-01-10",
            "pub_date_card": {
                "ru": "10 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 10",
                "zh": "1æœˆ10æ—¥"
            },
            "hash": "2bd352453760208e",
            "authors": [
                "Qian Chen",
                "Yafeng Chen",
                "Yanni Chen",
                "Mengzhe Chen",
                "Yingda Chen",
                "Chong Deng",
                "Zhihao Du",
                "Ruize Gao",
                "Changfeng Gao",
                "Zhifu Gao",
                "Yabin Li",
                "Xiang Lv",
                "Jiaqing Liu",
                "Haoneng Luo",
                "Bin Ma",
                "Chongjia Ni",
                "Xian Shi",
                "Jialong Tang",
                "Hui Wang",
                "Hao Wang",
                "Wen Wang",
                "Yuxuan Wang",
                "Yunlan Xu",
                "Fan Yu",
                "Zhijie Yan",
                "Yexin Yang",
                "Baosong Yang",
                "Xian Yang",
                "Guanrou Yang",
                "Tianyu Zhao",
                "Qinglin Zhang",
                "Shiliang Zhang",
                "Nan Zhao",
                "Pei Zhang",
                "Chong Zhang",
                "Jinren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06282.jpg",
            "data": {
                "categories": [
                    "#audio",
                    "#multimodal",
                    "#training"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "MinMo: Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¼ Ğ˜Ğ˜-Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¸",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ MinMo - Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ±Ğ¾Ğ»ÑŒÑˆÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ±ĞµÑĞ¿Ñ€ĞµĞ¿ÑÑ‚ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ½Ğ° 1,4 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ°Ñ… Ñ‡Ğ°ÑĞ¾Ğ² Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ€ĞµÑ‡ĞµĞ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾Ğ¼ ÑĞ¿ĞµĞºÑ‚Ñ€Ğµ Ñ€ĞµÑ‡ĞµĞ²Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ°Ğ¿Ğ¾Ğ² Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑ‡Ğ¸ Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°. MinMo Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğ¸ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑ‡Ğ¸, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ¯Ğ‘Ğœ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ´ÑƒĞ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğµ Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€ĞµÑ‡Ğ¸ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ½ÑĞ°Ğ½ÑĞ°Ğ¼Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸, Ğ´Ğ¸Ğ°Ğ»ĞµĞºÑ‚Ñ‹ Ğ¸ Ñ‚ĞµĞ¼Ğ¿ Ñ€ĞµÑ‡Ğ¸."
                },
                "en": {
                    "title": "MinMo: Revolutionizing Voice Interactions with Multimodal Learning",
                    "desc": "This paper presents MinMo, a Multimodal Large Language Model designed for seamless voice interactions, featuring around 8 billion parameters. It overcomes limitations of previous aligned models by employing a multi-stage training approach that includes speech-to-text, text-to-speech, and duplex interaction alignments, utilizing a vast dataset of 1.4 million hours of diverse speech. MinMo achieves state-of-the-art performance in voice comprehension and generation, enabling full-duplex conversations and enhanced instruction-following capabilities for nuanced speech generation. Additionally, it introduces a novel voice decoder that significantly improves voice generation quality compared to earlier models."
                },
                "zh": {
                    "title": "MinMoï¼šæ— ç¼è¯­éŸ³äº¤äº’çš„æ–°çªç ´",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºMinMoçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°æ— ç¼çš„è¯­éŸ³äº¤äº’ã€‚MinMoå…·æœ‰çº¦80äº¿ä¸ªå‚æ•°ï¼Œé€šè¿‡å¤šé˜¶æ®µçš„å¯¹é½è®­ç»ƒï¼Œå…‹æœäº†ä»¥å¾€æ¨¡å‹åœ¨è¯­éŸ³ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ”¯æŒå…¨åŒå·¥å¯¹è¯ï¼Œå…è®¸ç”¨æˆ·ä¸ç³»ç»Ÿè¿›è¡Œå®æ—¶çš„åŒå‘äº¤æµã€‚MinMoè¿˜å…·å¤‡æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ç”Ÿæˆè¯­éŸ³çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿè°ƒæ•´æƒ…æ„Ÿã€æ–¹è¨€å’Œè¯­é€Ÿç­‰ç»†èŠ‚ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06842",
            "title": "SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training",
            "url": "https://huggingface.co/papers/2501.06842",
            "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across diverse tasks, yet their training remains highly resource-intensive and susceptible to critical challenges such as training instability. A predominant source of this instability stems from gradient and loss spikes, which disrupt the learning process, often leading to costly interventions like checkpoint recovery and experiment restarts, further amplifying inefficiencies. This paper presents a comprehensive investigation into gradient spikes observed during LLM training, revealing their prevalence across multiple architectures and datasets. Our analysis shows that these spikes can be up to 1000times larger than typical gradients, substantially deteriorating model performance. To address this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a novel optimizer designed to counteract gradient spikes through momentum reset and spike-aware gradient clipping. Extensive experiments, including both pre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam and its variants across various tasks, including (1) LLM pre-training from 60M to 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time Series Forecasting. Additionally, SPAM facilitates memory-efficient training by enabling sparse momentum, where only a subset of momentum terms are maintained and updated. When operating under memory constraints, SPAM outperforms state-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our work underscores the importance of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is available at https://github.com/TianjinYellow/SPAM-Optimizer.git",
            "score": 10,
            "issue_id": 1658,
            "pub_date": "2025-01-12",
            "pub_date_card": {
                "ru": "12 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 12",
                "zh": "1æœˆ12æ—¥"
            },
            "hash": "d5fec659e34cf867",
            "authors": [
                "Tianjin Huang",
                "Ziquan Zhu",
                "Gaojie Jin",
                "Lu Liu",
                "Zhangyang Wang",
                "Shiwei Liu"
            ],
            "affiliations": [
                "Eindhoven University of Technology",
                "University of Exeter",
                "University of Leicester",
                "University of Oxford",
                "University of Texas at Austin"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06842.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#optimization"
                ],
                "emoji": "ğŸ“ˆ",
                "ru": {
                    "title": "SPAM: Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ SPAM (Spike-Aware Adam with Momentum Reset) Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). SPAM Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ€ĞµĞ·ĞºĞ¸Ñ… ÑĞºĞ°Ñ‡ĞºĞ¾Ğ² Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ² 1000 Ñ€Ğ°Ğ· Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ğ¸ Ğ½Ğ°Ñ€ÑƒÑˆĞ°ÑÑ‚ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ±Ñ€Ğ¾Ñ Ğ¸Ğ¼Ğ¿ÑƒĞ»ÑŒÑĞ° Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ ÑÑ‚Ğ¸Ğ¼ ÑĞºĞ°Ñ‡ĞºĞ°Ğ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ SPAM Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Adam Ğ¸ ĞµĞ³Ğ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ LLM, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ÑĞ´Ğ¾Ğ²."
                },
                "en": {
                    "title": "Taming Gradient Spikes for Stable LLM Training with SPAM",
                    "desc": "This paper investigates the issue of gradient spikes during the training of Large Language Models (LLMs), which can lead to instability and inefficiencies. These spikes can be significantly larger than normal gradients, negatively impacting model performance and requiring costly interventions. To combat this problem, the authors propose a new optimizer called Spike-Aware Adam with Momentum Reset (SPAM), which incorporates momentum reset and spike-aware gradient clipping. Experimental results show that SPAM outperforms traditional optimizers like Adam in various tasks while also being more memory-efficient."
                },
                "zh": {
                    "title": "åº”å¯¹æ¢¯åº¦æ³¢åŠ¨ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ï¼",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶è®­ç»ƒè¿‡ç¨‹èµ„æºæ¶ˆè€—å¤§ä¸”å®¹æ˜“å‡ºç°ä¸ç¨³å®šæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œæ¢¯åº¦å’ŒæŸå¤±çš„å‰§çƒˆæ³¢åŠ¨æ˜¯å¯¼è‡´è®­ç»ƒä¸ç¨³å®šçš„ä¸»è¦åŸå› ï¼Œè¿™ä¼šå½±å“å­¦ä¹ è¿‡ç¨‹å¹¶å¢åŠ å¹²é¢„æˆæœ¬ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ä¼˜åŒ–å™¨â€”â€”Spike-Aware Adam with Momentum Resetï¼ˆSPAMï¼‰ï¼Œæ—¨åœ¨é€šè¿‡åŠ¨é‡é‡ç½®å’Œæ¢¯åº¦å‰ªåˆ‡æ¥åº”å¯¹æ¢¯åº¦æ³¢åŠ¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSPAMåœ¨å¤šç§ä»»åŠ¡ä¸­å‡ä¼˜äºä¼ ç»Ÿçš„Adamä¼˜åŒ–å™¨ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œèµ„æºæ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.07574",
            "title": "UnCommon Objects in 3D",
            "url": "https://huggingface.co/papers/2501.07574",
            "abstract": "We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for 3D deep learning and 3D generative AI. uCO3D is the largest publicly-available collection of high-resolution videos of objects with 3D annotations that ensures full-360^{circ} coverage. uCO3D is significantly more diverse than MVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of higher quality, due to extensive quality checks of both the collected videos and the 3D annotations. Similar to analogous datasets, uCO3D contains annotations for 3D camera poses, depth maps and sparse point clouds. In addition, each object is equipped with a caption and a 3D Gaussian Splat reconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D and obtain superior results using the latter, showing that uCO3D is better for learning applications.",
            "score": 7,
            "issue_id": 1651,
            "pub_date": "2025-01-13",
            "pub_date_card": {
                "ru": "13 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 13",
                "zh": "1æœˆ13æ—¥"
            },
            "hash": "79c40f6997052ddd",
            "authors": [
                "Xingchen Liu",
                "Piyush Tayal",
                "Jianyuan Wang",
                "Jesus Zarzar",
                "Tom Monnier",
                "Konstantinos Tertikas",
                "Jiali Duan",
                "Antoine Toisoul",
                "Jason Y. Zhang",
                "Natalia Neverova",
                "Andrea Vedaldi",
                "Roman Shapovalov",
                "David Novotny"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "KAUST",
                "Meta AI",
                "NKUA, Greece"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.07574.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#open_source",
                    "#synthetic",
                    "#3d"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "uCO3D: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ´Ğ»Ñ 3D-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸",
                    "desc": "ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… uCO3D Ğ´Ğ»Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜ Ğ² 3D. Ğ­Ñ‚Ğ¾Ñ‚ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ 360-Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ½Ñ‹Ğ¼ Ğ¾Ñ…Ğ²Ğ°Ñ‚Ğ¾Ğ¼ Ğ¸ 3D-Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸. uCO3D Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ Ğ±Ğ¾Ğ»ĞµĞµ 1000 ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ², Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ñƒ Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°Ğ¼. ĞŸĞ¾Ğ¼Ğ¸Ğ¼Ğ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹, Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸ Ğº Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼ Ğ¸ 3D-Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ³Ğ°ÑƒÑÑĞ¾Ğ²Ñ‹Ñ… ÑĞ¿Ğ»Ğ°Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Unlocking 3D Learning with uCO3D: A New Era of Object-Centric Datasets",
                    "desc": "The paper presents Uncommon Objects in 3D (uCO3D), a comprehensive dataset designed for advancing 3D deep learning and generative AI. This dataset features high-resolution videos with full 360-degree coverage and includes over 1,000 diverse object categories, making it larger and more varied than existing datasets like MVImgNet and CO3Dv2. uCO3D provides detailed annotations such as 3D camera poses, depth maps, and sparse point clouds, along with captions and 3D Gaussian Splat reconstructions for each object. Experiments demonstrate that training large 3D models on uCO3D yields superior performance compared to other datasets, highlighting its effectiveness for learning applications."
                },
                "zh": {
                    "title": "uCO3Dï¼šæå‡3Då­¦ä¹ çš„å…¨æ–°æ•°æ®é›†",
                    "desc": "æˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªæ–°çš„3Dæ·±åº¦å­¦ä¹ å’Œç”ŸæˆAIæ•°æ®é›†ï¼Œåä¸ºUncommon Objects in 3Dï¼ˆuCO3Dï¼‰ã€‚uCO3Dæ˜¯ä¸€ä¸ªå…¬å¼€å¯ç”¨çš„é«˜åˆ†è¾¨ç‡è§†é¢‘é›†åˆï¼ŒåŒ…å«360åº¦çš„3Dæ³¨é‡Šï¼Œæ¶µç›–è¶…è¿‡1000ä¸ªç‰©ä½“ç±»åˆ«ï¼Œå…·æœ‰æ›´é«˜çš„å¤šæ ·æ€§å’Œè´¨é‡ã€‚è¯¥æ•°æ®é›†æä¾›äº†3Dç›¸æœºå§¿æ€ã€æ·±åº¦å›¾å’Œç¨€ç–ç‚¹äº‘çš„æ³¨é‡Šï¼Œå¹¶ä¸ºæ¯ä¸ªç‰©ä½“é…å¤‡äº†æè¿°å’Œ3Dé«˜æ–¯ç‚¹äº‘é‡å»ºã€‚é€šè¿‡åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒå¤§å‹3Dæ¨¡å‹ï¼Œæˆ‘ä»¬å‘ç°uCO3Dåœ¨å­¦ä¹ åº”ç”¨ä¸­è¡¨ç°æ›´ä¼˜ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.07171",
            "title": "BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature",
            "url": "https://huggingface.co/papers/2501.07171",
            "abstract": "The development of vision-language models (VLMs) is driven by large-scale and diverse multimodal datasets. However, progress toward generalist biomedical VLMs is limited by the lack of annotated, publicly accessible datasets across biology and medicine. Existing efforts are restricted to narrow domains, missing the full diversity of biomedical knowledge encoded in scientific literature. To address this gap, we introduce BIOMEDICA, a scalable, open-source framework to extract, annotate, and serialize the entirety of the PubMed Central Open Access subset into an easy-to-use, publicly accessible dataset.Our framework produces a comprehensive archive with over 24 million unique image-text pairs from over 6 million articles. Metadata and expert-guided annotations are also provided. We demonstrate the utility and accessibility of our resource by releasing BMCA-CLIP, a suite of CLIP-style models continuously pre-trained on the BIOMEDICA dataset via streaming, eliminating the need to download 27 TB of data locally.On average, our models achieve state-of-the-art performance across 40 tasks - spanning pathology, radiology, ophthalmology, dermatology, surgery, molecular biology, parasitology, and cell biology - excelling in zero-shot classification with a 6.56% average improvement (as high as 29.8% and 17.5% in dermatology and ophthalmology, respectively), and stronger image-text retrieval, all while using 10x less compute. To foster reproducibility and collaboration, we release our codebase and dataset for the broader research community.",
            "score": 3,
            "issue_id": 1656,
            "pub_date": "2025-01-13",
            "pub_date_card": {
                "ru": "13 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 13",
                "zh": "1æœˆ13æ—¥"
            },
            "hash": "07db2230e08b0fde",
            "authors": [
                "Alejandro Lozano",
                "Min Woo Sun",
                "James Burgess",
                "Liangyu Chen",
                "Jeffrey J Nirschl",
                "Jeffrey Gu",
                "Ivan Lopez",
                "Josiah Aklilu",
                "Austin Wolfgang Katzer",
                "Collin Chiu",
                "Anita Rau",
                "Xiaohan Wang",
                "Yuhui Zhang",
                "Alfred Seunghoon Song",
                "Robert Tibshirani",
                "Serena Yeung-Levy"
            ],
            "affiliations": [
                "Department of Biomedical Data Science, Stanford University",
                "Department of Computer Science, Stanford University",
                "Department of Electrical Engineering, Stanford University",
                "Department of Pathology, Stanford University",
                "Department of Statistics, Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.07171.jpg",
            "data": {
                "categories": [
                    "#healthcare",
                    "#cv",
                    "#dataset",
                    "#science",
                    "#multimodal",
                    "#open_source"
                ],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "BIOMEDICA: ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ±Ğ¸Ğ¾Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ BIOMEDICA - Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ´Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¸Ğ¾Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ» Ğ¾Ğ±ÑˆĞ¸Ñ€Ğ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ğ² Ğ¸Ğ· Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ 24 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ² ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ°Ñ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ-Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ±Ğ¾Ğ»ĞµĞµ 6 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ² ÑÑ‚Ğ°Ñ‚ĞµĞ¹. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ±Ñ‹Ğ»Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ BMCA-CLIP, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³ÑˆĞ¸Ğµ state-of-the-art Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² 40 Ğ±Ğ¸Ğ¾Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ² zero-shot ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ² 10 Ñ€Ğ°Ğ· Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²."
                },
                "en": {
                    "title": "Unlocking Biomedical Knowledge with BIOMEDICA",
                    "desc": "This paper presents BIOMEDICA, a new framework designed to create a large, open-source dataset from the PubMed Central Open Access subset, which includes over 24 million image-text pairs from scientific articles. The framework addresses the challenge of limited annotated datasets in the biomedical field, enabling the development of generalist vision-language models (VLMs) that can understand diverse biomedical knowledge. The authors also introduce BMCA-CLIP, a set of models that are continuously pre-trained on this dataset, achieving state-of-the-art performance across various medical tasks with significant improvements in zero-shot classification and image-text retrieval. By making their codebase and dataset publicly available, they aim to enhance reproducibility and collaboration in biomedical research."
                },
                "zh": {
                    "title": "æ¨åŠ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„è§†è§‰è¯­è¨€æ¨¡å‹å‘å±•",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†BIOMEDICAï¼Œä¸€ä¸ªå¯æ‰©å±•çš„å¼€æºæ¡†æ¶ï¼Œç”¨äºæå–ã€æ³¨é‡Šå’Œåºåˆ—åŒ–PubMed Centralå¼€æ”¾è·å–å­é›†çš„å…¨éƒ¨å†…å®¹ã€‚è¯¥æ¡†æ¶ç”Ÿæˆäº†ä¸€ä¸ªåŒ…å«è¶…è¿‡2400ä¸‡ä¸ªç‹¬ç‰¹å›¾åƒ-æ–‡æœ¬å¯¹çš„ç»¼åˆæ¡£æ¡ˆï¼Œæ¥è‡ªè¶…è¿‡600ä¸‡ç¯‡æ–‡ç« ã€‚æˆ‘ä»¬è¿˜æä¾›äº†å…ƒæ•°æ®å’Œä¸“å®¶æŒ‡å¯¼çš„æ³¨é‡Šï¼Œå¹¶å±•ç¤ºäº†BMCA-CLIPæ¨¡å‹åœ¨40ä¸ªåŒ»å­¦ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§èƒ½ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬åˆ†ç±»å’Œå›¾åƒ-æ–‡æœ¬æ£€ç´¢æ–¹é¢è¡¨ç°çªå‡ºã€‚é€šè¿‡å‘å¸ƒä»£ç åº“å’Œæ•°æ®é›†ï¼Œæˆ‘ä»¬ä¿ƒè¿›äº†ç ”ç©¶çš„å¯é‡å¤æ€§å’Œåˆä½œã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06590",
            "title": "ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning",
            "url": "https://huggingface.co/papers/2501.06590",
            "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found at https://github.com/gersteinlab/chemagent",
            "score": 3,
            "issue_id": 1651,
            "pub_date": "2025-01-11",
            "pub_date_card": {
                "ru": "11 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 11",
                "zh": "1æœˆ11æ—¥"
            },
            "hash": "c217e826245ef357",
            "authors": [
                "Xiangru Tang",
                "Tianyu Hu",
                "Muyang Ye",
                "Yanjun Shao",
                "Xunjian Yin",
                "Siru Ouyang",
                "Wangchunshu Zhou",
                "Pan Lu",
                "Zhuosheng Zhang",
                "Yilun Zhao",
                "Arman Cohan",
                "Mark Gerstein"
            ],
            "affiliations": [
                "Shanghai Jiao Tong University",
                "Stanford University",
                "UIUC",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06590.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#reasoning",
                    "#multimodal",
                    "#agents",
                    "#dataset"
                ],
                "emoji": "ğŸ§ª",
                "ru": {
                    "title": "ChemAgent: Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ´Ğ»Ñ LLM Ğ² Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…",
                    "desc": "ChemAgent - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ÑƒÑ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºÑƒ, ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½ÑƒÑ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. ĞŸÑ€Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ ChemAgent Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¸ ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ğ´ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸, ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ğ² Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ LLM Ğ´Ğ¾ 46% Ğ½Ğ° Ñ‡ĞµÑ‚Ñ‹Ñ€ĞµÑ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Empowering LLMs for Chemical Reasoning with ChemAgent",
                    "desc": "This paper introduces ChemAgent, a new framework that enhances large language models (LLMs) for chemical reasoning tasks. It addresses the challenges LLMs face with complex chemical calculations and domain-specific formulas by creating a dynamic library of decomposed sub-tasks. ChemAgent retrieves and refines relevant information from this library, allowing for better task decomposition and solution generation. Experimental results show that ChemAgent significantly improves performance on chemical reasoning datasets, indicating its potential for applications in drug discovery and materials science."
                },
                "zh": {
                    "title": "ChemAgentï¼šæå‡åŒ–å­¦æ¨ç†çš„æ™ºèƒ½åŠ©æ‰‹",
                    "desc": "åŒ–å­¦æ¨ç†é€šå¸¸æ¶‰åŠå¤æ‚çš„å¤šæ­¥éª¤è¿‡ç¨‹ï¼Œéœ€è¦ç²¾ç¡®çš„è®¡ç®—ï¼Œå“ªæ€•æ˜¯å¾®å°çš„é”™è¯¯ä¹Ÿå¯èƒ½å¯¼è‡´ä¸¥é‡çš„åæœã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†ç‰¹å®šé¢†åŸŸçš„å…¬å¼ã€å‡†ç¡®æ‰§è¡Œæ¨ç†æ­¥éª¤å’Œæœ‰æ•ˆæ•´åˆä»£ç æ—¶é¢ä¸´å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ChemAgentï¼Œä¸€ä¸ªé€šè¿‡åŠ¨æ€è‡ªæ›´æ–°åº“æ¥æå‡LLMsæ€§èƒ½çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†åŒ–å­¦ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œå¹¶å°†è¿™äº›å­ä»»åŠ¡ç¼–è¯‘æˆç»“æ„åŒ–çš„é›†åˆï¼Œä»¥ä¾¿åœ¨æœªæ¥æŸ¥è¯¢æ—¶å‚è€ƒï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„ä»»åŠ¡åˆ†è§£å’Œè§£å†³æ–¹æ¡ˆç”Ÿæˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.06708",
            "title": "Evaluating Sample Utility for Data Selection by Mimicking Model Weights",
            "url": "https://huggingface.co/papers/2501.06708",
            "abstract": "Foundation models rely on large-scale web-crawled datasets, which frequently contain noisy data, biases, and irrelevant content. Existing data selection techniques typically use human heuristics, downstream evaluation datasets, or specialized scoring models, and can overlook samples' utility in the training process. Instead, we propose a new approach, Mimic Score, a data quality metric that uses a pretrained reference model as a guide to assess the usefulness of data samples for training a new model. It relies on the alignment between the gradient of the new model parameters and the vector pointing toward the reference model in weight space. Samples that misalign with this direction are considered low-value and can be filtered out. Motivated by the Mimic score, we develop Grad-Mimic, a data selection framework that identifies and prioritizes useful samples, automating the selection process to create effective filters. Empirically, using Mimic scores to guide model training results in consistent performance gains across six image datasets and enhances the performance of CLIP models. Moreover, Mimic scores and their associated filters improve upon existing filtering methods and offer accurate estimation of dataset quality.",
            "score": 2,
            "issue_id": 1661,
            "pub_date": "2025-01-12",
            "pub_date_card": {
                "ru": "12 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 12",
                "zh": "1æœˆ12æ—¥"
            },
            "hash": "7560c17a0e1b7234",
            "authors": [
                "Tzu-Heng Huang",
                "Manjot Bilkhu",
                "Frederic Sala",
                "Javier Movellan"
            ],
            "affiliations": [
                "Apple Inc.",
                "University of Wisconsin-Madison"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.06708.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#optimization",
                    "#dataset",
                    "#ethics",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ - Mimic Score. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼, ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¼ Ğ½Ğ° ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ Ğ²ĞµÑĞ¾Ğ². ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Mimic Score Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Grad-Mimic Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ñ… Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Mimic Score Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ CLIP."
                },
                "en": {
                    "title": "Enhancing Data Selection with Mimic Score for Better Model Training",
                    "desc": "This paper introduces a new method called Mimic Score to improve data selection for training foundation models. It uses a pretrained reference model to evaluate the usefulness of data samples by analyzing the alignment of gradients in weight space. Samples that do not align well with the reference model are deemed low-value and can be removed from the training dataset. The proposed Grad-Mimic framework automates this selection process, leading to better model performance across various image datasets and outperforming existing data filtering techniques."
                },
                "zh": {
                    "title": "Mimic Scoreï¼šæå‡æ•°æ®é€‰æ‹©çš„æ–°æ–¹æ³•",
                    "desc": "åŸºç¡€æ¨¡å‹ä¾èµ–äºå¤§è§„æ¨¡çš„ç½‘ç»œçˆ¬å–æ•°æ®é›†ï¼Œè¿™äº›æ•°æ®é›†å¸¸å¸¸åŒ…å«å™ªå£°æ•°æ®ã€åè§å’Œæ— å…³å†…å®¹ã€‚ç°æœ‰çš„æ•°æ®é€‰æ‹©æŠ€æœ¯é€šå¸¸ä½¿ç”¨äººå·¥å¯å‘å¼æ–¹æ³•ã€ä¸‹æ¸¸è¯„ä¼°æ•°æ®é›†æˆ–ä¸“é—¨çš„è¯„åˆ†æ¨¡å‹ï¼Œå¯èƒ½ä¼šå¿½è§†æ ·æœ¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç§°ä¸ºMimic Scoreï¼Œè¿™æ˜¯ä¸€ç§æ•°æ®è´¨é‡æŒ‡æ ‡ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å‚è€ƒæ¨¡å‹æ¥è¯„ä¼°æ•°æ®æ ·æœ¬å¯¹æ–°æ¨¡å‹è®­ç»ƒçš„æœ‰ç”¨æ€§ã€‚åŸºäºMimic Scoreï¼Œæˆ‘ä»¬å¼€å‘äº†Grad-Mimicæ•°æ®é€‰æ‹©æ¡†æ¶ï¼Œè‡ªåŠ¨è¯†åˆ«å’Œä¼˜å…ˆé€‰æ‹©æœ‰ç”¨æ ·æœ¬ï¼Œä»è€Œæé«˜æ¨¡å‹è®­ç»ƒçš„æ•ˆæœã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-01-13.html",
    "link_next": "2025-01-15.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "13.01",
        "en": "01/13",
        "zh": "1æœˆ13æ—¥"
    },
    "short_date_next": {
        "ru": "15.01",
        "en": "01/15",
        "zh": "1æœˆ15æ—¥"
    },
    "categories": {
        "#dataset": 5,
        "#data": 2,
        "#benchmark": 3,
        "#agents": 2,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 1,
        "#plp": 0,
        "#inference": 2,
        "#3d": 1,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 5,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 2,
        "#training": 6,
        "#robotics": 0,
        "#agi": 2,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 4,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 6,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 1,
        "#hallucinations": 0,
        "#long_context": 2,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 3,
        "#small_models": 0,
        "#science": 3,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå«åšè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦æ¨ç†ä¸­çš„è¿‡ç¨‹ç›‘ç£ã€‚ç›®æ ‡æ˜¯è¯†åˆ«å’Œå‡å°‘æ¨ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ã€‚ç ”ç©¶å‘ç°ï¼Œå¸¸ç”¨çš„è’™ç‰¹å¡ç½—ï¼ˆMCï¼‰ä¼°è®¡æ–¹æ³•æ•ˆæœä¸ä½³ï¼Œå› ä¸ºå®ƒä¾èµ–å®Œæˆæ¨¡å‹è¯„ä¼°å½“å‰æ­¥éª¤çš„æ­£ç¡®æ€§ï¼Œå¯¼è‡´æ­¥éª¤éªŒè¯ä¸å‡†ç¡®ã€‚æ–‡ç« è¿˜æŒ‡å‡ºäº†ä¼ ç»ŸBest-of-Nï¼ˆBoNï¼‰è¯„ä¼°ç­–ç•¥çš„åå·®ï¼Œå¹¶æå‡ºäº†ä¸€ç§å…±è¯†è¿‡æ»¤æœºåˆ¶ï¼Œç»“åˆMCä¼°è®¡å’ŒLLM-as-a-judgeï¼Œæ”¹è¿›äº†æ¨¡å‹æ€§èƒ½å’Œæ•°æ®æ•ˆç‡ã€‚æœ€åï¼Œæ–‡ç« å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„æœ€å…ˆè¿›çš„PRMï¼Œå¹¶æä¾›äº†æœªæ¥ç ”ç©¶çš„å®ç”¨æŒ‡å—ã€‚",
        "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå«åšè¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦æ¨ç†ä¸­çš„è¿‡ç¨‹ç›‘ç£ã€‚ç›®æ ‡æ˜¯è¯†åˆ«å’Œå‡å°‘æ¨ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ã€‚ç ”ç©¶å‘ç°ï¼Œå¸¸ç”¨çš„è’™ç‰¹å¡ç½—ï¼ˆMCï¼‰ä¼°è®¡æ–¹æ³•æ•ˆæœä¸ä½³ï¼Œå› ä¸ºå®ƒä¾èµ–å®Œæˆæ¨¡å‹è¯„ä¼°å½“å‰æ­¥éª¤çš„æ­£ç¡®æ€§ï¼Œå¯¼è‡´æ­¥éª¤éªŒè¯ä¸å‡†ç¡®ã€‚æ–‡ç« è¿˜æŒ‡å‡ºäº†ä¼ ç»ŸBest-of-Nï¼ˆBoNï¼‰è¯„ä¼°ç­–ç•¥çš„åå·®ï¼Œå¹¶æå‡ºäº†ä¸€ç§å…±è¯†è¿‡æ»¤æœºåˆ¶ï¼Œç»“åˆMCä¼°è®¡å’ŒLLM-as-a-judgeï¼Œæ”¹è¿›äº†æ¨¡å‹æ€§èƒ½å’Œæ•°æ®æ•ˆç‡ã€‚æœ€åï¼Œæ–‡ç« å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„æœ€å…ˆè¿›çš„PRMï¼Œå¹¶æä¾›äº†æœªæ¥ç ”ç©¶çš„å®ç”¨æŒ‡å—ã€‚\n\nzhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le yÄ« zhÇ’ng xÄ«n de fÄngfÇ, jiÃ ozuÃ² guÃ²chÃ©ng jiÇnglÃ¬ mÃ³xÃ­ng (PRMs), yÃ²ngyÃº dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng (LLMs) zÃ i shÃ¹xuÃ© tuÄ«lÇ zhÅng de guÃ²chÃ©ng jiÃ ndÅ«. MÃ¹biÄo shÃ¬ shÃ­biÃ© hÃ© jiÇnshÇo tuÄ«lÇ guÃ²chÃ©ng zhÅng de cuÃ²wÃ¹. YÃ¡njiÅ« fÄxiÃ n, chÃ¡ngyÃ²ng de mÃ©ngtÃ¨kÇluÃ³ (MC) gÅ«jÃ¬ fÄngfÇ xiÃ ojiÃ , yÄ«nwÃ¨i tÄ yÄ«lÃ i wÃ¡nchÃ©ng mÃ³xÃ­ng pÃ­ngjiÃ  dÄngqiÃ¡n bÃ¹zhÃ²u de zhÃ¨ngquÃ¨xÃ¬ng, dÇozhÃ¬ bÃ¹zhÃ²u yÃ nzhÃ¨ng bÃ¹ zhÇ”nquÃ¨. WÃ©nzhÄng hÃ¡i zhÇchÅ« le chuÃ¡ntÇ’ng Best-of-N (BoN) pÃ­ngjiÃ  cÃ¨lÃ¼Ã¨ de piÄnchÄ, bÃ¬ng tÃ­chÅ« le yÄ« zhÇ’ng gÃ²ngshÃ¬ guÃ²lÇœ jÄ«zhÃ¬, jiÃ©hÃ© MC gÅ«jÃ¬ hÃ© LLM-as-a-judge, gÇijÃ¬n le mÃ³xÃ­ng xÃ¬ngnÃ©ng hÃ© shÃ¹jÃ¹ xiÃ oyÃ²ng. ZuÃ¬hÃ²u, wÃ©nzhÄng fÄbÃ¹ le yÄ«gÃ¨ xÄ«n de zuÃ¬ xiÄnjÃ¬n de PRM, bÃ¬ng tÃ­gÅng le wÃ¨ilÃ¡i yÃ¡njiÅ« de shÃ­yÃ²ng zhÇnÃ¡n.",
        "vocab": "[\n    {\"word\": \"è¿‡ç¨‹å¥–åŠ±æ¨¡å‹\", \"pinyin\": \"guÃ²chÃ©ng jiÇnglÃ¬ mÃ³xÃ­ng\", \"trans\": \"Process Reward Model\"},\n    {\"word\": \"å¤§å‹è¯­è¨€æ¨¡å‹\", \"pinyin\": \"dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng\", \"trans\": \"Large Language Model\"},\n    {\"word\": \"æ•°å­¦æ¨ç†\", \"pinyin\": \"shÃ¹xuÃ© tuÄ«lÇ\", \"trans\": \"Mathematical Reasoning\"},\n    {\"word\": \"è¿‡ç¨‹ç›‘ç£\", \"pinyin\": \"guÃ²chÃ©ng jiÃ ndÅ«\", \"trans\": \"Process Supervision\"},\n    {\"word\": \"è’™ç‰¹å¡ç½—\", \"pinyin\": \"mÃ©ngtÃ¨kÇluÃ³\", \"trans\": \"Monte Carlo\"},\n    {\"word\": \"ä¼°è®¡\", \"pinyin\": \"gÅ«jÃ¬\", \"trans\": \"Estimation\"},\n    {\"word\": \"ä¾èµ–\", \"pinyin\": \"yÄ«lÃ i\", \"trans\": \"Depend\"},\n    {\"word\": \"è¯„ä¼°\", \"pinyin\": \"pÃ­nggÅ«\", \"trans\": \"Evaluate\"},\n    {\"word\": \"æ­¥éª¤éªŒè¯\", \"pinyin\": \"bÃ¹zhÃ²u yÃ nzhÃ¨ng\", \"trans\": \"Step Verification\"},\n    {\"word\": \"åå·®\", \"pinyin\": \"piÄnchÄ\", \"trans\": \"Bias\"},\n    {\"word\": \"å…±è¯†è¿‡æ»¤æœºåˆ¶\", \"pinyin\": \"gÃ²ngshÃ­ guÃ²lÇœ jÄ«zhÃ¬\", \"trans\": \"Consensus Filtering Mechanism\"},\n    {\"word\": \"LLM-as-a-judge\", \"pinyin\": \"LLM-as-a-judge\", \"trans\": \"LLM-as-a-judge\"},\n    {\"word\": \"æœ€å…ˆè¿›\", \"pinyin\": \"zuÃ¬xiÄnjÃ¬n\", \"trans\": \"State-of-the-art\"},\n    {\"word\": \"å®ç”¨æŒ‡å—\", \"pinyin\": \"shÃ­yÃ²ng zhÇnÃ¡n\", \"trans\": \"Practical Guide\"}\n]",
        "trans": "This article introduces a new method called Process Reward Models (PRMs) for process supervision of large language models (LLMs) in mathematical reasoning. The goal is to identify and reduce errors in the reasoning process. The research found that the commonly used Monte Carlo (MC) estimation method performs poorly because it relies on the completion model to evaluate the correctness of the current step, leading to inaccurate step verification. The article also points out the bias in traditional Best-of-N (BoN) evaluation strategies and proposes a consensus filtering mechanism that combines MC estimation and LLM-as-a-judge to improve model performance and data efficiency. Finally, the article releases a new state-of-the-art PRM and provides practical guidelines for future research.",
        "update_ts": "2025-01-14 09:10"
    }
}