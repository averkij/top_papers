{
    "date": {
        "ru": "29 августа",
        "en": "August 29",
        "zh": "8月29日"
    },
    "time_utc": "2025-08-29 02:22",
    "weekday": 4,
    "issue_id": 5608,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2508.20722",
            "title": "rStar2-Agent: Agentic Reasoning Technical Report",
            "url": "https://huggingface.co/papers/2508.20722",
            "abstract": "rStar2-Agent, a 14B math reasoning model trained with agentic reinforcement learning, achieves state-of-the-art performance by efficiently handling complex problem-solving with advanced cognitive behaviors and minimal computational resources.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce rStar2-Agent, a 14B math reasoning model trained with agentic reinforcement learning to achieve frontier-level performance. Beyond current long CoT, the model demonstrates advanced cognitive behaviors, such as thinking carefully before using Python coding tools and reflecting on code execution feedback to autonomously explore, verify, and refine intermediate steps in complex problem-solving. This capability is enabled through three key innovations that makes agentic RL effective at scale: (i) an efficient RL infrastructure with a reliable Python code environment that supports high-throughput execution and mitigates the high rollout costs, enabling training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic RL algorithm with a Resample-on-Correct rollout strategy that addresses the inherent environment noises from coding tools, allowing the model to reason more effectively in a code environment; (iii) An efficient agent training recipe that starts with non-reasoning SFT and progresses through multi-RL stages, yielding advanced cognitive abilities with minimal compute cost. To this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates strong generalization to alignment, scientific reasoning, and agentic tool-use tasks. Code and training recipes are available at https://github.com/microsoft/rStar.",
            "score": 11,
            "issue_id": 5608,
            "pub_date": "2025-08-28",
            "pub_date_card": {
                "ru": "28 августа",
                "en": "August 28",
                "zh": "8月28日"
            },
            "hash": "4e0a26cb3998d9dd",
            "authors": [
                "Ning Shang",
                "Yifei Liu",
                "Yi Zhu",
                "Li Lyna Zhang",
                "Weijiang Xu",
                "Xinyu Guan",
                "Buze Zhang",
                "Bingcheng Dong",
                "Xudong Zhou",
                "Bowen Zhang",
                "Ying Xin",
                "Ziming Miao",
                "Scarlett Li",
                "Fan Yang",
                "Mao Yang"
            ],
            "affiliations": [
                "Microsoft"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.20722.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#agents",
                    "#alignment",
                    "#optimization",
                    "#rlhf",
                    "#science"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Агентное RL создает математического гения с минимальными ресурсами",
                    "desc": "rStar2-Agent - это модель машинного обучения с 14 миллиардами параметров, обученная с помощью агентного обучения с подкреплением для решения математических задач. Модель демонстрирует продвинутое когнитивное поведение, включая использование инструментов Python и анализ обратной связи от выполнения кода. Ключевые инновации включают эффективную инфраструктуру RL, алгоритм GRPO-RoC и эффективный рецепт обучения агента. rStar2-Agent достигает наилучших результатов на ряде математических тестов, превосходя более крупные модели."
                },
                "en": {
                    "title": "Revolutionizing Math Reasoning with rStar2-Agent!",
                    "desc": "The rStar2-Agent is a 14 billion parameter model designed for advanced math reasoning, utilizing agentic reinforcement learning to achieve top performance. It showcases sophisticated cognitive behaviors, such as careful consideration before executing Python code and self-reflection on code outcomes to enhance problem-solving. Key innovations include a robust RL infrastructure that minimizes computational costs, a novel GRPO-RoC algorithm that improves reasoning in coding environments, and a structured training approach that builds cognitive skills efficiently. This model not only excels in mathematical tasks but also generalizes well to other domains like alignment and scientific reasoning."
                },
                "zh": {
                    "title": "rStar2-Agent：高效的数学推理与认知能力",
                    "desc": "rStar2-Agent是一种14B的数学推理模型，采用代理强化学习进行训练，能够高效处理复杂问题，表现出色。该模型具备先进的认知行为，例如在使用Python编码工具前仔细思考，并根据代码执行反馈进行反思，从而自主探索和验证中间步骤。其成功得益于三项关键创新，包括高效的RL基础设施、GRPO-RoC算法和高效的代理训练方案，使得在有限的计算资源下也能实现卓越性能。rStar2-Agent在仅用510个RL步骤内，便在AIME24和AIME25上取得了80.6%和69.8%的平均通过率，超越了更大模型DeepSeek-R1。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.21058",
            "title": "Mixture of Contexts for Long Video Generation",
            "url": "https://huggingface.co/papers/2508.21058",
            "abstract": "Long video generation is addressed by introducing a sparse attention routing module, Mixture of Contexts, to efficiently manage long-term memory and retrieval in diffusion transformers.  \t\t\t\t\tAI-generated summary \t\t\t\t Long video generation is fundamentally a long context memory problem: models must retain and retrieve salient events across a long range without collapsing or drifting. However, scaling diffusion transformers to generate long-context videos is fundamentally limited by the quadratic cost of self-attention, which makes memory and computation intractable and difficult to optimize for long sequences. We recast long-context video generation as an internal information retrieval task and propose a simple, learnable sparse attention routing module, Mixture of Contexts (MoC), as an effective long-term memory retrieval engine. In MoC, each query dynamically selects a few informative chunks plus mandatory anchors (caption, local windows) to attend to, with causal routing that prevents loop closures. As we scale the data and gradually sparsify the routing, the model allocates compute to salient history, preserving identities, actions, and scenes over minutes of content. Efficiency follows as a byproduct of retrieval (near-linear scaling), which enables practical training and synthesis, and the emergence of memory and consistency at the scale of minutes.",
            "score": 2,
            "issue_id": 5608,
            "pub_date": "2025-08-28",
            "pub_date_card": {
                "ru": "28 августа",
                "en": "August 28",
                "zh": "8月28日"
            },
            "hash": "b61607b2a4b6bc58",
            "authors": [
                "Shengqu Cai",
                "Ceyuan Yang",
                "Lvmin Zhang",
                "Yuwei Guo",
                "Junfei Xiao",
                "Ziyan Yang",
                "Yinghao Xu",
                "Zhenheng Yang",
                "Alan Yuille",
                "Leonidas Guibas",
                "Maneesh Agrawala",
                "Lu Jiang",
                "Gordon Wetzstein"
            ],
            "affiliations": [
                "ByteDance",
                "ByteDance Seed",
                "CUHK",
                "Johns Hopkins University",
                "Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.21058.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#diffusion",
                    "#video",
                    "#long_context",
                    "#multimodal"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "Эффективная генерация длинных видео с помощью разреженного внимания",
                    "desc": "Эта статья представляет новый метод для генерации длинных видео с использованием разреженного внимания в диффузионных трансформерах. Авторы предлагают модуль Mixture of Contexts (MoC), который эффективно управляет долговременной памятью и извлечением информации. MoC динамически выбирает наиболее информативные фрагменты для обработки, что позволяет сохранять согласованность на протяжении нескольких минут видео. Этот подход решает проблему квадратичной сложности самовнимания и делает возможным практическое обучение и синтез длинных видео."
                },
                "en": {
                    "title": "Efficient Long Video Generation with Sparse Attention",
                    "desc": "This paper presents a new approach to generating long videos using a method called Mixture of Contexts (MoC), which enhances the efficiency of memory retrieval in diffusion transformers. The challenge of long video generation lies in managing long-term memory to retain important events without losing coherence. MoC addresses this by allowing the model to focus on a few key segments of information while maintaining essential context, thus optimizing the use of computational resources. As a result, this method not only improves the model's ability to generate consistent and coherent long videos but also makes the training process more efficient."
                },
                "zh": {
                    "title": "高效生成长视频的记忆检索新方法",
                    "desc": "本文提出了一种稀疏注意力路由模块，称为上下文混合（Mixture of Contexts, MoC），用于高效管理扩散变换器中的长期记忆和检索，以生成长视频。长视频生成本质上是一个长期上下文记忆问题，模型需要在长时间范围内保留和检索重要事件。传统的自注意力机制在处理长序列时计算成本呈二次增长，导致内存和计算变得难以优化。MoC模块通过动态选择信息丰富的片段和必要的锚点，提供了一种有效的长期记忆检索引擎，从而提高了生成长视频的效率和一致性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.20453",
            "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World\n  Tasks via MCP Servers",
            "url": "https://huggingface.co/papers/2508.20453",
            "abstract": "MCP-Bench evaluates large language models on complex, multi-step tasks requiring tool use, coordination, and planning across various domains.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce MCP-Bench, a benchmark for evaluating large language models (LLMs) on realistic, multi-step tasks that demand tool use, cross-tool coordination, precise parameter control, and planning/reasoning for solving tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28 representative live MCP servers spanning 250 tools across domains such as finance, traveling, scientific computing, and academic search. Unlike prior API-based benchmarks, each MCP server provides a set of complementary tools designed to work together, enabling the construction of authentic, multi-step tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability to retrieve relevant tools from fuzzy instructions without explicit tool names, plan multi-hop execution trajectories for complex objectives, ground responses in intermediate tool outputs, and orchestrate cross-domain workflows - capabilities not adequately evaluated by existing benchmarks that rely on explicit tool specifications, shallow few-step workflows, and isolated domain operations. We propose a multi-faceted evaluation framework covering tool-level schema understanding and usage, trajectory-level planning, and task completion. Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code and data: https://github.com/Accenture/mcp-bench.",
            "score": 2,
            "issue_id": 5608,
            "pub_date": "2025-08-28",
            "pub_date_card": {
                "ru": "28 августа",
                "en": "August 28",
                "zh": "8月28日"
            },
            "hash": "dcd0de7d4f5a0eee",
            "authors": [
                "Zhenting Wang",
                "Qi Chang",
                "Hemani Patel",
                "Shashank Biju",
                "Cheng-En Wu",
                "Quan Liu",
                "Aolin Ding",
                "Alireza Rezazadeh",
                "Ankit Shah",
                "Yujia Bao",
                "Eugene Siow"
            ],
            "affiliations": [
                "Center for Advanced AI, Accenture",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.20453.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#benchmark",
                    "#agents"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "MCP-Bench: Новый рубеж в оценке многозадачных языковых моделей",
                    "desc": "MCP-Bench - это новый бенчмарк для оценки больших языковых моделей (LLM) на сложных многоэтапных задачах, требующих использования инструментов и планирования в различных областях. Он включает 28 серверов MCP с 250 инструментами в таких сферах как финансы, путешествия, научные вычисления и академический поиск. MCP-Bench оценивает способность моделей извлекать релевантные инструменты из нечетких инструкций, планировать многоэтапные траектории выполнения и координировать рабочие процессы между различными доменами. Эксперименты на 20 продвинутых LLM выявили устойчивые проблемы в решении задач MCP-Bench."
                },
                "en": {
                    "title": "MCP-Bench: Evaluating LLMs on Complex Multi-Step Tasks",
                    "desc": "MCP-Bench is a new benchmark designed to assess large language models (LLMs) on complex tasks that require the use of multiple tools and careful planning. It connects LLMs to a variety of live servers that provide complementary tools across different domains, allowing for realistic multi-step task execution. The benchmark evaluates the models' abilities to understand fuzzy instructions, plan execution paths, and coordinate workflows across different domains. Results from testing 20 advanced LLMs show that there are still significant challenges in effectively completing these complex tasks."
                },
                "zh": {
                    "title": "评估大型语言模型的多步骤任务能力",
                    "desc": "MCP-Bench是一个用于评估大型语言模型（LLMs）的基准，专注于复杂的多步骤任务，这些任务需要工具使用、跨工具协调和规划能力。该基准基于模型上下文协议（MCP），连接到28个代表性的MCP服务器，涵盖250种工具，涉及金融、旅行、科学计算和学术搜索等多个领域。与以往的API基准不同，MCP服务器提供了一组互补工具，能够构建真实的多步骤任务，测试模型在模糊指令下检索相关工具的能力。实验表明，当前的LLMs在MCP-Bench中面临持续的挑战，特别是在工具理解、规划和任务完成方面。"
                }
            }
        }
    ],
    "link_prev": "2025-08-28.html",
    "link_next": "2025-09-01.html",
    "link_month": "2025-08.html",
    "short_date_prev": {
        "ru": "28.08",
        "en": "08/28",
        "zh": "8月28日"
    },
    "short_date_next": {
        "ru": "01.09",
        "en": "09/01",
        "zh": "9月1日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 2,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    }
}