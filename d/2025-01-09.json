{
    "date": {
        "ru": "9 ÑĞ½Ğ²Ğ°Ñ€Ñ",
        "en": "January 9",
        "zh": "1æœˆ9æ—¥"
    },
    "time_utc": "2025-01-09 19:07",
    "weekday": 3,
    "issue_id": 1588,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2501.04519",
            "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
            "url": "https://huggingface.co/papers/2501.04519",
            "abstract": "We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising \"deep thinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\\"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels. On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% the brightest high school math students. Code and data will be available at https://github.com/microsoft/rStar.",
            "score": 92,
            "issue_id": 1572,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "b065003de5fa3bde",
            "authors": [
                "Xinyu Guan",
                "Li Lyna Zhang",
                "Yifei Liu",
                "Ning Shang",
                "Youran Sun",
                "Yi Zhu",
                "Fan Yang",
                "Mao Yang"
            ],
            "affiliations": [
                "Microsoft",
                "Peking University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04519.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#optimization",
                    "#benchmark",
                    "#small_models",
                    "#dataset"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "ĞœĞ°Ğ»Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€ĞµÑˆĞ°ÑÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸: rStar-Math Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ³Ğ¸Ğ³Ğ°Ğ½Ñ‚Ğ¾Ğ² Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ rStar-Math - Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğ¹ Ğ¼Ğ°Ğ»Ñ‹Ğ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ (SLM) Ğ´Ğ¾ÑÑ‚Ğ¸Ñ‡ÑŒ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾Ğ¹Ñ‚Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ…. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñƒ ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾ (MCTS) Ñ Ğ´Ğ²ÑƒĞ¼Ñ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ SLM: Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¾Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ’ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ rStar-Math Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ SLM Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Empowering Small Models to Excel in Math Reasoning",
                    "desc": "The paper introduces rStar-Math, a framework that enhances the math reasoning abilities of small language models (SLMs) without relying on larger models. It employs Monte Carlo Tree Search (MCTS) to enable deep thinking, allowing the SLM to perform guided search during problem-solving. Key innovations include a code-augmented Chain of Thought (CoT) data synthesis method for generating verified reasoning paths, a refined process preference model (PPM) for better reward training, and a self-evolution strategy for iterative improvement. As a result, rStar-Math significantly boosts the performance of SLMs on math benchmarks, achieving state-of-the-art results in various assessments."
                },
                "zh": {
                    "title": "å°å‹è¯­è¨€æ¨¡å‹çš„æ•°å­¦æ¨ç†æ–°çªç ´",
                    "desc": "rStar-Mathå±•ç¤ºäº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨æ•°å­¦æ¨ç†èƒ½åŠ›ä¸Šå¯ä»¥ä¸OpenAIçš„o1ç›¸åª²ç¾ï¼Œç”šè‡³è¶…è¶Šå®ƒï¼Œè€Œæ— éœ€ä»æ›´å¼ºå¤§çš„æ¨¡å‹ä¸­è’¸é¦ã€‚è¯¥æ–¹æ³•é€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å®ç°â€œæ·±åº¦æ€è€ƒâ€ï¼Œåœ¨æµ‹è¯•æ—¶ç”±SLMé©±åŠ¨çš„è¿‡ç¨‹å¥–åŠ±æ¨¡å‹æŒ‡å¯¼æ•°å­¦ç­–ç•¥SLMè¿›è¡Œæœç´¢ã€‚rStar-Mathå¼•å…¥äº†ä¸‰é¡¹åˆ›æ–°æ¥è§£å†³è®­ç»ƒä¸¤ä¸ªSLMçš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ–°é¢–çš„ä»£ç å¢å¼ºçš„é“¾å¼æ¨ç†æ•°æ®åˆæˆæ–¹æ³•å’Œæ›´æœ‰æ•ˆçš„è¿‡ç¨‹åå¥½æ¨¡å‹ï¼ˆPPMï¼‰è®­ç»ƒæ–¹æ³•ã€‚ç»è¿‡å››è½®è‡ªæˆ‘è¿›åŒ–ï¼ŒrStar-Mathåœ¨747,000ä¸ªæ•°å­¦é—®é¢˜ä¸Šç”Ÿæˆäº†æ•°ç™¾ä¸‡ä¸ªåˆæˆè§£ï¼Œä½¿SLMsçš„æ•°å­¦æ¨ç†èƒ½åŠ›è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04682",
            "title": "Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though",
            "url": "https://huggingface.co/papers/2501.04682",
            "abstract": "We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.",
            "score": 38,
            "issue_id": 1574,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "3479f7793755e586",
            "authors": [
                "Violet Xiang",
                "Charlie Snell",
                "Kanishk Gandhi",
                "Alon Albalak",
                "Anikait Singh",
                "Chase Blagden",
                "Duy Phung",
                "Rafael Rafailov",
                "Nathan Lile",
                "Dakota Mahan",
                "Louis Castricato",
                "Jan-Philipp Franken",
                "Nick Haber",
                "Chelsea Finn"
            ],
            "affiliations": [
                "Stanford University",
                "SynthLabs.ai",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04682.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#training",
                    "#rlhf",
                    "#rl",
                    "#multimodal",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Meta-CoT: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ˜Ğ˜",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Meta Chain-of-Thought (Meta-CoT), ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑĞµÑ‚ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Chain-of-Thought. Meta-CoT Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ğ¼Ñ‹ÑĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ ÑĞ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ° Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ, ÑĞ¾Ğ³Ğ»Ğ°ÑÑƒÑÑ‰ĞµĞµÑÑ Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼. ĞĞ½Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ÑÑ‚ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Meta-CoT, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼."
                },
                "en": {
                    "title": "Empowering AI with Enhanced Reasoning through Meta-CoT",
                    "desc": "The paper introduces a new framework called Meta Chain-of-Thought (Meta-CoT), which enhances the traditional Chain-of-Thought (CoT) approach by focusing on the reasoning processes behind generating CoTs. It provides experimental results from advanced models that show behaviors similar to in-context search, and discusses techniques for creating Meta-CoT through process supervision, synthetic data, and search algorithms. The authors propose a detailed training pipeline that combines instruction tuning with search traces and reinforcement learning to improve the generation of Meta-CoTs. Additionally, the paper raises important questions about scaling, the role of verifiers, and the potential for discovering new reasoning methods, aiming to advance the reasoning capabilities of large language models (LLMs)."
                },
                "zh": {
                    "title": "æ¨åŠ¨äººå·¥æ™ºèƒ½æ¨ç†èƒ½åŠ›çš„å…ƒæ€ç»´é“¾",
                    "desc": "æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œç§°ä¸ºå…ƒæ€ç»´é“¾ï¼ˆMeta-CoTï¼‰ï¼Œå®ƒé€šè¿‡æ˜ç¡®å»ºæ¨¡æ‰€éœ€çš„æ¨ç†è¿‡ç¨‹æ¥æ‰©å±•ä¼ ç»Ÿçš„æ€ç»´é“¾ï¼ˆCoTï¼‰ã€‚æˆ‘ä»¬å±•ç¤ºäº†æ¥è‡ªæœ€å…ˆè¿›æ¨¡å‹çš„å®è¯è¯æ®ï¼Œè¿™äº›æ¨¡å‹è¡¨ç°å‡ºä¸ä¸Šä¸‹æ–‡æœç´¢ä¸€è‡´çš„è¡Œä¸ºï¼Œå¹¶æ¢ç´¢äº†é€šè¿‡è¿‡ç¨‹ç›‘ç£ã€åˆæˆæ•°æ®ç”Ÿæˆå’Œæœç´¢ç®—æ³•æ¥ç”Ÿæˆå…ƒæ€ç»´é“¾çš„æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬æ¦‚è¿°äº†ä¸€ä¸ªå…·ä½“çš„è®­ç»ƒæµç¨‹ï¼Œç»“åˆäº†æŒ‡ä»¤è°ƒä¼˜ã€çº¿æ€§åŒ–æœç´¢è½¨è¿¹å’Œå¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼Œä»¥ç”Ÿæˆå…ƒæ€ç»´é“¾ã€‚æ­¤é¡¹å·¥ä½œä¸ºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å®ç°å…ƒæ€ç»´é“¾æä¾›äº†ç†è®ºå’Œå®è·µçš„è·¯çº¿å›¾ï¼Œæ¨åŠ¨äº†äººå·¥æ™ºèƒ½æ›´å¼ºå¤§å’Œæ›´äººæ€§åŒ–çš„æ¨ç†èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04686",
            "title": "URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics",
            "url": "https://huggingface.co/papers/2501.04686",
            "abstract": "Chain-of-thought (CoT) reasoning has been widely applied in the mathematical reasoning of Large Language Models (LLMs). Recently, the introduction of derivative process supervision on CoT trajectories has sparked discussions on enhancing scaling capabilities during test time, thereby boosting the potential of these models. However, in multimodal mathematical reasoning, the scarcity of high-quality CoT training data has hindered existing models from achieving high-precision CoT reasoning and has limited the realization of reasoning potential during test time. In this work, we propose a three-module synthesis strategy that integrates CoT distillation, trajectory-format rewriting, and format unification. It results in a high-quality CoT reasoning instruction fine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively validate the state-of-the-art (SOTA) performance of the trained URSA-7B model on multiple multimodal mathematical benchmarks. For test-time scaling, we introduce a data synthesis strategy that automatically generates process annotation datasets, known as DualMath-1.1M, focusing on both interpretation and logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT reasoning capabilities to robust supervision abilities. The trained URSA-RM-7B acts as a verifier, effectively enhancing the performance of URSA-7B at test time. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD) verifying capabilities, showcasing its generalization. Model weights, training data and code will be open-sourced.",
            "score": 35,
            "issue_id": 1576,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "089df0fb9a548ce8",
            "authors": [
                "Ruilin Luo",
                "Zhuofan Zheng",
                "Yifan Wang",
                "Yiyao Yu",
                "Xinzhe Ni",
                "Zicheng Lin",
                "Jin Zeng",
                "Yujiu Yang"
            ],
            "affiliations": [
                "ByteDance",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04686.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#training",
                    "#multimodal",
                    "#data",
                    "#open_source",
                    "#reasoning",
                    "#math",
                    "#architecture",
                    "#benchmark"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£ÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· ÑĞ¸Ğ½Ñ‚ĞµĞ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… MMathCoT-1M Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ°Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. ĞĞ½Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ DualMath-1.1M Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ URSA-7B Ğ¿ĞµÑ€ĞµĞ¹Ñ‚Ğ¸ Ğ¾Ñ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´Ğ°Ñ‚ÑŒ Ğº Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ‚ÑŒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ĞµĞ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Enhancing Multimodal Mathematical Reasoning with CoT Synthesis",
                    "desc": "This paper discusses improving mathematical reasoning in Large Language Models (LLMs) using a method called Chain-of-Thought (CoT) reasoning. The authors introduce a new dataset, MMathCoT-1M, which is created through a three-module synthesis strategy to enhance the quality of CoT training data in multimodal mathematics. They also present a data synthesis strategy, DualMath-1.1M, that generates additional training data to improve the model's reasoning capabilities during testing. The results show that their model, URSA-RM-7B, significantly enhances performance and generalization in multimodal mathematical tasks."
                },
                "zh": {
                    "title": "æå‡å¤šæ¨¡æ€æ•°å­¦æ¨ç†çš„é“¾å¼æ¨ç†èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†é“¾å¼æ¨ç†ï¼ˆCoTï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­çš„æŒ‘æˆ˜ã€‚ç”±äºé«˜è´¨é‡çš„CoTè®­ç»ƒæ•°æ®ç¨€ç¼ºï¼Œç°æœ‰æ¨¡å‹åœ¨æµ‹è¯•æ—¶çš„æ¨ç†èƒ½åŠ›å—åˆ°é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ä¸‰æ¨¡å—åˆæˆç­–ç•¥ï¼Œç”Ÿæˆäº†é«˜è´¨é‡çš„å¤šæ¨¡æ€æ•°å­¦æ¨ç†æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†MMathCoT-1Mã€‚é€šè¿‡è¿›ä¸€æ­¥è®­ç»ƒURSA-7Bæ¨¡å‹ï¼Œç»“åˆç”Ÿæˆçš„æ•°æ®é›†DualMath-1.1Mï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨æµ‹è¯•æ—¶çš„æ¨ç†èƒ½åŠ›å’ŒéªŒè¯èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04227",
            "title": "Agent Laboratory: Using LLM Agents as Research Assistants",
            "url": "https://huggingface.co/papers/2501.04227",
            "abstract": "Historically, scientific discovery has been a lengthy and costly process, demanding substantial time and resources from initial conception to final results. To accelerate scientific discovery, reduce research costs, and improve research quality, we introduce Agent Laboratory, an autonomous LLM-based framework capable of completing the entire research process. This framework accepts a human-provided research idea and progresses through three stages--literature review, experimentation, and report writing to produce comprehensive research outputs, including a code repository and a research report, while enabling users to provide feedback and guidance at each stage. We deploy Agent Laboratory with various state-of-the-art LLMs and invite multiple researchers to assess its quality by participating in a survey, providing human feedback to guide the research process, and then evaluate the final paper. We found that: (1) Agent Laboratory driven by o1-preview generates the best research outcomes; (2) The generated machine learning code is able to achieve state-of-the-art performance compared to existing methods; (3) Human involvement, providing feedback at each stage, significantly improves the overall quality of research; (4) Agent Laboratory significantly reduces research expenses, achieving an 84% decrease compared to previous autonomous research methods. We hope Agent Laboratory enables researchers to allocate more effort toward creative ideation rather than low-level coding and writing, ultimately accelerating scientific discovery.",
            "score": 32,
            "issue_id": 1574,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "ff592ae1a5a88909",
            "authors": [
                "Samuel Schmidgall",
                "Yusheng Su",
                "Ze Wang",
                "Ximeng Sun",
                "Jialian Wu",
                "Xiaodong Yu",
                "Jiang Liu",
                "Zicheng Liu",
                "Emad Barsoum"
            ],
            "affiliations": [
                "AMD",
                "Johns Hopkins University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04227.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#training",
                    "#agents",
                    "#rlhf",
                    "#survey"
                ],
                "emoji": "ğŸ§ª",
                "ru": {
                    "title": "ĞĞ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ°Ñ Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¸Ñ Ğ˜Ğ˜: Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Agent Laboratory - Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ LLM, ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½ÑƒÑ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ» Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ‡ĞµÑ€ĞµĞ· ÑÑ‚Ğ°Ğ¿Ñ‹ Ğ¾Ğ±Ğ·Ğ¾Ñ€Ğ° Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹, ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼ Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Agent Laboratory, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ°Ñ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ o1-preview, Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ½Ğ°Ğ´ĞµÑÑ‚ÑÑ, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ğ¸Ñ‚ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼ ÑĞ¾ÑÑ€ĞµĞ´Ğ¾Ñ‚Ğ¾Ñ‡Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° Ñ‚Ğ²Ğ¾Ñ€Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ, ÑƒÑĞºĞ¾Ñ€ÑÑ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ."
                },
                "en": {
                    "title": "Accelerating Science with Autonomous Research Frameworks",
                    "desc": "The paper presents Agent Laboratory, an autonomous framework that utilizes large language models (LLMs) to streamline the scientific research process. It operates in three stages: conducting a literature review, performing experiments, and writing reports, all while allowing human researchers to provide feedback. The study shows that Agent Laboratory can produce high-quality research outputs, including code that outperforms existing methods, and significantly reduces research costs by 84%. By automating routine tasks, the framework aims to free researchers to focus more on innovative ideas and less on tedious coding and documentation."
                },
                "zh": {
                    "title": "Agent Laboratoryï¼šåŠ é€Ÿç§‘å­¦å‘ç°çš„æ™ºèƒ½åŠ©æ‰‹",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºAgent Laboratoryçš„è‡ªä¸»æ¡†æ¶ï¼Œæ—¨åœ¨åŠ é€Ÿç§‘å­¦å‘ç°å¹¶é™ä½ç ”ç©¶æˆæœ¬ã€‚è¯¥æ¡†æ¶åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œèƒ½å¤Ÿå®Œæˆæ–‡çŒ®ç»¼è¿°ã€å®éªŒå’ŒæŠ¥å‘Šæ’°å†™ç­‰æ•´ä¸ªç ”ç©¶è¿‡ç¨‹ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒAgent Laboratoryåœ¨ç”Ÿæˆç ”ç©¶æˆæœæ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨å­¦ä¹ ä»£ç çš„æ€§èƒ½ä¸Šï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚é€šè¿‡äººç±»åé¦ˆçš„å‚ä¸ï¼Œç ”ç©¶è´¨é‡æ˜¾è‘—æé«˜ï¼ŒåŒæ—¶ç ”ç©¶è´¹ç”¨å‡å°‘äº†84%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04306",
            "title": "LLM4SR: A Survey on Large Language Models for Scientific Research",
            "url": "https://huggingface.co/papers/2501.04306",
            "abstract": "In recent years, the rapid advancement of Large Language Models (LLMs) has transformed the landscape of scientific research, offering unprecedented support across various stages of the research cycle. This paper presents the first systematic survey dedicated to exploring how LLMs are revolutionizing the scientific research process. We analyze the unique roles LLMs play across four critical stages of research: hypothesis discovery, experiment planning and implementation, scientific writing, and peer reviewing. Our review comprehensively showcases the task-specific methodologies and evaluation benchmarks. By identifying current challenges and proposing future research directions, this survey not only highlights the transformative potential of LLMs, but also aims to inspire and guide researchers and practitioners in leveraging LLMs to advance scientific inquiry. Resources are available at the following repository: https://github.com/du-nlp-lab/LLM4SR",
            "score": 17,
            "issue_id": 1576,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "bfb9039780003b6d",
            "authors": [
                "Ziming Luo",
                "Zonglin Yang",
                "Zexin Xu",
                "Wei Yang",
                "Xinya Du"
            ],
            "affiliations": [
                "Nanyang Technological University, Singapore",
                "University of Texas at Dallas, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04306.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#survey",
                    "#multimodal",
                    "#benchmark"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "LLM ĞºĞ°Ğº Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ…",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€ Ñ€Ğ¾Ğ»Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚, ĞºĞ°Ğº LLM Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ½Ğ° Ñ‡ĞµÑ‚Ñ‹Ñ€ĞµÑ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°: Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·, Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğµ Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾ Ğ¸ Ñ€ĞµÑ†ĞµĞ½Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ. Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ğ¸ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑÑ‚Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Revolutionizing Research: The Power of Large Language Models",
                    "desc": "This paper systematically surveys the impact of Large Language Models (LLMs) on the scientific research process. It identifies how LLMs assist in four key stages: generating hypotheses, planning and conducting experiments, writing scientific papers, and facilitating peer reviews. The authors discuss specific methodologies and evaluation benchmarks for each task, highlighting the transformative potential of LLMs in enhancing research efficiency. Additionally, the paper addresses current challenges and suggests future research directions to further integrate LLMs into scientific inquiry."
                },
                "zh": {
                    "title": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼šç§‘å­¦ç ”ç©¶çš„å˜é©è€…",
                    "desc": "è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•æ”¹å˜äº†ç§‘å­¦ç ”ç©¶çš„æ ¼å±€ï¼Œä¸ºç ”ç©¶å‘¨æœŸçš„å„ä¸ªé˜¶æ®µæä¾›äº†å‰æ‰€æœªæœ‰çš„æ”¯æŒã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°è°ƒæŸ¥äº†LLMså¦‚ä½•é©æ–°ç§‘å­¦ç ”ç©¶è¿‡ç¨‹ï¼Œåˆ†æäº†å®ƒä»¬åœ¨å‡è®¾å‘ç°ã€å®éªŒè§„åˆ’ä¸å®æ–½ã€ç§‘å­¦å†™ä½œå’ŒåŒè¡Œè¯„å®¡ç­‰å››ä¸ªå…³é”®é˜¶æ®µçš„ç‹¬ç‰¹ä½œç”¨ã€‚æˆ‘ä»¬çš„ç»¼è¿°å…¨é¢å±•ç¤ºäº†ä»»åŠ¡ç‰¹å®šçš„æ–¹æ³•è®ºå’Œè¯„ä¼°åŸºå‡†ï¼Œå¹¶è¯†åˆ«äº†å½“å‰é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚é€šè¿‡å¼ºè°ƒLLMsçš„å˜é©æ½œåŠ›ï¼Œæœ¬æ–‡æ—¨åœ¨æ¿€åŠ±å’ŒæŒ‡å¯¼ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…åˆ©ç”¨LLMsæ¨åŠ¨ç§‘å­¦æ¢ç´¢ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04575",
            "title": "InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection",
            "url": "https://huggingface.co/papers/2501.04575",
            "abstract": "Graphical User Interface (GUI) Agents, powered by multimodal large language models (MLLMs), have shown great potential for task automation on computing devices such as computers and mobile phones. However, existing agents face challenges in multi-step reasoning and reliance on textual annotations, limiting their effectiveness. We introduce InfiGUIAgent, an MLLM-based GUI Agent trained with a two-stage supervised fine-tuning pipeline. Stage 1 enhances fundamental skills such as GUI understanding and grounding, while Stage 2 integrates hierarchical reasoning and expectation-reflection reasoning skills using synthesized data to enable native reasoning abilities of the agents. InfiGUIAgent achieves competitive performance on several GUI benchmarks, highlighting the impact of native reasoning skills in enhancing GUI interaction for automation tasks. Resources are available at https://github.com/Reallm-Labs/InfiGUIAgent.",
            "score": 14,
            "issue_id": 1574,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "501c7ba58ede235b",
            "authors": [
                "Yuhang Liu",
                "Pengxiang Li",
                "Zishu Wei",
                "Congkai Xie",
                "Xueyu Hu",
                "Xinchen Xu",
                "Shengyu Zhang",
                "Xiaotian Han",
                "Hongxia Yang",
                "Fei Wu"
            ],
            "affiliations": [
                "ByteDance Inc",
                "Dalian University of Technology",
                "Reallm Labs",
                "The Hong Kong Polytechnic University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04575.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#synthetic",
                    "#training",
                    "#agents",
                    "#multimodal",
                    "#reasoning"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ GUI: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ²",
                    "desc": "InfiGUIAgent - ÑÑ‚Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (MLLM). ĞĞ½ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ GUI Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. InfiGUIAgent Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ GUI, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ½Ğ° Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒÑ Ğ¾Ñ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Empowering GUI Agents with Native Reasoning Skills",
                    "desc": "InfiGUIAgent is a new type of Graphical User Interface (GUI) agent that uses multimodal large language models (MLLMs) to improve task automation on devices like computers and smartphones. This agent addresses the limitations of existing systems by employing a two-stage supervised fine-tuning process. The first stage focuses on developing basic skills such as understanding and interacting with GUIs, while the second stage enhances the agent's ability to perform complex reasoning tasks. As a result, InfiGUIAgent demonstrates strong performance on various GUI benchmarks, showcasing the importance of advanced reasoning capabilities in automating GUI interactions."
                },
                "zh": {
                    "title": "æå‡GUIäº¤äº’çš„åŸç”Ÿæ¨ç†èƒ½åŠ›",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºInfiGUIAgentçš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†ï¼Œå®ƒåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è¿›è¡Œä»»åŠ¡è‡ªåŠ¨åŒ–ã€‚InfiGUIAgenté€šè¿‡ä¸¤é˜¶æ®µçš„ç›‘ç£å¾®è°ƒæµç¨‹è¿›è¡Œè®­ç»ƒï¼Œç¬¬ä¸€é˜¶æ®µæå‡äº†GUIç†è§£å’ŒåŸºç¡€æŠ€èƒ½ï¼Œç¬¬äºŒé˜¶æ®µåˆ™é€šè¿‡åˆæˆæ•°æ®æ•´åˆäº†å±‚æ¬¡æ¨ç†å’ŒæœŸæœ›åæ€æ¨ç†èƒ½åŠ›ã€‚è¯¥ä»£ç†åœ¨å¤šä¸ªGUIåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾ç¤ºäº†åŸç”Ÿæ¨ç†èƒ½åŠ›åœ¨å¢å¼ºGUIäº¤äº’ä¸­çš„é‡è¦æ€§ã€‚æ­¤ç ”ç©¶ä¸ºæé«˜è®¡ç®—è®¾å¤‡ä¸Šçš„è‡ªåŠ¨åŒ–ä»»åŠ¡æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.02772",
            "title": "GeAR: Generation Augmented Retrieval",
            "url": "https://huggingface.co/papers/2501.02772",
            "abstract": "Document retrieval techniques form the foundation for the development of large-scale information systems. The prevailing methodology is to construct a bi-encoder and compute the semantic similarity. However, such scalar similarity is difficult to reflect enough information and impedes our comprehension of the retrieval results. In addition, this computational process mainly emphasizes the global semantics and ignores the fine-grained semantic relationship between the query and the complex text in the document. In this paper, we propose a new method called Generation Augmented Retrieval (GeAR) that incorporates well-designed fusion and decoding modules. This enables GeAR to generate the relevant text from documents based on the fused representation of the query and the document, thus learning to \"focus on\" the fine-grained information. Also when used as a retriever, GeAR does not add any computational burden over bi-encoders. To support the training of the new framework, we have introduced a pipeline to efficiently synthesize high-quality data by utilizing large language models. GeAR exhibits competitive retrieval and localization performance across diverse scenarios and datasets. Moreover, the qualitative analysis and the results generated by GeAR provide novel insights into the interpretation of retrieval results. The code, data, and models will be released after completing technical review to facilitate future research.",
            "score": 11,
            "issue_id": 1572,
            "pub_date": "2025-01-06",
            "pub_date_card": {
                "ru": "6 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 6",
                "zh": "1æœˆ6æ—¥"
            },
            "hash": "dafa87428ce906b5",
            "authors": [
                "Haoyu Liu",
                "Shaohan Huang",
                "Jianfeng Liu",
                "Yuefeng Zhan",
                "Hao Sun",
                "Weiwei Deng",
                "Feng Sun",
                "Furu Wei",
                "Qi Zhang"
            ],
            "affiliations": [
                "Microsoft Corporation"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.02772.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#data",
                    "#rag",
                    "#synthetic",
                    "#dataset"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "GeAR: ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Generation Augmented Retrieval (GeAR). Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ±Ğ¸-ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ¾Ğ², GeAR Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ ÑĞ»Ğ¸ÑĞ½Ğ¸Ñ Ğ¸ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ½Ğ° Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸, Ğ½Ğµ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ GeAR."
                },
                "en": {
                    "title": "GeAR: Enhancing Document Retrieval with Fine-Grained Semantic Focus",
                    "desc": "This paper introduces a new method called Generation Augmented Retrieval (GeAR) that enhances document retrieval techniques by focusing on fine-grained semantic relationships. Unlike traditional bi-encoders that primarily assess global semantics, GeAR generates relevant text from documents by fusing the query and document representations. This approach allows for a deeper understanding of retrieval results without increasing computational costs. Additionally, the authors provide a pipeline for synthesizing high-quality training data using large language models, leading to improved performance across various datasets."
                },
                "zh": {
                    "title": "ç”Ÿæˆå¢å¼ºæ£€ç´¢ï¼šå…³æ³¨ç»†ç²’åº¦ä¿¡æ¯çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æ¡£æ£€ç´¢æ–¹æ³•ï¼Œç§°ä¸ºç”Ÿæˆå¢å¼ºæ£€ç´¢ï¼ˆGeARï¼‰ã€‚GeARé€šè¿‡èåˆæŸ¥è¯¢å’Œæ–‡æ¡£çš„è¡¨ç¤ºï¼Œç”Ÿæˆç›¸å…³æ–‡æœ¬ï¼Œä»è€Œå…³æ³¨ç»†ç²’åº¦ä¿¡æ¯ã€‚ä¸ä¼ ç»Ÿçš„åŒç¼–ç å™¨æ–¹æ³•ç›¸æ¯”ï¼ŒGeARåœ¨æ£€ç´¢æ—¶ä¸ä¼šå¢åŠ è®¡ç®—è´Ÿæ‹…ï¼ŒåŒæ—¶åœ¨å¤šç§åœºæ™¯å’Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›çš„æ£€ç´¢å’Œå®šä½æ€§èƒ½ã€‚è¯¥æ–¹æ³•è¿˜é€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åˆæˆé«˜è´¨é‡æ•°æ®ï¼Œæ”¯æŒæ–°æ¡†æ¶çš„è®­ç»ƒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04144",
            "title": "Chirpy3D: Continuous Part Latents for Creative 3D Bird Generation",
            "url": "https://huggingface.co/papers/2501.04144",
            "abstract": "In this paper, we push the boundaries of fine-grained 3D generation into truly creative territory. Current methods either lack intricate details or simply mimic existing objects -- we enable both. By lifting 2D fine-grained understanding into 3D through multi-view diffusion and modeling part latents as continuous distributions, we unlock the ability to generate entirely new, yet plausible parts through interpolation and sampling. A self-supervised feature consistency loss further ensures stable generation of these unseen parts. The result is the first system capable of creating novel 3D objects with species-specific details that transcend existing examples. While we demonstrate our approach on birds, the underlying framework extends beyond things that can chirp! Code will be released at https://github.com/kamwoh/chirpy3d.",
            "score": 9,
            "issue_id": 1578,
            "pub_date": "2025-01-07",
            "pub_date_card": {
                "ru": "7 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 7",
                "zh": "1æœˆ7æ—¥"
            },
            "hash": "89e2fad397bf0684",
            "authors": [
                "Kam Woh Ng",
                "Jing Yang",
                "Jia Wei Sii",
                "Jiankang Deng",
                "Chee Seng Chan",
                "Yi-Zhe Song",
                "Tao Xiang",
                "Xiatian Zhu"
            ],
            "affiliations": [
                "Imperial College London",
                "Universiti Malaya",
                "University of Cambridge",
                "University of Surrey"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04144.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#open_source",
                    "#3d"
                ],
                "emoji": "ğŸ¦",
                "ru": {
                    "title": "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ±ĞµÑĞ¿Ñ€ĞµÑ†ĞµĞ´ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ², Ğ²Ñ‹Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ Ğ·Ğ° Ñ€Ğ°Ğ¼ĞºĞ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ñ€Ğ°ĞºÑƒÑ€ÑĞ½ÑƒÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ñ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ° ĞºĞ°Ğº Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ñ… Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğ¹. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğµ, Ğ½Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ´Ğ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¸ ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ¡Ğ°Ğ¼Ğ¾ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ğ¸Ñ… Ğ½ĞµĞ²Ğ¸Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ½ĞµĞµ Ñ‡Ğ°ÑÑ‚ĞµĞ¹."
                },
                "en": {
                    "title": "Unlocking Creative 3D Generation with Fine-Grained Detail",
                    "desc": "This paper introduces a novel approach to generating detailed 3D objects that are not just replicas of existing items. By utilizing multi-view diffusion and treating part latents as continuous distributions, the authors enable the creation of new and realistic 3D parts through interpolation and sampling techniques. A self-supervised feature consistency loss is implemented to maintain stability in generating these novel parts. The system is demonstrated on birds, showcasing its ability to produce unique species-specific details, while the framework is applicable to a broader range of objects."
                },
                "zh": {
                    "title": "çªç ´æ€§ç»†ç²’åº¦3Dç”Ÿæˆï¼Œåˆ›é€ å…¨æ–°ç‰©ä½“ï¼",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„ç»†ç²’åº¦3Dç”Ÿæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿåˆ›é€ å‡ºå…¨æ–°çš„3Dç‰©ä½“ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¨¡ä»¿ç°æœ‰ç‰©ä½“ã€‚æˆ‘ä»¬é€šè¿‡å¤šè§†è§’æ‰©æ•£å°†2Dç»†ç²’åº¦ç†è§£æå‡åˆ°3Dï¼Œå¹¶å°†éƒ¨åˆ†æ½œå˜é‡å»ºæ¨¡ä¸ºè¿ç»­åˆ†å¸ƒï¼Œä»è€Œå®ç°äº†æ–°éƒ¨ä»¶çš„æ’å€¼å’Œé‡‡æ ·ç”Ÿæˆã€‚è‡ªç›‘ç£ç‰¹å¾ä¸€è‡´æ€§æŸå¤±ç¡®ä¿äº†è¿™äº›æœªè§éƒ¨ä»¶çš„ç¨³å®šç”Ÿæˆã€‚æˆ‘ä»¬çš„ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç‰¹å®šç‰©ç§ç»†èŠ‚çš„å…¨æ–°3Då¯¹è±¡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„ç¤ºä¾‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04689",
            "title": "SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images",
            "url": "https://huggingface.co/papers/2501.04689",
            "abstract": "We study the problem of single-image 3D object reconstruction. Recent works have diverged into two directions: regression-based modeling and generative modeling. Regression methods efficiently infer visible surfaces, but struggle with occluded regions. Generative methods handle uncertain regions better by modeling distributions, but are computationally expensive and the generation is often misaligned with visible surfaces. In this paper, we present SPAR3D, a novel two-stage approach aiming to take the best of both directions. The first stage of SPAR3D generates sparse 3D point clouds using a lightweight point diffusion model, which has a fast sampling speed. The second stage uses both the sampled point cloud and the input image to create highly detailed meshes. Our two-stage design enables probabilistic modeling of the ill-posed single-image 3D task while maintaining high computational efficiency and great output fidelity. Using point clouds as an intermediate representation further allows for interactive user edits. Evaluated on diverse datasets, SPAR3D demonstrates superior performance over previous state-of-the-art methods, at an inference speed of 0.7 seconds. Project page with code and model: https://spar3d.github.io",
            "score": 9,
            "issue_id": 1576,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "00474027a65aa27c",
            "authors": [
                "Zixuan Huang",
                "Mark Boss",
                "Aaryaman Vasishta",
                "James M. Rehg",
                "Varun Jampani"
            ],
            "affiliations": [
                "Stability AI",
                "UIUC"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04689.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "ğŸ§Š",
                "ru": {
                    "title": "SPAR3D: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¾Ğ±Ğ»Ğ°ĞºĞ¾Ğ² Ñ‚Ğ¾Ñ‡ĞµĞº",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ SPAR3D Ğ´Ğ»Ñ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ 3D-Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞĞ° Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ»Ğ°ĞºĞ¾ Ñ‚Ğ¾Ñ‡ĞµĞº Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ»ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ñ‚Ğ¾Ñ‡ĞµĞº. ĞĞ° Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ»Ğ°ĞºĞ¾ Ñ‚Ğ¾Ñ‡ĞµĞº Ğ¸ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "SPAR3D: Efficient and Detailed 3D Reconstruction from a Single Image",
                    "desc": "This paper introduces SPAR3D, a new method for reconstructing 3D objects from a single image. It combines regression and generative modeling to efficiently create 3D point clouds and detailed meshes. The first stage generates sparse point clouds quickly, while the second stage refines these into high-quality meshes using the input image. SPAR3D achieves high fidelity and speed, outperforming existing methods and allowing for user interaction with the 3D output."
                },
                "zh": {
                    "title": "SPAR3Dï¼šé«˜æ•ˆçš„å•å›¾åƒä¸‰ç»´é‡å»ºæ–°æ–¹æ³•",
                    "desc": "æˆ‘ä»¬ç ”ç©¶äº†å•å¹…å›¾åƒçš„ä¸‰ç»´ç‰©ä½“é‡å»ºé—®é¢˜ã€‚æœ€è¿‘çš„ç ”ç©¶åˆ†ä¸ºä¸¤ç§æ–¹å‘ï¼šåŸºäºå›å½’çš„å»ºæ¨¡å’Œç”Ÿæˆå»ºæ¨¡ã€‚å›å½’æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ¨æ–­å¯è§è¡¨é¢ï¼Œä½†åœ¨å¤„ç†é®æŒ¡åŒºåŸŸæ—¶è¡¨ç°ä¸ä½³ï¼›è€Œç”Ÿæˆæ–¹æ³•é€šè¿‡å»ºæ¨¡åˆ†å¸ƒæ›´å¥½åœ°å¤„ç†ä¸ç¡®å®šåŒºåŸŸï¼Œä½†è®¡ç®—å¼€é”€å¤§ä¸”ç”Ÿæˆç»“æœå¸¸å¸¸ä¸å¯è§è¡¨é¢ä¸å¯¹é½ã€‚æœ¬æ–‡æå‡ºäº†SPAR3Dï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œæ—¨åœ¨ç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œå¿«é€Ÿç”Ÿæˆç¨€ç–çš„ä¸‰ç»´ç‚¹äº‘ï¼Œå¹¶åˆ©ç”¨è¾“å…¥å›¾åƒåˆ›å»ºé«˜ç»†èŠ‚çš„ç½‘æ ¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.03271",
            "title": "DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization",
            "url": "https://huggingface.co/papers/2501.03271",
            "abstract": "The rapid rise of large language models (LLMs) has unlocked many applications but also underscores the challenge of aligning them with diverse values and preferences. Direct Preference Optimization (DPO) is central to alignment but constrained by fixed divergences and limited feature transformations. We propose DPO-Kernels, which integrates kernel methods to address these issues through four key contributions: (i) Kernelized Representations with polynomial, RBF, Mahalanobis, and spectral kernels for richer transformations, plus a hybrid loss combining embedding-based and probability-based objectives; (ii) Divergence Alternatives (Jensen-Shannon, Hellinger, Renyi, Bhattacharyya, Wasserstein, and f-divergences) for greater stability; (iii) Data-Driven Selection metrics that automatically choose the best kernel-divergence pair; and (iv) a Hierarchical Mixture of Kernels for both local precision and global modeling. Evaluations on 12 datasets demonstrate state-of-the-art performance in factuality, safety, reasoning, and instruction following. Grounded in Heavy-Tailed Self-Regularization, DPO-Kernels maintains robust generalization for LLMs, offering a comprehensive resource for further alignment research.",
            "score": 4,
            "issue_id": 1576,
            "pub_date": "2025-01-05",
            "pub_date_card": {
                "ru": "5 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 5",
                "zh": "1æœˆ5æ—¥"
            },
            "hash": "33d1640aee045ed5",
            "authors": [
                "Amitava Das",
                "Suranjana Trivedy",
                "Danush Khanna",
                "Rajarshi Roy",
                "Gurpreet Singh",
                "Basab Ghosh",
                "Yaswanth Narsupalli",
                "Vinija Jain",
                "Vasu Sharma",
                "Aishwarya Naresh Reganti",
                "Aman Chadha"
            ],
            "affiliations": [
                "Amazon AI, USA",
                "Artificial Intelligence Institute, University of South Carolina, USA",
                "Meta AI, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.03271.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#alignment",
                    "#reasoning",
                    "#dataset",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "DPO-Kernels: ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ DPO-Kernels Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑĞ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ÑĞ´ĞµÑ€ Ğ´Ğ»Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ (DPO), Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ĞºĞµÑ€Ğ½ĞµĞ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ, Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ´Ğ¸Ğ²ĞµÑ€Ğ³ĞµĞ½Ñ†Ğ¸Ğ¸ Ğ¸ data-driven Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞµĞ¹ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ ÑĞ´Ñ€Ğ° Ğ¸ Ğ´Ğ¸Ğ²ĞµÑ€Ğ³ĞµĞ½Ñ†Ğ¸Ğ¸. DPO-Kernels Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ„Ğ°ĞºÑ‚Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸, Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼ Ğ½Ğ° 12 Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° ÑĞ°Ğ¼Ğ¾Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ Ñ‚ÑĞ¶ĞµĞ»Ñ‹Ğ¼Ğ¸ Ñ…Ğ²Ğ¾ÑÑ‚Ğ°Ğ¼Ğ¸ Ğ¸ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ LLM."
                },
                "en": {
                    "title": "Enhancing LLM Alignment with DPO-Kernels",
                    "desc": "This paper introduces DPO-Kernels, a method designed to improve the alignment of large language models (LLMs) with diverse user values. It enhances Direct Preference Optimization (DPO) by incorporating kernel methods, allowing for more flexible feature transformations and better divergence measures. The approach includes a hybrid loss function, various divergence alternatives, and data-driven selection metrics to optimize performance. Evaluations show that DPO-Kernels achieves state-of-the-art results in key areas such as factuality and safety across multiple datasets."
                },
                "zh": {
                    "title": "DPO-Kernelsï¼šæå‡å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†è®¸å¤šåº”ç”¨ï¼Œä½†ä¹Ÿçªæ˜¾äº†ä¸å¤šæ ·åŒ–ä»·å€¼è§‚å’Œåå¥½å¯¹é½çš„æŒ‘æˆ˜ã€‚ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ˜¯å¯¹é½çš„æ ¸å¿ƒï¼Œä½†å—åˆ°å›ºå®šæ•£åº¦å’Œæœ‰é™ç‰¹å¾å˜æ¢çš„é™åˆ¶ã€‚æˆ‘ä»¬æå‡ºäº†DPO-Kernelsï¼Œé€šè¿‡å››ä¸ªå…³é”®è´¡çŒ®æ¥è§£å†³è¿™äº›é—®é¢˜ï¼ŒåŒ…æ‹¬ä½¿ç”¨å¤šé¡¹å¼ã€RBFã€Mahalanobiså’Œè°±æ ¸çš„æ ¸åŒ–è¡¨ç¤ºï¼Œä»¥åŠç»“åˆåµŒå…¥åŸºç¡€å’ŒåŸºäºæ¦‚ç‡çš„ç›®æ ‡çš„æ··åˆæŸå¤±ã€‚æˆ‘ä»¬çš„è¯„ä¼°åœ¨12ä¸ªæ•°æ®é›†ä¸Šå±•ç¤ºäº†åœ¨äº‹å®æ€§ã€å®‰å…¨æ€§ã€æ¨ç†å’ŒæŒ‡ä»¤éµå¾ªæ–¹é¢çš„æœ€å…ˆè¿›æ€§èƒ½ï¼ŒDPO-Kernelsä¸ºè¿›ä¸€æ­¥çš„å¯¹é½ç ”ç©¶æä¾›äº†å…¨é¢çš„èµ„æºã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04694",
            "title": "EpiCoder: Encompassing Diversity and Complexity in Code Generation",
            "url": "https://huggingface.co/papers/2501.04694",
            "abstract": "Effective instruction tuning is indispensable for optimizing code LLMs, aligning model behavior with user expectations and enhancing model performance in real-world applications. However, most existing methods focus on code snippets, which are limited to specific functionalities and rigid structures, restricting the complexity and diversity of the synthesized data. To address these limitations, we introduce a novel feature tree-based synthesis framework inspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic structure of code, our framework models semantic relationships between code elements, enabling the generation of more nuanced and diverse data. The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features. This process enables the identification of more complex patterns and relationships within the code. By sampling subtrees with controlled depth and breadth, our framework allows precise adjustments to the complexity of the generated code, supporting a wide range of tasks from simple function-level operations to intricate multi-file scenarios. We fine-tuned widely-used base models to create the EpiCoder series, achieving state-of-the-art performance at both the function and file levels across multiple benchmarks. Notably, empirical evidence indicates that our approach shows significant potential in synthesizing highly complex repository-level code data. Further analysis elucidates the merits of this approach by rigorously assessing data complexity and diversity through software engineering principles and LLM-as-a-judge method.",
            "score": 3,
            "issue_id": 1581,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "1c1ef93cdfc23c2f",
            "authors": [
                "Yaoxiang Wang",
                "Haoling Li",
                "Xin Zhang",
                "Jie Wu",
                "Xiao Liu",
                "Wenxiang Hu",
                "Zhongxin Guo",
                "Yangyu Huang",
                "Ying Xin",
                "Yujiu Yang",
                "Jinsong Su",
                "Qi Chen",
                "Scarlett Li"
            ],
            "affiliations": [
                "Microsoft",
                "Tsinghua University",
                "Xiamen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04694.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#data",
                    "#synthetic",
                    "#training",
                    "#optimization",
                    "#alignment",
                    "#architecture"
                ],
                "emoji": "ğŸŒ³",
                "ru": {
                    "title": "Ğ”ĞµÑ€ĞµĞ²Ğ¾ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ ĞºĞ¾Ğ´Ğ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ´ĞµÑ€ĞµĞ²Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ², Ğ²Ğ´Ğ¾Ñ…Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ´ĞµÑ€ĞµĞ²ÑŒÑĞ¼Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒÑ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ²ÑĞ·Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ ĞºĞ¾Ğ´Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ ÑĞµÑ€Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ EpiCoder, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³ÑˆĞ¸Ñ… Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸ĞµĞ² ĞºĞ¾Ğ´Ğ°."
                },
                "en": {
                    "title": "Unlocking Code Complexity with Feature Trees",
                    "desc": "This paper presents a new framework for instruction tuning in code language models (LLMs) that enhances their performance by generating more complex and diverse code data. The proposed feature tree-based synthesis framework goes beyond traditional code snippet methods by modeling semantic relationships between code elements, inspired by Abstract Syntax Trees (AST). By iteratively refining the feature tree, the framework captures intricate patterns and relationships, allowing for the generation of code that ranges from simple functions to complex multi-file scenarios. The authors demonstrate that their fine-tuned EpiCoder models achieve state-of-the-art results across various benchmarks, highlighting the effectiveness of their approach in synthesizing complex repository-level code data."
                },
                "zh": {
                    "title": "ç‰¹å¾æ ‘æ¡†æ¶ï¼šæå‡ä»£ç ç”Ÿæˆçš„å¤æ‚æ€§ä¸å¤šæ ·æ€§",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç‰¹å¾æ ‘åˆæˆæ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–ä»£ç å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æŒ‡ä»¤è°ƒä¼˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å»ºæ¨¡ä»£ç å…ƒç´ ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨åŠŸèƒ½å’Œç»“æ„ä¸Šçš„å±€é™æ€§ï¼Œä»è€Œç”Ÿæˆæ›´å¤æ‚å’Œå¤šæ ·åŒ–çš„æ•°æ®ã€‚ç‰¹å¾æ ‘ä»åŸå§‹æ•°æ®æ„å»ºï¼Œå¹¶é€šè¿‡è¿­ä»£ç²¾ç‚¼ï¼Œå¢åŠ æå–ç‰¹å¾çš„æ•°é‡å’Œå¤šæ ·æ€§ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬é€šè¿‡å¾®è°ƒå¹¿æ³›ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹ï¼Œåˆ›å»ºäº†EpiCoderç³»åˆ—ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†å‡½æ•°å’Œæ–‡ä»¶çº§åˆ«çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2501.04652",
            "title": "Multi-task retriever fine-tuning for domain-specific and efficient RAG",
            "url": "https://huggingface.co/papers/2501.04652",
            "abstract": "Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information. However, when building real-world RAG applications, practical issues arise. First, the retrieved information is generally domain-specific. Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input. Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers. Moreover, these RAG applications normally retrieve different kinds of data. Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed. We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases.",
            "score": 1,
            "issue_id": 1584,
            "pub_date": "2025-01-08",
            "pub_date_card": {
                "ru": "8 ÑĞ½Ğ²Ğ°Ñ€Ñ",
                "en": "January 8",
                "zh": "1æœˆ8æ—¥"
            },
            "hash": "1c906eb3ec9e3da5",
            "authors": [
                "Patrice BÃ©chard",
                "Orlando Marquez Ayala"
            ],
            "affiliations": [
                "ServiceNow"
            ],
            "pdf_title_img": "assets/pdf/title_img/2501.04652.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#training",
                    "#hallucinations",
                    "#rag",
                    "#optimization"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ RAG",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ¾Ğ¼ĞµĞ½Ğ½Ğ¾-ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ´Ğ¸Ğ½ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€ Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ° Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ¾Ğ¼ĞµĞ½Ñ‹ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ñ€Ğ¿Ğ¾Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "One Retriever to Rule Them All: Scalable RAG Solutions",
                    "desc": "This paper discusses the challenges of using Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs), particularly the issues of domain-specific information retrieval and the high cost of fine-tuning LLMs. The authors propose a solution that involves instruction fine-tuning a small retriever encoder on multiple domain-specific tasks, allowing it to serve various applications without needing separate retrievers. This approach enhances the quality of data fed into the LLM while maintaining low costs and scalability. The results demonstrate that the fine-tuned encoder can effectively generalize to new, unseen tasks in real-world scenarios."
                },
                "zh": {
                    "title": "ä¸€ä¸ªç¼–ç å™¨ï¼Œå¤šç§åº”ç”¨ï¼Œä½æˆæœ¬é«˜æ•ˆèƒ½",
                    "desc": "æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶å˜å¾—éå¸¸æ™®éï¼Œå› ä¸ºå®ƒå¯ä»¥è§£å†³ç”Ÿæˆè™šå‡æˆ–è¿‡æ—¶ä¿¡æ¯çš„å…¸å‹é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡å¯¹å°å‹æ£€ç´¢å™¨ç¼–ç å™¨è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šç§ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸Šå·¥ä½œï¼Œä»è€Œå®ç°ä¸€ä¸ªç¼–ç å™¨æœåŠ¡å¤šä¸ªç”¨ä¾‹ã€‚è¿™æ ·å¯ä»¥é™ä½æˆæœ¬ï¼Œæé«˜å¯æ‰©å±•æ€§å’Œé€Ÿåº¦ï¼ŒåŒæ—¶é¿å…ä¸ºæ¯ä¸ªåº”ç”¨ç¨‹åºéƒ¨ç½²å•ç‹¬çš„æ£€ç´¢å™¨ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç¼–ç å™¨åœ¨ä¸åŒé¢†åŸŸè®¾ç½®å’Œæœªè§è¿‡çš„æ£€ç´¢ä»»åŠ¡ä¸­ä¹Ÿèƒ½å¾ˆå¥½åœ°æ³›åŒ–ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-01-08.html",
    "link_next": "2025-01-10.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "08.01",
        "en": "01/08",
        "zh": "1æœˆ8æ—¥"
    },
    "short_date_next": {
        "ru": "10.01",
        "en": "01/10",
        "zh": "1æœˆ10æ—¥"
    },
    "categories": {
        "#dataset": 5,
        "#data": 3,
        "#benchmark": 4,
        "#agents": 2,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 3,
        "#rag": 2,
        "#plp": 0,
        "#inference": 0,
        "#3d": 2,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 4,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 8,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 5,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 4,
        "#survey": 2,
        "#diffusion": 1,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 4,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 2,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº† rStar-Mathï¼Œå±•ç¤ºäº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å¯ä»¥é€šè¿‡è’™ç‰¹å¡ç½—æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œâ€œæ·±åº¦æ€è€ƒâ€ï¼Œä»è€Œåª²ç¾æˆ–è¶…è¶Š OpenAI o1 çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚rStar-Math é€šè¿‡ä¸‰é¡¹åˆ›æ–°è®­ç»ƒä¸¤ä¸ª SLMsï¼šä»£ç å¢å¼ºçš„æ€ç»´é“¾æ•°æ®åˆæˆæ–¹æ³•ã€æ›´æœ‰æ•ˆçš„è¿‡ç¨‹åå¥½æ¨¡å‹ï¼ˆPPMï¼‰è®­ç»ƒæ–¹æ³•å’Œè‡ªæˆ‘è¿›åŒ–é…æ–¹ã€‚ç»è¿‡å››è½®è‡ªæˆ‘è¿›åŒ–ï¼ŒrStar-Math å°† SLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›æå‡åˆ°æœ€å…ˆè¿›çš„æ°´å¹³ã€‚",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº† rStar-Mathï¼Œå±•ç¤ºäº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å¯ä»¥é€šè¿‡è’™ç‰¹å¡ç½—æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œâ€œæ·±åº¦æ€è€ƒâ€ï¼Œä»è€Œåª²ç¾æˆ–è¶…è¶Š OpenAI o1 çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚rStar-Math é€šè¿‡ä¸‰é¡¹åˆ›æ–°è®­ç»ƒä¸¤ä¸ª SLMsï¼šä»£ç å¢å¼ºçš„æ€ç»´é“¾æ•°æ®åˆæˆæ–¹æ³•ã€æ›´æœ‰æ•ˆçš„è¿‡ç¨‹åå¥½æ¨¡å‹ï¼ˆPPMï¼‰è®­ç»ƒæ–¹æ³•å’Œè‡ªæˆ‘è¿›åŒ–é…æ–¹ã€‚ç»è¿‡å››è½®è‡ªæˆ‘è¿›åŒ–ï¼ŒrStar-Math å°† SLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›æå‡åˆ°æœ€å…ˆè¿›çš„æ°´å¹³ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le rStar-Math, zhÇnshÃ¬ le xiÇoxÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng (SLMs) kÄ›yÇ tÅngguÃ² mÃ©ngtÃ¨kÇluÃ³ shÃ¹ sÅusuÇ’ (MCTS) jÃ¬nxÃ­ng â€œshÄ“ndÃ¹ sÄ«kÇoâ€, cÃ³ng'Ã©r qÃ­bÇ huÃ² chÄoyuÃ¨ OpenAI o1 de shÃ¹xuÃ© tuÄ«lÇ nÃ©nglÃ¬. rStar-Math tÅngguÃ² sÄn xiÃ ng chuÃ ngxÄ«n xÃ¹nliÃ n liÇng gÃ¨ SLMs: dÃ imÇ zÄ“ngqiÃ¡ng de sÄ«wÃ©i liÃ n shÃ¹jÃ¹ hÃ©chÃ©ng fÄngfÇ, gÃ¨ng yÇ’uxiÃ o de guÃ²chÃ©ng qiÄnhuÃ² mÃ³xÃ­ng (PPM) xÃ¹nliÃ n fÄngfÇ hÃ© zÃ¬wÇ’ jÃ¬nhuÃ  pÃ¨ifÃ¡ng. JÄ«ngguÃ² sÃ¬ lÃºn zÃ¬wÇ’ jÃ¬nhuÃ , rStar-Math jiÄng SLMs de shÃ¹xuÃ© tuÄ«lÇ nÃ©nglÃ¬ tÃ­shÄ“ng dÃ o zuÃ¬ xiÄnjÃ¬n de shuÇpÃ­ng.",
        "vocab": "[\n    {\"word\": \"å±•ç¤º\", \"pinyin\": \"zhÇnshÃ¬\", \"trans\": \"display, show\"},\n    {\"word\": \"å°å‹\", \"pinyin\": \"xiÇoxÃ­ng\", \"trans\": \"small, mini\"},\n    {\"word\": \"è¯­è¨€æ¨¡å‹\", \"pinyin\": \"yÇ”yÃ¡n mÃ³xÃ­ng\", \"trans\": \"language model\"},\n    {\"word\": \"è’™ç‰¹å¡ç½—æ ‘æœç´¢\", \"pinyin\": \"MÃ©ngtÃ¨kÇluÃ³ shÃ¹ sÅusuÇ’\", \"trans\": \"Monte Carlo Tree Search\"},\n    {\"word\": \"æ·±åº¦æ€è€ƒ\", \"pinyin\": \"shÄ“ndÃ¹ sÄ«kÇo\", \"trans\": \"deep thinking\"},\n    {\"word\": \"åª²ç¾\", \"pinyin\": \"pÃ¬mÄ›i\", \"trans\": \"rival, match\"},\n    {\"word\": \"è¶…è¶Š\", \"pinyin\": \"chÄoyuÃ¨\", \"trans\": \"surpass, exceed\"},\n    {\"word\": \"æ¨ç†\", \"pinyin\": \"tuÄ«lÇ\", \"trans\": \"reasoning\"},\n    {\"word\": \"èƒ½åŠ›\", \"pinyin\": \"nÃ©nglÃ¬\", \"trans\": \"ability, capability\"},\n    {\"word\": \"åˆ›æ–°\", \"pinyin\": \"chuÃ ngxÄ«n\", \"trans\": \"innovation\"},\n    {\"word\": \"è®­ç»ƒ\", \"pinyin\": \"xÃ¹nliÃ n\", \"trans\": \"train, training\"},\n    {\"word\": \"ä»£ç \", \"pinyin\": \"dÃ imÇ\", \"trans\": \"code\"},\n    {\"word\": \"å¢å¼º\", \"pinyin\": \"zÄ“ngqiÃ¡ng\", \"trans\": \"enhance, strengthen\"},\n    {\"word\": \"æ€ç»´é“¾\", \"pinyin\": \"sÄ«wÃ©i liÃ¡n\", \"trans\": \"chain of thought\"},\n    {\"word\": \"æ•°æ®åˆæˆ\", \"pinyin\": \"shÃ¹jÃ¹ hÃ©chÃ©ng\", \"trans\": \"data synthesis\"},\n    {\"word\": \"æ–¹æ³•\", \"pinyin\": \"fÄngfÇ\", \"trans\": \"method\"},\n    {\"word\": \"è¿‡ç¨‹\", \"pinyin\": \"guÃ²chÃ©ng\", \"trans\": \"process\"},\n    {\"word\": \"åå¥½\", \"pinyin\": \"piÄnhÃ o\", \"trans\": \"preference\"},\n    {\"word\": \"æ¨¡å‹\", \"pinyin\": \"mÃ³xÃ­ng\", \"trans\": \"model\"},\n    {\"word\": \"è‡ªæˆ‘è¿›åŒ–\", \"pinyin\": \"zÃ¬wÇ’ jÃ¬nhuÃ \", \"trans\": \"self-evolution\"},\n    {\"word\": \"é…æ–¹\", \"pinyin\": \"pÃ¨ifÄng\", \"trans\": \"formula, recipe\"},\n    {\"word\": \"å››è½®\", \"pinyin\": \"sÃ¬ lÃºn\", \"trans\": \"four rounds\"},\n    {\"word\": \"æœ€å…ˆè¿›\", \"pinyin\": \"zuÃ¬ xiÄnjÃ¬n\", \"trans\": \"most advanced\"}\n]",
        "trans": "This article introduces rStar-Math, demonstrating that Small Language Models (SLMs) can engage in \"deep thinking\" through Monte Carlo Tree Search (MCTS), thereby matching or surpassing the mathematical reasoning capabilities of OpenAI o1. rStar-Math achieves this through three innovative approaches to train two SLMs: a code-enhanced chain-of-thought data synthesis method, a more effective Process Preference Model (PPM) training method, and a self-evolutionary recipe. After four rounds of self-evolution, rStar-Math elevates the mathematical reasoning abilities of SLMs to the most advanced level.",
        "update_ts": "2025-01-09 09:11"
    }
}