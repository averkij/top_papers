{
    "date": {
        "ru": "20 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
        "en": "February 20",
        "zh": "2æœˆ20æ—¥"
    },
    "time_utc": "2026-02-20 11:26",
    "weekday": 4,
    "issue_id": 1151,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2602.13515",
            "title": "SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning",
            "url": "https://huggingface.co/papers/2602.13515",
            "abstract": "A trainable sparse attention method called SpargeAttention2 is proposed that achieves high sparsity in diffusion models while maintaining generation quality through hybrid masking rules and distillation-inspired fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Many training-free sparse attention methods are effective for accelerating diffusion models. Recently, several works suggest that making sparse attention trainable can further increase sparsity while preserving generation quality. We study three key questions: (1) when do the two common masking rules, i.e., Top-k and Top-p, fail, and how can we avoid these failures? (2) why can trainable sparse attention reach higher sparsity than training-free methods? (3) what are the limitations of fine-tuning sparse attention using the diffusion loss, and how can we address them? Based on this analysis, we propose SpargeAttention2, a trainable sparse attention method that achieves high sparsity without degrading generation quality. SpargeAttention2 includes (i) a hybrid masking rule that combines Top-k and Top-p for more robust masking at high sparsity, (ii) an efficient trainable sparse attention implementation, and (iii) a distillation-inspired fine-tuning objective to better preserve generation quality during fine-tuning using sparse attention. Experiments on video diffusion models show that SpargeAttention2 reaches 95% attention sparsity and a 16.2x attention speedup while maintaining generation quality, consistently outperforming prior sparse attention methods.",
            "score": 14,
            "issue_id": 1144,
            "pub_date": "2026-02-13",
            "pub_date_card": {
                "ru": "13 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 13",
                "zh": "2æœˆ13æ—¥"
            },
            "hash": "2df8fd40471c4cea",
            "authors": [
                "Jintao Zhang",
                "Kai Jiang",
                "Chendong Xiang",
                "Weiqi Feng",
                "Yuezhou Hu",
                "Haocheng Xi",
                "Jianfei Chen",
                "Jun Zhu"
            ],
            "affiliations": [
                "Tsinghua University",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.13515.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#video",
                    "#architecture",
                    "#diffusion",
                    "#training"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼Ğ¾Ğµ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ SpargeAttention2 â€” Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ» Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Top-k Ğ¸ Top-p) Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ±ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ, Ğ²Ğ´Ğ¾Ñ…Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½ÑƒÑ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸ĞµĞ¹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ 95% Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ² 16.2 Ñ€Ğ°Ğ·Ğ° Ğ±ĞµĞ· ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾."
                },
                "en": {
                    "title": "SpargeAttention2: High Sparsity, High Quality in Diffusion Models",
                    "desc": "The paper introduces SpargeAttention2, a novel trainable sparse attention method designed for diffusion models. It combines hybrid masking rules, specifically Top-k and Top-p, to enhance robustness and achieve high sparsity without sacrificing the quality of generated outputs. The method also incorporates a distillation-inspired fine-tuning process that helps maintain generation quality during training. Experimental results demonstrate that SpargeAttention2 can achieve 95% attention sparsity and a significant speedup in attention computation, outperforming existing sparse attention techniques."
                },
                "zh": {
                    "title": "SpargeAttention2ï¼šé«˜æ•ˆç¨€ç–æ³¨æ„åŠ›çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ï¼Œç§°ä¸ºSpargeAttention2ï¼Œæ—¨åœ¨åœ¨æ‰©æ•£æ¨¡å‹ä¸­å®ç°é«˜ç¨€ç–æ€§ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆè´¨é‡ã€‚è¯¥æ–¹æ³•é€šè¿‡æ··åˆæ©è”½è§„åˆ™å’Œçµæ„Ÿæ¥è‡ªè’¸é¦çš„å¾®è°ƒç­–ç•¥æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ç ”ç©¶äº†å¸¸è§çš„Top-kå’ŒTop-pæ©è”½è§„åˆ™çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSpargeAttention2åœ¨ä¿æŒç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†95%çš„æ³¨æ„åŠ›ç¨€ç–æ€§å’Œ16.2å€çš„æ³¨æ„åŠ›åŠ é€Ÿï¼Œä¼˜äºä¹‹å‰çš„ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.17270",
            "title": "Unified Latents (UL): How to train your latents",
            "url": "https://huggingface.co/papers/2602.17270",
            "abstract": "Unified Latents framework learns joint latent representations using diffusion prior regularization and diffusion model decoding, achieving competitive FID scores with reduced training compute.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model. By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate. On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality (PSNR) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.",
            "score": 12,
            "issue_id": 1144,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "5da1ee352ba9155f",
            "authors": [
                "Jonathan Heek",
                "Emiel Hoogeboom",
                "Thomas Mensink",
                "Tim Salimans"
            ],
            "affiliations": [
                "Google DeepMind Amsterdam"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.17270.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "Ğ•Ğ´Ğ¸Ğ½Ğ¾Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾ Ñ‡ĞµÑ€ĞµĞ· Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
                    "desc": "ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Unified Latents â€” Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·ÑƒÑÑ‚ÑÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¾Ğ¼ Ğ¸ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ. Ğ¡Ğ²ÑĞ·Ñ‹Ğ²Ğ°Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑˆÑƒĞ¼ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ° Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¼ ÑˆÑƒĞ¼Ğ° Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ°, Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ÑÑ‚ Ğ¿Ñ€Ğ¾ÑÑ‚ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ĞµÑ€Ñ…Ğ½ÑÑ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ Ğ´Ğ»Ñ Ğ±Ğ¸Ñ‚Ñ€ĞµĞ¹Ñ‚Ğ° Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°. ĞĞ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ ImageNet-512 Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ FID Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ³Ğ¾ 1.4 Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸, Ñ‚Ñ€ĞµĞ±ÑƒÑ Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ², Ñ‡ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Stable Diffusion Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ Kinetics-600 Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞºĞ¾Ñ€Ğ´ FVD Ñ€Ğ°Ğ²Ğ½Ñ‹Ğ¹ 1.3."
                },
                "en": {
                    "title": "Unified Latents: Efficient Learning of Joint Representations with Diffusion Models",
                    "desc": "Unified Latents (UL) is a novel framework that focuses on learning joint latent representations by utilizing a diffusion prior for regularization and a diffusion model for decoding. The framework connects the noise output from the encoder to the minimum noise level of the prior, simplifying the training process and ensuring an efficient upper limit on latent bitrate. On the ImageNet-512 dataset, UL achieves a competitive FrÃ©chet Inception Distance (FID) score of 1.4, indicating high-quality image reconstruction while using fewer training floating-point operations (FLOPs) compared to existing models. Additionally, UL sets a new state-of-the-art FrÃ©chet Video Distance (FVD) of 1.3 on the Kinetics-600 dataset, showcasing its effectiveness in video representation learning."
                },
                "zh": {
                    "title": "ç»Ÿä¸€æ½œåœ¨æ¡†æ¶ï¼šé«˜æ•ˆå­¦ä¹ ä¸ä¼˜è´¨é‡å»º",
                    "desc": "ç»Ÿä¸€æ½œåœ¨æ¡†æ¶ï¼ˆUnified Latentsï¼‰é€šè¿‡æ‰©æ•£å…ˆéªŒæ­£åˆ™åŒ–å’Œæ‰©æ•£æ¨¡å‹è§£ç æ¥å­¦ä¹ è”åˆæ½œåœ¨è¡¨ç¤ºã€‚è¯¥æ–¹æ³•å°†ç¼–ç å™¨è¾“å‡ºçš„å™ªå£°ä¸å…ˆéªŒçš„æœ€å°å™ªå£°æ°´å¹³ç›¸è”ç³»ï¼Œä»è€Œè·å¾—ä¸€ä¸ªç®€å•çš„è®­ç»ƒç›®æ ‡ï¼Œå¹¶ä¸ºæ½œåœ¨æ¯”ç‰¹ç‡æä¾›äº†ç´§å¯†çš„ä¸Šç•Œã€‚åœ¨ImageNet-512ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†ç«äº‰æ€§çš„FIDåˆ†æ•°1.4ï¼Œå¹¶ä¸”é‡å»ºè´¨é‡ï¼ˆPSNRï¼‰é«˜äºå…¶ä»–æ¨¡å‹ï¼ŒåŒæ—¶æ‰€éœ€çš„è®­ç»ƒè®¡ç®—é‡æ›´å°‘ã€‚åœ¨Kinetics-600ä¸Šï¼Œæˆ‘ä»¬åˆ›é€ äº†æ–°çš„æœ€å…ˆè¿›çš„FVDåˆ†æ•°1.3ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.16855",
            "title": "Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents",
            "url": "https://huggingface.co/papers/2602.16855",
            "abstract": "GUI-Owl-1.5 is a multi-platform GUI agent model with varying sizes that achieves superior performance across GUI automation, grounding, tool-calling, and memory tasks through innovations in data pipelines, unified reasoning enhancement, and multi-platform reinforcement learning.  \t\t\t\t\tAI-generated summary \t\t\t\t The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves state-of-the-art results on more than 20+ GUI benchmarks on open-source models: (1) on GUI automation tasks, it obtains 56.5 on OSWorld, 71.6 on AndroidWorld, and 48.4 on WebArena; (2) on grounding tasks, it obtains 80.3 on ScreenSpotPro; (3) on tool-calling tasks, it obtains 47.6 on OSWorld-MCP, and 46.8 on MobileWorld; (4) on memory and knowledge tasks, it obtains 75.5 on GUI-Knowledge Bench. GUI-Owl-1.5 incorporates several key innovations: (1) Hybird Data Flywheel: we construct the data pipeline for UI understanding and trajectory generation based on a combination of simulated environments and cloud-based sandbox environments, in order to improve the efficiency and quality of data collection. (2) Unified Enhancement of Agent Capabilities: we use a unified thought-synthesis pipeline to enhance the model's reasoning capabilities, while placing particular emphasis on improving key agent abilities, including Tool/MCP use, memory and multi-agent adaptation; (3) Multi-platform Environment RL Scaling: We propose a new environment RL algorithm, MRPO, to address the challenges of multi-platform conflicts and the low training efficiency of long-horizon tasks. The GUI-Owl-1.5 models are open-sourced, and an online cloud-sandbox demo is available at https://github.com/X-PLUG/MobileAgent.",
            "score": 10,
            "issue_id": 1144,
            "pub_date": "2026-02-15",
            "pub_date_card": {
                "ru": "15 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 15",
                "zh": "2æœˆ15æ—¥"
            },
            "hash": "dbbfaf7e24fe8d68",
            "authors": [
                "Haiyang Xu",
                "Xi Zhang",
                "Haowei Liu",
                "Junyang Wang",
                "Zhaozai Zhu",
                "Shengjie Zhou",
                "Xuhao Hu",
                "Feiyu Gao",
                "Junjie Cao",
                "Zihua Wang",
                "Zhiyuan Chen",
                "Jitong Liao",
                "Qi Zheng",
                "Jiahui Zeng",
                "Ze Xu",
                "Shuai Bai",
                "Junyang Lin",
                "Jingren Zhou",
                "Ming Yan"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.16855.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#multimodal",
                    "#optimization",
                    "#rl",
                    "#data",
                    "#open_source",
                    "#agents",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ GUI-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ² Ğ²ÑĞµÑ… Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼",
                    "desc": "GUI-Owl-1.5 â€” ÑÑ‚Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ², Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°Ñ Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ñ… (Ğ¾Ñ‚ 2B Ğ´Ğ¾ 235B Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²) Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ´ĞµÑĞºÑ‚Ğ¾Ğ¿Ğ°, Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ² Ğ¸ Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€Ğ¾Ğ². ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° 20+ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ñ‚Ñ€Ñ‘Ğ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸ÑĞ¼: Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ¾Ğ¼Ñƒ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‰ĞµĞ¼Ñƒ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ñ‹Ğµ Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ğ¸Ñ†Ñ‹; ĞµĞ´Ğ¸Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñƒ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· ÑĞ¸Ğ½Ñ‚ĞµĞ· Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹; Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñƒ RL (MRPO) Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ…. GUI-Owl-1.5 Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹Ğ´Ğ°ÑÑ‰Ğ¸ĞµÑÑ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ² (56.5 Ğ½Ğ° OSWorld), Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğ¸ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² ÑĞºÑ€Ğ°Ğ½Ğ° (80.3 Ğ½Ğ° ScreenSpotPro) Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒÑ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ° Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾Ğ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğµ Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½ÑƒÑ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ."
                },
                "en": {
                    "title": "Revolutionizing GUI Automation with GUI-Owl-1.5",
                    "desc": "The paper presents GUI-Owl-1.5, a versatile GUI agent model designed for various platforms, which excels in tasks like GUI automation, grounding, tool-calling, and memory management. It features multiple model sizes and utilizes advanced techniques such as a hybrid data pipeline for efficient data collection and a unified reasoning enhancement to improve agent capabilities. The model achieves impressive performance on over 20 GUI benchmarks, demonstrating its effectiveness in real-world applications. Additionally, it introduces a novel reinforcement learning algorithm, MRPO, to tackle multi-platform challenges and enhance training efficiency."
                },
                "zh": {
                    "title": "GUI-Owl-1.5ï¼šå¤šå¹³å°æ™ºèƒ½ä»£ç†çš„æœªæ¥",
                    "desc": "GUI-Owl-1.5 æ˜¯ä¸€ç§å¤šå¹³å°çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†æ¨¡å‹ï¼Œå…·æœ‰ä¸åŒçš„è§„æ¨¡ï¼Œèƒ½å¤Ÿåœ¨ GUI è‡ªåŠ¨åŒ–ã€åŸºç¡€çŸ¥è¯†ã€å·¥å…·è°ƒç”¨å’Œè®°å¿†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚è¯¥æ¨¡å‹é€šè¿‡åˆ›æ–°çš„æ•°æ®ç®¡é“ã€ç»Ÿä¸€çš„æ¨ç†å¢å¼ºå’Œå¤šå¹³å°å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œè¾¾åˆ°äº†è¡Œä¸šé¢†å…ˆçš„æ€§èƒ½ã€‚GUI-Owl-1.5 åœ¨è¶…è¿‡ 20 ä¸ª GUI åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œæ”¯æŒæ¡Œé¢ã€ç§»åŠ¨å’Œæµè§ˆå™¨ç­‰å¤šç§å¹³å°ã€‚è¯¥æ¨¡å‹çš„å…³é”®åˆ›æ–°åŒ…æ‹¬æ··åˆæ•°æ®é£è½®ã€ç»Ÿä¸€å¢å¼ºä»£ç†èƒ½åŠ›å’Œå¤šå¹³å°ç¯å¢ƒå¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.14457",
            "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5",
            "url": "https://huggingface.co/papers/2602.14457",
            "abstract": "Frontier AI risk analysis assesses critical dimensions including cyber offense, persuasion and manipulation, strategic deception, uncontrolled AI R&D, and self-replication, proposing mitigation strategies for secure deployment of advanced AI systems.  \t\t\t\t\tAI-generated summary \t\t\t\t To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the proliferation of agentic AI, this version of the risk analysis technical report presents an updated and granular assessment of five critical dimensions: cyber offense, persuasion and manipulation, strategic deception, uncontrolled AI R\\&D, and self-replication. Specifically, we introduce more complex scenarios for cyber offense. For persuasion and manipulation, we evaluate the risk of LLM-to-LLM persuasion on newly released LLMs. For strategic deception and scheming, we add the new experiment with respect to emergent misalignment. For uncontrolled AI R\\&D, we focus on the ``mis-evolution'' of agents as they autonomously expand their memory substrates and toolsets. Besides, we also monitor and evaluate the safety performance of OpenClaw during the interaction on the Moltbook. For self-replication, we introduce a new resource-constrained scenario. More importantly, we propose and validate a series of robust mitigation strategies to address these emerging threats, providing a preliminary technical and actionable pathway for the secure deployment of frontier AI. This work reflects our current understanding of AI frontier risks and urges collective action to mitigate these challenges.",
            "score": 6,
            "issue_id": 1144,
            "pub_date": "2026-02-16",
            "pub_date_card": {
                "ru": "16 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 16",
                "zh": "2æœˆ16æ—¥"
            },
            "hash": "b3f30ef42f37cd93",
            "authors": [
                "Dongrui Liu",
                "Yi Yu",
                "Jie Zhang",
                "Guanxu Chen",
                "Qihao Lin",
                "Hanxi Zhu",
                "Lige Huang",
                "Yijin Zhou",
                "Peng Wang",
                "Shuai Shao",
                "Boxuan Zhang",
                "Zicheng Liu",
                "Jingwei Sun",
                "Yu Li",
                "Yuejin Xie",
                "Jiaxuan Guo",
                "Jia Xu",
                "Chaochao Lu",
                "Bowen Zhou",
                "Xia Hu",
                "Jing Shao"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2602.14457.jpg",
            "data": {
                "categories": [
                    "#agi",
                    "#alignment",
                    "#security"
                ],
                "emoji": "âš ï¸",
                "ru": {
                    "title": "Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ¸ÑĞºĞ°Ğ¼Ğ¸ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ† AI: Ğ¾Ñ‚ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ ÑƒĞ³Ñ€Ğ¾Ğ· Ğº Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ñ‹Ğ¼ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸ÑĞ¼ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ñ€Ğ¸ÑĞºĞ¾Ğ² Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… AI ÑĞ¸ÑÑ‚ĞµĞ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿ÑÑ‚Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğ¹: ĞºĞ¸Ğ±ĞµÑ€Ğ°Ñ‚Ğ°Ğº, Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¸ ÑƒĞ±ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ, ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ğ±Ğ¼Ğ°Ğ½Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¸, Ğ½ĞµĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… AI Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ ÑĞ°Ğ¼Ğ¾Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ LLM, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑƒĞ³Ñ€Ğ¾Ğ·Ñ‹ LLM-to-LLM Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¸ Ğ°Ğ²Ğ°Ñ€Ğ¸Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğ¸ Ğ¸Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ². Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ²Ğ»ÑÑÑ‰Ğ¸Ñ…ÑÑ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ½ĞµĞ¿Ñ€ĞµĞ´Ğ²Ğ¸Ğ´ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒÑÑ‚ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ¼Ğ¸Ñ‚Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… AI ÑĞ¸ÑÑ‚ĞµĞ¼."
                },
                "en": {
                    "title": "Mitigating Risks of Advanced AI: A Pathway to Secure Deployment",
                    "desc": "This paper discusses the risks associated with advanced artificial intelligence, particularly focusing on five key areas: cyber offense, persuasion and manipulation, strategic deception, uncontrolled AI research and development, and self-replication. It highlights the evolving capabilities of Large Language Models (LLMs) and the potential dangers they pose, such as LLMs influencing each other and the risks of misalignment in AI behavior. The authors present new scenarios and experiments to better understand these risks, including how AI can autonomously evolve and expand its capabilities. Additionally, the paper proposes actionable strategies to mitigate these risks, emphasizing the need for secure deployment of advanced AI systems."
                },
                "zh": {
                    "title": "å‰æ²¿AIé£é™©ç®¡ç†ï¼šç¡®ä¿å®‰å…¨éƒ¨ç½²çš„å…³é”®ç­–ç•¥",
                    "desc": "æœ¬è®ºæ–‡åˆ†æäº†å‰æ²¿äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ‰€å¸¦æ¥çš„é£é™©ï¼ŒåŒ…æ‹¬ç½‘ç»œæ”»å‡»ã€è¯´æœä¸æ“æ§ã€æˆ˜ç•¥æ¬ºéª—ã€å¤±æ§çš„AIç ”å‘å’Œè‡ªæˆ‘å¤åˆ¶ç­‰äº”ä¸ªå…³é”®ç»´åº¦ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œè®ºæ–‡æå‡ºäº†é’ˆå¯¹è¿™äº›é£é™©çš„è¯¦ç»†è¯„ä¼°å’Œå¤æ‚åœºæ™¯åˆ†æã€‚ç‰¹åˆ«æ˜¯ï¼Œç ”ç©¶äº†LLMä¹‹é—´çš„è¯´æœé£é™©ä»¥åŠè‡ªä¸»æ‰©å±•è®°å¿†å’Œå·¥å…·é›†çš„å¤±æ§AIç ”å‘é—®é¢˜ã€‚æœ€åï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç³»åˆ—æœ‰æ•ˆçš„ç¼“è§£ç­–ç•¥ï¼Œä»¥ç¡®ä¿å‰æ²¿AIç³»ç»Ÿçš„å®‰å…¨éƒ¨ç½²ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.16968",
            "title": "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers",
            "url": "https://huggingface.co/papers/2602.16968",
            "abstract": "Dynamic tokenization improves diffusion transformer efficiency by adjusting patch sizes based on content complexity and denoising timestep, achieving significant speedup without quality loss.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to 3.52times and 3.2times speedup on FLUX-1.Dev and Wan 2.1, respectively, without compromising the generation quality and prompt adherence.",
            "score": 5,
            "issue_id": 1144,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "224fdbf2700a0983",
            "authors": [
                "Dahye Kim",
                "Deepti Ghadiyaram",
                "Raghudeep Gadde"
            ],
            "affiliations": [
                "Amazon",
                "Boston University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.16968.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#video",
                    "#architecture",
                    "#diffusion"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ²",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ¸Ğ´ĞµÑ Ğ·Ğ°ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¿Ğ°Ñ‚Ñ‡ĞµĞ¹ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ¸ ÑÑ‚Ğ°Ğ¿Ğ° ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ: Ğ½Ğ° Ñ€Ğ°Ğ½Ğ½Ğ¸Ñ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‡Ğ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹, Ğ° Ğ½Ğ° Ğ¿Ğ¾Ğ·Ğ´Ğ½Ğ¸Ñ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ… â€” Ğ¼ĞµĞ»ĞºĞ¸Ğµ Ğ¿Ğ°Ñ‚Ñ‡Ğ¸ Ğ´Ğ»Ñ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´ĞµÑ‚Ğ°Ğ»ĞµĞ¹. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ´Ğ¾ÑÑ‚Ğ¸Ñ‡ÑŒ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹ Ğ² 3-3.5 Ñ€Ğ°Ğ·Ğ° Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Dynamic Tokenization: Boosting Efficiency in Diffusion Transformers",
                    "desc": "This paper introduces a method called dynamic tokenization to enhance the efficiency of diffusion transformers in generating images and videos. Traditional diffusion transformers use fixed patch sizes, which can lead to unnecessary computational costs, especially when the content complexity varies. The proposed method adjusts the size of the patches based on the complexity of the content and the stage of the denoising process, allowing for coarser patches in early steps and finer patches in later steps. This approach significantly speeds up the generation process while maintaining high quality and adherence to prompts, achieving notable speedups in various benchmarks."
                },
                "zh": {
                    "title": "åŠ¨æ€æ ‡è®°åŒ–ï¼šæå‡æ‰©æ•£å˜æ¢å™¨æ•ˆç‡çš„å…³é”®",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åŠ¨æ€æ ‡è®°åŒ–æ–¹æ³•ï¼Œä»¥æé«˜æ‰©æ•£å˜æ¢å™¨çš„æ•ˆç‡ã€‚è¯¥æ–¹æ³•æ ¹æ®å†…å®¹å¤æ‚æ€§å’Œå»å™ªæ—¶é—´æ­¥è°ƒæ•´è¡¥ä¸å¤§å°ï¼Œä»è€Œåœ¨ä¸æŸå¤±è´¨é‡çš„æƒ…å†µä¸‹æ˜¾è‘—åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚é€šè¿‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åˆ†é…è¡¥ä¸å¤§å°ï¼Œæ—©æœŸæ—¶é—´æ­¥ä½¿ç”¨è¾ƒç²—çš„è¡¥ä¸ä»¥å»ºæ¨¡å…¨å±€ç»“æ„ï¼Œè€ŒåæœŸåˆ™ä½¿ç”¨è¾ƒç»†çš„è¡¥ä¸ä»¥ç»†åŒ–å±€éƒ¨ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨FLUX-1.Devå’ŒWan 2.1ä¸Šåˆ†åˆ«å®ç°äº†é«˜è¾¾3.52å€å’Œ3.2å€çš„åŠ é€Ÿã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.17004",
            "title": "Arcee Trinity Large Technical Report",
            "url": "https://huggingface.co/papers/2602.17004",
            "abstract": "Arcee Trinity models are sparse Mixture-of-Experts architectures with varying parameter counts and activation patterns, utilizing advanced attention mechanisms and training optimizations.  \t\t\t\t\tAI-generated summary \t\t\t\t We present the technical report for Arcee Trinity Large, a sparse Mixture-of-Experts model with 400B total parameters and 13B activated per token. Additionally, we report on Trinity Nano and Trinity Mini, with Trinity Nano having 6B total parameters with 1B activated per token, Trinity Mini having 26B total parameters with 3B activated per token. The models' modern architecture includes interleaved local and global attention, gated attention, depth-scaled sandwich norm, and sigmoid routing for Mixture-of-Experts. For Trinity Large, we also introduce a new MoE load balancing strategy titled Soft-clamped Momentum Expert Bias Updates (SMEBU). We train the models using the Muon optimizer. All three models completed training with zero loss spikes. Trinity Nano and Trinity Mini were pre-trained on 10 trillion tokens, and Trinity Large was pre-trained on 17 trillion tokens. The model checkpoints are available at https://huggingface.co/arcee-ai.",
            "score": 3,
            "issue_id": 1144,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "8146970e848e4315",
            "authors": [
                "Varun Singh",
                "Lucas Krauss",
                "Sami Jaghouar",
                "Matej Sirovatka",
                "Charles Goddard",
                "Fares Obied",
                "Jack Min Ong",
                "Jannik Straube",
                "Fern",
                "Aria Harley",
                "Conner Stewart",
                "Colin Kealty",
                "Maziyar Panahi",
                "Simon Kirsten",
                "Anushka Deshpande",
                "Anneketh Vij",
                "Arthur Bresnu",
                "Pranav Veldurthi",
                "Raghav Ravishankar",
                "Hardik Bishnoi",
                "DatologyAI Team",
                "Arcee AI Team",
                "Prime Intellect Team",
                "Mark McQuade",
                "Johannes Hagemann",
                "Lucas Atkins"
            ],
            "affiliations": [
                "Arcee AI",
                "DatologyAI",
                "Prime Intellect"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.17004.jpg",
            "data": {
                "categories": [],
                "emoji": "âš™ï¸",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Mixture-of-Experts Ñ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ°Ğ¼Ğ¸ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ‚Ñ€Ğ¸ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Mixture-of-Experts Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Arcee Trinity Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²: Trinity Large (400B Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², 13B Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…), Trinity Mini (26B Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², 3B Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…) Ğ¸ Trinity Nano (6B Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², 1B Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ…). ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ¶Ğ°ÑÑ‰ĞµĞµÑÑ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ, Ğ²ĞµĞ½Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ sandwich. Ğ”Ğ»Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ² MoE Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ SMEBU, Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ğ»Ğ¾ÑÑŒ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° Muon. Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ñ‹ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¼ Ğ¾Ğ±ÑŠÑ‘Ğ¼Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (10-17 Ñ‚Ñ€Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²) Ğ±ĞµĞ· ÑĞºĞ°Ñ‡ĞºĞ¾Ğ² Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ."
                },
                "en": {
                    "title": "Optimizing AI with Sparse Mixture-of-Experts Models",
                    "desc": "The Arcee Trinity models are advanced sparse Mixture-of-Experts architectures designed to optimize performance with varying parameter counts and activation patterns. These models utilize sophisticated attention mechanisms, including interleaved local and global attention, to enhance their efficiency and effectiveness. The introduction of a new load balancing strategy, Soft-clamped Momentum Expert Bias Updates (SMEBU), helps maintain stability during training, resulting in zero loss spikes. With extensive pre-training on trillions of tokens, these models demonstrate significant capabilities in handling large-scale data efficiently."
                },
                "zh": {
                    "title": "ç¨€ç–ä¸“å®¶æ··åˆæ¶æ„çš„åˆ›æ–°ä¹‹è·¯",
                    "desc": "Arcee Trinityæ¨¡å‹æ˜¯ä¸€ç§ç¨€ç–çš„ä¸“å®¶æ··åˆæ¶æ„ï¼Œå…·æœ‰ä¸åŒçš„å‚æ•°æ•°é‡å’Œæ¿€æ´»æ¨¡å¼ï¼Œé‡‡ç”¨äº†å…ˆè¿›çš„æ³¨æ„åŠ›æœºåˆ¶å’Œè®­ç»ƒä¼˜åŒ–æŠ€æœ¯ã€‚è¯¥æ¨¡å‹åŒ…æ‹¬Trinity Largeã€Trinity Nanoå’ŒTrinity Miniï¼Œåˆ†åˆ«å…·æœ‰400Bã€6Bå’Œ26Bçš„æ€»å‚æ•°é‡ã€‚æ¨¡å‹çš„ç°ä»£æ¶æ„ç»“åˆäº†å±€éƒ¨å’Œå…¨å±€æ³¨æ„åŠ›ã€é—¨æ§æ³¨æ„åŠ›ã€æ·±åº¦ç¼©æ”¾çš„ä¸‰æ˜æ²»å½’ä¸€åŒ–ä»¥åŠç”¨äºä¸“å®¶æ··åˆçš„sigmoidè·¯ç”±ã€‚æ‰€æœ‰æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰å‡ºç°æŸå¤±å³°å€¼ï¼ŒTrinity Nanoå’ŒTrinity Miniåœ¨10ä¸‡äº¿ä¸ªæ ‡è®°ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œè€ŒTrinity Largeåˆ™åœ¨17ä¸‡äº¿ä¸ªæ ‡è®°ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.15569",
            "title": "\"What Are You Doing?\": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing",
            "url": "https://huggingface.co/papers/2602.15569",
            "abstract": "Users prefer adaptive feedback mechanisms in in-car AI assistants, starting with high transparency to build trust and then reducing verbosity as reliability increases, particularly in attention-critical driving scenarios.  \t\t\t\t\tAI-generated summary \t\t\t\t Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning during extended operations, especially in attention-critical contexts such as driving? We investigate feedback timing and verbosity from agentic LLM-based in-car assistants through a controlled, mixed-methods study (N=45) comparing planned steps and intermediate results feedback against silent operation with final-only response. Using a dual-task paradigm with an in-car voice assistant, we found that intermediate feedback significantly improved perceived speed, trust, and user experience while reducing task load - effects that held across varying task complexities and interaction contexts. Interviews further revealed user preferences for an adaptive approach: high initial transparency to establish trust, followed by progressively reducing verbosity as systems prove reliable, with adjustments based on task stakes and situational context. We translate our empirical findings into design implications for feedback timing and verbosity in agentic assistants, balancing transparency and efficiency.",
            "score": 3,
            "issue_id": 1148,
            "pub_date": "2026-02-17",
            "pub_date_card": {
                "ru": "17 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 17",
                "zh": "2æœˆ17æ—¥"
            },
            "hash": "5418b971c97650c3",
            "authors": [
                "Johannes Kirmayr",
                "Raphael Wennmacher",
                "Khanh Huynh",
                "Lukas Stappen",
                "Elisabeth AndrÃ©",
                "Florian Alt"
            ],
            "affiliations": [
                "Augsburg University Augsburg, Germany",
                "BMW Group Research and Technology Munich, Germany",
                "LMU Munich Munich, Germany"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.15569.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸš—",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ğ² Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ñ… Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°Ñ…: Ğ¾Ñ‚ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ, ĞºĞ°Ğº Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ LLM-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼Ğ¸ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ğµ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ»Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ 45 ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°Ğ¼Ğ¸, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ¾ Ñ…Ğ¾Ğ´Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ Ğ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ´Ğ¾ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ğµ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸, Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ğµ Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ¾Ğ¿Ñ‹Ñ‚, Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°Ñ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´: Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ñ, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¼ĞµÑ€Ğµ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´Ñ‘Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹."
                },
                "en": {
                    "title": "Adaptive Feedback: Building Trust in In-Car AI Assistants",
                    "desc": "This paper explores how in-car AI assistants should provide feedback to users during driving tasks. It finds that giving intermediate updates about progress improves user trust and experience, especially in critical situations. Users prefer starting with clear and detailed feedback to build trust, then reducing the amount of information as the system proves reliable. The study suggests that feedback should adapt based on the complexity of the task and the context of the driving situation."
                },
                "zh": {
                    "title": "æ™ºèƒ½åŠ©æ‰‹åé¦ˆæœºåˆ¶çš„è‡ªé€‚åº”è®¾è®¡",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†åœ¨é©¾é©¶åœºæ™¯ä¸­ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ±½è½¦åŠ©æ‰‹å¦‚ä½•æœ‰æ•ˆåœ°æä¾›åé¦ˆã€‚é€šè¿‡å¯¹45åå‚ä¸è€…çš„å®éªŒï¼Œå‘ç°ä¸­é—´åé¦ˆæ˜¾è‘—æé«˜äº†ç”¨æˆ·çš„ä¿¡ä»»æ„Ÿå’Œä½“éªŒï¼ŒåŒæ—¶é™ä½äº†ä»»åŠ¡è´Ÿæ‹…ã€‚ç”¨æˆ·åå¥½ä¸€ç§è‡ªé€‚åº”çš„åé¦ˆæœºåˆ¶ï¼ŒåˆæœŸéœ€è¦é«˜é€æ˜åº¦ä»¥å»ºç«‹ä¿¡ä»»ï¼Œéšååœ¨ç³»ç»Ÿå¯é æ€§æé«˜æ—¶é€æ¸å‡å°‘å†—ä½™ä¿¡æ¯ã€‚ç ”ç©¶ç»“æœä¸ºè®¾è®¡æ™ºèƒ½åŠ©æ‰‹çš„åé¦ˆæ—¶æœºå’Œå†—ä½™åº¦æä¾›äº†é‡è¦çš„æŒ‡å¯¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.17288",
            "title": "ArXiv-to-Model: A Practical Study of Scientific LM Training",
            "url": "https://huggingface.co/papers/2602.17288",
            "abstract": "Training a 1.36B-parameter scientific language model from raw arXiv LaTeX sources demonstrates the impact of preprocessing decisions, tokenization, and infrastructure constraints on model development under limited computational resources.  \t\t\t\t\tAI-generated summary \t\t\t\t While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.",
            "score": 2,
            "issue_id": 1149,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "f1eb16a76041ec4c",
            "authors": [
                "Anuj Gupta"
            ],
            "affiliations": [
                "Independent Researcher"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.17288.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#open_source",
                    "#data",
                    "#plp",
                    "#small_models",
                    "#science",
                    "#optimization"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "Ğ˜Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ğ¾Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¹ LLM Ğ½Ğ° Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ°Ñ…: Ğ¾Ñ‚ ÑÑ‹Ñ€Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğº ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
                    "desc": "Ğ’ ÑÑ‚Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ 1.36 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ¾Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ½Ğ° ÑÑ‹Ñ€Ñ‹Ñ… LaTeX Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¸ĞºĞ°Ñ… Ğ¸Ğ· arXiv. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ pipeline, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ğ²Ğ¾Ğ², Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ LaTeX, Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ´Ğ¾Ğ¼ĞµĞ½Ğ½Ğ¾-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° Ğ½Ğ° Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ°Ñ… (2 GPU A100). Ğ§ĞµÑ€ĞµĞ· 24 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ ÑƒĞ·ĞºĞ¸Ğµ Ğ¼ĞµÑÑ‚Ğ°. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ²Ğ»Ğ¸ÑÑÑ‚ Ğ½Ğ° Ğ¾Ğ±ÑŠĞµĞ¼ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºÑƒÑ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ, Ğ° Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ¸ Ğ²Ğ²Ğ¾Ğ´Ğ°-Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ñ‚Ğ°ĞºĞ¸Ğ¼Ğ¸ Ğ¶Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸, ĞºĞ°Ğº Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹."
                },
                "en": {
                    "title": "Building Scientific Language Models on a Budget",
                    "desc": "This paper discusses the training of a 1.36 billion-parameter scientific language model using raw LaTeX sources from arXiv, focusing on the importance of preprocessing, tokenization, and infrastructure limitations. The authors present a comprehensive pipeline that includes steps like metadata filtering and domain-aware tokenization, all while using limited computational resources. Through extensive experiments, they analyze factors such as training stability and data yield losses, revealing how preprocessing choices can significantly influence model performance. The findings aim to assist researchers with moderate compute budgets in developing specialized models by providing a clear and practical approach to the training process."
                },
                "zh": {
                    "title": "ä»åŸå§‹æ•°æ®è®­ç»ƒç§‘å­¦è¯­è¨€æ¨¡å‹çš„å®è·µæ¢ç´¢",
                    "desc": "æœ¬ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•ä»åŸå§‹çš„arXiv LaTeXæºæ–‡ä»¶ä¸­è®­ç»ƒä¸€ä¸ª1.36Bå‚æ•°çš„ç§‘å­¦è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬è¯¦ç»†æè¿°äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„æµç¨‹ï¼ŒåŒ…æ‹¬å…ƒæ•°æ®è¿‡æ»¤ã€å½’æ¡£éªŒè¯ã€LaTeXæå–ã€æ–‡æœ¬è§„èŒƒåŒ–ã€é¢†åŸŸæ„ŸçŸ¥çš„åˆ†è¯å’Œåœ¨æœ‰é™è®¡ç®—èµ„æºä¸‹çš„å¯†é›†å˜æ¢å™¨è®­ç»ƒã€‚é€šè¿‡24æ¬¡å®éªŒï¼Œæˆ‘ä»¬åˆ†æäº†è®­ç»ƒçš„ç¨³å®šæ€§ã€æ‰©å±•è¡Œä¸ºã€æ•°æ®æŸå¤±å’ŒåŸºç¡€è®¾æ–½ç“¶é¢ˆã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†é¢„å¤„ç†å†³ç­–å¯¹å¯ç”¨æ ‡è®°é‡çš„æ˜¾è‘—å½±å“ï¼Œä»¥åŠå­˜å‚¨å’ŒI/Oé™åˆ¶å¦‚ä½•ä¸è®¡ç®—èƒ½åŠ›ç›¸åª²ç¾ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.16928",
            "title": "Discovering Multiagent Learning Algorithms with Large Language Models",
            "url": "https://huggingface.co/papers/2602.16928",
            "abstract": "AlphaEvolve, an evolutionary coding agent using large language models, automatically discovers new multiagent learning algorithms for imperfect-information games by evolving regret minimization and population-based training variants.  \t\t\t\t\tAI-generated summary \t\t\t\t Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (PSRO) rest on solid theoretical ground, the design of their most effective variants often relies on human intuition to navigate a vast algorithmic design space. In this work, we propose the use of AlphaEvolve, an evolutionary coding agent powered by large language models, to automatically discover new multiagent learning algorithms. We demonstrate the generality of this framework by evolving novel variants for two distinct paradigms of game-theoretic learning. First, in the domain of iterative regret minimization, we evolve the logic governing regret accumulation and policy derivation, discovering a new algorithm, Volatility-Adaptive Discounted (VAD-)CFR. VAD-CFR employs novel, non-intuitive mechanisms-including volatility-sensitive discounting, consistency-enforced optimism, and a hard warm-start policy accumulation schedule-to outperform state-of-the-art baselines like Discounted Predictive CFR+. Second, in the regime of population based training algorithms, we evolve training-time and evaluation-time meta strategy solvers for PSRO, discovering a new variant, Smoothed Hybrid Optimistic Regret (SHOR-)PSRO. SHOR-PSRO introduces a hybrid meta-solver that linearly blends Optimistic Regret Matching with a smoothed, temperature-controlled distribution over best pure strategies. By dynamically annealing this blending factor and diversity bonuses during training, the algorithm automates the transition from population diversity to rigorous equilibrium finding, yielding superior empirical convergence compared to standard static meta-solvers.",
            "score": 2,
            "issue_id": 1144,
            "pub_date": "2026-02-18",
            "pub_date_card": {
                "ru": "18 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 18",
                "zh": "2æœˆ18æ—¥"
            },
            "hash": "5c2d7c864e7c7a30",
            "authors": [
                "Zun Li",
                "John Schultz",
                "Daniel Hennes",
                "Marc Lanctot"
            ],
            "affiliations": [
                "Google DeepMind"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.16928.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#games",
                    "#rl",
                    "#agents",
                    "#architecture",
                    "#training"
                ],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "Ğ­Ğ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· LLM",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ AlphaEvolve â€” ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ³Ñ€ Ñ Ğ½ĞµĞ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ´Ğ²ÑƒÑ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼: Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¾Ğ¶Ğ°Ğ»ĞµĞ½Ğ¸Ñ (CFR) Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ (PSRO), Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸. Ğ’ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ Ğ±Ñ‹Ğ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ´Ğ²Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°: VAD-CFR Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ´Ğ¸ÑĞºĞ¾Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ²Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ SHOR-PSRO Ñ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¼ Ğ¼ĞµÑ‚Ğ°-Ñ€ĞµÑˆĞ°Ñ‚ĞµĞ»ĞµĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ LLM Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ² Ñ‚ĞµĞ¾Ñ€Ğ¸Ğ¸ Ğ¸Ğ³Ñ€."
                },
                "en": {
                    "title": "Automating Algorithm Discovery in Multi-Agent Learning",
                    "desc": "The paper introduces AlphaEvolve, an innovative evolutionary coding agent that leverages large language models to autonomously create new multiagent learning algorithms for imperfect-information games. Traditionally, the development of effective algorithms like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (PSRO) has relied heavily on human intuition and manual adjustments. AlphaEvolve automates this process by evolving variants of these algorithms, resulting in the discovery of new methods such as Volatility-Adaptive Discounted CFR and Smoothed Hybrid Optimistic Regret PSRO. These new algorithms demonstrate improved performance and convergence in multi-agent settings, showcasing the potential of automated algorithm design in game-theoretic learning."
                },
                "zh": {
                    "title": "è‡ªåŠ¨å‘ç°æ–°ç®—æ³•çš„è¿›åŒ–æ™ºèƒ½ä½“",
                    "desc": "AlphaEvolve æ˜¯ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›åŒ–ç¼–ç ä»£ç†ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å‘ç°ç”¨äºä¸å®Œå…¨ä¿¡æ¯åšå¼ˆçš„æ–°å¤šæ™ºèƒ½ä½“å­¦ä¹ ç®—æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è¿›åŒ–åæ‚”æœ€å°åŒ–å’ŒåŸºäºäººç¾¤çš„è®­ç»ƒå˜ä½“ï¼Œå‡å°‘äº†å¯¹äººå·¥è¿­ä»£ä¼˜åŒ–çš„ä¾èµ–ã€‚æˆ‘ä»¬æå‡ºçš„ VAD-CFR å’Œ SHOR-PSRO ç®—æ³•åœ¨ç†è®ºå’Œå®è·µä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ç°æœ‰çš„åŸºå‡†ã€‚é€šè¿‡åŠ¨æ€è°ƒæ•´è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç­–ç•¥æ··åˆå’Œå¤šæ ·æ€§å¥–åŠ±ï¼ŒAlphaEvolve å®ç°äº†ä»å¤šæ ·æ€§åˆ°å‡è¡¡çš„è‡ªåŠ¨è¿‡æ¸¡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.13579",
            "title": "TactAlign: Human-to-Robot Policy Transfer via Tactile Alignment",
            "url": "https://huggingface.co/papers/2602.13579",
            "abstract": "TactAlign enables transfer of human tactile demonstrations to robots with different embodiments through cross-embodiment tactile alignment without requiring paired data or manual labels.  \t\t\t\t\tAI-generated summary \t\t\t\t Human demonstrations collected by wearable devices (e.g., tactile gloves) provide fast and dexterous supervision for policy learning, and are guided by rich, natural tactile feedback. However, a key challenge is how to transfer human-collected tactile signals to robots despite the differences in sensing modalities and embodiment. Existing human-to-robot (H2R) approaches that incorporate touch often assume identical tactile sensors, require paired data, and involve little to no embodiment gap between human demonstrator and the robots, limiting scalability and generality. We propose TactAlign, a cross-embodiment tactile alignment method that transfers human-collected tactile signals to a robot with different embodiment. TactAlign transforms human and robot tactile observations into a shared latent representation using a rectified flow, without paired datasets, manual labels, or privileged information. Our method enables low-cost latent transport guided by hand-object interaction-derived pseudo-pairs. We demonstrate that TactAlign improves H2R policy transfer across multiple contact-rich tasks (pivoting, insertion, lid closing), generalizes to unseen objects and tasks with human data (less than 5 minutes), and enables zero-shot H2R transfer on a highly dexterous tasks (light bulb screwing).",
            "score": 2,
            "issue_id": 1144,
            "pub_date": "2026-02-14",
            "pub_date_card": {
                "ru": "14 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 14",
                "zh": "2æœˆ14æ—¥"
            },
            "hash": "1f9b648c18a6bfc8",
            "authors": [
                "Youngsun Wi",
                "Jessica Yin",
                "Elvis Xiang",
                "Akash Sharma",
                "Jitendra Malik",
                "Mustafa Mukadam",
                "Nima Fazeli",
                "Tess Hellebrekers"
            ],
            "affiliations": [
                "Amazon Frontier AI & Robotics",
                "Meta FAIR",
                "Microsoft Research",
                "Nvidia",
                "UC Berkeley",
                "University of Michigan",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.13579.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#transfer_learning",
                    "#training",
                    "#robotics"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ’Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºÑ‚Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‰ÑƒÑ‰ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ğ¸ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ° Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "TactAlign â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ñ‚Ğ°ĞºÑ‚Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ¾Ñ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ğº Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ñƒ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ñ€Ñ„Ğ¾Ğ»Ğ¾Ğ³Ğ¸ĞµĞ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ²Ñ‹Ğ¿Ñ€ÑĞ¼Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±Ñ‰ĞµĞµ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ»Ğ¸ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ¸, Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿ÑĞµĞ²Ğ´Ğ¾Ğ¿Ğ°Ñ€Ñ‹, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ€ÑƒĞºĞ°-Ğ¾Ğ±ÑŠĞµĞºÑ‚, Ñ‡Ñ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ½Ğ° ÑĞ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğµ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ñ‚Ğ°ĞºÑ‚Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚Ğ°Ğ¼Ğ¸, Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ¸ Ğ·Ğ°Ğ²Ğ¸Ğ½Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ. TactAlign Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ñ‚Ñ€ĞµĞ±ÑƒÑ Ğ¼ĞµĞ½ĞµĞµ 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ñ… Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¹, Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½ÑƒĞ»ĞµĞ²Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ° Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ Ğ»Ğ¾Ğ²ĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡."
                },
                "en": {
                    "title": "Bridging the Touch Gap: TactAlign for Robot Learning",
                    "desc": "TactAlign is a method that allows robots to learn from human tactile demonstrations even when the robots have different physical forms and sensing capabilities. It does this by creating a shared representation of tactile signals from both humans and robots, without needing matched data or manual labeling. This approach enhances the transfer of human touch-based skills to robots, making it easier for them to perform complex tasks like inserting objects or closing lids. TactAlign shows significant improvements in policy transfer for various tasks, enabling robots to adapt quickly to new challenges with minimal human input."
                },
                "zh": {
                    "title": "è·¨ä½“æ€è§¦è§‰å¯¹é½ï¼Œæå‡æœºå™¨äººå­¦ä¹ èƒ½åŠ›",
                    "desc": "TactAlignæ˜¯ä¸€ç§è·¨ä½“æ€è§¦è§‰å¯¹é½æ–¹æ³•ï¼Œèƒ½å¤Ÿå°†äººç±»æ”¶é›†çš„è§¦è§‰ä¿¡å·è½¬ç§»åˆ°ä¸åŒä½“æ€çš„æœºå™¨äººä¸Šï¼Œè€Œæ— éœ€é…å¯¹æ•°æ®æˆ–æ‰‹åŠ¨æ ‡ç­¾ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¿®æ­£æµå°†äººç±»å’Œæœºå™¨äººè§¦è§‰è§‚å¯Ÿè½¬æ¢ä¸ºå…±äº«çš„æ½œåœ¨è¡¨ç¤ºï¼Œä»è€Œå®ç°ä½æˆæœ¬çš„æ½œåœ¨ä¼ è¾“ã€‚TactAlignåœ¨å¤šä¸ªæ¥è§¦ä¸°å¯Œçš„ä»»åŠ¡ä¸­æé«˜äº†äººæœºæ”¿ç­–è½¬ç§»çš„æ•ˆæœï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨æœªè§è¿‡çš„ç‰©ä½“å’Œä»»åŠ¡ä¸Šè¿›è¡Œæ³›åŒ–ã€‚è¯¥æ–¹æ³•è¿˜æ”¯æŒåœ¨é«˜åº¦çµå·§çš„ä»»åŠ¡ä¸­å®ç°é›¶æ ·æœ¬çš„äººæœºè½¬ç§»ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.17365",
            "title": "Computer-Using World Model",
            "url": "https://huggingface.co/papers/2602.17365",
            "abstract": "A world model for desktop software that predicts UI state changes through textual description followed by visual synthesis, improving decision quality and execution robustness in computer-using tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Agents operating in complex software environments benefit from reasoning about the consequences of their actions, as even a single incorrect user interface (UI) operation can derail long, artifact-preserving workflows. This challenge is particularly acute for computer-using scenarios, where real execution does not support counterfactual exploration, making large-scale trial-and-error learning and planning impractical despite the environment being fully digital and deterministic. We introduce the Computer-Using World Model (CUWM), a world model for desktop software that predicts the next UI state given the current state and a candidate action. CUWM adopts a two-stage factorization of UI dynamics: it first predicts a textual description of agent-relevant state changes, and then realizes these changes visually to synthesize the next screenshot. CUWM is trained on offline UI transitions collected from agents interacting with real Microsoft Office applications, and further refined with a lightweight reinforcement learning stage that aligns textual transition predictions with the structural requirements of computer-using environments. We evaluate CUWM via test-time action search, where a frozen agent uses the world model to simulate and compare candidate actions before execution. Across a range of Office tasks, world-model-guided test-time scaling improves decision quality and execution robustness.",
            "score": 1,
            "issue_id": 1144,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "a16b27878cfc4bb7",
            "authors": [
                "Yiming Guan",
                "Rui Yu",
                "John Zhang",
                "Lu Wang",
                "Chaoyun Zhang",
                "Liqun Li",
                "Bo Qiao",
                "Si Qin",
                "He Huang",
                "Fangkai Yang",
                "Pu Zhao",
                "Lukas Wutschitz",
                "Samuel Kessler",
                "Huseyin A Inan",
                "Robert Sim",
                "Saravan Rajmohan",
                "Qingwei Lin",
                "Dongmei Zhang"
            ],
            "affiliations": [
                "Microsoft",
                "Nanjing University",
                "Nankai University",
                "The University of New South Wales"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.17365.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#rl",
                    "#agents",
                    "#cv",
                    "#training"
                ],
                "emoji": "ğŸ–¥ï¸",
                "ru": {
                    "title": "ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞ³Ğ¾: Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸ĞºĞ° Ğ² Ğ´ĞµÑĞºÑ‚Ğ¾Ğ¿Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ…",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ Ğ´ĞµÑĞºÑ‚Ğ¾Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ (CUWM), ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ° Ğ² Ğ´Ğ²Ğ° ÑÑ‚Ğ°Ğ¿Ğ°: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹, Ğ° Ğ·Ğ°Ñ‚ĞµĞ¼ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Microsoft Office Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ reinforcement learning Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ test-time Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑ Ğ°Ğ³ĞµĞ½Ñ‚Ñƒ ÑĞ¸Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸Ñ… Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸ĞµĞ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¸Ñ€Ğ° Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² Office Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Predicting UI Changes for Smarter Software Interaction",
                    "desc": "The paper presents the Computer-Using World Model (CUWM), which enhances decision-making in desktop software by predicting user interface (UI) state changes. It operates in two stages: first, it generates a textual description of potential state changes based on the current UI and a proposed action, and then it visually synthesizes the resulting UI screenshot. CUWM is trained on real interactions with Microsoft Office applications and fine-tuned using reinforcement learning to ensure accurate predictions. The model significantly improves the quality of decisions and the robustness of actions taken by agents in complex software environments."
                },
                "zh": {
                    "title": "æå‡å†³ç­–è´¨é‡çš„è®¡ç®—æœºä½¿ç”¨ä¸–ç•Œæ¨¡å‹",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºè®¡ç®—æœºä½¿ç”¨ä¸–ç•Œæ¨¡å‹ï¼ˆCUWMï¼‰çš„æ–°æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡æ–‡æœ¬æè¿°å’Œè§†è§‰åˆæˆæ¥é¢„æµ‹æ¡Œé¢è½¯ä»¶çš„ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰çŠ¶æ€å˜åŒ–ã€‚CUWM é‡‡ç”¨ä¸¤é˜¶æ®µçš„æ–¹å¼ï¼Œé¦–å…ˆé¢„æµ‹ä¸ä»£ç†ç›¸å…³çš„çŠ¶æ€å˜åŒ–çš„æ–‡æœ¬æè¿°ï¼Œç„¶åå°†è¿™äº›å˜åŒ–å¯è§†åŒ–ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªå±å¹•æˆªå›¾ã€‚è¯¥æ¨¡å‹åœ¨çœŸå®çš„ Microsoft Office åº”ç”¨ç¨‹åºä¸­æ”¶é›†çš„ç¦»çº¿ UI è½¬æ¢æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶é€šè¿‡è½»é‡çº§çš„å¼ºåŒ–å­¦ä¹ é˜¶æ®µè¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚é€šè¿‡åœ¨æµ‹è¯•æ—¶çš„åŠ¨ä½œæœç´¢è¯„ä¼°ï¼ŒCUWM æ˜¾è‘—æé«˜äº†å†³ç­–è´¨é‡å’Œæ‰§è¡Œçš„ç¨³å¥æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.17259",
            "title": "FRAPPE: Infusing World Modeling into Generalist Policies via Multiple Future Representation Alignment",
            "url": "https://huggingface.co/papers/2602.17259",
            "abstract": "FRAPPE addresses limitations in world modeling for robotics by using parallel progressive expansion to improve representation alignment and reduce error accumulation in predictive models.  \t\t\t\t\tAI-generated summary \t\t\t\t Enabling VLA models to predict environmental dynamics, known as world modeling, has been recognized as essential for improving robotic reasoning and generalization. However, current approaches face two main issues: 1. The training objective forces models to over-emphasize pixel-level reconstruction, which constrains semantic learning and generalization 2. Reliance on predicted future observations during inference often leads to error accumulation. To address these challenges, we introduce Future Representation Alignment via Parallel Progressive Expansion (FRAPPE). Our method adopts a two-stage fine-tuning strategy: In the mid-training phase, the model learns to predict the latent representations of future observations; In the post-training phase, we expand the computational workload in parallel and align the representation simultaneously with multiple different visual foundation models. By significantly improving fine-tuning efficiency and reducing dependence on action-annotated data, FRAPPE provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies. Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios.",
            "score": 1,
            "issue_id": 1146,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "a3cbf174483be5ca",
            "authors": [
                "Han Zhao",
                "Jingbo Wang",
                "Wenxuan Song",
                "Shuai Chen",
                "Yang Liu",
                "Yan Wang",
                "Haoang Li",
                "Donglin Wang"
            ],
            "affiliations": [
                "HKUST (GZ)",
                "ShanghaiTech University",
                "South China University of Technology",
                "Tsinghua University",
                "Westlake University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.17259.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#robotics",
                    "#training",
                    "#multimodal"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ’Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ´Ğ»Ñ Ğ¾ÑĞ¾Ğ·Ğ½Ğ°ÑÑ‰ĞµĞ¹ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸",
                    "desc": "FRAPPE â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¸Ñ€Ğ° Ğ² Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞµ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½ÑƒÑ ÑĞºÑĞ¿Ğ°Ğ½ÑĞ¸Ñ Ğ´Ğ»Ñ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¸ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ fine-tuning: Ğ½Ğ° Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¹, Ğ½Ğ° Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ². ĞœĞµÑ‚Ğ¾Ğ´ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ°ĞºÑ†ĞµĞ½Ñ‚Ğ° Ğ½Ğ° Ğ¿Ğ¸ĞºÑĞµĞ»ÑŒĞ½ÑƒÑ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¸ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑĞ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ FRAPPE Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆÑƒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ñ… Ğ¸ Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Enhancing Robot World Modeling with FRAPPE",
                    "desc": "FRAPPE is a method designed to improve how robots understand and predict their environments, which is crucial for their reasoning abilities. It tackles two main problems: the over-focus on pixel details during training that limits broader understanding, and the errors that build up when robots rely on their predictions during tasks. The approach uses a two-stage fine-tuning process, first teaching the model to predict future representations, then enhancing its learning by aligning it with various visual models in parallel. This results in better efficiency and less need for extensive labeled data, leading to improved performance in complex robotic tasks."
                },
                "zh": {
                    "title": "FRAPPEï¼šæå‡æœºå™¨äººä¸–ç•Œå»ºæ¨¡çš„æ™ºèƒ½æ–¹æ³•",
                    "desc": "FRAPPEæ–¹æ³•é€šè¿‡å¹¶è¡Œæ¸è¿›æ‰©å±•æ¥æ”¹å–„æœºå™¨äººä¸–ç•Œå»ºæ¨¡çš„å±€é™æ€§ï¼Œæå‡äº†è¡¨ç¤ºå¯¹é½åº¦å¹¶å‡å°‘äº†é¢„æµ‹æ¨¡å‹ä¸­çš„è¯¯å·®ç´¯ç§¯ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µçš„å¾®è°ƒç­–ç•¥ï¼Œé¦–å…ˆåœ¨ä¸­æœŸè®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹å­¦ä¹ é¢„æµ‹æœªæ¥è§‚å¯Ÿçš„æ½œåœ¨è¡¨ç¤ºï¼›ç„¶ååœ¨åæœŸè®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹å¹¶è¡Œæ‰©å±•è®¡ç®—å·¥ä½œé‡ï¼Œå¹¶ä¸å¤šä¸ªä¸åŒçš„è§†è§‰åŸºç¡€æ¨¡å‹åŒæ—¶å¯¹é½è¡¨ç¤ºã€‚FRAPPEæ˜¾è‘—æé«˜äº†å¾®è°ƒæ•ˆç‡ï¼Œå‡å°‘äº†å¯¹åŠ¨ä½œæ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä¸ºå¢å¼ºé€šç”¨æœºå™¨äººç­–ç•¥çš„ä¸–ç•Œæ„è¯†æä¾›äº†ä¸€æ¡å¯æ‰©å±•ä¸”æ•°æ®é«˜æ•ˆçš„è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFRAPPEåœ¨RoboTwinåŸºå‡†å’ŒçœŸå®ä¸–ç•Œä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹¶åœ¨é•¿æ—¶é—´è·¨åº¦å’Œæœªè§åœºæ™¯ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.14857",
            "title": "World Models for Policy Refinement in StarCraft II",
            "url": "https://huggingface.co/papers/2602.14857",
            "abstract": "StarWM, a world model for StarCraft II, predicts future observations under partial observability using a structured textual representation and achieves significant performance improvements in win rate and decision-making stability.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have recently shown strong reasoning and generalization capabilities, motivating their use as decision-making policies in complex environments. StarCraft II (SC2), with its massive state-action space and partial observability, is a challenging testbed. However, existing LLM-based SC2 agents primarily focus on improving the policy itself and overlook integrating a learnable, action-conditioned transition model into the decision loop. To bridge this gap, we propose StarWM, the first world model for SC2 that predicts future observations under partial observability. To facilitate learning SC2's hybrid dynamics, we introduce a structured textual representation that factorizes observations into five semantic modules, and construct SC2-Dynamics-50k, the first instruction-tuning dataset for SC2 dynamics prediction. We further develop a multi-dimensional offline evaluation framework for predicted structured observations. Offline results show StarWM's substantial gains over zero-shot baselines, including nearly 60% improvements in resource prediction accuracy and self-side macro-situation consistency. Finally, we propose StarWM-Agent, a world-model-augmented decision system that integrates StarWM into a Generate--Simulate--Refine decision loop for foresight-driven policy refinement. Online evaluation against SC2's built-in AI demonstrates consistent improvements, yielding win-rate gains of 30%, 15%, and 30% against Hard (LV5), Harder (LV6), and VeryHard (LV7), respectively, alongside improved macro-management stability and tactical risk assessment.",
            "score": 1,
            "issue_id": 1149,
            "pub_date": "2026-02-16",
            "pub_date_card": {
                "ru": "16 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 16",
                "zh": "2æœˆ16æ—¥"
            },
            "hash": "59ddaead78bf514a",
            "authors": [
                "Yixin Zhang",
                "Ziyi Wang",
                "Yiming Rong",
                "Haoxi Wang",
                "Jinling Jiang",
                "Shuang Xu",
                "Haoran Wu",
                "Shiyu Zhou",
                "Bo Xu"
            ],
            "affiliations": [
                "School of Artificial Intelligence, University of Chinese Academy of Sciences",
                "The Key Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.14857.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#reasoning",
                    "#synthetic"
                ],
                "emoji": "ğŸ®",
                "ru": {
                    "title": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ Ğ´Ğ»Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ² StarCraft II",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ StarWM â€” Ğ¿ĞµÑ€Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ´Ğ»Ñ Ğ¸Ğ³Ñ€Ñ‹ StarCraft II, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğµ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ñ Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¿ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ SC2-Dynamics-50k Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ Ğ¸Ğ³Ñ€Ñ‹. StarWM-Agent Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¸Ñ€Ğ° Ğ² Ñ†Ğ¸ĞºĞ» Generate-Simulate-Refine, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑ Ğ°Ğ³ĞµĞ½Ñ‚Ñƒ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ: 60% Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚ Ğ² Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¸ 30% Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚ win-rate Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¸ĞºĞ¾Ğ²."
                },
                "en": {
                    "title": "StarWM: Enhancing StarCraft II Decision-Making with Predictive World Models",
                    "desc": "StarWM is a novel world model designed for StarCraft II that enhances decision-making under partial observability by predicting future observations. It utilizes a structured textual representation to break down observations into five semantic modules, allowing for better understanding of the game's dynamics. The model is trained on a new dataset, SC2-Dynamics-50k, which focuses on instruction-tuning for predicting game dynamics. StarWM significantly improves win rates and decision-making stability, demonstrating its effectiveness in complex environments like StarCraft II."
                },
                "zh": {
                    "title": "StarWMï¼šæå‡ã€Šæ˜Ÿé™…äº‰éœ¸IIã€‹å†³ç­–çš„ä¸–ç•Œæ¨¡å‹",
                    "desc": "StarWMæ˜¯ä¸€ä¸ªç”¨äºã€Šæ˜Ÿé™…äº‰éœ¸IIã€‹çš„ä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨éƒ¨åˆ†å¯è§‚æµ‹çš„æƒ…å†µä¸‹é¢„æµ‹æœªæ¥çš„è§‚å¯Ÿç»“æœã€‚å®ƒé€šè¿‡ç»“æ„åŒ–çš„æ–‡æœ¬è¡¨ç¤ºï¼Œå°†è§‚å¯Ÿåˆ†è§£ä¸ºäº”ä¸ªè¯­ä¹‰æ¨¡å—ï¼Œä»è€Œæœ‰æ•ˆå­¦ä¹ æ¸¸æˆçš„æ··åˆåŠ¨æ€ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒStarWMåœ¨èµ„æºé¢„æµ‹å‡†ç¡®æ€§å’Œè‡ªæˆ‘å®è§‚æƒ…å†µä¸€è‡´æ€§æ–¹é¢ï¼Œè¾ƒé›¶æ ·æœ¬åŸºçº¿æœ‰è¿‘60%çš„æå‡ã€‚é€šè¿‡å°†StarWMé›†æˆåˆ°ç”Ÿæˆ-æ¨¡æ‹Ÿ-ç²¾ç‚¼çš„å†³ç­–å¾ªç¯ä¸­ï¼ŒStarWM-Agentåœ¨ä¸æ¸¸æˆå†…ç½®AIçš„å¯¹æŠ—ä¸­ï¼Œèµ¢å¾—ç‡åˆ†åˆ«æé«˜äº†30%ã€15%å’Œ30%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.17363",
            "title": "2Mamba2Furious: Linear in Complexity, Competitive in Accuracy",
            "url": "https://huggingface.co/papers/2602.17363",
            "abstract": "Researchers enhance linear attention by simplifying Mamba-2 and improving its architectural components to achieve near-softmax accuracy while maintaining memory efficiency for long sequences.  \t\t\t\t\tAI-generated summary \t\t\t\t Linear attention transformers have become a strong alternative to softmax attention due to their efficiency. However, linear attention tends to be less expressive and results in reduced accuracy compared to softmax attention. To bridge the accuracy gap between softmax attention and linear attention, we manipulate Mamba-2, a very strong linear attention variant. We first simplify Mamba-2 down to its most fundamental and important components, evaluating which specific choices make it most accurate. From this simplified Mamba variant (Mamba-2S), we improve the A-mask and increase the order of the hidden state, resulting in a method, which we call 2Mamba, that is nearly as accurate as softmax attention, yet much more memory efficient for long context lengths. We also investigate elements to Mamba-2 that help surpass softmax attention accuracy. Code is provided for all our experiments",
            "score": 0,
            "issue_id": 1144,
            "pub_date": "2026-02-19",
            "pub_date_card": {
                "ru": "19 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 19",
                "zh": "2æœˆ19æ—¥"
            },
            "hash": "39f75928670869d9",
            "authors": [
                "Gabriel Mongaras",
                "Eric C. Larson"
            ],
            "affiliations": [
                "Lyle School of Engineering Southern Methodist University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.17363.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#inference",
                    "#open_source",
                    "#architecture",
                    "#training",
                    "#long_context"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ°",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ğ»Ğ¸ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Mamba-2 Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ĞµÑ‘ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ½Ğ¸ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ ÑĞ°Ğ¼Ñ‹Ğµ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, ÑĞ¾Ğ·Ğ´Ğ°Ğ² ÑƒĞ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Mamba-2S, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞ»ÑƒĞ¶Ğ¸Ñ‚ Ğ±Ğ°Ğ·Ğ¾Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ. ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ 2Mamba Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ±Ğ»Ğ¸Ğ·ĞºĞ¾Ğ¹ Ğº softmax attention, Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ»ÑƒÑ‡ÑˆÑƒÑ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸-ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑÑ…. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµÑ‚ÑŒ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼Ğ¸ÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞºÑĞ¿Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ."
                },
                "en": {
                    "title": "Boosting Linear Attention: Mamba-2 Simplified for Efficiency and Accuracy",
                    "desc": "This paper presents enhancements to linear attention mechanisms by refining the Mamba-2 architecture. The authors simplify Mamba-2 to focus on its key components, which helps in achieving better accuracy. They introduce a new variant called 2Mamba, which maintains high accuracy similar to softmax attention while being more memory efficient for processing long sequences. Additionally, the study explores various elements of Mamba-2 that can further improve its performance beyond that of softmax attention."
                },
                "zh": {
                    "title": "æå‡çº¿æ€§æ³¨æ„åŠ›ï¼Œæ¥è¿‘softmaxå‡†ç¡®æ€§",
                    "desc": "ç ”ç©¶äººå‘˜é€šè¿‡ç®€åŒ–Mamba-2å¹¶æ”¹è¿›å…¶æ¶æ„ç»„ä»¶ï¼Œå¢å¼ºäº†çº¿æ€§æ³¨æ„åŠ›ï¼Œè¾¾åˆ°äº†æ¥è¿‘softmaxæ³¨æ„åŠ›çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å¯¹é•¿åºåˆ—çš„å†…å­˜æ•ˆç‡ã€‚çº¿æ€§æ³¨æ„åŠ›å˜æ¢å™¨å› å…¶é«˜æ•ˆæ€§æˆä¸ºsoftmaxæ³¨æ„åŠ›çš„å¼ºæœ‰åŠ›æ›¿ä»£å“ï¼Œä½†é€šå¸¸è¡¨ç°å‡ºè¾ƒä½çš„è¡¨è¾¾èƒ½åŠ›å’Œå‡†ç¡®æ€§ã€‚ä¸ºäº†ç¼©å°softmaxæ³¨æ„åŠ›ä¸çº¿æ€§æ³¨æ„åŠ›ä¹‹é—´çš„å‡†ç¡®æ€§å·®è·ï¼Œæˆ‘ä»¬å¯¹Mamba-2è¿›è¡Œäº†æ“ä½œï¼Œç®€åŒ–åˆ°æœ€åŸºæœ¬çš„ç»„ä»¶ï¼Œå¹¶è¯„ä¼°å“ªäº›é€‰æ‹©ä½¿å…¶æœ€å‡†ç¡®ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º2Mambaçš„æ–¹æ³•ï¼Œå‡ ä¹ä¸softmaxæ³¨æ„åŠ›åŒæ ·å‡†ç¡®ï¼Œä½†åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶æ›´åŠ èŠ‚çœå†…å­˜ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.16915",
            "title": "StereoAdapter-2: Globally Structure-Consistent Underwater Stereo Depth Estimation",
            "url": "https://huggingface.co/papers/2602.16915",
            "abstract": "StereoAdapter-2 improves underwater stereo depth estimation by replacing ConvGRU with a selective state space ConvSS2D operator for efficient long-range propagation and introduces a large-scale synthetic underwater dataset.  \t\t\t\t\tAI-generated summary \t\t\t\t Stereo depth estimation is fundamental to underwater robotic perception, yet suffers from severe domain shifts caused by wavelength-dependent light attenuation, scattering, and refraction. Recent approaches leverage monocular foundation models with GRU-based iterative refinement for underwater adaptation; however, the sequential gating and local convolutional kernels in GRUs necessitate multiple iterations for long-range disparity propagation, limiting performance in large-disparity and textureless underwater regions. In this paper, we propose StereoAdapter-2, which replaces the conventional ConvGRU updater with a novel ConvSS2D operator based on selective state space models. The proposed operator employs a four-directional scanning strategy that naturally aligns with epipolar geometry while capturing vertical structural consistency, enabling efficient long-range spatial propagation within a single update step at linear computational complexity. Furthermore, we construct UW-StereoDepth-80K, a large-scale synthetic underwater stereo dataset featuring diverse baselines, attenuation coefficients, and scattering parameters through a two-stage generative pipeline combining semantic-aware style transfer and geometry-consistent novel view synthesis. Combined with dynamic LoRA adaptation inherited from StereoAdapter, our framework achieves state-of-the-art zero-shot performance on underwater benchmarks with 17% improvement on TartanAir-UW and 7.2% improvment on SQUID, with real-world validation on the BlueROV2 platform demonstrates the robustness of our approach. Code: https://github.com/AIGeeksGroup/StereoAdapter-2. Website: https://aigeeksgroup.github.io/StereoAdapter-2.",
            "score": 0,
            "issue_id": 1150,
            "pub_date": "2026-02-18",
            "pub_date_card": {
                "ru": "18 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 18",
                "zh": "2æœˆ18æ—¥"
            },
            "hash": "9d84da997f9822b9",
            "authors": [
                "Zeyu Ren",
                "Xiang Li",
                "Yiran Wang",
                "Zeyu Zhang",
                "Hao Tang"
            ],
            "affiliations": [
                "Australian Centre for Robotics",
                "Peking University",
                "The University of Melbourne"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.16915.jpg",
            "data": {
                "categories": [
                    "#robotics",
                    "#dataset",
                    "#open_source",
                    "#cv",
                    "#synthetic",
                    "#architecture"
                ],
                "emoji": "ğŸŒŠ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑÑ‚ĞµÑ€ĞµĞ¾Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ° Ğ¿Ğ¾Ğ´ Ğ²Ğ¾Ğ´Ğ¾Ğ¹ Ñ‡ĞµÑ€ĞµĞ· ÑĞµĞ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ state space Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
                    "desc": "StereoAdapter-2 ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ğ² Ğ¿Ğ¾Ğ´Ğ²Ğ¾Ğ´Ğ½Ñ‹Ñ… ÑÑ‚ĞµÑ€ĞµĞ¾Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑÑ…, Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ğ² ConvGRU Ğ½Ğ° ÑĞµĞ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ ConvSS2D Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ state space Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸ÑÑ…. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‡ĞµÑ‚Ñ‹Ñ€Ñ‘Ñ…Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑÑƒĞµÑ‚ÑÑ Ñ ÑĞ¿Ğ¸Ğ¿Ğ¾Ğ»ÑÑ€Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸ĞµĞ¹ Ğ¸ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑÑ‚ÑŒ ĞºĞ°Ñ€Ñ‚Ñ‹ Ğ´Ğ¸ÑĞ¿Ğ°Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ° Ğ·Ğ° Ğ¾Ğ´Ğ¸Ğ½ ÑˆĞ°Ğ³ Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ UW-StereoDepth-80K Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ¿Ğ¾Ğ´Ğ²Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€ĞµĞ»Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ¸Ğ´Ğ¾Ğ². ĞœĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ½Ğ° Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ğ¾Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ² Ğ½ÑƒĞ»ĞµĞ²Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ²Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ñ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¸ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğµ BlueROV2."
                },
                "en": {
                    "title": "Revolutionizing Underwater Depth Estimation with StereoAdapter-2",
                    "desc": "StereoAdapter-2 enhances underwater stereo depth estimation by introducing a new operator called ConvSS2D, which replaces the traditional ConvGRU. This operator allows for efficient long-range disparity propagation in a single update step, addressing the limitations of GRUs in underwater environments. Additionally, the paper presents a large-scale synthetic dataset, UW-StereoDepth-80K, designed to improve model training with diverse underwater conditions. The proposed method achieves significant performance improvements on underwater benchmarks, demonstrating its effectiveness in real-world applications."
                },
                "zh": {
                    "title": "æ°´ä¸‹æ·±åº¦ä¼°è®¡çš„æ–°çªç ´",
                    "desc": "StereoAdapter-2 æ˜¯ä¸€ç§æ”¹è¿›çš„æ°´ä¸‹ç«‹ä½“æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œå®ƒç”¨é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´ ConvSS2D æ“ä½œç¬¦æ›¿ä»£äº†ä¼ ç»Ÿçš„ ConvGRUï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„é•¿è·ç¦»ä¿¡æ¯ä¼ æ’­ã€‚è¯¥æ–¹æ³•é€šè¿‡å››å‘æ‰«æç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ°´ä¸‹å›¾åƒçš„å‚ç›´ç»“æ„ä¸€è‡´æ€§ï¼Œå¹¶åœ¨å•æ¬¡æ›´æ–°ä¸­å®ç°é«˜æ•ˆçš„ç©ºé—´ä¼ æ’­ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€æ–¹æ³•ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº† UW-StereoDepth-80Kï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„åˆæˆæ°´ä¸‹ç«‹ä½“æ•°æ®é›†ï¼ŒåŒ…å«å¤šæ ·çš„åŸºçº¿ã€è¡°å‡ç³»æ•°å’Œæ•£å°„å‚æ•°ã€‚æœ€ç»ˆï¼Œç»“åˆåŠ¨æ€ LoRA é€‚åº”ï¼ŒStereoAdapter-2 åœ¨æ°´ä¸‹åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„é›¶-shot æ€§èƒ½ï¼Œæ˜¾ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„é²æ£’æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.16802",
            "title": "References Improve LLM Alignment in Non-Verifiable Domains",
            "url": "https://huggingface.co/papers/2602.16802",
            "abstract": "Reference-guided LLM-evaluators enhance LLM alignment by serving as soft verifiers, improving judge accuracy and enabling effective post-training in non-verifiable domains through self-improvement techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridge this gap by serving as soft \"verifiers\". First, we design evaluation protocols that enhance LLM-based evaluators for LLM alignment using reference outputs. Through comprehensive experiments, we show that a reference-guided approach substantially improves the accuracy of less capable LLM-judges using references from frontier models; stronger LLM-judges can also be enhanced by high-quality (i.e., human-written) references. Building on these improved judges, we demonstrate the utility of high-quality references in alignment tuning, where LLMs guided with references are used as judges to self-improve. We show that reference-guided self-improvement yields clear gains over both direct SFT on reference outputs and self-improvement with reference-free judges, achieving performance comparable to training with ArmoRM, a strong finetuned reward model. Specifically, our method achieves 73.1% and 58.7% on AlpacaEval and Arena-Hard with Llama-3-8B-Instruct, and 70.0% and 74.1% with Qwen2.5-7B, corresponding to average absolute gains of +20.2 / +17.1 points over SFT distillation and +5.3 / +3.6 points over reference-free self-improvement on AlpacaEval / Arena-Hard. These results highlight the potential of using reference-guided LLM-evaluators to enable effective LLM post-training in non-verifiable domains.",
            "score": 0,
            "issue_id": 1145,
            "pub_date": "2026-02-18",
            "pub_date_card": {
                "ru": "18 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 18",
                "zh": "2æœˆ18æ—¥"
            },
            "hash": "5316cc165a71867d",
            "authors": [
                "Kejian Shi",
                "Yixin Liu",
                "Peifeng Wang",
                "Alexander R. Fabbri",
                "Shafiq Joty",
                "Arman Cohan"
            ],
            "affiliations": [
                "Meta",
                "Nanyang Technological University",
                "Salesforce Research",
                "Scale AI",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.16802.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#reasoning"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "Ğ­Ñ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğµ LLM-Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ¸ ĞºĞ°Ğº Ğ¼Ğ¾ÑÑ‚Ğ¸Ğº Ğº Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ğ½ĞµĞ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ…",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¼ÑĞ³ĞºĞ¸Ñ… Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ… Ğ±ĞµĞ· Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¸ÑÑ‚Ğ¸Ğ½Ñ‹, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ LLM. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ñ‹ Ğ¾Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ¼ĞµĞ½ĞµĞµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… ÑÑƒĞ´ĞµĞ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ LLM. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ¾Ğ² Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ°. ĞœĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… AlpacaEval Ğ¸ Arena-Hard, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ· ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing LLM Alignment with Reference-Guided Evaluators",
                    "desc": "This paper explores how reference-guided LLM-evaluators can improve the alignment of large language models (LLMs) by acting as soft verifiers. It addresses the challenge of applying Reinforcement Learning with Verifiable Rewards (RLVR) in non-verifiable domains, where traditional ground-truth verifiers are absent. The authors demonstrate that using high-quality reference outputs enhances the accuracy of LLM judges, leading to better alignment tuning and self-improvement. Their experiments show significant performance gains, indicating that reference-guided approaches can effectively support LLM post-training in challenging environments."
                },
                "zh": {
                    "title": "å‚è€ƒå¼•å¯¼æå‡LLMå¯¹é½æ€§",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†å‚è€ƒå¼•å¯¼çš„LLMè¯„ä¼°å™¨å¦‚ä½•é€šè¿‡ä½œä¸ºè½¯éªŒè¯è€…æ¥å¢å¼ºLLMçš„å¯¹é½æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨å‚è€ƒè¾“å‡ºçš„è¯„ä¼°åè®®å¯ä»¥æ˜¾è‘—æé«˜LLMè¯„ä¼°è€…çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹å¯éªŒè¯é¢†åŸŸçš„æƒ…å†µä¸‹ã€‚é€šè¿‡å®éªŒï¼Œå‘ç°é«˜è´¨é‡çš„å‚è€ƒèµ„æ–™èƒ½å¤Ÿæœ‰æ•ˆæå‡LLMè¯„ä¼°è€…çš„æ€§èƒ½ï¼Œå¹¶ä¿ƒè¿›è‡ªæˆ‘æ”¹è¿›ã€‚æœ€ç»ˆç»“æœæ˜¾ç¤ºï¼Œå‚è€ƒå¼•å¯¼çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•åœ¨éå¯éªŒè¯é¢†åŸŸçš„åè®­ç»ƒä¸­è¡¨ç°å‡ºæ˜æ˜¾çš„ä¼˜åŠ¿ã€‚"
                }
            }
        }
    ],
    "link_prev": "2026-02-19.html",
    "link_next": "2026-02-23.html",
    "link_month": "2026-02.html",
    "short_date_prev": {
        "ru": "19.02",
        "en": "02/19",
        "zh": "2æœˆ19æ—¥"
    },
    "short_date_next": {
        "ru": "23.02",
        "en": "02/23",
        "zh": "2æœˆ23æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 2,
        "#benchmark": 2,
        "#agents": 3,
        "#cv": 2,
        "#rl": 3,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 1,
        "#inference": 3,
        "#3d": 0,
        "#audio": 0,
        "#video": 2,
        "#multimodal": 4,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 5,
        "#healthcare": 0,
        "#training": 8,
        "#robotics": 3,
        "#agi": 1,
        "#games": 2,
        "#interpretability": 0,
        "#reasoning": 4,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 1,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 2,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 1,
        "#science": 1,
        "#low_resource": 0
    }
}