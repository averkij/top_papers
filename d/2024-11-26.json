{
    "date": {
        "ru": "26 ноября",
        "en": "November 26",
        "zh": "11月26日"
    },
    "time_utc": "2024-11-26 02:19",
    "weekday": 1,
    "issue_id": 776,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.15138",
            "title": "Material Anything: Generating Materials for Any 3D Object via Diffusion",
            "url": "https://huggingface.co/papers/2411.15138",
            "abstract": "We present Material Anything, a fully-automated, unified diffusion framework designed to generate physically-based materials for 3D objects. Unlike existing methods that rely on complex pipelines or case-specific optimizations, Material Anything offers a robust, end-to-end solution adaptable to objects under diverse lighting conditions. Our approach leverages a pre-trained image diffusion model, enhanced with a triple-head architecture and rendering loss to improve stability and material quality. Additionally, we introduce confidence masks as a dynamic switcher within the diffusion model, enabling it to effectively handle both textured and texture-less objects across varying lighting conditions. By employing a progressive material generation strategy guided by these confidence masks, along with a UV-space material refiner, our method ensures consistent, UV-ready material outputs. Extensive experiments demonstrate our approach outperforms existing methods across a wide range of object categories and lighting conditions.",
            "score": 1,
            "issue_id": 776,
            "pub_date": "2024-11-22",
            "pub_date_card": {
                "ru": "22 ноября",
                "en": "November 22",
                "zh": "11月22日"
            },
            "hash": "34b8f6718115f1e3",
            "authors": [
                "Xin Huang",
                "Tengfei Wang",
                "Ziwei Liu",
                "Qing Wang"
            ],
            "affiliations": [
                "Northwestern Polytechnical University",
                "S-Lab, Nanyang Technological University",
                "Shanghai AI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.15138.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#architecture",
                    "#optimization",
                    "#diffusion"
                ],
                "emoji": "🎨",
                "ru": {
                    "title": "Универсальная генерация материалов для 3D-объектов с помощью диффузии",
                    "desc": "В статье представлен Material Anything - полностью автоматизированный унифицированный фреймворк диффузии для генерации физически корректных материалов для 3D-объектов. В отличие от существующих методов, он предлагает надежное сквозное решение, адаптируемое к объектам в различных условиях освещения. Подход использует предобученную модель диффузии изображений с тройной архитектурой и функцией потерь рендеринга для улучшения стабильности и качества материалов. Также вводятся маски уверенности как динамический переключатель в модели диффузии, позволяющий эффективно обрабатывать объекты с текстурами и без них в различных условиях освещения."
                },
                "en": {
                    "title": "Automating Realistic Material Generation for 3D Objects",
                    "desc": "Material Anything is a novel framework that automates the generation of realistic materials for 3D objects using a unified diffusion approach. It simplifies the material creation process by eliminating the need for complex workflows and optimizations tailored to specific cases. The framework utilizes a pre-trained image diffusion model, enhanced with a triple-head architecture and rendering loss, to ensure high-quality and stable material outputs. By incorporating confidence masks, it dynamically adapts to different object types and lighting scenarios, resulting in consistent and UV-ready materials across various conditions."
                },
                "zh": {
                    "title": "全自动材料生成，适应多种光照条件",
                    "desc": "本文介绍了一种名为Material Anything的全自动统一扩散框架，旨在为3D物体生成基于物理的材料。与现有方法依赖复杂流程或特定优化不同，Material Anything提供了一种稳健的端到端解决方案，适应不同光照条件下的物体。我们的方法利用了预训练的图像扩散模型，并通过三头架构和渲染损失来提高稳定性和材料质量。此外，我们引入了置信掩码作为扩散模型中的动态切换器，使其能够有效处理有纹理和无纹理的物体。"
                }
            }
        }
    ],
    "link_prev": "2024-11-25.html",
    "link_next": "2024-11-27.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "25.11",
        "en": "11/25",
        "zh": "11月25日"
    },
    "short_date_next": {
        "ru": "27.11",
        "en": "11/27",
        "zh": "11月27日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了大型扩散模型生成高质量图像，但难以学习新的个性化艺术风格。现有方法在微调时盲目使用预训练目标和噪声水平分布，导致风格对齐不佳。作者提出了风格友好的信噪比采样器，在微调时将信噪比分布偏向更高的噪声水平，以捕捉独特风格。这使模型能更好地生成具有高风格一致性的图像，并允许创建和共享新的风格模板。作者展示了生成水彩画、简笔画、3D渲染等多种风格的能力。",
        "title": "Style-Friendly SNR Sampler for Style-Driven Generation",
        "pinyin": "这篇文章讨论了大型扩散模型生成高质量图像，但难以学习新的个性化艺术风格。现有方法在微调时盲目使用预训练目标和噪声水平分布，导致风格对齐不佳。作者提出了风格友好的信噪比采样器，在微调时将信噪比分布偏向更高的噪声水平，以捕捉独特风格。这使模型能更好地生成具有高风格一致性的图像，并允许创建和共享新的风格模板。作者展示了生成水彩画、简笔画、3D渲染等多种风格的能力。\n\nzhè piān wén zhāng tǎo lùn le dà xíng kuò sàn mó xíng shēng chéng gāo zhì liàng tú xiàng, dàn nán yǐ xué xí xīn de gè xìng huà yì shù fēng gé. xiàn yǒu fāng fǎ zài wēi tiáo shí māng mù shǐ yòng yù xùn liàn mù biāo hé zào shēng shuǐ píng fēn bù, dǎo zhì fēng gé duì qí bù jiā. zuò zhě tí chū le fēng gé yǒu hǎo de xìn zào bǐ cǎi yǎng qì, zài wēi tiáo shí jiāng xìn zào bǐ fēn bù piān xiàng gèng gāo de zào shēng shuǐ píng, yǐ bǔ zhuō dú tè fēng gé. zhè shǐ mó xíng néng gèng hǎo de shēng chéng jù yǒu gāo fēng gé yī zhì xìng de tú xiàng, bìng yǔn xǔ chuàng jiàn hé gòng xiǎng xīn de fēng gé mú bǎn. zuò zhě zhǎn shì le shēng chéng shuǐ cǎi huà, jiǎn bǐ huà, 3D xuàn rán děng duō zhǒng fēng gé de néng lì.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high quality'}, {'word': '个性化', 'pinyin': 'gè xìng huà', 'trans': 'personalized'}, {'word': '艺术', 'pinyin': 'yì shù', 'trans': 'art'}, {'word': '风格', 'pinyin': 'fēng gé', 'trans': 'style'}, {'word': '现有', 'pinyin': 'xiàn yǒu', 'trans': 'existing'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '微调', 'pinyin': 'wēi tiáo', 'trans': 'fine-tune'}, {'word': '盲目', 'pinyin': 'máng mù', 'trans': 'blindly'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-trained'}, {'word': '目标', 'pinyin': 'mù biāo', 'trans': 'target'}, {'word': '噪声', 'pinyin': 'zào shēng', 'trans': 'noise'}, {'word': '水平', 'pinyin': 'shuǐ píng', 'trans': 'level'}, {'word': '分布', 'pinyin': 'fēn bù', 'trans': 'distribution'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'}, {'word': '对齐', 'pinyin': 'duì qí', 'trans': 'alignment'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '信噪比', 'pinyin': 'xìn zào bǐ', 'trans': 'signal-to-noise ratio'}, {'word': '采样器', 'pinyin': 'cǎi yàng qì', 'trans': 'sampler'}, {'word': '偏向', 'pinyin': 'piān xiàng', 'trans': 'bias towards'}, {'word': '捕捉', 'pinyin': 'bǔ zhuō', 'trans': 'capture'}, {'word': '独特', 'pinyin': 'dú tè', 'trans': 'unique'}, {'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'}, {'word': '模板', 'pinyin': 'mú bǎn', 'trans': 'template'}, {'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'}, {'word': '水彩画', 'pinyin': 'shuǐ cǎi huà', 'trans': 'watercolor painting'}, {'word': '简笔画', 'pinyin': 'jiǎn bǐ huà', 'trans': 'line drawing'}, {'word': '3D渲染', 'pinyin': '3D xuàn rán', 'trans': '3D rendering'}]",
        "trans": "This article discusses the ability of large diffusion models to generate high-quality images but their difficulty in learning new personalized artistic styles. Existing methods blindly use pre-trained objectives and noise level distributions during fine-tuning, leading to poor style alignment. The authors propose a style-friendly signal-to-noise ratio sampler that biases the signal-to-noise ratio distribution towards higher noise levels during fine-tuning to capture unique styles. This allows the model to generate images with higher style consistency and enables the creation and sharing of new style templates. The authors demonstrate the capability to generate various styles such as watercolor, sketch, and 3D rendering.",
        "update_ts": "2024-11-25 09:06"
    }
}