{
    "date": {
        "ru": "26 ноября",
        "en": "November 26",
        "zh": "11月26日"
    },
    "time_utc": "2024-11-26 05:10",
    "weekday": 1,
    "issue_id": 779,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2411.15466",
            "title": "Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator",
            "url": "https://huggingface.co/papers/2411.15466",
            "abstract": "Subject-driven text-to-image generation aims to produce images of a new subject within a desired context by accurately capturing both the visual characteristics of the subject and the semantic content of a text prompt. Traditional methods rely on time- and resource-intensive fine-tuning for subject alignment, while recent zero-shot approaches leverage on-the-fly image prompting, often sacrificing subject alignment. In this paper, we introduce Diptych Prompting, a novel zero-shot approach that reinterprets as an inpainting task with precise subject alignment by leveraging the emergent property of diptych generation in large-scale text-to-image models. Diptych Prompting arranges an incomplete diptych with the reference image in the left panel, and performs text-conditioned inpainting on the right panel. We further prevent unwanted content leakage by removing the background in the reference image and improve fine-grained details in the generated subject by enhancing attention weights between the panels during inpainting. Experimental results confirm that our approach significantly outperforms zero-shot image prompting methods, resulting in images that are visually preferred by users. Additionally, our method supports not only subject-driven generation but also stylized image generation and subject-driven image editing, demonstrating versatility across diverse image generation applications. Project page: https://diptychprompting.github.io/",
            "score": 11,
            "issue_id": 777,
            "pub_date": "2024-11-23",
            "pub_date_card": {
                "ru": "23 ноября",
                "en": "November 23",
                "zh": "11月23日"
            },
            "hash": "288600e8c54930f4",
            "authors": [
                "Chaehun Shin",
                "Jooyoung Choi",
                "Heeseung Kim",
                "Sungroh Yoon"
            ],
            "affiliations": [
                "AIIS, ASRI, INMC, ISRC, and Interdisciplinary Program in AI, Seoul National University",
                "Data Science and AI Laboratory, ECE, Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.15466.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#cv",
                    "#multimodal",
                    "#optimization"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Diptych Prompting: точная генерация изображений без дополнительного обучения",
                    "desc": "Статья представляет новый метод генерации изображений под названием Diptych Prompting. Этот подход использует свойство диптиха в крупномасштабных моделях text-to-image для точного воспроизведения субъекта в желаемом контексте. Метод интерпретирует задачу как инпейнтинг, размещая исходное изображение в левой части диптиха и генерируя правую часть на основе текстового промпта. Diptych Prompting превосходит существующие zero-shot методы и поддерживает различные приложения генерации изображений."
                },
                "en": {
                    "title": "Diptych Prompting: Zero-Shot Image Generation with Subject Precision",
                    "desc": "This paper presents Diptych Prompting, a new method for generating images from text prompts while maintaining accurate subject alignment. Unlike traditional methods that require extensive fine-tuning, this zero-shot approach treats the task as inpainting, using a diptych format with a reference image. By focusing on the left panel for the reference and performing text-conditioned inpainting on the right, the method enhances detail and prevents unwanted content from leaking into the generated image. The results show that Diptych Prompting not only improves visual quality but also allows for versatile applications in stylized image generation and editing."
                },
                "zh": {
                    "title": "Diptych Prompting：精准的主题驱动图像生成新方法",
                    "desc": "本文提出了一种新的零-shot方法，称为Diptych Prompting，旨在实现主题驱动的文本到图像生成。该方法通过将生成任务重新解释为图像修补，确保了主题的精确对齐。Diptych Prompting利用大型文本到图像模型的双联生成特性，左侧面板展示参考图像，右侧面板进行文本条件的修补。实验结果表明，该方法在视觉效果上优于传统的零-shot图像提示方法，且支持多种图像生成应用。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.15138",
            "title": "Material Anything: Generating Materials for Any 3D Object via Diffusion",
            "url": "https://huggingface.co/papers/2411.15138",
            "abstract": "We present Material Anything, a fully-automated, unified diffusion framework designed to generate physically-based materials for 3D objects. Unlike existing methods that rely on complex pipelines or case-specific optimizations, Material Anything offers a robust, end-to-end solution adaptable to objects under diverse lighting conditions. Our approach leverages a pre-trained image diffusion model, enhanced with a triple-head architecture and rendering loss to improve stability and material quality. Additionally, we introduce confidence masks as a dynamic switcher within the diffusion model, enabling it to effectively handle both textured and texture-less objects across varying lighting conditions. By employing a progressive material generation strategy guided by these confidence masks, along with a UV-space material refiner, our method ensures consistent, UV-ready material outputs. Extensive experiments demonstrate our approach outperforms existing methods across a wide range of object categories and lighting conditions.",
            "score": 8,
            "issue_id": 776,
            "pub_date": "2024-11-22",
            "pub_date_card": {
                "ru": "22 ноября",
                "en": "November 22",
                "zh": "11月22日"
            },
            "hash": "34b8f6718115f1e3",
            "authors": [
                "Xin Huang",
                "Tengfei Wang",
                "Ziwei Liu",
                "Qing Wang"
            ],
            "affiliations": [
                "Northwestern Polytechnical University",
                "S-Lab, Nanyang Technological University",
                "Shanghai AI Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.15138.jpg",
            "data": {
                "categories": [
                    "#3d",
                    "#architecture",
                    "#optimization",
                    "#diffusion"
                ],
                "emoji": "🎨",
                "ru": {
                    "title": "Универсальная генерация материалов для 3D-объектов с помощью диффузии",
                    "desc": "В статье представлен Material Anything - полностью автоматизированный унифицированный фреймворк диффузии для генерации физически корректных материалов для 3D-объектов. В отличие от существующих методов, он предлагает надежное сквозное решение, адаптируемое к объектам в различных условиях освещения. Подход использует предобученную модель диффузии изображений с тройной архитектурой и функцией потерь рендеринга для улучшения стабильности и качества материалов. Также вводятся маски уверенности как динамический переключатель в модели диффузии, позволяющий эффективно обрабатывать объекты с текстурами и без них в различных условиях освещения."
                },
                "en": {
                    "title": "Automating Realistic Material Generation for 3D Objects",
                    "desc": "Material Anything is a novel framework that automates the generation of realistic materials for 3D objects using a unified diffusion approach. It simplifies the material creation process by eliminating the need for complex workflows and optimizations tailored to specific cases. The framework utilizes a pre-trained image diffusion model, enhanced with a triple-head architecture and rendering loss, to ensure high-quality and stable material outputs. By incorporating confidence masks, it dynamically adapts to different object types and lighting scenarios, resulting in consistent and UV-ready materials across various conditions."
                },
                "zh": {
                    "title": "全自动材料生成，适应多种光照条件",
                    "desc": "本文介绍了一种名为Material Anything的全自动统一扩散框架，旨在为3D物体生成基于物理的材料。与现有方法依赖复杂流程或特定优化不同，Material Anything提供了一种稳健的端到端解决方案，适应不同光照条件下的物体。我们的方法利用了预训练的图像扩散模型，并通过三头架构和渲染损失来提高稳定性和材料质量。此外，我们引入了置信掩码作为扩散模型中的动态切换器，使其能够有效处理有纹理和无纹理的物体。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16594",
            "title": "From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge",
            "url": "https://huggingface.co/papers/2411.16594",
            "abstract": "Assessment and evaluation have long been critical challenges in artificial intelligence (AI) and natural language processing (NLP). However, traditional methods, whether matching-based or embedding-based, often fall short of judging subtle attributes and delivering satisfactory results. Recent advancements in Large Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs are leveraged to perform scoring, ranking, or selection across various tasks and applications. This paper provides a comprehensive survey of LLM-based judgment and assessment, offering an in-depth overview to advance this emerging field. We begin by giving detailed definitions from both input and output perspectives. Then we introduce a comprehensive taxonomy to explore LLM-as-a-judge from three dimensions: what to judge, how to judge and where to judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and highlight key challenges and promising directions, aiming to provide valuable insights and inspire future research in this promising research area. Paper list and more resources about LLM-as-a-judge can be found at https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge and https://llm-as-a-judge.github.io.",
            "score": 4,
            "issue_id": 778,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "56883eb77dcb5fa3",
            "authors": [
                "Dawei Li",
                "Bohan Jiang",
                "Liangjie Huang",
                "Alimohammad Beigi",
                "Chengshuai Zhao",
                "Zhen Tan",
                "Amrita Bhattacharjee",
                "Yuxuan Jiang",
                "Canyu Chen",
                "Tianhao Wu",
                "Kai Shu",
                "Lu Cheng",
                "Huan Liu"
            ],
            "affiliations": [
                "Arizona State University",
                "Emory University",
                "Illinois Institute of Technology",
                "University of California, Berkeley",
                "University of Illinois Chicago",
                "University of Maryland, Baltimore County"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.16594.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#multimodal",
                    "#survey"
                ],
                "emoji": "⚖️",
                "ru": {
                    "title": "LLM как судья: новая парадигма оценки в AI и NLP",
                    "desc": "Статья представляет собой обзор использования больших языковых моделей (LLM) в качестве судей для оценки и ранжирования в задачах искусственного интеллекта и обработки естественного языка. Авторы предлагают подробную таксономию подхода 'LLM-as-a-judge', рассматривая что, как и где оценивать. В работе также представлены бенчмарки для оценки эффективности LLM в роли судей. Статья завершается обсуждением ключевых проблем и перспективных направлений исследований в этой области."
                },
                "en": {
                    "title": "Harnessing LLMs for Enhanced AI Evaluation",
                    "desc": "This paper discusses the challenges of assessment and evaluation in artificial intelligence and natural language processing, particularly focusing on the limitations of traditional methods. It introduces the innovative concept of using Large Language Models (LLMs) as judges to score, rank, or select outputs in various tasks. The authors provide a detailed framework that categorizes LLM-based judgment into three key areas: what to judge, how to judge, and where to judge. Additionally, the paper compiles benchmarks for evaluating these models and identifies future research directions to enhance the effectiveness of LLMs in assessment tasks."
                },
                "zh": {
                    "title": "大型语言模型：评判的新力量",
                    "desc": "本论文探讨了大型语言模型（LLM）在评估和判断中的应用，提出了“LLM作为评判者”的新范式。传统的评估方法往往无法有效判断细微的属性，而LLM能够在多种任务中进行打分、排名和选择。我们从输入和输出的角度详细定义了评判的概念，并建立了一个全面的分类法，探讨了评判的内容、方式和场所。最后，我们编制了评估LLM作为评判者的基准，并强调了关键挑战和未来研究的方向。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14522",
            "title": "GMAI-VL & GMAI-VL-5.5M: A Large Vision-Language Model and A Comprehensive Multimodal Dataset Towards General Medical AI",
            "url": "https://huggingface.co/papers/2411.14522",
            "abstract": "Despite significant advancements in general artificial intelligence, such as GPT-4, their effectiveness in the medical domain (general medical AI, GMAI) remains constrained due to the absence of specialized medical knowledge. To address this challenge, we present GMAI-VL-5.5M, a comprehensive multimodal medical dataset created by converting hundreds of specialized medical datasets into meticulously constructed image-text pairs. This dataset features comprehensive task coverage, diverse modalities, and high-quality image-text data. Building upon this multimodal dataset, we propose GMAI-VL, a general medical vision-language model with a progressively three-stage training strategy. This approach significantly enhances the model's ability by integrating visual and textual information, thereby improving its ability to process multimodal data and support accurate diagnosis and clinical decision-making. Experimental evaluations demonstrate that GMAI-VL achieves state-of-the-art results across a wide range of multimodal medical tasks, such as visual question answering and medical image diagnosis. Our contributions include the development of the GMAI-VL-5.5M dataset, the introduction of the GMAI-VL model, and the establishment of new benchmarks in multiple medical domains. Code and dataset will be released at https://github.com/uni-medical/GMAI-VL.",
            "score": 4,
            "issue_id": 778,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "eb0e262f1661d5c8",
            "authors": [
                "Tianbin Li",
                "Yanzhou Su",
                "Wei Li",
                "Bin Fu",
                "Zhe Chen",
                "Ziyan Huang",
                "Guoan Wang",
                "Chenglong Ma",
                "Ying Chen",
                "Ming Hu",
                "Yanjun Li",
                "Pengcheng Chen",
                "Xiaowei Hu",
                "Zhongying Deng",
                "Yuanfeng Ji",
                "Jin Ye",
                "Yu Qiao",
                "Junjun He"
            ],
            "affiliations": [
                "East China Normal University",
                "Fudan University",
                "Monash University",
                "Nanjing University",
                "Shanghai AI Laboratory",
                "Shanghai Jiao Tong University",
                "Shenzhen Institute of Advanced Technology (SIAT), Chinese Academy of Sciences",
                "Stanford University",
                "University of Cambridge",
                "University of Washington",
                "Xiamen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14522.jpg",
            "data": {
                "categories": [
                    "#agi",
                    "#benchmark",
                    "#multimodal",
                    "#optimization",
                    "#science",
                    "#healthcare",
                    "#dataset"
                ],
                "emoji": "🏥",
                "ru": {
                    "title": "GMAI-VL: Мощная мультимодальная модель для медицинского ИИ",
                    "desc": "Исследователи представили GMAI-VL-5.5M - обширный мультимодальный медицинский датасет, созданный путем преобразования сотен специализированных медицинских наборов данных в пары изображение-текст. На основе этого датасета была разработана модель GMAI-VL - общая медицинская модель компьютерного зрения и обработки естественного языка, обученная по трехэтапной стратегии. GMAI-VL достигает передовых результатов в широком спектре мультимодальных медицинских задач, таких как визуальные вопросно-ответные системы и диагностика медицинских изображений. Работа вносит вклад в развитие искусственного интеллекта в медицине, предоставляя новый датасет, модель и бенчмарки."
                },
                "en": {
                    "title": "Empowering Medical AI with Multimodal Learning",
                    "desc": "This paper introduces GMAI-VL-5.5M, a new multimodal medical dataset designed to enhance general medical AI (GMAI) by combining various specialized medical datasets into image-text pairs. The dataset supports a wide range of medical tasks and includes high-quality data that improves the model's understanding of both visual and textual information. The authors propose a three-stage training strategy for the GMAI-VL model, which significantly boosts its performance in tasks like visual question answering and medical image diagnosis. Experimental results show that GMAI-VL sets new benchmarks in the medical domain, demonstrating its effectiveness in aiding clinical decision-making."
                },
                "zh": {
                    "title": "医学领域的多模态智能突破",
                    "desc": "尽管通用人工智能（如GPT-4）取得了显著进展，但在医学领域的有效性仍然受到限制，因为缺乏专业的医学知识。为了解决这个问题，我们提出了GMAI-VL-5.5M，这是一个通过将数百个专业医学数据集转换为精心构建的图像-文本对而创建的综合多模态医学数据集。基于这个多模态数据集，我们提出了GMAI-VL，一个具有逐步三阶段训练策略的通用医学视觉-语言模型。实验评估表明，GMAI-VL在视觉问答和医学图像诊断等多种多模态医学任务中达到了最先进的结果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16657",
            "title": "DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation",
            "url": "https://huggingface.co/papers/2411.16657",
            "abstract": "Storytelling video generation (SVG) has recently emerged as a task to create long, multi-motion, multi-scene videos that consistently represent the story described in the input text script. SVG holds great potential for diverse content creation in media and entertainment; however, it also presents significant challenges: (1) objects must exhibit a range of fine-grained, complex motions, (2) multiple objects need to appear consistently across scenes, and (3) subjects may require multiple motions with seamless transitions within a single scene. To address these challenges, we propose DreamRunner, a novel story-to-video generation method: First, we structure the input script using a large language model (LLM) to facilitate both coarse-grained scene planning as well as fine-grained object-level layout and motion planning. Next, DreamRunner presents retrieval-augmented test-time adaptation to capture target motion priors for objects in each scene, supporting diverse motion customization based on retrieved videos, thus facilitating the generation of new videos with complex, scripted motions. Lastly, we propose a novel spatial-temporal region-based 3D attention and prior injection module SR3AI for fine-grained object-motion binding and frame-by-frame semantic control. We compare DreamRunner with various SVG baselines, demonstrating state-of-the-art performance in character consistency, text alignment, and smooth transitions. Additionally, DreamRunner exhibits strong fine-grained condition-following ability in compositional text-to-video generation, significantly outperforming baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to generate multi-object interactions with qualitative examples.",
            "score": 4,
            "issue_id": 777,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "02cf3312e8d1f6ca",
            "authors": [
                "Zun Wang",
                "Jialu Li",
                "Han Lin",
                "Jaehong Yoon",
                "Mohit Bansal"
            ],
            "affiliations": [
                "UNC Chapel Hill"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.16657.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#3d",
                    "#video",
                    "#story_generation"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "DreamRunner: От сценария к видео с помощью ИИ",
                    "desc": "DreamRunner - это новый метод генерации видео по текстовому сценарию, который использует большую языковую модель для структурирования входных данных. Он применяет адаптацию на основе извлечения информации для захвата целевых движений объектов в каждой сцене. DreamRunner также предлагает новый модуль пространственно-временного 3D-внимания и внедрения приоров для точного связывания объектов и движений. Метод демонстрирует передовые результаты в согласованности персонажей, соответствии тексту и плавных переходах."
                },
                "en": {
                    "title": "DreamRunner: Crafting Seamless Storytelling Videos from Text",
                    "desc": "This paper introduces DreamRunner, a new method for generating storytelling videos from text scripts. It addresses challenges in creating complex motions and maintaining object consistency across scenes by using a large language model for scene planning and a retrieval-augmented approach for motion customization. The method incorporates a novel spatial-temporal region-based attention module to ensure precise object-motion binding and semantic control in video frames. DreamRunner outperforms existing models in character consistency and smooth transitions, showcasing its effectiveness in generating multi-object interactions and adhering to compositional text prompts."
                },
                "zh": {
                    "title": "DreamRunner：创新的故事视频生成方法",
                    "desc": "故事视频生成（SVG）是一项新兴任务，旨在根据输入文本脚本创建长篇、多动作、多场景的视频。该方法面临着多个挑战，包括对象需要展现复杂的细微动作，以及多个对象在不同场景中的一致性。为了解决这些问题，我们提出了DreamRunner，这是一种新颖的故事到视频生成方法，利用大型语言模型（LLM）进行场景规划和对象布局。DreamRunner还引入了空间-时间区域基础的3D注意力机制，能够实现细粒度的对象动作绑定和逐帧语义控制，展现出在角色一致性和文本对齐方面的先进性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14486",
            "title": "The Impossible Test: A 2024 Unsolvable Dataset and A Chance for an AGI Quiz",
            "url": "https://huggingface.co/papers/2411.14486",
            "abstract": "This research introduces a novel evaluation framework designed to assess large language models' (LLMs) ability to acknowledge uncertainty on 675 fundamentally unsolvable problems. Using a curated dataset of graduate-level grand challenge questions with intentionally unknowable answers, we evaluated twelve state-of-the-art LLMs, including both open and closed-source models, on their propensity to admit ignorance rather than generate plausible but incorrect responses. The best models scored in 62-68% accuracy ranges for admitting the problem solution was unknown in fields ranging from biology to philosophy and mathematics. We observed an inverse relationship between problem difficulty and model accuracy, with GPT-4 demonstrating higher rates of uncertainty acknowledgment on more challenging problems (35.8%) compared to simpler ones (20.0%). This pattern indicates that models may be more prone to generate speculative answers when problems appear more tractable. The study also revealed significant variations across problem categories, with models showing difficulty in acknowledging uncertainty in invention and NP-hard problems while performing relatively better on philosophical and psychological challenges. These results contribute to the growing body of research on artificial general intelligence (AGI) assessment by highlighting the importance of uncertainty recognition as a critical component of future machine intelligence evaluation. This impossibility test thus extends previous theoretical frameworks for universal intelligence testing by providing empirical evidence of current limitations in LLMs' ability to recognize their own knowledge boundaries, suggesting new directions for improving model training architectures and evaluation approaches.",
            "score": 3,
            "issue_id": 777,
            "pub_date": "2024-11-20",
            "pub_date_card": {
                "ru": "20 ноября",
                "en": "November 20",
                "zh": "11月20日"
            },
            "hash": "c30a94b30cace49a",
            "authors": [
                "David Noever",
                "Forrest McKee"
            ],
            "affiliations": [
                "PeopleTec, Inc., Huntsville, AL"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14486.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#benchmark",
                    "#interpretability",
                    "#agi",
                    "#dataset"
                ],
                "emoji": "🤔",
                "ru": {
                    "title": "Признание незнания: ключевой аспект оценки искусственного интеллекта",
                    "desc": "Это исследование представляет новую систему оценки способности больших языковых моделей (LLM) признавать неопределенность на 675 принципиально нерешаемых проблемах. Двенадцать современных LLM были оценены на их склонность признавать незнание, а не генерировать правдоподобные, но неверные ответы. Лучшие модели показали точность 62-68% в признании неизвестности решения проблемы в различных областях. Исследование выявило обратную зависимость между сложностью проблемы и точностью модели, а также значительные различия между категориями проблем."
                },
                "en": {
                    "title": "Evaluating Uncertainty: A New Benchmark for Language Models",
                    "desc": "This research presents a new framework to evaluate how well large language models (LLMs) recognize their own uncertainty when faced with unsolvable problems. By testing twelve advanced LLMs on a set of graduate-level questions that have no answers, the study found that the best models could admit ignorance 62-68% of the time. Interestingly, the models were more likely to acknowledge uncertainty on harder problems, with GPT-4 showing a 35.8% acknowledgment rate on difficult questions. The findings emphasize the need for better training and evaluation methods to enhance LLMs' ability to recognize their knowledge limits, which is crucial for advancing artificial general intelligence (AGI)."
                },
                "zh": {
                    "title": "承认不确定性：评估大型语言模型的新视角",
                    "desc": "本研究提出了一种新的评估框架，用于评估大型语言模型（LLMs）在675个根本无法解决的问题上承认不确定性的能力。我们使用了一组经过精心挑选的研究生级别的重大挑战问题数据集，评估了包括开源和闭源模型在内的十二个最先进的LLMs，观察它们承认无知的倾向。结果显示，最佳模型在承认问题解决方案未知的准确率范围为62%到68%，并且在更具挑战性的问题上（如生物学、哲学和数学）表现出更高的不确定性承认率。研究还发现，不同问题类别之间存在显著差异，模型在承认发明和NP难题的不确定性时表现较差，而在哲学和心理学挑战中表现相对较好。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16443",
            "title": "SplatFlow: Multi-View Rectified Flow Model for 3D Gaussian Splatting Synthesis",
            "url": "https://huggingface.co/papers/2411.16443",
            "abstract": "Text-based generation and editing of 3D scenes hold significant potential for streamlining content creation through intuitive user interactions. While recent advances leverage 3D Gaussian Splatting (3DGS) for high-fidelity and real-time rendering, existing methods are often specialized and task-focused, lacking a unified framework for both generation and editing. In this paper, we introduce SplatFlow, a comprehensive framework that addresses this gap by enabling direct 3DGS generation and editing. SplatFlow comprises two main components: a multi-view rectified flow (RF) model and a Gaussian Splatting Decoder (GSDecoder). The multi-view RF model operates in latent space, generating multi-view images, depths, and camera poses simultaneously, conditioned on text prompts, thus addressing challenges like diverse scene scales and complex camera trajectories in real-world settings. Then, the GSDecoder efficiently translates these latent outputs into 3DGS representations through a feed-forward 3DGS method. Leveraging training-free inversion and inpainting techniques, SplatFlow enables seamless 3DGS editing and supports a broad range of 3D tasks-including object editing, novel view synthesis, and camera pose estimation-within a unified framework without requiring additional complex pipelines. We validate SplatFlow's capabilities on the MVImgNet and DL3DV-7K datasets, demonstrating its versatility and effectiveness in various 3D generation, editing, and inpainting-based tasks.",
            "score": 2,
            "issue_id": 779,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "8447f5d110a89105",
            "authors": [
                "Hyojun Go",
                "Byeongjun Park",
                "Jiho Jang",
                "Jin-Young Kim",
                "Soonwoo Kwon",
                "Changick Kim"
            ],
            "affiliations": [
                "KAIST",
                "Twelve Labs"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.16443.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "🎨",
                "ru": {
                    "title": "Универсальная система для интуитивного создания и редактирования 3D-сцен",
                    "desc": "SplatFlow - это комплексная система для генерации и редактирования 3D-сцен на основе текстовых запросов. Она состоит из двух основных компонентов: многоракурсной модели выпрямленного потока и декодера гауссовского сплаттинга. Система позволяет генерировать многоракурсные изображения, карты глубины и положения камер одновременно, а затем эффективно преобразовывать их в 3D-представления. SplatFlow поддерживает широкий спектр задач 3D-моделирования, включая редактирование объектов, синтез новых ракурсов и оценку положения камеры, в рамках единой системы."
                },
                "en": {
                    "title": "SplatFlow: Unifying 3D Scene Generation and Editing",
                    "desc": "This paper presents SplatFlow, a unified framework for generating and editing 3D scenes using 3D Gaussian Splatting (3DGS). It features a multi-view rectified flow model that generates images, depths, and camera poses from text prompts, addressing challenges in scene diversity and camera movement. The framework also includes a Gaussian Splatting Decoder that converts latent outputs into 3DGS representations efficiently. SplatFlow supports various 3D tasks like object editing and novel view synthesis, demonstrating its effectiveness on multiple datasets without the need for complex pipelines."
                },
                "zh": {
                    "title": "SplatFlow：统一的3D生成与编辑框架",
                    "desc": "本文介绍了一种名为SplatFlow的综合框架，旨在简化3D场景的生成和编辑。SplatFlow结合了多视角整流流模型和高斯点云解码器，能够根据文本提示同时生成多视角图像、深度和相机姿态。该框架通过无训练反演和修补技术，实现了无缝的3D高斯点云编辑，支持多种3D任务，如物体编辑和新视角合成。我们在MVImgNet和DL3DV-7K数据集上验证了SplatFlow的能力，展示了其在多种3D生成和编辑任务中的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16205",
            "title": "MH-MoE:Multi-Head Mixture-of-Experts",
            "url": "https://huggingface.co/papers/2411.16205",
            "abstract": "Multi-Head Mixture-of-Experts (MH-MoE) demonstrates superior performance by using the multi-head mechanism to collectively attend to information from various representation spaces within different experts. In this paper, we present a novel implementation of MH-MoE that maintains both FLOPs and parameter parity with sparse Mixture of Experts models. Experimental results on language models show that the new implementation yields quality improvements over both vanilla MoE and fine-grained MoE models. Additionally, our experiments demonstrate that MH-MoE is compatible with 1-bit Large Language Models (LLMs) such as BitNet.",
            "score": 2,
            "issue_id": 778,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "b684b6d745cb66ff",
            "authors": [
                "Shaohan Huang",
                "Xun Wu",
                "Shuming Ma",
                "Furu Wei"
            ],
            "affiliations": [
                "Microsoft Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.16205.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#architecture"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Мультиголовая смесь экспертов: эффективность без компромиссов",
                    "desc": "Статья представляет новую реализацию мультиголовой смеси экспертов (MH-MoE), которая сохраняет паритет по FLOP и параметрам с разреженными моделями смеси экспертов. Эксперименты на языковых моделях показывают, что новая реализация улучшает качество по сравнению с обычными MoE и мелкозернистыми MoE моделями. MH-MoE использует механизм мультиголовности для совместного внимания к информации из различных пространств представлений в разных экспертах. Исследование также демонстрирует совместимость MH-MoE с 1-битными большими языковыми моделями, такими как BitNet."
                },
                "en": {
                    "title": "Unlocking Performance with Multi-Head Mixture-of-Experts",
                    "desc": "The Multi-Head Mixture-of-Experts (MH-MoE) model enhances performance by allowing multiple heads to focus on different aspects of data from various experts. This paper introduces a new way to implement MH-MoE that keeps the same computational cost and number of parameters as traditional sparse Mixture of Experts models. Experiments conducted on language models reveal that this new approach provides better results compared to standard MoE and fine-grained MoE models. Furthermore, the findings indicate that MH-MoE can effectively work with 1-bit Large Language Models like BitNet."
                },
                "zh": {
                    "title": "多头混合专家：提升模型性能的新方法",
                    "desc": "多头混合专家模型（MH-MoE）通过多头机制，能够同时关注来自不同专家的多种表示空间的信息，从而展现出优越的性能。本文提出了一种新颖的MH-MoE实现，能够在计算量（FLOPs）和参数数量上与稀疏混合专家模型保持一致。实验结果表明，该新实现相较于传统的MoE和细粒度MoE模型在语言模型上有显著的质量提升。此外，我们的实验还表明MH-MoE与1位大语言模型（如BitNet）兼容。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16341",
            "title": "From CISC to RISC: language-model guided assembly transpilation",
            "url": "https://huggingface.co/papers/2411.16341",
            "abstract": "The transition from x86 to ARM architecture is becoming increasingly common across various domains, primarily driven by ARM's energy efficiency and improved performance across traditional sectors. However, this ISA shift poses significant challenges, mainly due to the extensive legacy ecosystem of x86 software and lack of portability across proprietary ecosystems and software stacks. This paper introduces CRT, a lightweight LLM-based transpiler that automatically converts x86 assembly to ARM assembly. Our approach bridges the fundamental architectural gap between x86's CISC-based and ARM's RISC-based computing paradigms while preserving program semantics and optimizing performance. We evaluate CRT on diverse real-world applications, achieving 79.25% translation accuracy from x86 to ARMv5 on our comprehensive test suite, and an 88.68% accuracy from x86 to RISC-V. In practical deployments on Apple M2 hardware (ARMv8), our transpiled code achieves 1.73times speedup compared to Apple's Rosetta 2 virtualization engine, while delivering 2.41times memory efficiency and 1.47times better energy consumption. Through testing and analysis, we show that CRT successfully navigates the CISC/RISC divide and generates correctly executable RISC code despite machine ``language'' barriers. We release our code, models, training datasets, and benchmarks at: https://ahmedheakl.github.io/asm2asm/.",
            "score": 2,
            "issue_id": 778,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "1d28eaae89074f91",
            "authors": [
                "Ahmed Heakl",
                "Chaimaa Abi",
                "Rania Hossam",
                "Abdulrahman Mahmoud"
            ],
            "affiliations": [
                "Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.16341.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#dataset",
                    "#architecture",
                    "#benchmark"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Преодоление барьера CISC/RISC: автоматическая трансляция x86 в ARM с помощью ИИ",
                    "desc": "Статья представляет CRT - лёгкий транспилятор на основе большой языковой модели, который автоматически конвертирует ассемблерный код x86 в ассемблер ARM. Этот подход преодолевает фундаментальный архитектурный разрыв между вычислительными парадигмами CISC (x86) и RISC (ARM), сохраняя семантику программ и оптимизируя производительность. Авторы оценивают CRT на различных реальных приложениях, достигая 79.25% точности перевода с x86 на ARMv5. В практических развертываниях на оборудовании Apple M2 (ARMv8) транспилированный код достигает ускорения в 1.73 раза по сравнению с виртуализационным движком Apple Rosetta 2."
                },
                "en": {
                    "title": "Bridging the CISC/RISC Divide with CRT Transpiler",
                    "desc": "This paper presents CRT, a lightweight LLM-based transpiler designed to convert x86 assembly code into ARM assembly code. The transition from x86 to ARM architecture is challenging due to the differences in their instruction set architectures (ISAs), specifically x86's Complex Instruction Set Computing (CISC) and ARM's Reduced Instruction Set Computing (RISC). CRT effectively bridges this gap while maintaining the original program's functionality and optimizing performance. The evaluation shows that CRT achieves high translation accuracy and outperforms existing solutions in terms of speed, memory efficiency, and energy consumption on ARM hardware."
                },
                "zh": {
                    "title": "轻松跨越架构鸿沟，提升性能与效率",
                    "desc": "本论文介绍了一种名为CRT的轻量级LLM基础的转译器，能够自动将x86汇编代码转换为ARM汇编代码。该方法解决了x86的复杂指令集（CISC）与ARM的精简指令集（RISC）之间的架构差异，同时保持程序语义并优化性能。通过在真实应用上的评估，CRT在x86到ARMv5的转换准确率达到79.25%，在x86到RISC-V的转换准确率达到88.68%。在Apple M2硬件上的实际部署中，转译后的代码相比于Apple的Rosetta 2虚拟化引擎实现了1.73倍的速度提升和2.41倍的内存效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.15671",
            "title": "Best of Both Worlds: Advantages of Hybrid Graph Sequence Models",
            "url": "https://huggingface.co/papers/2411.15671",
            "abstract": "Modern sequence models (e.g., Transformers, linear RNNs, etc.) emerged as dominant backbones of recent deep learning frameworks, mainly due to their efficiency, representational power, and/or ability to capture long-range dependencies. Adopting these sequence models for graph-structured data has recently gained popularity as the alternative to Message Passing Neural Networks (MPNNs). There is, however, a lack of a common foundation about what constitutes a good graph sequence model, and a mathematical description of the benefits and deficiencies in adopting different sequence models for learning on graphs. To this end, we first present Graph Sequence Model (GSM), a unifying framework for adopting sequence models for graphs, consisting of three main steps: (1) Tokenization, which translates the graph into a set of sequences; (2) Local Encoding, which encodes local neighborhoods around each node; and (3) Global Encoding, which employs a scalable sequence model to capture long-range dependencies within the sequences. This framework allows us to understand, evaluate, and compare the power of different sequence model backbones in graph tasks. Our theoretical evaluations of the representation power of Transformers and modern recurrent models through the lens of global and local graph tasks show that there are both negative and positive sides for both types of models. Building on this observation, we present GSM++, a fast hybrid model that uses the Hierarchical Affinity Clustering (HAC) algorithm to tokenize the graph into hierarchical sequences, and then employs a hybrid architecture of Transformer to encode these sequences. Our theoretical and experimental results support the design of GSM++, showing that GSM++ outperforms baselines in most benchmark evaluations.",
            "score": 1,
            "issue_id": 779,
            "pub_date": "2024-11-23",
            "pub_date_card": {
                "ru": "23 ноября",
                "en": "November 23",
                "zh": "11月23日"
            },
            "hash": "540358181ae0274e",
            "authors": [
                "Ali Behrouz",
                "Ali Parviz",
                "Mahdi Karami",
                "Clayton Sanford",
                "Bryan Perozzi",
                "Vahab Mirrokni"
            ],
            "affiliations": [
                "Google Research",
                "New Jersey Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.15671.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#math",
                    "#architecture",
                    "#benchmark",
                    "#graphs"
                ],
                "emoji": "🕸️",
                "ru": {
                    "title": "Унифицированный подход к обработке графов с помощью последовательностных моделей",
                    "desc": "Статья представляет унифицированный фреймворк Graph Sequence Model (GSM) для применения последовательностных моделей к графовым данным. GSM состоит из трех этапов: токенизация графа в набор последовательностей, локальное кодирование окрестностей узлов и глобальное кодирование для захвата дальних зависимостей. Авторы теоретически оценивают репрезентативную мощность трансформеров и современных рекуррентных моделей для графовых задач. На основе этого анализа предлагается гибридная модель GSM++, использующая иерархическую кластеризацию для токенизации и архитектуру трансформера для кодирования."
                },
                "en": {
                    "title": "Unifying Sequence Models for Enhanced Graph Learning",
                    "desc": "This paper introduces the Graph Sequence Model (GSM), a framework that integrates sequence models with graph-structured data. It consists of three steps: tokenization of graphs into sequences, local encoding of node neighborhoods, and global encoding to capture long-range dependencies. The authors evaluate the strengths and weaknesses of different sequence models, particularly Transformers and recurrent models, in graph tasks. They also propose GSM++, a hybrid model that enhances performance by using hierarchical tokenization and a Transformer architecture, demonstrating superior results in benchmark tests."
                },
                "zh": {
                    "title": "图序列模型：结合序列与图的力量",
                    "desc": "现代序列模型（如变换器和线性递归神经网络）在深度学习框架中占据主导地位，因其高效性、表示能力和捕捉长距离依赖的能力。将这些序列模型应用于图结构数据的研究逐渐受到关注，作为消息传递神经网络（MPNNs）的替代方案。本文提出了图序列模型（GSM），这是一个统一框架，包含图的标记化、局部编码和全局编码三个主要步骤。我们还提出了GSM++，一种快速混合模型，利用层次亲和聚类算法对图进行分层序列标记，并采用变换器的混合架构进行编码，实验结果表明GSM++在大多数基准评估中优于其他模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16035",
            "title": "Predicting Emergent Capabilities by Finetuning",
            "url": "https://huggingface.co/papers/2411.16035",
            "abstract": "A fundamental open challenge in modern LLM scaling is the lack of understanding around emergent capabilities. In particular, language model pretraining loss is known to be highly predictable as a function of compute. However, downstream capabilities are far less predictable -- sometimes even exhibiting emergent jumps -- which makes it challenging to anticipate the capabilities of future models. In this work, we first pose the task of emergence prediction: given access to current LLMs that have random few-shot accuracy on a task, can we predict whether future models (GPT-N+1) will have non-trivial accuracy on that task? We then discover a simple insight for this problem: finetuning LLMs on a given task can shift the point in scaling at which emergence occurs towards less capable models. To operationalize this insight, we can finetune LLMs with varying amounts of data and fit a parametric function that predicts when emergence will occur (i.e., \"emergence laws\"). We validate this approach using four standard NLP benchmarks where large-scale open-source LLMs already demonstrate emergence (MMLU, GSM8K, CommonsenseQA, and CoLA). Using only small-scale LLMs, we find that, in some cases, we can accurately predict whether models trained with up to 4x more compute have emerged. Finally, we present a case study of two realistic uses for emergence prediction.",
            "score": 1,
            "issue_id": 779,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "a3e818d78a8bea58",
            "authors": [
                "Charlie Snell",
                "Eric Wallace",
                "Dan Klein",
                "Sergey Levine"
            ],
            "affiliations": [
                "University of California, Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.16035.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#agi",
                    "#benchmark",
                    "#open_source"
                ],
                "emoji": "🔮",
                "ru": {
                    "title": "Предсказание будущего ИИ: раскрытие тайн эмерджентности в языковых моделях",
                    "desc": "Статья посвящена проблеме предсказания возникновения новых способностей у крупномасштабных языковых моделей (LLM). Авторы предлагают метод предсказания эмерджентности, основанный на дообучении моделей на конкретных задачах. Они обнаружили, что дообучение может сдвинуть точку возникновения эмерджентности в сторону менее мощных моделей. Используя этот подход, исследователи смогли точно предсказать эмерджентность для моделей, обученных с использованием в 4 раза больше вычислительных ресурсов."
                },
                "en": {
                    "title": "Predicting Emergence: Unlocking Future LLM Capabilities",
                    "desc": "This paper addresses the challenge of predicting emergent capabilities in large language models (LLMs) as they scale. While the pretraining loss of LLMs is predictable based on compute resources, their downstream performance can show unexpected jumps in capability. The authors introduce the concept of emergence prediction, which involves fine-tuning LLMs on specific tasks to determine when these emergent capabilities will appear. They validate their approach using standard NLP benchmarks and demonstrate that it is possible to predict the emergence of capabilities in future models based on the performance of smaller models."
                },
                "zh": {
                    "title": "预测语言模型能力的突破",
                    "desc": "本研究探讨了大型语言模型（LLM）在扩展时出现的能力预测问题。我们发现，通过对特定任务进行微调，可以提前预测未来模型在该任务上的表现。研究表明，微调可以将能力出现的临界点向能力较低的模型移动。我们在多个自然语言处理基准上验证了这一方法，并展示了如何利用这一预测能力进行实际应用。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.14525",
            "title": "SegBook: A Simple Baseline and Cookbook for Volumetric Medical Image Segmentation",
            "url": "https://huggingface.co/papers/2411.14525",
            "abstract": "Computed Tomography (CT) is one of the most popular modalities for medical imaging. By far, CT images have contributed to the largest publicly available datasets for volumetric medical segmentation tasks, covering full-body anatomical structures. Large amounts of full-body CT images provide the opportunity to pre-train powerful models, e.g., STU-Net pre-trained in a supervised fashion, to segment numerous anatomical structures. However, it remains unclear in which conditions these pre-trained models can be transferred to various downstream medical segmentation tasks, particularly segmenting the other modalities and diverse targets. To address this problem, a large-scale benchmark for comprehensive evaluation is crucial for finding these conditions. Thus, we collected 87 public datasets varying in modality, target, and sample size to evaluate the transfer ability of full-body CT pre-trained models. We then employed a representative model, STU-Net with multiple model scales, to conduct transfer learning across modalities and targets. Our experimental results show that (1) there may be a bottleneck effect concerning the dataset size in fine-tuning, with more improvement on both small- and large-scale datasets than medium-size ones. (2) Models pre-trained on full-body CT demonstrate effective modality transfer, adapting well to other modalities such as MRI. (3) Pre-training on the full-body CT not only supports strong performance in structure detection but also shows efficacy in lesion detection, showcasing adaptability across target tasks. We hope that this large-scale open evaluation of transfer learning can direct future research in volumetric medical image segmentation.",
            "score": 1,
            "issue_id": 778,
            "pub_date": "2024-11-21",
            "pub_date_card": {
                "ru": "21 ноября",
                "en": "November 21",
                "zh": "11月21日"
            },
            "hash": "eb68ad946d69ba56",
            "authors": [
                "Jin Ye",
                "Ying Chen",
                "Yanjun Li",
                "Haoyu Wang",
                "Zhongying Deng",
                "Ziyan Huang",
                "Yanzhou Su",
                "Chenglong Ma",
                "Yuanfeng Ji",
                "Junjun He"
            ],
            "affiliations": [
                "East China Normal University",
                "Shanghai AI Laboratory",
                "Stanford University",
                "University of Cambridge",
                "Xiamen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2411.14525.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#healthcare",
                    "#open_source",
                    "#training",
                    "#transfer_learning",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Универсальность предобученных КТ-моделей в медицинской сегментации",
                    "desc": "Статья посвящена исследованию переноса обучения моделей, предобученных на полноразмерных КТ-изображениях, на другие задачи сегментации медицинских изображений. Авторы создали масштабный бенчмарк из 87 публичных датасетов для оценки эффективности такого переноса. Результаты показывают, что предобученные модели хорошо адаптируются к другим модальностям (например, МРТ) и различным целевым задачам. Исследование выявило эффект 'бутылочного горлышка' в зависимости от размера датасета при тонкой настройке моделей."
                },
                "en": {
                    "title": "Unlocking Transfer Learning in Medical Imaging with CT Datasets",
                    "desc": "This paper investigates the transferability of models pre-trained on full-body CT images for various medical segmentation tasks. It highlights the effectiveness of the STU-Net model in adapting to different imaging modalities, such as MRI, and diverse anatomical targets. The study reveals that dataset size impacts fine-tuning performance, with both small and large datasets yielding better results than medium-sized ones. Overall, the findings emphasize the potential of using large-scale CT datasets to enhance model performance in medical image segmentation tasks."
                },
                "zh": {
                    "title": "全身CT预训练模型的迁移学习能力研究",
                    "desc": "计算机断层扫描（CT）是医学成像中最常用的技术之一。本文探讨了在不同条件下，基于全身CT预训练模型的迁移学习能力，特别是在其他成像模态和多样化目标的分割任务中。我们收集了87个公共数据集进行评估，结果表明，数据集大小对微调有瓶颈效应，且全身CT预训练模型在迁移到其他模态（如MRI）时表现良好。我们的研究希望为未来的体积医学图像分割研究提供指导。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2411.16085",
            "title": "Cautious Optimizers: Improving Training with One Line of Code",
            "url": "https://huggingface.co/papers/2411.16085",
            "abstract": "AdamW has been the default optimizer for transformer pretraining. For many years, our community searches for faster and more stable optimizers with only constraint positive outcomes. In this work, we propose a single-line modification in Pytorch to any momentum-based optimizer, which we rename Cautious Optimizer, e.g. C-AdamW and C-Lion. Our theoretical result shows that this modification preserves Adam's Hamiltonian function and it does not break the convergence guarantee under the Lyapunov analysis. In addition, a whole new family of optimizers is revealed by our theoretical insight. Among them, we pick the simplest one for empirical experiments, showing speed-up on Llama and MAE pretraining up to 1.47times. Code is available at https://github.com/kyleliang919/C-Optim",
            "score": 1,
            "issue_id": 777,
            "pub_date": "2024-11-25",
            "pub_date_card": {
                "ru": "25 ноября",
                "en": "November 25",
                "zh": "11月25日"
            },
            "hash": "48a2e1454fdde298",
            "authors": [
                "Kaizhao Liang",
                "Lizhang Chen",
                "Bo Liu",
                "Qiang Liu"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2411.16085.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Осторожная оптимизация: простое изменение, большой результат",
                    "desc": "Статья представляет модификацию оптимизаторов на основе импульса, названную Cautious Optimizer. Авторы предлагают простое изменение в коде PyTorch, которое сохраняет функцию Гамильтона для Adam и гарантирует сходимость по анализу Ляпунова. Теоретический анализ раскрывает целое семейство новых оптимизаторов. Эмпирические эксперименты показывают ускорение предобучения Llama и MAE до 1.47 раз."
                },
                "en": {
                    "title": "Cautious Optimizer: Speeding Up Transformer Pretraining!",
                    "desc": "This paper introduces a new optimizer called the Cautious Optimizer, which is a simple modification of existing momentum-based optimizers like AdamW and Lion. The modification preserves the Hamiltonian function of Adam, ensuring that the convergence properties remain intact according to Lyapunov stability analysis. The authors demonstrate that this new optimizer can significantly speed up the pretraining of models like Llama and MAE, achieving improvements of up to 1.47 times. Additionally, the research opens the door to a new family of optimizers, expanding the options available for machine learning practitioners."
                },
                "zh": {
                    "title": "提升变换器预训练速度的新优化器",
                    "desc": "本文提出了一种新的优化器，称为Cautious Optimizer，旨在提高变换器预训练的速度和稳定性。通过对现有的动量优化器进行简单的修改，我们的理论分析表明，这种修改保持了Adam的哈密顿函数，并且在Lyapunov分析下不破坏收敛性保证。我们还揭示了一系列新的优化器，并选择了其中最简单的进行实证实验，结果显示在Llama和MAE预训练中速度提升可达1.47倍。相关代码已在GitHub上发布。"
                }
            }
        }
    ],
    "link_prev": "2024-11-25.html",
    "link_next": "2024-11-27.html",
    "link_month": "2024-11.html",
    "short_date_prev": {
        "ru": "25.11",
        "en": "11/25",
        "zh": "11月25日"
    },
    "short_date_next": {
        "ru": "27.11",
        "en": "11/27",
        "zh": "11月27日"
    },
    "categories": {
        "#dataset": 4,
        "#data": 0,
        "#benchmark": 7,
        "#agents": 0,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 3,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 4,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 6,
        "#healthcare": 2,
        "#training": 5,
        "#robotics": 0,
        "#agi": 3,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 0,
        "#transfer_learning": 1,
        "#graphs": 1,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 7,
        "#survey": 1,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 1,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 3,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了大型扩散模型生成高质量图像，但难以学习新的个性化艺术风格。现有方法在微调时盲目使用预训练目标和噪声水平分布，导致风格对齐不佳。作者提出了风格友好的信噪比采样器，在微调时将信噪比分布偏向更高的噪声水平，以捕捉独特风格。这使模型能更好地生成具有高风格一致性的图像，并允许创建和共享新的风格模板。作者展示了生成水彩画、简笔画、3D渲染等多种风格的能力。",
        "title": "Style-Friendly SNR Sampler for Style-Driven Generation",
        "pinyin": "这篇文章讨论了大型扩散模型生成高质量图像，但难以学习新的个性化艺术风格。现有方法在微调时盲目使用预训练目标和噪声水平分布，导致风格对齐不佳。作者提出了风格友好的信噪比采样器，在微调时将信噪比分布偏向更高的噪声水平，以捕捉独特风格。这使模型能更好地生成具有高风格一致性的图像，并允许创建和共享新的风格模板。作者展示了生成水彩画、简笔画、3D渲染等多种风格的能力。\n\nzhè piān wén zhāng tǎo lùn le dà xíng kuò sàn mó xíng shēng chéng gāo zhì liàng tú xiàng, dàn nán yǐ xué xí xīn de gè xìng huà yì shù fēng gé. xiàn yǒu fāng fǎ zài wēi tiáo shí māng mù shǐ yòng yù xùn liàn mù biāo hé zào shēng shuǐ píng fēn bù, dǎo zhì fēng gé duì qí bù jiā. zuò zhě tí chū le fēng gé yǒu hǎo de xìn zào bǐ cǎi yǎng qì, zài wēi tiáo shí jiāng xìn zào bǐ fēn bù piān xiàng gèng gāo de zào shēng shuǐ píng, yǐ bǔ zhuō dú tè fēng gé. zhè shǐ mó xíng néng gèng hǎo de shēng chéng jù yǒu gāo fēng gé yī zhì xìng de tú xiàng, bìng yǔn xǔ chuàng jiàn hé gòng xiǎng xīn de fēng gé mú bǎn. zuò zhě zhǎn shì le shēng chéng shuǐ cǎi huà, jiǎn bǐ huà, 3D xuàn rán děng duō zhǒng fēng gé de néng lì.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'}, {'word': '扩散', 'pinyin': 'kuò sàn', 'trans': 'diffusion'}, {'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high quality'}, {'word': '个性化', 'pinyin': 'gè xìng huà', 'trans': 'personalized'}, {'word': '艺术', 'pinyin': 'yì shù', 'trans': 'art'}, {'word': '风格', 'pinyin': 'fēng gé', 'trans': 'style'}, {'word': '现有', 'pinyin': 'xiàn yǒu', 'trans': 'existing'}, {'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'}, {'word': '微调', 'pinyin': 'wēi tiáo', 'trans': 'fine-tune'}, {'word': '盲目', 'pinyin': 'máng mù', 'trans': 'blindly'}, {'word': '预训练', 'pinyin': 'yù xùn liàn', 'trans': 'pre-trained'}, {'word': '目标', 'pinyin': 'mù biāo', 'trans': 'target'}, {'word': '噪声', 'pinyin': 'zào shēng', 'trans': 'noise'}, {'word': '水平', 'pinyin': 'shuǐ píng', 'trans': 'level'}, {'word': '分布', 'pinyin': 'fēn bù', 'trans': 'distribution'}, {'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'}, {'word': '对齐', 'pinyin': 'duì qí', 'trans': 'alignment'}, {'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'}, {'word': '信噪比', 'pinyin': 'xìn zào bǐ', 'trans': 'signal-to-noise ratio'}, {'word': '采样器', 'pinyin': 'cǎi yàng qì', 'trans': 'sampler'}, {'word': '偏向', 'pinyin': 'piān xiàng', 'trans': 'bias towards'}, {'word': '捕捉', 'pinyin': 'bǔ zhuō', 'trans': 'capture'}, {'word': '独特', 'pinyin': 'dú tè', 'trans': 'unique'}, {'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'}, {'word': '模板', 'pinyin': 'mú bǎn', 'trans': 'template'}, {'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'}, {'word': '水彩画', 'pinyin': 'shuǐ cǎi huà', 'trans': 'watercolor painting'}, {'word': '简笔画', 'pinyin': 'jiǎn bǐ huà', 'trans': 'line drawing'}, {'word': '3D渲染', 'pinyin': '3D xuàn rán', 'trans': '3D rendering'}]",
        "trans": "This article discusses the ability of large diffusion models to generate high-quality images but their difficulty in learning new personalized artistic styles. Existing methods blindly use pre-trained objectives and noise level distributions during fine-tuning, leading to poor style alignment. The authors propose a style-friendly signal-to-noise ratio sampler that biases the signal-to-noise ratio distribution towards higher noise levels during fine-tuning to capture unique styles. This allows the model to generate images with higher style consistency and enables the creation and sharing of new style templates. The authors demonstrate the capability to generate various styles such as watercolor, sketch, and 3D rendering.",
        "update_ts": "2024-11-25 09:06"
    }
}