{
    "date": {
        "ru": "20 Ğ¼Ğ°Ñ",
        "en": "May 20",
        "zh": "5æœˆ20æ—¥"
    },
    "time_utc": "2025-05-20 03:38",
    "weekday": 1,
    "issue_id": 3846,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.12081",
            "title": "VisionReasoner: Unified Visual Perception and Reasoning via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.12081",
            "abstract": "Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).",
            "score": 11,
            "issue_id": 3845,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 Ğ¼Ğ°Ñ",
                "en": "May 17",
                "zh": "5æœˆ17æ—¥"
            },
            "hash": "9b7953f88ae7653d",
            "authors": [
                "Yuqi Liu",
                "Tianyuan Qu",
                "Zhisheng Zhong",
                "Bohao Peng",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "affiliations": [
                "CUHK",
                "HKUST",
                "SmartMore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12081.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ VisionReasoner - ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸ Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. VisionReasoner Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ²Ñ‹Ğ´Ğ°Ñ‡ĞµĞ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ VisionReasoner Ğ½Ğ°Ğ´ Qwen2.5VL Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ, ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‡ĞµÑ‚Ğ° Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "VisionReasoner: Unifying Visual Perception with Advanced Reasoning",
                    "desc": "This paper presents VisionReasoner, a unified framework designed to enhance visual perception tasks through advanced reasoning capabilities. It employs innovative multi-object cognitive learning strategies and reformulates tasks systematically to improve its performance across various visual challenges. The model processes visual inputs in a structured manner, allowing it to effectively respond to user queries. Evaluation results demonstrate that VisionReasoner significantly outperforms existing models in detection, segmentation, and counting tasks, showcasing its effectiveness as a comprehensive solution for visual perception."
                },
                "zh": {
                    "title": "ç»Ÿä¸€è§†è§‰æ„ŸçŸ¥çš„æ¨ç†èƒ½åŠ›",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºVisionReasonerçš„ç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨å…±äº«æ¨¡å‹ä¸­å¤„ç†å¤šç§è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ã€‚é€šè¿‡è®¾è®¡æ–°é¢–çš„å¤šå¯¹è±¡è®¤çŸ¥å­¦ä¹ ç­–ç•¥å’Œç³»ç»Ÿçš„ä»»åŠ¡é‡æ„ï¼ŒVisionReasonerå¢å¼ºäº†å…¶æ¨ç†èƒ½åŠ›ï¼Œä»¥åˆ†æè§†è§‰è¾“å…¥å¹¶è§£å†³å¤šæ ·çš„æ„ŸçŸ¥ä»»åŠ¡ã€‚è¯¥æ¨¡å‹åœ¨ç”Ÿæˆæ‰€éœ€è¾“å‡ºä¹‹å‰ï¼Œä¼šå…ˆè¿›è¡Œç»“æ„åŒ–çš„æ¨ç†è¿‡ç¨‹ï¼Œä»¥å“åº”ç”¨æˆ·æŸ¥è¯¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVisionReasoneråœ¨æ£€æµ‹ã€åˆ†å‰²å’Œè®¡æ•°ç­‰ä¸‰ä¸ªå…³é”®é¢†åŸŸçš„åä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†Qwen2.5VLã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13417",
            "title": "AdaptThink: Reasoning Models Can Learn When to Think",
            "url": "https://huggingface.co/papers/2505.13417",
            "abstract": "Recently, large reasoning models have achieved impressive performance on various tasks by employing human-like deep thinking. However, the lengthy thinking process substantially increases inference overhead, making efficiency a critical bottleneck. In this work, we first demonstrate that NoThinking, which prompts the reasoning model to skip thinking and directly generate the final solution, is a better choice for relatively simple tasks in terms of both performance and efficiency. Motivated by this, we propose AdaptThink, a novel RL algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty. Specifically, AdaptThink features two core components: (1) a constrained optimization objective that encourages the model to choose NoThinking while maintaining the overall performance; (2) an importance sampling strategy that balances Thinking and NoThinking samples during on-policy training, thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process. Our experiments indicate that AdaptThink significantly reduces the inference costs while further enhancing performance. Notably, on three math datasets, AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive thinking-mode selection for optimizing the balance between reasoning quality and efficiency. Our codes and models are available at https://github.com/THU-KEG/AdaptThink.",
            "score": 9,
            "issue_id": 3845,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "edd33223d8d833a7",
            "authors": [
                "Jiajie Zhang",
                "Nianyi Lin",
                "Lei Hou",
                "Ling Feng",
                "Juanzi Li"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13417.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#inference",
                    "#training",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ˜",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ AdaptThink, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒÑ‡Ğ¸Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½ÑƒÑ Ñ†ĞµĞ»ĞµĞ²ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ¿Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ AdaptThink Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ° Ñ‚Ñ€ĞµÑ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ğ» ÑÑ€ĞµĞ´Ğ½ÑÑ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ DeepSeek-R1-Distill-Qwen-1.5B Ğ½Ğ° 53% Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ğ» ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° 2.4%."
                },
                "en": {
                    "title": "Optimize Reasoning with Adaptive Thinking Modes!",
                    "desc": "This paper introduces AdaptThink, a reinforcement learning algorithm designed to optimize reasoning models by allowing them to choose between two thinking modes: NoThinking and traditional thinking. NoThinking enables models to skip lengthy reasoning processes for simpler tasks, improving efficiency without sacrificing performance. AdaptThink employs a constrained optimization objective to encourage the use of NoThinking while maintaining overall accuracy, and it uses importance sampling to balance training between both modes. The results show that AdaptThink significantly reduces inference costs and enhances performance on math tasks, demonstrating the effectiveness of adaptive thinking-mode selection."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”æ€è€ƒæ¨¡å¼é€‰æ‹©ï¼Œæå‡æ¨ç†æ•ˆç‡ä¸è´¨é‡",
                    "desc": "æœ€è¿‘ï¼Œå¤§å‹æ¨ç†æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å†—é•¿çš„æ€è€ƒè¿‡ç¨‹æ˜¾è‘—å¢åŠ äº†æ¨ç†å¼€é”€ï¼Œå¯¼è‡´æ•ˆç‡æˆä¸ºç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºNoThinkingçš„æ–¹æ³•ï¼Œé¼“åŠ±æ¨ç†æ¨¡å‹è·³è¿‡æ€è€ƒï¼Œç›´æ¥ç”Ÿæˆæœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºç›¸å¯¹ç®€å•çš„ä»»åŠ¡ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†AdaptThinkï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨æ ¹æ®é—®é¢˜éš¾åº¦è‡ªé€‚åº”é€‰æ‹©æœ€ä½³æ€è€ƒæ¨¡å¼ã€‚å®éªŒè¡¨æ˜ï¼ŒAdaptThinkæ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11896",
            "title": "AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.11896",
            "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.",
            "score": 7,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 Ğ¼Ğ°Ñ",
                "en": "May 17",
                "zh": "5æœˆ17æ—¥"
            },
            "hash": "bdc79864df7cbd51",
            "authors": [
                "Chenwei Lou",
                "Zewei Sun",
                "Xinnian Liang",
                "Meng Qu",
                "Wei Shen",
                "Wenqi Wang",
                "Yuntao Li",
                "Qingping Yang",
                "Shuangzhi Wu"
            ],
            "affiliations": [
                "ByteDance Seed"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11896.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "AdaCoT: Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "AdaCoT - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğ¹ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ (LLM) Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (Chain-of-Thought, CoT). Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ² Ñ‡Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Proximal Policy Optimization (PPO), AdaCoT Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ğ°Ğ¼Ğ¸, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼ CoT. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²ĞºĞ»Ğ°Ğ´Ğ¾Ğ¼ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Selective Loss Masking (SLM), Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ÑÑ‰Ğ¸Ğ¹ ĞºĞ¾Ğ»Ğ»Ğ°Ğ¿Ñ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ AdaCoT Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CoT Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…."
                },
                "en": {
                    "title": "Adaptive Reasoning for Efficient Language Models",
                    "desc": "This paper presents AdaCoT, a new framework that improves the efficiency of Large Language Models (LLMs) by adaptively deciding when to use Chain-of-Thought (CoT) prompting. Traditional CoT prompting can be computationally expensive, especially for simpler queries, but AdaCoT optimizes this by framing the decision to use CoT as a Pareto optimization problem. The authors employ reinforcement learning, specifically Proximal Policy Optimization (PPO), to dynamically adjust when CoT is triggered based on the complexity of the input. Their approach includes a technique called Selective Loss Masking (SLM) to ensure stable training, resulting in significant reductions in CoT usage while maintaining high performance on complex tasks."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”é“¾å¼æ¨ç†ï¼Œæå‡æ•ˆç‡ä¸æ€§èƒ½",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†AdaCoTï¼ˆè‡ªé€‚åº”é“¾å¼æ¨ç†ï¼‰ï¼Œå®ƒå…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥çš„å¤æ‚æ€§è‡ªé€‚åº”åœ°å†³å®šæ˜¯å¦ä½¿ç”¨é“¾å¼æ¨ç†ã€‚æˆ‘ä»¬å°†è‡ªé€‚åº”æ¨ç†è§†ä¸ºä¸€ä¸ªå¸•ç´¯æ‰˜ä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨å¹³è¡¡æ¨¡å‹æ€§èƒ½ä¸é“¾å¼æ¨ç†çš„è®¡ç®—æˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaCoTåœ¨ä¸éœ€è¦å¤æ‚æ¨ç†çš„æŸ¥è¯¢ä¸­æ˜¾è‘—å‡å°‘äº†é“¾å¼æ¨ç†çš„ä½¿ç”¨ï¼Œæå‡äº†æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12849",
            "title": "Accelerate TarFlow Sampling with GS-Jacobi Iteration",
            "url": "https://huggingface.co/papers/2505.12849",
            "abstract": "Image generation models have achieved widespread applications. As an instance, the TarFlow model combines the transformer architecture with Normalizing Flow models, achieving state-of-the-art results on multiple benchmarks. However, due to the causal form of attention requiring sequential computation, TarFlow's sampling process is extremely slow. In this paper, we demonstrate that through a series of optimization strategies, TarFlow sampling can be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as GS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow model have varying importance: a small number of blocks play a major role in image generation tasks, while other blocks contribute relatively little; some blocks are sensitive to initial values and prone to numerical overflow, while others are relatively robust. Based on these two characteristics, we propose the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM is used to identify whether a TarFlow block is \"simple\" (converges in few iterations) or \"tough\" (requires more iterations); IGM is used to evaluate whether the initial value of the iteration is good. Experiments on four TarFlow models demonstrate that GS-Jacobi sampling can significantly enhance sampling efficiency while maintaining the quality of generated images (measured by FID), achieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in Img64uncond, and 2.51x in Img64cond without degrading FID scores or sample quality. Code and checkpoints are accessible on https://github.com/encoreus/GS-Jacobi_for_TarFlow",
            "score": 4,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "191f5a409cc6b32e",
            "authors": [
                "Ben Liu",
                "Zhen Qin"
            ],
            "affiliations": [
                "TapTap, Shanghai, China",
                "Zhejiang University, Hangzhou, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12849.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#architecture",
                    "#open_source",
                    "#cv",
                    "#training"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² TarFlow Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ TarFlow Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ“Ğ°ÑƒÑÑĞ°-Ğ—ĞµĞ¹Ğ´ĞµĞ»Ñ-Ğ¯ĞºĞ¾Ğ±Ğ¸ Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ´Ğ²Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸: Convergence Ranking Metric (CRM) Ğ¸ Initial Guessing Metric (IGM). CRM Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² TarFlow, Ğ° IGM Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ´Ğ¾ 5.32 Ñ€Ğ°Ğ·) Ğ±ĞµĞ· ÑƒÑ…ÑƒĞ´ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Accelerating TarFlow: Faster Sampling without Quality Loss",
                    "desc": "This paper presents an optimization strategy for the TarFlow model, which combines transformer architecture with Normalizing Flow for image generation. The authors introduce the Gauss-Seidel-Jacobi (GS-Jacobi) iteration method to accelerate the slow sampling process of TarFlow. They identify that certain blocks within the model are more critical for image generation and propose metrics to evaluate their performance: the Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM). Experimental results show that the GS-Jacobi method significantly improves sampling speed while preserving image quality, achieving notable speed-ups across various benchmarks."
                },
                "zh": {
                    "title": "åŠ é€ŸTarFlowé‡‡æ ·ï¼Œæå‡å›¾åƒç”Ÿæˆæ•ˆç‡",
                    "desc": "å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨å¤šä¸ªåº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚TarFlowæ¨¡å‹ç»“åˆäº†å˜æ¢å™¨æ¶æ„å’Œå½’ä¸€åŒ–æµæ¨¡å‹ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç„¶è€Œï¼Œç”±äºå› æœæ³¨æ„åŠ›çš„é¡ºåºè®¡ç®—ï¼ŒTarFlowçš„é‡‡æ ·è¿‡ç¨‹éå¸¸ç¼“æ…¢ã€‚æœ¬æ–‡é€šè¿‡ä¼˜åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨é«˜æ–¯-èµ›å¾·å°”-é›…å¯æ¯”è¿­ä»£æ–¹æ³•æ˜¾è‘—åŠ é€Ÿäº†TarFlowçš„é‡‡æ ·è¿‡ç¨‹ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13379",
            "title": "Thinkless: LLM Learns When to Think",
            "url": "https://huggingface.co/papers/2505.13379",
            "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "d41117eabc11e5c3",
            "authors": [
                "Gongfan Fang",
                "Xinyin Ma",
                "Xinchao Wang"
            ],
            "affiliations": [
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13379.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rl",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼ Ğ¸ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Thinkless - Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰ÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼ Ğ¸ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ´Ğ²Ğ° ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ°: <short> Ğ´Ğ»Ñ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¸ <think> Ğ´Ğ»Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ’ Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ»ĞµĞ¶Ğ¸Ñ‚ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ DeGRPO, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ Ñ†ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Thinkless ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° 50-90%, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Thinkless: Smart Reasoning for Efficient Language Models",
                    "desc": "This paper introduces Thinkless, a framework designed to enhance the efficiency of Reasoning Language Models (RLMs) by enabling them to choose between short-form and long-form reasoning based on task complexity. The framework utilizes reinforcement learning and two control tokens, <short> for brief answers and <think> for detailed reasoning, to guide the model's response strategy. A novel algorithm called Decoupled Group Relative Policy Optimization (DeGRPO) is employed to separate the learning objectives, allowing for better control over reasoning mode selection and response accuracy. The results show that Thinkless can significantly reduce the reliance on long-chain reasoning, improving computational efficiency while maintaining performance on various benchmarks."
                },
                "zh": {
                    "title": "è®©æ¨¡å‹å­¦ä¼šä½•æ—¶æ€è€ƒ",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºThinklessçš„å¯å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„æ•ˆç‡ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§å’Œè‡ªèº«èƒ½åŠ›è‡ªé€‚åº”é€‰æ‹©çŸ­æœŸæˆ–é•¿æœŸæ¨ç†ã€‚Thinklessä½¿ç”¨ä¸¤ä¸ªæ§åˆ¶æ ‡è®°<short>å’Œ<think>æ¥åˆ†åˆ«è¡¨ç¤ºç®€æ´å›ç­”å’Œè¯¦ç»†æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒThinklessèƒ½å¤Ÿå°†é•¿æœŸæ¨ç†çš„ä½¿ç”¨å‡å°‘50%è‡³90%ï¼Œæ˜¾è‘—æå‡æ¨ç†è¯­è¨€æ¨¡å‹çš„æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13215",
            "title": "Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation",
            "url": "https://huggingface.co/papers/2505.13215",
            "abstract": "Recent advancements in dynamic 3D scene reconstruction have shown promising results, enabling high-fidelity 3D novel view synthesis with improved temporal consistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an appealing approach due to its ability to model high-fidelity spatial and temporal variations. However, existing methods suffer from substantial computational and memory overhead due to the redundant allocation of 4D Gaussians to static regions, which can also degrade image quality. In this work, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework that adaptively represents static regions with 3D Gaussians while reserving 4D Gaussians for dynamic elements. Our method begins with a fully 4D Gaussian representation and iteratively converts temporally invariant Gaussians into 3D, significantly reducing the number of parameters and improving computational efficiency. Meanwhile, dynamic Gaussians retain their full 4D representation, capturing complex motions with high fidelity. Our approach achieves significantly faster training times compared to baseline 4D Gaussian Splatting methods while maintaining or improving the visual quality.",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "0ab00a261298ad44",
            "authors": [
                "Seungjun Oh",
                "Younggeun Lee",
                "Hyejin Jeon",
                "Eunbyung Park"
            ],
            "affiliations": [
                "Department of Artificial Intelligence, Sungkyunkwan University",
                "Department of Artificial Intelligence, Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13215.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ 3D-4D Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑÑ†ĞµĞ½",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ 3D-4DGS Ğ´Ğ»Ñ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… 3D-ÑÑ†ĞµĞ½. ĞĞ½ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ 3D Ğ³Ğ°ÑƒÑÑĞ¸Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ĞµĞ¹ Ğ¸ 4D Ğ³Ğ°ÑƒÑÑĞ¸Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ 4D Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼. ĞœĞµÑ‚Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°."
                },
                "en": {
                    "title": "Efficient 3D-4D Scene Reconstruction with Hybrid Gaussian Splatting",
                    "desc": "This paper presents a new method called hybrid 3D-4D Gaussian Splatting (3D-4DGS) for dynamic 3D scene reconstruction. It combines 3D and 4D Gaussian representations to efficiently model static and dynamic elements in a scene. By converting static regions to 3D Gaussians, the method reduces computational load and memory usage while preserving the quality of dynamic elements with 4D Gaussians. The results show that 3D-4DGS achieves faster training times and improved visual quality compared to traditional 4D Gaussian Splatting techniques."
                },
                "zh": {
                    "title": "é«˜æ•ˆçš„åŠ¨æ€3Dåœºæ™¯é‡å»ºæ–°æ–¹æ³•",
                    "desc": "æœ€è¿‘åŠ¨æ€3Dåœºæ™¯é‡å»ºçš„è¿›å±•æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ•ˆæœï¼Œèƒ½å¤Ÿå®ç°é«˜ä¿çœŸåº¦çš„3Dæ–°è§†å›¾åˆæˆï¼Œå¹¶æé«˜æ—¶é—´ä¸€è‡´æ€§ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­ï¼Œ4Dé«˜æ–¯ç‚¹äº‘ï¼ˆ4DGSï¼‰å› å…¶èƒ½å¤Ÿå»ºæ¨¡é«˜ä¿çœŸçš„ç©ºé—´å’Œæ—¶é—´å˜åŒ–è€Œå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨é™æ€åŒºåŸŸå†—ä½™åˆ†é…4Dé«˜æ–¯æ—¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼Œå¹¶å¯èƒ½é™ä½å›¾åƒè´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆ3D-4Dé«˜æ–¯ç‚¹äº‘ï¼ˆ3D-4DGSï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°ç”¨3Dé«˜æ–¯è¡¨ç¤ºé™æ€åŒºåŸŸï¼ŒåŒæ—¶ä¸ºåŠ¨æ€å…ƒç´ ä¿ç•™4Dé«˜æ–¯ï¼Œä»è€Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.11932",
            "title": "Neuro-Symbolic Query Compiler",
            "url": "https://huggingface.co/papers/2505.11932",
            "abstract": "Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar G[q] to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.",
            "score": 3,
            "issue_id": 3846,
            "pub_date": "2025-05-17",
            "pub_date_card": {
                "ru": "17 Ğ¼Ğ°Ñ",
                "en": "May 17",
                "zh": "5æœˆ17æ—¥"
            },
            "hash": "9445be4eff7e4edc",
            "authors": [
                "Yuyao Zhang",
                "Zhicheng Dou",
                "Xiaoxi Li",
                "Jiajie Jin",
                "Yongkang Wu",
                "Zhonghua Li",
                "Qi Ye",
                "Ji-Rong Wen"
            ],
            "affiliations": [
                "Huawei Poisson Lab",
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.11932.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#rag",
                    "#multimodal"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšĞ¾Ğ¼Ğ¿Ğ¸Ğ»ÑÑ†Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² RAG-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ…",
                    "desc": "QCompiler - ÑÑ‚Ğ¾ Ğ½ĞµĞ¹Ñ€Ğ¾-ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² RAG-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ…. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°Ñ‚Ğ¸ĞºÑƒ BNF Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¸Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ñ… Ğ² Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´ĞµÑ€ĞµĞ²ÑŒÑ. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ñ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸. QCompiler Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‡Ğ¸Ğº Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ»ĞµĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€."
                },
                "en": {
                    "title": "Enhancing Query Understanding in RAG Systems with QCompiler",
                    "desc": "This paper introduces QCompiler, a neuro-symbolic framework designed to enhance the understanding of complex search queries in Retrieval-Augmented Generation (RAG) systems. It utilizes a specially designed Backus-Naur Form (BNF) grammar to formalize these queries, ensuring that they are both complete and free of unnecessary complexity. QCompiler operates through a series of components, including a Query Expression Translator and a Lexical Syntax Parser, which work together to convert queries into Abstract Syntax Trees (ASTs). By focusing on the atomicity of sub-queries, QCompiler improves the accuracy of document retrieval and response generation for intricate queries."
                },
                "zh": {
                    "title": "æå‡RAGç³»ç»Ÿçš„å¤æ‚æŸ¥è¯¢è¯†åˆ«èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºQCompilerçš„ç¥ç»ç¬¦å·æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿå¯¹å¤æ‚æŸ¥è¯¢çš„è¯†åˆ«èƒ½åŠ›ã€‚QCompileråŸºäºè¯­è¨€è¯­æ³•è§„åˆ™å’Œç¼–è¯‘å™¨è®¾è®¡ï¼Œè®¾è®¡äº†ä¸€ç§æœ€å°ä½†è¶³å¤Ÿçš„å·´ç§‘æ–¯-è¯ºå°”å½¢å¼ï¼ˆBNFï¼‰è¯­æ³•G[q]ï¼Œä»¥å½¢å¼åŒ–å¤æ‚æŸ¥è¯¢ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼Œè¿™ç§è¯­æ³•åœ¨ä¿æŒå®Œæ•´æ€§çš„åŒæ—¶ï¼Œå‡å°‘äº†å†—ä½™ã€‚é€šè¿‡å°†æŸ¥è¯¢ç¼–è¯‘æˆæŠ½è±¡è¯­æ³•æ ‘ï¼ˆASTï¼‰ï¼ŒQCompilerèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°æ£€ç´¢æ–‡æ¡£å¹¶ç”Ÿæˆå“åº”ï¼Œä»è€Œæ˜¾è‘—æå‡RAGç³»ç»Ÿå¤„ç†å¤æ‚æŸ¥è¯¢çš„èƒ½åŠ›ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-19.html",
    "link_next": "2025-05-21.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "19.05",
        "en": "05/19",
        "zh": "5æœˆ19æ—¥"
    },
    "short_date_next": {
        "ru": "21.05",
        "en": "05/21",
        "zh": "5æœˆ21æ—¥"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 2,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 5,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 5,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†Qwen3ï¼Œè¿™æ˜¯Qwenæ¨¡å‹ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ã€‚Qwen3åŒ…æ‹¬å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜æ€§èƒ½ã€æ•ˆç‡å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚å®ƒåŒ…å«å¯†é›†å’Œæ··åˆä¸“å®¶æ¶æ„ï¼Œå‚æ•°è§„æ¨¡ä»0.6åˆ°2350äº¿ä¸ç­‰ã€‚Qwen3çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æ€è€ƒæ¨¡å¼å’Œéæ€è€ƒæ¨¡å¼ç»“åˆåœ¨ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œæ¶ˆé™¤äº†åˆ‡æ¢æ¨¡å‹çš„éœ€è¦ã€‚å®ƒè¿˜å¼•å…¥äº†æ€è€ƒé¢„ç®—æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºã€‚",
        "title": "Qwen3 Technical Report",
        "pinyin": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†Qwen3ï¼Œè¿™æ˜¯Qwenæ¨¡å‹ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ã€‚\nZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le Qwen3, zhÃ¨ shÃ¬ Qwen mÃ³xÃ­ng xÃ¬liÃ¨ de zuÃ¬xÄ«n bÇnbÄ›n.\n\nQwen3åŒ…æ‹¬å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜æ€§èƒ½ã€æ•ˆç‡å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚\nQwen3 bÄokuÃ² duÅzhÇ’ng dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng, zhÇ zÃ i tÃ­gÄo xÃ¬ngnÃ©ng, xiÃ olÇœ hÃ© duÅyÇ”yÃ¡n nÃ©nglÃ¬.\n\nå®ƒåŒ…å«å¯†é›†å’Œæ··åˆä¸“å®¶æ¶æ„ï¼Œå‚æ•°è§„æ¨¡ä»0.6åˆ°2350äº¿ä¸ç­‰ã€‚\nTÄ bÄohÃ¡n mÃ¬jÃ­ hÃ© hÃ¹nhÃ© zhuÄnjiÄ jiÃ gÃ²u, cÄnshÃ¹ guÄ«mÃ³ cÃ³ng 0.6 dÃ o 2350 yÃ¬ bÃ¹dÄ›ng.\n\nQwen3çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æ€è€ƒæ¨¡å¼å’Œéæ€è€ƒæ¨¡å¼ç»“åˆåœ¨ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œæ¶ˆé™¤äº†åˆ‡æ¢æ¨¡å‹çš„éœ€è¦ã€‚\nQwen3 de chuÃ ngxÄ«n zhÄ« chÃ¹ zÃ i yÃº jiÄng sÄ«kÇo mÃ³shÃ¬ hÃ© fÄ“i sÄ«kÇo mÃ³shÃ¬ jiÃ©hÃ© zÃ i yÄ«gÃ¨ kuÃ ngjiÃ  zhÅng, xiÄochÃº le qiÄ“huÃ n mÃ³xÃ­ng de xÅ«yÃ o.\n\nå®ƒè¿˜å¼•å…¥äº†æ€è€ƒé¢„ç®—æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºã€‚\nTÄ hÃ¡i yÇnrÃ¹ le sÄ«kÇo yÃ¹suÃ n jÄ«zhÃ¬, yÇ”nxÇ” yÃ²nghÃ¹ gÄ“njÃ¹ rÃ¨nwÃ¹ fÃ¹zÃ¡xÃ¬ng dÃ²ngtÃ i fÄ“npÃ¨i jÃ¬suÃ n zÄ«yuÃ¡n.",
        "vocab": "[\n    {\"word\": \"ç³»åˆ—\", \"pinyin\": \"xÃ¬liÃ¨\", \"trans\": \"series\"},\n    {\"word\": \"ç‰ˆæœ¬\", \"pinyin\": \"bÇnbÄ›n\", \"trans\": \"version\"},\n    {\"word\": \"æ—¨åœ¨\", \"pinyin\": \"zhÇzÃ i\", \"trans\": \"aim to\"},\n    {\"word\": \"æ•ˆç‡\", \"pinyin\": \"xiÃ olÇœ\", \"trans\": \"efficiency\"},\n    {\"word\": \"å¤šè¯­è¨€\", \"pinyin\": \"duÅyÇ”yÃ¡n\", \"trans\": \"multilingual\"},\n    {\"word\": \"èƒ½åŠ›\", \"pinyin\": \"nÃ©nglÃ¬\", \"trans\": \"ability\"},\n    {\"word\": \"åŒ…å«\", \"pinyin\": \"bÄohÃ¡n\", \"trans\": \"contain\"},\n    {\"word\": \"å¯†é›†\", \"pinyin\": \"mÃ¬jÃ­\", \"trans\": \"dense\"},\n    {\"word\": \"æ··åˆ\", \"pinyin\": \"hÃ¹nhÃ©\", \"trans\": \"hybrid\"},\n    {\"word\": \"ä¸“å®¶\", \"pinyin\": \"zhuÄnjiÄ\", \"trans\": \"expert\"},\n    {\"word\": \"æ¶æ„\", \"pinyin\": \"jiÃ gÃ²u\", \"trans\": \"architecture\"},\n    {\"word\": \"å‚æ•°\", \"pinyin\": \"cÄnshÇ”\", \"trans\": \"parameter\"},\n    {\"word\": \"è§„æ¨¡\", \"pinyin\": \"guÄ«mÃ³\", \"trans\": \"scale\"},\n    {\"word\": \"åˆ›æ–°\", \"pinyin\": \"chuÃ ngxÄ«n\", \"trans\": \"innovation\"},\n    {\"word\": \"ä¹‹å¤„\", \"pinyin\": \"zhÄ«chÃ¹\", \"trans\": \"place\"},\n    {\"word\": \"æ€è€ƒ\", \"pinyin\": \"sÄ«kÇo\", \"trans\": \"think\"},\n    {\"word\": \"æ¨¡å¼\", \"pinyin\": \"mÃ³shÃ¬\", \"trans\": \"mode\"},\n    {\"word\": \"ç»“åˆ\", \"pinyin\": \"jiÃ©hÃ©\", \"trans\": \"combine\"},\n    {\"word\": \"æ¡†æ¶\", \"pinyin\": \"kuÃ ngjiÃ \", \"trans\": \"framework\"},\n    {\"word\": \"æ¶ˆé™¤\", \"pinyin\": \"xiÄochÃº\", \"trans\": \"eliminate\"},\n    {\"word\": \"åˆ‡æ¢\", \"pinyin\": \"qiÄ“huÃ n\", \"trans\": \"switch\"},\n    {\"word\": \"éœ€è¦\", \"pinyin\": \"xÅ«yÃ o\", \"trans\": \"need\"},\n    {\"word\": \"å¼•å…¥\", \"pinyin\": \"yÇnrÃ¹\", \"trans\": \"introduce\"},\n    {\"word\": \"é¢„ç®—\", \"pinyin\": \"yÃ¹suÃ n\", \"trans\": \"budget\"},\n    {\"word\": \"æœºåˆ¶\", \"pinyin\": \"jÄ«zhÃ¬\", \"trans\": \"mechanism\"},\n    {\"word\": \"å…è®¸\", \"pinyin\": \"yÇ”nxÇ”\", \"trans\": \"allow\"},\n    {\"word\": \"æ ¹æ®\", \"pinyin\": \"gÄ“njÃ¹\", \"trans\": \"according to\"},\n    {\"word\": \"ä»»åŠ¡\", \"pinyin\": \"rÃ¨nwÃ¹\", \"trans\": \"task\"},\n    {\"word\": \"å¤æ‚æ€§\", \"pinyin\": \"fÃ¹zÃ¡xÃ¬ng\", \"trans\": \"complexity\"},\n    {\"word\": \"åŠ¨æ€\", \"pinyin\": \"dÃ²ngtÃ i\", \"trans\": \"dynamic\"},\n    {\"word\": \"åˆ†é…\", \"pinyin\": \"fÄ“npÃ¨i\", \"trans\": \"allocate\"},\n    {\"word\": \"è®¡ç®—\", \"pinyin\": \"jÃ¬suÃ n\", \"trans\": \"compute\"},\n    {\"word\": \"èµ„æº\", \"pinyin\": \"zÄ«yuÃ¡n\", \"trans\": \"resources\"}\n]",
        "trans": "This article introduces Qwen3, the latest version in the Qwen model series. Qwen3 includes a variety of large language models aimed at enhancing performance, efficiency, and multilingual capabilities. It features dense and mixture-of-experts architectures, with parameter sizes ranging from 0.6 to 2350 billion. The innovation of Qwen3 lies in combining thinking and non-thinking modes within a single framework, eliminating the need to switch models. It also introduces a thinking budget mechanism, allowing users to dynamically allocate computational resources based on the complexity of the task.",
        "update_ts": "2025-05-19 09:13"
    }
}