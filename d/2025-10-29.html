
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 7 papers. October 29.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ", "Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹", "Ğ¼Ğ¸Ğ½ÑƒÑ‚"],
                hour: ["Ñ‡Ğ°Ñ", "Ñ‡Ğ°ÑĞ°", "Ñ‡Ğ°ÑĞ¾Ğ²"],
                day: ["Ğ´ĞµĞ½ÑŒ", "Ğ´Ğ½Ñ", "Ğ´Ğ½ĞµĞ¹"],
                justNow: "Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾",
                ago: "Ğ½Ğ°Ğ·Ğ°Ğ´"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["åˆ†é’Ÿ", "åˆ†é’Ÿ", "åˆ†é’Ÿ"],
                hour: ["å°æ—¶", "å°æ—¶", "å°æ—¶"],
                day: ["å¤©", "å¤©", "å¤©"],
                justNow: "åˆšåˆš",
                ago: "å‰"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            } else if (lastDigit === 1) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒÑ";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "ÑÑ‚Ğ°Ñ‚ÑŒĞ¸";
            } else {
                word = "ÑÑ‚Ğ°Ñ‚ĞµĞ¹";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "ç¯‡è®ºæ–‡"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">ğŸ”º</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">29 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ</span> | <span id="title-articles-count">7 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-10-28.html">â¬…ï¸ <span id="prev-date">28.10</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-10-30.html">â¡ï¸ <span id="next-date">30.10</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-10.html">ğŸ“ˆ <span id='top-month-label'>ĞœĞµÑÑÑ†</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">ğŸ”€ <span id="sort-label-text">Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ</option>
                    <option value="pub_date">Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸</option>
                    <option value="issue_id">Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">ğŸ·ï¸ Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> AâˆªB</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> Aâˆ©B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">ğŸ§¹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> âœ–ï¸ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '29 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 29', 'zh': '10æœˆ29æ—¥'};
        let feedDateNext = {'ru': '30.10', 'en': '10/30', 'zh': '10æœˆ30æ—¥'};
        let feedDatePrev = {'ru': '28.10', 'en': '10/28', 'zh': '10æœˆ28æ—¥'};
        let filterLabel = {'ru': 'Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€', 'en': 'Topics', 'zh': 'ä¸»é¢˜ç­›é€‰'}
        let publishedLabel = {'ru': 'ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¾Ñ‚ ', 'en': 'published on ', 'zh': 'å‘è¡¨äº'}
        let sortLabel = {'ru': 'Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾', 'en': 'Sort by', 'zh': 'æ’åºæ–¹å¼'}
        let paperLabel = {'ru': 'Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ', 'en': 'Paper', 'zh': 'è®ºæ–‡'}
        let topMonthLabel = {'ru': 'ĞœĞµÑÑÑ†', 'en': 'Month', 'zh': 'æœˆåº¦è®ºæ–‡'}
        let topDayLabel = {'ru': 'Ğ”ĞµĞ½ÑŒ', 'en': 'Day', 'zh': 'æ—¥åº¦è®ºæ–‡'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2510.24320', 'title': 'Critique-RL: Training Language Models for Critiquing through Two-Stage\n  Reinforcement Learning', 'url': 'https://huggingface.co/papers/2510.24320', 'abstract': "Critique-RL is an online reinforcement learning approach for developing critiquing language models without strong supervision, using a two-stage optimization strategy to improve both the critic's discriminability and helpfulness.  \t\t\t\t\tAI-generated summary \t\t\t\t Training critiquing language models to assess and provide feedback on model outputs is a promising way to improve LLMs for complex reasoning tasks. However, existing approaches typically rely on stronger supervisors for annotating critique data. To address this, we propose Critique-RL, an online RL approach for developing critiquing language models without stronger supervision. Our approach operates on a two-player paradigm: the actor generates a response, the critic provides feedback, and the actor refines the response accordingly. We first reveal that relying solely on indirect reward signals from the actor's outputs for RL optimization often leads to unsatisfactory critics: while their helpfulness (i.e., providing constructive feedback) improves, the discriminability (i.e., determining whether a response is high-quality or not) remains poor, resulting in marginal performance gains. To overcome this, Critique-RL adopts a two-stage optimization strategy. In stage I, it reinforces the discriminability of the critic with direct rule-based reward signals; in stage II, it introduces indirect rewards based on actor refinement to improve the critic's helpfulness, while maintaining its discriminability via appropriate regularization. Extensive experiments across various tasks and models show that Critique-RL delivers substantial performance improvements. For example, it achieves a 9.02% gain on in-domain tasks and a 5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.", 'score': 5, 'issue_id': 6667, 'pub_date': '2025-10-28', 'pub_date_card': {'ru': '28 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 28', 'zh': '10æœˆ28æ—¥'}, 'hash': '0c26fc5b04f76bff', 'authors': ['Zhiheng Xi', 'Jixuan Huang', 'Xin Guo', 'Boyang Hong', 'Dingwen Yang', 'Xiaoran Fan', 'Shuo Li', 'Zehui Chen', 'Junjie Ye', 'Siyu Yuan', 'Zhengyin Du', 'Xuesong Yao', 'Yufei Xu', 'Jiecao Chen', 'Rui Zheng', 'Tao Gui', 'Qi Zhang', 'Xuanjing Huang'], 'affiliations': ['ByteDance Seed', 'Fudan University'], 'pdf_title_img': 'assets/pdf/title_img/2510.24320.jpg', 'data': {'categories': ['#rl', '#reasoning', '#optimization', '#training', '#rlhf'], 'emoji': 'ğŸ§ ', 'ru': {'title': 'Critique-RL: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±ĞµĞ· ÑĞ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ´Ğ·Ğ¾Ñ€Ğ°', 'desc': 'Critique-RL â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±ĞµĞ· ÑĞ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ´Ğ·Ğ¾Ñ€Ğ°. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ ĞºĞ°Ğº ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ, Ñ‚Ğ°Ğº Ğ¸ ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ. Ğ’ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ ÑƒÑĞ¸Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ°Ñ‚ÑŒ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ñ€ÑĞ¼Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ° Ğ²Ğ¾ Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ ĞºĞ¾ÑĞ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Critique-RL Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ….'}, 'en': {'title': 'Empowering Language Models with Self-Supervised Critique', 'desc': "Critique-RL is a novel online reinforcement learning method designed to enhance critiquing language models without the need for strong supervision. It employs a two-stage optimization strategy where an actor generates responses and a critic evaluates them, allowing for iterative refinement. The first stage focuses on improving the critic's ability to distinguish high-quality responses using direct reward signals, while the second stage enhances the critic's helpfulness through indirect rewards based on the actor's improvements. Experimental results demonstrate that Critique-RL significantly boosts performance, achieving notable gains in both in-domain and out-of-domain tasks."}, 'zh': {'title': 'Critique-RLï¼šæ— å¼ºç›‘ç£çš„è¯„ä¼°è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•', 'desc': 'Critique-RLæ˜¯ä¸€ç§åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºåœ¨æ²¡æœ‰å¼ºç›‘ç£çš„æƒ…å†µä¸‹å¼€å‘è¯„ä¼°è¯­è¨€æ¨¡å‹ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œæ—¨åœ¨æé«˜è¯„ä¼°è€…çš„åŒºåˆ†èƒ½åŠ›å’Œæœ‰ç”¨æ€§ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡ç›´æ¥çš„åŸºäºè§„åˆ™çš„å¥–åŠ±ä¿¡å·æ¥å¢å¼ºè¯„ä¼°è€…çš„åŒºåˆ†èƒ½åŠ›ï¼›åœ¨ç¬¬äºŒé˜¶æ®µï¼ŒåŸºäºç”Ÿæˆè€…çš„åé¦ˆå¼•å…¥é—´æ¥å¥–åŠ±ï¼Œä»¥æé«˜è¯„ä¼°è€…çš„æœ‰ç”¨æ€§ï¼ŒåŒæ—¶é€šè¿‡é€‚å½“çš„æ­£åˆ™åŒ–ä¿æŒå…¶åŒºåˆ†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCritique-RLåœ¨å¤šä¸ªä»»åŠ¡å’Œæ¨¡å‹ä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶æ½œåŠ›ã€‚'}}}, {'id': 'https://huggingface.co/papers/2510.24701', 'title': 'Tongyi DeepResearch Technical Report', 'url': 'https://huggingface.co/papers/2510.24701', 'abstract': "Tongyi DeepResearch, a large language model with agentic capabilities, achieves top performance in various deep research tasks through an end-to-end training framework and automated data synthesis.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community.", 'score': 4, 'issue_id': 6667, 'pub_date': '2025-10-28', 'pub_date_card': {'ru': '28 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 28', 'zh': '10æœˆ28æ—¥'}, 'hash': 'a6f467c756fc29b7', 'authors': ['Tongyi DeepResearch Team', 'Baixuan Li', 'Bo Zhang', 'Dingchu Zhang', 'Fei Huang', 'Guangyu Li', 'Guoxin Chen', 'Huifeng Yin', 'Jialong Wu', 'Jingren Zhou', 'Kuan Li', 'Liangcai Su', 'Litu Ou', 'Liwen Zhang', 'Pengjun Xie', 'Rui Ye', 'Wenbiao Yin', 'Xinmiao Yu', 'Xinyu Wang', 'Xixi Wu', 'Xuanzhong Chen', 'Yida Zhao', 'Zhen Zhang', 'Zhengwei Tao', 'Zhongwang Zhang', 'Zile Qiao', 'Chenxi Wang', 'Donglei Yu', 'Gang Fu', 'Haiyang Shen', 'Jiayin Yang', 'Jun Lin', 'Junkai Zhang', 'Kui Zeng', 'Li Yang', 'Hailong Yin', 'Maojia Song', 'Ming Yan', 'Peng Xia', 'Qian Xiao', 'Rui Min', 'Ruixue Ding', 'Runnan Fang', 'Shaowei Chen', 'Shen Huang', 'Shihang Wang', 'Shihao Cai', 'Weizhou Shen', 'Xiaobin Wang', 'Xin Guan', 'Xinyu Geng', 'Yingcheng Shi', 'Yuning Wu', 'Zhuo Chen', 'Zijian Li', 'Yong Jiang'], 'affiliations': ['Tongyi Lab, Alibaba Group'], 'pdf_title_img': 'assets/pdf/title_img/2510.24701.jpg', 'data': {'categories': ['#long_context', '#synthetic', '#dataset', '#benchmark', '#training', '#open_source', '#agi', '#agents'], 'emoji': 'ğŸ”', 'ru': {'title': 'ĞĞ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ AI-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹', 'desc': 'Tongyi DeepResearch - ÑÑ‚Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸, ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰Ğ°ÑÑÑ Ğ½Ğ° Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· end-to-end Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ mid-training Ğ¸ post-training, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´Ğ°Ñ‚ÑŒ Ğ¸ Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. ĞšĞ»ÑÑ‡ĞµĞ²Ğ°Ñ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ - Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ±ĞµĞ· Ğ´Ğ¾Ñ€Ğ¾Ğ³Ğ¾ÑÑ‚Ğ¾ÑÑ‰ĞµĞ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ¸. ĞŸÑ€Ğ¸ 30.5 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¸Ğ· ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 3.3 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ° Ğ½Ğ° Ñ‚Ğ¾ĞºĞµĞ½, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ state-of-the-art Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğµ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹.'}, 'en': {'title': 'Empowering Autonomous Deep Research with Tongyi DeepResearch', 'desc': 'Tongyi DeepResearch is a large language model designed for complex research tasks that require deep information-seeking capabilities. It utilizes an end-to-end training framework that includes both mid-training and post-training phases to enhance its autonomous research abilities. The model features a fully automated data synthesis pipeline, eliminating the need for expensive human annotations, which allows for scalable training across various tasks. With 30.5 billion parameters, Tongyi DeepResearch achieves top performance on multiple benchmarks, demonstrating its effectiveness in deep research applications.'}, 'zh': {'title': 'è‡ªä¸»æ·±åº¦ç ”ç©¶çš„æœªæ¥', 'desc': 'Tongyi DeepResearch æ˜¯ä¸€ç§å…·æœ‰è‡ªä¸»èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºé•¿æ—¶é—´çš„ä¿¡æ¯æ£€ç´¢ç ”ç©¶ä»»åŠ¡ã€‚å®ƒé€šè¿‡ç«¯åˆ°ç«¯çš„è®­ç»ƒæ¡†æ¶å’Œè‡ªåŠ¨åŒ–çš„æ•°æ®åˆæˆï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ä»»åŠ¡ä¸­å®ç°å¯æ‰©å±•çš„æ¨ç†å’Œä¿¡æ¯è·å–ã€‚è¯¥æ¨¡å‹å…·æœ‰ 305 äº¿ä¸ªå‚æ•°ï¼Œä¸”æ¯ä¸ªä»¤ç‰Œä»…æ¿€æ´» 33 äº¿ä¸ªå‚æ•°ï¼Œè¡¨ç°å‡ºè‰²ï¼Œè¾¾åˆ°äº†å¤šé¡¹æ·±åº¦ç ”ç©¶åŸºå‡†çš„æœ€å…ˆè¿›æ°´å¹³ã€‚æˆ‘ä»¬å°†æ¨¡å‹ã€æ¡†æ¶å’Œå®Œæ•´è§£å†³æ–¹æ¡ˆå¼€æºï¼Œä»¥æ”¯æŒç¤¾åŒºçš„å‘å±•ã€‚'}}}, {'id': 'https://huggingface.co/papers/2510.22099', 'title': 'Generalization or Memorization: Dynamic Decoding for Mode Steering', 'url': 'https://huggingface.co/papers/2510.22099', 'abstract': "A framework using the Information Bottleneck principle and Dynamic Mode Steering algorithm improves the reliability of Large Language Models by balancing generalization and memorization.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) exhibit a troubling duality, capable of both remarkable generalization and brittle, verbatim memorization of their training data. This unpredictability undermines their reliability in high-stakes applications. In this work, we propose a unified framework to understand, identify, and control these distinct reasoning modes. First, we introduce a theoretical model based on the Information Bottleneck (IB) principle, formalizing generalization as the learning of a compressed, task-relevant representation and memorization as a failure to compress. Building on this theory, we develop Dynamic Mode Steering (DMS), a novel inference-time algorithm which comprises two components: (1) a lightweight, causally-grounded linear probe that identifies the model's instantaneous reliance on memorization, and (2) a dynamic activation steering mechanism that nudges the model's computation towards pre-identified generalization circuits. We frame DMS as a form of adaptive, self-contrastive decoding. Experiments on reasoning and faithfulness tasks demonstrate that DMS significantly improves logical consistency and factual accuracy, thereby offering a principled approach to enhancing LLM reliability.", 'score': 1, 'issue_id': 6667, 'pub_date': '2025-10-25', 'pub_date_card': {'ru': '25 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 25', 'zh': '10æœˆ25æ—¥'}, 'hash': '7a4136db7043277f', 'authors': ['Xuanming Zhang'], 'affiliations': ['Department of Computer Science, University of Wisconsin-Madison, Madison, USA', 'Stanford University, Palo Alto, USA'], 'pdf_title_img': 'assets/pdf/title_img/2510.22099.jpg', 'data': {'categories': ['#reasoning', '#interpretability', '#inference', '#training'], 'emoji': 'ğŸ§­', 'ru': {'title': 'Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ğ¼Ğ¸ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ: ĞºĞ°Ğº Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒ LLM Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒ, Ğ° Ğ½Ğµ Ğ·Ğ°ÑƒÑ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ', 'desc': 'Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğµ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ‚Ğ¾ Ğ±Ğ»ĞµÑÑ‚ÑÑ‰Ğµ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ, Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚ Ğ·Ğ°ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ñ€Ğ°Ğ·Ñ‹ Ğ¸Ğ· Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ° Information Bottleneck Ğ¾Ğ½Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ´Ğµ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ÑÑ ĞºĞ°Ğº ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ° Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğµ â€” ĞºĞ°Ğº Ğ½ĞµÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğº Ñ‚Ğ°ĞºĞ¾Ğ¼Ñƒ ÑĞ¶Ğ°Ñ‚Ğ¸Ñ. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Dynamic Mode Steering Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ»ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ°, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ·Ğ°ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ ĞµÑ‘ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ğ² ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñƒ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰Ğ¸Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² LLM.'}, 'en': {'title': 'Balancing Generalization and Memorization for Reliable LLMs', 'desc': "This paper presents a framework that enhances the reliability of Large Language Models (LLMs) by addressing their tendency to both generalize and memorize training data. It introduces the Information Bottleneck principle to differentiate between effective generalization, which compresses information, and problematic memorization, which retains too much detail. The Dynamic Mode Steering algorithm is developed to dynamically adjust the model's focus during inference, promoting generalization while minimizing reliance on memorization. Experimental results show that this approach improves logical consistency and factual accuracy in LLM outputs, making them more reliable for critical applications."}, 'zh': {'title': 'æå‡å¤§å‹è¯­è¨€æ¨¡å‹å¯é æ€§çš„åˆ›æ–°æ¡†æ¶', 'desc': 'æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨ä¿¡æ¯ç“¶é¢ˆåŸç†å’ŒåŠ¨æ€æ¨¡å¼å¼•å¯¼ç®—æ³•æ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯é æ€§ã€‚è¯¥æ¡†æ¶æ—¨åœ¨å¹³è¡¡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œè®°å¿†èƒ½åŠ›ï¼Œè§£å†³æ¨¡å‹åœ¨é«˜é£é™©åº”ç”¨ä¸­çš„ä¸å¯é æ€§é—®é¢˜ã€‚é€šè¿‡ç†è®ºæ¨¡å‹ï¼Œæ³›åŒ–è¢«å®šä¹‰ä¸ºå­¦ä¹ å‹ç¼©çš„ã€ä¸ä»»åŠ¡ç›¸å…³çš„è¡¨ç¤ºï¼Œè€Œè®°å¿†åˆ™è¢«è§†ä¸ºæœªèƒ½è¿›è¡Œå‹ç¼©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠ¨æ€æ¨¡å¼å¼•å¯¼ç®—æ³•æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„é€»è¾‘ä¸€è‡´æ€§å’Œäº‹å®å‡†ç¡®æ€§ï¼Œæä¾›äº†ä¸€ç§å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹å¯é æ€§çš„åŸåˆ™æ€§æ–¹æ³•ã€‚'}}}, {'id': 'https://huggingface.co/papers/2510.21323', 'title': 'VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a\n  Unified Concept Set', 'url': 'https://huggingface.co/papers/2510.21323', 'abstract': 'VL-SAE, a sparse autoencoder, enhances vision-language alignment by correlating neurons to unified concepts, improving interpretability and performance in tasks like zero-shot image classification and hallucination elimination.  \t\t\t\t\tAI-generated summary \t\t\t\t The alignment of vision-language representations endows current Vision-Language Models (VLMs) with strong multi-modal reasoning capabilities. However, the interpretability of the alignment component remains uninvestigated due to the difficulty in mapping the semantics of multi-modal representations into a unified concept set. To address this problem, we propose VL-SAE, a sparse autoencoder that encodes vision-language representations into its hidden activations. Each neuron in its hidden layer correlates to a concept represented by semantically similar images and texts, thereby interpreting these representations with a unified concept set. To establish the neuron-concept correlation, we encourage semantically similar representations to exhibit consistent neuron activations during self-supervised training. First, to measure the semantic similarity of multi-modal representations, we perform their alignment in an explicit form based on cosine similarity. Second, we construct the VL-SAE with a distance-based encoder and two modality-specific decoders to ensure the activation consistency of semantically similar representations. Experiments across multiple VLMs (e.g., CLIP, LLaVA) demonstrate the superior capability of VL-SAE in interpreting and enhancing the vision-language alignment. For interpretation, the alignment between vision and language representations can be understood by comparing their semantics with concepts. For enhancement, the alignment can be strengthened by aligning vision-language representations at the concept level, contributing to performance improvements in downstream tasks, including zero-shot image classification and hallucination elimination. Codes are available at https://github.com/ssfgunner/VL-SAE.', 'score': 1, 'issue_id': 6667, 'pub_date': '2025-10-24', 'pub_date_card': {'ru': '24 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 24', 'zh': '10æœˆ24æ—¥'}, 'hash': '41279ff25d4d0ecb', 'authors': ['Shufan Shen', 'Junshu Sun', 'Qingming Huang', 'Shuhui Wang'], 'affiliations': ['Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS', 'University of Chinese Academy of Sciences'], 'pdf_title_img': 'assets/pdf/title_img/2510.21323.jpg', 'data': {'categories': ['#alignment', '#multimodal', '#interpretability', '#cv', '#hallucinations', '#training'], 'emoji': 'ğŸ”', 'ru': {'title': 'Ğ Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ñ ÑĞ²ÑĞ·Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ñ€ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ¼', 'desc': 'VL-SAE â€” ÑÑ‚Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² VLM Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ¿ÑƒÑ‚Ñ‘Ğ¼ ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ¾Ğ² Ñ ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ¾Ğ¼ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚Ğ¾Ğ². ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ñ ĞºĞ¾Ñ€Ñ€ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ñ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚Ğ¾Ğ¼, Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğ¼Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°Ğ¼Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ ÑĞ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ¾Ğ² Ğ´Ğ»Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ±Ğ»Ğ¸Ğ·ĞºĞ¸Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… zero-shot ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ ÑƒÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ‚Ğ¸Ğ¿Ğ° CLIP Ğ¸ LLaVA.'}, 'en': {'title': 'Enhancing Vision-Language Alignment with VL-SAE', 'desc': 'The paper introduces VL-SAE, a sparse autoencoder designed to improve the alignment between vision and language representations in multi-modal models. By correlating neurons in its hidden layer to unified concepts derived from semantically similar images and texts, VL-SAE enhances both interpretability and performance. The model employs self-supervised training to ensure consistent neuron activations for similar representations, using cosine similarity for semantic alignment. Experiments show that VL-SAE significantly boosts the effectiveness of vision-language models in tasks like zero-shot image classification and reducing hallucinations.'}, 'zh': {'title': 'VL-SAEï¼šæå‡è§†è§‰-è¯­è¨€å¯¹é½çš„ç¨€ç–è‡ªç¼–ç å™¨', 'desc': 'VL-SAEæ˜¯ä¸€ç§ç¨€ç–è‡ªç¼–ç å™¨ï¼Œé€šè¿‡å°†è§†è§‰å’Œè¯­è¨€è¡¨ç¤ºå…³è”åˆ°ç»Ÿä¸€çš„æ¦‚å¿µï¼Œå¢å¼ºäº†è§†è§‰-è¯­è¨€å¯¹é½çš„èƒ½åŠ›ã€‚å®ƒçš„éšè—å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒä¸è¯­ä¹‰ç›¸ä¼¼çš„å›¾åƒå’Œæ–‡æœ¬æ‰€ä»£è¡¨çš„æ¦‚å¿µç›¸å…³è”ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œæ€§èƒ½ã€‚é€šè¿‡è‡ªç›‘ç£è®­ç»ƒï¼ŒVL-SAEé¼“åŠ±è¯­ä¹‰ç›¸ä¼¼çš„è¡¨ç¤ºåœ¨ç¥ç»å…ƒæ¿€æ´»ä¸Šä¿æŒä¸€è‡´ã€‚å®éªŒè¡¨æ˜ï¼ŒVL-SAEåœ¨é›¶æ ·æœ¬å›¾åƒåˆ†ç±»å’Œæ¶ˆé™¤å¹»è§‰ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯¹é½èƒ½åŠ›ã€‚'}}}, {'id': 'https://huggingface.co/papers/2510.24591', 'title': 'ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?', 'url': 'https://huggingface.co/papers/2510.24591', 'abstract': "ReplicationBench evaluates AI agents' ability to replicate astrophysics research papers, providing insights into their faithfulness and correctness in scientific research tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Frontier AI agents show increasing promise as scientific research assistants, and may eventually be useful for extended, open-ended research workflows. However, in order to use agents for novel research, we must first assess the underlying faithfulness and correctness of their work. To evaluate agents as research assistants, we introduce ReplicationBench, an evaluation framework that tests whether agents can replicate entire research papers drawn from the astrophysics literature. Astrophysics, where research relies heavily on archival data and computational study while requiring little real-world experimentation, is a particularly useful testbed for AI agents in scientific research. We split each paper into tasks which require agents to replicate the paper's core contributions, including the experimental setup, derivations, data analysis, and codebase. Each task is co-developed with the original paper authors and targets a key scientific result, enabling objective evaluation of both faithfulness (adherence to original methods) and correctness (technical accuracy of results). ReplicationBench is extremely challenging for current frontier language models: even the best-performing language models score under 20%. We analyze ReplicationBench trajectories in collaboration with domain experts and find a rich, diverse set of failure modes for agents in scientific research. ReplicationBench establishes the first benchmark of paper-scale, expert-validated astrophysics research tasks, reveals insights about agent performance generalizable to other domains of data-driven science, and provides a scalable framework for measuring AI agents' reliability in scientific research.", 'score': 0, 'issue_id': 6667, 'pub_date': '2025-10-28', 'pub_date_card': {'ru': '28 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 28', 'zh': '10æœˆ28æ—¥'}, 'hash': 'd655b0884e7b15c0', 'authors': ['Christine Ye', 'Sihan Yuan', 'Suchetha Cooray', 'Steven Dillmann', 'Ian L. V. Roque', 'Dalya Baron', 'Philipp Frank', 'Sergio Martin-Alvarez', 'Nolan Koblischke', 'Frank J Qu', 'Diyi Yang', 'Risa Wechsler', 'Ioana Ciuca'], 'affiliations': ['Stanford University', 'University of Toronto'], 'pdf_title_img': 'assets/pdf/title_img/2510.24591.jpg', 'data': {'categories': ['#benchmark', '#science', '#agents'], 'emoji': 'ğŸ”­', 'ru': {'title': 'ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹', 'desc': 'Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ ReplicationBench â€” Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ°ÑÑ‚Ñ€Ğ¾Ñ„Ğ¸Ğ·Ğ¸ĞºĞµ. ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼ Ğ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ², Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ²ÑĞµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ñ‹ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾ Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹. Ğ”Ğ°Ğ¶Ğµ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ LLM Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ½Ğ¸Ğ¶Ğµ 20%, Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ñ€Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ… Ğ¸ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ… Ğ½Ğ°ÑƒĞºĞ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….'}, 'en': {'title': 'Evaluating AI Agents in Astrophysics Research Replication', 'desc': "ReplicationBench is a framework designed to evaluate AI agents' ability to replicate research papers in astrophysics, focusing on their faithfulness and correctness. It breaks down each paper into specific tasks that require the agents to reproduce key contributions, such as experimental setups and data analyses, in collaboration with the original authors. The framework reveals that even advanced language models struggle with these tasks, scoring below 20%, highlighting various failure modes in their performance. This benchmark not only assesses AI reliability in astrophysics but also offers insights applicable to other scientific fields."}, 'zh': {'title': 'è¯„ä¼° AI ä»£ç†åœ¨ç§‘å­¦ç ”ç©¶ä¸­çš„å¯é æ€§', 'desc': 'ReplicationBench æ˜¯ä¸€ä¸ªè¯„ä¼° AI ä»£ç†åœ¨å¤åˆ¶å¤©ä½“ç‰©ç†å­¦ç ”ç©¶è®ºæ–‡èƒ½åŠ›çš„æ¡†æ¶ã€‚å®ƒé€šè¿‡å°†è®ºæ–‡åˆ†è§£ä¸ºå¤šä¸ªä»»åŠ¡ï¼Œæµ‹è¯•ä»£ç†æ˜¯å¦èƒ½å¤Ÿå‡†ç¡®å¤ç°è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ï¼ŒåŒ…æ‹¬å®éªŒè®¾ç½®ã€æ¨å¯¼ã€æ•°æ®åˆ†æå’Œä»£ç åº“ã€‚è¯¥æ¡†æ¶ä¸åŸè®ºæ–‡ä½œè€…å…±åŒå¼€å‘ï¼Œç¡®ä¿è¯„ä¼°çš„å®¢è§‚æ€§ï¼Œå…³æ³¨ä»£ç†çš„å¿ å®æ€§å’Œæ­£ç¡®æ€§ã€‚å°½ç®¡å½“å‰çš„å‰æ²¿è¯­è¨€æ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼ŒReplicationBench ä»ä¸ºç§‘å­¦ç ”ç©¶ä¸­çš„ AI ä»£ç†æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„å¯é æ€§æµ‹é‡æ¡†æ¶ã€‚'}}}, {'id': 'https://huggingface.co/papers/2510.24563', 'title': 'OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents', 'url': 'https://huggingface.co/papers/2510.24563', 'abstract': "OSWorld-MCP is a benchmark that evaluates multimodal agents' tool invocation, GUI operation, and decision-making abilities, highlighting the importance of assessing tool usage in real-world scenarios.  \t\t\t\t\tAI-generated summary \t\t\t\t With advances in decision-making and reasoning capabilities, multimodal agents show strong potential in computer application scenarios. Past evaluations have mainly assessed GUI interaction skills, while tool invocation abilities, such as those enabled by the Model Context Protocol (MCP), have been largely overlooked. Comparing agents with integrated tool invocation to those evaluated only on GUI interaction is inherently unfair. We present OSWorld-MCP, the first comprehensive and fair benchmark for assessing computer-use agents' tool invocation, GUI operation, and decision-making abilities in a real-world environment. We design a novel automated code-generation pipeline to create tools and combine them with a curated selection from existing tools. Rigorous manual validation yields 158 high-quality tools (covering 7 common applications), each verified for correct functionality, practical applicability, and versatility. Extensive evaluations of state-of-the-art multimodal agents on OSWorld-MCP show that MCP tools generally improve task success rates (e.g., from 8.3% to 20.4% for OpenAI o3 at 15 steps, from 40.1% to 43.3% for Claude 4 Sonnet at 50 steps), underscoring the importance of assessing tool invocation capabilities. However, even the strongest models have relatively low tool invocation rates, Only 36.3%, indicating room for improvement and highlighting the benchmark's challenge. By explicitly measuring MCP tool usage skills, OSWorld-MCP deepens understanding of multimodal agents and sets a new standard for evaluating performance in complex, tool-assisted environments. Our code, environment, and data are publicly available at https://osworld-mcp.github.io.", 'score': 0, 'issue_id': 6667, 'pub_date': '2025-10-28', 'pub_date_card': {'ru': '28 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 28', 'zh': '10æœˆ28æ—¥'}, 'hash': '31a5246f81b64759', 'authors': ['Hongrui Jia', 'Jitong Liao', 'Xi Zhang', 'Haiyang Xu', 'Tianbao Xie', 'Chaoya Jiang', 'Ming Yan', 'Si Liu', 'Wei Ye', 'Fei Huang'], 'affiliations': ['Beijing Zhongguancun Academy', 'Peking University', 'Tongyi Lab, Alibaba Group'], 'pdf_title_img': 'assets/pdf/title_img/2510.24563.jpg', 'data': {'categories': ['#multimodal', '#reasoning', '#benchmark', '#optimization', '#open_source', '#agents'], 'emoji': 'ğŸ› ï¸', 'ru': {'title': 'ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ GUI, Ğ½Ğ¾ Ğ¸ ÑƒĞ¼ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸', 'desc': 'OSWorld-MCP â€” ÑÑ‚Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸Ğ·Ğ¼ĞµÑ€ÑĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñƒ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼ Ğ¸ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ 158 Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ 7 Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ´Ğ° Ğ¸ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ MCP-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸ ÑƒÑĞ¿ĞµÑ…Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ñ 8.3% Ğ´Ğ¾ 20.4% Ğ´Ğ»Ñ OpenAI o3. ĞĞ´Ğ½Ğ°ĞºĞ¾ Ğ´Ğ°Ğ¶Ğµ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² 36.3% ÑĞ»ÑƒÑ‡Ğ°ĞµĞ², Ñ‡Ñ‚Ğ¾ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ° Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ.'}, 'en': {'title': 'Revolutionizing Multimodal Agent Evaluation with OSWorld-MCP', 'desc': "OSWorld-MCP is a new benchmark designed to evaluate multimodal agents on their ability to invoke tools, operate GUIs, and make decisions in real-world scenarios. It addresses the gap in previous assessments that primarily focused on GUI interactions, providing a fair comparison by including tool invocation capabilities. The benchmark features a unique automated code-generation pipeline that creates and validates 158 high-quality tools for common applications. Results show that while integrating MCP tools significantly improves task success rates, there is still a need for enhancement in tool invocation rates among leading models, emphasizing the benchmark's importance in advancing multimodal agent evaluation."}, 'zh': {'title': 'è¯„ä¼°å¤šæ¨¡æ€æ™ºèƒ½ä½“çš„æ–°æ ‡å‡†', 'desc': 'OSWorld-MCPæ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€æ™ºèƒ½ä½“åœ¨å·¥å…·è°ƒç”¨ã€å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ“ä½œå’Œå†³ç­–èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨çœŸå®åœºæ™¯ä¸­è¯„ä¼°å·¥å…·ä½¿ç”¨çš„é‡è¦æ€§ï¼Œå°¤å…¶æ˜¯é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰å®ç°çš„å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆç®¡é“ï¼Œç ”ç©¶å›¢é˜Ÿåˆ›å»ºäº†158ä¸ªé«˜è´¨é‡å·¥å…·ï¼Œå¹¶å¯¹å…¶åŠŸèƒ½å’Œé€‚ç”¨æ€§è¿›è¡Œäº†ä¸¥æ ¼éªŒè¯ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨MCPå·¥å…·çš„æ™ºèƒ½ä½“åœ¨ä»»åŠ¡æˆåŠŸç‡ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œæ˜¾ç¤ºå‡ºå·¥å…·è°ƒç”¨èƒ½åŠ›çš„å…³é”®æ€§ã€‚'}}}, {'id': 'https://huggingface.co/papers/2510.24448', 'title': 'Rethinking Visual Intelligence: Insights from Video Pretraining', 'url': 'https://huggingface.co/papers/2510.24448', 'abstract': 'Video Diffusion Models (VDMs) show higher data efficiency than large language models across various visual tasks, suggesting video pretraining can enhance visual foundation models.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) have demonstrated that large-scale pretraining enables systems to adapt rapidly to new problems with little supervision in the language domain. This success, however, has not translated as effectively to the visual domain, where models, including LLMs, continue to struggle with compositional understanding, sample efficiency, and general-purpose problem-solving. We investigate Video Diffusion Models (VDMs) as a promising direction for bridging this gap. Pretraining on spatiotemporal data endows these models with strong inductive biases for structure and dynamics, which we hypothesize can support broad task adaptability. To test this, we design a controlled evaluation in which both a pretrained LLM and a pretrained VDM are equipped with lightweight adapters and presented with tasks in their natural modalities. Across benchmarks including ARC-AGI, ConceptARC, visual games, route planning, and cellular automata, VDMs demonstrate higher data efficiency than their language counterparts. Taken together, our results indicate that video pretraining offers inductive biases that support progress toward visual foundation models.', 'score': 0, 'issue_id': 6667, 'pub_date': '2025-10-28', 'pub_date_card': {'ru': '28 Ğ¾ĞºÑ‚ÑĞ±Ñ€Ñ', 'en': 'October 28', 'zh': '10æœˆ28æ—¥'}, 'hash': 'cb963e7271205da4', 'authors': ['Pablo Acuaviva', 'Aram Davtyan', 'Mariam Hassan', 'Sebastian Stapf', 'Ahmad Rahimi', 'Alexandre Alahi', 'Paolo Favaro'], 'affiliations': ['Computer Vision Group University of Bern Bern, Switzerland', 'VITA Lab, EPFL Lausanne, Switzerland'], 'pdf_title_img': 'assets/pdf/title_img/2510.24448.jpg', 'data': {'categories': ['#multimodal', '#transfer_learning', '#games', '#diffusion', '#benchmark', '#video'], 'emoji': 'ğŸ¬', 'ru': {'title': 'Ğ’Ğ¸Ğ´ĞµĞ¾-Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ñ Ğ¿Ğ¾Ğ±ĞµĞ¶Ğ´Ğ°ĞµÑ‚ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…', 'desc': 'Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ»Ğ¸ Video Diffusion Models (VDMs) Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ğ² Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. VDMs, Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¼Ğ°Ğ»Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¼Ñƒ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾-Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ÑÑŒ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ARC-AGI, ConceptARC, Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ³Ñ€Ñ‹ Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¾Ğ². Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ´Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ¸Ğ½Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… foundation models.'}, 'en': {'title': 'Unlocking Visual Potential with Video Diffusion Models', 'desc': 'This paper explores the effectiveness of Video Diffusion Models (VDMs) in improving visual tasks through video pretraining. Unlike large language models (LLMs), which excel in language tasks, VDMs leverage spatiotemporal data to enhance their understanding of structure and dynamics. The authors conducted experiments comparing pretrained VDMs and LLMs, finding that VDMs showed superior data efficiency across various benchmarks. The results suggest that video pretraining can significantly advance the development of visual foundation models.'}, 'zh': {'title': 'è§†é¢‘é¢„è®­ç»ƒæå‡è§†è§‰æ¨¡å‹æ•ˆç‡', 'desc': 'è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰åœ¨å„ç§è§†è§‰ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ¯”å¤§å‹è¯­è¨€æ¨¡å‹æ›´é«˜çš„æ•°æ®æ•ˆç‡ï¼Œè¡¨æ˜è§†é¢‘é¢„è®­ç»ƒå¯ä»¥å¢å¼ºè§†è§‰åŸºç¡€æ¨¡å‹çš„èƒ½åŠ›ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯­è¨€é¢†åŸŸçš„é¢„è®­ç»ƒå–å¾—äº†æˆåŠŸï¼Œä½†åœ¨è§†è§‰é¢†åŸŸï¼Œæ¨¡å‹ä»ç„¶é¢ä¸´ç»„åˆç†è§£å’Œæ ·æœ¬æ•ˆç‡ç­‰æŒ‘æˆ˜ã€‚æˆ‘ä»¬ç ”ç©¶VDMsä½œä¸ºå¼¥åˆè¿™ä¸€å·®è·çš„æœ‰å‰æ™¯çš„æ–¹å‘ï¼Œè®¤ä¸ºå…¶åœ¨æ—¶ç©ºæ•°æ®ä¸Šçš„é¢„è®­ç»ƒèµ‹äºˆäº†æ¨¡å‹å¼ºå¤§çš„ç»“æ„å’ŒåŠ¨æ€çš„å½’çº³åç½®ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒVDMsåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæ¯”è¯­è¨€æ¨¡å‹æ›´é«˜çš„æ•°æ®æ•ˆç‡ï¼Œæ”¯æŒäº†è§†é¢‘é¢„è®­ç»ƒå¯¹è§†è§‰åŸºç¡€æ¨¡å‹çš„è¿›å±•ã€‚'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents (3)', '#agi (1)', '#alignment (1)', '#architecture', '#audio', '#benchmark (4)', '#cv (1)', '#data', '#dataset (1)', '#diffusion (1)', '#ethics', '#games (1)', '#graphs', '#hallucinations (1)', '#healthcare', '#inference (1)', '#interpretability (2)', '#leakage', '#long_context (1)', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal (3)', '#open_source (2)', '#optimization (2)', '#plp', '#rag', '#reasoning (3)', '#rl (1)', '#rlhf (1)', '#robotics', '#science (1)', '#security', '#small_models', '#story_generation', '#survey', '#synthetic (1)', '#training (4)', '#transfer_learning (1)', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `ğŸ·ï¸ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            ğŸ”º ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = 'ğŸ”„ ' + getTimeDiff('2025-10-29 02:31',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ",
                    pub_date: "Ğ´Ğ°Ñ‚Ğµ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸",
                    issue_id: "Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "è¯„åˆ†",
                    pub_date: "å‘å¸ƒæ—¥æœŸ",
                    issue_id: "HFä¸Šä¼ æ—¥æœŸ"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-10-29 02:31')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-10-29 02:31')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    