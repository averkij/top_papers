
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining</h1>
                <div><p class='zh-text'>1. 这篇文章介绍了一种新的多模态教材数据集，用于视觉-语言模型（VLMs）的预训练。</p>
<p class='zh-text'>2. 与现有的图像-文本数据集相比，这个数据集从网络上的教学视频中提取信息，包含更丰富的基础知识和更好的图像-文本对齐。</p>
<p class='zh-text'>3. 数据集收集了超过2.5年的教学视频，总计22,000课时。</p>
<p class='zh-text'>4. 实验表明，使用这个数据集预训练的VLMs在知识和推理密集型任务中表现出色，并展示了优异的上下文意识能力。</p>
<p class='zh-text'>5. 代码可在GitHub上找到。</p></div>
                <div class="pinyin">
                    <p>1. 这篇文章介绍了一种新的多模态教材数据集，用于视觉-语言模型（VLMs）的预训练。与现有的图像-文本数据集相比，这个数据集从网络上的教学视频中提取信息，包含更丰富的基础知识和更好的图像-文本对齐。数据集收集了超过2</p>
<p>2. 5年的教学视频，总计22,000课时。实验表明，使用这个数据集预训练的VLMs在知识和推理密集型任务中表现出色，并展示了优异的上下文意识能力。代码可在GitHub上找到。

zhè piān wén zhāng jiè shào le yī zhǒng xīn de duō mó tài jiào cái shù jù, yòng yú shì jué - yǔ yán mó xíng (VLMs) de yù xùn liàn</p>
<p>3.  yǔ xiàn yǒu de tú xiàng - wén běn shù jù xiāng bǐ, zhè gè shù jù cóng wǎng luò shàng de jiào xué shì pín zhōng tí qǔ xìn xī, bāo hán gèng fēng fù de jī chǔ zhī shi hé gèng hǎo de tú xiàng - wén běn duì qí</p>
<p>4.  shù jù shōu jí le chāo guò 2</p>
<p>5. 5 nián de jiào xué shì pín, zǒng jì 22,000 kè shí</p>
<p>6.  shí yàn biǎo míng, shǐ yòng zhè gè shù jù yù xùn liàn de VLMs zài zhī shi hé tuī lǐ mì jī xíng rèn wù zhōng biǎo xiàn chū sè, bìng zhàn shì le yōu yì de shàng xià wén yì shí néng lì</p>
<p>7.  dài mǎ kě zài GitHub shàng zhǎo dào</p>
                </div>
                <div><p>1. This article introduces a new multimodal educational dataset for the pre-training of vision-language models (VLMs).</p>
<p>2.  Unlike existing image-text datasets, this dataset extracts information from educational videos on the web, containing richer foundational knowledge and better image-text alignment.</p>
<p>3.  The dataset has collected over 2.</p>
<p>4. 5 years of educational videos, totaling 22,000 hours.</p>
<p>5.  Experiments show that VLMs pre-trained with this dataset perform excellently in knowledge and reasoning-intensive tasks and demonstrate superior context awareness.</p>
<p>6.  The code can be found on GitHub.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">多模态</td>
                            <td>duō mó tài</td>
                            <td>multimodal</td>
                        </tr>
            
                        <tr>
                            <td class="zh">数据集</td>
                            <td>shù jù jí</td>
                            <td>dataset</td>
                        </tr>
            
                        <tr>
                            <td class="zh">预训练</td>
                            <td>yù xùn liàn</td>
                            <td>pre-training</td>
                        </tr>
            
                        <tr>
                            <td class="zh">视觉-语言模型</td>
                            <td>shì jué yǔ yán mó xíng</td>
                            <td>vision-language models</td>
                        </tr>
            
                        <tr>
                            <td class="zh">提取</td>
                            <td>tí qū</td>
                            <td>extract</td>
                        </tr>
            
                        <tr>
                            <td class="zh">对齐</td>
                            <td>duì qí</td>
                            <td>alignment</td>
                        </tr>
            
                        <tr>
                            <td class="zh">课时</td>
                            <td>kè shí</td>
                            <td>class hours</td>
                        </tr>
            
                        <tr>
                            <td class="zh">表现</td>
                            <td>biǎo xiàn</td>
                            <td>performance</td>
                        </tr>
            
                        <tr>
                            <td class="zh">出色</td>
                            <td>chū sè</td>
                            <td>outstanding</td>
                        </tr>
            
                        <tr>
                            <td class="zh">上下文</td>
                            <td>shàng xià wén</td>
                            <td>context</td>
                        </tr>
            
                        <tr>
                            <td class="zh">意识</td>
                            <td>yì shí</td>
                            <td>awareness</td>
                        </tr>
            
                        <tr>
                            <td class="zh">能力</td>
                            <td>néng lì</td>
                            <td>ability</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        