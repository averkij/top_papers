{
    "date": {
        "ru": "12 августа",
        "en": "August 12",
        "zh": "8月12日"
    },
    "time_utc": "2025-08-12 04:20",
    "weekday": 1,
    "issue_id": 5296,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2508.07999",
            "title": "WideSearch: Benchmarking Agentic Broad Info-Seeking",
            "url": "https://huggingface.co/papers/2508.07999",
            "abstract": "WideSearch is a new benchmark evaluating the reliability of automated search agents in large-scale information collection tasks, revealing significant deficiencies in current systems.  \t\t\t\t\tAI-generated summary \t\t\t\t From professional research to everyday planning, many tasks are bottlenecked by wide-scale information seeking, which is more repetitive than cognitively complex. With the rapid development of Large Language Models (LLMs), automated search agents powered by LLMs offer a promising solution to liberate humans from this tedious work. However, the capability of these agents to perform such \"wide-context\" collection reliably and completely remains largely unevaluated due to a lack of suitable benchmarks. To bridge this gap, we introduce WideSearch, a new benchmark engineered to evaluate agent reliability on these large-scale collection tasks. The benchmark features 200 manually curated questions (100 in English, 100 in Chinese) from over 15 diverse domains, grounded in real user queries. Each task requires agents to collect large-scale atomic information, which could be verified one by one objectively, and arrange it into a well-organized output. A rigorous five-stage quality control pipeline ensures the difficulty, completeness, and verifiability of the dataset. We benchmark over 10 state-of-the-art agentic search systems, including single-agent, multi-agent frameworks, and end-to-end commercial systems. Most systems achieve overall success rates near 0\\%, with the best performer reaching just 5\\%. However, given sufficient time, cross-validation by multiple human testers can achieve a near 100\\% success rate. These results demonstrate that present search agents have critical deficiencies in large-scale information seeking, underscoring urgent areas for future research and development in agentic search. Our dataset, evaluation pipeline, and benchmark results have been publicly released at https://widesearch-seed.github.io/",
            "score": 49,
            "issue_id": 5295,
            "pub_date": "2025-08-11",
            "pub_date_card": {
                "ru": "11 августа",
                "en": "August 11",
                "zh": "8月11日"
            },
            "hash": "45f13eb4f1110e39",
            "authors": [
                "Ryan Wong",
                "Jiawei Wang",
                "Junjie Zhao",
                "Li Chen",
                "Yan Gao",
                "Long Zhang",
                "Xuan Zhou",
                "Zuo Wang",
                "Kai Xiang",
                "Ge Zhang",
                "Wenhao Huang",
                "Yang Wang",
                "Ke Wang"
            ],
            "affiliations": [
                "bytedance.com"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.07999.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#benchmark",
                    "#agents",
                    "#dataset",
                    "#survey"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Поисковые агенты на основе ИИ пока не справляются с масштабными задачами",
                    "desc": "WideSearch - это новый эталонный тест для оценки надежности автоматизированных поисковых агентов в задачах сбора информации большого масштаба. Бенчмарк включает 200 вручную отобранных вопросов из более чем 15 различных областей на английском и китайском языках. Тестирование более 10 современных систем агентного поиска показало, что большинство из них достигают общего уровня успешности около 0%, при этом лучший результат составляет всего 5%. Эти результаты демонстрируют критические недостатки современных поисковых агентов в задачах широкомасштабного поиска информации."
                },
                "en": {
                    "title": "WideSearch: Evaluating the Reliability of Automated Search Agents",
                    "desc": "WideSearch is a benchmark designed to assess the reliability of automated search agents in large-scale information collection tasks. It highlights significant shortcomings in current systems, which struggle to perform effectively in wide-context searches. The benchmark includes 200 curated questions across various domains, requiring agents to gather and organize information that can be objectively verified. Results show that most tested systems have low success rates, indicating a need for improvement in agentic search capabilities."
                },
                "zh": {
                    "title": "提升自动搜索代理的可靠性",
                    "desc": "WideSearch是一个新的基准，用于评估自动搜索代理在大规模信息收集任务中的可靠性。当前的系统在执行这些任务时存在显著缺陷，成功率普遍接近0%。该基准包含200个手动策划的问题，涵盖15个不同领域，旨在测试代理收集和组织信息的能力。研究结果表明，现有的搜索代理在大规模信息获取方面亟需改进，未来的研究和开发方向应集中在提升其性能上。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.07629",
            "title": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving\n  Clipping Policy Optimization",
            "url": "https://huggingface.co/papers/2508.07629",
            "abstract": "Klear-Reasoner, a model with long reasoning capabilities, achieves high performance across benchmarks through detailed post-training workflows, including long Chain-of-Thought supervised fine-tuning and reinforcement learning with Gradient-Preserving clipping Policy Optimization.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Klear-Reasoner, a model with long reasoning capabilities that demonstrates careful deliberation during problem solving, achieving outstanding performance across multiple benchmarks. Although there are already many excellent works related to inference models in the current community, there are still many problems with reproducing high-performance inference models due to incomplete disclosure of training details. This report provides an in-depth analysis of the reasoning model, covering the entire post-training workflow from data preparation and long Chain-of-Thought supervised fine-tuning (long CoT SFT) to reinforcement learning (RL), along with detailed ablation studies for each experimental component. For SFT data, our experiments show that a small number of high-quality data sources are more effective than a large number of diverse data sources, and that difficult samples can achieve better results without accuracy filtering. In addition, we investigate two key issues with current clipping mechanisms in RL: Clipping suppresses critical exploration signals and ignores suboptimal trajectories. To address these challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO) that gently backpropagates gradients from clipped tokens. GPPO not only enhances the model's exploration capacity but also improves its efficiency in learning from negative samples. Klear-Reasoner exhibits exceptional reasoning abilities in mathematics and programming, scoring 90.5\\% on AIME 2024, 83.2\\% on AIME 2025, 66.0\\% on LiveCodeBench V5 and 58.1\\% on LiveCodeBench V6.",
            "score": 12,
            "issue_id": 5295,
            "pub_date": "2025-08-11",
            "pub_date_card": {
                "ru": "11 августа",
                "en": "August 11",
                "zh": "8月11日"
            },
            "hash": "a361b2d0bb1f93c2",
            "authors": [
                "Zhenpeng Su",
                "Leiyu Pan",
                "Xue Bai",
                "Dening Liu",
                "Guanting Dong",
                "Jiaming Huang",
                "Wenping Hu",
                "Guorui Zhou"
            ],
            "affiliations": [
                "Klear Team, Kuaishou Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.07629.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#long_context",
                    "#optimization",
                    "#math",
                    "#plp",
                    "#rl",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Klear-Reasoner: Мощный ИИ для длительных рассуждений",
                    "desc": "Klear-Reasoner - это модель с длительными способностями к рассуждению, достигающая высокой производительности в различных тестах. Модель использует детальные пост-тренировочные процессы, включая длинную цепочку рассуждений при обучении с учителем и обучение с подкреплением с использованием оптимизации политики с сохранением градиента. Исследователи обнаружили, что небольшое количество высококачественных источников данных более эффективно, чем большое количество разнообразных источников. Klear-Reasoner демонстрирует исключительные способности к рассуждению в математике и программировании, достигая высоких результатов в тестах AIME и LiveCodeBench."
                },
                "en": {
                    "title": "Klear-Reasoner: Mastering Long Reasoning with Enhanced Learning Techniques",
                    "desc": "Klear-Reasoner is a machine learning model designed for long reasoning tasks, showcasing its ability to solve complex problems effectively. It utilizes a comprehensive post-training workflow that includes long Chain-of-Thought supervised fine-tuning and a novel reinforcement learning approach called Gradient-Preserving clipping Policy Optimization. The model demonstrates that using a few high-quality data sources can be more beneficial than many diverse ones, and it addresses issues in current reinforcement learning methods that hinder exploration. Klear-Reasoner achieves impressive performance on various benchmarks, particularly in mathematics and programming tasks."
                },
                "zh": {
                    "title": "Klear-Reasoner：长推理能力的突破",
                    "desc": "Klear-Reasoner是一种具有长推理能力的模型，能够在解决问题时进行细致的思考，表现出色。该模型通过详细的后训练工作流程，包括长链思维的监督微调和梯度保留剪切策略优化的强化学习，达到了高性能。研究表明，少量高质量的数据源比大量多样化的数据源更有效，且困难样本在没有准确性过滤的情况下也能取得更好的结果。此外，Klear-Reasoner在数学和编程方面展现了卓越的推理能力，取得了多个基准测试的高分。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.05614",
            "title": "OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks",
            "url": "https://huggingface.co/papers/2508.05614",
            "abstract": "OmniEAR evaluates language models' embodied reasoning capabilities in physical interactions, tool usage, and multi-agent coordination, revealing performance degradation under constraints and highlighting architectural limitations.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models excel at abstract reasoning but their capacity for embodied agent reasoning remains largely unexplored. We present OmniEAR, a comprehensive framework for evaluating how language models reason about physical interactions, tool usage, and multi-agent coordination in embodied tasks. Unlike existing benchmarks that provide predefined tool sets or explicit collaboration directives, OmniEAR requires agents to dynamically acquire capabilities and autonomously determine coordination strategies based on task demands. Through text-based environment representation, we model continuous physical properties and complex spatial relationships across 1,500 scenarios spanning household and industrial domains. Our systematic evaluation reveals severe performance degradation when models must reason from constraints: while achieving 85-96% success with explicit instructions, performance drops to 56-85% for tool reasoning and 63-85% for implicit collaboration, with compound tasks showing over 50% failure rates. Surprisingly, complete environmental information degrades coordination performance, indicating models cannot filter task-relevant constraints. Fine-tuning improves single-agent tasks dramatically (0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing fundamental architectural limitations. These findings demonstrate that embodied reasoning poses fundamentally different challenges than current models can address, establishing OmniEAR as a rigorous benchmark for evaluating and advancing embodied AI systems. Our code and data are included in the supplementary materials and will be open-sourced upon acceptance.",
            "score": 12,
            "issue_id": 5294,
            "pub_date": "2025-08-07",
            "pub_date_card": {
                "ru": "7 августа",
                "en": "August 7",
                "zh": "8月7日"
            },
            "hash": "d9c4313e65f213fe",
            "authors": [
                "Zixuan Wang",
                "Dingming Li",
                "Hongxing Li",
                "Shuo Chen",
                "Yuchen Yan",
                "Wenqi Zhang",
                "Yongliang Shen",
                "Weiming Lu",
                "Jun Xiao",
                "Yueting Zhuang"
            ],
            "affiliations": [
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.05614.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#open_source",
                    "#agents",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "OmniEAR: раскрывая ограничения языковых моделей в воплощенном рассуждении",
                    "desc": "OmniEAR - это комплексная система оценки способностей языковых моделей к воплощенному рассуждению в физических взаимодействиях, использовании инструментов и координации между агентами. Фреймворк моделирует непрерывные физические свойства и сложные пространственные отношения в 1500 сценариях бытовых и промышленных задач. Оценка выявила значительное снижение производительности моделей при необходимости рассуждать с учетом ограничений, особенно в сложных задачах. Результаты показывают, что воплощенное рассуждение представляет принципиально иные проблемы, чем те, с которыми могут справиться современные модели."
                },
                "en": {
                    "title": "Evaluating Language Models in Real-World Reasoning Tasks",
                    "desc": "OmniEAR is a framework designed to assess how well language models can reason in real-world scenarios involving physical interactions, tool usage, and teamwork. It highlights that while these models perform well with clear instructions, their performance significantly drops when faced with constraints or when they need to figure things out on their own. The study shows that even with complete information about the environment, models struggle to coordinate effectively, revealing limitations in their architecture. Overall, OmniEAR serves as a new benchmark to push the boundaries of embodied AI capabilities."
                },
                "zh": {
                    "title": "OmniEAR：评估语言模型的体现推理能力",
                    "desc": "OmniEAR是一个评估语言模型在物理交互、工具使用和多智能体协调中的体现推理能力的框架。研究发现，当模型在约束条件下进行推理时，性能显著下降，尤其是在工具推理和隐性协作任务中。尽管在明确指令下模型的成功率高达85-96%，但在复杂任务中失败率超过50%。这些结果表明，现有模型在处理体现推理时面临根本性的挑战，OmniEAR为评估和推动体现人工智能系统提供了严格的基准。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.06600",
            "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of\n  Deep-Research Agent",
            "url": "https://huggingface.co/papers/2508.06600",
            "abstract": "BrowseComp-Plus, a curated benchmark, enables controlled evaluation of deep research agents and retrieval methods, providing insights into their performance and effectiveness.  \t\t\t\t\tAI-generated summary \t\t\t\t Deep-Research agents, which integrate large language models (LLMs) with search tools, have shown success in improving the effectiveness of handling complex queries that require iterative search planning and reasoning over search results. Evaluations on current benchmarks like BrowseComp relies on black-box live web search APIs, have notable limitations in (1) fairness: dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep research methods; (2) transparency: lack of control over the document corpus makes it difficult to isolate retriever contributions. In other words, the current evaluations may compare a complete deep research system at a given time, but they do not foster well-controlled experiments to provide insights into the capability of underlying deep research LLMs. To address these challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp, employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus includes human-verified supporting documents and mined challenging negatives, enabling controlled experimentation. The benchmark is shown to be effective in distinguishing the performance of deep research systems. For instance, the open-source model Search-R1, when paired with the BM25 retriever, achieves 3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with fewer search calls. This benchmark allows comprehensive evaluation and disentangled analysis of deep research agents and retrieval methods, fostering insights into retrieval effectiveness, citation accuracy, and context engineering in Deep-Research system.",
            "score": 9,
            "issue_id": 5295,
            "pub_date": "2025-08-08",
            "pub_date_card": {
                "ru": "8 августа",
                "en": "August 8",
                "zh": "8月8日"
            },
            "hash": "bbe851198d9c0416",
            "authors": [
                "Zijian Chen",
                "Xueguang Ma",
                "Shengyao Zhuang",
                "Ping Nie",
                "Kai Zou",
                "Andrew Liu",
                "Joshua Green",
                "Kshama Patel",
                "Ruoxi Meng",
                "Mingyi Su",
                "Sahel Sharifymoghaddam",
                "Yanxi Li",
                "Haoran Hong",
                "Xinyu Shi",
                "Xuye Liu",
                "Nandan Thakur",
                "Crystina Zhang",
                "Luyu Gao",
                "Wenhu Chen",
                "Jimmy Lin"
            ],
            "affiliations": [
                "CSIRO",
                "Carnegie Mellon University",
                "Independent",
                "The University of Queensland",
                "University of Waterloo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.06600.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#rag",
                    "#ethics",
                    "#benchmark",
                    "#agents",
                    "#open_source"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "BrowseComp-Plus: Прозрачная оценка агентов глубокого исследования",
                    "desc": "BrowseComp-Plus - это новый эталонный тест для оценки агентов глубокого исследования и методов извлечения информации. Он использует фиксированный, тщательно отобранный корпус документов, что позволяет проводить контролируемые эксперименты. Тест эффективно различает производительность различных систем глубокого исследования, например, показывая, что GPT-5 достигает точности 55.9%, а при интеграции с ретривером Qwen3-Embedding-8B точность повышается до 70.1%. BrowseComp-Plus способствует получению новых знаний об эффективности извлечения информации, точности цитирования и инженерии контекста в системах глубокого исследования."
                },
                "en": {
                    "title": "BrowseComp-Plus: A Fair Benchmark for Deep Research Evaluation",
                    "desc": "BrowseComp-Plus is a new benchmark designed to evaluate deep research agents and retrieval methods in a controlled manner. It addresses limitations of existing benchmarks by using a fixed, curated document corpus, allowing for fair comparisons and reproducibility. The benchmark includes human-verified documents and challenging negatives for each query, enabling detailed analysis of the performance of different deep research systems. Results show significant improvements in accuracy when using advanced models like GPT-5, highlighting the effectiveness of this new evaluation framework."
                },
                "zh": {
                    "title": "BrowseComp-Plus：深度研究的公平评估工具",
                    "desc": "BrowseComp-Plus是一个经过精心策划的基准测试，旨在对深度研究代理和检索方法进行控制评估。它解决了现有基准测试在公平性和透明性方面的局限性，通过使用固定的文档库来确保实验的可控性。每个查询都包含经过人工验证的支持文档和具有挑战性的负样本，从而使得实验结果更具可信度。该基准测试有效区分了不同深度研究系统的性能，提供了对检索有效性和引用准确性的深入分析。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.08134",
            "title": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided\n  Region Control",
            "url": "https://huggingface.co/papers/2508.08134",
            "abstract": "Follow-Your-Shape framework uses a Trajectory Divergence Map and Scheduled KV Injection to enable precise and controllable shape editing in images while preserving non-target content.  \t\t\t\t\tAI-generated summary \t\t\t\t While recent flow-based image editing models demonstrate general-purpose capabilities across diverse tasks, they often struggle to specialize in challenging scenarios -- particularly those involving large-scale shape transformations. When performing such structural edits, these methods either fail to achieve the intended shape change or inadvertently alter non-target regions, resulting in degraded background quality. We propose Follow-Your-Shape, a training-free and mask-free framework that supports precise and controllable editing of object shapes while strictly preserving non-target content. Motivated by the divergence between inversion and editing trajectories, we compute a Trajectory Divergence Map (TDM) by comparing token-wise velocity differences between the inversion and denoising paths. The TDM enables precise localization of editable regions and guides a Scheduled KV Injection mechanism that ensures stable and faithful editing. To facilitate a rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120 new images and enriched prompt pairs specifically curated for shape-aware editing. Experiments demonstrate that our method achieves superior editability and visual fidelity, particularly in tasks requiring large-scale shape replacement.",
            "score": 5,
            "issue_id": 5295,
            "pub_date": "2025-08-11",
            "pub_date_card": {
                "ru": "11 августа",
                "en": "August 11",
                "zh": "8月11日"
            },
            "hash": "46943e7de387bfc9",
            "authors": [
                "Zeqian Long",
                "Mingzhe Zheng",
                "Kunyu Feng",
                "Xinhua Zhang",
                "Hongyu Liu",
                "Harry Yang",
                "Linfeng Zhang",
                "Qifeng Chen",
                "Yue Ma"
            ],
            "affiliations": [
                "HKUST",
                "Shanghai Jiao Tong University",
                "University of Illinois at Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.08134.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#cv",
                    "#games"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Точное редактирование форм объектов с сохранением фона",
                    "desc": "Статья представляет новый фреймворк Follow-Your-Shape для точного и контролируемого редактирования форм объектов на изображениях. Метод использует карту расхождения траекторий (Trajectory Divergence Map) для локализации редактируемых областей. Предложенный механизм планового введения ключей и значений (Scheduled KV Injection) обеспечивает стабильное и точное редактирование. Авторы также представляют новый бенчмарк ReShapeBench для оценки методов редактирования форм."
                },
                "en": {
                    "title": "Precision in Shape Editing with Follow-Your-Shape",
                    "desc": "The Follow-Your-Shape framework introduces a novel approach for shape editing in images, focusing on maintaining the quality of non-target content. It utilizes a Trajectory Divergence Map (TDM) to analyze differences in editing paths, allowing for precise localization of areas that can be modified. Additionally, the Scheduled KV Injection mechanism ensures that the editing process remains stable and accurate. This method outperforms existing models, especially in complex scenarios involving significant shape transformations, while also introducing a new benchmark for evaluating shape-aware editing."
                },
                "zh": {
                    "title": "精确可控的形状编辑新方法",
                    "desc": "Follow-Your-Shape框架利用轨迹发散图和调度KV注入技术，实现了图像中形状的精确和可控编辑，同时保持非目标内容的完整性。该方法解决了现有基于流的图像编辑模型在大规模形状变换中的不足，避免了对非目标区域的意外修改。通过计算反演和去噪路径之间的速度差异，Follow-Your-Shape能够精确定位可编辑区域。我们还引入了ReShapeBench基准，专门用于形状感知编辑的评估，实验结果表明该方法在大规模形状替换任务中表现出色。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.07917",
            "title": "MolmoAct: Action Reasoning Models that can Reason in Space",
            "url": "https://huggingface.co/papers/2508.07917",
            "abstract": "Action Reasoning Models (ARMs) integrate perception, planning, and control to enable adaptable and explainable robotic behavior, achieving superior performance across various tasks and settings.  \t\t\t\t\tAI-generated summary \t\t\t\t Reasoning is central to purposeful action, yet most robotic foundation models map perception and instructions directly to control, which limits adaptability, generalization, and semantic grounding. We introduce Action Reasoning Models (ARMs), a class of vision-language-action models that integrate perception, planning, and control through a structured three-stage pipeline. Our model, MolmoAct, encodes observations and instructions into depth-aware perception tokens, generates mid-level spatial plans as editable trajectory traces, and predicts precise low-level actions, enabling explainable and steerable behavior. MolmoAct-7B-D achieves strong performance across simulation and real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks; and in real-world fine-tuning, an additional 10% (single-arm) and an additional 22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines by an additional 23.3% on out-of-distribution generalization and achieves top human-preference scores for open-ended instruction following and trajectory steering. Furthermore, we release, for the first time, the MolmoAct Dataset -- a mid-training robot dataset comprising over 10,000 high quality robot trajectories across diverse scenarios and tasks. Training with this dataset yields an average 5.5% improvement in general performance over the base model. We release all model weights, training code, our collected dataset, and our action reasoning dataset, establishing MolmoAct as both a state-of-the-art robotics foundation model and an open blueprint for building ARMs that transform perception into purposeful action through structured reasoning. Blogpost: https://allenai.org/blog/molmoact",
            "score": 4,
            "issue_id": 5294,
            "pub_date": "2025-08-11",
            "pub_date_card": {
                "ru": "11 августа",
                "en": "August 11",
                "zh": "8月11日"
            },
            "hash": "fa9d385dde41879a",
            "authors": [
                "Jason Lee",
                "Jiafei Duan",
                "Haoquan Fang",
                "Yuquan Deng",
                "Shuo Liu",
                "Boyang Li",
                "Bohan Fang",
                "Jieyu Zhang",
                "Yi Ru Wang",
                "Sangho Lee",
                "Winson Han",
                "Wilbert Pumacay",
                "Angelica Wu",
                "Rose Hendrix",
                "Karen Farley",
                "Eli VanderBilt",
                "Ali Farhadi",
                "Dieter Fox",
                "Ranjay Krishna"
            ],
            "affiliations": [
                "Allen Institute for AI",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.07917.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#robotics",
                    "#agents",
                    "#dataset",
                    "#reasoning",
                    "#training"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "MolmoAct: Разумные действия роботов через структурированное рассуждение",
                    "desc": "Модель Action Reasoning Models (ARM) интегрирует восприятие, планирование и управление для адаптивного и объяснимого поведения роботов. MolmoAct, реализация ARM, кодирует наблюдения и инструкции в токены восприятия с учетом глубины, генерирует пространственные планы в виде редактируемых траекторий и прогнозирует точные низкоуровневые действия. Модель достигает высокой производительности в симуляциях и реальных условиях, превосходя базовые модели в задачах с нулевым обучением, долгосрочном планировании и обобщении на новые распределения. Авторы также выпускают набор данных MolmoAct Dataset, содержащий более 10000 высококачественных траекторий роботов."
                },
                "en": {
                    "title": "Transforming Perception into Purposeful Action with ARMs",
                    "desc": "Action Reasoning Models (ARMs) are designed to enhance robotic behavior by combining perception, planning, and control in a structured way. The proposed model, MolmoAct, processes observations and instructions into depth-aware tokens, creates editable spatial plans, and predicts specific actions, making the robot's behavior more explainable and adaptable. MolmoAct demonstrates impressive performance in both simulated and real-world tasks, outperforming existing models in accuracy and generalization. Additionally, the introduction of the MolmoAct Dataset provides valuable training data, further improving the model's capabilities and establishing a new standard in robotics."
                },
                "zh": {
                    "title": "行动推理模型：将感知转化为有目的的行动",
                    "desc": "行动推理模型（ARMs）结合了感知、规划和控制，能够实现灵活和可解释的机器人行为，提升了在各种任务和环境中的表现。我们提出的MolmoAct模型通过一个结构化的三阶段流程，将观察和指令编码为深度感知标记，生成可编辑的中级空间计划，并预测精确的低级动作。该模型在模拟和现实世界中表现出色，尤其在长时间任务上超越了现有的基线模型。我们还首次发布了MolmoAct数据集，包含超过10,000条高质量机器人轨迹，训练该数据集可显著提升模型的整体性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.06026",
            "title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via\n  Past-Future",
            "url": "https://huggingface.co/papers/2508.06026",
            "abstract": "Temporal Self-Rewarding Language Models improve generative capabilities by strategically using past and future model outputs, enhancing preference learning and out-of-distribution generalization.  \t\t\t\t\tAI-generated summary \t\t\t\t Self-Rewarding Language Models propose an architecture in which the Large Language Models(LLMs) both generates responses and evaluates its own outputs via LLM-as-a-Judge prompting, dynamically improving its generative capabilities through iterative Direct Preference Optimization (DPO). However, our analysis reveals a critical limitation in existing Self-Rewarding paradigms: the synchronized improvement of chosen and rejected responses progressively narrows the representational difference between contrasting samples, undermining effective preference learning. We propose Temporal Self-Rewarding Language Models that strategically coordinate past, present, and future model generations to sustain learning signals. Our dual-phase framework introduces: (1) Anchored Rejection - fixing rejected responses using the past initial model's outputs and (2) Future-Guided Chosen - dynamically curating chosen samples using next-generation model predictions. Extensive experiments across three model families (Llama, Qwen, Mistral) and different model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained with our method compared to Self-Rewarding using same computation resources. For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our method also demonstrates superior out-of-distribution generalization across mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code generation (HumanEval) tasks, even though we do not specifically collect such training data.",
            "score": 3,
            "issue_id": 5296,
            "pub_date": "2025-08-08",
            "pub_date_card": {
                "ru": "8 августа",
                "en": "August 8",
                "zh": "8月8日"
            },
            "hash": "9118094d6c4509d1",
            "authors": [
                "Yidong Wang",
                "Xin Wang",
                "Cunxiang Wang",
                "Junfeng Fang",
                "Qiufeng Wang",
                "Jianing Chu",
                "Xuran Meng",
                "Shuxun Yang",
                "Libo Qin",
                "Yue Zhang",
                "Wei Ye",
                "Shikun Zhang"
            ],
            "affiliations": [
                "Beijing Institute of Technology",
                "Central South University",
                "National University of Singapore",
                "North Carolina State University",
                "Peking University",
                "Southeast University",
                "Tsinghua University",
                "University of Michigan",
                "Westlake University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.06026.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#agi",
                    "#rlhf",
                    "#architecture",
                    "#optimization",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "⏳",
                "ru": {
                    "title": "Временная самокоррекция: новый шаг в развитии языковых моделей",
                    "desc": "Предложена новая архитектура языковых моделей под названием Temporal Self-Rewarding Language Models. Эта архитектура улучшает генеративные способности моделей, стратегически используя прошлые и будущие выходные данные модели. Метод включает в себя две фазы: фиксацию отвергнутых ответов с использованием выходных данных начальной модели и динамический отбор выбранных образцов с использованием предсказаний модели следующего поколения. Эксперименты показали значительные улучшения по сравнению с базовыми методами самовознаграждения, особенно в задачах вне распределения обучающих данных."
                },
                "en": {
                    "title": "Enhancing Language Models with Temporal Self-Rewarding Strategies",
                    "desc": "This paper introduces Temporal Self-Rewarding Language Models, which enhance the generative abilities of language models by effectively utilizing outputs from past and future generations. The proposed architecture allows models to generate responses and evaluate them through a self-judging mechanism, improving performance via Direct Preference Optimization. A key innovation is the dual-phase framework that includes Anchored Rejection and Future-Guided Chosen strategies, which help maintain diverse learning signals and improve preference learning. Experimental results show that this approach significantly outperforms traditional Self-Rewarding methods across various tasks and model sizes, demonstrating better generalization capabilities."
                },
                "zh": {
                    "title": "时间自奖励模型：提升生成能力的新策略",
                    "desc": "本文提出了一种时间自奖励语言模型，通过战略性地利用过去和未来的模型输出，提升生成能力和偏好学习。该模型采用了自我评估机制，使大型语言模型（LLMs）能够生成响应并评估自身输出，从而通过直接偏好优化（DPO）不断改进生成能力。研究发现，现有自奖励模型存在一个关键限制，即选择和拒绝响应的同步改进会逐渐缩小对比样本之间的表示差异，影响有效的偏好学习。为此，本文提出了时间自奖励语言模型，通过协调过去、现在和未来的生成，保持学习信号，从而显著提高模型的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.07101",
            "title": "Less Is More: Training-Free Sparse Attention with Global Locality for\n  Efficient Reasoning",
            "url": "https://huggingface.co/papers/2508.07101",
            "abstract": "LessIsMore is a training-free sparse attention mechanism that improves efficiency and generalization in reasoning tasks by aggregating token selections from local attention heads.  \t\t\t\t\tAI-generated summary \t\t\t\t Large reasoning models achieve strong performance through test-time scaling but incur substantial computational overhead, particularly from excessive token generation when processing short input prompts. While sparse attention mechanisms can reduce latency and memory usage, existing approaches suffer from significant accuracy degradation due to accumulated errors during long-generation reasoning. These methods generally require either high token retention rates or expensive retraining. We introduce LessIsMore, a training-free sparse attention mechanism for reasoning tasks, which leverages global attention patterns rather than relying on traditional head-specific local optimizations. LessIsMore aggregates token selections from local attention heads with recent contextual information, enabling unified cross-head token ranking for future decoding layers. This unified selection improves generalization and efficiency by avoiding the need to maintain separate token subsets per head. Evaluation across diverse reasoning tasks and benchmarks shows that LessIsMore preserves -- and in some cases improves -- accuracy while achieving a 1.1times average decoding speed-up compared to full attention. Moreover, LessIsMore attends to 2times fewer tokens without accuracy loss, achieving a 1.13times end-to-end speed-up compared to existing sparse attention methods.",
            "score": 2,
            "issue_id": 5296,
            "pub_date": "2025-08-09",
            "pub_date_card": {
                "ru": "9 августа",
                "en": "August 9",
                "zh": "8月9日"
            },
            "hash": "7365d6ccd543770b",
            "authors": [
                "Lijie Yang",
                "Zhihao Zhang",
                "Arti Jain",
                "Shijie Cao",
                "Baihong Yuan",
                "Yiwei Chen",
                "Zhihao Jia",
                "Ravi Netravali"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Microsoft Research",
                "Princeton University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.07101.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#optimization",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Меньше значит больше: эффективное разреженное внимание для улучшенного рассуждения",
                    "desc": "LessIsMore - это механизм разреженного внимания, не требующий дополнительного обучения, который улучшает эффективность и обобщающую способность в задачах рассуждения. Он агрегирует выбор токенов из локальных голов внимания с недавней контекстной информацией, что позволяет проводить единый ранжирование токенов для будущих слоев декодирования. Этот подход улучшает обобщение и эффективность, избегая необходимости поддерживать отдельные подмножества токенов для каждой головы. Оценка на различных задачах рассуждения показывает, что LessIsMore сохраняет или даже улучшает точность, при этом ускоряя декодирование в среднем в 1.1 раза по сравнению с полным вниманием."
                },
                "en": {
                    "title": "LessIsMore: Efficient Reasoning with Sparse Attention",
                    "desc": "LessIsMore is a novel sparse attention mechanism designed to enhance efficiency and generalization in reasoning tasks without the need for retraining. It aggregates token selections from local attention heads, utilizing global attention patterns to improve the decision-making process during decoding. This approach allows for a unified ranking of tokens across different heads, which reduces the number of tokens processed while maintaining or even improving accuracy. Evaluations demonstrate that LessIsMore achieves faster decoding speeds and lower token usage compared to traditional sparse attention methods, making it a significant advancement in the field."
                },
                "zh": {
                    "title": "LessIsMore：高效推理的新选择",
                    "desc": "LessIsMore是一种无训练的稀疏注意力机制，旨在提高推理任务的效率和泛化能力。它通过聚合来自局部注意力头的标记选择，利用全局注意力模式，而不是依赖传统的头特定局部优化。该方法在推理过程中避免了维护每个头的独立标记子集，从而提高了通用性和效率。评估结果表明，LessIsMore在保持或提高准确性的同时，解码速度平均提升了1.1倍，并且在不损失准确性的情况下，关注的标记数量减少了2倍。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.07050",
            "title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability",
            "url": "https://huggingface.co/papers/2508.07050",
            "abstract": "A reasoning-intensive reranker, ReasonRank, achieves state-of-the-art performance in passage ranking tasks by using synthesized training data and a two-stage post-training approach with reinforcement learning.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Model (LLM) based listwise ranking has shown superior performance in many passage ranking tasks. With the development of Large Reasoning Models, many studies have demonstrated that step-by-step reasoning during test-time helps improve listwise ranking performance. However, due to the scarcity of reasoning-intensive training data, existing rerankers perform poorly in many complex ranking scenarios and the ranking ability of reasoning-intensive rerankers remains largely underdeveloped. In this paper, we first propose an automated reasoning-intensive training data synthesis framework, which sources training queries and passages from diverse domains and applies DeepSeek-R1 to generate high-quality training labels. A self-consistency data filtering mechanism is designed to ensure the data quality. To empower the listwise reranker with strong reasoning ability, we further propose a two-stage post-training approach, which includes a cold-start supervised fine-tuning (SFT) stage for reasoning pattern learning and a reinforcement learning (RL) stage for further ranking ability enhancement. During the RL stage, based on the nature of listwise ranking, we design a multi-view ranking reward, which is more effective than a ranking metric-based reward. Extensive experiments demonstrate that our trained reasoning-intensive reranker ReasonRank outperforms existing baselines significantly and also achieves much lower latency than pointwise reranker Rank1. Through further experiments, our ReasonRank has achieved state-of-the-art (SOTA) performance 40.6 on the BRIGHT leaderboard\\footnote{https://brightbenchmark.github.io/.} Our codes are available at https://github.com/8421BCD/ReasonRank.",
            "score": 1,
            "issue_id": 5296,
            "pub_date": "2025-08-09",
            "pub_date_card": {
                "ru": "9 августа",
                "en": "August 9",
                "zh": "8月9日"
            },
            "hash": "bfd8a67bb2b2dbf4",
            "authors": [
                "Wenhan Liu",
                "Xinyu Ma",
                "Weiwei Sun",
                "Yutao Zhu",
                "Yuchen Li",
                "Dawei Yin",
                "Zhicheng Dou"
            ],
            "affiliations": [
                "Baidu Inc.",
                "Carnegie Mellon University",
                "Gaoling School of Artificial Intelligence, Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.07050.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#optimization",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "ReasonRank: Рассуждающий ранжировщик нового поколения",
                    "desc": "ReasonRank - это новый ранжировщик пассажей, использующий синтезированные данные для обучения и двухэтапный подход с обучением с подкреплением. Он применяет пошаговое рассуждение во время тестирования для улучшения производительности ранжирования списков. Модель использует автоматизированную систему синтеза обучающих данных с рассуждениями и механизм фильтрации для обеспечения качества данных. ReasonRank достигает наилучших результатов в задачах ранжирования пассажей, превосходя существующие базовые модели."
                },
                "en": {
                    "title": "ReasonRank: Elevating Passage Ranking with Advanced Reasoning Techniques",
                    "desc": "The paper introduces ReasonRank, a novel reranker that excels in passage ranking tasks by leveraging synthesized training data and a two-stage post-training method involving reinforcement learning. It addresses the challenge of limited reasoning-intensive training data by creating a framework that generates high-quality training labels from diverse domains. The two-stage approach consists of a supervised fine-tuning phase to learn reasoning patterns, followed by a reinforcement learning phase that enhances ranking capabilities using a multi-view ranking reward. Experimental results show that ReasonRank achieves state-of-the-art performance while maintaining lower latency compared to traditional pointwise rerankers."
                },
                "zh": {
                    "title": "推理强化重排序，提升段落排名性能！",
                    "desc": "本文提出了一种名为ReasonRank的推理强化重排序模型，旨在提高段落排名任务的性能。通过合成训练数据和两阶段的后训练方法，ReasonRank在复杂的排名场景中表现出色。我们设计了一种自动化的推理训练数据合成框架，并引入了自一致性数据过滤机制，以确保数据质量。最终，ReasonRank在BRIGHT排行榜上达到了40.6的最新性能，显著优于现有基线模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2508.06601",
            "title": "Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant\n  Safeguards into Open-Weight LLMs",
            "url": "https://huggingface.co/papers/2508.06601",
            "abstract": "Data filtering during pretraining enhances LLM resistance to adversarial fine-tuning attacks without degrading unrelated capabilities, offering a promising defense mechanism for open-weight AI systems.  \t\t\t\t\tAI-generated summary \t\t\t\t Open-weight AI systems offer unique benefits, including enhanced transparency, open research, and decentralized access. However, they are vulnerable to tampering attacks which can efficiently elicit harmful behaviors by modifying weights or activations. Currently, there is not yet a robust science of open-weight model risk management. Existing safety fine-tuning methods and other post-training techniques have struggled to make LLMs resistant to more than a few dozen steps of adversarial fine-tuning. In this paper, we investigate whether filtering text about dual-use topics from training data can prevent unwanted capabilities and serve as a more tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable data filtering and show that it offers a tractable and effective method for minimizing biothreat proxy knowledge in LLMs. We pretrain multiple 6.9B-parameter models from scratch and find that they exhibit substantial resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M tokens of biothreat-related text -- outperforming existing post-training baselines by over an order of magnitude -- with no observed degradation to unrelated capabilities. However, while filtered models lack internalized dangerous knowledge, we find that they can still leverage such information when it is provided in context (e.g., via search tool augmentation), demonstrating a need for a defense-in-depth approach. Overall, these findings help to establish pretraining data curation as a promising layer of defense for open-weight AI systems.",
            "score": 0,
            "issue_id": 5294,
            "pub_date": "2025-08-08",
            "pub_date_card": {
                "ru": "8 августа",
                "en": "August 8",
                "zh": "8月8日"
            },
            "hash": "4d2d99e849d503f3",
            "authors": [
                "Kyle O'Brien",
                "Stephen Casper",
                "Quentin Anthony",
                "Tomek Korbak",
                "Robert Kirk",
                "Xander Davies",
                "Ishan Mishra",
                "Geoffrey Irving",
                "Yarin Gal",
                "Stella Biderman"
            ],
            "affiliations": [
                "EleutherAI",
                "OATML, University of Oxford",
                "UK AI Security Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2508.06601.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#open_source",
                    "#security",
                    "#data"
                ],
                "emoji": "🛡️",
                "ru": {
                    "title": "Фильтрация данных как защита от атак на открытые ИИ-системы",
                    "desc": "Статья исследует возможность фильтрации текстов о двойном назначении из обучающих данных для предотвращения нежелательных способностей в языковых моделях. Авторы разработали многоэтапный конвейер для масштабируемой фильтрации данных и продемонстрировали его эффективность в минимизации знаний о биоугрозах в больших языковых моделях. Эксперименты показали, что предобученные на отфильтрованных данных модели демонстрируют значительную устойчивость к атакам состязательной дообучения, превосходя существующие базовые показатели более чем на порядок. Однако отфильтрованные модели все еще могут использовать опасную информацию, предоставленную в контексте, что указывает на необходимость многоуровневого подхода к защите."
                },
                "en": {
                    "title": "Data Filtering: A Shield for Open-Weight AI Systems",
                    "desc": "This paper explores how filtering training data can improve the resilience of large language models (LLMs) against adversarial fine-tuning attacks. By removing text related to dual-use topics, the authors create a multi-stage data filtering pipeline that enhances the models' resistance without harming their unrelated capabilities. The study shows that pretrained models can withstand significant adversarial attacks, outperforming existing methods by a large margin. However, the research also highlights that while these models do not retain dangerous knowledge, they can still respond to such information when presented in context, indicating the need for comprehensive defense strategies."
                },
                "zh": {
                    "title": "数据过滤提升LLM对抗攻击的防御能力",
                    "desc": "本文探讨了在预训练阶段进行数据过滤如何增强大型语言模型（LLM）对对抗性微调攻击的抵抗力，同时不影响其其他能力。研究表明，通过过滤与双重用途相关的文本，可以有效防止模型学习不必要的能力，从而提供更强的防护机制。我们提出了一种多阶段的数据过滤流程，经过实验证明，该方法在抵御对抗性微调攻击方面表现优异，且未观察到对无关能力的降级。总体而言，这些发现为开放权重的人工智能系统建立了一个有前景的防御层。"
                }
            }
        }
    ],
    "link_prev": "2025-08-11.html",
    "link_next": "2025-08-13.html",
    "link_month": "2025-08.html",
    "short_date_prev": {
        "ru": "11.08",
        "en": "08/11",
        "zh": "8月11日"
    },
    "short_date_next": {
        "ru": "13.08",
        "en": "08/13",
        "zh": "8月13日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 6,
        "#agents": 4,
        "#cv": 1,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 1,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 6,
        "#robotics": 1,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 6,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 1,
        "#optimization": 5,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    }
}