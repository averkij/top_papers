
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Qwen2.5 Technical Report</h1>
                <div><p class='zh-text'>1. 这篇文章介绍了Qwen2.5，一个大型语言模型系列。</p>
<p class='zh-text'>2. 与以前的版本相比，Qwen2.5在预训练和后训练阶段都有显著改进。</p>
<p class='zh-text'>3. 预训练数据集从7万亿个标记扩展到18万亿个，增强了常识、专业知识和推理能力。</p>
<p class='zh-text'>4. 后训练技术提高了人类偏好，改善了长文本生成和结构化数据分析。</p>
<p class='zh-text'>5. Qwen2.5系列提供多种尺寸和版本，包括基础模型和指令调整模型。</p></div>
                <div class="pinyin">
                    <p>1. 这篇文章介绍了Qwen2</p>
<p>2. 5，一个大型语言模型系列。
Zhè piān wénzhāng jièshào le Qwen2</p>
<p>3. 5, yīgè dàxíng yǔyán móxíng xìliè</p>
<p>4. 

与以前的版本相比，Qwen2</p>
<p>5. 5在预训练和后训练阶段都有显著改进。
Yǔ yǐqián de bǎnběn xiāngbǐ, Qwen2</p>
<p>6. 5 zài yùxùnliàn hé hòuxùnliàn jiēduàn dōu yǒu xiǎnzhù gǎijìn</p>
<p>7. 

预训练数据集从7万亿个标记扩展到18万亿个，增强了常识、专业知识和推理能力。
Yùxùnliàn shùjùjí cóng 7 wànyì gè biāojì kuòzhǎn dào 18 wànyì gè, zēngqiáng le chángshí, zhuānyè zhīshi hé tuīlǐ nénglì</p>
<p>8. 

后训练技术提高了人类偏好，改善了长文本生成和结构化数据分析。
Hòuxùnliàn jìshù tígāo le rénlèi piānhào, gǎishàn le cháng wénběn shēngchéng hé jiégòuhuà shùjù fēnxi</p>
<p>9. 

Qwen2</p>
<p>10. 5系列提供多种尺寸和版本，包括基础模型和指令调整模型。
Qwen2</p>
<p>11. 5 xìliè tígōng duōzhǒng chǐcūn hé bǎnběn, bāokuò jīchǔ móxíng hé zhǐlìng tiáozhěng móxíng</p>
                </div>
                <div><p>1. This article introduces Qwen2.</p>
<p>2. 5, a series of large language models.</p>
<p>3.  Compared to previous versions, Qwen2.</p>
<p>4. 5 has significant improvements in both the pre-training and post-training stages.</p>
<p>5.  The pre-training dataset has been expanded from 7 trillion tokens to 18 trillion tokens, enhancing common sense, professional knowledge, and reasoning abilities.</p>
<p>6.  Post-training techniques have improved human preference, enhancing long text generation and structured data analysis.</p>
<p>7.  The Qwen2.</p>
<p>8. 5 series offers various sizes and versions, including base models and instruction-tuned models.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">篇</td>
                            <td>piān</td>
                            <td>article</td>
                        </tr>
            
                        <tr>
                            <td class="zh">介绍</td>
                            <td>jièshào</td>
                            <td>introduce</td>
                        </tr>
            
                        <tr>
                            <td class="zh">语言模型</td>
                            <td>yǔyán móxíng</td>
                            <td>language model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">系列</td>
                            <td>xìliè</td>
                            <td>series</td>
                        </tr>
            
                        <tr>
                            <td class="zh">版本</td>
                            <td>bǎnběn</td>
                            <td>version</td>
                        </tr>
            
                        <tr>
                            <td class="zh">预训练</td>
                            <td>yù xùnliàn</td>
                            <td>pre-training</td>
                        </tr>
            
                        <tr>
                            <td class="zh">后训练</td>
                            <td>hòu xùnliàn</td>
                            <td>post-training</td>
                        </tr>
            
                        <tr>
                            <td class="zh">显著</td>
                            <td>xiǎnzhù</td>
                            <td>significant</td>
                        </tr>
            
                        <tr>
                            <td class="zh">改进</td>
                            <td>gǎijìn</td>
                            <td>improvement</td>
                        </tr>
            
                        <tr>
                            <td class="zh">标记</td>
                            <td>biāojì</td>
                            <td>token</td>
                        </tr>
            
                        <tr>
                            <td class="zh">扩展</td>
                            <td>kuòzhǎn</td>
                            <td>expand</td>
                        </tr>
            
                        <tr>
                            <td class="zh">常识</td>
                            <td>chángshí</td>
                            <td>common sense</td>
                        </tr>
            
                        <tr>
                            <td class="zh">专业知识</td>
                            <td>zhuānyè zhīshi</td>
                            <td>professional knowledge</td>
                        </tr>
            
                        <tr>
                            <td class="zh">推理</td>
                            <td>tuīlǐ</td>
                            <td>reasoning</td>
                        </tr>
            
                        <tr>
                            <td class="zh">偏好</td>
                            <td>piānhào</td>
                            <td>preference</td>
                        </tr>
            
                        <tr>
                            <td class="zh">长文本</td>
                            <td>cháng wénběn</td>
                            <td>long text</td>
                        </tr>
            
                        <tr>
                            <td class="zh">结构化</td>
                            <td>jiégòuhuà</td>
                            <td>structured</td>
                        </tr>
            
                        <tr>
                            <td class="zh">数据分析</td>
                            <td>shùjù fēnxī</td>
                            <td>data analysis</td>
                        </tr>
            
                        <tr>
                            <td class="zh">尺寸</td>
                            <td>chǐcùn</td>
                            <td>size</td>
                        </tr>
            
                        <tr>
                            <td class="zh">基础模型</td>
                            <td>jīchǔ móxíng</td>
                            <td>base model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">指令调整</td>
                            <td>zhǐlìng tiáozhěng</td>
                            <td>instruction tuning</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        