
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF (11 статей)</title>
    <link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #0989eacf;
            --secondary-color: #fff;
            --background-color: #f5f5f5;
            --text-color: #333333;
            --header-color: #0989eacf;
            --body-color: #f5f5f5;
            --menu-color: #002370;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        header {
            padding: 3em 0;
            text-align: center;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2em;
            padding: 10px 0 20px 0;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.tags {
            color: #555;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 6px rgba(0,0,0,0.16), 0 3px 6px rgba(0,0,0,0.23);
            transition: background-color 0.2s ease;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .article-content {
            padding: 1.5em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
        }
        body.dark-theme>div>main>article {
            background-color: #444;
        }
        body.light-theme>div>main>article {
            background-color: #fff;
        }
        body.dark-theme>div>main>article:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
        }
        .pub-date {
            font-size: 0.9em;
            margin-bottom: 0.8em;
            font-weight: 300;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 1em;
            position: absolute;
            bottom: 10px;
            font-weight: 300;
            font-family: 'Roboto Slab';
        }
        .background-digit {
            position: absolute;
            bottom: -20px;
            right: -10px;
            font-size: 12em;
            font-weight: bold;
            color: rgba(0, 0, 0, 0.03);
            z-index: 0;
            line-height: 1;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 80px;
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        a:hover {
            color: var(--secondary-color);
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 1em 0;
            margin-top: 2em;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: fixed;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
        }
        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
        }
        .update-info-container {
            flex: 1;
        }
        .sort-container {
            flex: 2;
        }
        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
                display: block;
                margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .category-toggle {
            display: inline-block;
            margin-bottom: 10px;
            margin-top: 15px;
            cursor: pointer;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }
        
        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        body.light-theme>div>main>article.x2dc1395b8aa096fc { background: url("https://hfday.ru/img/20241023/2dc1395b8aa096fc.jpg") !important; background-size: cover !important; background-position: center !important; background-blend-mode: lighten !important; background-color: rgba(255,255,255,0.91) !important;}
body.light-theme>div>main>article.x2dc1395b8aa096fc:hover { background-color: rgba(255,255,255,0.95) !important;}
body.dark-theme>div>main>article.x2dc1395b8aa096fc { background: url("https://hfday.ru/img/20241023/2dc1395b8aa096fc.jpg") !important; background-size: cover !important; background-position: center !important; background-blend-mode: hue !important; background-color: rgba(60,60,60,0.9) !important; }
body.dark-theme>div>main>article.x2dc1395b8aa096fc:hover { background-color: rgba(60,60,60,0.92) !important;}

        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .sort-container {
                margin-top: 0px;
                text-align: left;
                width: 100%;
            .sort-dropdown {
                float: right;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiffRu(dateString) {
        const timeUnits = {
            minute: ["минуту", "минуты", "минут"],
            hour: ["час", "часа", "часов"],
            day: ["день", "дня", "дней"]
        };

        function getRussianPlural(number, words) {
            if (number % 10 === 1 && number % 100 !== 11) {
                return words[0];
            } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                return words[1];
            } else {
                return words[2];
            }
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);

        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes == 0) {
            return 'только что';
        }
        else if (minutes < 60) {
            return `${minutes} ${getRussianPlural(minutes, timeUnits.minute)} назад`;
        } else if (hours < 24) {
            return `${hours} ${getRussianPlural(hours, timeUnits.hour)} назад`;
        } else {
            return `${days} ${getRussianPlural(days, timeUnits.day)} назад`;
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function formatArticlesTitle(number) {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;

        let word;

        if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
            word = "статей";
        } else if (lastDigit === 1) {
            word = "статья";
        } else if (lastDigit >= 2 && lastDigit <= 4) {
            word = "статьи";
        } else {
            word = "статей";
        }

        return `${number} ${word}`;
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p>24 октября | 11 статей</p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item" id="nav-prev"><a href="/d/2024-10-23.html">⬅️ 23.10</a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2024-10-25.html">➡️ 25.10</a></span>
            <!--<span class="nav-item" id="nav-weekly">Топ за неделю</span>
            <span class="nav-item" id="nav-weekly">Топ за месяц</span>-->
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 Сортировка по</label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="category-toggle">
            <div class="svg-container">
                <span id="category-toggle">🏷️ Фильтр</span>
                <svg height="3" width="200">
                    <line x1="0" y1="0" x2="200" y2="0" 
                        stroke="black" 
                        stroke-width="2" 
                        stroke-dasharray="3, 3" />
                </svg>
            </div>
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">градиент обреченный</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>    
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2410.17637', 'title': 'MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models', 'url': 'https://huggingface.co/papers/2410.17637', 'abstract': "Visual preference alignment involves training Large Vision-Language Models (LVLMs) to predict human preferences between visual inputs. This is typically achieved by using labeled datasets of chosen/rejected pairs and employing optimization algorithms like direct preference optimization (DPO). Existing visual alignment methods, primarily designed for single-image scenarios, struggle to effectively handle the complexity of multi-image tasks due to the scarcity of diverse training data and the high cost of annotating chosen/rejected pairs. We present Multi-Image Augmented Direct Preference Optimization (MIA-DPO), a visual preference alignment approach that effectively handles multi-image inputs. MIA-DPO mitigates the scarcity of diverse multi-image training data by extending single-image data with unrelated images arranged in grid collages or pic-in-pic formats, significantly reducing the costs associated with multi-image data annotations. Our observation reveals that attention values of LVLMs vary considerably across different images. We use attention values to identify and filter out rejected responses the model may have mistakenly focused on. Our attention-aware selection for constructing the chosen/rejected pairs without relying on (i) human annotation, (ii) extra data, and (iii) external models or APIs. MIA-DPO is compatible with various architectures and outperforms existing methods on five multi-image benchmarks, achieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the recent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's ability to understand single images.", 'score': 26, 'issue_id': 243, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': '2dc1395b8aa096fc', 'data': {'desc': 'Статья представляет новый метод обучения больших визуально-языковых моделей (LVLM) под названием MIA-DPO. Этот подход эффективно работает с многоизображительными входными данными, решая проблему нехватки разнообразных обучающих данных. MIA-DPO расширяет однозображительные данные, добавляя несвязанные изображения в виде сеток или картинок-в-картинке. Метод использует значения внимания LVLM для идентификации и фильтрации ошибочно отвергнутых ответов, не требуя дополнительной аннотации или внешних моделей.', 'emoji': '🖼️', 'title': 'MIA-DPO: эффективное обучение LVLM на многоизображительных данных', 'categories': ['#rlhf', '#optimization', '#cv', '#benchmark', '#architecture'], 'embedding': [0.019406927128253464, -0.00032496327835267045, 0.05562897572685504, 0.015816329456466206, -0.02450203390461819, -0.03451525086763078, 0.08920864375292675, -0.025601970127620298, -0.03974943293500763, 0.027258198147789552, -0.03218894842041746, -0.04536290292448261, -0.017346125810203006, -0.043188312731967694, -0.021126365985968905, -0.037296700486585205, 0.08217916774124985, -0.004766391687361908, 0.021796443535306742, 0.04918107272506999, -0.04442732216445273, 0.026196190508844343, 0.03800470349768615, 0.06281017023781788, 0.05588183572927325, -0.09441753940375594, 0.001143396679022866, 0.018800065620284773, 0.08450546394387562, -0.06933392624465834, 0.016182975002902188, -0.027005338145371337, -0.11702313369788345, -0.028421349371396207, -0.019748285425530112, 0.10296417334841293, -0.001698896246181948, 0.10508818654477416, -0.07257052927994144, 0.019242567502222873, -0.02428710560855065, -0.029559215219219802, 0.034818681621615125, 0.018167917695768424, 0.02184701636840206, 0.06119187288323471, 0.15019823362989693, 0.026423764094714898, -0.07560483265672652, 0.06210216514518774, -0.08005515038183025, 0.06382160816596155, -0.05679213007275547, 0.010360896864426148, 0.01452674864795628, -0.032517665590949464, 0.03264409351062939, 0.0007593671375162076, 0.048624784050196615, 0.09062466018277458, 0.001004324302151604, -0.04311245764538309, 0.1229906072744381, 0.024249175983729162, -0.040103434440558104, -0.02826963503516863, -0.12309174877757036, -0.013780813930504652, 0.06463075268019478, -0.08298831433701226, 0.07337967379417466, 0.008698348280884569, 0.06741220438067838, 0.013287739215471238, 0.040558581612299215, -0.014375032646505352, 0.028219062202073313, 0.06948564890700266, 0.0151462533641988, -0.026550194095924008, 0.042227449718448516, 0.07004193758187605, 0.0021145332879908833, -0.034919825206276574, -0.017358769018476838, 0.02953392880267214, -0.04829606271660625, -0.031860231249885455, -0.09370953431112579, -0.01125222431396844, -0.08303888925163677, 0.02826963503516863, -0.04460432291722797, -0.023351526930049958, -0.0186862788273495, 0.06710877154516484, -0.005531290384612605, -0.08794435206695242, -0.0186862788273495, 0.09846328279021388, -0.12521577030004832, -0.0007443535878821835, 0.04614676518522654, -0.003988850406296138, 0.14180331193993834, -0.09290038979689258, 0.12541805538784204, 0.03350381502101629, 0.11075223144887365, 0.03969885802038313, -0.03823227708355671, -0.012984308461486894, -0.044174462162034515, 0.061040158547007124, 0.08238145491057275, -0.1486810819415044, -0.06154587438878518, -0.019988502219674496, 0.004504050319502915, -0.09891842996195499, -0.06989022324564846, -0.009279924204917278, 0.07363253379659288, -0.027586914277556964, 0.06286074098938402, -0.07671741208800245, 0.024729607490488748, -0.10281246317524373, 0.045868618766260666, -0.060079293451958775, -0.06119187288323471, 0.056943840245924686, 0.10994308277158206, -0.06377103325133705, -0.1463547732497035, 0.007086372530438308, -0.014994536946442035, 0.09492326149012155, -0.10822363558774989, 0.019444856753074953, 0.030267220311849943, -0.08582034095212036, 0.019748285425530112, 0.04121601387183404, -0.05059708291033027, -0.022618235420872157, -0.020810294105239914, 0.035349683879940835, 0.0014009967397027139, 0.05042007799449666, -0.0578541345894069, -0.0749474003971917, -0.022871093341761187, -0.01462789181631189, -0.13199238839083619, -0.06422618042307815, -0.04801792046069874, -0.038105849163876784, 0.0060117220995251075, -0.09335553488710452, 0.05714612741524758, -0.03304866784927518, 0.05871385401826462, 0.005161483827955249, 0.031278656158464424, 0.10215503091570889, -0.07272223945311064, 0.09143380261547861, -0.0896132243361601, -0.04098844236749267, -0.06427675325617348, -0.00020762092133887089, -0.05087522516623777, -0.09553011675350269, 0.05921957402310105, -0.030191361062206965, -0.011372332711040633, -0.026676622015603925, 0.0058094351383551285, -0.07287395378933822, -0.01678983713532963, 0.0748968254825672, -0.027662773527199938, 0.06281017023781788, -0.04141830104115694, -0.0674627772137737, -0.05805641967720061, -0.042227449718448516, -0.06114130213166857, 0.04983850498460481, -0.019735642217256284, 0.04273316764175576, 0.09446811431838044, 0.022555021461032197, -0.043061884812287766, -0.05062236932687793, 0.0500407942354569, 0.09487268657549705, -0.0272329106904773, -0.012105623387606757, 0.07631283566782747, 0.042682596890189634, 0.060888442129250354, -0.17164068190424073, 0.025601970127620298, -0.04399746349078846, -0.05729784383300434, -0.01909085316599529, 0.019432213544801125, -0.030115503894093173, 0.0532521004465464, 0.0018853798214683957, 0.12663177424072106, 0.05034422290791205, 0.008281131566576621, -0.13543126194320873, -0.06149530363721905, -0.06549047210905248, 0.0453881851779719, 0.07297510361858722, -0.008856385262013657, -0.05320152969498027, 0.06958679041013492, 0.043567602735595005, -0.12835122142455324, -0.01462789181631189, 0.01909085316599529, -0.12986837519447497, 0.029559215219219802, -0.15909887324316277, 0.0297615023885427, -0.0374989876559081, -0.030064933142527044, 0.035804831051681946, 0.03105108257259387, -0.08713520547119001, 0.05765184742008401, -0.10620077430216684, 0.02304809617606561, -0.03656340689587822, 0.017042695056218662, 0.040052861607462784, 0.06124244571633002, -0.08779263564919565, -0.10326761034698483, 0.09330496205400919, -0.0748968254825672, 0.05254409327238708, -0.01855984882614039, 0.002131917178985102, 0.0030959420353373203, -0.03335209860325953, -0.15292910417116848, -0.12895808085099275, -0.014589963440407914, 0.03322566860205042]}}, {'id': 'https://huggingface.co/papers/2410.18072', 'title': 'WorldSimBench: Towards Video Generation Models as World Simulators', 'url': 'https://huggingface.co/papers/2410.18072', 'abstract': 'Recent advancements in predictive models have demonstrated exceptional capabilities in predicting the future state of objects and scenes. However, the lack of categorization based on inherent characteristics continues to hinder the progress of predictive model development. Additionally, existing benchmarks are unable to effectively evaluate higher-capability, highly embodied predictive models from an embodied perspective. In this work, we classify the functionalities of predictive models into a hierarchy and take the first step in evaluating World Simulators by proposing a dual evaluation framework called WorldSimBench. WorldSimBench includes Explicit Perceptual Evaluation and Implicit Manipulative Evaluation, encompassing human preference assessments from the visual perspective and action-level evaluations in embodied tasks, covering three representative embodied scenarios: Open-Ended Embodied Environment, Autonomous, Driving, and Robot Manipulation. In the Explicit Perceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessment dataset based on fine-grained human feedback, which we use to train a Human Preference Evaluator that aligns with human perception and explicitly assesses the visual fidelity of World Simulators. In the Implicit Manipulative Evaluation, we assess the video-action consistency of World Simulators by evaluating whether the generated situation-aware video can be accurately translated into the correct control signals in dynamic environments. Our comprehensive evaluation offers key insights that can drive further innovation in video generation models, positioning World Simulators as a pivotal advancement toward embodied artificial intelligence.', 'score': 12, 'issue_id': 243, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': 'e4c42676df8ded0d', 'data': {'desc': 'Статья представляет новый подход к оценке предиктивных моделей, называемый WorldSimBench. Эта система включает в себя явную перцептивную оценку и неявную манипулятивную оценку, охватывающие три сценария: открытую среду, автономное вождение и робототехнику. Авторы вводят датасет HF-Embodied для оценки визуальной точности симуляторов мира на основе человеческих предпочтений. Также предлагается оценка соответствия видео и действий, проверяя, могут ли сгенерированные видео точно преобразовываться в сигналы управления в динамических средах.', 'emoji': '🌐', 'title': 'WorldSimBench: Комплексная оценка симуляторов мира для воплощенного ИИ', 'categories': ['#benchmark', '#video', '#rlhf', '#agents'], 'embedding': [0.06881044100443194, 0.051858759640815356, 0.06641266637746733, 0.010866640183924619, -0.0031435888596035243, -0.015683091311885364, 0.03200744695325655, 0.01055994835123045, 0.10845729470250465, -0.012316455199092607, 0.02880112746183785, -0.1116357283554009, -0.019237925572553823, -0.17754654234791142, -0.007486062661077917, 0.038810427307116986, 0.034572506427210235, 0.016756511971711314, 0.012867105861054324, -0.007395448993553813, 0.09289966379184549, -0.0394516916366028, 0.006830857568341274, -0.040371764763073865, 0.009967476046319387, -0.04118031609555916, -0.031338303253279486, 0.0794052378141728, -0.022026032946499866, 0.014526028659766963, 0.09462828825080184, -0.02498142301142457, -0.1186617566092537, -0.07979557271716463, -0.026222129380643742, 0.08464687208803476, -0.07711898713720437, 0.1141450290883721, -0.03518588707418401, 0.09066918479192193, 0.06875467579541825, -0.005983970861724546, -0.03936804274507707, 0.054340172379253704, -0.12011157011521441, 0.033624549618227126, 0.010016268070894145, -0.03317845166223202, -0.005882902052964405, 0.14230490084476574, -0.12356882550115832, 0.08152419502011057, 0.04670076347842714, -0.06312270230654368, 0.07661712828421637, -0.030390346444296376, -0.008664037104875672, -0.033429381088726014, -0.04675652437542003, 0.06312270230654368, -0.01812268391658165, -0.0032446574527626253, -0.05052046577283002, 0.02376859816870704, -0.09959112235172014, -0.07014872624837568, -0.09758368262774735, 0.08475840035005172, -0.006081554264070942, 0.0055378741993356755, 0.046561355845918924, 0.04873608041688078, 0.07087363300135603, 0.05408924079674931, -0.06579928357448314, -0.015362459578344536, 0.09317847905686194, 0.10639409623754938, -0.043856895207488214, -0.01569703272193931, -0.0386989012011104, 0.010441453588406781, -0.07589222368724642, 0.05882902052964405, -0.0829182519410992, 0.01983736761228718, -0.03722120616864805, -0.10109669675467374, -0.12011157011521441, -0.048289980304875274, 0.016059486314030525, 0.022750939699480218, -0.05141265952880984, 0.12334577760116595, 0.055176600926219836, -0.03563198503017912, -0.12769521811904808, -0.14219337042673835, 0.10511156542256733, 0.07338293157831681, -0.07533460393726553, 0.03638477330966112, 0.02180298289049711, 0.07031601109536473, 0.040539051766073336, 0.011040896274943255, 0.000842094887260792, 0.031840162106267486, -0.13784392128481462, 0.010845729470250465, -0.13483277247890746, -0.039786261330580934, -0.16483277324016, 0.019879189902039643, 0.038559493568602186, -0.07070634599835655, -0.08085505132013351, -0.0769517022902153, 0.039144999157105516, 0.011215153443967093, 0.04731414412540092, 0.052583666393795706, 0.10171007093361631, -0.09144984812987439, 0.051189611628817494, -0.07622679553723494, 0.008552513154879496, -0.06278813261256555, 0.01437268220441728, -0.07650561080225139, -0.07973980750815093, 0.006545076880523339, 0.01622677245462583, -0.07215616166032766, -0.09250933535688487, -0.024200753205440923, -0.11587364923530766, -0.005109202844207213, -0.031198897776781667, -0.010037179215770377, -0.08631973564999822, 0.014609671514463577, -0.04421935073998879, 0.08118962317012206, -0.07265802482533647, 0.02296004683622175, 0.08726769030297092, 0.06234203250056004, -0.06446099186250821, 0.11899632845924224, -0.04628254489292328, -0.007200281757658942, -0.05414500384975259, -0.04357808641050297, -0.041263958519053685, -0.0754461235752409, -0.016198891574927307, 0.06975838918937344, -0.007430300470478788, -0.04304834387500293, 0.007409389756804634, -0.015975842381328712, -0.015404281005692843, 0.07059482636038118, 0.07371750342830535, 0.03883830452159783, -0.11442383572934696, 0.08197029513211608, -0.0744424101812857, -0.053949837476261885, 0.0354925817096917, 0.020952611424269754, -0.03256506885924784, -0.009179836074311373, 0.018429376396078938, -0.024828078927686324, 0.022946104994965726, -0.056682179641194236, -0.0352416501271873, -0.10098516849265676, -0.008127326559361658, 0.06964686955139808, -0.08247215182909368, 0.01201673374802385, 0.028661721985340026, -0.02206785308024193, -0.027978635366101737, 0.08604092900902337, -0.026250010907145387, -0.04368960604847835, -0.06200746065057151, 0.09741639778075827, 0.08174724723212373, 0.11721194310329298, 0.039842022227573826, -0.006632204926032658, -0.013278351262119258, 0.10282531690160929, 0.05804835072366041, -0.06791824078042093, 0.07171007017236375, -0.05486991060273295, 0.05093868435833389, -0.11921937635923457, 0.05099444525532677, 0.0794052378141728, 0.0070852724012490185, 0.05450745722624277, -0.0998141680957021, 0.032397784012258776, 0.08230486482609423, 0.0016894175607406424, 0.10288108211062298, -0.005485596768347173, -0.08425653718504292, -0.003816218828398495, -0.039144999157105516, -0.0012738155741393578, -0.051161730102315846, 0.044024182210487685, -0.018610602006318824, 0.026375475620392386, 0.1082900098555156, -0.03789035202463552, -0.01926580709905547, -0.07076211120737025, 0.022276960216983464, -0.07215616166032766, 0.006189593670057533, -0.05983273823562005, -0.020827146711022756, 0.032397784012258776, -0.08174724723212373, 0.032258378535760954, -0.04770448118440314, -0.026807630657126272, 0.01862454276956965, 0.0009514409217906146, 0.03250930580624455, -0.03752789864814534, 0.02238848632299004, 0.015752794265735316, 0.04148700426303564, -0.04681228527241292, 0.010002327954446442, 0.08553906584401456, -0.023754657405456216, -0.07750932419620658, 0.027002799186627385, -0.021398707224254465, 0.11046473011445665, -0.07488850382526002, -0.026473058807137743, 0.019251866335804647, -0.0034276268442145863, -0.029860606064806734]}}, {'id': 'https://huggingface.co/papers/2410.17891', 'title': 'Scaling Diffusion Language Models via Adaptation from Autoregressive Models', 'url': 'https://huggingface.co/papers/2410.17891', 'abstract': 'Diffusion Language Models (DLMs) have emerged as a promising new paradigm for text generative modeling, potentially addressing limitations of autoregressive (AR) models. However, current DLMs have been studied at a smaller scale compared to their AR counterparts and lack fair comparison on language modeling benchmarks. Additionally, training diffusion models from scratch at scale remains challenging. Given the prevalence of open-source AR language models, we propose adapting these models to build text diffusion models. We demonstrate connections between AR and diffusion modeling objectives and introduce a simple continual pre-training approach for training diffusion models. Through systematic evaluation on language modeling, reasoning, and commonsense benchmarks, we show that we can convert AR models ranging from 127M to 7B parameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA, using less than 200B tokens for training. Our experimental results reveal that these models outperform earlier DLMs and are competitive with their AR counterparts. We release a suite of DLMs (with 127M, 355M, and 7B parameters) capable of generating fluent text, performing in-context learning, filling in the middle without prompt re-ordering, and following instructions https://github.com/HKUNLP/DiffuLLaMA.', 'score': 9, 'issue_id': 243, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': 'a6f6dc7932b17a7f', 'data': {'desc': 'Исследователи предлагают новый подход к созданию диффузионных языковых моделей (DLM), адаптируя существующие авторегрессионные модели. Они демонстрируют связь между целевыми функциями авторегрессионных и диффузионных моделей и вводят метод дообучения для создания DLM. Эксперименты показывают, что полученные модели DiffuGPT и DiffuLLaMA превосходят предыдущие DLM и конкурентоспособны с авторегрессионными аналогами. Авторы представляют набор DLM различных размеров, способных генерировать связный текст и выполнять различные языковые задачи.', 'emoji': '🔄', 'title': 'Преобразование авторегрессионных моделей в диффузионные: новый шаг в языковом моделировании', 'categories': ['#diffusion', '#benchmark', '#multimodal'], 'embedding': [0.004957958828755283, 0.041299545636998586, 0.10368928361453277, -0.02056168683894174, -0.055569405845362206, -0.029647082866578724, -0.07031744293530909, -0.03410169593841481, -0.09105529965821564, 0.09045128151267814, -0.07036777985592084, -0.04442028945440663, -0.05959617273077591, 0.01965566377093609, 0.03155979869351295, -0.02614882770820975, 0.08768288161350031, -0.009242692419704037, 0.04890006994897344, 0.08722987630494837, 0.058388140590001504, 0.025016297835627536, -0.05129096265749093, -0.027885371576028873, 0.016987929412380583, -0.04152605036642486, -0.030100093363006404, 0.08758221607287797, -0.09170964849891401, -0.09488073338723438, 0.03140879415712857, -0.027457527464756777, -0.058237142279068, -0.013653261256671172, 0.024714290838009082, 0.09306868517607278, 0.048749065412589075, 0.10610534997123185, -0.02434936528356381, 0.0335731821362198, 0.022436651531779872, -0.11486356950336937, 0.007235599795104725, 0.03161013146382411, -0.049655088480594724, 0.07389120451217084, 0.07056911716261638, 0.08712920038857458, -0.013942685788014436, 0.025708399885572285, -0.065082643909121, 0.06256591616210015, -0.03140879415712857, -0.0765086019501146, -0.0009484927203367068, -0.02660183924221258, -0.01613224077480633, -0.05204598118911221, -0.015175883276369274, -0.08214606936424289, 0.04952925136694108, -0.028262880841839515, 0.002156523159487868, -0.02592232090363319, -0.03508321712431207, -0.05330434610019778, -0.14103756048400928, 0.05954583996046474, -0.008972143662923848, 0.08410912626208945, -0.020461017148018828, -0.13469541145887143, 0.02632499966732485, -0.08592117239810075, -0.09236400564021355, -0.05063661174164227, -0.03249098710909904, 0.0426837455865875, -0.03646742122420157, 0.08481381202339956, 0.058136470512994795, 0.028514555069146803, -0.08496480825918278, -0.09090430342243243, -0.05456271101128334, -0.05994851457385582, 0.03513355612007411, 0.013967852588200077, -0.041349878407309755, -0.17395640415528216, 0.05516672915682083, -0.05446204547066102, -0.04857289345347397, 0.025330890619761647, 0.12331979033848958, -0.053757359709350895, 0.02728135550564167, -0.004372818947961217, 0.08169306405569093, 0.028866896912226714, -0.025695816174206923, 0.031131954582240853, 0.07278384206231936, -0.0578847983608378, 0.04728936319480797, 0.00032914112328609127, -0.019403990581203946, -0.033900358631719266, -0.07892466830681369, 0.0694617547127649, -0.110434123854264, 0.018611219877911426, 0.033673853902293, -0.025846818635441006, 0.030477603666392194, -0.09629010698500491, -0.11204483060842949, -0.019554994080013172, 0.04698735412203922, 0.018988729143722065, -0.036215751147194865, 0.03790195809440224, 0.07333751913694452, -0.04728936319480797, 0.022008807420507776, -0.055770743152057746, 0.03347251037014659, -0.11305152336735806, -0.0166607549920314, 0.02136704021602448, -0.0022729218670724015, 0.01203626285433804, 0.0006299690205091301, 0.025418976599319198, -0.0808877106786082, -0.07011610355346326, -0.09120630834490061, 0.032415485878481996, -0.029571581635961686, -0.018422466282581252, 0.026425669358247767, -0.033673853902293, -0.10771605049994647, 0.08702853277280195, -0.03598924226746801, -0.020712689300175825, -0.03832980013052405, 0.030049759555120095, -0.03256648937729123, 0.10912542409771697, -0.0578847983608378, -0.05909282635131162, 0.037096602642169206, -0.014748039787642263, -0.0008084996369481269, -0.07384086136610821, -0.04947891652147962, 0.15241318990499225, 0.1028839343877506, -0.09749813082517815, 0.0034982551583689738, 0.12019903822048038, -0.038380139126286086, -0.05707944290860477, -0.007015385883785993, 0.013414171985819423, -0.015050046577745689, 0.0023122459650891654, -0.13399073192301217, -0.061156546714630215, -0.03075444531643021, -0.01718926671907612, -0.052297657491569796, -0.10600468235545922, -0.05209631810972396, -0.00654349878273512, -0.08118971975137694, -0.105098655137153, -0.0008973716419329489, -0.1334873834683976, -0.07268316822109586, 0.11204483060842949, -0.057985465976610424, -0.07731395325204704, -0.056727098990374564, -0.027583364578410416, -0.03541039361981154, 0.027784701885105956, 0.028816562066765253, 0.014194357940171433, -0.01081564866231851, 0.09276667817845433, 0.1530172039002292, 0.03790195809440224, 0.06729736465852339, -0.00015562438122298917, 0.1576479847808798, 0.07374019582548588, 0.005983526117156753, -0.015289136678657554, 0.10263225808529304, 0.04094720171876839, -0.1290579253683905, -0.15946002676659052, -0.03883314858513862, -0.010482181763741556, 0.026878679854675448, -0.022902246777148062, -0.07162614061670583, -0.06322026292764822, 0.06125721225525255, 0.03800262571017486, 0.08692786515702933, 0.023732767576961532, -0.09452838739385389, 0.04109820625515275, -0.037398611714937954, -0.0222856469953955, 0.049655088480594724, 0.026274664821863393, -0.058388140590001504, 0.004224960961963273, 0.028011206614532224, 0.03619057957416356, -0.07967968268813438, -0.04932791198509525, 0.09035061182175523, -0.033271175138601346, 0.07082079138992366, 0.010991819998888524, 0.07535090672995194, -0.06664302204327589, -0.06966309409461073, -0.13378938009026461, 0.08778355130442322, -0.12029970583625299, 0.04872389798985834, -0.005118400318603562, -0.004136875189920751, -0.02798604126695179, -0.03913515558275708, 0.007059428458534711, 0.08043470121975566, -0.03966367146010238, 0.015414973792311198, 0.05828747297422888, -0.04937824683055671, -0.06120687948494138, 0.06639134574081831, 0.010004002807008, 0.0016390205197676065, -0.00039933430622196797, -0.038984153121522994, -0.025091800103819725, -0.005193901964250661, 0.004077103183480358]}}, {'id': 'https://huggingface.co/papers/2410.18084', 'title': 'DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes', 'url': 'https://huggingface.co/papers/2410.18084', 'abstract': 'LiDAR scene generation has been developing rapidly recently. However, existing methods primarily focus on generating static and single-frame scenes, overlooking the inherently dynamic nature of real-world driving environments. In this work, we introduce DynamicCity, a novel 4D LiDAR generation framework capable of generating large-scale, high-quality LiDAR scenes that capture the temporal evolution of dynamic environments. DynamicCity mainly consists of two key models. 1) A VAE model for learning HexPlane as the compact 4D representation. Instead of using naive averaging operations, DynamicCity employs a novel Projection Module to effectively compress 4D LiDAR features into six 2D feature maps for HexPlane construction, which significantly enhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, we utilize an Expansion & Squeeze Strategy to reconstruct 3D feature volumes in parallel, which improves both network training efficiency and reconstruction accuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06x training speedup, and 70.84% memory reduction). 2) A DiT-based diffusion model for HexPlane generation. To make HexPlane feasible for DiT generation, a Padded Rollout Operation is proposed to reorganize all six feature planes of the HexPlane as a squared 2D feature map. In particular, various conditions could be introduced in the diffusion or sampling process, supporting versatile 4D generation applications, such as trajectory- and command-driven generation, inpainting, and layout-conditioned generation. Extensive experiments on the CarlaSC and Waymo datasets demonstrate that DynamicCity significantly outperforms existing state-of-the-art 4D LiDAR generation methods across multiple metrics. The code will be released to facilitate future research.', 'score': 8, 'issue_id': 250, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': 'c726f29cc044d5f6', 'data': {'desc': 'Статья представляет DynamicCity - новую систему для генерации динамических 4D LiDAR сцен. Основу системы составляют VAE модель для создания компактного 4D представления HexPlane и DiT-based диффузионная модель для генерации HexPlane. Авторы предлагают ряд инновационных методов, включая Projection Module и Expansion & Squeeze Strategy, для повышения качества и эффективности генерации. Эксперименты показывают, что DynamicCity значительно превосходит существующие методы генерации 4D LiDAR сцен по нескольким метрикам.', 'emoji': '🚗', 'title': 'DynamicCity: революция в генерации динамических 4D LiDAR сцен', 'categories': ['#3d', '#dataset', '#diffusion'], 'embedding': [0.012189797802003306, -0.04918367435415624, 0.10538550299104071, 0.03959031134043916, -0.054560486205170615, -0.07816186059681479, -0.0010656345047710834, -0.03172318865432467, -0.08953806253539363, 0.056711211790016466, 0.0008113856259240426, -0.06503111903200379, -0.00429437433948907, -0.10351777250359093, 0.05931472193073514, -0.04072227061902101, -0.0028652745363968485, -0.08885888992378485, -0.02882253904464574, 0.011347902639949255, -0.029742258861256313, -0.015069221987714945, 0.036420823671529795, -0.010513080719227425, 0.0071773358847519, -0.023615522985408855, 0.022582608085380186, 0.09078322111959404, -0.03172318865432467, -0.05122120274448377, -0.013611823308213191, -0.07419999678847762, -0.05495667427488452, -0.06938916246565394, -0.015026773461990621, 0.06950236388237273, -0.03840175557569838, 0.06808741583969553, -0.05014584206316108, 0.007881273390979401, 0.1383255572642369, -0.039703508534957486, 0.03709999839423881, 0.05521136374035029, -0.010937565976470677, 0.02647372048049306, -0.00046737580513446026, 0.06384255904506254, 0.10425354793465934, 0.0972919880269898, -0.024025857537787198, -0.008284534490915502, 0.03435499387147246, -0.10425354793465934, -0.05908832754169849, -0.03245896197429285, 0.03127040409845184, -0.06774782425614057, 0.019328222520582073, 0.0342418008991546, 0.07403020521890061, -0.09672601049879911, -0.02709629871704315, 0.070860715438891, -0.003958323704355682, -0.03732639278327546, -0.08155774265476082, 0.04210892358526909, 0.02903478272881748, 0.0581261619437939, 0.002661875306653202, 0.10063127148767666, 0.015493707244958198, -0.12440243744889787, 0.022794849658451695, -0.05402280375340904, -0.026006787330855555, 0.04587269019209897, -0.04499542037898288, 0.00566333903021103, 0.06565369726855388, 0.014743782586795042, -0.04791021858242649, -0.036081236310175284, -0.11319602919099628, -0.22888237132819292, 0.02130915231365043, -0.031496796376388254, 0.034807778427345296, -0.017389738508807737, 0.05688100547069372, 0.040043095896312, -0.030195041306028916, -0.03667551313699556, 0.04926857225004499, 0.08868909413200736, -0.021408199858853963, -0.05954111209757132, 0.14477773401877445, 0.04590099160182878, -0.0028935734128063832, 0.02214397423437226, 0.018465101301230663, 0.008411879434758407, 0.0973485887353492, -0.008525075995946662, -0.053824714996302675, 0.0864251713526432, 0.01641342431713847, 0.07516216660858269, -0.12417604305986121, -0.038062163992143405, 0.023275935624054344, 0.06978535264646807, -0.009430643629922167, -0.06389916186452217, -0.07301144102373684, -0.00030487760131100294, -0.04717444737355854, 0.0218326840605471, -0.07244545927334568, 0.04963646102112931, 0.030251639903288077, -0.04049588045218483, 0.118855829806106, -0.13753317690260863, 0.04007139519494158, -0.2248073272141393, 0.02524271471225779, 0.07414340241341892, -0.026402973289469223, 0.06321998080851246, 0.03967520712522767, -0.07935041636155557, -0.05733379002656656, -0.026190731716397714, -0.11155468464818219, -0.009225476987063065, -0.041797633411443935, 0.01151769632062651, 0.04660846562316739, 0.057956368263116634, 0.03305324302331359, 0.06571029586581303, -0.026374676101939876, 0.06565369726855388, -0.018493402710960474, 0.0765771167623601, 0.0104140350740141, 0.139457518653919, -0.06706865164453177, 0.01485697872576325, -0.025171967521233955, -0.04573119792115153, 0.015040922689085363, -0.08421784717053818, -0.0006637001891097092, 0.058182758429952824, -0.019781004965354673, -0.047598932630801796, -0.07137009225872229, 0.06457833447613096, -0.03387391212807028, 0.008581674593205826, -0.073577422774128, 0.01788497306817506, -0.0759545364147098, 0.03619443350469361, -0.14726803007617292, -0.12055377505727947, -0.043042789884544116, -0.03390220931559963, -0.045052023198442516, -0.04918367435415624, 0.040410982556296084, 0.017389738508807737, 0.03316644021783191, -0.03455308896187953, -0.036420823671529795, -0.09876353888912663, -0.03458138826050911, 0.07765247955478304, -0.047853622096267555, -0.0171209004495773, -0.07069092175821375, 0.02081391986538334, -0.028935736239164067, 0.12259129922540653, 0.02810091537399235, 0.13425048992808072, -0.07850144795816931, 0.15462578438685706, 0.04983455400043615, 0.023106139832276856, 0.031779787251583834, -0.06033348401479866, 0.13685400429099984, 0.07159648664775894, 0.07765247955478304, -0.01914427813503991, 0.08110495387668751, 0.013123665156828439, -0.04227871726594635, -0.14783401604876456, -0.012883122807357183, -0.045533102830744465, 0.046580166324537806, 0.004595051379110538, -0.07567154342841398, 0.00534143783328241, 0.02055922934436746, 0.006961555685469059, 0.07199267682857309, 0.05903173105553956, -0.13504285973420782, 0.043099390592903505, 0.06848360602050967, -0.0026813309952947806, 0.06016369033412141, 0.04191083060596226, -0.016710563786098722, -0.008150114194640143, 0.023940961752998684, 0.04567460143499261, -0.04162783973076668, 0.030959113924626677, -0.012734553495097105, -0.07572814835897385, 0.11313943481593758, -0.0030863605638964545, 0.14149503648874534, -0.011354976936831592, -0.042505109543882764, -0.013958485810890129, -0.03724149699848695, -0.06644606918578122, 0.01040695993269167, -0.0631067878361946, 0.0036647213838365976, -0.0005695175477281779, -0.025398359799170375, 0.034072002996276884, 0.05589054057415954, -0.02851124887082058, 0.0003736353336968279, 0.054900073566525126, -0.07284164734305959, -0.02263920668263935, 0.001516649874204265, -0.013710869164536538, 0.02817166150946607, -0.031355299883240345, -0.07997299459810567, -0.03506247000391129, -0.003047449397723321, 0.10193302866913624]}}, {'id': 'https://huggingface.co/papers/2410.18013', 'title': 'Scalable Ranked Preference Optimization for Text-to-Image Generation', 'url': 'https://huggingface.co/papers/2410.18013', 'abstract': "Direct Preference Optimization (DPO) has emerged as a powerful approach to align text-to-image (T2I) models with human feedback. Unfortunately, successful application of DPO to T2I models requires a huge amount of resources to collect and label large-scale datasets, e.g., millions of generated paired images annotated with human preferences. In addition, these human preference datasets can get outdated quickly as the rapid improvements of T2I models lead to higher quality images. In this work, we investigate a scalable approach for collecting large-scale and fully synthetic datasets for DPO training. Specifically, the preferences for paired images are generated using a pre-trained reward function, eliminating the need for involving humans in the annotation process, greatly improving the dataset collection efficiency. Moreover, we demonstrate that such datasets allow averaging predictions across multiple models and collecting ranked preferences as opposed to pairwise preferences. Furthermore, we introduce RankDPO to enhance DPO-based methods using the ranking feedback. Applying RankDPO on SDXL and SD3-Medium models with our synthetically generated preference dataset ``Syn-Pic'' improves both prompt-following (on benchmarks like T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user studies). This pipeline presents a practical and scalable solution to develop better preference datasets to enhance the performance of text-to-image models.", 'score': 8, 'issue_id': 246, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': '05611e12662f347d', 'data': {'desc': 'Статья представляет новый подход к улучшению моделей генерации изображений по текстовому описанию (text-to-image). Авторы предлагают использовать синтетические наборы данных для обучения методом Direct Preference Optimization (DPO), что позволяет избежать трудоемкого процесса сбора предпочтений от людей. Они вводят метод RankDPO, который использует ранжированные предпочтения вместо попарных. Эксперименты показывают, что предложенный подход улучшает как следование промпту, так и визуальное качество генерируемых изображений.', 'emoji': '🖼️', 'title': 'Синтетические данные для улучшения генерации изображений по тексту', 'categories': ['#dataset', '#rlhf', '#rag'], 'embedding': [0.11313629875154683, 0.01483814839591593, 0.04772632237617878, -0.009208200592789354, -0.022385452729000548, -0.0005678797120236724, 0.08265398270529555, 0.08157928527904237, -0.05197626055524052, -0.03453685816169468, -0.016792142767122344, -0.025157682448973456, -0.08162813278891914, -0.1385382328061637, 0.06770591978161597, -0.0512435137704585, 0.10483182046507877, -0.08372868013154872, 0.005932205977351472, 0.0825074321435169, -0.035831381430615816, -0.03666182725122555, 0.006594732508849463, -0.02579273220596483, 0.10180312826601176, -0.0196620725269415, 0.04831252261525629, 0.02255642905375466, 0.08895561067692469, -0.12202697928512947, -0.0603295903676595, -0.03973937097624348, -0.11948678025716397, -0.03348658649841697, 0.10199852432963014, -0.0023066299787552385, 0.016535681292046786, 0.1390267279853023, -0.07591270104029338, 0.016792142767122344, 0.06355368465445609, -0.0525136092683671, 0.032289762265323554, 0.03971494320523094, -0.03324233489277354, 0.08802746582048723, 0.15524488038277923, -0.10004453357289043, 0.02889469767788408, 0.07698739846654655, -0.10004453357289043, 0.15475638520364068, -0.072981705869017, -0.08690392088435728, -0.004054539103387775, -0.0013754290906939544, 0.02245872800988987, -0.02050473323707604, -0.008829614118106906, -0.007699960733196013, 0.006594732508849463, -0.09408485021862124, 0.04872774452154262, 0.03729687500017985, 0.0073274802976500165, -0.006576413789028987, -0.13179695114116155, 0.0456013532866479, -0.028259649928929778, -0.03417048577332221, 0.09379175311113809, 0.009220412269454843, 0.017036393368747245, -0.007211462140394409, -0.00795642240907528, -0.05393025532805435, -0.002143288010155056, 0.09799284378032305, -0.017805776789955385, -0.011705650318669929, -0.009690593347258214, 0.025695033170137112, -0.09227740399954897, -0.016816568530097813, -0.09374289756911301, -0.03710147692852442, -0.055444600423569315, -0.027013978185959568, -0.096087696517386, -0.011229363603337523, -0.07166276286123163, -0.011919368716575498, -0.00023757065344430514, 0.02816194888506499, 0.05226936368683489, -0.000631995211314972, -0.01632807033890362, -0.011968218234489356, 0.03566040711389878, 0.08939526035422354, -0.053637158220571204, -0.032314190036336086, -0.04933836650752145, 0.012676541264332979, 0.045625777041586296, -0.04130256358163523, 0.06697317299683395, 0.08519417370111274, 0.08573152040620224, 0.04821482357942858, -0.07659659429108738, -0.0008029697689964603, -0.07425180136692562, 0.0374434255619585, 0.04347638419711703, -0.17556643646183587, -0.0691225658413032, 0.03605120325720964, 0.006674113427267824, -0.012328486190155034, -0.03407278673749449, 0.00018347324308604966, 0.016047182096834058, 0.07434950441882748, 0.018917111856653217, -0.11938908925348456, 4.615454139621896e-05, -0.11255010252854346, 0.04521055513529997, -0.08402177322295772, -0.027966550813409555, 0.04247496405979027, 0.03443916113390404, -0.04977801618482033, -0.11137770405842551, 0.04056981679685321, -0.024595909980908475, 0.08153042973701728, -0.08094423552205099, -0.031190642088150526, -0.056470450339945695, -0.0945244998959201, -0.02847947577159775, 0.12163617510967031, -0.12261317350009576, -0.07146735675742791, -0.03121506785112599, 0.05930374045128312, -0.07483799558189191, 0.12251547245623098, -0.06785247034339462, 0.009220412269454843, 0.00685119418472873, 0.03732129875511824, -0.0666312223553628, -0.09848133695142455, -0.03319348738289675, 0.03165471652440632, 0.018428613665459028, -0.07806209388476264, 0.0218603168973617, 0.0666312223553628, -0.06145313530378945, 0.03187454035903722, 0.008744126959748386, 0.05334405910505098, -0.045039580818582926, 0.03043346853637451, -0.12808435163504103, -0.12134308001022424, 0.023802098788687796, 0.033437732964428965, -0.06306518345120629, -0.030726567651894725, 0.02454706046299462, -0.0055566727230409564, -0.07615694862986266, 0.03937299657983394, -0.036808377813004195, -0.019820835970207885, 0.0037034308088378957, 0.08822286389214265, -0.08099308303192777, 0.06799902291321033, 0.020016234041863316, -0.054809552674615014, -0.02413183454063414, -0.02490122197791643, -0.011717862196139127, 0.02513325869403506, -0.01090573368972392, 0.06506802573389689, 0.06526342380555233, -0.030360193255485186, -0.08431487434651501, -0.06433527894911488, 0.10971681040916897, 0.10766511258445326, -0.07522879975735107, 0.00333400379446754, 0.05231821119671167, 0.021493944508989227, -0.0655565269371467, -0.12222237735678491, -0.02225111705674671, -0.03463455719752239, -0.022666338963033036, -0.025353082528665957, -0.05378370677431278, -0.10004453357289043, 0.060964638116613803, 0.0014525203448379994, 0.08988376356551042, 0.010533253454981632, -0.009049438755952634, -0.11841208483894787, -0.15182540208058676, -0.00961121182642873, 0.03421933328319899, 0.061013489642564735, -0.0339995094485681, -0.022348816092574424, 0.04816597205347764, -0.028455050008622286, -0.041913187575651135, -0.01480151035386385, -0.07557074839078516, -0.07405640329527018, -0.017182941922488818, -0.13023374648754737, 0.01248724762538434, -0.00329431333525836, -0.03844484770732234, 0.009617317865565182, 0.00958068102833535, -0.02267855184452077, 0.060964638116613803, -0.08963950995182991, 0.05148776336806486, -0.060964638116613803, 0.03544058127123081, 0.025108832931059595, 0.05143891184211393, 0.0012731497222990705, -0.014557261358668609, 0.06951336399265115, -0.09344980246966693, -0.029725145506530885, -0.0009075389823889967, -0.03937299657983394, 0.0432809861254616, 0.013250527417100519, -0.07664544983311247, -0.1356072416509615, -0.012267423790753443, -0.019136936695302652]}}, {'id': 'https://huggingface.co/papers/2410.17883', 'title': 'Lightweight Neural App Control', 'url': 'https://huggingface.co/papers/2410.17883', 'abstract': 'This paper introduces a novel mobile phone control architecture, termed ``app agents", for efficient interactions and controls across various Android apps. The proposed Lightweight Multi-modal App Control (LiMAC) takes as input a textual goal and a sequence of past mobile observations, such as screenshots and corresponding UI trees, to generate precise actions. To address the computational constraints inherent to smartphones, within LiMAC, we introduce a small Action Transformer (AcT) integrated with a fine-tuned vision-language model (VLM) for real-time decision-making and task execution. We evaluate LiMAC on two open-source mobile control datasets, demonstrating the superior performance of our small-form-factor approach against fine-tuned versions of open-source VLMs, such as Florence2 and Qwen2-VL. It also significantly outperforms prompt engineering baselines utilising closed-source foundation models like GPT-4o. More specifically, LiMAC increases the overall action accuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared to prompt-engineering baselines.', 'score': 5, 'issue_id': 243, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': '66e9ccd38bb979e0', 'data': {'desc': "Статья представляет новую архитектуру управления мобильными приложениями под названием 'app agents'. Предложенная система LiMAC использует текстовую цель и последовательность предыдущих наблюдений для генерации точных действий. Авторы вводят компактный Action Transformer (AcT) в сочетании с настроенной мультимодальной моделью для принятия решений в реальном времени. Эксперименты показывают, что LiMAC превосходит базовые модели на основе промптов и настроенные мультимодальные модели, повышая точность действий до 42%.", 'emoji': '📱', 'title': 'Эффективное управление Android-приложениями с помощью легковесных агентов', 'categories': ['#agents', '#cv', '#multimodal', '#architecture'], 'embedding': [0.008865341087960986, 0.09468604357218173, 0.05227403965179727, 0.005268714105163022, -0.017874941402068783, -0.011763625379604773, 0.00514084855051685, -0.018661804957292815, -0.0164716984704767, -0.00457037181742621, -0.03999895286044254, -0.10984629269851756, -0.052405180552037696, -0.0009548929999207165, -0.01673398632221804, -0.07375544557084171, 0.002070437566211576, -0.06672611984848749, 0.05675916534562184, 0.054555945777325095, 0.08067985050465629, -0.029297593179535862, 0.031736870402439034, 0.032707337269260145, -0.03113361015881209, -0.07008340354394194, -0.09909248069168837, -0.008622724472110049, -0.06410324133107406, -0.06966374862899892, 0.04993967514908644, 0.002370429611810554, -0.029874625243114718, -0.08692230662052597, -0.020196190806212155, 0.02879924565610126, 0.047893826678165045, -0.03451712606848829, -0.06866705358212973, -0.021769921950833868, -0.055080521480807776, -0.02633373420188952, 0.053769080205014246, 0.11635104473447594, -0.07564391487604046, 0.011311178280652078, -0.020196190806212155, 0.11257410007281796, -0.0990400243315922, 0.054555945777325095, -0.10182028403181512, 0.025520642466617408, -0.07826679541054071, -0.029927083620297716, -0.010058752729616583, -0.10108587078542677, -0.033520431021619085, -0.0005364613876273701, 0.026241934563177808, 0.022124009441286924, -0.1359701994429356, -0.021363373057567567, 0.007560457361451174, 0.09374180488540869, -0.12967528494988284, -0.04537586088094396, -0.13817341295997182, 0.04073335803848357, -0.0195142419882673, -0.06279179400402003, 0.012484918282999902, -0.012681634676077618, -0.08277815735276067, -0.09059434864742576, -0.03370403433321617, -0.027199286331431462, -0.0014663549562841198, 0.08749934070119167, 0.020078160970365525, 0.07532917671546342, 0.11026595769889473, -0.014255363198486453, 0.029350049539632033, -0.0889156987313512, -0.09227298847806616, -0.009901379010028362, -0.08225357761510432, -0.06751298138662469, -0.16324818241703226, -0.0721817083749595, 0.008839112504495535, 0.08482400178950841, -0.04388081629355334, 0.015002884887055718, 0.03045166134086723, 0.1361800269004071, -0.05938204789720892, 0.04776267972666413, 0.10486281746417156, 0.1426847890217996, 0.04193988255991111, -0.025966532621412422, 0.01102921899131165, -0.07443739237169975, 0.06499501558940361, -0.019356868873805128, 0.041100560627504085, 0.03944814695982494, -0.02364528019163881, 0.08996485013831658, -0.0747521325493636, -0.11561664157352174, -0.0662015441450048, 0.05004458988636561, 0.04629386533640842, -0.006435896759935802, -0.0064457324787353465, -0.08172900191162165, -0.06767035853526052, -0.10795782541040566, -0.023881339863332064, 0.051041282916147984, 0.03700886368566129, 0.0021966636326824756, 0.07737502115221116, -0.041834967822631935, 0.07291611960426103, -0.04448407653718028, 0.05460840213742127, -0.024576405796931208, -0.02104862783718664, 0.04159890815093868, 0.08608299275646628, -0.04485128316037445, -0.05633950639650515, -0.004540864257610211, -0.05597229977331098, 0.05612967490485998, -0.10171536122618863, 0.08692230662052597, 0.027855006969328234, 0.00514084855051685, 0.0061342650244528675, 0.0195142419882673, -0.0391858591080836, -0.03454335424853636, -0.016314325356014528, 0.03089755048711883, -0.07889629391964988, 0.09888265323421686, -0.0004229397206745099, -0.08797146004457819, -0.07742747952939416, 0.020642081969550582, -0.0008061263713731317, -0.058542723947715064, -0.014412736918074674, 0.0952106192756644, -0.058700099079264066, -0.10328908631954985, -0.028327126312714748, -0.03632691486771643, 0.01735036368149927, -0.013573414985667645, -0.0823584923523835, 0.08503383731532724, 0.021284687508879897, 0.09138120816847613, -0.08797146004457819, -0.033520431021619085, -0.10722341418110413, -0.06746052099235486, -0.020786339985445296, -0.1084823990968015, -0.06515238870386578, -0.10103341845950425, 0.015356974394595603, -0.0038917011689971696, -0.12841630003418547, -0.0018474925896684105, -0.03992026226903779, 0.10701358874071945, -0.02869432890173526, -0.03866128138751408, -0.09059434864742576, -0.06824739059883937, 0.0584902675876189, 0.12306562221081897, -0.02427477264948749, 0.0013704558508120953, -0.012235744722991286, 0.14866495728592796, 0.014832397884278188, 0.052483869126355616, 0.0008860423026852531, 0.06688349296294967, 0.10491528189261505, -0.03651051616222668, -0.0007811270409635064, -0.0678277316497227, 0.04524471392944305, -0.004947411133789683, 0.05786077714685704, -0.06614908778490863, -0.0898074830751149, -0.05513297985799078, -0.03074017737265666, 0.014425850806390033, 0.030215601669173975, 0.02879924565610126, 0.10575459979084842, -0.08713214012925799, 0.01820280172101717, -0.004822824353785374, -0.08335518538216587, -0.02049782395365587, 0.0305565760781464, -0.026805853545276034, -0.051880602831468184, 0.006039185602555875, 0.07254891499815368, 0.01614383916007173, 0.12348528519410933, -0.07454230509189208, -0.1145674861323827, 0.005757226313215444, 0.04193988255991111, -0.05195929342287293, 0.04154645179084251, -0.04810365816981022, 0.038320304961454825, 0.004596600602600345, -0.0682998509931092, -0.07590620474486863, 0.07564391487604046, -0.09872527406849421, 0.03108115178162909, -0.08739442596391249, 0.0011147248827158276, -0.0024015764580931427, -0.019251954136525955, 0.05502806512071161, -0.0056785395542756755, -0.11656087219194745, -0.02037979411780924, 0.05597229977331098, -0.072286631180586, -0.09153857926585146, 0.050674082344214305, -0.03582856532719499, 0.04508734283206771, 0.0013352108287047657, -0.03307454389245432, -0.0294811934655027, -0.01614383916007173, 0.08020773116126977]}}, {'id': 'https://huggingface.co/papers/2410.13924', 'title': 'ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding', 'url': 'https://huggingface.co/papers/2410.13924', 'abstract': 'The performance of neural networks scales with both their size and the amount of data they have been trained on. This is shown in both language and image generation. However, this requires scaling-friendly network architectures as well as large-scale datasets. Even though scaling-friendly architectures like transformers have emerged for 3D vision tasks, the GPT-moment of 3D vision remains distant due to the lack of training data. In this paper, we introduce ARKit LabelMaker, the first large-scale, real-world 3D dataset with dense semantic annotations. Specifically, we complement ARKitScenes dataset with dense semantic annotations that are automatically generated at scale. To this end, we extend LabelMaker, a recent automatic annotation pipeline, to serve the needs of large-scale pre-training. This involves extending the pipeline with cutting-edge segmentation models as well as making it robust to the challenges of large-scale processing. Further, we push forward the state-of-the-art performance on ScanNet and ScanNet200 dataset with prevalent 3D semantic segmentation models, demonstrating the efficacy of our generated dataset.', 'score': 4, 'issue_id': 249, 'pub_date': '2024-10-17', 'pub_date_ru': '17 октября', 'hash': '37c34e5be2bb734e', 'data': {'desc': 'Эта статья представляет ARKit LabelMaker - первый крупномасштабный набор данных реального мира с плотными семантическими аннотациями для задач 3D-зрения. Авторы расширили существующий инструмент LabelMaker, чтобы автоматически генерировать аннотации в больших масштабах. Они использовали современные модели сегментации и сделали процесс устойчивым к проблемам обработки больших данных. Результаты показывают улучшение производительности моделей семантической сегментации на наборах данных ScanNet и ScanNet200.', 'emoji': '🏷️', 'title': 'Большие данные для прорыва в 3D-зрении', 'categories': ['#dataset', '#data', '#3d'], 'embedding': [0.046309019829328536, 0.03673270051817575, 0.12946809725509664, -0.08332337936591237, -0.02419898689592474, -0.04454866568594626, -0.019035285605191615, -0.0069416584882112334, -0.13960773257249065, 0.013836374957346916, -0.03957273572043524, -0.0007884914964086981, -0.11885903362464735, -0.1043067884091334, -0.01651211248366949, 0.003928521240162009, 0.019035285605191615, -0.005260521743295119, 0.02786052164603092, -0.04518239593914578, 0.04088713296641502, 0.029996416409282457, 0.04264748507922235, -0.04325774391676911, 0.014998208204641228, 0.027719693152114342, -0.06210525616616369, 0.033376296202130416, 0.09811034482967873, -0.011970400864929669, -0.07313680121721282, -0.06844252417838509, -0.11735687520632015, -0.02175796372918728, 0.05295142030618571, 0.09341607185200086, -0.008033078300777234, 0.0028268336223888336, -0.08923816392695896, -0.04274137277240834, 0.039267607316949324, -0.008074152161353355, -0.029198388277088528, 0.03445597726100764, -0.0036996754451913065, 0.017756094467403512, 0.06736284718065773, -0.03356406346620265, -0.01525639377682162, 0.08740739756719335, -0.07445119643261768, 0.14308149802794967, -0.10543341229931616, -0.08351114459940967, -0.034808046465224146, -0.09318135160374844, -0.056753783550208464, -0.012087756724848521, -0.0017544851726528647, -0.016946331642670665, 0.030160714288276862, -0.07022634973742012, -0.03466721797130757, -0.016770295009987477, -0.110315460663366, -0.06661176187976932, -0.08107012549382209, 0.09163224426239089, -0.025607267773940633, 0.00535440740590617, 0.07754941923763248, -0.0678322694019882, -0.07736164588183544, -0.03462027717057698, -0.06412379588172636, -0.03478457504957138, -0.11003380367553285, 0.08585828210353606, -0.021089029398371012, 0.005154900372857686, 0.07332457254243493, -0.09501212405523886, -0.06539124826582567, -0.056519067363105906, -0.04598042204076479, -0.06590761331846164, -0.025114370075807548, -0.10627838326281562, -0.10374347037231725, 0.08036598505481414, 0.013824639452578027, -0.04804590458763297, 0.007727949897291317, 0.09088115896150248, 0.024715358040285518, 0.0939793817665173, -0.03788279582401125, -0.07928629587363718, 0.051871735186158625, 0.05093288059062304, -0.06032143060712866, 0.07074271682063103, 0.02706249554441192, -0.06304411076169926, -0.005609658391193111, -0.06055614476365629, 0.04839797379184948, 0.08102318063194162, -0.018389820659453174, -0.020549186838357474, -0.14824518916580812, -0.003165701449792182, 0.0019935997881182113, 0.03396307956287455, 0.019176112068533254, -0.012850577327448322, -0.032296609051528404, -0.0014801635352371207, 0.05881926406650171, 0.043562870289680096, -0.025536853526982345, 0.04947765485072669, 0.030489314107415542, 0.022110034963978727, 0.10571506725657437, -0.008344073644417617, 0.026170581749606937, -0.07252654237966606, 0.006748020222834661, -0.018530649153369747, -0.0855296883761222, -0.00322144601120312, 0.10458844539696656, -0.06309105156242986, -0.08388669131100374, -0.11961012298668564, -0.18899149769945642, -0.03478457504957138, -0.02628793882787075, 0.0023779435594953476, 0.0239290646006305, -0.06135417086527528, -0.02349484442634186, 0.055110784454515074, -0.015197714831574725, 0.0019657275683299903, -0.008514240494141428, 0.12993752556815188, -0.0510267662532341, 0.1328479770479446, -0.07008552327407848, 0.10355570716939487, -0.021218121169173744, -0.013507775747380718, 0.016852445980059617, -0.06036837546900912, -0.04952459768203222, 0.11594858620600451, 0.017404023232612073, -0.053326962956629906, 0.020197117634140966, 0.05182479235485309, 0.03973703563000458, 0.0987675383762313, -0.0049671294537505725, 0.17237375978419964, -0.0681139243592464, -0.032484382407325436, -0.11040934429540213, -0.12486770790945488, 0.019305203839335983, 0.05525161294843165, -0.009500038733212502, -0.07102437990018899, 0.040840190135109485, 0.0062257821383194115, -0.06459321810305681, -5.537777053845592e-05, -0.06449933447102069, -0.11923458033624143, -0.032132311172534, 0.09205472771356568, -0.10233518949430136, -0.032484382407325436, -0.03985439067769346, -0.025795039099162736, -0.028118706202923845, 0.05665989585702248, 0.03551219096538196, 0.06571984808496434, -0.04182598553137566, 0.049430714049996105, 0.042670958525450046, 0.04382105383128555, 0.050322627844801085, -0.09003619002857796, 0.12383496562073332, 0.01756832314218141, 0.0431873276392359, -0.05562715356830092, 0.10778054980344257, 0.06750367364399937, -0.04839797379184948, -0.13378683570463004, 0.026804309972231533, -0.08740739756719335, -0.02459799994673424, -0.08304172237807922, -0.019187848791647102, -0.039338021563907616, 0.030325016228421136, -0.018190314641692157, 0.04541710603452355, 0.028165650049516832, -0.056002698249320054, 0.02212176965651764, -0.11313202038882285, -0.03274256594893089, 0.0239290646006305, 0.06675259240426083, -0.021276800723593118, 0.10505786558772208, 0.07740859074371591, -0.026381824490481803, -0.019234789592377694, -0.09726537589675421, 0.05370250154592424, -0.06121334237135871, 0.10205353453704313, -0.08670325509761047, -0.02272028974037562, 0.0020390755290345054, -0.002784291656136015, -0.031052628083081846, -0.002825366531999603, -0.07609419146716119, 0.04262401569414452, -0.046238605582370244, -0.007176372644738861, -0.008179774140963264, 0.09158529736993551, 0.06496876481465087, 0.026217524580912463, 0.029714759421449306, -0.016336074835698836, 0.057317095495299834, -0.019117432514113884, -0.009500038733212502, 0.022168712487823167, 0.012052550210541857, 0.06351354110532945, -0.05558021479814526, -0.0024835647268752863, -0.06337271058083795, -0.026733895725273245, 0.034174320273174484]}}, {'id': 'https://huggingface.co/papers/2410.17434', 'title': 'LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding', 'url': 'https://huggingface.co/papers/2410.17434', 'abstract': "Multimodal Large Language Models (MLLMs) have shown promising progress in understanding and analyzing video content. However, processing long videos remains a significant challenge constrained by LLM's context size. To address this limitation, we propose LongVU, a spatiotemporal adaptive compression mechanism thats reduces the number of video tokens while preserving visual details of long videos. Our idea is based on leveraging cross-modal query and inter-frame dependencies to adaptively reduce temporal and spatial redundancy in videos. Specifically, we leverage DINOv2 features to remove redundant frames that exhibit high similarity. Then we utilize text-guided cross-modal query for selective frame feature reduction. Further, we perform spatial token reduction across frames based on their temporal dependencies. Our adaptive compression strategy effectively processes a large number of frames with little visual information loss within given context length. Our LongVU consistently surpass existing methods across a variety of video understanding benchmarks, especially on hour-long video understanding tasks such as VideoMME and MLVU. Given a light-weight LLM, our LongVU also scales effectively into a smaller size with state-of-the-art video understanding performance.", 'score': 2, 'issue_id': 253, 'pub_date': '2024-10-22', 'pub_date_ru': '22 октября', 'hash': 'ab4b27c05d7611e1', 'data': {'desc': 'LongVU - это новый механизм адаптивного сжатия для анализа длинных видео мультимодальными большими языковыми моделями (MLLM). Он использует кросс-модальные запросы и межкадровые зависимости для уменьшения временной и пространственной избыточности в видео. LongVU применяет признаки DINOv2 для удаления похожих кадров и текстовые запросы для выборочного сокращения признаков кадров. Этот подход позволяет эффективно обрабатывать большое количество кадров с минимальной потерей визуальной информации в рамках заданного контекста.', 'emoji': '🎥', 'title': 'LongVU: Эффективное сжатие для понимания длинных видео', 'categories': ['#video', '#multimodal', '#benchmark', '#architecture'], 'embedding': [-0.012843565359532752, 0.03310339764647547, 0.018170475969938787, -0.05531454744327182, -0.029439185217606325, 0.033831220054698546, 0.06761225144797631, -0.016074848997828226, -0.010986362189668992, 0.1557039318772138, 0.015221538783937522, -0.029765449878116128, -0.08794109021680163, -0.03327908017060725, -0.029464281567331177, -0.022073113816266303, 0.08337337285557764, 0.04630459850747698, 0.025461254284075342, 0.06580523350720875, -0.03230028013203447, 0.025448708128227377, 1.2162653137052004e-05, -0.0011646735987565992, 0.09301075678168169, -0.10194541061125861, -0.02926350269347454, 0.10882208098380501, 0.10751702234176579, -0.07539242271484865, 0.0633958930779725, -0.03398180622910548, -0.08718817145885371, -0.022273892690122938, -0.05127387361641426, 0.1032002826108915, 0.014029414725167362, 0.07599475933641857, -0.010735388597348197, 0.0064562919777510575, 0.044347006506389244, -0.006195906547628385, 0.023265236865529233, -0.021157060709049016, 0.06048459738803682, 0.10059015523174078, 0.014644300329205478, 0.09371348485919437, -0.10104190567890374, 0.09526951305552546, -0.013439628297474339, 0.06555426193390242, -0.07318385712144013, 0.020630017174682574, -0.005060251900457933, -0.015259185327539256, 0.07629592562818906, -0.06409862115548519, 0.012122017442543782, -0.012115742345605338, -0.03378102533623439, -0.14506263541069642, 0.011758106238432244, 0.024670688982525682, -0.07343483071376092, -0.008683681448664797, -0.13381904674092723, 0.038725202076432354, 0.038223254891790764, -0.04708261765317868, 0.0006282179035459667, -0.022951520379881855, 0.0768480634932659, -0.047710050624473435, 0.03235047485049863, 0.033053200908996855, -0.02908782218835721, -0.006001402366907298, 0.016928158202211697, -0.03024229869401841, 0.041385522155032786, -0.006832751962429358, -0.004793592786706938, 0.00265090702938987, -0.06650796158472143, 0.04808651202246186, 0.003912048472720719, 0.10540884820430005, -0.02926350269347454, -0.03749543046455323, -0.009574636994748559, 0.09280998194585398, -0.06334569634049389, 0.023880121661961566, 0.07388658116092389, 0.0045143846904877345, 0.077199426522515, -0.12879957489451135, 0.08628466248846994, 0.12779567043015588, -0.08794109021680163, -0.02740629811030066, 0.08929635165336285, -0.077199426522515, -0.013063166899485917, -0.03598959092964292, 0.05047075812098772, -0.04115964289342238, 0.014619203171874847, 0.007968407013402701, -0.039302438310248496, 0.0045771279876172105, -0.09100296804311533, 0.051700529732866846, 0.05626824709409085, -0.12056764308540376, -0.07408736003478052, 0.05556552103559262, 0.01804499018328562, -0.01661444171656432, -0.04419642033198231, 0.006039048506706141, 0.06424919925383428, -0.11193415554759732, 0.04838768033324681, -0.0500692023922889, 0.02715532653699432, 0.01210946866197702, 0.002735610541085096, -0.01606229981345857, -0.05561571575405678, 0.022637803894234476, 0.04479875897256667, 0.0026273780405895093, -0.10480650956371566, -0.016514052279636003, -0.09918470311474432, 0.048362581964507496, -0.055816492608898954, 0.13261436945975852, 0.0018917122659469958, -0.04151100592267149, 0.1069146897582248, 0.031873628053610804, -0.03762091827022086, 0.04494934514697361, 0.0010650685489455864, 0.01648895592991115, -0.03011681290736524, 0.060584990862994056, -0.0751414471035134, -0.11625089931650054, -0.04457288374898519, 0.0026446327400572113, -0.1358268253844213, -0.1372322714443744, -0.05240325579136506, 0.01214711439797297, 0.09873295266758135, -0.10581040191398439, 0.0031920685223605742, 0.005574747663764839, 0.06746166123554045, 0.017869307659153837, -0.0048814336449699396, 0.04246470557349051, -0.05054605322720564, 0.019889644572582618, -0.1183590774919952, -0.10611157426279827, -0.029163113256546223, -0.058627394823877396, -0.01594936220166783, -0.069670226828949, 0.11574894809383003, -0.05953090177524672, -0.06791341370171788, -0.09833139491986809, -0.004210079638839344, -0.037947184949745125, -0.07669748539491678, 0.08859362761387908, -0.031371680868969215, 0.011638893529703058, -0.10274852408767068, -0.0022054290544465433, -0.06389783420557071, 0.047584562818805805, 0.011714185405497853, 0.030367786499686036, -0.07423794620918746, 0.14345640845787228, 0.007171566211111708, 0.07223015545160665, 0.08236948252432337, -0.00902249509164281, 0.05877797696025541, 0.020416689116456287, 0.03752052883329254, -0.018358708687947457, 0.05134916670361773, 0.03019210397555425, 0.015698388609347032, -0.18471644280723742, -0.044673271166899044, -0.010528335636060348, 0.0020171991630581164, 0.1032002826108915, -0.07122626713936685, 0.01090479602454154, 0.026954547663137686, 0.09381387025809378, 0.17056154835246026, -0.011049105082995577, -0.024281681428689295, -0.04532580452594757, -0.0918562802760205, 0.06665854977814283, 0.04281606860273962, -0.0006670403211685977, -0.024319325953276575, 0.015522707498525369, 0.09270958443286782, 0.027080035468805313, -0.08713797875940402, -0.06962003009147037, -0.02790824529494225, -0.0669597120318844, 0.00991345063772657, -0.03448375139473261, 0.042941556408407244, -0.020642565349545002, -0.07980955390166572, -0.03290261877261884, -0.026226725254914613, -0.11675284246311321, 0.06565464935181628, -0.026678475702077584, 0.018948493096626023, -0.012278875483466024, 0.06274336173793843, 0.0029944269950717135, 0.07835390504719066, 0.001169379457087105, -0.0681643913320676, 0.08653564011881965, -0.07835390504719066, -0.009882078383457496, 0.0876399259440456, 0.00870250350905699, -0.007485283100561979, -0.12116998172598811, -0.09316134497510309, -0.0827208455535725, -0.018534389193064785, 0.006029636870805707]}}, {'id': 'https://huggingface.co/papers/2410.13458', 'title': 'MedINST: Meta Dataset of Biomedical Instructions', 'url': 'https://huggingface.co/papers/2410.13458', 'abstract': "The integration of large language model (LLM) techniques in the field of medical analysis has brought about significant advancements, yet the scarcity of large, diverse, and well-annotated datasets remains a major challenge. Medical data and tasks, which vary in format, size, and other parameters, require extensive preprocessing and standardization for effective use in training LLMs. To address these challenges, we introduce MedINST, the Meta Dataset of Biomedical Instructions, a novel multi-domain, multi-task instructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over 7 million training samples, making it the most comprehensive biomedical instruction dataset to date. Using MedINST as the meta dataset, we curate MedINST32, a challenging benchmark with different task difficulties aiming to evaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and evaluate on MedINST32, showcasing enhanced cross-task generalization.", 'score': 2, 'issue_id': 250, 'pub_date': '2024-10-17', 'pub_date_ru': '17 октября', 'hash': '838e617c67ce19c3', 'data': {'desc': 'Статья представляет MedINST - новый мета-датасет медицинских инструкций для обучения больших языковых моделей (LLM) в области биомедицинского анализа. MedINST включает 133 задачи и более 7 миллионов обучающих примеров, что делает его самым обширным биомедицинским инструкционным датасетом на сегодняшний день. Авторы также создали MedINST32 - сложный бенчмарк для оценки способности LLM к обобщению. Эксперименты показали улучшенную кросс-задачную генерализацию моделей, обученных на MedINST.', 'emoji': '🧬', 'title': 'MedINST: революция в обучении LLM для медицинского анализа', 'categories': ['#dataset', '#data', '#benchmark', '#medicine'], 'embedding': [0.014804388351798944, 0.007851771587139214, 0.12218369604906569, -0.07203367173507462, -0.06114250740876376, 0.03259751621449102, 0.045464291874616654, -0.02201028972570843, -0.09082726703275561, 0.04277949020125179, 0.024885049726050285, -0.09376535331537024, -0.015133655881442672, -0.05060593620024381, 0.09168842936904605, 0.014361143363588064, 0.05042863451138802, 0.02550559435113282, -0.051112499262790934, 0.1466001690428055, 0.1336321012900118, 0.015526245589390903, 0.029507464091088464, -0.04478042712321374, 0.0525308840458594, -0.07304680401612125, 0.012170246062664989, -0.008200035565075882, -0.007098254696783894, 0.02293477218831924, 0.059420180684198756, -0.016463392898059443, -0.09477847944046448, 0.013791256686347545, -0.007376866125371322, 0.04513502434497293, 0.024087209568064354, 0.05339204638214984, 0.034395823807465864, 0.024150529694384727, -0.06012937307573299, -0.09092858374923331, -0.05987609051846736, 0.035915525307012024, -0.1214745057095156, -0.01895822803651079, 0.09842575401064507, 0.040930525276030166, 0.0329774390243974, 0.10045201857273835, -0.09918560783839435, 0.026290771715045156, -0.0743132168024494, -0.0008421658469578147, 0.04323540003552039, -0.0036251121155716345, 0.006908292471037054, 0.07694735909158336, -0.019540780175404275, -0.04792113452687895, 0.027177261691466916, -0.0988310126686193, -0.01650138333226436, -0.06033200035273596, -0.1114444996155269, -0.10830378810789343, 0.006655009708573014, 0.030191328842491375, 0.03814441099015588, -0.08642014273879402, 0.0027433710460246976, 0.03125511640380066, -9.57231452189897e-05, 0.06524569181321295, -0.01812239539233581, -0.06813311050366014, -0.08034135520846658, 0.07983478598996706, -0.0586096756801551, -0.029558121423335238, -0.01565288625242848, 0.009327144894292844, 0.013411332440052277, -0.04450181282184853, -0.05080856142526266, -0.00655369648046835, -0.022301562717178976, 0.021858319780952228, -0.05622881389630264, -0.056583411118061824, -0.06813311050366014, -0.0704126617269873, -0.06686669771733202, 0.07010871773350665, 0.11519308885020105, -0.024796401959598587, -0.00433113850078985, -0.053037453264358915, -0.00296499374532855, 0.16159453008547037, -0.02743054424873254, 0.007630149093033775, 0.06833574393661551, -0.10344076218759973, 0.008953552865828027, -0.05283482188338767, 0.0810505476000008, -0.10257959985130931, -0.027126606411204266, 0.005591221121271664, -0.07051397844346499, 0.03229357837696275, -0.07598489029873588, -0.062104982357563614, 0.05855901834790832, -0.07745392625809873, -0.1107353031200244, -0.05567159555349287, -0.03791645607302158, -0.05073257850486869, -0.03467443605684695, 0.07704867580806103, 0.0713751387277713, -0.08054398043348543, 0.04427385790471423, -0.0728948361233492, 0.03477574866935637, -0.014753732045544232, 0.05288548126761858, -0.027202589331598238, -0.013753264815753733, 0.007256556654172133, 0.08773721490935306, -0.09021938930571494, -0.05268285604259973, -0.017134592803404625, -0.12532440755669916, 0.0593188660197052, -0.08150645743426942, -0.04429918759682968, -0.02385925465093005, 0.01085950631513481, 0.018970892882568514, 0.053240078489377764, -0.058964272901914284, -0.07117251555473658, 0.015412268130823753, 0.056938008339821, -0.009916027199032649, 0.05855901834790832, -0.05022600928636917, 0.01030228386835678, 0.05855901834790832, 0.051365783872040695, -0.08398862567467891, 0.0366753729788089, -0.07390796430042756, -0.017172585289593676, 0.10597359186422428, -0.06914624688867504, 0.11965087047640943, 0.04906090911255047, 0.07259089418185266, 0.013601294665799119, 0.06757589216085037, 0.10769591038085276, -0.04204497016958623, -0.015082999985584785, -0.09057398447548999, -0.05729260556158018, 0.01695729316653297, -0.042450222671608064, 0.040449285749646104, -0.14153450763757233, -0.05906558756640783, -0.02052858481631959, -0.02775981177837627, -0.04285547517362989, 0.0217696699625164, -0.035332971116134405, -0.04665472174055081, 0.010922827672645663, -0.06093988013176077, 0.06266220275235752, -0.050023384061350325, -0.03515567558323101, -0.1261349105087587, 0.030343298787247574, 0.04665472174055081, -0.023441337302850494, 0.07228695839630851, 0.05800179384914615, 0.15754200506525207, 0.0890036276956812, 0.08191170993629124, -0.04670537496882933, 0.18185716749846662, -0.0007448102190874601, 0.057191292949070764, 0.020680552709091662, 0.03948681285283038, 0.07056462756777525, -0.06007871574348621, -0.07790983609236735, -0.025201654461620416, -0.034446481139712645, -0.07345205446615896, 0.014310486646936526, -0.060230685688242414, -0.04450181282184853, 0.0962981788880265, 0.05987609051846736, 0.1074932851558339, 0.02927950917395416, -0.02084518749990559, 0.061953010360823284, -0.13383471420312584, -0.08697736928954031, 0.062408920195091894, 0.03497837594635935, 0.053240078489377764, -0.013639287357186582, 0.07319876780492507, 0.0120056118874463, -0.04047461544176156, 0.031837668542694146, -0.03300276871651285, -0.04151307741492365, 0.09842575401064507, -0.11802985636435386, 0.052024318931328146, -0.051264471259531263, 0.016045475549979885, -0.06012937307573299, -0.0022431371233318288, 0.007566828145919749, -0.007763122589497039, -0.10587227925171486, 0.05369598832364637, 0.014120524626388098, 0.051264471259531263, 0.056938008339821, -0.04475509743109828, -0.035890195614896564, -0.060433312965245393, 0.05103651634239696, -0.023441337302850494, -0.04761719463736654, -0.004761719463736654, 0.07968281809719499, -0.020895842780168237, -0.06605619476527248, 0.03974009746208013, -0.1386977524353243, -0.06757589216085037, 0.0762888240322959]}}, {'id': 'https://huggingface.co/papers/2410.15522', 'title': 'M-RewardBench: Evaluating Reward Models in Multilingual Settings', 'url': 'https://huggingface.co/papers/2410.15522', 'abstract': "Reward models (RMs) have driven the state-of-the-art performance of LLMs today by enabling the integration of human feedback into the language modeling process. However, RMs are primarily trained and evaluated in English, and their capabilities in multilingual settings remain largely understudied. In this work, we conduct a systematic evaluation of several reward models in multilingual settings. We first construct the first-of-its-kind multilingual RM evaluation benchmark, M-RewardBench, consisting of 2.87k preference instances for 23 typologically diverse languages, that tests the chat, safety, reasoning, and translation capabilities of RMs. We then rigorously evaluate a wide range of reward models on M-RewardBench, offering fresh insights into their performance across diverse languages. We identify a significant gap in RMs' performances between English and non-English languages and show that RM preferences can change substantially from one language to another. We also present several findings on how different multilingual aspects impact RM performance. Specifically, we show that the performance of RMs is improved with improved translation quality. Similarly, we demonstrate that the models exhibit better performance for high-resource languages. We release M-RewardBench dataset and the codebase in this study to facilitate a better understanding of RM evaluation in multilingual settings.", 'score': 2, 'issue_id': 247, 'pub_date': '2024-10-20', 'pub_date_ru': '20 октября', 'hash': '5143b0b6f1067fee', 'data': {'desc': 'Данная статья посвящена исследованию моделей вознаграждения (reward models) в многоязычном контексте. Авторы создали первый в своем роде многоязычный эталонный набор данных M-RewardBench для оценки таких моделей на 23 типологически разных языках. Проведя тщательную оценку различных моделей вознаграждения, исследователи выявили значительный разрыв в производительности между английским и другими языками. Результаты показывают, что качество перевода и ресурсообеспеченность языка положительно влияют на эффективность моделей вознаграждения.', 'emoji': '🌍', 'title': 'Многоязычная оценка моделей вознаграждения: новые горизонты и вызовы', 'categories': ['#dataset', '#benchmark', '#rlhf', '#multilingual'], 'embedding': [0.01826244564503357, 0.06497826174016313, 0.11391501491816758, -0.014391670299656253, -0.024684126141905568, 0.0014737501669571755, 0.055434579352020744, 0.09523376388764691, -0.03424049808917424, 0.12376328417608058, -0.025255222881681284, -0.03919001287668162, -0.017957858775262958, 0.04873369526482402, 0.0934570175503017, -0.08584237285379313, -0.008230157181882568, -0.04419029630367745, -0.00525092874734726, 0.07259290019488168, 0.014290141343066049, 0.008407831191438087, 0.013579441351710294, -0.009435807611690723, 0.09538605732253222, 0.050282008731929624, -0.0779739120075991, 0.052185665224714246, -0.012595883797950954, -0.051348056534336745, 0.026346653963534295, -0.06254157510438493, -0.06558743339910769, -0.005831545049153858, -0.03799705491883508, 0.09350777786740345, -0.0248871819744893, -0.015863833928424192, 0.0022748736388620234, -0.002798380266691049, -0.07000392220481484, -0.12264647189537835, 0.06924245919158166, 0.09807656426918926, -0.05898807826850118, 0.1088385878946241, 0.03919001287668162, 0.024785653017899097, -0.011250630948801434, 0.050053567539303324, -0.1729030973478621, 0.12112353754652529, -0.04472332020488101, -0.12589538602268485, 0.10822941831627622, -0.022704317730186604, 0.05447005842560715, 0.01798324205470884, 0.02047069108818548, -0.09193408944323866, 0.0007408410128323403, -0.021752488443495956, -0.012272261549192599, -0.046550833101117996, -0.0590388406661996, -0.03220992727975685, -0.13066721369287765, -0.019556934640066987, 0.03916463167783241, 0.05051044784395925, 0.06690730775418367, -0.045865515765029126, 0.0743696548546136, -0.012208806679532558, -0.04946977915980467, -0.03251451206893078, 0.04726153371665275, 0.08954816728575556, -0.003639163323416957, -0.04518019634834358, -0.011720200188404622, -0.037057915191270704, 0.0022256958235919565, -0.05482540977367286, -0.011111029153639072, 0.0009732461582455494, -0.014797784045420396, -0.06797335347599413, 0.02972247824628021, -0.016054198953523655, -0.059292665138271784, -0.014505888815372726, 0.005790299092591296, 0.0707653872986447, 0.09558911523571263, -0.11208750202193059, -0.05309942583402609, -0.02954480153194901, -0.0007162520635853735, 0.09853344457384518, -0.047616880903525116, -0.027031973380219843, 0.10157929454618124, -0.045434020820415776, 0.04858140182993871, -0.029138689866781545, 0.032793715659255505, -0.018985835819694593, -0.055180759041141905, -0.004289580730864403, -0.14132771252291562, 0.01270375795022363, -0.0826442273659751, -0.07447118173060711, 0.02837722477295169, -0.048505258233391066, -0.10812789144028268, -0.006231313807295198, 0.021143316784551402, -0.012849704733008793, 0.002558836386023185, 0.08371027516838223, 0.027235029212803574, -0.0727959581080621, 0.05447005842560715, -0.03190534249058291, -0.003940576242958497, 0.0007015780313496385, 0.0347735219903778, 0.03809858387542528, -0.029697097047430995, 0.06350610019199188, 0.06812564274968608, -0.0646229124726941, -0.13442377260313518, 0.07330359872981976, -0.0016030403793520472, -0.009283515841282756, -0.13807879839560913, -0.010996808557325924, 0.005358802899619934, -0.025267914521404228, -0.10792483560769894, 0.044824847080874544, -0.1352360042558568, -0.06756724181082667, -0.02206976487239284, -0.014556653293667827, -0.07416659278023982, 0.002371643022496456, 0.012646647860126722, -0.03835240418630412, -0.05934342961656689, 0.10051324674377411, -0.08162893780007306, -0.10609731438907527, -0.09188332080375021, 0.049317485724919355, 0.06990239532882131, -0.11432113074452839, 0.06589201818828164, 0.0743696548546136, -0.012710102937846432, -0.04172822638845336, 0.0826442273659751, -0.0068658670812083, -0.08452250057931383, 0.061627818656266445, -0.07863384814483876, -0.039063104801838874, 0.07919225740608488, -0.03515425453729273, -0.1313779247113958, -0.06106941355621367, -0.06558743339910769, -0.06792258691710235, -0.04368265152072643, -0.04962207051409329, -0.0038295293888147546, -0.05959724992744573, 0.00507325411361274, 0.04578936800728814, -0.08244116737219802, 0.0339866777782954, -0.001695843792020794, -0.039875332293367156, -0.02503947540937461, -0.005974319754246956, -0.030179356470339456, -0.03825087522971391, 0.054520822903902255, 0.041398256239236854, 0.1617349537348731, 0.05655139579391632, 0.0010129057638725767, -0.02530598735997639, 0.04617010055420307, 0.06309998228503438, -0.11005693329310988, -0.020305706013577226, 0.05033277112962805, 0.0392915439138685, 0.06426755904403171, -0.08954816728575556, 0.013858644317856016, -0.03198148816772722, -0.05325171718831472, 0.06695806599068875, -0.0928478417301638, -0.020838730955079127, 0.08904052874459456, 0.10528508897814366, 0.09959949445684899, 0.02335156222770331, -0.040712940983744665, 0.03411358793373482, -0.04129672936324332, 0.04048449979111836, 0.07406505966245627, 0.04520558170838614, 0.05538381487372564, 0.01734868919691508, 0.10183311901825343, 0.013604823382798177, -0.09863497144983871, 0.0754357026570207, 0.07538493401753224, -0.03238760191349137, 0.04561169337355361, -0.1369619965178903, 0.10711260187438064, -0.02047069108818548, -0.009429462832127587, -0.05497770112796149, -0.013160636174282874, -0.015013532349965745, -0.038174727471972925, 0.015178515552036987, 0.03226069175805195, -0.055739166221791356, 0.029062542109040555, 0.06106941355621367, 0.0714760837529861, 0.024328774793839852, 0.14092160085774816, 0.08406562859704461, -0.050688120397097094, -0.07944608187815706, 0.07690786212459529, -0.0826442273659751, -0.021409828735153184, -0.003848565808100833, -0.03957074334299988, -0.0021511357691743386, -0.03581419067453238, 0.08726377408486266]}}, {'id': 'https://huggingface.co/papers/2410.18071', 'title': "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts", 'url': 'https://huggingface.co/papers/2410.18071', 'abstract': "Recently, multimodal large language models (MLLMs) have received much attention for their impressive capabilities. The evaluation of MLLMs is becoming critical to analyzing attributes of MLLMs and providing valuable insights. However, current benchmarks overlook the problem of prompt sensitivity - minor prompt variations may lead to significant performance fluctuations. Thus, inappropriate prompts may obscure the models' capabilities, underestimating the models' performance. Moreover, different models have different preferences for different prompts, and thus, using the same prompt for all models will cause evaluation bias. This paper analyzes this deficiency in existing benchmarks and further introduces a new evaluation framework named TP-Eval, which introduces a prompt customization method to reduce evaluation biases and tap models' potential. TP-Eval will rewrite the original prompts to different customized prompts for different models. In particular, we propose some well-designed modules for prompt customization tailored to the scenario of MLLM evaluation. Extensive experiments demonstrate the effectiveness of our approach to uncovering models' capabilities, and TP-Eval should benefit the community in developing more comprehensive and convincing MLLM evaluation benchmarks.", 'score': 2, 'issue_id': 245, 'pub_date': '2024-10-23', 'pub_date_ru': '23 октября', 'hash': '9fe4ef775d3f190c', 'data': {'desc': 'Статья посвящена проблеме чувствительности к промптам в мультимодальных больших языковых моделях (MLLM). Авторы предлагают новую систему оценки TP-Eval, которая использует метод настройки промптов для снижения предвзятости оценки и раскрытия потенциала моделей. TP-Eval переписывает исходные промпты в индивидуальные варианты для разных моделей. Эксперименты показывают эффективность этого подхода в выявлении возможностей моделей.', 'emoji': '🎯', 'title': 'Точная настройка промптов для справедливой оценки мультимодальных языковых моделей', 'categories': ['#benchmark', '#multimodal'], 'embedding': [0.09228843151180205, -0.028497679834461994, 0.088152104222084, 0.005663947551181898, -0.035319931692149885, 0.048695845240216036, 0.04348515103720302, 0.10442881905094235, 0.012952880808457664, 0.07515222648247115, -0.024079331412122314, -0.062044901020362496, -0.03429928031469431, -0.028229087585800224, -0.01964755202447066, -0.09723053971020969, 0.0753133772526935, -0.04813180297497281, -0.033681518350907456, 0.02518056233739334, -0.021366544913528542, 0.04985079794538282, 0.0003993217055375848, -0.028551399533005627, 0.041175251870925834, -0.06274324045061268, -0.046869417116775156, 0.05046855782781755, 0.07848277286349964, 0.01873433796275022, 0.09997018189537102, -0.04864212970437666, -0.11194941658293682, -0.006956549647100483, -0.07499106738684023, 0.07794558420347183, -0.0033456572056467303, 0.06779278180205117, 0.029276598812527616, 0.054954054832660706, -0.029974940324129923, -0.004257193281277831, -0.04114839410300615, 0.046036782602870155, -0.02911544387960098, 0.10066852965102972, 0.10072224934957336, -0.011428617143578155, -0.07364810406217925, 0.08353231421493815, -0.03636744500022941, 0.14965983323323573, -0.0029511616769937648, -0.010078939376937256, 0.06553660233431763, -0.08294141001907097, -0.003196252546184957, -0.043001684157070987, 0.033359206403702046, -0.01145547616030912, -0.03010923540778474, -0.09078431949827084, -0.0485346903072894, -0.056619330104527084, -0.02820222981788054, -0.0699952415712411, -0.02787991787067514, 0.0024106191261394133, 0.006191060385535555, 0.002753074607419792, 0.04466695734758523, 0.03639430276814909, 0.045392158708459356, 0.03241913249270979, -0.02428077507828061, 0.07703236806039925, 0.009971502061202122, 0.12140388163545943, 0.06644981847739019, -0.04332399610427638, 0.05323506402495495, -0.04372688343659297, -0.02158141954499881, -0.031156748715864265, -0.0205070484689996, 0.05041484021062605, -0.043162841171349754, 0.031532776198909034, -0.057639981481982655, -0.10738334627433462, -0.05060285291147237, 0.01375194373686869, 0.024455360976519215, 0.18930409659054148, 0.09325536527206613, 0.007601171876429581, -0.009535038980687305, -0.0792885537721892, 0.0789125179637359, 0.09927183830241659, 0.007016983163218397, -0.04716487129606087, -0.023166115269049742, -0.006996838588467355, 0.08159844877576213, -0.047648336094840774, 0.030592704369268912, -0.025946049309470923, -0.0471111495161651, 0.054228855553138715, -0.08858185764772879, 0.03787156117646489, -0.0940611461807557, 0.0031945737275547634, 0.03626000560314214, -0.06193746370462736, -0.038328170288677244, -0.05903666450518727, 0.021702285744693788, -0.09502807994101978, -0.01048182837433555, 0.07106961680994457, 0.022427485024215776, -0.09701566299738729, 0.008265938056104082, -0.03945625898186795, 0.033896390901025586, -0.0732720765791345, 0.005156979083444071, -0.012596995402541378, -0.04407605315171806, 0.03067328183573223, 0.11023042785658321, -0.04447894256538678, -0.04004716317773512, 0.043646308051481786, -0.13923841985098412, 0.04348515103720302, -0.08782979227487858, 0.004153113602803084, -0.00025768107230918414, 0.02903486433178553, -0.05608214768855568, 0.0735406709091484, -0.09578013698846145, -0.05293961192702137, -0.005408784394615184, 0.03620629006730278, -0.025449152504702977, 0.12258568378313738, -0.04114839410300615, -0.035400511239965335, -0.03733437876049349, 0.0410678145551907, -0.07547453842967655, -0.11033786100961407, -0.019298382309345573, 0.049474766299633786, -0.0007814367897404869, -0.16502333400037367, 0.06720188593159254, -0.018062854219067594, -0.02739644890919097, 0.03217739801196771, 0.054040840770940256, 0.0923958750715936, -0.057693701180526295, 0.051086319791604405, -0.13504838743218733, -0.11861051350769808, -0.03029725018998319, -0.06832996838072684, 0.011066016463141095, -0.12559392862372115, 0.035749680955090415, -0.015793247948726333, -0.07966458541793825, -0.06714815790764038, -0.03945625898186795, 0.03161335366537235, -0.03797900057355216, 0.10426766619936785, -0.006184345735420421, 0.05259044013054415, 0.011522624742812595, -0.049609061383288605, -0.05522264708132247, 0.11839563887622781, -0.033788955666642584, -0.08331744166482001, -0.01925809149476178, 0.07837533762911664, 0.13386657487774875, 0.0731646351006951, 0.03027039242206351, -0.06145399682449532, 0.10507344086400103, 0.08428437542508407, -0.029249740003931865, -0.04410291091963774, 0.04426406585256438, 0.08245793897623467, 0.02460308494413388, -0.11603203041816766, 0.09347024198488854, 0.015806676832686176, -0.03338606417162174, 0.06392505092369914, -0.09137521536872947, 0.012308258579128565, 0.08036292068548415, 0.03717322174621472, 0.1538498656520325, 0.04848097269009789, -0.022709508238189516, 0.029625768527652703, -0.07869765165767416, -0.0009350381419478814, 0.04313597715937367, 0.08321000226773274, 0.05183838100175034, -0.015000899254160016, 0.11259403839599548, -0.04200788846618296, -0.05592099067427691, 0.039268246281021636, -0.0004876635104370947, -0.1178584502162, 0.026268360216000257, -0.08858185764772879, 0.02402561171357868, -0.03891907448454441, -0.05003881064622914, -0.006201132672911076, -0.01823744219865834, 0.007963771932461002, 0.038328170288677244, -0.010139372268649532, 0.022709508238189516, -0.15309781068594297, 0.13053603682212878, 0.06317299179490533, 0.017243648589122446, -0.0857884936826717, 0.014880032638194615, 0.051757801453934896, -0.05973500393543744, -0.06328042911064047, 0.023085537802586424, 0.005109975075691638, 0.06811509166790444, -0.07805302568191123, -0.03660917531826723, -0.0672556014674319, -0.0029243024521275877, 0.010152802401420653]}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            const themeToggle = document.getElementById('theme-toggle');
            let settingSortBy = localStorage.getItem('sort_by');
            const sortDropdown = document.getElementById('sort-dropdown');
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }
            
            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (2)', '#agents (2)', '#agi', '#alignment', '#architecture (3)', '#audio', '#benchmark (7)', '#cv (2)', '#data (2)', '#dataset (5)', '#diffusion (2)', '#edge_computing', '#ethics', '#games', '#graphs', '#hallucinations', '#inference', '#interpretability', '#math', '#medicine (1)', '#multilingual (1)', '#multimodal (4)', '#optimization (1)', '#plp', '#quantum', '#rag (1)', '#reasoning', '#rl', '#rlhf (4)', '#robotics', '#security', '#story_generation', '#survey', '#training', '#transfer_learning', '#video (2)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = '🏷️ Фильтр';
            } else {
                categoryToggle.textContent = `🏷️ Фильтр (${formatArticlesTitle(selectedArticles.length)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles = selectedCategories.length === 0
                ? articlesData
                : articlesData.filter(article => 
                    article.data && article.data.categories && 
                    article.data.categories.some(cat => selectedCategories.includes(cat))
                );

            console.log('filteredArticles', filteredArticles)

            //if (filteredArticles.length === 0) {
            //    selectedArticles = articlesData;
            //    selectedCategories = [];
            //    cleanCategorySelection();
            //} else {
            //    selectedArticles = filteredArticles;
            //}

            selectedArticles = filteredArticles;

            console.log('selectedArticles', selectedArticles)

            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                const explanation = item["data"]["desc"];
                const cats = item["data"]["categories"].join(" ");
                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="background-digit">${index + 1}</div>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <h2>${item['data']['emoji']} ${item['title']}</h2>
                            <p class="meta"><svg class="text-sm peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path transform="translate(0, 2)" fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg> ${item['score']}. ${item['data']['title']}</p>
                            <p class="pub-date">📅 Статья от ${item['pub_date_ru']}</p>
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>
                            <div class="links">
                                <a href="${item['url']}" target="_blank">Статья</a>
                            </div>
                            <p class="tags">${cats}</p>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            }
            if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
        });

        clearCategoriesButton.addEventListener('click', clearAllCategories);
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiffRu('2024-10-24 20:13');
        } 
        function hideNextLink() {
            if (isToday('2024-10-24 20:13')) {
                const element = document.getElementById('nav-next');
                if (element) {    
                    element.style.display = 'none';
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink(); 
    </script>
</body>
</html>
    