
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Chain-of-Model Learning for Language Model</h1>
                <div><p class='zh-text'>1. 这篇文章提出了一种新的学习范式，称为Chain-of-Model (CoM)。</p>
<p class='zh-text'>2. 它将因果关系引入每层的隐藏状态，形成链式结构，提高了模型训练的扩展效率和部署的灵活性。</p>
<p class='zh-text'>3. 作者引入了Chain-of-Representation (CoR)的概念，将每层的隐藏状态表示为多个子表示（即链）的组合。</p>
<p class='zh-text'>4. 每层中，每个链只能查看输入表示中的所有前序链。</p>
<p class='zh-text'>5. 因此，基于CoM框架的模型可以通过增加链来逐步扩展模型大小，并通过使用不同的链数量提供多个不同大小的子模型进行弹性推理。</p>
<p class='zh-text'>6. 基于这一原则，作者设计了Chain-of-Language-Model (CoLM)，并进一步引入了KV共享机制的CoLM-Air，以实现更多的扩展功能。</p>
<p class='zh-text'>7. 实验结果表明，CoLM系列模型在性能上与标准Transformer相当，同时提供了更大的灵活性。</p></div>
                <div class="pinyin">
                    <p>1. Zhè piān wénzhāng tíchū le yīzhǒng xīn de xuéxí fànshì, chēngwéi Chain-of-Model (CoM)</p>
<p>2.  Tā jiāng yīnguǒ guānxì yǐnrù měi céng de yǐncáng zhuàngtài, xíngchéng liànshì jiégòu, tīgāo le móxíng xùnliàn de kuòzhǎn xiàolǜ hé bùshǔ de línghuóxìng</p>
<p>3.  Zuòzhě yǐnrù le Chain-of-Representation (CoR) de gàiniàn, jiāng měi céng de yǐncáng zhuàngtài biǎoshì wéi duōgè zǐ biǎoshì (jiē liàn) de zǔhé</p>
<p>4.  Měi céng zhōng, měi gè liàn zhǐnéng chá kàn shūrù biǎoshì zhōng de suǒyǒu qiánxù liàn</p>
<p>5.  Yīncǐ, jīyú CoM kuàngjià de móxíng kěyǐ tōngguò zēngjiā liàn lái zhúbù kuòzhǎn móxíng dàxìng, bìng tōngguò shǐyòng bùtóng de liàn shùliàng tígōng duōgè bùtóng dàxìng de zǐ móxíng jìnxíng tánxìng tuīlǐ</p>
<p>6.  Jīyú zhè yī yuánzé, zuòzhě shèjì le Chain-of-Language-Model (CoLM), bìng jìn yībù yǐnrù le KV gòngxiǎng jīzhì de CoLM-Air, yǐ shíxiàn gèng duō de kuòzhǎn gōngnéng</p>
<p>7.  Shíyàn jiéguǒ biǎomíng, CoLM xìliè móxíng zài xìngnéng shàng yǔ biāozhǔn Transformer xiāngdāng, tóngshí tígōng le gèng dà de línghuóxìng</p>
                </div>
                <div><p>1. This article proposes a new learning paradigm called Chain-of-Model (CoM).</p>
<p>2.  It introduces causality into the hidden states of each layer, forming a chain-like structure that enhances the scalability of model training and the flexibility of deployment.</p>
<p>3.  The authors introduce the concept of Chain-of-Representation (CoR), representing the hidden states of each layer as a combination of multiple sub-representations (i.</p>
<p>4. e.</p>
<p>5. , chains).</p>
<p>6.  Within each layer, each chain can only view all preceding chains in the input representation.</p>
<p>7.  Therefore, models based on the CoM framework can incrementally scale the model size by adding chains and provide multiple sub-models of different sizes for elastic inference by using different numbers of chains.</p>
<p>8.  Based on this principle, the authors designed Chain-of-Language-Model (CoLM) and further introduced CoLM-Air with a KV sharing mechanism to achieve more scalable functionalities.</p>
<p>9.  Experimental results show that the CoLM series models perform comparably to standard Transformers while offering greater flexibility.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">范式</td>
                            <td>fàn shì</td>
                            <td>paradigm</td>
                        </tr>
            
                        <tr>
                            <td class="zh">Chain-of-Model</td>
                            <td>Chèin-òf-Módel</td>
                            <td>Chain-of-Model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">因果关系</td>
                            <td>yīn guǒ guān xì</td>
                            <td>causal relationship</td>
                        </tr>
            
                        <tr>
                            <td class="zh">隐藏状态</td>
                            <td>yǐn cáng zhuàng tài</td>
                            <td>hidden state</td>
                        </tr>
            
                        <tr>
                            <td class="zh">链式结构</td>
                            <td>liàn shì jiégòu</td>
                            <td>chain structure</td>
                        </tr>
            
                        <tr>
                            <td class="zh">扩展效率</td>
                            <td>kuò zhǎn xiào lǜ</td>
                            <td>scalability</td>
                        </tr>
            
                        <tr>
                            <td class="zh">部署</td>
                            <td>bù shǔ</td>
                            <td>deployment</td>
                        </tr>
            
                        <tr>
                            <td class="zh">灵活性</td>
                            <td>líng huó xìng</td>
                            <td>flexibility</td>
                        </tr>
            
                        <tr>
                            <td class="zh">Chain-of-Representation</td>
                            <td>Chèin-òf-Rěprizen téi shēn</td>
                            <td>Chain-of-Representation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">子表示</td>
                            <td>zǐ biǎo shì</td>
                            <td>sub-representation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">组合</td>
                            <td>zǔ hé</td>
                            <td>combination</td>
                        </tr>
            
                        <tr>
                            <td class="zh">前序链</td>
                            <td>qián xù liàn</td>
                            <td>preceding chain</td>
                        </tr>
            
                        <tr>
                            <td class="zh">弹性推理</td>
                            <td>tán xìng tuī lǐ</td>
                            <td>elastic inference</td>
                        </tr>
            
                        <tr>
                            <td class="zh">Chain-of-Language-Model</td>
                            <td>Chèin-òf-Lánggù Módel</td>
                            <td>Chain-of-Language-Model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">KV共享机制</td>
                            <td>KV gòng xiǎng jī zhì</td>
                            <td>KV sharing mechanism</td>
                        </tr>
            
                        <tr>
                            <td class="zh">CoLM-Air</td>
                            <td>CoLM-Éir</td>
                            <td>CoLM-Air</td>
                        </tr>
            
                        <tr>
                            <td class="zh">扩展功能</td>
                            <td>kuò zhǎn gōng néng</td>
                            <td>extended functionality</td>
                        </tr>
            
                        <tr>
                            <td class="zh">Transformer</td>
                            <td>Tèinshèin fōměi</td>
                            <td>Transformer</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        