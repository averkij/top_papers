{
    "date": {
        "ru": "12 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
        "en": "February 12",
        "zh": "2æœˆ12æ—¥"
    },
    "time_utc": "2026-02-12 04:17",
    "weekday": 3,
    "issue_id": 1017,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2602.10604",
            "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters",
            "url": "https://huggingface.co/papers/2602.10604",
            "abstract": "Step 3.5 Flash is a sparse Mixture-of-Experts model that achieves frontier-level agentic intelligence through efficient parameter utilization and optimized attention mechanisms, demonstrating strong performance across multiple benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.",
            "score": 57,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "4a737b220dcc18cc",
            "authors": [
                "Ailin Huang",
                "Ang Li",
                "Aobo Kong",
                "Bin Wang",
                "Binxing Jiao",
                "Bo Dong",
                "Bojun Wang",
                "Boyu Chen",
                "Brian Li",
                "Buyun Ma",
                "Chang Su",
                "Changxin Miao",
                "Changyi Wan",
                "Chao Lou",
                "Chen Hu",
                "Chen Xu",
                "Chenfeng Yu",
                "Chengting Feng",
                "Chengyuan Yao",
                "Chunrui Han",
                "Dan Ma",
                "Dapeng Shi",
                "Daxin Jiang",
                "Dehua Ma",
                "Deshan Sun",
                "Di Qi",
                "Enle Liu",
                "Fajie Zhang",
                "Fanqi Wan",
                "Guanzhe Huang",
                "Gulin Yan",
                "Guoliang Cao",
                "Guopeng Li",
                "Han Cheng",
                "Hangyu Guo",
                "Hanshan Zhang",
                "Hao Nie",
                "Haonan Jia",
                "Haoran Lv",
                "Hebin Zhou",
                "Hekun Lv",
                "Heng Wang",
                "Heung-Yeung Shum",
                "Hongbo Huang",
                "Hongbo Peng",
                "Hongyu Zhou",
                "Hongyuan Wang",
                "Houyong Chen",
                "Huangxi Zhu",
                "Huimin Wu",
                "Huiyong Guo",
                "Jia Wang",
                "Jian Zhou",
                "Jianjian Sun",
                "Jiaoren Wu",
                "Jiaran Zhang",
                "Jiashu Lv",
                "Jiashuo Liu",
                "Jiayi Fu",
                "Jiayu Liu",
                "Jie Cheng",
                "Jie Luo",
                "Jie Yang",
                "Jie Zhou",
                "Jieyi Hou",
                "Jing Bai",
                "Jingcheng Hu",
                "Jingjing Xie",
                "Jingwei Wu",
                "Jingyang Zhang",
                "Jishi Zhou",
                "Junfeng Liu",
                "Junzhe Lin",
                "Ka Man Lo",
                "Kai Liang",
                "Kaibo Liu",
                "Kaijun Tan",
                "Kaiwen Yan",
                "Kaixiang Li",
                "Kang An",
                "Kangheng Lin",
                "Lei Yang",
                "Liang Lv",
                "Liang Zhao",
                "Liangyu Chen",
                "Lieyu Shi",
                "Liguo Tan",
                "Lin Lin",
                "Lina Chen",
                "Luck Ma",
                "Mengqiang Ren",
                "Michael Li",
                "Ming Li",
                "Mingliang Li",
                "Mingming Zhang",
                "Mingrui Chen",
                "Mitt Huang",
                "Na Wang",
                "Peng Liu",
                "Qi Han",
                "Qian Zhao",
                "Qinglin He",
                "Qinxin Du",
                "Qiuping Wu",
                "Quan Sun",
                "Rongqiu Yang",
                "Ruihang Miao",
                "Ruixin Han",
                "Ruosi Wan",
                "Ruyan Guo",
                "Shan Wang",
                "Shaoliang Pang",
                "Shaowen Yang",
                "Shengjie Fan",
                "Shijie Shang",
                "Shiliang Yang",
                "Shiwei Li",
                "Shuangshuang Tian",
                "Siqi Liu",
                "Siye Wu",
                "Siyu Chen",
                "Song Yuan",
                "Tiancheng Cao",
                "Tianchi Yue",
                "Tianhao Cheng",
                "Tianning Li",
                "Tingdan Luo",
                "Wang You",
                "Wei Ji",
                "Wei Yuan",
                "Wei Zhang",
                "Weibo Wu",
                "Weihao Xie",
                "Wen Sun",
                "Wenjin Deng",
                "Wenzhen Zheng",
                "Wuxun Xie",
                "Xiangfeng Wang",
                "Xiangwen Kong",
                "Xiangyu Liu",
                "Xiangyu Zhang",
                "Xiaobo Yang",
                "Xiaojia Liu",
                "Xiaolan Yuan",
                "Xiaoran Jiao",
                "Xiaoxiao Ren",
                "Xiaoyun Zhang",
                "Xin Li",
                "Xin Liu",
                "Xin Wu",
                "Xing Chen",
                "Xingping Yang",
                "Xinran Wang",
                "Xu Zhao",
                "Xuan He",
                "Xuanti Feng",
                "Xuedan Cai",
                "Xuqiang Zhou",
                "Yanbo Yu",
                "Yang Li",
                "Yang Xu",
                "Yanlin Lai",
                "Yanming Xu",
                "Yaoyu Wang",
                "Yeqing Shen",
                "Yibo Zhu",
                "Yichen Lv",
                "Yicheng Cao",
                "Yifeng Gong",
                "Yijing Yang",
                "Yikun Yang",
                "Yin Zhao",
                "Yingxiu Zhao",
                "Yinmin Zhang",
                "Yitong Zhang",
                "Yixuan Zhang",
                "Yiyang Chen",
                "Yongchi Zhao",
                "Yongshen Long",
                "Yongyao Wang",
                "Yousong Guan",
                "Yu Zhou",
                "Yuang Peng",
                "Yuanhao Ding",
                "Yuantao Fan",
                "Yuanzhen Yang",
                "Yuchu Luo",
                "Yudi Zhao",
                "Yue Peng",
                "Yueqiang Lin",
                "Yufan Lu",
                "Yuling Zhao",
                "Yunzhou Ju",
                "Yurong Zhang",
                "Yusheng Li",
                "Yuxiang Yang",
                "Yuyang Chen",
                "Yuzhu Cai",
                "Zejia Weng",
                "Zetao Hong",
                "Zexi Li",
                "Zhe Xie",
                "Zheng Ge",
                "Zheng Gong",
                "Zheng Zeng",
                "Zhenyi Lu",
                "Zhewei Huang",
                "Zhichao Chang",
                "Zhiguo Huang",
                "Zhiheng Hu",
                "Zidong Yang",
                "Zili Wang",
                "Ziqi Ren",
                "Zixin Zhang",
                "Zixuan Wang"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2602.10604.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#agents",
                    "#benchmark",
                    "#inference",
                    "#rl"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸: Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ˜Ğ˜ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ¹ ÑĞ¼ĞµÑĞ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Step 3.5 Flash, Ğ¾Ñ‚Ğ½Ğ¾ÑÑÑ‰Ğ°ÑÑÑ Ğº Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Mixture-of-Experts, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 11 Ğ¼Ğ»Ñ€Ğ´ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸Ğ· 196 Ğ¼Ğ»Ñ€Ğ´ Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾ Ñ‡Ğ¸ÑĞ»Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ². ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ° Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ (ÑĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞµ Ğ¾ĞºĞ½Ğ¾ Ñ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ¼ 3:1 Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ) Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ‚Ğ¾ĞºĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞµĞº Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ€Ğ°ÑƒĞ½Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ¼. Ğ”Ğ»Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ñ„Ñ€Ğ¾Ğ½Ñ‚Ğ¸Ñ€Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸ Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑÑ… Ğ¸ Ğ¾ÑÑ‚Ğ°Ñ‘Ñ‚ÑÑ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¿Ñ€Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ²ÑĞµÑ… ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ°Ñ…: 85.4% Ğ½Ğ° IMO-AnswerBench, 86.4% Ğ½Ğ° LiveCodeBench, 88.2% Ğ½Ğ° tau2-Bench Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸, ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼Ñ‹Ğµ Ñ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ½Ğ° Ñ€Ñ‹Ğ½ĞºĞµ."
                },
                "en": {
                    "title": "Efficient Intelligence with Step 3.5 Flash",
                    "desc": "Step 3.5 Flash is a sparse Mixture-of-Experts (MoE) model that enhances agentic intelligence while optimizing computational efficiency. It utilizes a large foundation of 196 billion parameters but activates only 11 billion during inference, allowing for faster processing. The model employs advanced techniques like interleaved attention and Multi-Token Prediction to minimize latency in multi-round interactions. With a robust reinforcement learning framework, it achieves impressive performance across various tasks, making it a strong contender among leading AI models."
                },
                "zh": {
                    "title": "é«˜æ•ˆæ™ºèƒ½çš„ç¨€ç–ä¸“å®¶æ¨¡å‹",
                    "desc": "Step 3.5 Flash æ˜¯ä¸€ç§ç¨€ç–çš„ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆMixture-of-Expertsï¼‰ï¼Œé€šè¿‡é«˜æ•ˆçš„å‚æ•°åˆ©ç”¨å’Œä¼˜åŒ–çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°äº†å‰æ²¿æ°´å¹³çš„æ™ºèƒ½è¡¨ç°ã€‚è¯¥æ¨¡å‹ç»“åˆäº†1960äº¿å‚æ•°çš„åŸºç¡€å’Œ110äº¿æ´»è·ƒå‚æ•°ï¼Œä»¥æé«˜æ¨ç†æ•ˆç‡ã€‚å®ƒé‡‡ç”¨äº†äº¤é”™çš„3:1æ»‘åŠ¨çª—å£/å…¨æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šæ ‡è®°é¢„æµ‹ï¼ˆMTP-3ï¼‰ï¼Œé™ä½äº†å¤šè½®äº¤äº’çš„å»¶è¿Ÿå’Œæˆæœ¬ã€‚é€šè¿‡å¯éªŒè¯ä¿¡å·ä¸åå¥½åé¦ˆç›¸ç»“åˆçš„å¯æ‰©å±•å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ŒStep 3.5 Flash åœ¨æ•°å­¦ã€ç¼–ç å’Œå·¥å…·ä½¿ç”¨ç­‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå±•ç°äº†ä¸å‰æ²¿æ¨¡å‹ç›¸åª²ç¾çš„èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10177",
            "title": "Towards Autonomous Mathematics Research",
            "url": "https://huggingface.co/papers/2602.10177",
            "abstract": "Aletheia, a math research agent, demonstrates advanced reasoning capabilities by generating and verifying solutions end-to-end in natural language, achieving autonomous research outcomes from Olympiad problems to PhD-level exercises and contributing to AI-assisted mathematical research.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research. We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom's Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest codifying standard levels quantifying autonomy and novelty of AI-assisted results. We conclude with reflections on human-AI collaboration in mathematics.",
            "score": 10,
            "issue_id": 1017,
            "pub_date": "2026-02-10",
            "pub_date_card": {
                "ru": "10 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 10",
                "zh": "2æœˆ10æ—¥"
            },
            "hash": "576d66277cc83830",
            "authors": [
                "Tony Feng",
                "Trieu H. Trinh",
                "Garrett Bingham",
                "Dawsen Hwang",
                "Yuri Chervonyi",
                "Junehyuk Jung",
                "Joonkyung Lee",
                "Carlo Pagano",
                "Sang-hyun Kim",
                "Federico Pasqualotto",
                "Sergei Gukov",
                "Jonathan N. Lee",
                "Junsu Kim",
                "Kaiying Hou",
                "Golnaz Ghiasi",
                "Yi Tay",
                "YaGuang Li",
                "Chenkai Kuang",
                "Yuan Liu",
                "Hanzhao",
                "Lin",
                "Evan Zheran Liu",
                "Nigamaa Nayakanti",
                "Xiaomeng Yang",
                "Heng-tze Cheng",
                "Demis Hassabis",
                "Koray Kavukcuoglu",
                "Quoc V. Le",
                "Thang Luong"
            ],
            "affiliations": [
                "Google DeepMind"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10177.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#training",
                    "#reasoning",
                    "#agents",
                    "#math",
                    "#open_source"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "ĞÑ‚ Ğ¾Ğ»Ğ¸Ğ¼Ğ¿Ğ¸Ğ°Ğ´ Ğº Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ğ¼ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸ÑĞ¼: AI-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹",
                    "desc": "Aletheia â€” ÑÑ‚Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚ÑƒÑ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚, Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ Ğ¿ĞµÑ€ĞµÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ° ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ñ‹ÑˆĞµ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ¾Ğ»Ğ¸Ğ¼Ğ¿Ğ¸Ğ°Ğ´. ĞĞ³ĞµĞ½Ñ‚ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¾Ñ‚ Ğ¾Ğ»Ğ¸Ğ¼Ğ¿Ğ¸Ğ°Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ´Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ´Ğ¾ĞºÑ‚Ğ¾Ñ€ÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ°Ñ€Ğ¸Ñ„Ğ¼ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ğ¸ ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ñ AI Ğ² Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·. Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ½Ğ¾Ğ²Ğ¸Ğ·Ğ½Ñ‹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ², Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ AI Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ."
                },
                "en": {
                    "title": "Aletheia: Revolutionizing Math Research with AI Autonomy",
                    "desc": "Aletheia is a math research agent that showcases advanced reasoning abilities by autonomously generating and verifying mathematical solutions in natural language. It utilizes an enhanced version of Gemini Deep Think to tackle complex problems, extending its capabilities from Olympiad-level challenges to professional research tasks. The agent has successfully produced research papers independently and in collaboration with humans, demonstrating its effectiveness in navigating mathematical literature and solving open problems. This work emphasizes the importance of defining standards for measuring the autonomy and novelty of AI-generated mathematical results."
                },
                "zh": {
                    "title": "Aletheiaï¼šæ•°å­¦ç ”ç©¶çš„æ™ºèƒ½åŠ©æ‰‹",
                    "desc": "Aletheia æ˜¯ä¸€ä¸ªæ•°å­¦ç ”ç©¶ä»£ç†ï¼Œèƒ½å¤Ÿåœ¨è‡ªç„¶è¯­è¨€ä¸­ç”Ÿæˆã€éªŒè¯å’Œä¿®è®¢è§£å†³æ–¹æ¡ˆï¼Œå±•ç°å‡ºå…ˆè¿›çš„æ¨ç†èƒ½åŠ›ã€‚å®ƒä½¿ç”¨äº†ä¸€ç§æ”¹è¿›ç‰ˆçš„ Gemini Deep Thinkï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ¨ç†é—®é¢˜ï¼Œå¹¶é€šè¿‡å·¥å…·ä½¿ç”¨æ¥åº”å¯¹æ•°å­¦ç ”ç©¶çš„å¤æ‚æ€§ã€‚Aletheia ä»å¥¥æ—åŒ¹å…‹é—®é¢˜åˆ°åšå£«çº§ç»ƒä¹ ï¼Œå±•ç¤ºäº†å…¶åœ¨ AI è¾…åŠ©æ•°å­¦ç ”ç©¶ä¸­çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬ç”Ÿæˆæ— äººå·¥å¹²é¢„çš„ç ”ç©¶è®ºæ–‡å’Œäººæœºåä½œçš„è¯æ˜ã€‚æˆ‘ä»¬å»ºè®®å¯¹ AI è¾…åŠ©ç»“æœçš„è‡ªä¸»æ€§å’Œæ–°é¢–æ€§è¿›è¡Œæ ‡å‡†åŒ–é‡åŒ–ï¼Œä»¥å¸®åŠ©å…¬ä¼—æ›´å¥½åœ°ç†è§£ AI å’Œæ•°å­¦çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10224",
            "title": "Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models",
            "url": "https://huggingface.co/papers/2602.10224",
            "abstract": "Meta-Experience Learning enhances LLM reasoning by incorporating self-distilled error representations into parametric memory through contrastive trajectory analysis and language-modeled reward signals.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach for enhancing the reasoning capabilities of Large Language Models (LLMs). Despite its efficacy, RLVR faces a meta-learning bottleneck: it lacks mechanisms for error attribution and experience internalization intrinsic to the human learning cycle beyond practice and verification, thereby limiting fine-grained credit assignment and reusable knowledge formation. We term such reusable knowledge representations derived from past errors as meta-experience. Based on this insight, we propose Meta-Experience Learning (MEL), a novel framework that incorporates self-distilled meta-experience into the model's parametric memory. Building upon standard RLVR, we introduce an additional design that leverages the LLM's self-verification capability to conduct contrastive analysis on paired correct and incorrect trajectories, identify the precise bifurcation points where reasoning errors arise, and summarize them into generalizable meta-experience. The meta-experience is further internalized into the LLM's parametric memory by minimizing the negative log-likelihood, which induces a language-modeled reward signal that bridges correct and incorrect reasoning trajectories and facilitates effective knowledge reuse. Experimental results demonstrate that MEL achieves consistent improvements on benchmarks, yielding 3.92%--4.73% Pass@1 gains across varying model sizes.",
            "score": 8,
            "issue_id": 1017,
            "pub_date": "2026-02-10",
            "pub_date_card": {
                "ru": "10 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 10",
                "zh": "2æœˆ10æ—¥"
            },
            "hash": "e9eb1cf90cc7d4ea",
            "authors": [
                "Shiting Huang",
                "Zecheng Li",
                "Yu Zeng",
                "Qingnan Ren",
                "Zhen Fang",
                "Qisheng Su",
                "Kou Shi",
                "Lin Chen",
                "Zehui Chen",
                "Feng Zhao"
            ],
            "affiliations": [
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10224.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ…: Ğ²ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
                    "desc": "Meta-Experience Learning â€” ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. ĞœĞµÑ‚Ğ¾Ğ´ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¼ĞµÑÑ‚Ğ°, Ğ³Ğ´Ğµ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸. ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ± Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ… (Ğ¼ĞµÑ‚Ğ°-Ğ¾Ğ¿Ñ‹Ñ‚) Ğ²ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ Ğ½ĞµĞ¿Ğ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñ‹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´Ğ°ĞµÑ‚ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ° 3.92%-4.73% Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Enhancing LLM Reasoning with Meta-Experience Learning",
                    "desc": "Meta-Experience Learning (MEL) is a new framework designed to improve the reasoning abilities of Large Language Models (LLMs) by integrating self-distilled error representations into their memory. It addresses the limitations of Reinforcement Learning with Verifiable Rewards (RLVR) by enabling fine-grained credit assignment and the formation of reusable knowledge from past mistakes. MEL uses contrastive trajectory analysis to pinpoint where reasoning errors occur and summarizes these insights into generalizable meta-experience. This approach not only enhances the model's learning process but also leads to significant performance improvements on various benchmarks."
                },
                "zh": {
                    "title": "å…ƒç»éªŒå­¦ä¹ ï¼šæå‡LLMæ¨ç†èƒ½åŠ›çš„æ–°æ–¹æ³•",
                    "desc": "Meta-Experience Learningï¼ˆMELï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡å°†è‡ªæˆ‘æç‚¼çš„å…ƒç»éªŒèå…¥æ¨¡å‹çš„å‚æ•°è®°å¿†ä¸­ï¼Œå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¯¹æ¯”è½¨è¿¹åˆ†æï¼Œè¯†åˆ«æ¨ç†é”™è¯¯çš„å…³é”®åˆ†å‰ç‚¹ï¼Œå¹¶å°†è¿™äº›é”™è¯¯æ€»ç»“ä¸ºå¯é‡ç”¨çš„å…ƒç»éªŒã€‚é€šè¿‡æœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ŒMELå°†å…ƒç»éªŒå†…åŒ–åˆ°LLMçš„å‚æ•°è®°å¿†ä¸­ï¼Œä»è€Œä¿ƒè¿›çŸ¥è¯†çš„æœ‰æ•ˆé‡ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMELåœ¨åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†3.92%åˆ°4.73%çš„Pass@1æå‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ä¸Šçš„ä¸€è‡´æ€§æ”¹è¿›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.09713",
            "title": "Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models",
            "url": "https://huggingface.co/papers/2602.09713",
            "abstract": "Stroke3D generates rigged 3D meshes from 2D strokes and text prompts through a two-stage pipeline combining controllable skeleton generation with enhanced mesh synthesis.  \t\t\t\t\tAI-generated summary \t\t\t\t Rigged 3D assets are fundamental to 3D deformation and animation. However, existing 3D generation methods face challenges in generating animatable geometry, while rigging techniques lack fine-grained structural control over skeleton creation. To address these limitations, we introduce Stroke3D, a novel framework that directly generates rigged meshes from user inputs: 2D drawn strokes and a descriptive text prompt. Our approach pioneers a two-stage pipeline that separates the generation into: 1) Controllable Skeleton Generation, we employ the Skeletal Graph VAE (Sk-VAE) to encode the skeleton's graph structure into a latent space, where the Skeletal Graph DiT (Sk-DiT) generates a skeletal embedding. The generation process is conditioned on both the text for semantics and the 2D strokes for explicit structural control, with the VAE's decoder reconstructing the final high-quality 3D skeleton; and 2) Enhanced Mesh Synthesis via TextuRig and SKA-DPO, where we then synthesize a textured mesh conditioned on the generated skeleton. For this stage, we first enhance an existing skeleton-to-mesh model by augmenting its training data with TextuRig: a dataset of textured and rigged meshes with captions, curated from Objaverse-XL. Additionally, we employ a preference optimization strategy, SKA-DPO, guided by a skeleton-mesh alignment score, to further improve geometric fidelity. Together, our framework enables a more intuitive workflow for creating ready to animate 3D content. To the best of our knowledge, our work is the first to generate rigged 3D meshes conditioned on user-drawn 2D strokes. Extensive experiments demonstrate that Stroke3D produces plausible skeletons and high-quality meshes.",
            "score": 7,
            "issue_id": 1017,
            "pub_date": "2026-02-10",
            "pub_date_card": {
                "ru": "10 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 10",
                "zh": "2æœˆ10æ—¥"
            },
            "hash": "88480aeee4c64487",
            "authors": [
                "Ruisi Zhao",
                "Haoren Zheng",
                "Zongxin Yang",
                "Hehe Fan",
                "Yi Yang"
            ],
            "affiliations": [
                "DBMI, HMS, Harvard University",
                "ReLER, CCAI, Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.09713.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "ĞÑ‚ ÑˆÑ‚Ñ€Ğ¸Ñ…Ğ° Ğº Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ¸Ğ³Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Stroke3D â€” ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ¸Ğ³Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… 3D-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ· Ğ´Ğ²ÑƒĞ¼ĞµÑ€Ğ½Ñ‹Ñ… Ñ€Ğ¸ÑÑƒĞ½ĞºĞ¾Ğ² Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ pipeline. ĞĞ° Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ğ²Ñ‚Ğ¾ĞºĞ¾Ğ´ĞµÑ€ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ ÑĞºĞµĞ»ĞµÑ‚Ğ° (Sk-VAE) Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€ (Sk-DiT) Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ ÑĞºĞµĞ»ĞµÑ‚Ğ°, Ğ¾Ğ±ÑƒÑĞ»Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ¸ 2D-ÑˆÑ‚Ñ€Ğ¸Ñ…Ğ°Ğ¼Ğ¸. ĞĞ° Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ĞºĞ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ TextuRig Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ SKA-DPO Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğº Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ 3D-Ğ°ÑÑĞµÑ‚Ñ‹ Ğ¸Ğ½Ñ‚ÑƒĞ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ¼, Ğ²Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ¸Ğ³Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ñ€Ğ¸ÑÑƒĞ½ĞºĞ¾Ğ²."
                },
                "en": {
                    "title": "From 2D Strokes to Rigged 3D Meshes: Stroke3D Revolutionizes Animation Creation!",
                    "desc": "Stroke3D is a novel framework that generates rigged 3D meshes from 2D strokes and text prompts using a two-stage pipeline. The first stage involves Controllable Skeleton Generation, where a Skeletal Graph VAE encodes the skeleton's structure, allowing for fine control over its creation. The second stage focuses on Enhanced Mesh Synthesis, which produces a textured mesh based on the generated skeleton, utilizing a dataset of rigged meshes and a preference optimization strategy for improved quality. This approach simplifies the process of creating animatable 3D assets, making it more intuitive for users."
                },
                "zh": {
                    "title": "Stroke3Dï¼šä»2Dçº¿æ¡ç”Ÿæˆå¯åŠ¨ç”»çš„3Dç½‘æ ¼",
                    "desc": "Stroke3D æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡ç”¨æˆ·è¾“å…¥çš„ 2D çº¿æ¡å’Œæ–‡æœ¬æç¤ºç›´æ¥ç”Ÿæˆå¸¦éª¨æ¶çš„ 3D ç½‘æ ¼ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µçš„æµç¨‹ï¼Œé¦–å…ˆç”Ÿæˆå¯æ§çš„éª¨æ¶ï¼Œç„¶ååˆæˆé«˜è´¨é‡çš„ç½‘æ ¼ã€‚æˆ‘ä»¬ä½¿ç”¨äº†éª¨æ¶å›¾å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆSk-VAEï¼‰æ¥ç¼–ç éª¨æ¶çš„å›¾ç»“æ„ï¼Œå¹¶é€šè¿‡æ–‡æœ¬å’Œ 2D çº¿æ¡è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚æœ€ç»ˆï¼Œç»“åˆå¢å¼ºçš„ç½‘æ ¼åˆæˆæŠ€æœ¯ï¼ŒStroke3D æä¾›äº†ä¸€ç§æ›´ç›´è§‚çš„å·¥ä½œæµç¨‹ï¼Œä¾¿äºåˆ›å»ºå¯åŠ¨ç”»çš„ 3D å†…å®¹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.08253",
            "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
            "url": "https://huggingface.co/papers/2602.08253",
            "abstract": "A generative evolutionary framework extends large language models for automated design of large neighborhood search operators in combinatorial optimization problems.  \t\t\t\t\tAI-generated summary \t\t\t\t While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.",
            "score": 7,
            "issue_id": 1017,
            "pub_date": "2026-02-09",
            "pub_date_card": {
                "ru": "9 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 9",
                "zh": "2æœˆ9æ—¥"
            },
            "hash": "034646ca5ddc25d4",
            "authors": [
                "Baoyun Zhao",
                "He Wang",
                "Liang Zeng"
            ],
            "affiliations": [
                "International Centre for Theoretical Physics Asia-Pacific, University of Chinese Academy of Sciences",
                "Software College, Northeastern University",
                "Taiji Laboratory for Gravitational Wave Universe, University of Chinese Academy of Sciences",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.08253.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "Ğ­Ğ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¾ĞºÑ€ĞµÑÑ‚Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ G-LNS, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ğ¾ĞºÑ€ĞµÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ (Large Neighborhood Search) Ğ¿Ñ€Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ², Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ¼Ğ¸ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸Ğº, Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ñ‹ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ñ€Ğ°Ğ·Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. ĞœĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ ĞºĞ¾Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ²Ğ½Ğ¾ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸, Ñ‡Ñ‚Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‰ĞµĞ¹ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ĞºĞ¾Ğ¼Ğ¼Ğ¸Ğ²Ğ¾ÑĞ¶ĞµÑ€Ğ° Ğ¸ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ½Ğ°Ğ´ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ LLM-Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ñ€ĞµÑˆĞ°Ñ‚ĞµĞ»ÑĞ¼Ğ¸."
                },
                "en": {
                    "title": "Revolutionizing Heuristic Design with G-LNS",
                    "desc": "This paper introduces G-LNS, a generative evolutionary framework that enhances large language models (LLMs) for creating Large Neighborhood Search (LNS) operators in combinatorial optimization problems. Unlike traditional methods that limit heuristic design to fixed forms, G-LNS allows for the co-evolution of destroy and repair operators, improving the exploration of the solution space. The framework employs a cooperative evaluation mechanism to optimize the interaction between these operators, leading to better structural disruption and reconstruction. Experimental results show that G-LNS outperforms existing LLM-based methods and classical solvers, achieving near-optimal solutions efficiently across various problem instances."
                },
                "zh": {
                    "title": "ç”Ÿæˆè¿›åŒ–æ¡†æ¶ï¼šä¼˜åŒ–ç»„åˆé—®é¢˜çš„æ–°æ–¹æ³•",
                    "desc": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§ç”Ÿæˆè¿›åŒ–æ¡†æ¶G-LNSï¼Œç”¨äºè‡ªåŠ¨è®¾è®¡å¤§é‚»åŸŸæœç´¢ï¼ˆLNSï¼‰ç®—å­ï¼Œä»¥è§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒG-LNSåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…±åŒè¿›åŒ–ç ´åå’Œä¿®å¤ç®—å­ï¼Œå¢å¼ºäº†æœç´¢ç©ºé—´çš„æ¢ç´¢èƒ½åŠ›ã€‚é€šè¿‡åˆä½œè¯„ä¼°æœºåˆ¶ï¼ŒG-LNSèƒ½å¤Ÿæ•æ‰ç®—å­ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œä»è€Œå‘ç°æœ‰æ•ˆçš„äº’è¡¥é€»è¾‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒG-LNSåœ¨è§£å†³æ—…è¡Œå•†é—®é¢˜å’Œå®¹é‡è½¦è¾†è·¯å¾„é—®é¢˜ç­‰å¤æ‚ç»„åˆä¼˜åŒ–åŸºå‡†ä¸Šï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„LLMåŸºç¡€è‡ªåŠ¨å¯å‘å¼è®¾è®¡æ–¹æ³•å’Œç»å…¸æ±‚è§£å™¨ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10999",
            "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
            "url": "https://huggingface.co/papers/2602.10999",
            "abstract": "CLI-Gym enables scalable derivation of environment-intensive tasks by simulating and exploring environment histories, while LiberCoder achieves significant performance improvements on Terminal-Bench through fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.",
            "score": 6,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "c72eb824352bcaac",
            "authors": [
                "Yusong Lin",
                "Haiyang Wang",
                "Shuzhe Wu",
                "Lue Fan",
                "Feiyang Pan",
                "Sanyuan Zhao",
                "Dandan Tu"
            ],
            "affiliations": [
                "Beijing Institute of Technology",
                "Huawei Technologies Co., Ltd",
                "Institute of Automation, Chinese Academy of Sciences"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10999.jpg",
            "data": {
                "categories": [],
                "emoji": "âš™ï¸",
                "ru": {
                    "title": "Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ CLI-Gym, ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¾Ğ¹, Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ Ñ Dockerfile Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡: Ğ¾Ğ½Ğ¸ Ğ±ĞµÑ€ÑƒÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ, Ğ¸Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒÑÑ‚ ĞµÑ‘ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ Ñ€Ğ°Ğ½Ğ½ĞµĞµ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼Ğ¸, Ğ¸ Ñ‚Ğ°ĞºĞ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ÑÑ‚ Ğ¿Ğ°Ñ€Ñ‹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°-Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ° ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ Ğ¸Ğ· 1,655 Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ LiberCoder Ğ¿ÑƒÑ‚ĞµĞ¼ fine-tuning Ğ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸ÑÑ…. ĞœĞ¾Ğ´ĞµĞ»ÑŒ LiberCoder Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ (+21.1%) Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ Terminal-Bench, ÑÑ‚Ğ°Ğ² Ğ½Ğ¾Ğ²Ñ‹Ğ¼ state-of-the-art Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸ĞµĞ¼."
                },
                "en": {
                    "title": "Revolutionizing Task Generation for Agentic Coding with CLI-Gym and LiberCoder",
                    "desc": "This paper introduces CLI-Gym, a novel approach for generating a large set of environment-intensive tasks by simulating and exploring historical environments. It leverages execution feedback to trace back to earlier states of a system that encountered runtime failures, allowing for the creation of tasks based on these buggy states and their associated error messages. Additionally, the paper presents LiberCoder, a fine-tuned model that significantly enhances performance on the Terminal-Bench benchmark by utilizing curated successful trajectories. This work represents a significant advancement in the scalable derivation of tasks that require interaction with command line interfaces, marking a first in the field."
                },
                "zh": {
                    "title": "å¤§è§„æ¨¡ç”Ÿæˆç¯å¢ƒå¯†é›†å‹ä»»åŠ¡çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºCLI-Gymçš„æ–¹æ³•ï¼Œç”¨äºå¤§è§„æ¨¡ç”Ÿæˆç¯å¢ƒå¯†é›†å‹ä»»åŠ¡ï¼Œä¸»è¦é€šè¿‡æ¨¡æ‹Ÿå’Œæ¢ç´¢ç¯å¢ƒå†å²æ¥å®ç°ã€‚æˆ‘ä»¬é€šè¿‡æ‰§è¡Œåé¦ˆå¼•å¯¼ä»£ç†ï¼Œè¿½è¸ªå¥åº·ç¯å¢ƒçš„å†å²çŠ¶æ€ï¼Œä»è€Œé€†è½¬åˆ°æ—©æœŸçš„è¿è¡Œå¤±è´¥çŠ¶æ€ï¼Œå¹¶ä»ä¸­æå–ä»»åŠ¡ã€‚æ­¤æ–¹æ³•ç”Ÿæˆäº†1,655ä¸ªç¯å¢ƒå¯†é›†å‹ä»»åŠ¡ï¼Œæˆä¸ºåŒç±»ä¸­æœ€å¤§çš„é›†åˆã€‚æ­¤å¤–ï¼Œç»è¿‡ç²¾ç»†è°ƒä¼˜çš„æ¨¡å‹LiberCoderåœ¨Terminal-Benchä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç»å¯¹æé«˜äº†21.1%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10560",
            "title": "When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning",
            "url": "https://huggingface.co/papers/2602.10560",
            "abstract": "GRU-Mem addresses long-context reasoning challenges in LLMs by incorporating text-controlled gates and reinforcement learning rewards to stabilize memory updates and improve computational efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t While reasoning over long context is crucial for various real-world applications, it remains challenging for large language models (LLMs) as they suffer from performance degradation as the context length grows. Recent work MemAgent has tried to tackle this by processing context chunk-by-chunk in an RNN-like loop and updating a textual memory for final answering. However, this naive recurrent memory update faces two crucial drawbacks: (i) memory can quickly explode because it can update indiscriminately, even on evidence-free chunks; and (ii) the loop lacks an exit mechanism, leading to unnecessary computation after even sufficient evidence is collected. To address these issues, we propose GRU-Mem, which incorporates two text-controlled gates for more stable and efficient long-context reasoning. Specifically, in GRU-Mem, the memory only updates when the update gate is open and the recurrent loop will exit immediately once the exit gate is open. To endow the model with such capabilities, we introduce two reward signals r^{update} and r^{exit} within end-to-end RL, rewarding the correct updating and exiting behaviors respectively. Experiments on various long-context reasoning tasks demonstrate the effectiveness and efficiency of GRU-Mem, which generally outperforms the vanilla MemAgent with up to 400\\% times inference speed acceleration.",
            "score": 5,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "766dce90e9fcaf33",
            "authors": [
                "Leheng Sheng",
                "Yongtao Zhang",
                "Wenchang Ma",
                "Yaorui Shi",
                "Ting Huang",
                "Xiang Wang",
                "An Zhang",
                "Ke Shen",
                "Tat-Seng Chua"
            ],
            "affiliations": [
                "ByteDance Seed",
                "National University of Singapore",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10560.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#reasoning",
                    "#long_context"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ñ‚Ğ²Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²",
                    "desc": "GRU-Mem Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ… Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆÑ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ·Ğ°Ñ‚Ğ²Ğ¾Ñ€Ñ‹, Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ°Ğ¼ Ğ² Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ´Ğ²Ğ° Ñ‚Ğ¸Ğ¿Ğ° Ğ·Ğ°Ñ‚Ğ²Ğ¾Ñ€Ğ¾Ğ²: update gate ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ… Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ° exit gate Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¸Ğ· Ñ†Ğ¸ĞºĞ»Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ±Ğ¾Ñ€Ğ° Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. Ğ”Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¸Ñ… Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ¾Ğ² Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ reinforcement learning Ñ Ğ´Ğ²ÑƒĞ¼Ñ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ°Ğ¼Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñ‹, Ğ¿Ğ¾Ğ¾Ñ‰Ñ€ÑÑÑ‰Ğ¸Ğ¼Ğ¸ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ´Ğ¾ 400% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ¼ MemAgent."
                },
                "en": {
                    "title": "Efficient Long-Context Reasoning with GRU-Mem",
                    "desc": "GRU-Mem is a novel approach designed to enhance long-context reasoning in large language models (LLMs) by using text-controlled gates and reinforcement learning. It addresses the limitations of previous methods, like MemAgent, which struggled with indiscriminate memory updates and lacked an efficient exit mechanism. By implementing an update gate and an exit gate, GRU-Mem ensures that memory updates occur only when necessary and allows the model to stop processing once sufficient evidence is gathered. Experimental results show that GRU-Mem significantly improves both the speed and accuracy of long-context reasoning tasks compared to traditional methods."
                },
                "zh": {
                    "title": "GRU-Memï¼šé«˜æ•ˆç¨³å®šçš„é•¿ä¸Šä¸‹æ–‡æ¨ç†",
                    "desc": "GRU-Memæ˜¯ä¸€ç§æ–°å‹çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚å®ƒé€šè¿‡å¼•å…¥æ–‡æœ¬æ§åˆ¶çš„é—¨æ§æœºåˆ¶å’Œå¼ºåŒ–å­¦ä¹ å¥–åŠ±ï¼Œæ¥ç¨³å®šå†…å­˜æ›´æ–°å¹¶æé«˜è®¡ç®—æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿçš„MemAgentç›¸æ¯”ï¼ŒGRU-Memåœ¨å†…å­˜æ›´æ–°æ—¶ä»…åœ¨æ›´æ–°é—¨å¼€å¯æ—¶è¿›è¡Œï¼Œå¹¶åœ¨é€€å‡ºé—¨å¼€å¯æ—¶ç«‹å³é€€å‡ºå¾ªç¯ï¼Œä»è€Œé¿å…äº†ä¸å¿…è¦çš„è®¡ç®—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGRU-Memåœ¨å¤šç§é•¿ä¸Šä¸‹æ–‡æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†400%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.11089",
            "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning",
            "url": "https://huggingface.co/papers/2602.11089",
            "abstract": "DataChef-32B automates data recipe generation for LLM adaptation through reinforcement learning with proxy rewards, achieving performance comparable to human-crafted recipes.  \t\t\t\t\tAI-generated summary \t\t\t\t In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the data recipe, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate end-to-end data recipe generation for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.",
            "score": 4,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "c18e7b1c9f3e8df4",
            "authors": [
                "Yicheng Chen",
                "Zerun Ma",
                "Xinchen Xie",
                "Yining Li",
                "Kai Chen"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.11089.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#data",
                    "#training",
                    "#optimization",
                    "#benchmark",
                    "#rl"
                ],
                "emoji": "ğŸ‘¨â€ğŸ³",
                "ru": {
                    "title": "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºÑƒĞ»Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ñ… Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ DataChef-32B â€” ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ñ… Ğ´Ğ»Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆÑ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒÑÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ ĞºĞ°Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ³Ğ´Ğµ Ğ¿Ñ€Ğ¾ĞºÑĞ¸-Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ° Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ñ‹Ğµ Ğ¿Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ñƒ Ñ Ñ€ĞµÑ†ĞµĞ¿Ñ‚Ğ°Ğ¼Ğ¸, Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°Ğ¼Ğ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½ÑƒÑ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ Qwen3-1.7B-Base Ğº Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼ Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ğ±Ğ°Ğ»Ğ»Ğ° Ğ½Ğ° AIME'25, Ñ‡Ñ‚Ğ¾ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ° Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM."
                },
                "en": {
                    "title": "Automating Data Recipes for LLMs with DataChef-32B",
                    "desc": "DataChef-32B is a system that automates the creation of data recipes for adapting Large Language Models (LLMs) using reinforcement learning. It generates a complete data processing pipeline that transforms raw data into training sets, aiming to reduce the manual effort typically required. By utilizing a proxy reward to predict the effectiveness of these recipes, DataChef-32B can produce high-quality recipes that perform similarly to those crafted by human experts. This innovation not only streamlines the training process for LLMs but also contributes to the development of self-evolving AI systems."
                },
                "zh": {
                    "title": "è‡ªåŠ¨åŒ–æ•°æ®é…æ–¹ç”Ÿæˆï¼Œæå‡LLMæ€§èƒ½",
                    "desc": "DataChef-32B æ˜¯ä¸€ç§é€šè¿‡å¼ºåŒ–å­¦ä¹ å’Œä»£ç†å¥–åŠ±è‡ªåŠ¨ç”Ÿæˆæ•°æ®é…æ–¹çš„æ–¹æ³•ï¼Œæ—¨åœ¨é€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿå°†åŸå§‹æ•°æ®æºè½¬åŒ–ä¸ºé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œå‡å°‘äººå·¥å¹²é¢„ã€‚é€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ŒDataChef-32B ç”Ÿæˆçš„é…æ–¹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¸äººç±»ä¸“å®¶ç›¸å½“çš„æ€§èƒ½ã€‚æ­¤ç ”ç©¶ä¸º LLM çš„è®­ç»ƒè‡ªåŠ¨åŒ–å’Œè‡ªæˆ‘è¿›åŒ–çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å‘å±•æä¾›äº†æ–°çš„æ€è·¯ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10179",
            "title": "When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models",
            "url": "https://huggingface.co/papers/2602.10179",
            "abstract": "Visual-to-visual jailbreak attacks compromise image editing models through malicious visual inputs, necessitating new safety benchmarks and defense mechanisms.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in large image editing models have shifted the paradigm from text-driven instructions to vision-prompt editing, where user intent is inferred directly from visual inputs such as marks, arrows, and visual-text prompts. While this paradigm greatly expands usability, it also introduces a critical and underexplored safety risk: the attack surface itself becomes visual. In this work, we propose Vision-Centric Jailbreak Attack (VJA), the first visual-to-visual jailbreak attack that conveys malicious instructions purely through visual inputs. To systematically study this emerging threat, we introduce IESBench, a safety-oriented benchmark for image editing models. Extensive experiments on IESBench demonstrate that VJA effectively compromises state-of-the-art commercial models, achieving attack success rates of up to 80.9% on Nano Banana Pro and 70.1% on GPT-Image-1.5. To mitigate this vulnerability, we propose a training-free defense based on introspective multimodal reasoning, which substantially improves the safety of poorly aligned models to a level comparable with commercial systems, without auxiliary guard models and with negligible computational overhead. Our findings expose new vulnerabilities, provide both a benchmark and practical defense to advance safe and trustworthy modern image editing systems. Warning: This paper contains offensive images created by large image editing models.",
            "score": 4,
            "issue_id": 1017,
            "pub_date": "2026-02-10",
            "pub_date_card": {
                "ru": "10 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 10",
                "zh": "2æœˆ10æ—¥"
            },
            "hash": "1791cf6930f61520",
            "authors": [
                "Jiacheng Hou",
                "Yining Sun",
                "Ruochong Jin",
                "Haochen Han",
                "Fangming Liu",
                "Wai Kin Victor Chan",
                "Alex Jinpeng Wang"
            ],
            "affiliations": [
                "Central South University, Changsha, China",
                "Peng Cheng Laboratory, Shenzhen, China",
                "Tsinghua University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10179.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#security",
                    "#ethics",
                    "#benchmark"
                ],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚ Ğ°Ñ‚Ğ°Ğº Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ°Ñ‚Ğ°Ğº Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ³Ğ´Ğµ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°ÑÑ‚ÑÑ Ğ¸ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ñ‡ĞµÑ€ĞµĞ· Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Vision-Centric Jailbreak Attack (VJA) â€” Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ°Ñ‚Ğ°ĞºÑƒ Ñ‚Ğ°ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ´Ğ° Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ IESBench, ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ VJA ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ñ€Ğ¾Ğ¼ĞµÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ¾Ğ¹ ÑƒÑĞ¿ĞµÑ…Ğ° Ğ´Ğ¾ 80.9%. Ğ”Ğ»Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ±ĞµĞ· ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¸Ğ½Ñ‚Ñ€Ğ¾ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚."
                },
                "en": {
                    "title": "Visual Attacks: A New Threat to Image Editing Safety",
                    "desc": "This paper introduces a new type of attack called Vision-Centric Jailbreak Attack (VJA), which targets image editing models by using malicious visual inputs instead of text. The authors highlight the risks associated with the shift to vision-prompt editing, where user intent is interpreted from visual cues. They also present IESBench, a benchmark designed to evaluate the safety of image editing models against these visual attacks. To counteract the vulnerabilities exposed by VJA, the paper proposes a novel defense mechanism that enhances model safety without requiring additional training or significant computational resources."
                },
                "zh": {
                    "title": "è§†è§‰è¾“å…¥çš„å®‰å…¨æŒ‘æˆ˜ä¸é˜²å¾¡",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†è§‰åˆ°è§†è§‰çš„è¶Šç‹±æ”»å‡»æ–¹æ³•ï¼Œç§°ä¸ºè§†è§‰ä¸­å¿ƒè¶Šç‹±æ”»å‡»ï¼ˆVJAï¼‰ï¼Œå®ƒé€šè¿‡æ¶æ„çš„è§†è§‰è¾“å…¥æ¥ç ´åå›¾åƒç¼–è¾‘æ¨¡å‹çš„å®‰å…¨æ€§ã€‚éšç€å›¾åƒç¼–è¾‘æ¨¡å‹çš„å‘å±•ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥é€šè¿‡è§†è§‰è¾“å…¥è¿›è¡Œç¼–è¾‘ï¼Œè¿™è™½ç„¶æé«˜äº†å¯ç”¨æ€§ï¼Œä½†ä¹Ÿå¸¦æ¥äº†æ–°çš„å®‰å…¨é£é™©ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…ä»¬å¼•å…¥äº†IESBenchï¼Œä¸€ä¸ªä¸“æ³¨äºå®‰å…¨æ€§çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å›¾åƒç¼–è¾‘æ¨¡å‹çš„è„†å¼±æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVJAèƒ½å¤Ÿæœ‰æ•ˆæ”»å‡»å…ˆè¿›çš„å•†ä¸šæ¨¡å‹ï¼ŒæˆåŠŸç‡é«˜è¾¾80.9%ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºå†…çœå¤šæ¨¡æ€æ¨ç†çš„é˜²å¾¡æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å®‰å…¨æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.09901",
            "title": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search",
            "url": "https://huggingface.co/papers/2602.09901",
            "abstract": "A unified generative large language model approach for social network search query processing that improves semantic understanding through multi-task learning and reinforcement learning while enhancing downstream task performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Query Processing (QP) bridges user intent and content supply in large-scale Social Network Service (SNS) search engines. Traditional QP systems rely on pipelines of isolated discriminative models (e.g., BERT), suffering from limited semantic understanding and high maintenance overhead. While Large Language Models (LLMs) offer a potential solution, existing approaches often optimize sub-tasks in isolation, neglecting intrinsic semantic synergy and necessitating independent iterations. Moreover, standard generative methods often lack grounding in SNS scenarios, failing to bridge the gap between open-domain corpora and informal SNS linguistic patterns, while struggling to adhere to rigorous business definitions. We present QP-OneModel, a Unified Generative LLM for Multi-Task Query Understanding in the SNS domain. We reformulate heterogeneous sub-tasks into a unified sequence generation paradigm, adopting a progressive three-stage alignment strategy culminating in multi-reward Reinforcement Learning. Furthermore, QP-OneModel generates intent descriptions as a novel high-fidelity semantic signal, effectively augmenting downstream tasks such as query rewriting and ranking. Offline evaluations show QP-OneModel achieves a 7.35% overall gain over discriminative baselines, with significant F1 boosts in NER (+9.01%) and Term Weighting (+9.31%). It also exhibits superior generalization, surpassing a 32B model by 7.60% accuracy on unseen tasks. Fully deployed at Xiaohongshu, online A/B tests confirm its industrial value, optimizing retrieval relevance (DCG) by 0.21% and lifting user retention by 0.044%.",
            "score": 4,
            "issue_id": 1017,
            "pub_date": "2026-02-10",
            "pub_date_card": {
                "ru": "10 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 10",
                "zh": "2æœˆ10æ—¥"
            },
            "hash": "54bedc96b8103bef",
            "authors": [
                "Jianzhao Huang",
                "Xiaorui Huang",
                "Fei Zhao",
                "Yunpeng Liu",
                "Hui Zhang",
                "Fangcheng Shi",
                "Congfeng Li",
                "Zechen Sun",
                "Yi Wu",
                "Yao Hu",
                "Yunhan Bai",
                "Shaosheng Cao"
            ],
            "affiliations": [
                "Xiaohongshu Inc., China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.09901.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…",
                    "desc": "Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ QP-OneModel â€” ĞµĞ´Ğ¸Ğ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ±Ğ¾Ğ»ÑŒÑˆÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ĞµĞ´Ğ¸Ğ½ÑƒÑ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñƒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ² Ñ‚Ñ€Ñ‘Ñ…ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ ĞºĞ°Ğº Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ÑĞ¸Ğ³Ğ½Ğ°Ğ», ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ². Ğ’ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğ¸ Ñ Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ QP-OneModel Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚ Ğ² 7.35% Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ñ€Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚Ğ° Ğ² Ğ¿Ñ€Ğ¾Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ğ¾Ğ¹ ÑÑ€ĞµĞ´Ğµ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸ Xiaohongshu."
                },
                "en": {
                    "title": "Unified Generative Model for Enhanced Social Network Query Processing",
                    "desc": "This paper introduces QP-OneModel, a unified generative large language model designed to enhance query processing in social network search engines. It addresses the limitations of traditional systems that use isolated models by integrating multi-task learning and reinforcement learning to improve semantic understanding. The model reformulates various sub-tasks into a cohesive sequence generation framework, allowing for better alignment and performance across tasks. Evaluation results demonstrate significant improvements in accuracy and user engagement, showcasing the model's effectiveness in real-world applications."
                },
                "zh": {
                    "title": "ç»Ÿä¸€ç”Ÿæˆæ¨¡å‹æå‡ç¤¾äº¤ç½‘ç»œæŸ¥è¯¢å¤„ç†",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ç”Ÿæˆå¤§è¯­è¨€æ¨¡å‹QP-OneModelï¼Œç”¨äºç¤¾äº¤ç½‘ç»œæœç´¢æŸ¥è¯¢å¤„ç†ã€‚è¯¥æ¨¡å‹é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ æé«˜äº†è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œå¹¶å¢å¼ºäº†ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚ä¸ä¼ ç»Ÿçš„ç¦»æ•£æ¨¡å‹ä¸åŒï¼ŒQP-OneModelå°†å¼‚æ„å­ä»»åŠ¡é‡æ–°æ„é€ æˆç»Ÿä¸€çš„åºåˆ—ç”ŸæˆèŒƒå¼ï¼Œé‡‡ç”¨æ¸è¿›çš„ä¸‰é˜¶æ®µå¯¹é½ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒQP-OneModelåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„åˆ¤åˆ«åŸºçº¿ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä»·å€¼ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10609",
            "title": "Online Causal Kalman Filtering for Stable and Effective Policy Optimization",
            "url": "https://huggingface.co/papers/2602.10609",
            "abstract": "Online Causal Kalman Filtering addresses high-variance token-level importance sampling in reinforcement learning for large language models by modeling IS ratios as evolving latent states and using Kalman filtering for stable policy optimization.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement learning for large language models suffers from high-variance token-level importance sampling (IS) ratios, which would destabilize policy optimization at scale. To improve stability, recent methods typically use a fixed sequence-level IS ratio for all tokens in a sequence or adjust each token's IS ratio separately, thereby neglecting temporal off-policy derivation across tokens in a sequence. In this paper, we first empirically identify that local off-policy deviation is structurally inconsistent at the token level, which may distort policy-gradient updates across adjacent tokens and lead to training collapse. To address the issue, we propose Online Causal Kalman Filtering for stable and effective Policy Optimization (KPO). Concretely, we model the desired IS ratio as a latent state that evolves across tokens and apply a Kalman filter to update this state online and autoregressively based on the states of past tokens, regardless of future tokens. The resulting filtered IS ratios preserve token-wise local structure-aware variation while strongly smoothing noise spikes, yielding more stable and effective policy updates. Experimentally, KPO achieves superior results on challenging math reasoning datasets compared with state-of-the-art counterparts.",
            "score": 3,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "857c0a58eccaf142",
            "authors": [
                "Shuo He",
                "Lang Feng",
                "Xin Cheng",
                "Lei Feng",
                "Bo An"
            ],
            "affiliations": [
                "Nanyang Technological University, Singapore",
                "Southeast University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10609.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "ĞšĞ°Ğ»Ğ¼Ğ°Ğ½Ğ¾Ğ²Ğ° Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ Online Causal Kalman Filtering Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¸ Ğ¿Ñ€Ğ¸ importance sampling Ğ² reinforcement learning Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒÑÑ‚ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹ importance sampling ĞºĞ°Ğº ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ ĞšĞ°Ğ»Ğ¼Ğ°Ğ½Ğ° Ğ´Ğ»Ñ Ğ¸Ñ… Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¾ÑˆĞ»Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ². ĞœĞµÑ‚Ğ¾Ğ´ KPO ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ÑÑ ÑˆÑƒĞ¼Ğ¾Ğ²Ñ‹Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ¾ÑÑ‹ Ğ¸ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Stabilizing Policy Optimization with Kalman Filtering in RL",
                    "desc": "This paper introduces Online Causal Kalman Filtering (KPO) to improve the stability of policy optimization in reinforcement learning for large language models. It addresses the problem of high-variance token-level importance sampling (IS) ratios, which can destabilize training. By modeling IS ratios as evolving latent states and using Kalman filtering, the method updates these states based on past tokens, ensuring that the updates are more stable and effective. The experimental results show that KPO outperforms existing methods on complex math reasoning tasks."
                },
                "zh": {
                    "title": "åœ¨çº¿å› æœå¡å°”æ›¼æ»¤æ³¢ï¼šç¨³å®šå¼ºåŒ–å­¦ä¹ çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨çº¿å› æœå¡å°”æ›¼æ»¤æ³¢æ–¹æ³•ï¼Œç”¨äºè§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸­å¼ºåŒ–å­¦ä¹ çš„é«˜æ–¹å·®é‡è¦æ€§é‡‡æ ·é—®é¢˜ã€‚æˆ‘ä»¬é€šè¿‡å°†é‡è¦æ€§é‡‡æ ·æ¯”ç‡å»ºæ¨¡ä¸ºä¸æ–­æ¼”å˜çš„æ½œåœ¨çŠ¶æ€ï¼Œå¹¶åˆ©ç”¨å¡å°”æ›¼æ»¤æ³¢è¿›è¡Œç¨³å®šçš„ç­–ç•¥ä¼˜åŒ–ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå±€éƒ¨çš„ç¦»çº¿ç­–ç•¥åå·®åœ¨ä»¤ç‰Œçº§åˆ«ä¸Šæ˜¯ä¸ä¸€è‡´çš„ï¼Œè¿™å¯èƒ½å¯¼è‡´ç­–ç•¥æ¢¯åº¦æ›´æ–°çš„å¤±çœŸã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¿æŒä»¤ç‰Œé—´å±€éƒ¨ç»“æ„å˜åŒ–çš„åŒæ—¶ï¼Œæœ‰æ•ˆå¹³æ»‘å™ªå£°ï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„ç­–ç•¥æ›´æ–°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.04935",
            "title": "ASA: Training-Free Representation Engineering for Tool-Calling Agents",
            "url": "https://huggingface.co/papers/2602.04935",
            "abstract": "A training-free method called Activation Steering Adapter corrects tool calling behavior in language models by using mid-layer activation interventions guided by a probe and router-conditioned steering vectors.  \t\t\t\t\tAI-generated summary \t\t\t\t Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-efficient fine-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify a critical Lazy Agent failure mode where tool necessity is nearly perfectly decodable from mid-layer activations, yet the model remains conservative in entering tool mode, revealing a representation-behavior gap. We propose Activation Steering Adapter (ASA), a training-free, inference-time controller that performs a single-shot mid-layer intervention and targets tool domains via a router-conditioned mixture of steering vectors with a probe-guided signed gate to amplify true intent while suppressing spurious triggers. On MTU-Bench with Qwen2.5-1.5B, ASA improves strict tool-use F1 from 0.18 to 0.50 while reducing the false positive rate from 0.15 to 0.05, using only about 20KB of portable assets and no weight updates.",
            "score": 3,
            "issue_id": 1017,
            "pub_date": "2026-02-04",
            "pub_date_card": {
                "ru": "4 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 4",
                "zh": "2æœˆ4æ—¥"
            },
            "hash": "79e467c611d9e5d6",
            "authors": [
                "Youjin Wang",
                "Run Zhou",
                "Rong Fu",
                "Shuaishuai Cao",
                "Hongwei Zeng",
                "Jiaxuan Lu",
                "Sicheng Fan",
                "Jiaqiao Zhao",
                "Liangming Pan"
            ],
            "affiliations": [
                "Central South University",
                "Fudan University",
                "Peking University",
                "Renmin University of China",
                "Shanghai AI Laboratory",
                "University South University",
                "University of the Chinese Academy of Sciences"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.04935.jpg",
            "data": {
                "categories": [
                    "#small_models",
                    "#inference",
                    "#training",
                    "#agents"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "ĞĞ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¹: Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ½Ğ°Ğ´Ñ‘Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Activation Steering Adapter (ASA) Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ±ĞµĞ· Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ \"Ğ»ĞµĞ½Ğ¸Ğ²Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°\", ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ° Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸Ğ· Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¹ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… ÑĞ»Ğ¾Ñ‘Ğ², Ğ½Ğ¾ Ğ½Ğµ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸Ğ·-Ğ·Ğ° Ñ€Ğ°Ğ·Ñ€Ñ‹Ğ²Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸ĞµĞ¼. ASA Ñ€ĞµÑˆĞ°ĞµÑ‚ ÑÑ‚Ñƒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ´Ğ½Ğ¾ĞºÑ€Ğ°Ñ‚Ğ½Ğ¾Ğµ Ğ²Ğ¼ĞµÑˆĞ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾ Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ ÑĞ»Ğ¾Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‰Ğ¸Ñ… Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ², ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ñ… Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¸ Ğ·Ğ¾Ğ½Ğ´Ğ¾Ğ¼. ĞĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¼ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğµ MTU-Bench Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ğ» Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ F1 Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ñ 0.18 Ğ´Ğ¾ 0.50, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ·Ğ¸Ğ² Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ñ‚Ñ€ĞµĞ±ÑƒÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 20KB Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ±ĞµĞ· Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing Tool Calling in Language Models with Activation Steering",
                    "desc": "The paper introduces the Activation Steering Adapter (ASA), a novel method for improving tool calling behavior in language models without the need for training. It addresses the issue of models being overly cautious in using tools, despite having the necessary information available in their mid-layer activations. ASA utilizes a single-shot intervention at inference time, employing router-conditioned steering vectors and a probe-guided mechanism to enhance the model's decision-making. The results show significant improvements in tool-use accuracy while maintaining a low false positive rate, demonstrating the effectiveness of this training-free approach."
                },
                "zh": {
                    "title": "æ¿€æ´»å¼•å¯¼é€‚é…å™¨ï¼šæ— éœ€è®­ç»ƒçš„å·¥å…·è°ƒç”¨ä¿®æ­£æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºæ¿€æ´»å¼•å¯¼é€‚é…å™¨ï¼ˆActivation Steering Adapter, ASAï¼‰çš„æ–¹æ³•ï¼Œç”¨äºä¿®æ­£è¯­è¨€æ¨¡å‹ä¸­çš„å·¥å…·è°ƒç”¨è¡Œä¸ºã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸­é—´å±‚æ¿€æ´»å¹²é¢„ï¼Œåˆ©ç”¨æ¢é’ˆå’Œè·¯ç”±æ¡ä»¶å¼•å¯¼çš„å‘é‡ï¼Œåœ¨æ¨ç†æ—¶è¿›è¡Œå•æ¬¡å¹²é¢„ï¼Œè€Œæ— éœ€è®­ç»ƒã€‚ASAèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å·¥å…·è°ƒç”¨çš„å¿…è¦æ€§ï¼Œå¹¶é€šè¿‡æ”¾å¤§çœŸå®æ„å›¾æ¥æŠ‘åˆ¶é”™è¯¯è§¦å‘ï¼Œä»è€Œæé«˜å·¥å…·ä½¿ç”¨çš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒASAåœ¨MTU-Benchä¸Šæ˜¾è‘—æé«˜äº†å·¥å…·ä½¿ç”¨çš„F1åˆ†æ•°ï¼ŒåŒæ—¶é™ä½äº†è¯¯æŠ¥ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨ç‰¹å®šé¢†åŸŸå·¥å…·è°ƒç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.11144",
            "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite",
            "url": "https://huggingface.co/papers/2602.11144",
            "abstract": "GENIUS evaluates multimodal models' generative fluid intelligence through pattern induction, constraint execution, and contextual adaptation tasks, revealing deficiencies in context comprehension rather than generative capability.  \t\t\t\t\tAI-generated summary \t\t\t\t Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess Crystallized Intelligence, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks Generative Fluid Intelligence (GFI): the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on the fly. To rigorously assess this capability, we introduce GENIUS (GEN Fluid Intelligence EvalUation Suite). We formalize GFI as a synthesis of three primitives. These include Inducing Implicit Patterns (e.g., inferring personalized visual preferences), Executing Ad-hoc Constraints (e.g., visualizing abstract metaphors), and Adapting to Contextual Knowledge (e.g., simulating counter-intuitive physics). Collectively, these primitives challenge models to solve problems grounded entirely in the immediate context. Our systematic evaluation of 12 representative models reveals significant performance deficits in these tasks. Crucially, our diagnostic analysis disentangles these failure modes. It demonstrates that deficits stem from limited context comprehension rather than insufficient intrinsic generative capability. To bridge this gap, we propose a training-free attention intervention strategy. Ultimately, GENIUS establishes a rigorous standard for GFI, guiding the field beyond knowledge utilization toward dynamic, general-purpose reasoning. Our dataset and code will be released at: https://github.com/arctanxarc/GENIUS{https://github.com/arctanxarc/GENIUS}.",
            "score": 2,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "63e69030ff6001c2",
            "authors": [
                "Ruichuan An",
                "Sihan Yang",
                "Ziyu Guo",
                "Wei Dai",
                "Zijun Shen",
                "Haodong Li",
                "Renrui Zhang",
                "Xinyu Wei",
                "Guopeng Li",
                "Wenshan Wu",
                "Wentao Zhang"
            ],
            "affiliations": [
                "CUHK",
                "MSRA",
                "Peking University",
                "PolyU",
                "StepFun"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.11144.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#benchmark"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ñ„Ğ»ÑĞ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°: Ğ¾Ñ‚ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğº ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¾Ñ†ĞµĞ½Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¸ĞºĞ° GENIUS Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ»ÑĞ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ½Ğ° Ğ¸Ğ½Ğ´ÑƒĞºÑ†Ğ¸Ñ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ², Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ Ğº ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ñƒ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ 12 Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼, Ğ¸ÑĞ¿Ñ‹Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğµ Ğ¸Ğ·-Ğ·Ğ° Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹, Ğ° Ğ¸Ğ·-Ğ·Ğ° Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ° Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ñ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ´ĞµÑ„Ğ¸Ñ†Ğ¸Ñ‚Ğ¾Ğ². ĞœĞµÑ‚Ğ¾Ğ´Ğ¸ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸, ÑĞ¼ĞµÑ‰Ğ°Ñ Ñ„Ğ¾ĞºÑƒÑ Ñ Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ½Ğ° Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ² Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Unlocking Generative Fluid Intelligence in AI Models",
                    "desc": "The paper introduces GENIUS, a new evaluation suite designed to measure Generative Fluid Intelligence (GFI) in multimodal models. Unlike traditional benchmarks that focus on Crystallized Intelligence, GENIUS assesses a model's ability to induce patterns, execute constraints, and adapt to new contexts. The study reveals that many models struggle with context comprehension, which limits their performance in GFI tasks. To address these deficiencies, the authors propose a training-free attention intervention strategy, aiming to enhance dynamic reasoning capabilities in AI systems."
                },
                "zh": {
                    "title": "è¯„ä¼°ç”Ÿæˆæµä½“æ™ºèƒ½çš„æ–°æ ‡å‡†",
                    "desc": "GENIUSè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹çš„ç”Ÿæˆæµä½“æ™ºèƒ½ï¼Œé‡ç‚¹åœ¨äºæ¨¡å¼è¯±å¯¼ã€çº¦æŸæ‰§è¡Œå’Œä¸Šä¸‹æ–‡é€‚åº”ä»»åŠ¡ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè€Œéç”Ÿæˆèƒ½åŠ›ä¸è¶³ã€‚æˆ‘ä»¬æå‡ºçš„GENIUSå·¥å…·ä¸ºç”Ÿæˆæµä½“æ™ºèƒ½æä¾›äº†ä¸¥æ ¼çš„è¯„ä¼°æ ‡å‡†ï¼Œå¼ºè°ƒäº†æ¨¡å‹åœ¨åŠ¨æ€æ¨ç†ä¸­çš„é‡è¦æ€§ã€‚é€šè¿‡å¯¹12ä¸ªä»£è¡¨æ€§æ¨¡å‹çš„ç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬æ­ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨å¤„ç†å³æ—¶ä¸Šä¸‹æ–‡é—®é¢˜æ—¶çš„æ˜¾è‘—æ€§èƒ½ç¼ºé™·ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.06008",
            "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
            "url": "https://huggingface.co/papers/2602.06008",
            "abstract": "AgenticPay presents a benchmark and simulation framework for evaluating multi-agent language-mediated economic interactions, focusing on negotiation performance and strategic reasoning challenges in complex market scenarios.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.",
            "score": 2,
            "issue_id": 1017,
            "pub_date": "2026-02-05",
            "pub_date_card": {
                "ru": "5 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 5",
                "zh": "2æœˆ5æ—¥"
            },
            "hash": "fb4093533108c1ec",
            "authors": [
                "Xianyang Liu",
                "Shangding Gu",
                "Dawn Song"
            ],
            "affiliations": [
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.06008.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#agents"
                ],
                "emoji": "ğŸ¤",
                "ru": {
                    "title": "LLM-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ ÑƒÑ‡Ğ°Ñ‚ÑÑ Ğ²ĞµÑÑ‚Ğ¸ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹ Ñ‡ĞµÑ€ĞµĞ· ÑĞ·Ñ‹Ğº",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° AgenticPay Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° Ğ² ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€Ñ‹Ğ½ĞºĞ¸, Ğ³Ğ´Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ñ‹ Ğ¸Ğ¼ĞµÑÑ‚ Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ‚ÑŒ ÑĞ¾Ğ³Ğ»Ğ°ÑˆĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ€Ğ°ÑƒĞ½Ğ´Ğ¾Ğ²Ñ‹Ğµ Ğ»Ğ¸Ğ½Ğ³Ğ²Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ğ²Ğ¾Ğº. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ 110 Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¾Ñ‚ Ğ´Ğ²ÑƒÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ñ… Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ² Ğ´Ğ¾ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ñ… Ñ€Ñ‹Ğ½ĞºĞ¾Ğ² Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¾ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸, ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ±Ğ»Ğ°Ğ³Ğ¾ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ². Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… LLM-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ» ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ² ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğº ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Revolutionizing Multi-Agent Negotiation with Language",
                    "desc": "AgenticPay is a new benchmark and simulation framework designed to evaluate how well multiple agents can negotiate and interact in economic scenarios using natural language. It focuses on the complexities of negotiation where agents have private constraints and varying valuations for products, requiring them to communicate effectively over multiple rounds. The framework includes over 110 different tasks, allowing for a comprehensive assessment of negotiation strategies and outcomes. By testing advanced language models, the study reveals significant performance gaps and highlights the difficulties in long-term strategic reasoning in these interactions."
                },
                "zh": {
                    "title": "AgenticPayï¼šå¤šæ™ºèƒ½ä½“ç»æµäº’åŠ¨çš„æ–°åŸºå‡†",
                    "desc": "AgenticPayæ˜¯ä¸€ä¸ªåŸºå‡†å’Œä»¿çœŸæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¤šæ™ºèƒ½ä½“ä¹‹é—´çš„è¯­è¨€ä¸­ä»‹ç»æµäº’åŠ¨ï¼Œç‰¹åˆ«å…³æ³¨è°ˆåˆ¤è¡¨ç°å’Œå¤æ‚å¸‚åœºåœºæ™¯ä¸­çš„æˆ˜ç•¥æ¨ç†æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶æ¨¡æ‹Ÿäº†ä¹°å–åŒæ–¹åœ¨å…·æœ‰ç§å¯†çº¦æŸå’Œäº§å“ä¾èµ–ä¼°å€¼çš„å¸‚åœºä¸­ï¼Œé€šè¿‡å¤šè½®è¯­è¨€è°ˆåˆ¤è¾¾æˆåè®®ï¼Œè€Œä¸ä»…ä»…ä¾èµ–æ•°å­—ç«æ ‡ã€‚AgenticPayæ”¯æŒè¶…è¿‡110ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ï¼Œä»åŒè¾¹è°ˆåˆ¤åˆ°å¤šå¯¹å¤šå¸‚åœºï¼Œæä¾›ç»“æ„åŒ–çš„è¡ŒåŠ¨æå–å’Œå¯è¡Œæ€§ã€æ•ˆç‡åŠç¦åˆ©çš„è¯„ä¼°æŒ‡æ ‡ã€‚é€šè¿‡å¯¹æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ­ç¤ºäº†è°ˆåˆ¤è¡¨ç°çš„æ˜¾è‘—å·®è·ï¼Œå¹¶çªå‡ºäº†é•¿æœŸæˆ˜ç•¥æ¨ç†ä¸­çš„æŒ‘æˆ˜ï¼Œç¡®ç«‹äº†AgenticPayä½œä¸ºç ”ç©¶æ™ºèƒ½å•†ä¸šå’ŒåŸºäºè¯­è¨€çš„å¸‚åœºäº’åŠ¨çš„åŸºç¡€ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10652",
            "title": "UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory",
            "url": "https://huggingface.co/papers/2602.10652",
            "abstract": "A unified framework for memory extraction and management in LLM-based agents that improves generalization through semantic neighborhood modeling and marginal utility rewards.  \t\t\t\t\tAI-generated summary \t\t\t\t Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO. This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.67% improvement in multi-turn interactive tasks. Futhermore, UMEM maintains a monotonic growth curve during continuous evolution. Codes and models will be publicly released.",
            "score": 1,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "a5d917cb654e3d7f",
            "authors": [
                "Yongshi Ye",
                "Hui Jiang",
                "Feihu Jiang",
                "Tian Lan",
                "Yichao Du",
                "Biao Fu",
                "Xiaodong Shi",
                "Qianghuai Jia",
                "Longyue Wang",
                "Weihua Luo"
            ],
            "affiliations": [
                "Alibaba International Digital Commerce",
                "Tongyi Lab, Alibaba Group",
                "Xiamen University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10652.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ¡Ğ°Ğ¼Ğ¾Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‰Ğ°ÑÑÑ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ: ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ² LLM-Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ñ…",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ UMEM â€” ĞµĞ´Ğ¸Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒÑ Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ñ… Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€ĞµÑˆĞ°ÑÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ… Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¾ÑĞµĞ´ÑÑ‚Ğ²Ğ° Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚Ğ¸. ĞšĞ»ÑÑ‡ĞµĞ²Ğ°Ñ Ğ¸Ğ´ĞµÑ Ğ·Ğ°ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ GRPO. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ğ¿ÑÑ‚Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° 10.67% Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ Ğ¼Ğ¾Ğ½Ğ¾Ñ‚Ğ¾Ğ½Ğ½Ñ‹Ğ¼ Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Enhancing LLMs with Unified Memory Management for Better Generalization",
                    "desc": "This paper presents a new framework called Unified Memory Extraction and Management (UMEM) for improving how Large Language Models (LLMs) handle memory. It focuses on two key processes: extracting useful insights from experiences and managing the memory bank effectively. The authors introduce Semantic Neighborhood Modeling to enhance generalization and reduce overfitting by evaluating memory utility based on related queries. Their experiments show that UMEM significantly outperforms existing methods, leading to better performance in interactive tasks."
                },
                "zh": {
                    "title": "ç»Ÿä¸€è®°å¿†æå–ä¸ç®¡ç†ï¼Œæå‡æ™ºèƒ½ä½“æ³›åŒ–èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è®°å¿†æå–å’Œç®¡ç†æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡è‡ªæˆ‘æ¼”åŒ–çš„è®°å¿†ï¼Œä»£ç†èƒ½å¤Ÿåœ¨æå–ç»éªŒå’Œæ›´æ–°è®°å¿†åº“ä¹‹é—´å®ç°ç´§å¯†åè°ƒã€‚æˆ‘ä»¬å¼•å…¥äº†è¯­ä¹‰é‚»åŸŸå»ºæ¨¡å’Œè¾¹é™…æ•ˆç”¨å¥–åŠ±ï¼Œä»¥ä¼˜åŒ–è®°å¿†çš„æå–å’Œç®¡ç†ï¼Œé¿å…è¿‡æ‹Ÿåˆç‰¹å®šå®ä¾‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šè½®äº¤äº’ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡äº†è®°å¿†çš„æ³›åŒ–èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.09014",
            "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
            "url": "https://huggingface.co/papers/2602.09014",
            "abstract": "ArcFlow is a few-step distillation framework that uses non-linear flow trajectories to approximate teacher diffusion models, achieving fast inference with minimal quality loss through lightweight adapter training.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.",
            "score": 1,
            "issue_id": 1017,
            "pub_date": "2026-02-09",
            "pub_date_card": {
                "ru": "9 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 9",
                "zh": "2æœˆ9æ—¥"
            },
            "hash": "d34bd75b555fb1b3",
            "authors": [
                "Zihan Yang",
                "Shuyuan Tu",
                "Licheng Zhang",
                "Qi Dai",
                "Yu-Gang Jiang",
                "Zuxuan Wu"
            ],
            "affiliations": [
                "Fudan University",
                "Microsoft Research Asia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.09014.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#training",
                    "#optimization",
                    "#diffusion",
                    "#inference"
                ],
                "emoji": "âš¡",
                "ru": {
                    "title": "ĞĞµĞ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ArcFlow â€” ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ½ĞµĞ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ´Ğ»Ñ Ğ°Ğ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ¼Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ², Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ñ… Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ, ArcFlow Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ·ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ»Ğµ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğº ÑĞ¼ĞµÑÑŒ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² Ğ¸Ğ¼Ğ¿ÑƒĞ»ÑŒÑĞ°, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½ĞµĞµ Ğ¾Ñ‚ÑĞ»ĞµĞ´Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… ÑˆĞ°Ğ³Ğ°Ñ…. Ğ‘Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½ĞµĞ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸Ğ·Ğ±ĞµĞ³Ğ°ĞµÑ‚ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸. ĞĞ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞµ ArcFlow Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ»ĞµĞ³ĞºĞ¸Ñ… Ğ°Ğ´Ğ°Ğ¿Ñ‚ĞµÑ€Ğ¾Ğ², Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ÑÑ‰Ğ¸Ñ… Ğ¼ĞµĞ½ĞµĞµ 5% Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ 40-ĞºÑ€Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸."
                },
                "en": {
                    "title": "ArcFlow: Fast and Efficient Few-Step Distillation for Diffusion Models",
                    "desc": "ArcFlow is a novel framework designed to improve the efficiency of diffusion models by reducing the number of inference steps needed for high-quality image generation. It achieves this by using non-linear flow trajectories to better approximate the complex behavior of teacher models during the denoising process. By parameterizing the velocity field as a mixture of continuous momentum processes, ArcFlow captures the evolving dynamics of the inference trajectory, leading to more accurate and coherent outputs. This method allows for significant speed improvements, achieving a 40x reduction in inference time while maintaining the quality of generated images with minimal parameter adjustments."
                },
                "zh": {
                    "title": "ArcFlowï¼šå¿«é€Ÿé«˜æ•ˆçš„å°‘æ­¥è’¸é¦æ¡†æ¶",
                    "desc": "ArcFlowæ˜¯ä¸€ç§å°‘æ­¥è’¸é¦æ¡†æ¶ï¼Œåˆ©ç”¨éçº¿æ€§æµè½¨è¿¹æ¥è¿‘ä¼¼æ•™å¸ˆæ‰©æ•£æ¨¡å‹ï¼Œä»è€Œå®ç°å¿«é€Ÿæ¨ç†ä¸”è´¨é‡æŸå¤±æœ€å°ã€‚ä¼ ç»Ÿçš„è’¸é¦æ–¹æ³•é€šå¸¸ä½¿ç”¨çº¿æ€§æ·å¾„æ¥è¿‘ä¼¼æ•™å¸ˆè½¨è¿¹ï¼Œè¿™å¯¼è‡´éš¾ä»¥åŒ¹é…ä¸æ–­å˜åŒ–çš„åˆ‡çº¿æ–¹å‘ï¼Œè¿›è€Œå½±å“ç”Ÿæˆè´¨é‡ã€‚ArcFlowé€šè¿‡å°†æ¨ç†è½¨è¿¹çš„é€Ÿåº¦åœºå‚æ•°åŒ–ä¸ºè¿ç»­åŠ¨é‡è¿‡ç¨‹çš„æ··åˆï¼Œèƒ½å¤Ÿæ•æ‰é€Ÿåº¦æ¼”å˜å¹¶åœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ä¸­å½¢æˆè¿ç»­çš„éçº¿æ€§è½¨è¿¹ã€‚ç»è¿‡å®éªŒéªŒè¯ï¼ŒArcFlowåœ¨ä¿æŒç”Ÿæˆå¤šæ ·æ€§å’Œè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†40å€çš„é€Ÿåº¦æå‡ï¼Œä¸”ä»…éœ€å¾®è°ƒä¸åˆ°5%çš„åŸå§‹å‚æ•°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.08995",
            "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents",
            "url": "https://huggingface.co/papers/2602.08995",
            "abstract": "Computer-use agents face safety risks from misaligned actions caused by external attacks or internal limitations, prompting the development of DeAction, a guardrail that detects and corrects such actions before execution.  \t\t\t\t\tAI-generated summary \t\t\t\t Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.",
            "score": 1,
            "issue_id": 1017,
            "pub_date": "2026-02-09",
            "pub_date_card": {
                "ru": "9 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 9",
                "zh": "2æœˆ9æ—¥"
            },
            "hash": "d4e80fde2d84ca42",
            "authors": [
                "Yuting Ning",
                "Jaylen Jones",
                "Zhehao Zhang",
                "Chentao Ye",
                "Weitong Ruan",
                "Junyi Li",
                "Rahul Gupta",
                "Huan Sun"
            ],
            "affiliations": [
                "Amazon AGI",
                "The Ohio State University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.08995.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#security",
                    "#alignment",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹",
                    "desc": "Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° DeAction Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ñ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²ÑƒÑÑ‚ Ñ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ¾Ğ¼. Ğ¢Ğ°ĞºĞ¸Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ°Ñ‚ÑŒ ĞºĞ°Ğº Ğ¸Ğ·-Ğ·Ğ° Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ°Ñ‚Ğ°Ğº (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, ĞºĞ¾ÑĞ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½ÑŠĞµĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·Ğ¾Ğº), Ñ‚Ğ°Ğº Ğ¸ Ğ¸Ğ·-Ğ·Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ñ… Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ğ¾ÑˆĞ¸Ğ±Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº MisActBench Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑĞ¼Ğ¸ Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ: Ğ½Ğ° 15% Ğ¿Ğ¾ F1-Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ Ğ½Ğ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ Ğ¸ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ğ°Ñ‚Ğ°Ğº Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ Ğ½Ğ° 90% Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "DeAction: Safeguarding Computer-Use Agents from Misalignment Risks",
                    "desc": "This paper introduces DeAction, a safety mechanism designed for computer-use agents (CUAs) to detect and correct misaligned actions that may arise from both external attacks and internal limitations. Misaligned actions can lead to safety risks and inefficiencies, prompting the need for a robust solution. The authors define misaligned action detection and create MisActBench, a benchmark for evaluating action alignment in CUAs. DeAction demonstrates significant improvements in performance, achieving over 15% better F1 scores and reducing attack success rates by more than 90% while maintaining task success in safe environments."
                },
                "zh": {
                    "title": "DeActionï¼šç¡®ä¿è®¡ç®—æœºä»£ç†å®‰å…¨çš„å®ˆæŠ¤è€…",
                    "desc": "è®¡ç®—æœºä½¿ç”¨ä»£ç†ï¼ˆCUAï¼‰åœ¨è¿‡å»ä¸€å¹´å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»ç„¶ç»å¸¸äº§ç”Ÿä¸ç”¨æˆ·åŸæ„ä¸ç¬¦çš„è¡Œä¸ºã€‚è¿™äº›ä¸ä¸€è‡´çš„è¡Œä¸ºå¯èƒ½æºäºå¤–éƒ¨æ”»å‡»ï¼ˆå¦‚é—´æ¥æç¤ºæ³¨å…¥ï¼‰æˆ–å†…éƒ¨é™åˆ¶ï¼ˆå¦‚é”™è¯¯æ¨ç†ï¼‰ï¼Œä¸ä»…å¸¦æ¥å®‰å…¨é£é™©ï¼Œè¿˜é™ä½äº†ä»»åŠ¡çš„æ•ˆç‡å’Œå¯é æ€§ã€‚æœ¬æ–‡é¦–æ¬¡å®šä¹‰å¹¶ç ”ç©¶äº†CUAä¸­çš„ä¸ä¸€è‡´è¡Œä¸ºæ£€æµ‹ï¼Œæ„å»ºäº†MisActBenchåŸºå‡†ï¼Œæä¾›äº†çœŸå®è½¨è¿¹å’Œäººç±»æ ‡æ³¨çš„è¡Œä¸ºå¯¹é½æ ‡ç­¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†DeActionï¼Œä¸€ä¸ªå®ç”¨çš„ä¿æŠ¤æœºåˆ¶ï¼Œå¯ä»¥åœ¨æ‰§è¡Œå‰æ£€æµ‹å¹¶é€šè¿‡ç»“æ„åŒ–åé¦ˆè¿­ä»£çº æ­£ä¸ä¸€è‡´çš„è¡Œä¸ºã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.08711",
            "title": "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions",
            "url": "https://huggingface.co/papers/2602.08711",
            "abstract": "Omni Dense Captioning introduces a six-dimensional structural schema for generating time-aware audio-visual narratives with explicit timestamps, along with a unified evaluation metric and strong baseline model.  \t\t\t\t\tAI-generated summary \t\t\t\t This paper proposes Omni Dense Captioning, a novel task designed to generate continuous, fine-grained, and structured audio-visual narratives with explicit timestamps. To ensure dense semantic coverage, we introduce a six-dimensional structural schema to create \"script-like\" captions, enabling readers to vividly imagine the video content scene by scene, akin to a cinematographic screenplay. To facilitate research, we construct OmniDCBench, a high-quality, human-annotated benchmark, and propose SodaM, a unified metric that evaluates time-aware detailed descriptions while mitigating scene boundary ambiguity. Furthermore, we construct a training dataset, TimeChatCap-42K, and present TimeChat-Captioner-7B, a strong baseline trained via SFT and GRPO with task-specific rewards. Extensive experiments demonstrate that TimeChat-Captioner-7B achieves state-of-the-art performance, surpassing Gemini-2.5-Pro, while its generated dense descriptions significantly boost downstream capabilities in audio-visual reasoning (DailyOmni and WorldSense) and temporal grounding (Charades-STA). All datasets, models, and code will be made publicly available at https://github.com/yaolinli/TimeChat-Captioner.",
            "score": 1,
            "issue_id": 1017,
            "pub_date": "2026-02-09",
            "pub_date_card": {
                "ru": "9 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 9",
                "zh": "2æœˆ9æ—¥"
            },
            "hash": "06197a055773ca80",
            "authors": [
                "Linli Yao",
                "Yuancheng Wei",
                "Yaojie Zhang",
                "Lei Li",
                "Xinlong Chen",
                "Feifan Song",
                "Ziyue Wang",
                "Kun Ouyang",
                "Yuanxin Liu",
                "Lingpeng Kong",
                "Qi Liu",
                "Pengfei Wan",
                "Kun Gai",
                "Yuanxing Zhang",
                "Xu Sun"
            ],
            "affiliations": [
                "Institute of Automation, Chinese Academy of Sciences",
                "Kling Team, Kuaishou Technology",
                "School of Computer Science, Peking University",
                "South China University of Technology",
                "The University of Hong Kong",
                "University of Electronic Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.08711.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#multimodal",
                    "#training",
                    "#reasoning",
                    "#benchmark",
                    "#audio",
                    "#dataset",
                    "#open_source"
                ],
                "emoji": "ğŸ¬",
                "ru": {
                    "title": "Ğ’Ğ¸Ğ´ĞµĞ¾ Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚ĞºĞ°Ğ¼Ğ¸: ĞºĞ°Ğº Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾ ĞºĞ°Ğº ĞºĞ¸Ğ½ĞµĞ¼Ğ°Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸ÑÑ‚",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Omni Dense Captioning â€” Ğ½Ğ¾Ğ²ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ñ… Ğ°ÑƒĞ´Ğ¸Ğ¾Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ ÑĞ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚ĞºĞ°Ğ¼Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ ÑˆĞµÑÑ‚Ğ¸Ñ‚Ğ¾Ñ‡ĞµÑ‡Ğ½ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½ÑƒÑ ÑÑ…ĞµĞ¼Ñƒ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ 'ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ĞµĞ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ñ‹Ñ…' Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞµĞ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‚ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ ÑÑ†ĞµĞ½Ğ° Ğ·Ğ° ÑÑ†ĞµĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾ ĞºĞ¸Ğ½ĞµĞ¼Ğ°Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ñ. ĞĞ½Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº OmniDCBench Ñ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ SodaM Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ TimeChat-Captioner-7B, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ SFT Ğ¸ GRPO Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¾-ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°Ğ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Gemini-2.5-Pro Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ»Ğ¾ĞºĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Crafting Cinematic Narratives with Time-Aware Captions",
                    "desc": "Omni Dense Captioning is a new approach for creating detailed audio-visual narratives that include specific timestamps. It uses a six-dimensional structural schema to produce captions that resemble a screenplay, allowing for a richer understanding of video content. The paper introduces a benchmark called OmniDCBench and a new evaluation metric, SodaM, to assess the quality of these time-aware descriptions. Additionally, it presents a strong baseline model, TimeChat-Captioner-7B, which outperforms existing models and enhances tasks related to audio-visual reasoning and temporal grounding."
                },
                "zh": {
                    "title": "å…¨æ–¹ä½å¯†é›†å­—å¹•ç”Ÿæˆï¼šéŸ³è§†é¢‘å™è¿°çš„æ–°çºªå…ƒ",
                    "desc": "æœ¬æ–‡æå‡ºäº†Omni Dense Captioningï¼Œè¿™æ˜¯ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨ç”Ÿæˆå…·æœ‰æ˜ç¡®æ—¶é—´æˆ³çš„è¿ç»­ã€ç»†è‡´ä¸”ç»“æ„åŒ–çš„éŸ³è§†é¢‘å™è¿°ã€‚ä¸ºç¡®ä¿è¯­ä¹‰çš„å¯†é›†è¦†ç›–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å…­ç»´ç»“æ„æ¡†æ¶ï¼Œåˆ›å»ºç±»ä¼¼å‰§æœ¬çš„å­—å¹•ï¼Œä½¿è¯»è€…èƒ½å¤Ÿé€å¸§ç”ŸåŠ¨æƒ³è±¡è§†é¢‘å†…å®¹ã€‚æˆ‘ä»¬æ„å»ºäº†OmniDCBenchï¼Œä¸€ä¸ªé«˜è´¨é‡çš„äººç±»æ ‡æ³¨åŸºå‡†ï¼Œå¹¶æå‡ºäº†SodaMï¼Œä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°æ—¶é—´æ„ŸçŸ¥çš„è¯¦ç»†æè¿°ã€‚é€šè¿‡å¤§é‡å®éªŒï¼ŒTimeChat-Captioner-7Bæ¨¡å‹åœ¨éŸ³è§†é¢‘æ¨ç†å’Œæ—¶é—´å®šä½ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ç°æœ‰çš„åŸºå‡†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.10699",
            "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
            "url": "https://huggingface.co/papers/2602.10699",
            "abstract": "V-STAR addresses limitations in generative recommendation by combining value-guided decoding and tree-structured advantage reinforcement to improve exploration and reward signal quality.  \t\t\t\t\tAI-generated summary \t\t\t\t Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.",
            "score": 0,
            "issue_id": 1017,
            "pub_date": "2026-02-11",
            "pub_date_card": {
                "ru": "11 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 11",
                "zh": "2æœˆ11æ—¥"
            },
            "hash": "4aaea540952b7aaf",
            "authors": [
                "Jie Jiang",
                "Yangru Huang",
                "Zeyu Wang",
                "Changping Wang",
                "Yuling Xiong",
                "Jun Zhang",
                "Huan Yu"
            ],
            "affiliations": [
                "Tencent Inc., China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.10699.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸŒ³",
                "ru": {
                    "title": "Ğ”ĞµÑ€ĞµĞ²Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹: Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°ĞµĞ¼ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ğ¾-Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ½Ğ¾Ğµ Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ",
                    "desc": "V-STAR â€” ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸ÑĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ½ĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ¾Ğ¹ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ²Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹: Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ğ¾Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ ÑĞµĞ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ÑƒĞ³Ğ»ÑƒĞ±Ğ»ÑĞµÑ‚ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑÑ‹, Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ½Ğ° Ğ´ĞµÑ€ĞµĞ²Ğµ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ¶Ğ´ĞµĞ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ½Ñ‹Ñ… ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ¼Ğ°Ğ»Ğ¾Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ñ‹Ñ… Ğ²ĞµÑ‚Ğ²ÑÑ… Ğ¸ ÑƒÑĞ¸Ğ»Ğ¸Ñ‚ÑŒ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚Ğ¾Ñ‡ĞºĞ°Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ V-STAR Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¸Ñ… Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑÑ… Ğ½Ğ° Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºÑƒ."
                },
                "en": {
                    "title": "Enhancing Generative Recommendations with V-STAR: Smart Exploration and Learning",
                    "desc": "V-STAR is a novel framework designed to enhance generative recommendation systems by addressing common issues in exploration and reward signal quality. It combines value-guided decoding with tree-structured advantage reinforcement to improve the decision-making process in recommendation tasks. By using Value-Guided Efficient Decoding, V-STAR efficiently explores high-potential options while avoiding the pitfalls of traditional decoding methods that can overlook valuable items. Additionally, the Sibling-GRPO component refines the learning process by focusing on relative advantages among similar options, leading to better performance in both accuracy and diversity of recommendations."
                },
                "zh": {
                    "title": "V-STARï¼šæå‡ç”Ÿæˆæ¨èçš„æ¢ç´¢ä¸å¥–åŠ±è´¨é‡",
                    "desc": "V-STARæ˜¯ä¸€ç§æ–°é¢–çš„ç”Ÿæˆæ¨èæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•ä¸­çš„æ¢ç´¢ä¸è¶³å’Œå¥–åŠ±ä¿¡å·è´¨é‡ä½çš„é—®é¢˜ã€‚å®ƒç»“åˆäº†ä»·å€¼å¼•å¯¼è§£ç å’Œæ ‘ç»“æ„ä¼˜åŠ¿å¼ºåŒ–å­¦ä¹ ï¼Œå½¢æˆä¸€ä¸ªè‡ªæˆ‘æ¼”åŒ–çš„å¾ªç¯ã€‚é€šè¿‡ä»·å€¼å¼•å¯¼é«˜æ•ˆè§£ç ï¼ŒV-STARèƒ½å¤Ÿè¯†åˆ«å…³é”®èŠ‚ç‚¹å¹¶é€‰æ‹©æ€§åœ°æ·±å…¥é«˜æ½œåŠ›çš„å‰ç¼€ï¼Œä»è€Œæé«˜æ¢ç´¢æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒV-STARåœ¨å‡†ç¡®æ€§å’Œå€™é€‰é›†å¤šæ ·æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚"
                }
            }
        }
    ],
    "link_prev": "2026-02-11.html",
    "link_next": "2026-02-13.html",
    "link_month": "2026-02.html",
    "short_date_prev": {
        "ru": "11.02",
        "en": "02/11",
        "zh": "2æœˆ11æ—¥"
    },
    "short_date_next": {
        "ru": "13.02",
        "en": "02/13",
        "zh": "2æœˆ13æ—¥"
    },
    "categories": {
        "#dataset": 4,
        "#data": 1,
        "#benchmark": 7,
        "#agents": 5,
        "#cv": 1,
        "#rl": 4,
        "#rlhf": 2,
        "#rag": 0,
        "#plp": 0,
        "#inference": 3,
        "#3d": 0,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 3,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 7,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 5,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 2,
        "#optimization": 5,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 1,
        "#low_resource": 0
    }
}