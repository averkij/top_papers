{
    "date": {
        "ru": "4 февраля",
        "en": "February 4",
        "zh": "2月4日"
    },
    "time_utc": "2025-02-04 04:12",
    "weekday": 1,
    "issue_id": 2018,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.00094",
            "title": "AIN: The Arabic INclusive Large Multimodal Model",
            "url": "https://huggingface.co/papers/2502.00094",
            "abstract": "Amid the swift progress of large language models (LLMs) and their evolution into large multimodal models (LMMs), significant strides have been made in high-resource languages such as English and Chinese. While Arabic LLMs have seen notable progress, Arabic LMMs remain largely unexplored, often narrowly focusing on a few specific aspects of the language and visual understanding. To bridge this gap, we introduce AIN-the Arabic Inclusive Multimodal Model-designed to excel across diverse domains. AIN is an English-Arabic bilingual LMM designed to excel in English and Arabic, leveraging carefully constructed 3.6 million high-quality Arabic-English multimodal data samples. AIN demonstrates state-of-the-art Arabic performance, while also possessing strong English-language visual capabilities. On the recent CAMEL-Bench benchmark comprising 38 sub-domains including, multi-image understanding, complex visual perception, handwritten document understanding, video understanding, medical imaging, plant diseases, and remote sensing-based land use understanding, our AIN demonstrates strong performance with the 7B model outperforming GPT-4o by an absolute gain of 3.4% averaged over eight domains and 38 sub-domains. AIN's superior capabilities position it as a significant step toward empowering Arabic speakers with advanced multimodal generative AI tools across diverse applications.",
            "score": 3,
            "issue_id": 2018,
            "pub_date": "2025-01-31",
            "pub_date_card": {
                "ru": "31 января",
                "en": "January 31",
                "zh": "1月31日"
            },
            "hash": "e2d63540ee133732",
            "authors": [
                "Ahmed Heakl",
                "Sara Ghaboura",
                "Omkar Thawkar",
                "Fahad Shahbaz Khan",
                "Hisham Cholakkal",
                "Rao Muhammad Anwer",
                "Salman Khan"
            ],
            "affiliations": [
                "Aalto University",
                "Australian National University",
                "Linköping University",
                "Mohamed bin Zayed University of AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.00094.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#low_resource",
                    "#multimodal",
                    "#multilingual"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "AIN: Прорыв в арабоязычном мультимодальном ИИ",
                    "desc": "Представлена модель AIN - двуязычная мультимодальная языковая модель для арабского и английского языков. Модель обучена на 3,6 миллионах высококачественных мультимодальных арабско-английских образцов данных. AIN демонстрирует передовые результаты в арабском языке, сохраняя при этом сильные визуальные возможности для английского. На бенчмарке CAMEL-Bench, охватывающем 38 поддоменов, 7B-версия AIN превосходит GPT-4o на 3,4% в среднем по восьми доменам."
                },
                "en": {
                    "title": "Empowering Arabic with Advanced Multimodal AI",
                    "desc": "This paper presents AIN, the Arabic Inclusive Multimodal Model, which is designed to enhance the performance of large multimodal models (LMMs) specifically for Arabic and English. AIN utilizes a substantial dataset of 3.6 million high-quality Arabic-English multimodal samples to achieve state-of-the-art results in Arabic language tasks. The model excels across various domains, as evidenced by its performance on the CAMEL-Bench benchmark, where it surpasses GPT-4o in multiple sub-domains. AIN aims to provide advanced generative AI tools for Arabic speakers, addressing the current limitations in Arabic multimodal understanding."
                },
                "zh": {
                    "title": "推动阿拉伯语多模态AI的进步",
                    "desc": "随着大型语言模型（LLMs）和多模态模型（LMMs）的快速发展，阿拉伯语的研究仍然相对滞后。我们提出了AIN模型，这是一个旨在提升阿拉伯语和英语的多模态模型，利用了360万高质量的阿拉伯语-英语多模态数据样本。AIN在多个领域表现出色，尤其是在复杂的视觉理解和多图像理解方面，超越了现有的GPT-4o模型。该模型的优越性能为阿拉伯语使用者提供了先进的多模态生成AI工具，推动了相关应用的发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01441",
            "title": "Improved Training Technique for Latent Consistency Models",
            "url": "https://huggingface.co/papers/2502.01441",
            "abstract": "Consistency models are a new family of generative models capable of producing high-quality samples in either a single step or multiple steps. Recently, consistency models have demonstrated impressive performance, achieving results on par with diffusion models in the pixel space. However, the success of scaling consistency training to large-scale datasets, particularly for text-to-image and video generation tasks, is determined by performance in the latent space. In this work, we analyze the statistical differences between pixel and latent spaces, discovering that latent data often contains highly impulsive outliers, which significantly degrade the performance of iCT in the latent space. To address this, we replace Pseudo-Huber losses with Cauchy losses, effectively mitigating the impact of outliers. Additionally, we introduce a diffusion loss at early timesteps and employ optimal transport (OT) coupling to further enhance performance. Lastly, we introduce the adaptive scaling-c scheduler to manage the robust training process and adopt Non-scaling LayerNorm in the architecture to better capture the statistics of the features and reduce outlier impact. With these strategies, we successfully train latent consistency models capable of high-quality sampling with one or two steps, significantly narrowing the performance gap between latent consistency and diffusion models. The implementation is released here: https://github.com/quandao10/sLCT/",
            "score": 0,
            "issue_id": 2018,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "2ea077ca6fd7397f",
            "authors": [
                "Quan Dao",
                "Khanh Doan",
                "Di Liu",
                "Trung Le",
                "Dimitris Metaxas"
            ],
            "affiliations": [
                "Monash University",
                "Rutgers University",
                "VinAI Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01441.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#training",
                    "#optimization",
                    "#architecture",
                    "#open_source",
                    "#diffusion",
                    "#video"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Преодоление выбросов в латентном пространстве для улучшения консистентных моделей",
                    "desc": "Эта статья представляет новый подход к обучению консистентных моделей в латентном пространстве для генеративных задач. Авторы обнаружили, что латентные данные часто содержат импульсивные выбросы, которые ухудшают производительность iCT. Для решения этой проблемы они предложили использовать функцию потерь Коши вместо Псевдо-Хубера, а также ввели диффузионные потери на ранних временных шагах и применили оптимальный транспорт. Эти стратегии позволили успешно обучить латентные консистентные модели, способные к высококачественному сэмплированию за один-два шага."
                },
                "en": {
                    "title": "Enhancing Latent Consistency Models for High-Quality Generation",
                    "desc": "This paper introduces advancements in consistency models, a type of generative model that can create high-quality outputs efficiently. The authors focus on improving performance in latent spaces, where data often contains outliers that hinder model effectiveness. By replacing traditional loss functions with Cauchy losses and incorporating diffusion loss, they enhance the model's robustness against these outliers. Additionally, they propose an adaptive scaling-c scheduler and Non-scaling LayerNorm to optimize training, resulting in latent consistency models that perform comparably to diffusion models in generating images and videos."
                },
                "zh": {
                    "title": "提升一致性模型性能的创新方法",
                    "desc": "一致性模型是一种新型生成模型，能够在单步或多步中生成高质量样本。最近，这些模型在像素空间中表现出色，达到了与扩散模型相当的效果。然而，在大规模数据集上进行一致性训练的成功，尤其是在文本到图像和视频生成任务中，取决于潜在空间的表现。为了解决潜在数据中的异常值对性能的影响，本文提出了使用Cauchy损失替代伪Huber损失，并引入扩散损失和最优传输方法，以提高模型的鲁棒性和性能。"
                }
            }
        }
    ],
    "link_prev": "2025-02-03.html",
    "link_next": "2025-02-05.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "03.02",
        "en": "02/03",
        "zh": "2月3日"
    },
    "short_date_next": {
        "ru": "05.02",
        "en": "02/05",
        "zh": "2月5日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 0,
        "#benchmark": 1,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "这篇文章介绍了一种新的语言建模方法，称为测试时缩放。OpenAI的o1模型展示了这种能力，但没有公开其方法，导致许多复制努力。作者通过整理一个小数据集s1K和开发预算强制方法，寻找最简单的途径实现测试时缩放和强大的推理性能。他们的模型s1在数学竞赛问题上超越了o1-preview，并且通过预算强制进一步提升了性能。模型、数据和代码都是开源的。",
        "title": "s1: Simple test-time scaling",
        "pinyin": "这篇文章介绍了一种新的语言建模方法，称为测试时缩放。OpenAI的o1模型展示了这种能力，但没有公开其方法，导致许多复制努力。作者通过整理一个小数据集s1K和开发预算强制方法，寻找最简单的途径实现测试时缩放和强大的推理性能。他们的模型s1在数学竞赛问题上超越了o1-preview，并且通过预算强制进一步提升了性能。模型、数据和代码都是开源的。\n\nZhè piān wénzhāng jièshào le yīzhǒng xīn de yǔyán jiànmó fāngfǎ, chēngwéi cèshì shí suōfàng. OpenAI de o1 móxíng zhǎnshì le zhè zhǒng nénglì, dàn méiyǒu gōngkāi qí fāngfǎ, dǎozhì xǔduō fùzhì nǔlì. Zuòzhě tōngguò zhěnglǐ yīgè xiǎo shùjùjí s1K hé kāifā yùsuàn qiángzhì fāngfǎ, xúnzhǎo zuì jiǎndān de tújìng shíxiàn cèshì shí suōfàng hé qiángdà de tuīlǐ xìngnéng. Tāmen de móxíng s1 zài shùxué jìngsài wèntí shàng chāoyuè le o1-preview, bìngqiě tōngguò yùsuàn qiángzhì jìnfā tīshēng le xìngnéng. Móxíng, shùjù hé dàimǎ dōu shì kāiyuán de.",
        "vocab": "[\n{'word': '建模', 'pinyin': 'jiàn mó', 'trans': 'modeling'},\n{'word': '称为', 'pinyin': 'chēng wéi', 'trans': 'called'},\n{'word': '缩放', 'pinyin': 'suō fàng', 'trans': 'scaling'},\n{'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'},\n{'word': '能力', 'pinyin': 'néng lì', 'trans': 'capability'},\n{'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'},\n{'word': '复制', 'pinyin': 'fù zhì', 'trans': 'replicate'},\n{'word': '努力', 'pinyin': 'nǔ lì', 'trans': 'efforts'},\n{'word': '整理', 'pinyin': 'zhěng lǐ', 'trans': 'organize'},\n{'word': '预算', 'pinyin': 'yù suàn', 'trans': 'budget'},\n{'word': '强制', 'pinyin': 'qiáng zhì', 'trans': 'enforcement'},\n{'word': '途径', 'pinyin': 'tú jìng', 'trans': 'means'},\n{'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'},\n{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'},\n{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},\n{'word': '超越', 'pinyin': 'chāo yuè', 'trans': 'surpass'},\n{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'}\n]",
        "trans": "This article introduces a new language modeling method called test-time scaling. The o1 model from OpenAI demonstrated this capability, but its method was not made public, leading to many attempts to replicate it. The authors, by curating a small dataset s1K and developing a budget enforcement method, sought the simplest way to achieve test-time scaling and powerful reasoning performance. Their model, s1, outperformed o1-preview on mathematical competition problems and further enhanced performance through budget enforcement. The model, data, and code are all open-sourced.",
        "update_ts": "2025-02-03 09:11"
    }
}