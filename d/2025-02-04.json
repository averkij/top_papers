{
    "date": {
        "ru": "4 февраля",
        "en": "February 4",
        "zh": "2月4日"
    },
    "time_utc": "2025-02-04 07:10",
    "weekday": 1,
    "issue_id": 2021,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.01456",
            "title": "Process Reinforcement through Implicit Rewards",
            "url": "https://huggingface.co/papers/2502.01456",
            "abstract": "Dense process rewards have proven a more effective alternative to the sparse outcome-level rewards in the inference-time scaling of large language models (LLMs), particularly in tasks requiring complex multi-step reasoning. While dense rewards also offer an appealing choice for the reinforcement learning (RL) of LLMs since their fine-grained rewards have the potential to address some inherent issues of outcome rewards, such as training efficiency and credit assignment, this potential remains largely unrealized. This can be primarily attributed to the challenges of training process reward models (PRMs) online, where collecting high-quality process labels is prohibitively expensive, making them particularly vulnerable to reward hacking. To address these challenges, we propose PRIME (Process Reinforcement through IMplicit rEwards), which enables online PRM updates using only policy rollouts and outcome labels through implict process rewards. PRIME combines well with various advantage functions and forgoes the dedicated reward model training phrase that existing approaches require, substantially reducing the development overhead. We demonstrate PRIME's effectiveness on competitional math and coding. Starting from Qwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several key reasoning benchmarks over the SFT model. Notably, our resulting model, Eurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning benchmarks with 10% of its training data.",
            "score": 17,
            "issue_id": 2019,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "9d62c40e4bafac91",
            "authors": [
                "Ganqu Cui",
                "Lifan Yuan",
                "Zefan Wang",
                "Hanbin Wang",
                "Wendi Li",
                "Bingxiang He",
                "Yuchen Fan",
                "Tianyu Yu",
                "Qixin Xu",
                "Weize Chen",
                "Jiarui Yuan",
                "Huayu Chen",
                "Kaiyan Zhang",
                "Xingtai Lv",
                "Shuo Wang",
                "Yuan Yao",
                "Xu Han",
                "Hao Peng",
                "Yu Cheng",
                "Zhiyuan Liu",
                "Maosong Sun",
                "Bowen Zhou",
                "Ning Ding"
            ],
            "affiliations": [
                "Peking University",
                "Shanghai AI Lab",
                "Shanghai Jiaotong University",
                "Tsinghua University",
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01456.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "PRIME: Эффективное обучение ИИ-моделей с неявными процессными наградами",
                    "desc": "Эта статья представляет новый метод обучения с подкреплением для больших языковых моделей, называемый PRIME. Он использует неявные процессные награды, что позволяет обновлять модели вознаграждения процесса в режиме онлайн, используя только развертывания политики и метки результатов. PRIME решает проблемы обучения с плотными наградами, такие как уязвимость к взлому наград и высокая стоимость сбора качественных меток процесса. Метод показал значительное улучшение производительности на задачах рассуждения по сравнению с базовыми моделями, используя при этом меньше данных для обучения."
                },
                "en": {
                    "title": "Unlocking LLM Potential with PRIME: Efficient Training through Implicit Rewards",
                    "desc": "This paper introduces PRIME, a method that enhances the training of large language models (LLMs) using dense process rewards instead of traditional sparse outcome rewards. Dense rewards help improve training efficiency and address credit assignment issues, but collecting high-quality process labels has been a challenge. PRIME allows for online updates of process reward models using only policy rollouts and outcome labels, which reduces the need for extensive reward model training. The results show that PRIME significantly improves reasoning performance in tasks like math and coding, achieving better results with less training data compared to existing models."
                },
                "zh": {
                    "title": "PRIME：提升大语言模型推理效率的新方法",
                    "desc": "本文提出了一种新的方法PRIME（通过隐式奖励进行过程强化学习），旨在解决大语言模型（LLMs）在复杂多步骤推理任务中的训练效率问题。传统的稀疏结果奖励在训练过程中存在效率低下和信用分配等问题，而PRIME通过仅使用策略回滚和结果标签来实现在线过程奖励模型（PRM）的更新。该方法避免了现有方法中需要的专门奖励模型训练阶段，从而显著降低了开发成本。实验结果表明，PRIME在数学和编码竞赛任务中表现出色，相较于传统模型有显著提升。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01534",
            "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
            "url": "https://huggingface.co/papers/2502.01534",
            "abstract": "Large Language Models (LLMs) as judges and LLM-based data synthesis have emerged as two fundamental LLM-driven data annotation methods in model development. While their combination significantly enhances the efficiency of model training and evaluation, little attention has been given to the potential contamination brought by this new model development paradigm. In this work, we expose preference leakage, a contamination problem in LLM-as-a-judge caused by the relatedness between the synthetic data generators and LLM-based evaluators. To study this issue, we first define three common relatednesses between data generator LLM and judge LLM: being the same model, having an inheritance relationship, and belonging to the same model family. Through extensive experiments, we empirically confirm the bias of judges towards their related student models caused by preference leakage across multiple LLM baselines and benchmarks. Further analysis suggests that preference leakage is a pervasive issue that is harder to detect compared to previously identified biases in LLM-as-a-judge scenarios. All of these findings imply that preference leakage is a widespread and challenging problem in the area of LLM-as-a-judge. We release all codes and data at: https://github.com/David-Li0406/Preference-Leakage.",
            "score": 7,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "d2508b2b8b82b41b",
            "authors": [
                "Dawei Li",
                "Renliang Sun",
                "Yue Huang",
                "Ming Zhong",
                "Bohan Jiang",
                "Jiawei Han",
                "Xiangliang Zhang",
                "Wei Wang",
                "Huan Liu"
            ],
            "affiliations": [
                "Arizona State University",
                "University of California, Los Angeles",
                "University of Illinois Urbana Champaign",
                "University of Notre Dame"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01534.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#open_source",
                    "#training",
                    "#dataset",
                    "#leakage"
                ],
                "emoji": "🕵️",
                "ru": {
                    "title": "Осторожно: LLM-судьи могут быть предвзяты!",
                    "desc": "Исследование выявляет проблему 'утечки предпочтений' при использовании больших языковых моделей (LLM) в качестве судей для оценки других моделей. Эта проблема возникает из-за связанности между генераторами синтетических данных и LLM-оценщиками. Эксперименты подтверждают предвзятость судей к связанным с ними моделям-ученикам на различных базовых моделях и эталонных тестах. Результаты указывают на то, что утечка предпочтений является распространенной и трудно обнаруживаемой проблемой в области использования LLM в качестве судей."
                },
                "en": {
                    "title": "Uncovering Preference Leakage: A Hidden Bias in LLM Evaluation",
                    "desc": "This paper discusses a problem called preference leakage in the context of using Large Language Models (LLMs) as judges for data annotation. Preference leakage occurs when the relationship between the data generators and the evaluators leads to biased evaluations, particularly when they are similar or related models. The authors identify three types of relatedness that can cause this issue and demonstrate through experiments that judges show bias towards their related models. The findings highlight that preference leakage is a significant and often unnoticed challenge in LLM-based model development."
                },
                "zh": {
                    "title": "偏好泄漏：LLM评判中的隐患",
                    "desc": "本文探讨了大型语言模型（LLM）作为评判者和基于LLM的数据合成在模型开发中的应用。我们揭示了偏好泄漏这一问题，它是由合成数据生成器与LLM评估者之间的相关性引起的。通过定义三种常见的相关性，我们进行了广泛的实验，证实了评判者对其相关学生模型的偏见。研究表明，偏好泄漏是一个普遍存在且难以检测的问题，影响了LLM作为评判者的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01068",
            "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation",
            "url": "https://huggingface.co/papers/2502.01068",
            "abstract": "While large language models (LLMs) excel at handling long-context sequences, they require substantial key-value (KV) caches to store contextual information, which can heavily burden computational efficiency and memory usage. Previous efforts to compress these KV caches primarily focused on reducing memory demands but were limited in enhancing latency. To address this issue, we introduce FastKV, a KV cache compression method designed to enhance latency for long-context sequences. To enhance processing speeds while maintaining accuracy, FastKV adopts a novel Token-Selective Propagation (TSP) approach that retains the full context information in the initial layers of LLMs and selectively propagates only a portion of this information in deeper layers even in the prefill stage. Additionally, FastKV incorporates grouped-query attention (GQA)-aware KV cache compression to exploit the advantages of GQA in both memory and computational efficiency. Our experimental results show that FastKV achieves 2.00times and 1.40times improvements in time-to-first-token (TTFT) and throughput, respectively, compared to HeadKV, the state-of-the-art KV cache compression method. Moreover, FastKV successfully maintains accuracy on long-context benchmarks at levels comparable to the baselines. Our code is available at https://github.com/dongwonjo/FastKV.",
            "score": 6,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "58ab72f123d7a4b6",
            "authors": [
                "Dongwon Jo",
                "Jiwon Song",
                "Yulhwa Kim",
                "Jae-Joon Kim"
            ],
            "affiliations": [
                "Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea",
                "Department of Semiconductor Systems Engineering, Sungkyunkwan University, Suwon, South Korea"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01068.jpg",
            "data": {
                "categories": [
                    "#long_context",
                    "#training",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "FastKV: Ускорение обработки длинных последовательностей в LLM",
                    "desc": "Статья представляет FastKV - новый метод сжатия кэша ключ-значение (KV) для больших языковых моделей (LLM), направленный на улучшение латентности при обработке длинных последовательностей. FastKV использует подход Token-Selective Propagation (TSP), который сохраняет полную контекстную информацию в начальных слоях LLM и выборочно распространяет только часть этой информации в более глубоких слоях. Метод также включает сжатие кэша KV с учетом grouped-query attention (GQA) для повышения эффективности памяти и вычислений. Эксперименты показывают, что FastKV достигает значительного улучшения времени до первого токена и пропускной способности по сравнению с современными методами, сохраняя при этом точность на уровне базовых показателей."
                },
                "en": {
                    "title": "FastKV: Speeding Up Long-Context Processing in LLMs",
                    "desc": "This paper presents FastKV, a new method for compressing key-value (KV) caches in large language models (LLMs) to improve computational efficiency and reduce latency. FastKV uses a Token-Selective Propagation (TSP) strategy that keeps full context information in the early layers of the model while selectively passing on only part of this information in the deeper layers. Additionally, it employs grouped-query attention (GQA) to enhance both memory usage and processing speed. Experimental results demonstrate that FastKV significantly improves time-to-first-token and throughput while maintaining accuracy on long-context tasks."
                },
                "zh": {
                    "title": "FastKV：提升长上下文处理速度的创新方法",
                    "desc": "本文介绍了一种名为FastKV的KV缓存压缩方法，旨在提高长上下文序列的处理速度。FastKV采用了一种新颖的选择性传播方法（TSP），在LLM的初始层保留完整的上下文信息，而在更深层次中仅选择性传播部分信息。该方法还结合了分组查询注意力（GQA）来优化内存和计算效率。实验结果表明，FastKV在首次令牌时间和吞吐量方面分别比现有的HeadKV方法提高了2.00倍和1.40倍，同时在长上下文基准测试中保持了与基线相当的准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.00094",
            "title": "AIN: The Arabic INclusive Large Multimodal Model",
            "url": "https://huggingface.co/papers/2502.00094",
            "abstract": "Amid the swift progress of large language models (LLMs) and their evolution into large multimodal models (LMMs), significant strides have been made in high-resource languages such as English and Chinese. While Arabic LLMs have seen notable progress, Arabic LMMs remain largely unexplored, often narrowly focusing on a few specific aspects of the language and visual understanding. To bridge this gap, we introduce AIN-the Arabic Inclusive Multimodal Model-designed to excel across diverse domains. AIN is an English-Arabic bilingual LMM designed to excel in English and Arabic, leveraging carefully constructed 3.6 million high-quality Arabic-English multimodal data samples. AIN demonstrates state-of-the-art Arabic performance, while also possessing strong English-language visual capabilities. On the recent CAMEL-Bench benchmark comprising 38 sub-domains including, multi-image understanding, complex visual perception, handwritten document understanding, video understanding, medical imaging, plant diseases, and remote sensing-based land use understanding, our AIN demonstrates strong performance with the 7B model outperforming GPT-4o by an absolute gain of 3.4% averaged over eight domains and 38 sub-domains. AIN's superior capabilities position it as a significant step toward empowering Arabic speakers with advanced multimodal generative AI tools across diverse applications.",
            "score": 6,
            "issue_id": 2018,
            "pub_date": "2025-01-31",
            "pub_date_card": {
                "ru": "31 января",
                "en": "January 31",
                "zh": "1月31日"
            },
            "hash": "e2d63540ee133732",
            "authors": [
                "Ahmed Heakl",
                "Sara Ghaboura",
                "Omkar Thawkar",
                "Fahad Shahbaz Khan",
                "Hisham Cholakkal",
                "Rao Muhammad Anwer",
                "Salman Khan"
            ],
            "affiliations": [
                "Aalto University",
                "Australian National University",
                "Linköping University",
                "Mohamed bin Zayed University of AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.00094.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#low_resource",
                    "#multimodal",
                    "#multilingual"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "AIN: Прорыв в арабоязычном мультимодальном ИИ",
                    "desc": "Представлена модель AIN - двуязычная мультимодальная языковая модель для арабского и английского языков. Модель обучена на 3,6 миллионах высококачественных мультимодальных арабско-английских образцов данных. AIN демонстрирует передовые результаты в арабском языке, сохраняя при этом сильные визуальные возможности для английского. На бенчмарке CAMEL-Bench, охватывающем 38 поддоменов, 7B-версия AIN превосходит GPT-4o на 3,4% в среднем по восьми доменам."
                },
                "en": {
                    "title": "Empowering Arabic with Advanced Multimodal AI",
                    "desc": "This paper presents AIN, the Arabic Inclusive Multimodal Model, which is designed to enhance the performance of large multimodal models (LMMs) specifically for Arabic and English. AIN utilizes a substantial dataset of 3.6 million high-quality Arabic-English multimodal samples to achieve state-of-the-art results in Arabic language tasks. The model excels across various domains, as evidenced by its performance on the CAMEL-Bench benchmark, where it surpasses GPT-4o in multiple sub-domains. AIN aims to provide advanced generative AI tools for Arabic speakers, addressing the current limitations in Arabic multimodal understanding."
                },
                "zh": {
                    "title": "推动阿拉伯语多模态AI的进步",
                    "desc": "随着大型语言模型（LLMs）和多模态模型（LMMs）的快速发展，阿拉伯语的研究仍然相对滞后。我们提出了AIN模型，这是一个旨在提升阿拉伯语和英语的多模态模型，利用了360万高质量的阿拉伯语-英语多模态数据样本。AIN在多个领域表现出色，尤其是在复杂的视觉理解和多图像理解方面，超越了现有的GPT-4o模型。该模型的优越性能为阿拉伯语使用者提供了先进的多模态生成AI工具，推动了相关应用的发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01061",
            "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models",
            "url": "https://huggingface.co/papers/2502.01061",
            "abstract": "End-to-end human animation, such as audio-driven talking human generation, has undergone notable advancements in the recent few years. However, existing methods still struggle to scale up as large general video generation models, limiting their potential in real applications. In this paper, we propose OmniHuman, a Diffusion Transformer-based framework that scales up data by mixing motion-related conditions into the training phase. To this end, we introduce two training principles for these mixed conditions, along with the corresponding model architecture and inference strategy. These designs enable OmniHuman to fully leverage data-driven motion generation, ultimately achieving highly realistic human video generation. More importantly, OmniHuman supports various portrait contents (face close-up, portrait, half-body, full-body), supports both talking and singing, handles human-object interactions and challenging body poses, and accommodates different image styles. Compared to existing end-to-end audio-driven methods, OmniHuman not only produces more realistic videos, but also offers greater flexibility in inputs. It also supports multiple driving modalities (audio-driven, video-driven and combined driving signals). Video samples are provided on the ttfamily project page (https://omnihuman-lab.github.io)",
            "score": 4,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "56b819a66e336562",
            "authors": [
                "Gaojie Lin",
                "Jianwen Jiang",
                "Jiaqi Yang",
                "Zerong Zheng",
                "Chao Liang"
            ],
            "affiliations": [
                "ByteDance"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01061.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#architecture",
                    "#video",
                    "#training",
                    "#diffusion"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "OmniHuman: универсальная модель для генерации реалистичных видео с людьми",
                    "desc": "OmniHuman - это новая модель на основе Diffusion Transformer для генерации реалистичных видео с людьми. Она использует смешанные условия движения при обучении, что позволяет масштабировать данные и улучшить качество генерации. Модель поддерживает различные типы портретов, взаимодействие с объектами и сложные позы тела. OmniHuman может генерировать видео на основе аудио, видео или комбинированных сигналов управления."
                },
                "en": {
                    "title": "OmniHuman: Revolutionizing Realistic Human Animation Generation",
                    "desc": "The paper presents OmniHuman, a new framework for generating realistic human animations from audio inputs. It utilizes a Diffusion Transformer architecture that enhances the training process by incorporating motion-related conditions, allowing for better scalability in video generation. OmniHuman is designed to handle various types of human portraits and interactions, producing high-quality videos that can depict talking, singing, and complex body movements. This approach not only improves the realism of the generated videos but also increases flexibility by supporting multiple input modalities such as audio and video."
                },
                "zh": {
                    "title": "OmniHuman：灵活真实的人类动画生成",
                    "desc": "本文提出了一种名为OmniHuman的框架，旨在提升人类动画生成的质量和灵活性。该框架基于扩散变换器，通过在训练阶段混合与运动相关的条件来扩展数据规模。OmniHuman支持多种人像内容和不同的驱动模式，如音频驱动和视频驱动，能够生成高度真实的人类视频。与现有方法相比，OmniHuman不仅生成更真实的视频，还提供了更大的输入灵活性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01081",
            "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
            "url": "https://huggingface.co/papers/2502.01081",
            "abstract": "The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, o3 outperformed humans in novel problem-solving and skill acquisition on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI). However, this benchmark is limited to symbolic patterns, whereas humans often perceive and reason about multimodal scenarios involving both vision and language data. Thus, there is an urgent need to investigate advanced reasoning capabilities in multimodal tasks. To this end, we track the evolution of the GPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring fine-grained visual perception with abstract or algorithmic reasoning. The superior performance of o1 comes at nearly 750 times the computational cost of GPT-4o, raising concerns about its efficiency. Our results reveal a clear upward trend in reasoning capabilities across model iterations, with notable performance jumps across GPT-series models and subsequently to o1. Nonetheless, we observe that the o1 model still struggles with simple multimodal puzzles requiring abstract reasoning. Furthermore, its performance in algorithmic puzzles remains poor. We plan to continuously track new models in the series and update our results in this paper accordingly. All resources used in this evaluation are openly available https://github.com/declare-lab/LLM-PuzzleTest.",
            "score": 3,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "7585b424ff041825",
            "authors": [
                "Vernon Y. H. Toh",
                "Yew Ken Chia",
                "Deepanway Ghosal",
                "Soujanya Poria"
            ],
            "affiliations": [
                "Singapore University of Technology and Design (SUTD)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01081.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#benchmark",
                    "#agi",
                    "#open_source",
                    "#training",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эволюция рассуждений: от символов к мультимодальности",
                    "desc": "Статья рассматривает эволюцию возможностей рассуждения в мультимодальных задачах у языковых моделей серий GPT и OpenAI. Авторы отмечают значительный прогресс модели o3 в решении символических паттернов, но подчеркивают необходимость исследования мультимодальных сценариев. Проводится анализ производительности моделей на сложных визуально-лингвистических головоломках, требующих абстрактного и алгоритмического мышления. Результаты показывают общую тенденцию улучшения способностей к рассуждению, но выявляют сохраняющиеся трудности даже у передовых моделей в некоторых типах задач."
                },
                "en": {
                    "title": "Advancing Reasoning in Multimodal AI: A New Era for LLMs",
                    "desc": "This paper discusses the advancements in Large Language Models (LLMs) with the release of OpenAI's o1 and o3, which show improved reasoning abilities. The o3 model has demonstrated superior problem-solving skills compared to humans on the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI). However, the study highlights that these models primarily focus on symbolic reasoning, while human reasoning often involves multimodal inputs like vision and language. The authors emphasize the need for further research into multimodal reasoning capabilities, as the o1 model, despite its high performance, still faces challenges with simple multimodal and algorithmic puzzles."
                },
                "zh": {
                    "title": "多模态推理能力的探索与挑战",
                    "desc": "本文探讨了OpenAI的o1和o3模型在大型语言模型中的先进推理能力。o3在抽象和推理语料库（ARC-AGI）中超越了人类，表现出色，但该基准仅限于符号模式。人类通常在多模态场景中进行推理，因此需要研究多模态任务中的高级推理能力。尽管o1在推理能力上有所提升，但在简单的多模态难题和算法难题上仍然存在不足。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01441",
            "title": "Improved Training Technique for Latent Consistency Models",
            "url": "https://huggingface.co/papers/2502.01441",
            "abstract": "Consistency models are a new family of generative models capable of producing high-quality samples in either a single step or multiple steps. Recently, consistency models have demonstrated impressive performance, achieving results on par with diffusion models in the pixel space. However, the success of scaling consistency training to large-scale datasets, particularly for text-to-image and video generation tasks, is determined by performance in the latent space. In this work, we analyze the statistical differences between pixel and latent spaces, discovering that latent data often contains highly impulsive outliers, which significantly degrade the performance of iCT in the latent space. To address this, we replace Pseudo-Huber losses with Cauchy losses, effectively mitigating the impact of outliers. Additionally, we introduce a diffusion loss at early timesteps and employ optimal transport (OT) coupling to further enhance performance. Lastly, we introduce the adaptive scaling-c scheduler to manage the robust training process and adopt Non-scaling LayerNorm in the architecture to better capture the statistics of the features and reduce outlier impact. With these strategies, we successfully train latent consistency models capable of high-quality sampling with one or two steps, significantly narrowing the performance gap between latent consistency and diffusion models. The implementation is released here: https://github.com/quandao10/sLCT/",
            "score": 2,
            "issue_id": 2018,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "2ea077ca6fd7397f",
            "authors": [
                "Quan Dao",
                "Khanh Doan",
                "Di Liu",
                "Trung Le",
                "Dimitris Metaxas"
            ],
            "affiliations": [
                "Monash University",
                "Rutgers University",
                "VinAI Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01441.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#training",
                    "#optimization",
                    "#architecture",
                    "#open_source",
                    "#diffusion",
                    "#video"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Преодоление выбросов в латентном пространстве для улучшения консистентных моделей",
                    "desc": "Эта статья представляет новый подход к обучению консистентных моделей в латентном пространстве для генеративных задач. Авторы обнаружили, что латентные данные часто содержат импульсивные выбросы, которые ухудшают производительность iCT. Для решения этой проблемы они предложили использовать функцию потерь Коши вместо Псевдо-Хубера, а также ввели диффузионные потери на ранних временных шагах и применили оптимальный транспорт. Эти стратегии позволили успешно обучить латентные консистентные модели, способные к высококачественному сэмплированию за один-два шага."
                },
                "en": {
                    "title": "Enhancing Latent Consistency Models for High-Quality Generation",
                    "desc": "This paper introduces advancements in consistency models, a type of generative model that can create high-quality outputs efficiently. The authors focus on improving performance in latent spaces, where data often contains outliers that hinder model effectiveness. By replacing traditional loss functions with Cauchy losses and incorporating diffusion loss, they enhance the model's robustness against these outliers. Additionally, they propose an adaptive scaling-c scheduler and Non-scaling LayerNorm to optimize training, resulting in latent consistency models that perform comparably to diffusion models in generating images and videos."
                },
                "zh": {
                    "title": "提升一致性模型性能的创新方法",
                    "desc": "一致性模型是一种新型生成模型，能够在单步或多步中生成高质量样本。最近，这些模型在像素空间中表现出色，达到了与扩散模型相当的效果。然而，在大规模数据集上进行一致性训练的成功，尤其是在文本到图像和视频生成任务中，取决于潜在空间的表现。为了解决潜在数据中的异常值对性能的影响，本文提出了使用Cauchy损失替代伪Huber损失，并引入扩散损失和最优传输方法，以提高模型的鲁棒性和性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01100",
            "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
            "url": "https://huggingface.co/papers/2502.01100",
            "abstract": "We investigate the logical reasoning capabilities of large language models (LLMs) and their scalability in complex non-monotonic reasoning. To this end, we introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM reasoning performance on logic grid puzzles derived from constraint satisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with controllable and quantifiable complexity, facilitating a systematic study of the scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By encompassing a broad range of search space complexities and diverse logical constraints, ZebraLogic provides a structured environment to evaluate reasoning under increasing difficulty.   Our results reveal a significant decline in accuracy as problem complexity grows -- a phenomenon we term the curse of complexity. This limitation persists even with larger models and increased inference-time computation, suggesting inherent constraints in current LLM reasoning capabilities. Additionally, we explore strategies to enhance logical reasoning, including Best-of-N sampling, backtracking mechanisms, and self-verification prompts. Our findings offer critical insights into the scalability of LLM reasoning, highlight fundamental limitations, and outline potential directions for improvement.",
            "score": 1,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "901fd196d7bfe394",
            "authors": [
                "Bill Yuchen Lin",
                "Ronan Le Bras",
                "Kyle Richardson",
                "Ashish Sabharwal",
                "Radha Poovendran",
                "Peter Clark",
                "Yejin Choi"
            ],
            "affiliations": [
                "Allen Institute for AI",
                "Stanford University",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01100.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#inference",
                    "#benchmark"
                ],
                "emoji": "🧩",
                "ru": {
                    "title": "Проклятие сложности в логическом мышлении LLM",
                    "desc": "В статье исследуются возможности логического рассуждения больших языковых моделей (LLM) и их масштабируемость в сложных задачах немонотонного вывода. Для этого представлена ZebraLogic, комплексная система оценки производительности LLM на логических головоломках, основанных на задачах удовлетворения ограничений (CSP). ZebraLogic позволяет генерировать головоломки с контролируемой сложностью, что помогает систематически изучать пределы масштабируемости моделей, таких как Llama и DeepSeek-R1. Результаты показывают значительное снижение точности по мере увеличения сложности задач, что авторы называют \"проклятием сложности\"."
                },
                "en": {
                    "title": "Unraveling the Limits of Logical Reasoning in Large Language Models",
                    "desc": "This paper examines how well large language models (LLMs) can perform logical reasoning, especially in complex scenarios where reasoning does not follow a straightforward path. The authors introduce ZebraLogic, a new framework designed to evaluate LLMs on logic grid puzzles that are based on constraint satisfaction problems (CSPs). Through this framework, they discover that as the complexity of the puzzles increases, the accuracy of the models significantly decreases, a challenge they refer to as the 'curse of complexity.' The study also suggests methods to improve reasoning capabilities, such as using advanced sampling techniques and self-verification prompts, while highlighting the limitations of current LLMs in handling complex reasoning tasks."
                },
                "zh": {
                    "title": "揭示大型语言模型推理能力的复杂性挑战",
                    "desc": "本文研究了大型语言模型（LLMs）的逻辑推理能力及其在复杂非单调推理中的可扩展性。我们引入了ZebraLogic，一个全面的评估框架，用于评估LLM在基于约束满足问题（CSPs）的逻辑网格谜题上的推理表现。研究结果显示，随着问题复杂性的增加，模型的准确性显著下降，这一现象被称为复杂性诅咒。我们还探讨了增强逻辑推理的策略，包括最佳采样、回溯机制和自我验证提示。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01636",
            "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
            "url": "https://huggingface.co/papers/2502.01636",
            "abstract": "Prior work in parameter-modifying knowledge editing has shown that large-scale sequential editing leads to significant model degradation. In this paper, we study the reasons behind this and scale sequential knowledge editing to 10,000 sequential edits, while maintaining the downstream performance of the original model. We first show that locate-then-edit knowledge editing methods lead to overfitting on the edited facts. We also show that continuous knowledge editing using these methods leads to disproportionate growth in the norm of the edited matrix. We then provide a crucial insight into the inner workings of locate-then-edit methods. We show that norm-growth is a hidden trick employed by these methods that gives larger importance to the output activations produced from the edited layers. With this \"importance hacking\", the edited layers provide a much larger contributions to the model's output. To mitigate these issues, we present ENCORE - Early stopping and Norm-Constrained Robust knowledge Editing. ENCORE controls for overfitting and the disproportionate norm-growth to enable long-term sequential editing, where we are able to perform up to 10,000 sequential edits without loss of downstream performance. ENCORE is also 61% faster than MEMIT and 64% faster than AlphaEdit on Llama3-8B.",
            "score": 0,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "919dd5274b620b3a",
            "authors": [
                "Akshat Gupta",
                "Phudish Prateepamornkul",
                "Maochuan Lu",
                "Ahmed Alaa",
                "Thomas Hartvigsen",
                "Gopala Anumanchipalli"
            ],
            "affiliations": [
                "SCB DataX",
                "University of California, Berkeley",
                "University of Virginia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01636.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#interpretability",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное масштабирование редактирования знаний в нейросетях",
                    "desc": "Статья посвящена улучшению методов последовательного редактирования знаний в больших языковых моделях. Авторы выявили проблемы переобучения и непропорционального роста нормы при использовании существующих методов редактирования. Они предложили новый метод ENCORE, который контролирует переобучение и рост нормы, позволяя выполнять до 10 000 последовательных правок без потери производительности модели. ENCORE также показывает значительное ускорение по сравнению с другими методами редактирования знаний."
                },
                "en": {
                    "title": "ENCORE: Efficient Knowledge Editing Without Degradation",
                    "desc": "This paper investigates the challenges of sequential knowledge editing in machine learning models, particularly focusing on the degradation of model performance after numerous edits. It identifies that traditional locate-then-edit methods can lead to overfitting and excessive growth in the norm of the edited parameters. The authors introduce a new method called ENCORE, which employs early stopping and norm constraints to prevent these issues, allowing for effective long-term editing. ENCORE not only maintains the model's performance after 10,000 edits but also operates significantly faster than existing methods."
                },
                "zh": {
                    "title": "ENCORE：高效的知识编辑解决方案",
                    "desc": "本论文研究了在知识编辑中进行大规模顺序编辑时模型性能下降的原因。我们发现，定位后编辑的方法容易导致对编辑事实的过拟合，并且连续的知识编辑会导致编辑矩阵的范数不成比例地增长。为了解决这些问题，我们提出了ENCORE方法，通过早停和范数约束来控制过拟合和范数增长，从而实现长时间的顺序编辑。ENCORE能够在不损失下游性能的情况下，进行多达10,000次的顺序编辑，并且比现有方法更快。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01637",
            "title": "Scaling Embedding Layers in Language Models",
            "url": "https://huggingface.co/papers/2502.01637",
            "abstract": "We propose SCONE (Scalable, Contextualized, Offloaded, N-gram Embedding), a method for extending input embedding layers to enhance language model performance as layer size scales. To avoid increased decoding costs, SCONE retains the original vocabulary while introducing embeddings for a set of frequent n-grams. These embeddings provide contextualized representation for each input token and are learned with a separate model during training. During inference, they are precomputed and stored in off-accelerator memory with minimal impact on inference speed. SCONE enables two new scaling strategies: increasing the number of cached n-gram embeddings and scaling the model used to learn them, all while maintaining fixed inference-time FLOPS. We show that scaling both aspects allows SCONE to outperform a 1.9B parameter baseline across diverse corpora, while using only half the inference-time FLOPS.",
            "score": 0,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "478a2a0ee08530a8",
            "authors": [
                "Da Yu",
                "Edith Cohen",
                "Badih Ghazi",
                "Yangsibo Huang",
                "Pritish Kamath",
                "Ravi Kumar",
                "Daogao Liu",
                "Chiyuan Zhang"
            ],
            "affiliations": [
                "Google"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01637.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#inference",
                    "#long_context",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Ускорение языковых моделей без увеличения вычислительных затрат",
                    "desc": "SCONE - это новый метод расширения слоёв входных эмбеддингов для улучшения производительности языковых моделей при увеличении размера слоя. Он вводит эмбеддинги для частых n-грамм, обеспечивая контекстуализированное представление для каждого входного токена. Эти эмбеддинги обучаются отдельной моделью и предварительно вычисляются для использования во время инференса. SCONE позволяет масштабировать количество кэшированных n-граммных эмбеддингов и модель для их обучения, сохраняя фиксированное количество FLOPS при инференсе."
                },
                "en": {
                    "title": "Enhancing Language Models with SCONE: Scalable N-gram Embeddings for Better Performance",
                    "desc": "SCONE (Scalable, Contextualized, Offloaded, N-gram Embedding) is a novel approach designed to improve the performance of language models as they grow in size. It introduces embeddings for common n-grams while keeping the original vocabulary intact, which helps in providing better contextual representations for input tokens. These n-gram embeddings are learned through a separate model during training and stored in off-accelerator memory to ensure fast inference. By scaling both the number of cached n-gram embeddings and the model that learns them, SCONE achieves superior performance compared to a large baseline model while maintaining efficient inference-time computations."
                },
                "zh": {
                    "title": "SCONE：提升语言模型性能的新方法",
                    "desc": "我们提出了一种方法SCONE（可扩展的上下文化的离线N-gram嵌入），旨在通过扩展输入嵌入层来提升语言模型的性能。SCONE在保持原有词汇的同时，引入了一组常见n-gram的嵌入，以提供每个输入标记的上下文化表示。这些嵌入在训练过程中由一个单独的模型学习，并在推理时预先计算并存储在离线加速器内存中，几乎不影响推理速度。通过增加缓存的n-gram嵌入数量和扩展学习它们的模型，SCONE在多种语料库上超越了1.9B参数的基线，同时仅使用一半的推理时间FLOPS。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.01591",
            "title": "Improving Transformer World Models for Data-Efficient RL",
            "url": "https://huggingface.co/papers/2502.01591",
            "abstract": "We present an approach to model-based RL that achieves a new state of the art performance on the challenging Craftax-classic benchmark, an open-world 2D survival game that requires agents to exhibit a wide range of general abilities -- such as strong generalization, deep exploration, and long-term reasoning. With a series of careful design choices aimed at improving sample efficiency, our MBRL algorithm achieves a reward of 67.4% after only 1M environment steps, significantly outperforming DreamerV3, which achieves 53.2%, and, for the first time, exceeds human performance of 65.0%. Our method starts by constructing a SOTA model-free baseline, using a novel policy architecture that combines CNNs and RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna with warmup\", which trains the policy on real and imaginary data, (b) \"nearest neighbor tokenizer\" on image patches, which improves the scheme to create the transformer world model (TWM) inputs, and (c) \"block teacher forcing\", which allows the TWM to reason jointly about the future tokens of the next timestep.",
            "score": 0,
            "issue_id": 2020,
            "pub_date": "2025-02-03",
            "pub_date_card": {
                "ru": "3 февраля",
                "en": "February 3",
                "zh": "2月3日"
            },
            "hash": "d9195e9417fce419",
            "authors": [
                "Antoine Dedieu",
                "Joseph Ortiz",
                "Xinghua Lou",
                "Carter Wendelken",
                "Wolfgang Lehrach",
                "J Swaroop Guntupalli",
                "Miguel Lazaro-Gredilla",
                "Kevin Patrick Murphy"
            ],
            "affiliations": [
                "Google DeepMind"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.01591.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#architecture",
                    "#benchmark",
                    "#games",
                    "#training",
                    "#reasoning",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Новый рубеж в model-based RL: превосходя человека в Craftax-classic",
                    "desc": "Статья представляет новый подход к обучению с подкреплением на основе модели, достигающий наилучших результатов на бенчмарке Craftax-classic. Авторы разработали алгоритм, превосходящий как предыдущий SOTA-метод DreamerV3, так и человеческий уровень производительности. Ключевые улучшения включают комбинированную архитектуру политики с CNN и RNN, обучение на реальных и воображаемых данных, токенизацию изображений методом ближайших соседей и блочное teacher forcing для трансформерной модели мира. Эти инновации позволили значительно повысить эффективность использования данных в сложной среде, требующей широкого спектра навыков."
                },
                "en": {
                    "title": "Revolutionizing Model-Based RL for Superior Game Performance",
                    "desc": "This paper introduces a new model-based reinforcement learning (MBRL) approach that excels in the Craftax-classic benchmark, a complex 2D survival game. The proposed algorithm achieves a remarkable reward of 67.4% after just 1 million environment steps, surpassing previous methods like DreamerV3 and even human performance. Key innovations include a novel policy architecture that integrates convolutional neural networks (CNNs) and recurrent neural networks (RNNs), along with enhancements like 'Dyna with warmup' for training on both real and simulated data. Additional techniques such as a nearest neighbor tokenizer for image patches and block teacher forcing for future reasoning further boost the model's efficiency and effectiveness."
                },
                "zh": {
                    "title": "基于模型的强化学习新突破！",
                    "desc": "本文提出了一种基于模型的强化学习方法，在Craftax-classic基准测试中取得了新的最佳表现。这是一款开放世界的2D生存游戏，要求智能体展现出强大的泛化能力、深度探索能力和长期推理能力。我们的MBRL算法在仅1M环境步骤后获得了67.4%的奖励，显著超越了DreamerV3的53.2%，并首次超过了人类表现的65.0%。该方法通过构建一个最先进的无模型基线，并结合CNN和RNN的新型策略架构，进一步提升了样本效率。"
                }
            }
        }
    ],
    "link_prev": "2025-02-03.html",
    "link_next": "2025-02-05.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "03.02",
        "en": "02/03",
        "zh": "2月3日"
    },
    "short_date_next": {
        "ru": "05.02",
        "en": "02/05",
        "zh": "2月5日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 0,
        "#benchmark": 5,
        "#agents": 0,
        "#cv": 0,
        "#rl": 2,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 3,
        "#3d": 0,
        "#audio": 0,
        "#video": 2,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 5,
        "#healthcare": 0,
        "#training": 10,
        "#robotics": 0,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 4,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 2,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 1,
        "#open_source": 3,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "这篇文章介绍了一种新的语言建模方法，称为测试时缩放。OpenAI的o1模型展示了这种能力，但没有公开其方法，导致许多复制努力。作者通过整理一个小数据集s1K和开发预算强制方法，寻找最简单的途径实现测试时缩放和强大的推理性能。他们的模型s1在数学竞赛问题上超越了o1-preview，并且通过预算强制进一步提升了性能。模型、数据和代码都是开源的。",
        "title": "s1: Simple test-time scaling",
        "pinyin": "这篇文章介绍了一种新的语言建模方法，称为测试时缩放。OpenAI的o1模型展示了这种能力，但没有公开其方法，导致许多复制努力。作者通过整理一个小数据集s1K和开发预算强制方法，寻找最简单的途径实现测试时缩放和强大的推理性能。他们的模型s1在数学竞赛问题上超越了o1-preview，并且通过预算强制进一步提升了性能。模型、数据和代码都是开源的。\n\nZhè piān wénzhāng jièshào le yīzhǒng xīn de yǔyán jiànmó fāngfǎ, chēngwéi cèshì shí suōfàng. OpenAI de o1 móxíng zhǎnshì le zhè zhǒng nénglì, dàn méiyǒu gōngkāi qí fāngfǎ, dǎozhì xǔduō fùzhì nǔlì. Zuòzhě tōngguò zhěnglǐ yīgè xiǎo shùjùjí s1K hé kāifā yùsuàn qiángzhì fāngfǎ, xúnzhǎo zuì jiǎndān de tújìng shíxiàn cèshì shí suōfàng hé qiángdà de tuīlǐ xìngnéng. Tāmen de móxíng s1 zài shùxué jìngsài wèntí shàng chāoyuè le o1-preview, bìngqiě tōngguò yùsuàn qiángzhì jìnfā tīshēng le xìngnéng. Móxíng, shùjù hé dàimǎ dōu shì kāiyuán de.",
        "vocab": "[\n{'word': '建模', 'pinyin': 'jiàn mó', 'trans': 'modeling'},\n{'word': '称为', 'pinyin': 'chēng wéi', 'trans': 'called'},\n{'word': '缩放', 'pinyin': 'suō fàng', 'trans': 'scaling'},\n{'word': '展示', 'pinyin': 'zhǎn shì', 'trans': 'demonstrate'},\n{'word': '能力', 'pinyin': 'néng lì', 'trans': 'capability'},\n{'word': '公开', 'pinyin': 'gōng kāi', 'trans': 'public'},\n{'word': '复制', 'pinyin': 'fù zhì', 'trans': 'replicate'},\n{'word': '努力', 'pinyin': 'nǔ lì', 'trans': 'efforts'},\n{'word': '整理', 'pinyin': 'zhěng lǐ', 'trans': 'organize'},\n{'word': '预算', 'pinyin': 'yù suàn', 'trans': 'budget'},\n{'word': '强制', 'pinyin': 'qiáng zhì', 'trans': 'enforcement'},\n{'word': '途径', 'pinyin': 'tú jìng', 'trans': 'means'},\n{'word': '实现', 'pinyin': 'shí xiàn', 'trans': 'achieve'},\n{'word': '推理', 'pinyin': 'tuī lǐ', 'trans': 'reasoning'},\n{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},\n{'word': '超越', 'pinyin': 'chāo yuè', 'trans': 'surpass'},\n{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open-source'}\n]",
        "trans": "This article introduces a new language modeling method called test-time scaling. The o1 model from OpenAI demonstrated this capability, but its method was not made public, leading to many attempts to replicate it. The authors, by curating a small dataset s1K and developing a budget enforcement method, sought the simplest way to achieve test-time scaling and powerful reasoning performance. Their model, s1, outperformed o1-preview on mathematical competition problems and further enhanced performance through budget enforcement. The model, data, and code are all open-sourced.",
        "update_ts": "2025-02-03 09:11"
    }
}