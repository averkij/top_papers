{
    "date": {
        "ru": "10 марта",
        "en": "March 10",
        "zh": "3月10日"
    },
    "time_utc": "2025-03-10 03:11",
    "weekday": 0,
    "issue_id": 2608,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.05236",
            "title": "Unified Reward Model for Multimodal Understanding and Generation",
            "url": "https://huggingface.co/papers/2503.05236",
            "abstract": "Recent advances in human preference alignment have significantly enhanced multimodal generation and understanding. A key approach is training reward models to guide preference optimization. However, existing models are often task-specific, limiting their adaptability across diverse visual applications. We also argue that jointly learning to assess multiple tasks may foster a synergistic effect, where improved image understanding enhances image generation assessment, and refined image evaluation benefits video assessment through better frame analysis. To this end, this paper proposes UnifiedReward, the first unified reward model for multimodal understanding and generation assessment, enabling both pairwise ranking and pointwise scoring, which can be employed for vision model preference alignment. Specifically, (1) we first develop UnifiedReward on our constructed large-scale human preference dataset, including both image and video generation/understanding tasks. (2) Then, it is utilized to automatically construct high-quality preference pair data based on the vision models, fine-gradually filtering their outputs through pair ranking and point sifting. (3) Finally, these data are used for their preference alignment through Direct Preference Optimization (DPO). Experimental results demonstrate that joint learning to assess diverse visual tasks can lead to substantial mutual benefits and we apply our pipeline to both image and video understanding/generation tasks, significantly improving the performance in each domain.",
            "score": 37,
            "issue_id": 2607,
            "pub_date": "2025-03-07",
            "pub_date_card": {
                "ru": "7 марта",
                "en": "March 7",
                "zh": "3月7日"
            },
            "hash": "6ebf61a6777b8e4d",
            "authors": [
                "Yibin Wang",
                "Yuhang Zang",
                "Hao Li",
                "Cheng Jin",
                "Jiaqi Wang"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2503.05236.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#video",
                    "#cv",
                    "#alignment",
                    "#dataset",
                    "#rlhf",
                    "#rag"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Единая модель вознаграждения для улучшения мультимодальных AI-систем",
                    "desc": "Статья представляет UnifiedReward - первую унифицированную модель вознаграждения для оценки мультимодального понимания и генерации. Модель обучается на большом наборе данных о человеческих предпочтениях, включающем задачи по генерации и пониманию изображений и видео. UnifiedReward используется для автоматического создания высококачественных пар предпочтений на основе моделей компьютерного зрения. Затем эти данные применяются для настройки предпочтений моделей с помощью метода Direct Preference Optimization (DPO)."
                },
                "en": {
                    "title": "UnifiedReward: Enhancing Multimodal Learning through Joint Preference Alignment",
                    "desc": "This paper introduces UnifiedReward, a novel reward model designed to enhance multimodal understanding and generation in machine learning. It addresses the limitation of existing task-specific models by enabling joint learning across various visual tasks, which improves both image and video assessments. The model is trained on a large-scale human preference dataset and utilizes techniques like pairwise ranking and pointwise scoring for effective preference alignment. Experimental results show that this unified approach leads to significant performance improvements in both image and video tasks, demonstrating the benefits of synergistic learning."
                },
                "zh": {
                    "title": "统一奖励模型，提升多模态理解与生成",
                    "desc": "最近在人类偏好对齐方面的进展显著提升了多模态生成和理解的能力。关键方法是训练奖励模型来指导偏好优化。然而，现有模型通常是特定于任务的，限制了它们在不同视觉应用中的适应性。本文提出了UnifiedReward，这是第一个用于多模态理解和生成评估的统一奖励模型，能够同时进行成对排名和逐点评分，从而实现视觉模型的偏好对齐。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.05179",
            "title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching",
            "url": "https://huggingface.co/papers/2503.05179",
            "abstract": "Recent advances in large language models have demonstrated remarkable reasoning capabilities through Chain of Thought (CoT) prompting, but often at the cost of excessive verbosity in their intermediate outputs, which increases computational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting framework that combines cognitive-inspired reasoning paradigms with linguistic constraints to minimize token usage while preserving reasoning accuracy. SoT is designed as a flexible framework that can incorporate any custom reasoning paradigms based on cognitive science, and we instantiate it with three such paradigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each tailored to different reasoning tasks and selected dynamically via a lightweight routing model. Through comprehensive evaluation across 15 reasoning datasets with multiple languages and multimodal scenarios, we demonstrate that SoT achieves token reductions of 76% with negligible accuracy impact. In certain domains like mathematical and multi-hop reasoning, it even improves accuracy while using significantly fewer tokens. Our code is publicly available: https://www.github.com/SimonAytes/SoT.",
            "score": 18,
            "issue_id": 2607,
            "pub_date": "2025-03-07",
            "pub_date_card": {
                "ru": "7 марта",
                "en": "March 7",
                "zh": "3月7日"
            },
            "hash": "e02cb6f62715b753",
            "authors": [
                "Simon A. Aytes",
                "Jinheon Baek",
                "Sung Ju Hwang"
            ],
            "affiliations": [
                "DeepAuto.ai",
                "KAIST"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.05179.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#reasoning",
                    "#multilingual",
                    "#optimization",
                    "#open_source",
                    "#math",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное рассуждение с минимальным использованием токенов",
                    "desc": "Статья представляет новый метод промптинга под названием Sketch-of-Thought (SoT), который сочетает когнитивно-вдохновленные парадигмы рассуждений с лингвистическими ограничениями. SoT направлен на минимизацию использования токенов при сохранении точности рассуждений в больших языковых моделях. Метод включает три парадигмы: Conceptual Chaining, Chunked Symbolism и Expert Lexicons, каждая из которых адаптирована для различных задач рассуждения. Эксперименты на 15 наборах данных показали, что SoT сокращает использование токенов на 76% без значительного влияния на точность, а в некоторых областях даже улучшает ее."
                },
                "en": {
                    "title": "Efficient Reasoning with Sketch-of-Thought",
                    "desc": "This paper presents a new prompting framework called Sketch-of-Thought (SoT) that enhances reasoning in large language models while reducing the number of tokens used. SoT integrates cognitive-inspired reasoning methods with linguistic constraints to maintain accuracy without excessive verbosity. The framework is adaptable, allowing for the inclusion of various reasoning paradigms, which are dynamically selected based on the task at hand. Evaluation shows that SoT can reduce token usage by 76% with little to no loss in accuracy, and in some cases, it even improves performance in specific reasoning tasks."
                },
                "zh": {
                    "title": "思维草图：高效推理的新方法",
                    "desc": "本文介绍了一种新的提示框架，称为思维草图（Sketch-of-Thought，SoT），旨在提高大型语言模型的推理能力，同时减少中间输出的冗长性。SoT结合了认知科学的推理范式和语言约束，以最小化令牌使用量，同时保持推理的准确性。该框架灵活，可以根据认知科学的不同推理范式进行定制，并通过轻量级路由模型动态选择。通过在15个推理数据集上的全面评估，SoT实现了76%的令牌减少，且对准确性影响微乎其微，甚至在某些领域提高了准确性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.05652",
            "title": "BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities",
            "url": "https://huggingface.co/papers/2503.05652",
            "abstract": "Real-world household tasks present significant challenges for mobile manipulation robots. An analysis of existing robotics benchmarks reveals that successful task performance hinges on three key whole-body control capabilities: bimanual coordination, stable and precise navigation, and extensive end-effector reachability. Achieving these capabilities requires careful hardware design, but the resulting system complexity further complicates visuomotor policy learning. To address these challenges, we introduce the BEHAVIOR Robot Suite (BRS), a comprehensive framework for whole-body manipulation in diverse household tasks. Built on a bimanual, wheeled robot with a 4-DoF torso, BRS integrates a cost-effective whole-body teleoperation interface for data collection and a novel algorithm for learning whole-body visuomotor policies. We evaluate BRS on five challenging household tasks that not only emphasize the three core capabilities but also introduce additional complexities, such as long-range navigation, interaction with articulated and deformable objects, and manipulation in confined spaces. We believe that BRS's integrated robotic embodiment, data collection interface, and learning framework mark a significant step toward enabling real-world whole-body manipulation for everyday household tasks. BRS is open-sourced at https://behavior-robot-suite.github.io/",
            "score": 1,
            "issue_id": 2608,
            "pub_date": "2025-03-07",
            "pub_date_card": {
                "ru": "7 марта",
                "en": "March 7",
                "zh": "3月7日"
            },
            "hash": "52a7efb2f40f020a",
            "authors": [
                "Yunfan Jiang",
                "Ruohan Zhang",
                "Josiah Wong",
                "Chen Wang",
                "Yanjie Ze",
                "Hang Yin",
                "Cem Gokmen",
                "Shuran Song",
                "Jiajun Wu",
                "Li Fei-Fei"
            ],
            "affiliations": [
                "Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.05652.jpg",
            "data": {
                "categories": [
                    "#robotics",
                    "#open_source",
                    "#dataset",
                    "#training"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Комплексная система для обучения роботов домашним задачам",
                    "desc": "Статья представляет BEHAVIOR Robot Suite (BRS) - комплексную систему для манипуляции роботов в домашних условиях. BRS основан на двуруком колесном роботе с 4-осевым торсом и включает интерфейс телеуправления для сбора данных и новый алгоритм обучения визуомоторным политикам. Система оценивается на пяти сложных бытовых задачах, требующих бимануальной координации, точной навигации и широкой досягаемости манипуляторов. BRS представляет значительный шаг вперед в решении задач роботизированной манипуляции в реальных домашних условиях."
                },
                "en": {
                    "title": "Empowering Robots for Everyday Household Tasks with BRS",
                    "desc": "This paper presents the BEHAVIOR Robot Suite (BRS), a framework designed to enhance mobile manipulation robots for household tasks. It identifies three essential capabilities for effective task performance: bimanual coordination, stable navigation, and extensive reachability. The BRS integrates a teleoperation interface for data collection and a novel algorithm for learning visuomotor policies, addressing the complexities of hardware design and policy learning. The framework is evaluated on five challenging tasks that test these capabilities in real-world scenarios, aiming to improve robotic manipulation in everyday environments."
                },
                "zh": {
                    "title": "实现家庭任务的全身操控机器人",
                    "desc": "本论文介绍了BEHAVIOR机器人套件（BRS），旨在解决移动操作机器人在家庭任务中面临的挑战。研究表明，成功完成任务依赖于三项关键的全身控制能力：双手协调、稳定精确的导航和广泛的末端执行器可达性。BRS框架结合了一个双手轮式机器人和4自由度的躯干，提供了一种经济高效的全身遥操作接口用于数据收集，并提出了一种新算法用于学习全身视觉运动策略。通过在五个复杂的家庭任务上评估BRS，展示了其在长距离导航、与可动和可变形物体的交互以及在狭小空间中的操作能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.02130",
            "title": "Forgetting Transformer: Softmax Attention with a Forget Gate",
            "url": "https://huggingface.co/papers/2503.02130",
            "abstract": "An essential component of modern recurrent sequence models is the forget gate. While Transformers do not have an explicit recurrent form, we show that a forget gate can be naturally incorporated into Transformers by down-weighting the unnormalized attention scores in a data-dependent way. We name this attention mechanism the Forgetting Attention and the resulting model the Forgetting Transformer (FoX). We show that FoX outperforms the Transformer on long-context language modeling, length extrapolation, and short-context downstream tasks, while performing on par with the Transformer on long-context downstream tasks. Moreover, it is compatible with the FlashAttention algorithm and does not require any positional embeddings. Several analyses, including the needle-in-the-haystack test, show that FoX also retains the Transformer's superior long-context capabilities over recurrent sequence models such as Mamba-2, HGRN2, and DeltaNet. We also introduce a \"Pro\" block design that incorporates some common architectural components in recurrent sequence models and find it significantly improves the performance of both FoX and the Transformer. Our code is available at https://github.com/zhixuan-lin/forgetting-transformer.",
            "score": 1,
            "issue_id": 2607,
            "pub_date": "2025-03-03",
            "pub_date_card": {
                "ru": "3 марта",
                "en": "March 3",
                "zh": "3月3日"
            },
            "hash": "4c39f334b6c4ed28",
            "authors": [
                "Zhixuan Lin",
                "Evgenii Nikishin",
                "Xu Owen He",
                "Aaron Courville"
            ],
            "affiliations": [
                "MakerMaker AI",
                "Mila & Universite de Montreal"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.02130.jpg",
            "data": {
                "categories": [
                    "#long_context",
                    "#architecture",
                    "#optimization",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Forgetting Transformer: Улучшение обработки длинных последовательностей в трансформерах",
                    "desc": "Исследователи представили новую модель под названием Forgetting Transformer (FoX), которая включает механизм 'забывающего внимания' в архитектуру трансформера. FoX превосходит стандартный трансформер в задачах моделирования языка с длинным контекстом и экстраполяции длины, сохраняя при этом высокую производительность на задачах с коротким контекстом. Модель совместима с алгоритмом FlashAttention и не требует позиционных эмбеддингов. Анализ показывает, что FoX сохраняет преимущества трансформера в обработке длинного контекста по сравнению с рекуррентными моделями."
                },
                "en": {
                    "title": "Enhancing Transformers with Forgetting Attention for Superior Performance",
                    "desc": "This paper introduces a new attention mechanism called Forgetting Attention, which integrates a forget gate into Transformer models. The Forgetting Transformer (FoX) leverages this mechanism to improve performance on various language modeling tasks, particularly those involving long contexts. FoX not only matches the performance of traditional Transformers on long-context tasks but also excels in short-context and length extrapolation tasks. Additionally, it is compatible with the FlashAttention algorithm and eliminates the need for positional embeddings, enhancing its efficiency and effectiveness."
                },
                "zh": {
                    "title": "遗忘变换器：提升长上下文建模的利器",
                    "desc": "本文提出了一种新的注意力机制，称为遗忘注意力（Forgetting Attention），可以有效地将遗忘门集成到Transformer模型中。通过以数据为依赖的方式降低未归一化注意力分数，遗忘注意力使得Transformer在长上下文语言建模和长度外推任务中表现优于传统的Transformer。我们还设计了一个“Pro”模块，结合了递归序列模型中的一些常见架构组件，显著提升了FoX和Transformer的性能。此外，FoX在长上下文任务中保持了Transformer的优势，超越了其他递归序列模型。"
                }
            }
        }
    ],
    "link_prev": "2025-03-07.html",
    "link_next": "2025-03-11.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "07.03",
        "en": "03/07",
        "zh": "3月7日"
    },
    "short_date_next": {
        "ru": "11.03",
        "en": "03/11",
        "zh": "3月11日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 1,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 1,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种新的大型语言模型，叫做 START。它结合了外部工具来增强复杂推理任务的能力。START 通过执行代码，进行复杂计算、自我检查、探索多种方法和自我调试，解决了传统大型推理模型的局限性。其创新点在于自学习框架，包括两种技术：Hint-infer 和 Hint-RFT。这些技术使模型能够高效利用外部工具，并在多个高难度基准测试中表现出色。",
        "title": "START: Self-taught Reasoner with Tools",
        "pinyin": "这篇文章介绍了一种新的大型语言模型，叫做 START。它结合了外部工具来增强复杂推理任务的能力。START 通过执行代码，进行复杂计算、自我检查、探索多种方法和自我调试，解决了传统大型推理模型的局限性。其创新点在于自学习框架，包括两种技术：Hint-infer 和 Hint-RFT。这些技术使模型能够高效利用外部工具，并在多个高难度基准测试中表现出色。\n\nZhè piān wénzhāng jièshào le yī zhǒng xīn de dàxíng yǔyán móxíng, jiàozuò START. Tā jiéhé le wàibù gōngjù lái zēngqiáng fùzá pīnglǐ rènwù de nénglì. START tōngguò zhíxíng dàimǎ, jìnxíng fùzá jìsuàn, zìwǒ jiǎnchá, tànsuǒ duōzhǒng fāngfǎ hé zìwǒ tiáoshì, jiějué le chuántǒng dàxíng tuīlǐ móxíng de júxìanxìng. Qí chuàngxīn diǎn zài yú zìxuéxí kuàngjià, bāokuò liǎng zhǒng jìshù: Hint-infer hé Hint-RFT. Zhèxiē jìshù shǐ móxíng nénggòu gāoxiào lìyòng wàibù gōngjù, bìng zài duōgè gāo nándù jīzhǔn cèshì zhōng biǎoxiàn chūsè.",
        "vocab": "[{'word': '介绍', 'pinyin': 'jièshào', 'trans': 'introduce'},\n{'word': '大型', 'pinyin': 'dàxíng', 'trans': 'large-scale'},\n{'word': '语言模型', 'pinyin': 'yǔyán móxíng', 'trans': 'language model'},\n{'word': '结合', 'pinyin': 'jiéhé', 'trans': 'combine'},\n{'word': '外部', 'pinyin': 'wàibù', 'trans': 'external'},\n{'word': '工具', 'pinyin': 'gōngjù', 'trans': 'tool'},\n{'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhance'},\n{'word': '复杂', 'pinyin': 'fùzá', 'trans': 'complex'},\n{'word': '推理', 'pinyin': 'tuīlǐ', 'trans': 'reasoning'},\n{'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'},\n{'word': '能力', 'pinyin': 'nénglì', 'trans': 'ability'},\n{'word': '执行', 'pinyin': 'zhíxíng', 'trans': 'execute'},\n{'word': '代码', 'pinyin': 'dàimǎ', 'trans': 'code'},\n{'word': '计算', 'pinyin': 'jìsuàn', 'trans': 'calculation'},\n{'word': '自我检查', 'pinyin': 'zìwǒ jiǎnchá', 'trans': 'self-check'},\n{'word': '探索', 'pinyin': 'tànsuǒ', 'trans': 'explore'},\n{'word': '方法', 'pinyin': 'fāngfǎ', 'trans': 'method'},\n{'word': '自我调试', 'pinyin': 'zìwǒ tiáoshì', 'trans': 'self-debug'},\n{'word': '解决', 'pinyin': 'jiějué', 'trans': 'solve'},\n{'word': '局限性', 'pinyin': 'júxiànxìng', 'trans': 'limitation'},\n{'word': '创新点', 'pinyin': 'chuàngxīn diǎn', 'trans': 'innovation'},\n{'word': '自学习', 'pinyin': 'zì xuéxí', 'trans': 'self-learning'},\n{'word': '框架', 'pinyin': 'kuàngjià', 'trans': 'framework'},\n{'word': '技术', 'pinyin': 'jìshù', 'trans': 'technology'},\n{'word': '高效', 'pinyin': 'gāoxiào', 'trans': 'efficient'},\n{'word': '利用', 'pinyin': 'lìyòng', 'trans': 'utilize'},\n{'word': '基准测试', 'pinyin': 'jīzhǔn cèshì', 'trans': 'benchmark test'},\n{'word': '表现', 'pinyin': 'biǎoxiàn', 'trans': 'performance'},\n{'word': '出色', 'pinyin': 'chūsè', 'trans': 'outstanding'}]",
        "trans": "This article introduces a new large language model called START, which combines external tools to enhance its capabilities in complex reasoning tasks. START addresses the limitations of traditional large reasoning models by executing code, performing complex calculations, self-checking, exploring multiple methods, and self-debugging. Its innovative aspect lies in the self-learning framework, which includes two techniques: Hint-infer and Hint-RFT. These techniques enable the model to efficiently utilize external tools and perform exceptionally well on multiple high-difficulty benchmark tests.",
        "update_ts": "2025-03-09 18:23"
    }
}