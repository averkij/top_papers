{
    "date": {
        "ru": "4 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
        "en": "March 4",
        "zh": "3æœˆ4æ—¥"
    },
    "time_utc": "2025-03-04 05:10",
    "weekday": 1,
    "issue_id": 2511,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.01785",
            "title": "Visual-RFT: Visual Reinforcement Fine-Tuning",
            "url": "https://huggingface.co/papers/2503.01785",
            "abstract": "Reinforcement Fine-Tuning (RFT) in Large Reasoning Models like OpenAI o1 learns from feedback on its answers, which is especially useful in applications when fine-tuning data is scarce. Recent open-source work like DeepSeek-R1 demonstrates that reinforcement learning with verifiable reward is one key direction in reproducing o1. While the R1-style model has demonstrated success in language models, its application in multi-modal domains remains under-explored. This work introduces Visual Reinforcement Fine-Tuning (Visual-RFT), which further extends the application areas of RFT on visual tasks. Specifically, Visual-RFT first uses Large Vision-Language Models (LVLMs) to generate multiple responses containing reasoning tokens and final answers for each input, and then uses our proposed visual perception verifiable reward functions to update the model via the policy optimization algorithm such as Group Relative Policy Optimization (GRPO). We design different verifiable reward functions for different perception tasks, such as the Intersection over Union (IoU) reward for object detection. Experimental results on fine-grained image classification, few-shot object detection, reasoning grounding, as well as open-vocabulary object detection benchmarks show the competitive performance and advanced generalization ability of Visual-RFT compared with Supervised Fine-tuning (SFT). For example, Visual-RFT improves accuracy by 24.3% over the baseline in one-shot fine-grained image classification with around 100 samples. In few-shot object detection, Visual-RFT also exceeds the baseline by 21.9 on COCO's two-shot setting and 15.4 on LVIS. Our Visual-RFT represents a paradigm shift in fine-tuning LVLMs, offering a data-efficient, reward-driven approach that enhances reasoning and adaptability for domain-specific tasks.",
            "score": 7,
            "issue_id": 2511,
            "pub_date": "2025-03-03",
            "pub_date_card": {
                "ru": "3 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
                "en": "March 3",
                "zh": "3æœˆ3æ—¥"
            },
            "hash": "ef2e10eb59ab7743",
            "authors": [
                "Ziyu Liu",
                "Zeyi Sun",
                "Yuhang Zang",
                "Xiaoyi Dong",
                "Yuhang Cao",
                "Haodong Duan",
                "Dahua Lin",
                "Jiaqi Wang"
            ],
            "affiliations": [
                "Shanghai Artificial Intelligence Laboratory",
                "Shanghai Jiaotong University",
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.01785.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#open_source",
                    "#cv",
                    "#optimization",
                    "#rlhf",
                    "#reasoning",
                    "#training",
                    "#rl"
                ],
                "emoji": "ğŸ”¬",
                "ru": {
                    "title": "Visual-RFT: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Visual Reinforcement Fine-Tuning (Visual-RFT) - Ğ¼ĞµÑ‚Ğ¾Ğ´, Ñ€Ğ°ÑÑˆĞ¸Ñ€ÑÑÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Visual-RFT Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Visual-RFT Ğ½Ğ°Ğ´ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ¼ Supervised Fine-tuning Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ·ĞµĞ¼Ğ»ĞµĞ½Ğ¸Ñ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ĞµĞ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Revolutionizing Visual Learning with Reinforcement Fine-Tuning",
                    "desc": "This paper introduces Visual Reinforcement Fine-Tuning (Visual-RFT), a method that enhances large vision-language models (LVLMs) by using reinforcement learning to improve their performance on visual tasks. Visual-RFT generates multiple responses for each input and employs verifiable reward functions to optimize the model's policy, making it particularly effective in scenarios with limited fine-tuning data. The approach demonstrates significant improvements in tasks like fine-grained image classification and object detection, outperforming traditional supervised fine-tuning methods. Overall, Visual-RFT represents a novel, efficient way to fine-tune LVLMs, focusing on reasoning and adaptability in specific domains."
                },
                "zh": {
                    "title": "è§†è§‰å¼ºåŒ–å¾®è°ƒï¼šæå‡æ¨ç†ä¸é€‚åº”æ€§çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰åœ¨å¤§å‹æ¨ç†æ¨¡å‹ä¸­é€šè¿‡åé¦ˆå­¦ä¹ ï¼Œç‰¹åˆ«é€‚ç”¨äºå¾®è°ƒæ•°æ®ç¨€ç¼ºçš„åº”ç”¨åœºæ™¯ã€‚æœ¬æ–‡æå‡ºçš„è§†è§‰å¼ºåŒ–å¾®è°ƒï¼ˆVisual-RFTï¼‰æ‰©å±•äº†RFTåœ¨è§†è§‰ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œåˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆå¤šç§å“åº”ï¼Œå¹¶é€šè¿‡å¯éªŒè¯çš„è§†è§‰æ„ŸçŸ¥å¥–åŠ±å‡½æ•°è¿›è¡Œæ¨¡å‹æ›´æ–°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVisual-RFTåœ¨ç»†ç²’åº¦å›¾åƒåˆ†ç±»å’Œå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•ï¼Œå‡†ç¡®ç‡æ˜¾è‘—æé«˜ã€‚Visual-RFTä»£è¡¨äº†ä¸€ç§æ–°çš„å¾®è°ƒèŒƒå¼ï¼Œæä¾›äº†ä¸€ç§æ•°æ®é«˜æ•ˆã€ä»¥å¥–åŠ±é©±åŠ¨çš„æ–¹æ³•ï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.01743",
            "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs",
            "url": "https://huggingface.co/papers/2503.01743",
            "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable language and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language model trained on high-quality web and synthetic data, significantly outperforming recent open-source models of similar size and matching the performance of models twice its size on math and coding tasks requiring complex reasoning. This achievement is driven by a carefully curated synthetic data recipe emphasizing high-quality math and coding datasets. Compared to its predecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of 200K tokens to better support multilingual applications, as well as group query attention for more efficient long-sequence generation. Phi-4-Multimodal is a multimodal model that integrates text, vision, and speech/audio input modalities into a single model. Its novel modality extension approach leverages LoRA adapters and modality-specific routers to allow multiple inference modes combining various modalities without interference. For example, it now ranks first in the OpenASR leaderboard to date, although the LoRA component of the speech/audio modality has just 460 million parameters. Phi-4-Multimodal supports scenarios involving (vision + language), (vision + speech), and (speech/audio) inputs, outperforming larger vision-language and speech-language models on a wide range of tasks. Additionally, we experiment to further train Phi-4-Mini to enhance its reasoning capabilities. Despite its compact 3.8-billion-parameter size, this experimental version achieves reasoning performance on par with or surpassing significantly larger models, including DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.",
            "score": 7,
            "issue_id": 2511,
            "pub_date": "2025-03-03",
            "pub_date_card": {
                "ru": "3 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
                "en": "March 3",
                "zh": "3æœˆ3æ—¥"
            },
            "hash": "fb054d6547a4a4fb",
            "authors": [
                "Abdelrahman Abouelenin",
                "Atabak Ashfaq",
                "Adam Atkinson",
                "Hany Awadalla",
                "Nguyen Bach",
                "Jianmin Bao",
                "Alon Benhaim",
                "Martin Cai",
                "Vishrav Chaudhary",
                "Congcong Chen",
                "Dong Chen",
                "Dongdong Chen",
                "Junkun Chen",
                "Weizhu Chen",
                "Yen-Chun Chen",
                "Yi-ling Chen",
                "Qi Dai",
                "Xiyang Dai",
                "Ruchao Fan",
                "Mei Gao",
                "Min Gao",
                "Amit Garg",
                "Abhishek Goswami",
                "Junheng Hao",
                "Amr Hendy",
                "Yuxuan Hu",
                "Xin Jin",
                "Mahmoud Khademi",
                "Dongwoo Kim",
                "Young Jin Kim",
                "Gina Lee",
                "Jinyu Li",
                "Yunsheng Li",
                "Chen Liang",
                "Xihui Lin",
                "Zeqi Lin",
                "Mengchen Liu",
                "Yang Liu",
                "Gilsinia Lopez",
                "Chong Luo",
                "Piyush Madan",
                "Vadim Mazalov",
                "Ali Mousavi",
                "Anh Nguyen",
                "Jing Pan",
                "Daniel Perez-Becker",
                "Jacob Platin",
                "Thomas Portet",
                "Kai Qiu",
                "Bo Ren",
                "Liliang Ren",
                "Sambuddha Roy",
                "Ning Shang",
                "Yelong Shen",
                "Saksham Singhal",
                "Subhojit Som",
                "Xia Song",
                "Tetyana Sych",
                "Praneetha Vaddamanu",
                "Shuohang Wang",
                "Yiming Wang",
                "Zhenghao Wang",
                "Haibin Wu",
                "Haoran Xu",
                "Weijian Xu",
                "Yifan Yang",
                "Ziyi Yang",
                "Donghan Yu",
                "Ishmam Zabir",
                "Jianwen Zhang",
                "Li Lyna Zhang",
                "Yunan Zhang",
                "Xiren Zhou"
            ],
            "affiliations": [
                "Microsoft"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.01743.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#small_models",
                    "#data",
                    "#agi",
                    "#synthetic",
                    "#long_context",
                    "#optimization",
                    "#dataset",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸: Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ² Ğ² ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ˜Ğ˜",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ´Ğ²Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: Phi-4-Mini Ğ¸ Phi-4-Multimodal. Phi-4-Mini - ÑÑ‚Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ 3,8 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¾ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ²ĞµĞ±-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Phi-4-Multimodal - ÑÑ‚Ğ¾ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‰Ğ°Ñ Ñ‚ĞµĞºÑÑ‚, Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ñ€ĞµÑ‡ÑŒ/Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ² ĞµĞ´Ğ¸Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ LoRA-Ğ°Ğ´Ğ°Ğ¿Ñ‚ĞµÑ€Ğ¾Ğ². ĞĞ±Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° ÑĞ²Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…."
                },
                "en": {
                    "title": "Compact Models, Superior Performance!",
                    "desc": "The paper presents Phi-4-Mini and Phi-4-Multimodal, two advanced models designed for language and multimodal tasks. Phi-4-Mini, with 3.8 billion parameters, excels in math and coding tasks by utilizing a high-quality synthetic data approach and an expanded vocabulary of 200K tokens. Phi-4-Multimodal integrates text, vision, and audio inputs, employing innovative techniques like LoRA adapters for efficient multi-modal processing. Both models demonstrate superior performance compared to larger counterparts, showcasing their effectiveness in complex reasoning and diverse input scenarios."
                },
                "zh": {
                    "title": "ç´§å‡‘å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹Phi-4ç³»åˆ—",
                    "desc": "æˆ‘ä»¬ä»‹ç»äº†Phi-4-Miniå’ŒPhi-4-Multimodalè¿™ä¸¤ç§ç´§å‡‘è€Œå¼ºå¤§çš„è¯­è¨€å’Œå¤šæ¨¡æ€æ¨¡å‹ã€‚Phi-4-Miniæ˜¯ä¸€ä¸ªæ‹¥æœ‰38äº¿å‚æ•°çš„è¯­è¨€æ¨¡å‹ï¼Œç»è¿‡é«˜è´¨é‡çš„ç½‘ç»œå’Œåˆæˆæ•°æ®è®­ç»ƒï¼Œåœ¨æ•°å­¦å’Œç¼–ç ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºåŒç±»å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸”åœ¨å¤æ‚æ¨ç†æ–¹é¢ä¸ä¸¤å€äºå…¶è§„æ¨¡çš„æ¨¡å‹ç›¸å½“ã€‚ç›¸æ¯”äºå‰èº«Phi-3.5-Miniï¼ŒPhi-4-Miniæ‰©å±•äº†è¯æ±‡é‡ï¼Œæ”¯æŒå¤šè¯­è¨€åº”ç”¨ï¼Œå¹¶é‡‡ç”¨äº†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ä»¥æé«˜é•¿åºåˆ—ç”Ÿæˆçš„æ•ˆç‡ã€‚Phi-4-Multimodalåˆ™æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå°†æ–‡æœ¬ã€è§†è§‰å’Œè¯­éŸ³/éŸ³é¢‘è¾“å…¥æ•´åˆåˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œæ”¯æŒå¤šç§æ¨ç†æ¨¡å¼ï¼Œä¸”åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†æ›´å¤§çš„è§†è§‰-è¯­è¨€å’Œè¯­éŸ³-è¯­è¨€æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.00784",
            "title": "DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with Dynamic Multi-Sequence Drafting",
            "url": "https://huggingface.co/papers/2503.00784",
            "abstract": "Large language models (LLMs) exhibit exceptional performance across a wide range of tasks; however, their token-by-token autoregressive generation process significantly hinders inference speed. Speculative decoding presents a promising draft-then-verify framework that reduces generation latency while maintaining output distribution fidelity. Nevertheless, the draft model introduces additional computational overhead, becoming a performance bottleneck and increasing the time to first token (TTFT). Previous approaches to mitigate draft model overhead have primarily relied on heuristics and generally failed to match the quality of the draft language models. To address these challenges, we propose DuoDecoding, a novel approach that strategically deploys the draft and target models on the CPU and GPU respectively, enabling parallel decoding while preserving draft quality. Our method incorporates a hardware-aware optimal draft budget to minimize idle times and employs dynamic multi-sequence drafting to enhance draft quality. Extensive experiments across seven tasks show that DuoDecoding achieves up to 2.61x speedup in generation latency, while reducing TTFT to 83% of that in conventional speculative decoding. The Code is available at https://github.com/KaiLv69/DuoDecoding.",
            "score": 6,
            "issue_id": 2510,
            "pub_date": "2025-03-02",
            "pub_date_card": {
                "ru": "2 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
                "en": "March 2",
                "zh": "3æœˆ2æ—¥"
            },
            "hash": "b4870a0e44c3cc55",
            "authors": [
                "Kai Lv",
                "Honglin Guo",
                "Qipeng Guo",
                "Xipeng Qiu"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.00784.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#optimization"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "DuoDecoding: ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ (LLM) Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ DuoDecoding. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° CPU Ğ¸ GPU, Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ¸ Ğ¾Ğ±Ñ‰ÑƒÑ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ. DuoDecoding Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ°Ğ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ğ½Ğ¾-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±ÑĞ´Ğ¶ĞµÑ‚ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ° Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¼ ÑĞ¿ĞµĞºÑƒĞ»ÑÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼."
                },
                "en": {
                    "title": "DuoDecoding: Speeding Up Text Generation with Smart Model Deployment",
                    "desc": "This paper introduces DuoDecoding, a new method to improve the speed of generating text with large language models (LLMs) while keeping the quality high. It uses a draft-then-verify approach, where a draft model quickly generates initial text, and a target model refines it, but does so in a way that reduces the time it takes to start generating text. By using both CPU and GPU for different parts of the process, DuoDecoding allows for faster and more efficient decoding. The results show that this method can significantly speed up text generation without sacrificing quality, achieving a notable improvement in performance across various tasks."
                },
                "zh": {
                    "title": "DuoDecodingï¼šåŠ é€Ÿç”Ÿæˆçš„æ–°æ–¹æ³•",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é€å­—è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹æ˜¾è‘—å½±å“æ¨ç†é€Ÿåº¦ã€‚æ¨æµ‹è§£ç æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è‰ç¨¿-éªŒè¯æ¡†æ¶ï¼Œèƒ½å¤Ÿå‡å°‘ç”Ÿæˆå»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒè¾“å‡ºåˆ†å¸ƒçš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬æå‡ºçš„DuoDecodingæ–¹æ³•é€šè¿‡åœ¨CPUå’ŒGPUä¸Šåˆ†åˆ«éƒ¨ç½²è‰ç¨¿æ¨¡å‹å’Œç›®æ ‡æ¨¡å‹ï¼Œå®ç°äº†å¹¶è¡Œè§£ç ï¼Œæå‡äº†ç”Ÿæˆæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDuoDecodingåœ¨ç”Ÿæˆå»¶è¿Ÿä¸Šå®ç°äº†æœ€é«˜2.61å€çš„åŠ é€Ÿï¼ŒåŒæ—¶å°†é¦–æ¬¡ç”Ÿæˆæ—¶é—´ç¼©çŸ­è‡³ä¼ ç»Ÿæ¨æµ‹è§£ç çš„83%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.01307",
            "title": "Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs",
            "url": "https://huggingface.co/papers/2503.01307",
            "abstract": "Test-time inference has emerged as a powerful paradigm for enabling language models to ``think'' longer and more carefully about complex challenges, much like skilled human experts. While reinforcement learning (RL) can drive self-improvement in language models on verifiable tasks, some models exhibit substantial gains while others quickly plateau. For instance, we find that Qwen-2.5-3B far exceeds Llama-3.2-3B under identical RL training for the game of Countdown. This discrepancy raises a critical question: what intrinsic properties enable effective self-improvement? We introduce a framework to investigate this question by analyzing four key cognitive behaviors -- verification, backtracking, subgoal setting, and backward chaining -- that both expert human problem solvers and successful language models employ. Our study reveals that Qwen naturally exhibits these reasoning behaviors, whereas Llama initially lacks them. In systematic experimentation with controlled behavioral datasets, we find that priming Llama with examples containing these reasoning behaviors enables substantial improvements during RL, matching or exceeding Qwen's performance. Importantly, the presence of reasoning behaviors, rather than correctness of answers, proves to be the critical factor -- models primed with incorrect solutions containing proper reasoning patterns achieve comparable performance to those trained on correct solutions. Finally, leveraging continued pretraining with OpenWebMath data, filtered to amplify reasoning behaviors, enables the Llama model to match Qwen's self-improvement trajectory. Our findings establish a fundamental relationship between initial reasoning behaviors and the capacity for improvement, explaining why some language models effectively utilize additional computation while others plateau.",
            "score": 2,
            "issue_id": 2511,
            "pub_date": "2025-03-03",
            "pub_date_card": {
                "ru": "3 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
                "en": "March 3",
                "zh": "3æœˆ3æ—¥"
            },
            "hash": "fa966620baa8c013",
            "authors": [
                "Kanishk Gandhi",
                "Ayush Chakravarthy",
                "Anikait Singh",
                "Nathan Lile",
                "Noah D. Goodman"
            ],
            "affiliations": [
                "Stanford University",
                "SynthLabs"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.01307.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸ - ĞºĞ»ÑÑ‡ Ğº ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº ÑĞ°Ğ¼Ğ¾ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ Ñƒ Ğ½Ğ¸Ñ… Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğ¹, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ, Ğ±ÑĞºÑ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³, Ğ¿Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾Ğ´Ñ†ĞµĞ»ĞµĞ¹ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğµ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Qwen Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ±Ğ»Ğ°Ğ´Ğ°ĞµÑ‚ ÑÑ‚Ğ¸Ğ¼Ğ¸ Ğ½Ğ°Ğ²Ñ‹ĞºĞ°Ğ¼Ğ¸, Ğ² Ñ‚Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ ĞºĞ°Ğº Llama Ğ½ĞµÑ‚. ĞŸÑ€Ğ°Ğ¹Ğ¼Ğ¸Ğ½Ğ³ Llama Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¼Ğ¸ ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ğ¸Ğ» Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ ĞµĞµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ’Ğ°Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾ÑÑŒ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼, Ñ‡ĞµĞ¼ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Unlocking Self-Improvement in Language Models through Reasoning",
                    "desc": "This paper explores how language models can improve their problem-solving abilities through a process called test-time inference, similar to human experts. It highlights the differences in performance between two models, Qwen-2.5-3B and Llama-3.2-3B, when trained with reinforcement learning (RL) on the game Countdown. The authors identify four cognitive behaviorsâ€”verification, backtracking, subgoal setting, and backward chainingâ€”that are crucial for effective self-improvement in these models. They demonstrate that enhancing Llama with examples of these reasoning behaviors can significantly boost its performance, suggesting that the ability to reason is more important than simply providing correct answers."
                },
                "zh": {
                    "title": "æ¨ç†è¡Œä¸ºæ˜¯æ¨¡å‹è‡ªæˆ‘æå‡çš„å…³é”®",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­è‡ªæˆ‘æ”¹è¿›çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å®ç°çš„è‡ªæˆ‘æå‡ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒæ¨¡å‹åœ¨ç›¸åŒçš„RLè®­ç»ƒä¸‹è¡¨ç°å·®å¼‚æ˜¾è‘—ï¼Œä¾‹å¦‚Qwen-2.5-3Båœ¨æ¸¸æˆCountdownä¸­è¿œè¶…Llama-3.2-3Bã€‚æˆ‘ä»¬åˆ†æäº†å››ç§å…³é”®çš„è®¤çŸ¥è¡Œä¸ºï¼šéªŒè¯ã€å›æº¯ã€å­ç›®æ ‡è®¾å®šå’Œé€†å‘é“¾æ¨ç†ï¼Œå‘ç°Qwenè‡ªç„¶å±•ç°äº†è¿™äº›æ¨ç†è¡Œä¸ºï¼Œè€ŒLlamaåˆ™æœ€åˆç¼ºä¹ã€‚é€šè¿‡å¯¹Llamaè¿›è¡Œç¤ºä¾‹å¼•å¯¼ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å…¶åœ¨RLä¸­çš„è¡¨ç°ï¼Œè¯æ˜äº†æ¨ç†è¡Œä¸ºçš„å­˜åœ¨æ˜¯æ¨¡å‹è‡ªæˆ‘æ”¹è¿›çš„å…³é”®å› ç´ ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.01807",
            "title": "Large-Scale Data Selection for Instruction Tuning",
            "url": "https://huggingface.co/papers/2503.01807",
            "abstract": "Selecting high-quality training data from a larger pool is a crucial step when instruction-tuning language models, as carefully curated datasets often produce models that outperform those trained on much larger, noisier datasets. Automated data selection approaches for instruction-tuning are typically tested by selecting small datasets (roughly 10k samples) from small pools (100-200k samples). However, popular deployed instruction-tuned models often train on hundreds of thousands to millions of samples, subsampled from even larger data pools. We present a systematic study of how well data selection methods scale to these settings, selecting up to 2.5M samples from pools of up to 5.8M samples and evaluating across 7 diverse tasks. We show that many recently proposed methods fall short of random selection in this setting (while using more compute), and even decline in performance when given access to larger pools of data to select over. However, we find that a variant of representation-based data selection (RDS+), which uses weighted mean pooling of pretrained LM hidden states, consistently outperforms more complex methods across all settings tested -- all whilst being more compute-efficient. Our findings highlight that the scaling properties of proposed automated selection methods should be more closely examined. We release our code, data, and models at https://github.com/hamishivi/automated-instruction-selection.",
            "score": 0,
            "issue_id": 2511,
            "pub_date": "2025-03-03",
            "pub_date_card": {
                "ru": "3 Ğ¼Ğ°Ñ€Ñ‚Ğ°",
                "en": "March 3",
                "zh": "3æœˆ3æ—¥"
            },
            "hash": "8bbc980a9ef867f7",
            "authors": [
                "Hamish Ivison",
                "Muru Zhang",
                "Faeze Brahman",
                "Pang Wei Koh",
                "Pradeep Dasigi"
            ],
            "affiliations": [
                "Allen Institute for AI",
                "University of Southern California",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.01807.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#open_source",
                    "#optimization",
                    "#dataset",
                    "#training"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´ÑÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ´Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¾Ğ±ÑŠĞµĞ¼Ğ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ Ğ´Ğ¾ 2,5 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² Ğ¸Ğ· Ğ¿ÑƒĞ»Ğ¾Ğ² Ğ´Ğ¾ 5,8 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ². Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ğµ Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ÑƒÑÑ‚ÑƒĞ¿Ğ°ÑÑ‚ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ñƒ Ğ² ÑÑ‚Ğ¸Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ…, Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ (RDS+) Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "Quality Over Quantity: Smart Data Selection for Language Models",
                    "desc": "This paper investigates the importance of selecting high-quality training data for instruction-tuning language models. It reveals that many automated data selection methods do not perform better than random selection when scaling to larger datasets, which can include millions of samples. The study introduces a representation-based data selection method (RDS+) that consistently outperforms more complex approaches while being more efficient in terms of computational resources. The authors emphasize the need for a deeper examination of how these selection methods behave as the size of the data pools increases."
                },
                "zh": {
                    "title": "é«˜æ•ˆé€‰æ‹©ï¼šä¼˜åŒ–è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®çš„å…³é”®",
                    "desc": "åœ¨å¯¹è¯­è¨€æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜æ—¶ï¼Œä»æ›´å¤§æ•°æ®é›†ä¸­é€‰æ‹©é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®æ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ã€‚ç»è¿‡ç²¾å¿ƒç­–åˆ’çš„æ•°æ®é›†é€šå¸¸èƒ½äº§ç”Ÿæ¯”é‚£äº›åœ¨æ›´å¤§ã€æ›´å˜ˆæ‚çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ›´å¥½çš„æ•ˆæœã€‚æˆ‘ä»¬è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼Œè¯„ä¼°æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œå‘ç°è®¸å¤šæ–°æå‡ºçš„æ–¹æ³•åœ¨è¿™ç§æƒ…å†µä¸‹çš„è¡¨ç°ä¸å¦‚éšæœºé€‰æ‹©ã€‚æˆ‘ä»¬è¿˜å‘ç°ä¸€ç§åŸºäºè¡¨ç¤ºçš„æ•°æ®é€‰æ‹©å˜ä½“ï¼ˆRDS+ï¼‰åœ¨æ‰€æœ‰æµ‹è¯•è®¾ç½®ä¸­å§‹ç»ˆä¼˜äºæ›´å¤æ‚çš„æ–¹æ³•ï¼ŒåŒæ—¶è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-03-03.html",
    "link_next": "2025-03-05.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "03.03",
        "en": "03/03",
        "zh": "3æœˆ3æ—¥"
    },
    "short_date_next": {
        "ru": "05.03",
        "en": "03/05",
        "zh": "3æœˆ5æ—¥"
    },
    "categories": {
        "#dataset": 2,
        "#data": 2,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 1,
        "#rl": 2,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 5,
        "#robotics": 0,
        "#agi": 1,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 5,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è®¾è®¡å¤æ‚å·¥ç¨‹æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆå¯¹äººç±»ç”Ÿäº§æ´»åŠ¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä»¥å‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç ”ç©¶æœªèƒ½å……åˆ†è§£å†³ä¸å¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡ç›¸å…³çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼ŒSolutionBenchï¼Œæ¥è¯„ä¼°ç³»ç»Ÿç”Ÿæˆå®Œæ•´å’Œå¯è¡Œçš„å·¥ç¨‹é—®é¢˜è§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªæ–°ç³»ç»Ÿï¼ŒSolutionRAGï¼Œåˆ©ç”¨åŸºäºæ ‘çš„æ¢ç´¢å’ŒåŒç‚¹æ€ç»´æœºåˆ¶ç”Ÿæˆå¯é çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSolutionRAGåœ¨SolutionBenchä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­å¢å¼ºå¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡è‡ªåŠ¨åŒ–å’Œå¯é æ€§çš„æ½œåŠ›ã€‚",
        "title": "DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking",
        "pinyin": "è®¾è®¡å¤æ‚å·¥ç¨‹æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆå¯¹äººç±»ç”Ÿäº§æ´»åŠ¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä»¥å‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç ”ç©¶æœªèƒ½å……åˆ†è§£å†³ä¸å¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡ç›¸å…³çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼ŒSolutionBenchï¼Œæ¥è¯„ä¼°ç³»ç»Ÿç”Ÿæˆå®Œæ•´å’Œå¯è¡Œçš„å·¥ç¨‹é—®é¢˜è§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªæ–°ç³»ç»Ÿï¼ŒSolutionRAGï¼Œåˆ©ç”¨åŸºäºæ ‘çš„æ¢ç´¢å’ŒåŒç‚¹æ€ç»´æœºåˆ¶ç”Ÿæˆå¯é çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSolutionRAGåœ¨SolutionBenchä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­å¢å¼ºå¤æ‚å·¥ç¨‹è§£å†³æ–¹æ¡ˆè®¾è®¡è‡ªåŠ¨åŒ–å’Œå¯é æ€§çš„æ½œåŠ›ã€‚\n\nShÃ¨jÃ¬ fÃ¹zÃ¡ gÅngchÃ©ng tiÇozhÃ n de jiÄ›juÃ© fÄng'Ã n duÃ¬ rÃ©nlÃ¨i shÄ“ngchÇn huÃ³dÃ²ng zhÃ¬guÄn zhÃ²ngyÃ o. RÃ¡n'Ã©r, yÇqiÃ¡n de jiÇnsuÇ’ zÄ“ngqiÃ¡ng shÄ“ngchÃ©ng (RAG) yÃ¡njiÅ« wÃ¨i nÃ©ng chÃ³ngfÄ“n jiÄ›juÃ© yÇ” fÃ¹zÃ¡ gÅngchÃ©ng jiÄ›juÃ© fÄng'Ã n shÃ¨jÃ¬ xiÄngguÄn de rÃ¨nwÃ¹. WÇ’men yÇnrÃ¹ le yÄ«gÃ¨ xÄ«n de jÄ«zhÇ”n, SolutionBench, lÃ¡i pÃ­nggÅ« xÃ¬tÇ’ng shÄ“ngchÃ©ng wÃ¡nzhÄ›ng hÃ© kÄ›xÃ­ng de gÅngchÃ©ng wÃ¨ntÃ­ jiÄ›juÃ© fÄng'Ã n de nÃ©nglÃ¬. WÇ’men hÃ¡i tÃ­chÅ« le yÄ«gÃ¨ xÄ«n xÃ¬tÇ’ng, SolutionRAG, lÃ¬yÃ²ng jÄ«yÃº shÃ¹ de tÃ nsuÇ’ hÃ© shuÄngdiÇn sÄ«wÃ©i jÄ«zhÃ¬ shÄ“ngchÃ©ng kÄ›kÃ o de jiÄ›juÃ© fÄng'Ã n. ShÃ­yÃ n jiÃ©guÇ’ xiÇnshÃ¬, SolutionRAG zÃ i SolutionBench shÃ ng dÃ¡ dÃ o le zuÃ¬ xiÄnjÃ¬n de xÃ¬ngnÃ©ng, tÅ«xÃ¬ le qÃ­ zÃ i shÃ­jÃ¬ yÃ¬ngyÃ²ng zhÅng zÄ“ngqiÃ¡ng fÃ¹zÃ¡ gÅngchÃ©ng jiÄ›juÃ© fÄng'Ã n shÃ¨jÃ¬ zÃ¬dÃ²nghuÃ  hÃ© kÄ›kÃ oxÃ¬ng de qiÃ¡nlÃ¬.",
        "vocab": "[{'word': 'è®¾è®¡', 'pinyin': 'shÃ¨jÃ¬', 'trans': 'design'},\n{'word': 'å¤æ‚', 'pinyin': 'fÃ¹zÃ¡', 'trans': 'complex'},\n{'word': 'å·¥ç¨‹', 'pinyin': 'gÅngchÃ©ng', 'trans': 'engineering'},\n{'word': 'æŒ‘æˆ˜', 'pinyin': 'tiÇozhÃ n', 'trans': 'challenge'},\n{'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ›juÃ© fÄngÃ n', 'trans': 'solution'},\n{'word': 'è‡³å…³é‡è¦', 'pinyin': 'zhÃ¬guÄn zhÃ²ngyÃ o', 'trans': 'crucial'},\n{'word': 'æ£€ç´¢', 'pinyin': 'jiÇnsuÇ’', 'trans': 'retrieval'},\n{'word': 'å¢å¼º', 'pinyin': 'zÄ“ngqiÃ¡ng', 'trans': 'enhanced'},\n{'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generation'},\n{'word': 'ç ”ç©¶', 'pinyin': 'yÃ¡njiÅ«', 'trans': 'research'},\n{'word': 'æœªèƒ½', 'pinyin': 'wÃ¨inÃ©ng', 'trans': 'failed to'},\n{'word': 'å……åˆ†', 'pinyin': 'chÅngfÃ¨n', 'trans': 'adequately'},\n{'word': 'ç›¸å…³', 'pinyin': 'xiÄngguÄn', 'trans': 'related'},\n{'word': 'ä»»åŠ¡', 'pinyin': 'rÃ¨nwÃ¹', 'trans': 'task'},\n{'word': 'å¼•å…¥', 'pinyin': 'yÇnrÃ¹', 'trans': 'introduce'},\n{'word': 'åŸºå‡†', 'pinyin': 'jÄ«zhÇ”n', 'trans': 'benchmark'},\n{'word': 'è¯„ä¼°', 'pinyin': 'pÃ­nggÅ«', 'trans': 'evaluate'},\n{'word': 'ç³»ç»Ÿ', 'pinyin': 'xÃ¬tÇ’ng', 'trans': 'system'},\n{'word': 'å®Œæ•´', 'pinyin': 'wÃ¡nzhÄ›ng', 'trans': 'complete'},\n{'word': 'å¯è¡Œ', 'pinyin': 'kÄ›xÃ­ng', 'trans': 'feasible'},\n{'word': 'å·¥ç¨‹é—®é¢˜', 'pinyin': 'gÅngchÃ©ng wÃ¨ntÃ­', 'trans': 'engineering problem'},\n{'word': 'è§£å†³æ–¹æ¡ˆ', 'pinyin': 'jiÄ›juÃ© fÄngÃ n', 'trans': 'solution'},\n{'word': 'èƒ½åŠ›', 'pinyin': 'nÃ©nglÃ¬', 'trans': 'capability'},\n{'word': 'æå‡º', 'pinyin': 'tÃ­chÅ«', 'trans': 'propose'},\n{'word': 'æ–°ç³»ç»Ÿ', 'pinyin': 'xÄ«n xÃ¬tÇ’ng', 'trans': 'new system'},\n{'word': 'åˆ©ç”¨', 'pinyin': 'lÃ¬yÃ²ng', 'trans': 'utilize'},\n{'word': 'åŸºäº', 'pinyin': 'jÄ«yÃº', 'trans': 'based on'},\n{'word': 'æ ‘', 'pinyin': 'shÃ¹', 'trans': 'tree'},\n{'word': 'æ¢ç´¢', 'pinyin': 'tÃ nsuÇ’', 'trans': 'exploration'},\n{'word': 'åŒç‚¹æ€ç»´', 'pinyin': 'shuÄngdiÇn sÄ«wÃ©i', 'trans': 'dual-point thinking'},\n{'word': 'æœºåˆ¶', 'pinyin': 'jÄ«zhÃ¬', 'trans': 'mechanism'},\n{'word': 'ç”Ÿæˆ', 'pinyin': 'shÄ“ngchÃ©ng', 'trans': 'generate'},\n{'word': 'å¯é ', 'pinyin': 'kÄ›kÃ o', 'trans': 'reliable'},\n{'word': 'å®éªŒ', 'pinyin': 'shÃ­yÃ n', 'trans': 'experiment'},\n{'word': 'ç»“æœ', 'pinyin': 'jiÃ©guÇ’', 'trans': 'result'},\n{'word': 'æ˜¾ç¤º', 'pinyin': 'xiÇnshÃ¬', 'trans': 'show'},\n{'word': 'è¾¾åˆ°', 'pinyin': 'dÃ¡dÃ o', 'trans': 'achieve'},\n{'word': 'æœ€å…ˆè¿›', 'pinyin': 'zuÃ¬ xiÄnjÃ¬n', 'trans': 'state-of-the-art'},\n{'word': 'æ€§èƒ½', 'pinyin': 'xÃ¬ngnÃ©ng', 'trans': 'performance'},\n{'word': 'çªæ˜¾', 'pinyin': 'tÅ«xiÇn', 'trans': 'highlight'},\n{'word': 'æ½œåŠ›', 'pinyin': 'qiÃ¡nlÃ¬', 'trans': 'potential'},\n{'word': 'å®é™…', 'pinyin': 'shÃ­jÃ¬', 'trans': 'practical'},\n{'word': 'åº”ç”¨', 'pinyin': 'yÃ¬ngyÃ²ng', 'trans': 'application'},\n{'word': 'å¢å¼º', 'pinyin': 'zÄ“ngqiÃ¡ng', 'trans': 'enhance'},\n{'word': 'è‡ªåŠ¨åŒ–', 'pinyin': 'zÃ¬dÃ²nghuÃ ', 'trans': 'automation'}]",
        "trans": "Designing solutions for complex engineering challenges is crucial for human productive activities. However, previous research on Retrieval-Augmented Generation (RAG) has failed to adequately address tasks related to the design of complex engineering solutions. We introduce a new benchmark, SolutionBench, to evaluate the capability of systems to generate complete and feasible engineering problem solutions. We also propose a new system, SolutionRAG, which utilizes tree-based exploration and dual-point thinking mechanisms to generate reliable solutions. Experimental results demonstrate that SolutionRAG achieves state-of-the-art performance on SolutionBench, highlighting its potential to enhance the automation and reliability of complex engineering solution design in practical applications.",
        "update_ts": "2025-03-03 09:12"
    }
}