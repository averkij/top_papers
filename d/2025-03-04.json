{
    "date": {
        "ru": "4 марта",
        "en": "March 4",
        "zh": "3月4日"
    },
    "time_utc": "2025-03-04 04:13",
    "weekday": 1,
    "issue_id": 2510,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.00784",
            "title": "DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with Dynamic Multi-Sequence Drafting",
            "url": "https://huggingface.co/papers/2503.00784",
            "abstract": "Large language models (LLMs) exhibit exceptional performance across a wide range of tasks; however, their token-by-token autoregressive generation process significantly hinders inference speed. Speculative decoding presents a promising draft-then-verify framework that reduces generation latency while maintaining output distribution fidelity. Nevertheless, the draft model introduces additional computational overhead, becoming a performance bottleneck and increasing the time to first token (TTFT). Previous approaches to mitigate draft model overhead have primarily relied on heuristics and generally failed to match the quality of the draft language models. To address these challenges, we propose DuoDecoding, a novel approach that strategically deploys the draft and target models on the CPU and GPU respectively, enabling parallel decoding while preserving draft quality. Our method incorporates a hardware-aware optimal draft budget to minimize idle times and employs dynamic multi-sequence drafting to enhance draft quality. Extensive experiments across seven tasks show that DuoDecoding achieves up to 2.61x speedup in generation latency, while reducing TTFT to 83% of that in conventional speculative decoding. The Code is available at https://github.com/KaiLv69/DuoDecoding.",
            "score": 5,
            "issue_id": 2510,
            "pub_date": "2025-03-02",
            "pub_date_card": {
                "ru": "2 марта",
                "en": "March 2",
                "zh": "3月2日"
            },
            "hash": "b4870a0e44c3cc55",
            "authors": [
                "Kai Lv",
                "Honglin Guo",
                "Qipeng Guo",
                "Xipeng Qiu"
            ],
            "affiliations": [
                "Fudan University",
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.00784.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "DuoDecoding: Параллельное ускорение языковых моделей",
                    "desc": "Статья представляет новый метод ускорения генерации текста большими языковыми моделями (LLM) под названием DuoDecoding. Этот подход использует параллельное декодирование на CPU и GPU, оптимизируя время генерации первого токена и общую латентность. DuoDecoding применяет аппаратно-ориентированный оптимальный бюджет черновика и динамическое многопоследовательное черновое декодирование для повышения качества. Эксперименты показали значительное ускорение генерации по сравнению с обычным спекулятивным декодированием."
                },
                "en": {
                    "title": "DuoDecoding: Speeding Up Text Generation with Smart Model Deployment",
                    "desc": "This paper introduces DuoDecoding, a new method to improve the speed of generating text with large language models (LLMs) while keeping the quality high. It uses a draft-then-verify approach, where a draft model quickly generates initial text, and a target model refines it, but does so in a way that reduces the time it takes to start generating text. By using both CPU and GPU for different parts of the process, DuoDecoding allows for faster and more efficient decoding. The results show that this method can significantly speed up text generation without sacrificing quality, achieving a notable improvement in performance across various tasks."
                },
                "zh": {
                    "title": "DuoDecoding：加速生成的新方法",
                    "desc": "大型语言模型（LLMs）在多种任务中表现出色，但其逐字自回归生成过程显著影响推理速度。推测解码提供了一种有前景的草稿-验证框架，能够减少生成延迟，同时保持输出分布的准确性。我们提出的DuoDecoding方法通过在CPU和GPU上分别部署草稿模型和目标模型，实现了并行解码，提升了生成效率。实验结果表明，DuoDecoding在生成延迟上实现了最高2.61倍的加速，同时将首次生成时间缩短至传统推测解码的83%。"
                }
            }
        }
    ],
    "link_prev": "2025-03-03.html",
    "link_next": "2025-03-05.html",
    "link_month": "2025-03.html",
    "short_date_prev": {
        "ru": "03.03",
        "en": "03/03",
        "zh": "3月3日"
    },
    "short_date_next": {
        "ru": "05.03",
        "en": "03/05",
        "zh": "3月5日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "设计复杂工程挑战的解决方案对人类生产活动至关重要。然而，以前的检索增强生成（RAG）研究未能充分解决与复杂工程解决方案设计相关的任务。我们引入了一个新的基准，SolutionBench，来评估系统生成完整和可行的工程问题解决方案的能力。我们还提出了一个新系统，SolutionRAG，利用基于树的探索和双点思维机制生成可靠的解决方案。实验结果显示，SolutionRAG在SolutionBench上达到了最先进的性能，突显了其在实际应用中增强复杂工程解决方案设计自动化和可靠性的潜力。",
        "title": "DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking",
        "pinyin": "设计复杂工程挑战的解决方案对人类生产活动至关重要。然而，以前的检索增强生成（RAG）研究未能充分解决与复杂工程解决方案设计相关的任务。我们引入了一个新的基准，SolutionBench，来评估系统生成完整和可行的工程问题解决方案的能力。我们还提出了一个新系统，SolutionRAG，利用基于树的探索和双点思维机制生成可靠的解决方案。实验结果显示，SolutionRAG在SolutionBench上达到了最先进的性能，突显了其在实际应用中增强复杂工程解决方案设计自动化和可靠性的潜力。\n\nShèjì fùzá gōngchéng tiǎozhàn de jiějué fāng'àn duì rénlèi shēngchǎn huódòng zhìguān zhòngyào. Rán'ér, yǐqián de jiǎnsuǒ zēngqiáng shēngchéng (RAG) yánjiū wèi néng chóngfēn jiějué yǔ fùzá gōngchéng jiějué fāng'àn shèjì xiāngguān de rènwù. Wǒmen yǐnrù le yīgè xīn de jīzhǔn, SolutionBench, lái pínggū xìtǒng shēngchéng wánzhěng hé kěxíng de gōngchéng wèntí jiějué fāng'àn de nénglì. Wǒmen hái tíchū le yīgè xīn xìtǒng, SolutionRAG, lìyòng jīyú shù de tànsuǒ hé shuāngdiǎn sīwéi jīzhì shēngchéng kěkào de jiějué fāng'àn. Shíyàn jiéguǒ xiǎnshì, SolutionRAG zài SolutionBench shàng dá dào le zuì xiānjìn de xìngnéng, tūxì le qí zài shíjì yìngyòng zhōng zēngqiáng fùzá gōngchéng jiějué fāng'àn shèjì zìdònghuà hé kěkàoxìng de qiánlì.",
        "vocab": "[{'word': '设计', 'pinyin': 'shèjì', 'trans': 'design'},\n{'word': '复杂', 'pinyin': 'fùzá', 'trans': 'complex'},\n{'word': '工程', 'pinyin': 'gōngchéng', 'trans': 'engineering'},\n{'word': '挑战', 'pinyin': 'tiǎozhàn', 'trans': 'challenge'},\n{'word': '解决方案', 'pinyin': 'jiějué fāngàn', 'trans': 'solution'},\n{'word': '至关重要', 'pinyin': 'zhìguān zhòngyào', 'trans': 'crucial'},\n{'word': '检索', 'pinyin': 'jiǎnsuǒ', 'trans': 'retrieval'},\n{'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhanced'},\n{'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generation'},\n{'word': '研究', 'pinyin': 'yánjiū', 'trans': 'research'},\n{'word': '未能', 'pinyin': 'wèinéng', 'trans': 'failed to'},\n{'word': '充分', 'pinyin': 'chōngfèn', 'trans': 'adequately'},\n{'word': '相关', 'pinyin': 'xiāngguān', 'trans': 'related'},\n{'word': '任务', 'pinyin': 'rènwù', 'trans': 'task'},\n{'word': '引入', 'pinyin': 'yǐnrù', 'trans': 'introduce'},\n{'word': '基准', 'pinyin': 'jīzhǔn', 'trans': 'benchmark'},\n{'word': '评估', 'pinyin': 'pínggū', 'trans': 'evaluate'},\n{'word': '系统', 'pinyin': 'xìtǒng', 'trans': 'system'},\n{'word': '完整', 'pinyin': 'wánzhěng', 'trans': 'complete'},\n{'word': '可行', 'pinyin': 'kěxíng', 'trans': 'feasible'},\n{'word': '工程问题', 'pinyin': 'gōngchéng wèntí', 'trans': 'engineering problem'},\n{'word': '解决方案', 'pinyin': 'jiějué fāngàn', 'trans': 'solution'},\n{'word': '能力', 'pinyin': 'nénglì', 'trans': 'capability'},\n{'word': '提出', 'pinyin': 'tíchū', 'trans': 'propose'},\n{'word': '新系统', 'pinyin': 'xīn xìtǒng', 'trans': 'new system'},\n{'word': '利用', 'pinyin': 'lìyòng', 'trans': 'utilize'},\n{'word': '基于', 'pinyin': 'jīyú', 'trans': 'based on'},\n{'word': '树', 'pinyin': 'shù', 'trans': 'tree'},\n{'word': '探索', 'pinyin': 'tànsuǒ', 'trans': 'exploration'},\n{'word': '双点思维', 'pinyin': 'shuāngdiǎn sīwéi', 'trans': 'dual-point thinking'},\n{'word': '机制', 'pinyin': 'jīzhì', 'trans': 'mechanism'},\n{'word': '生成', 'pinyin': 'shēngchéng', 'trans': 'generate'},\n{'word': '可靠', 'pinyin': 'kěkào', 'trans': 'reliable'},\n{'word': '实验', 'pinyin': 'shíyàn', 'trans': 'experiment'},\n{'word': '结果', 'pinyin': 'jiéguǒ', 'trans': 'result'},\n{'word': '显示', 'pinyin': 'xiǎnshì', 'trans': 'show'},\n{'word': '达到', 'pinyin': 'dádào', 'trans': 'achieve'},\n{'word': '最先进', 'pinyin': 'zuì xiānjìn', 'trans': 'state-of-the-art'},\n{'word': '性能', 'pinyin': 'xìngnéng', 'trans': 'performance'},\n{'word': '突显', 'pinyin': 'tūxiǎn', 'trans': 'highlight'},\n{'word': '潜力', 'pinyin': 'qiánlì', 'trans': 'potential'},\n{'word': '实际', 'pinyin': 'shíjì', 'trans': 'practical'},\n{'word': '应用', 'pinyin': 'yìngyòng', 'trans': 'application'},\n{'word': '增强', 'pinyin': 'zēngqiáng', 'trans': 'enhance'},\n{'word': '自动化', 'pinyin': 'zìdònghuà', 'trans': 'automation'}]",
        "trans": "Designing solutions for complex engineering challenges is crucial for human productive activities. However, previous research on Retrieval-Augmented Generation (RAG) has failed to adequately address tasks related to the design of complex engineering solutions. We introduce a new benchmark, SolutionBench, to evaluate the capability of systems to generate complete and feasible engineering problem solutions. We also propose a new system, SolutionRAG, which utilizes tree-based exploration and dual-point thinking mechanisms to generate reliable solutions. Experimental results demonstrate that SolutionRAG achieves state-of-the-art performance on SolutionBench, highlighting its potential to enhance the automation and reliability of complex engineering solution design in practical applications.",
        "update_ts": "2025-03-03 09:12"
    }
}