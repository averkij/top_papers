
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
            <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-C1CRWDNJ1J');
            </script>
            <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
            <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap" rel="stylesheet">
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Chinese reading task about ML</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background-color: #f4f4f9;
                    color: #333;
                    margin: 0;
                    padding: 20px;
                }
                .container {
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                }
                h1 {
                    color: #0056b3;
                    text-align: center;
                }
                p {
                    line-height: 1.6;
                }
                .zh-text {
                    font-size: 1.3em;
                    font-family: 'Noto Sans SC';
                    font-weight: 300;
                    margin: 0 0 5px 0;
                }
                .pinyin {
                    padding-top: 5px;
                    padding-bottom: 5px;
                    font-style: italic;
                    color: #888;
                }
                table {
                    width: 100%;
                    border-collapse: collapse;
                    margin-top: 20px;
                }
                th, td {
                    padding: 12px;
                    border: 1px solid #ddd;
                    text-align: left;
                }
                th {
                    background-color: #0056b3;
                    color: #fff;
                }
                td {
                    background-color: #f9f9f9;
                }
                td.zh {
                    font-family: 'Noto Sans SC';
                    font-size: 1.2em;
                    font-weight: 400;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization</h1>
                <div><p class='zh-text'>1. 这篇文章讨论了计算机视觉（CV）尚未完全实现自然语言处理（NLP）中观察到的零样本任务泛化。</p>
<p class='zh-text'>2. 作者提出，CV 使用离散和术语化的任务定义（如“图像分割”），这可能是零样本任务泛化的主要障碍。</p>
<p class='zh-text'>3. 为了验证这一点，作者引入了解释性指令，通过详细的语言转换从输入图像到输出来定义 CV 任务目标。</p>
<p class='zh-text'>4. 他们创建了一个包含 1200 万个“图像输入到解释性指令到输出”三元组的大规模数据集，并训练了一个自回归视觉-语言模型（AR-based VLM），该模型以图像和解释性指令作为输入。</p>
<p class='zh-text'>5. 通过学习遵循这些指令，AR-based VLM 实现了指令级别的零样本能力，并在未见过的 CV 任务上展示了强大的零样本泛化。</p>
<p class='zh-text'>6. 代码和数据集将在 GitHub 存储库中公开。</p></div>
                <div class="pinyin">
                    <p>1. 这篇文章讨论了计算机视觉（CV）尚未完全实现自然语言处理（NLP）中观察到的零样本任务泛化。
Zhè piān wénzhāng tǎolùn le jìsuànjī shìjué (CV) shàng wèi quánxiàn shíxiàn zìrán yǔyán chǔlǐ (NLP) zhōng guānchá dào de líng yàngbǎn rènwù fànhuà</p>
<p>2. 

作者提出，CV 使用离散和术语化的任务定义（如“图像分割”），这可能是零样本任务泛化的主要障碍。
Zuòzhě tíchū, CV shǐyòng lí sàn hé shùyǔ huà de rènwù dìngyì (rú “túxiàng fēngē”), zhè kěnéng shì líng yàngbǎn rènwù fànhuà de zhǔyào zhàng'ài</p>
<p>3. 

为了验证这一点，作者引入了解释性指令，通过详细的语言转换从输入图像到输出来定义 CV 任务目标。
Wèile yànzhèng zhè yī diǎn, zuòzhě yǐnrù le jiěshì xìng zhǐlìng, tōngguò xiángxì de yǔyán zhuǎnhuàn cóng shūrù túxiàng dào shūchū lái dìngyì CV rènwù mùbiāo</p>
<p>4. 

他们创建了一个包含 1200 万个“图像输入到解释性指令到输出”三元组的大规模数据集，并训练了一个自回归视觉-语言模型（AR-based VLM），该模型以图像和解释性指令作为输入。
Tāmen chuàngjiàn le yīgè bāohán 1200 wàn gè “túxiàng shūrù dào jiěshì xìng zhǐlìng dào shūchū” sānyuánzǔ de dà guīmó shùjùjí, bìng xùnliàn le yīgè zì huíguī shìjué-yǔyán móxíng (AR-based VLM), gāi móxíng yǐ túxiàng hé jiěshì xìng zhǐlìng zuòwéi shūrù</p>
<p>5. 

通过学习遵循这些指令，AR-based VLM 实现了指令级别的零样本能力，并在未见过的 CV 任务上展示了强大的零样本泛化。
Tōngguò xuéxí zūnxún zhèxiē zhǐlìng, AR-based VLM shíxiàn le zhǐlìng jíbié de líng yàngbǎn nénglì, bìng zài wèi jiànguò de CV rènwù shàng zhǎnshì le qiángdà de líng yàngbǎn fànhuà</p>
<p>6. 

代码和数据集将在 GitHub 存储库中公开。
Dàimǎ hé shùjùjí jiāng zài GitHub cúnchūkù zhōng gōngkāi</p>
                </div>
                <div><p>1. This article discusses the fact that computer vision (CV) has not yet fully achieved the zero-shot task generalization observed in natural language processing (NLP).</p>
<p>2.  The authors suggest that CV's use of discrete and terminological task definitions (such as "image segmentation") may be a major obstacle to zero-shot task generalization.</p>
<p>3.  To validate this, the authors introduce explanatory instructions, defining CV task objectives through detailed language transformations from input images to outputs.</p>
<p>4.  They created a large-scale dataset containing 12 million "image input to explanatory instruction to output" triplets and trained an autoregressive vision-language model (AR-based VLM) that takes images and explanatory instructions as inputs.</p>
<p>5.  By learning to follow these instructions, the AR-based VLM achieved instruction-level zero-shot capabilities and demonstrated strong zero-shot generalization on unseen CV tasks.</p>
<p>6.  The code and dataset will be made publicly available on a GitHub repository.</p></div>
                <h2>Vocabulary</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Word</th>
                            <th>Pinyin</th>
                            <th>Translation</th>
                        </tr>
                    </thead>
                    <tbody>
        
                        <tr>
                            <td class="zh">讨论</td>
                            <td>tǎo lùn</td>
                            <td>discuss</td>
                        </tr>
            
                        <tr>
                            <td class="zh">计算机视觉</td>
                            <td>jì suàn jī shì jué</td>
                            <td>computer vision</td>
                        </tr>
            
                        <tr>
                            <td class="zh">自然语言处理</td>
                            <td>zì rán yǔ yán chǔ lǐ</td>
                            <td>natural language processing</td>
                        </tr>
            
                        <tr>
                            <td class="zh">观察</td>
                            <td>guān chá</td>
                            <td>observe</td>
                        </tr>
            
                        <tr>
                            <td class="zh">零样本任务泛化</td>
                            <td>líng yàng běn rèn wù fàn huà</td>
                            <td>zero-shot task generalization</td>
                        </tr>
            
                        <tr>
                            <td class="zh">提出</td>
                            <td>tí chū</td>
                            <td>propose</td>
                        </tr>
            
                        <tr>
                            <td class="zh">离散</td>
                            <td>lí sàn</td>
                            <td>discrete</td>
                        </tr>
            
                        <tr>
                            <td class="zh">术语化</td>
                            <td>shù yǔ huà</td>
                            <td>terminological</td>
                        </tr>
            
                        <tr>
                            <td class="zh">任务定义</td>
                            <td>rèn wù dìng yì</td>
                            <td>task definition</td>
                        </tr>
            
                        <tr>
                            <td class="zh">图像分割</td>
                            <td>tú xiàng fēn gē</td>
                            <td>image segmentation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">障碍</td>
                            <td>zhàng ài</td>
                            <td>obstacle</td>
                        </tr>
            
                        <tr>
                            <td class="zh">验证</td>
                            <td>yàn zhèng</td>
                            <td>verify</td>
                        </tr>
            
                        <tr>
                            <td class="zh">引入</td>
                            <td>yǐn rù</td>
                            <td>introduce</td>
                        </tr>
            
                        <tr>
                            <td class="zh">解释性指令</td>
                            <td>jiě shì xìng zhǐ lǐng</td>
                            <td>explanatory instructions</td>
                        </tr>
            
                        <tr>
                            <td class="zh">语言转换</td>
                            <td>yǔ yán zhuǎn huàn</td>
                            <td>language transformation</td>
                        </tr>
            
                        <tr>
                            <td class="zh">输入图像</td>
                            <td>shū rù tú xiàng</td>
                            <td>input image</td>
                        </tr>
            
                        <tr>
                            <td class="zh">输出</td>
                            <td>shū chū</td>
                            <td>output</td>
                        </tr>
            
                        <tr>
                            <td class="zh">三元组</td>
                            <td>sān yuán zǔ</td>
                            <td>triplet</td>
                        </tr>
            
                        <tr>
                            <td class="zh">大规模数据集</td>
                            <td>dà guī mó shù jù</td>
                            <td>large-scale dataset</td>
                        </tr>
            
                        <tr>
                            <td class="zh">自回归视觉-语言模型</td>
                            <td>zì huí guī shì jué yǔ yán mó xíng</td>
                            <td>autoregressive vision-language model</td>
                        </tr>
            
                        <tr>
                            <td class="zh">遵循</td>
                            <td>zūn zhòng</td>
                            <td>follow</td>
                        </tr>
            
                        <tr>
                            <td class="zh">指令级别</td>
                            <td>zhǐ lǐng jí bié</td>
                            <td>instruction level</td>
                        </tr>
            
                        <tr>
                            <td class="zh">零样本能力</td>
                            <td>líng yàng běn néng lì</td>
                            <td>zero-shot capability</td>
                        </tr>
            
                        <tr>
                            <td class="zh">展示</td>
                            <td>zhǎn shì</td>
                            <td>demonstrate</td>
                        </tr>
            
                        <tr>
                            <td class="zh">未见过的</td>
                            <td>wèi jiàn guò de</td>
                            <td>unseen</td>
                        </tr>
            
                        <tr>
                            <td class="zh">存储库</td>
                            <td>cún chǔ kù</td>
                            <td>repository</td>
                        </tr>
            
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        