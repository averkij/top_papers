{
    "date": {
        "ru": "12 декабря",
        "en": "December 12",
        "zh": "12月12日"
    },
    "time_utc": "2024-12-12 03:29",
    "weekday": 3,
    "issue_id": 1080,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.07797",
            "title": "Mogo: RQ Hierarchical Causal Transformer for High-Quality 3D Human Motion Generation",
            "url": "https://huggingface.co/papers/2412.07797",
            "abstract": "In the field of text-to-motion generation, Bert-type Masked Models (MoMask, MMM) currently produce higher-quality outputs compared to GPT-type autoregressive models (T2M-GPT). However, these Bert-type models often lack the streaming output capability required for applications in video game and multimedia environments, a feature inherent to GPT-type models. Additionally, they demonstrate weaker performance in out-of-distribution generation. To surpass the quality of BERT-type models while leveraging a GPT-type structure, without adding extra refinement models that complicate scaling data, we propose a novel architecture, Mogo (Motion Only Generate Once), which generates high-quality lifelike 3D human motions by training a single transformer model. Mogo consists of only two main components: 1) RVQ-VAE, a hierarchical residual vector quantization variational autoencoder, which discretizes continuous motion sequences with high precision; 2) Hierarchical Causal Transformer, responsible for generating the base motion sequences in an autoregressive manner while simultaneously inferring residuals across different layers. Experimental results demonstrate that Mogo can generate continuous and cyclic motion sequences up to 260 frames (13 seconds), surpassing the 196 frames (10 seconds) length limitation of existing datasets like HumanML3D. On the HumanML3D test set, Mogo achieves a FID score of 0.079, outperforming both the GPT-type model T2M-GPT (FID = 0.116), AttT2M (FID = 0.112) and the BERT-type model MMM (FID = 0.080). Furthermore, our model achieves the best quantitative performance in out-of-distribution generation.",
            "score": 1,
            "issue_id": 1080,
            "pub_date": "2024-12-05",
            "pub_date_card": {
                "ru": "5 декабря",
                "en": "December 5",
                "zh": "12月5日"
            },
            "hash": "ff9bb8b603f9d972",
            "authors": [
                "Dongjie Fu"
            ],
            "affiliations": [
                "Mogo AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.07797.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#3d",
                    "#games",
                    "#architecture"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Mogo: Революция в генерации движений из текста",
                    "desc": "Статья представляет новую архитектуру Mogo для генерации высококачественных трехмерных движений человека на основе текста. Mogo использует RVQ-VAE для дискретизации непрерывных последовательностей движений и иерархический причинный трансформер для генерации базовых последовательностей движений. Эксперименты показывают, что Mogo превосходит существующие модели по качеству генерации, включая GPT-подобные и BERT-подобные модели. Модель также демонстрирует лучшие результаты при генерации вне распределения обучающих данных."
                },
                "en": {
                    "title": "Mogo: Revolutionizing Text-to-Motion with High-Quality 3D Generation",
                    "desc": "This paper introduces Mogo, a new architecture for generating high-quality 3D human motions from text. Mogo combines a hierarchical residual vector quantization variational autoencoder (RVQ-VAE) with a hierarchical causal transformer to produce continuous and cyclic motion sequences efficiently. Unlike existing Bert-type models, Mogo maintains the streaming output capability of GPT-type models while improving performance in out-of-distribution scenarios. Experimental results show that Mogo not only generates longer motion sequences but also achieves superior quality metrics compared to both GPT-type and Bert-type models."
                },
                "zh": {
                    "title": "Mogo：高效生成高质量3D人类动作的创新架构",
                    "desc": "在文本到动作生成领域，Bert类型的模型（如MoMask, MMM）虽然输出质量较高，但缺乏流式输出能力，无法满足视频游戏和多媒体环境的需求。相比之下，GPT类型的自回归模型（如T2M-GPT）具备这一特性，但在生成质量上稍逊一筹。为了解决这一问题，我们提出了一种新架构Mogo（Motion Only Generate Once），它通过训练单一的变换器模型生成高质量的3D人类动作。Mogo结合了高精度的层次残差向量量化变分自编码器和层次因果变换器，能够生成连续且循环的动作序列，超越了现有数据集的限制。"
                }
            }
        }
    ],
    "link_prev": "2024-12-11.html",
    "link_next": "2024-12-13.html",
    "link_month": "2024-12.html",
    "short_date_prev": {
        "ru": "11.12",
        "en": "12/11",
        "zh": "12月11日"
    },
    "short_date_next": {
        "ru": "13.12",
        "en": "12/13",
        "zh": "12月13日"
    },
    "categories": {
        "#dataset": 0,
        "#data": 0,
        "#benchmark": 0,
        "#agents": 0,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 0,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 0,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章讨论了代码大语言模型（codeLLMs）在代码生成方面的进展。以前的代码相关基准测试主要关注生成正确的代码片段，但忽略了与人类偏好的一致性。为了弥补这一差距，作者提出了一个名为CodeArena的严格人工编制基准测试，模拟真实世界编码任务的复杂性和多样性。通过系统实验，作者发现在开源代码LLMs和专有LLMs之间存在显著的性能差距，强调了人类偏好一致性的重要性。",
        "title": "Evaluating and Aligning CodeLLMs on Human Preference",
        "pinyin": "这篇文章讨论了代码大语言模型（codeLLMs）在代码生成方面的进展。以前的代码相关基准测试主要关注生成正确的代码片段，但忽略了与人类偏好的一致性。为了弥补这一差距，作者提出了一个名为CodeArena的严格人工编制基准测试，模拟真实世界编码任务的复杂性和多样性。通过系统实验，作者发现在开源代码LLMs和专有LLMs之间存在显著的性能差距，强调了人类偏好一致性的重要性。\n\nzhè piān wén zhāng tǎo lùn le dài mǎ dà yǔ yán mó xíng (codeLLMs) zài dài mǎ shēng chéng fāng miàn de jìn zhàn. yǐ qián de dài mǎ xiāng guān jī zhǔn cè shì zhǔ yào guān zhù shēng chéng zhèng què de dài mǎ piàn duàn, dàn hū lüè le yǔ rén lèi piān hào de yī zhì xìng. wèi le mí bǔ zhè yī chā jù, zuò zhě tí chū le yī gè míng wèi CodeArena de yán gé rén gōng biān zhì jī zhǔn cè shì, mó nǐ zhēn shí shì jiè biān mǎ rèn wù de fú zà xìng hé duō yàng xìng. tōng guò xì tǒng shí yàn, zuò zhě fā xiàn zài kāi yuán dài mǎ LLMs hé zhuān yǒu LLMs zhī jiān cún zài xiǎn zhù de xìng néng chā jù, qiáng diào le rén lèi piān hào yī zhì xìng de zhòng yào xìng.",
        "vocab": "[{'word': '讨论', 'pinyin': 'tǎo lùn', 'trans': 'discuss'},\n{'word': '代码', 'pinyin': 'dài mǎ', 'trans': 'code'},\n{'word': '大语言模型', 'pinyin': 'dà yǔ yán mó xíng', 'trans': 'large language model'},\n{'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'},\n{'word': '以前', 'pinyin': 'yǐ qián', 'trans': 'before'},\n{'word': '相关', 'pinyin': 'xiāng guān', 'trans': 'related'},\n{'word': '基准测试', 'pinyin': 'jī zhǔn cè shì', 'trans': 'benchmark test'},\n{'word': '主要', 'pinyin': 'zhǔ yào', 'trans': 'main'},\n{'word': '关注', 'pinyin': 'guān zhù', 'trans': 'focus on'},\n{'word': '生成', 'pinyin': 'shēng chéng', 'trans': 'generate'},\n{'word': '正确', 'pinyin': 'zhèng què', 'trans': 'correct'},\n{'word': '片段', 'pinyin': 'piàn duàn', 'trans': 'segment'},\n{'word': '忽略', 'pinyin': 'hū lüè', 'trans': 'ignore'},\n{'word': '一致性', 'pinyin': 'yī zhì xìng', 'trans': 'consistency'},\n{'word': '弥补', 'pinyin': 'mí bǔ', 'trans': 'make up for'},\n{'word': '差距', 'pinyin': 'chā jù', 'trans': 'gap'},\n{'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'},\n{'word': '严格', 'pinyin': 'yán gé', 'trans': 'strict'},\n{'word': '人工编制', 'pinyin': 'rén gōng biān zhì', 'trans': 'artificially compiled'},\n{'word': '模拟', 'pinyin': 'mó nǐ', 'trans': 'simulate'},\n{'word': '真实世界', 'pinyin': 'zhēn shí shì jiè', 'trans': 'real world'},\n{'word': '复杂性', 'pinyin': 'fù zá xìng', 'trans': 'complexity'},\n{'word': '多样性', 'pinyin': 'duō yàng xìng', 'trans': 'diversity'},\n{'word': '系统', 'pinyin': 'xì tǒng', 'trans': 'system'},\n{'word': '实验', 'pinyin': 'shí yàn', 'trans': 'experiment'},\n{'word': '开源', 'pinyin': 'kāi yuán', 'trans': 'open source'},\n{'word': '专有', 'pinyin': 'zhuān yǒu', 'trans': 'proprietary'},\n{'word': '存在', 'pinyin': 'cún zài', 'trans': 'exist'},\n{'word': '显著', 'pinyin': 'xiǎn zhù', 'trans': 'significant'},\n{'word': '性能', 'pinyin': 'xìng néng', 'trans': 'performance'},\n{'word': '强调', 'pinyin': 'qiáng diào', 'trans': 'emphasize'},\n{'word': '重要性', 'pinyin': 'zhòng yào xìng', 'trans': 'importance'}]",
        "trans": "This article discusses the advancements in code generation by code large language models (codeLLMs). Previous code-related benchmark tests primarily focused on generating correct code snippets but overlooked consistency with human preferences. To address this gap, the authors propose a rigorous, human-crafted benchmark test called CodeArena, which simulates the complexity and diversity of real-world coding tasks. Through systematic experiments, the authors found a significant performance gap between open-source codeLLMs and proprietary LLMs, highlighting the importance of consistency with human preferences.",
        "update_ts": "2024-12-11 09:11"
    }
}