{
    "date": {
        "ru": "2 января",
        "en": "January 2",
        "zh": "1月2日"
    },
    "time_utc": "2025-01-02 12:18",
    "weekday": 3,
    "issue_id": 1459,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2412.19723",
            "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
            "url": "https://huggingface.co/papers/2412.19723",
            "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at https://qiushisun.github.io/OS-Genesis-Home/{OS-Genesis Homepage}.",
            "score": 35,
            "issue_id": 1455,
            "pub_date": "2025-12-27",
            "pub_date_card": {
                "ru": "27 декабря",
                "en": "December 27",
                "zh": "12月27日"
            },
            "hash": "b331198d09aa8650",
            "authors": [
                "Qiushi Sun",
                "Kanzhi Cheng",
                "Zichen Ding",
                "Chuanyang Jin",
                "Yian Wang",
                "Fangzhi Xu",
                "Zhenyu Wu",
                "Chengyou Jia",
                "Liheng Chen",
                "Zhoumianze Liu",
                "Ben Kao",
                "Guohao Li",
                "Junxian He",
                "Yu Qiao",
                "Zhiyong Wu"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Johns Hopkins University",
                "Shanghai AI Laboratory",
                "Shanghai Jiao Tong University",
                "The University of Hong Kong",
                "University of Oxford"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.19723.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#synthetic",
                    "#dataset",
                    "#optimization",
                    "#training",
                    "#data",
                    "#agents"
                ],
                "emoji": "🖥️",
                "ru": {
                    "title": "Революция в обучении ИИ-агентов: от заданий к исследованию",
                    "desc": "Статья представляет OS-Genesis - новый метод синтеза данных для обучения ИИ-агентов взаимодействию с графическим интерфейсом. Вместо предопределенных задач, агенты сначала исследуют среду и выполняют пошаговые действия, а затем ретроспективно формируют качественные траектории. Используется модель вознаграждения для обеспечения качества сгенерированных траекторий. Результаты показывают значительное улучшение производительности агентов на сложных онлайн-бенчмарках по сравнению с существующими методами."
                },
                "en": {
                    "title": "Revolutionizing GUI Agent Training with OS-Genesis",
                    "desc": "This paper introduces OS-Genesis, a new method for generating high-quality trajectory data for training GUI agents using Vision-Language Models (VLMs). Unlike traditional methods that rely on human supervision or predefined tasks, OS-Genesis allows agents to first interact with their environment and then derive tasks retrospectively. This approach enhances data diversity and quality by enabling agents to explore and learn from real-world interactions. The results show that GUI agents trained with OS-Genesis perform significantly better on challenging benchmarks, demonstrating the effectiveness of this novel data synthesis pipeline."
                },
                "zh": {
                    "title": "OS-Genesis：提升GUI代理性能的新方法",
                    "desc": "本论文提出了一种名为OS-Genesis的新型图形用户界面（GUI）数据合成管道，旨在解决高质量轨迹数据收集的瓶颈。传统方法依赖于人类监督或合成数据生成，往往资源消耗大且数据质量难以保证。OS-Genesis通过让代理先感知环境并进行逐步交互，随后回溯生成高质量任务，从而实现轨迹级探索。实验结果表明，使用OS-Genesis训练的GUI代理在复杂的在线基准测试中表现显著提升，且其数据质量和多样性优于现有合成方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2412.19638",
            "title": "Xmodel-2 Technical Report",
            "url": "https://huggingface.co/papers/2412.19638",
            "abstract": "Xmodel-2 is a 1.2-billion-parameter large language model designed specifically for reasoning tasks. Its architecture enables different model scales to share a unified set of hyperparameters, allowing for extensive experimentation on smaller models and seamless transfer of optimal configurations to larger models. To maximize training efficiency and stability, Xmodel-2 employs the WSD learning rate scheduler from MiniCPM. Pretrained on 1.5 trillion tokens from diverse sources, Xmodel-2 achieves state-of-the-art performance in complex reasoning and agent-based tasks, while maintaining low training costs. These results highlight the potential of efficient model design and training strategies in advancing reasoning capabilities. Model checkpoints and code are publicly available on GitHub at https://github.com/XiaoduoAILab/Xmodel-2",
            "score": 6,
            "issue_id": 1453,
            "pub_date": "2025-12-27",
            "pub_date_card": {
                "ru": "27 декабря",
                "en": "December 27",
                "zh": "12月27日"
            },
            "hash": "4707dc8ac5a87e66",
            "authors": [
                "Wang Qun",
                "Liu Yang",
                "Lin Qingquan",
                "Qu Zhijiu",
                "Jiang Ling"
            ],
            "affiliations": [
                "AI Lab, Xiaodu Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2412.19638.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#small_models",
                    "#reasoning",
                    "#open_source",
                    "#architecture"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное рассуждение с Xmodel-2: мощь в компактности",
                    "desc": "Xmodel-2 - это языковая модель с 1,2 миллиардами параметров, специализирующаяся на задачах рассуждения. Её архитектура позволяет разным масштабам модели использовать единый набор гиперпараметров, что облегчает эксперименты и перенос оптимальных конфигураций. Модель использует планировщик скорости обучения WSD из MiniCPM для повышения эффективности и стабильности. Предобученная на 1,5 триллионах токенов, Xmodel-2 достигает передовых результатов в сложных задачах рассуждения, сохраняя низкие затраты на обучение."
                },
                "en": {
                    "title": "Unlocking Reasoning Power with Efficient Model Design",
                    "desc": "Xmodel-2 is a large language model with 1.2 billion parameters, specifically built for reasoning tasks. It features a flexible architecture that allows different model sizes to use the same hyperparameters, facilitating experimentation and optimization across scales. The model utilizes the WSD learning rate scheduler to enhance training efficiency and stability. With pretraining on 1.5 trillion tokens, Xmodel-2 demonstrates superior performance in complex reasoning tasks while keeping training costs low, showcasing the benefits of efficient model design."
                },
                "zh": {
                    "title": "高效推理能力的模型设计与训练策略",
                    "desc": "Xmodel-2 是一个拥有 12 亿参数的大型语言模型，专门设计用于推理任务。它的架构允许不同规模的模型共享统一的超参数，从而可以在较小的模型上进行广泛实验，并将最佳配置无缝转移到更大的模型上。为了最大化训练效率和稳定性，Xmodel-2 采用了 MiniCPM 的 WSD 学习率调度器。经过在 1.5 万亿个来自多样化来源的标记上进行预训练，Xmodel-2 在复杂推理和基于代理的任务中达到了最先进的性能，同时保持了较低的训练成本。"
                }
            }
        }
    ],
    "link_prev": "2025-01-01.html",
    "link_next": "2025-01-03.html",
    "link_month": "2025-01.html",
    "short_date_prev": {
        "ru": "01.01",
        "en": "01/01",
        "zh": "1月1日"
    },
    "short_date_next": {
        "ru": "03.01",
        "en": "01/03",
        "zh": "1月3日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 1,
        "#benchmark": 1,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种新的图形用户界面（GUI）数据合成方法，称为OS-Genesis。它通过让代理首先感知环境并进行步进交互，然后逆向推导出高质量任务，从而解决了传统方法中数据收集困难的问题。OS-Genesis 使用一种轨迹奖励模型来确保生成轨迹的质量。实验结果表明，使用OS-Genesis训练的GUI代理在挑战性在线基准上表现更好。进一步分析验证了OS-Genesis在数据质量和多样性方面的优越性。",
        "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
        "pinyin": "这篇文章介绍了一种新的图形用户界面（GUI）数据合成方法，称为OS-Genesis。它通过让代理首先感知环境并进行步进交互，然后逆向推导出高质量任务，从而解决了传统方法中数据收集困难的问题。OS-Genesis 使用一种轨迹奖励模型来确保生成轨迹的质量。实验结果表明，使用OS-Genesis训练的GUI代理在挑战性在线基准上表现更好。进一步分析验证了OS-Genesis在数据质量和多样性方面的优越性。\n\nZhè piān wénzhāng jièshào le yī zhǒng xīn de túxíng yònghù jiēmiàn (GUI) shùjù héchéng fāngfǎ, chēngwéi OS-Genesis. Tā tōngguò ràng dàilǐ shǒuxiān gǎnzhī huánjìng bìng jìnxíng bùjìn jiāohù, ránhòu nìxiàng tuīdǎo chū gāo zhìliàng rènwù, cóng'ér jiějué le chuántǒng fāngfǎ zhōng shùjù shōucuì kùnnán de wèntí. OS-Genesis shǐyòng yī zhǒng guǐjī jiǎnglì móxíng lái quèbǎo shēngchéng guǐjī de zhìliàng. Shíyàn jiéguǒ biǎomíng, shǐyòng OS-Genesis xùnliàn de GUI dàilǐ zài tiǎozhànxìng zàixiàn jīzhǔn shàng biǎoxiàn gèng hǎo. Jìn yībù fēnxi yànzhèng le OS-Genesis zài shùjù zhìliàng hé duōyàngxìng fāngmiàn de yōuyuèxìng.",
        "vocab": "[{'word': '图形用户界面', 'pinyin': 'tú xíng yòng hù jiē miàn', 'trans': 'graphical user interface'},\n{'word': '数据合成', 'pinyin': 'shù jù hé chéng', 'trans': 'data synthesis'},\n{'word': '代理', 'pinyin': 'dài lǐ', 'trans': 'agent'},\n{'word': '感知', 'pinyin': 'gǎn zhī', 'trans': 'perceive'},\n{'word': '步进', 'pinyin': 'bù jìn', 'trans': 'stepwise'},\n{'word': '逆向', 'pinyin': 'nì xiàng', 'trans': 'reverse'},\n{'word': '推导', 'pinyin': 'tuī dǎo', 'trans': 'deduce'},\n{'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high quality'},\n{'word': '轨迹', 'pinyin': 'guǐ jì', 'trans': 'trajectory'},\n{'word': '奖励', 'pinyin': 'jiǎng lì', 'trans': 'reward'},\n{'word': '模型', 'pinyin': 'mó xíng', 'trans': 'model'},\n{'word': '确保', 'pinyin': 'què bǎo', 'trans': 'ensure'},\n{'word': '挑战性', 'pinyin': 'tiǎo zhàn xìng', 'trans': 'challenging'},\n{'word': '基准', 'pinyin': 'jī zhǔn', 'trans': 'benchmark'},\n{'word': '多样性', 'pinyin': 'duō yàng xìng', 'trans': 'diversity'},\n{'word': '优越性', 'pinyin': 'yōu yuè xìng', 'trans': 'superiority'}]",
        "trans": "This article introduces a new method for synthesizing Graphical User Interface (GUI) data, called OS-Genesis. It addresses the challenges of data collection in traditional methods by having agents first perceive the environment and engage in step-by-step interactions, then retroactively deduce high-quality tasks. OS-Genesis employs a trajectory reward model to ensure the quality of the generated trajectories. Experimental results show that GUI agents trained using OS-Genesis perform better on challenging online benchmarks. Further analysis validates the superiority of OS-Genesis in terms of data quality and diversity.",
        "update_ts": "2025-01-02 09:10"
    }
}