{
    "date": {
        "ru": "25 июля",
        "en": "July 25",
        "zh": "7月25日"
    },
    "time_utc": "2025-07-25 03:57",
    "weekday": 4,
    "issue_id": 5006,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2507.15758",
            "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy\n  Optimization",
            "url": "https://huggingface.co/papers/2507.15758",
            "abstract": "Large reasoning models have achieved remarkable performance through extended chain-of-thought sequences, yet this computational freedom leads to excessive token generation even for simple problems. We present Length-Adaptive Policy Optimization (LAPO), a novel framework that transforms reasoning length control from an external constraint into an intrinsic model capability. Unlike existing approaches that impose rigid limits or rely on post-hoc interventions, LAPO enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. In the first stage, models learn natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage leverages these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context to ensure inference-time flexibility. Experiments on mathematical reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\% while improving accuracy by 2.3\\%. Our analysis reveals that models trained with LAPO develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality.",
            "score": 12,
            "issue_id": 5006,
            "pub_date": "2025-07-21",
            "pub_date_card": {
                "ru": "21 июля",
                "en": "July 21",
                "zh": "7月21日"
            },
            "hash": "ce0e5d782e94f5ee",
            "authors": [
                "Xingyu Wu",
                "Yuchen Yan",
                "Shangke Lyu",
                "Linjuan Wu",
                "Yiwen Qiu",
                "Yongliang Shen",
                "Weiming Lu",
                "Jian Shao",
                "Jun Xiao",
                "Yueting Zhuang"
            ],
            "affiliations": [
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.15758.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#reasoning",
                    "#math",
                    "#rl",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективные рассуждения: меньше слов, больше смысла",
                    "desc": "Статья представляет новый подход к оптимизации длины рассуждений в больших языковых моделях под названием LAPO (Length-Adaptive Policy Optimization). Этот метод использует двухэтапный процесс обучения с подкреплением, чтобы модели могли самостоятельно определять оптимальную глубину рассуждений. LAPO позволяет сократить использование токенов на 40.9%, одновременно повышая точность на 2.3% на задачах математических рассуждений. Исследование показывает, что модели, обученные с помощью LAPO, развивают способность эффективно распределять вычислительные ресурсы в зависимости от сложности задачи."
                },
                "en": {
                    "title": "Smart Reasoning: Less is More with LAPO",
                    "desc": "This paper introduces Length-Adaptive Policy Optimization (LAPO), a new method for improving reasoning models in machine learning. LAPO allows models to learn how much reasoning is needed for different problems, rather than setting strict limits on reasoning length. It uses a two-stage reinforcement learning process where models first learn successful reasoning patterns and then apply this knowledge during inference. The results show that LAPO can significantly reduce the number of tokens used while also increasing the accuracy of the models."
                },
                "zh": {
                    "title": "智能推理，灵活控制！",
                    "desc": "本文提出了一种新的框架，称为长度自适应策略优化（LAPO），旨在改善推理模型的效率。LAPO通过强化学习的两阶段过程，使模型能够内在理解适当的推理深度，从而减少不必要的计算。第一阶段，模型学习成功解决方案长度的统计分布；第二阶段，模型将这些模式作为元认知指导，嵌入推理上下文中。实验结果表明，LAPO在数学推理基准测试中减少了多达40.9%的标记使用，同时提高了2.3%的准确率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.18537",
            "title": "TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive\n  Generation",
            "url": "https://huggingface.co/papers/2507.18537",
            "abstract": "TTS-VAR, a test-time scaling framework for visual auto-regressive models, improves generation quality by dynamically adjusting batch sizes and using clustering and resampling techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Scaling visual generation models is essential for real-world content creation, yet requires substantial training and computational expenses. Alternatively, test-time scaling has garnered growing attention due to resource efficiency and promising performance. In this work, we present TTS-VAR, the first general test-time scaling framework for visual auto-regressive (VAR) models, modeling the generation process as a path searching problem. To dynamically balance computational efficiency with exploration capacity, we first introduce an adaptive descending batch size schedule throughout the causal generation process. Besides, inspired by VAR's hierarchical coarse-to-fine multi-scale generation, our framework integrates two key components: (i) At coarse scales, we observe that generated tokens are hard for evaluation, possibly leading to erroneous acceptance of inferior samples or rejection of superior samples. Noticing that the coarse scales contain sufficient structural information, we propose clustering-based diversity search. It preserves structural variety through semantic feature clustering, enabling later selection on samples with higher potential. (ii) In fine scales, resampling-based potential selection prioritizes promising candidates using potential scores, which are defined as reward functions incorporating multi-scale generation history. Experiments on the powerful VAR model Infinity show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights reveal that early-stage structural features effectively influence final quality, and resampling efficacy varies across generation scales. Code is available at https://github.com/ali-vilab/TTS-VAR.",
            "score": 7,
            "issue_id": 5005,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 июля",
                "en": "July 24",
                "zh": "7月24日"
            },
            "hash": "acf3b32f27e7342b",
            "authors": [
                "Zhekai Chen",
                "Ruihang Chu",
                "Yukang Chen",
                "Shiwei Zhang",
                "Yujie Wei",
                "Yingya Zhang",
                "Xihui Liu"
            ],
            "affiliations": [
                "CUHK",
                "HKU MMLab",
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18537.jpg",
            "data": {
                "categories": [
                    "#cv",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "Умное масштабирование для лучшей генерации изображений",
                    "desc": "TTS-VAR - это новая система масштабирования визуальных авторегрессионных моделей во время тестирования. Она улучшает качество генерации изображений, динамически регулируя размеры батчей и применяя методы кластеризации и ресэмплинга. TTS-VAR моделирует процесс генерации как задачу поиска пути, балансируя вычислительную эффективность и способность к исследованию. Эксперименты показали значительное улучшение оценки GenEval на 8.7% для модели Infinity."
                },
                "en": {
                    "title": "Dynamic Scaling for Enhanced Visual Generation Quality",
                    "desc": "TTS-VAR is a novel framework designed to enhance the quality of visual auto-regressive (VAR) models during the generation process. It introduces a dynamic batch size adjustment strategy that balances computational efficiency with the ability to explore diverse outputs. The framework employs clustering techniques at coarse scales to maintain structural diversity and resampling methods at fine scales to prioritize high-potential candidates based on their generation history. Experiments demonstrate a significant improvement in generation quality, highlighting the importance of early-stage features in the overall output."
                },
                "zh": {
                    "title": "动态调整，提升生成质量的创新框架",
                    "desc": "TTS-VAR是一个用于视觉自回归模型的测试时间缩放框架，通过动态调整批量大小和使用聚类与重采样技术来提高生成质量。该框架将生成过程建模为路径搜索问题，旨在平衡计算效率与探索能力。它在粗尺度上采用基于聚类的多样性搜索，以保留结构多样性，并在细尺度上通过重采样优先选择潜在的优质样本。实验结果表明，TTS-VAR在强大的VAR模型Infinity上实现了8.7%的GenEval分数提升，显示出早期结构特征对最终质量的有效影响。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.15844",
            "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning",
            "url": "https://huggingface.co/papers/2507.15844",
            "abstract": "Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet exhibit significant computational inefficiency by applying uniform reasoning strategies regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. HBPO addresses the fundamental challenge of exploration space collapse in efficiency-oriented training, where penalties on long output length systematically bias models away from necessary long reasoning paths. Through hierarchical budget exploration, our approach partitions rollout samples into multiple subgroups with distinct token budgets, aiming to enable efficient resource allocation while preventing degradation of capability. We introduce differentiated reward mechanisms that create budget-aware incentives aligned with the complexity of the problem, allowing models to discover natural correspondences between task requirements and computational effort. Extensive experiments demonstrate that HBPO reduces average token usage by up to 60.6% while improving accuracy by 3.14% across four reasoning benchmarks. Unlike existing methods that impose external constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive behavior where models automatically adjust reasoning depth based on problem complexity. Our results suggest that reasoning efficiency and capability are not inherently conflicting, and can be simultaneously optimized through appropriately structured hierarchical training that preserves exploration diversity.",
            "score": 3,
            "issue_id": 5006,
            "pub_date": "2025-07-21",
            "pub_date_card": {
                "ru": "21 июля",
                "en": "July 21",
                "zh": "7月21日"
            },
            "hash": "c5c45ecb7b33f3cb",
            "authors": [
                "Shangke Lyu",
                "Linjuan Wu",
                "Yuchen Yan",
                "Xingyu Wu",
                "Hao Li",
                "Yongliang Shen",
                "Peisheng Jiang",
                "Weiming Lu",
                "Jun Xiao",
                "Yueting Zhuang"
            ],
            "affiliations": [
                "SF Technology",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.15844.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#reasoning",
                    "#rl",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Адаптивные рассуждения: эффективность без потери возможностей",
                    "desc": "Статья представляет метод Hierarchical Budget Policy Optimization (HBPO) для оптимизации глубины рассуждений в больших языковых моделях. HBPO использует иерархическое исследование бюджета токенов и дифференцированные механизмы вознаграждения, чтобы модели могли адаптировать глубину рассуждений к сложности задачи. Эксперименты показывают, что HBPO снижает использование токенов на 60.6% при одновременном повышении точности на 3.14% на четырех эталонных тестах. Метод позволяет оптимизировать как эффективность, так и способности моделей машинного обучения."
                },
                "en": {
                    "title": "Optimizing Reasoning Efficiency with Adaptive Depth",
                    "desc": "This paper introduces Hierarchical Budget Policy Optimization (HBPO), a new reinforcement learning framework designed to improve the efficiency of reasoning models. HBPO allows models to adapt their reasoning depth based on the complexity of the problem, rather than using a one-size-fits-all approach. By implementing hierarchical budget exploration and differentiated reward mechanisms, the framework encourages models to allocate resources effectively while maintaining their performance. The results show that HBPO can significantly reduce token usage and enhance accuracy, demonstrating that efficiency and capability can be optimized together."
                },
                "zh": {
                    "title": "高效推理，能力与效率并存",
                    "desc": "本文提出了一种名为层次预算策略优化（HBPO）的强化学习框架，旨在提高推理模型的计算效率。HBPO通过分层预算探索，将样本分成多个具有不同令牌预算的子组，从而实现高效的资源分配。该方法引入了差异化奖励机制，使模型能够根据问题复杂性调整推理深度，避免了长输出长度的惩罚对模型的负面影响。实验结果表明，HBPO在四个推理基准上平均减少了60.6%的令牌使用，同时提高了3.14%的准确率，证明了推理效率与能力可以同时优化。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.16535",
            "title": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent\n  Diffusion",
            "url": "https://huggingface.co/papers/2507.16535",
            "abstract": "Despite the remarkable developments achieved by recent 3D generation works, scaling these methods to geographic extents, such as modeling thousands of square kilometers of Earth's surface, remains an open challenge. We address this through a dual innovation in data infrastructure and model architecture. First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date, consisting of 50k curated scenes (each measuring 600m x 600m) captured across the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene provides pose-annotated multi-view images, depth maps, normals, semantic segmentation, and camera poses, with explicit quality control to ensure terrain diversity. Building on this foundation, we propose EarthCrafter, a tailored framework for large-scale 3D Earth generation via sparse-decoupled latent diffusion. Our architecture separates structural and textural generation: 1) Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the costly computation suffering from vast geographic scales while preserving critical information. 2) We propose condition-aware flow matching models trained on mixed inputs (semantics, images, or neither) to flexibly model latent geometry and texture features independently. Extensive experiments demonstrate that EarthCrafter performs substantially better in extremely large-scale generation. The framework further supports versatile applications, from semantic-guided urban layout generation to unconditional terrain synthesis, while maintaining geographic plausibility through our rich data priors from Aerial-Earth3D. Our project page is available at https://whiteinblue.github.io/earthcrafter/",
            "score": 2,
            "issue_id": 5005,
            "pub_date": "2025-07-22",
            "pub_date_card": {
                "ru": "22 июля",
                "en": "July 22",
                "zh": "7月22日"
            },
            "hash": "7ee137161bbe047e",
            "authors": [
                "Shang Liu",
                "Chenjie Cao",
                "Chaohui Yu",
                "Wen Qian",
                "Jing Wang",
                "Fan Wang"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group",
                "Fudan University",
                "Hupan Lab"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.16535.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#architecture",
                    "#synthetic",
                    "#3d",
                    "#dataset"
                ],
                "emoji": "🌎",
                "ru": {
                    "title": "EarthCrafter: революция в широкомасштабном 3D-моделировании Земли",
                    "desc": "Статья представляет Aerial-Earth3D - крупнейший набор данных 3D аэросъемки, охватывающий 50 тысяч сцен по всей территории США. На основе этих данных разработан фреймворк EarthCrafter для широкомасштабной генерации 3D-моделей земной поверхности с использованием разреженной латентной диффузии. Архитектура EarthCrafter разделяет генерацию структуры и текстуры, применяя сжатие геометрии и текстур в компактные латентные пространства. Модель демонстрирует превосходные результаты в генерации крупномасштабных 3D-сцен и поддерживает различные приложения, сохраняя географическую достоверность."
                },
                "en": {
                    "title": "Revolutionizing Large-Scale 3D Earth Generation",
                    "desc": "This paper presents a solution to the challenge of generating large-scale 3D models of Earth's surface by introducing a new dataset and a novel model architecture. The Aerial-Earth3D dataset is the largest of its kind, containing 50,000 scenes with detailed annotations that support diverse terrain representation. The EarthCrafter framework utilizes a dual approach with sparse-decoupled latent diffusion, allowing for efficient generation of 3D structures and textures while managing computational costs. The results show significant improvements in generating realistic and plausible large-scale 3D environments, with applications in urban planning and terrain synthesis."
                },
                "zh": {
                    "title": "大规模3D地球生成的新突破",
                    "desc": "尽管最近的3D生成技术取得了显著进展，但将这些方法扩展到大规模地理范围仍然是一个挑战。我们通过数据基础设施和模型架构的双重创新来解决这个问题。我们介绍了Aerial-Earth3D，这是迄今为止最大的3D航空数据集，包含50,000个场景，支持大规模的3D地球生成。基于此，我们提出了EarthCrafter框架，通过稀疏解耦的潜在扩散技术，实现了高效的地形生成。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.18634",
            "title": "Captain Cinema: Towards Short Movie Generation",
            "url": "https://huggingface.co/papers/2507.18634",
            "abstract": "Captain Cinema generates high-quality short movies from textual descriptions using top-down keyframe planning and bottom-up video synthesis with interleaved training of Multimodal Diffusion Transformers.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Captain Cinema, a generation framework for short movie generation. Given a detailed textual description of a movie storyline, our approach firstly generates a sequence of keyframes that outline the entire narrative, which ensures long-range coherence in both the storyline and visual appearance (e.g., scenes and characters). We refer to this step as top-down keyframe planning. These keyframes then serve as conditioning signals for a video synthesis model, which supports long context learning, to produce the spatio-temporal dynamics between them. This step is referred to as bottom-up video synthesis. To support stable and efficient generation of multi-scene long narrative cinematic works, we introduce an interleaved training strategy for Multimodal Diffusion Transformers (MM-DiT), specifically adapted for long-context video data. Our model is trained on a specially curated cinematic dataset consisting of interleaved data pairs. Our experiments demonstrate that Captain Cinema performs favorably in the automated creation of visually coherent and narrative consistent short movies in high quality and efficiency. Project page: https://thecinema.ai",
            "score": 1,
            "issue_id": 5006,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 июля",
                "en": "July 24",
                "zh": "7月24日"
            },
            "hash": "a52dc2cc9f063733",
            "authors": [
                "Junfei Xiao",
                "Ceyuan Yang",
                "Lvmin Zhang",
                "Shengqu Cai",
                "Yang Zhao",
                "Yuwei Guo",
                "Gordon Wetzstein",
                "Maneesh Agrawala",
                "Alan Yuille",
                "Lu Jiang"
            ],
            "affiliations": [
                "ByteDance Seed",
                "CUHK Project Lead",
                "Johns Hopkins University",
                "Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18634.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#video",
                    "#long_context",
                    "#story_generation",
                    "#multimodal",
                    "#dataset"
                ],
                "emoji": "🎬",
                "ru": {
                    "title": "От текста к кино: ИИ-режиссер Captain Cinema",
                    "desc": "Captain Cinema - это система генерации коротких фильмов на основе текстовых описаний. Она использует двухэтапный подход: сначала планирование ключевых кадров сверху вниз, а затем синтез видео снизу вверх. Для обучения применяются мультимодальные диффузионные трансформеры с чередующейся стратегией обучения. Система демонстрирует хорошие результаты в создании визуально согласованных и нарративно последовательных коротких фильмов высокого качества."
                },
                "en": {
                    "title": "Transforming Text to Cinematic Reality with Captain Cinema",
                    "desc": "Captain Cinema is a framework designed to create short movies from text descriptions. It uses a two-step process: first, it generates keyframes that outline the movie's storyline, ensuring that the visuals and narrative are coherent. Next, it synthesizes video by connecting these keyframes, allowing for smooth transitions and dynamic scenes. The model employs Multimodal Diffusion Transformers with a unique training strategy to enhance the quality and efficiency of the movie generation process."
                },
                "zh": {
                    "title": "用文本描述生成高质量短片的创新框架",
                    "desc": "Captain Cinema 是一个短片生成框架，可以根据文本描述生成高质量的短电影。首先，它通过自上而下的关键帧规划生成一系列关键帧，以确保故事情节和视觉外观的一致性。接着，这些关键帧作为条件信号，供视频合成模型使用，从而生成场景之间的时空动态。我们还引入了一种交错训练策略，专门为长上下文视频数据设计的多模态扩散变换器，以支持多场景长叙事电影的稳定高效生成。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.18192",
            "title": "TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance",
            "url": "https://huggingface.co/papers/2507.18192",
            "abstract": "TeEFusion enhances text-to-image synthesis by efficiently incorporating classifier-free guidance into text embeddings, reducing inference costs without sacrificing image quality.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in text-to-image synthesis largely benefit from sophisticated sampling strategies and classifier-free guidance (CFG) to ensure high-quality generation. However, CFG's reliance on two forward passes, especially when combined with intricate sampling algorithms, results in prohibitively high inference costs. To address this, we introduce TeEFusion (Text Embeddings Fusion), a novel and efficient distillation method that directly incorporates the guidance magnitude into the text embeddings and distills the teacher model's complex sampling strategy. By simply fusing conditional and unconditional text embeddings using linear operations, TeEFusion reconstructs the desired guidance without adding extra parameters, simultaneously enabling the student model to learn from the teacher's output produced via its sophisticated sampling approach. Extensive experiments on state-of-the-art models such as SD3 demonstrate that our method allows the student to closely mimic the teacher's performance with a far simpler and more efficient sampling strategy. Consequently, the student model achieves inference speeds up to 6times faster than the teacher model, while maintaining image quality at levels comparable to those obtained through the teacher's complex sampling approach. The code is publicly available at https://github.com/AIDC-AI/TeEFusion{github.com/AIDC-AI/TeEFusion}.",
            "score": 1,
            "issue_id": 5006,
            "pub_date": "2025-07-24",
            "pub_date_card": {
                "ru": "24 июля",
                "en": "July 24",
                "zh": "7月24日"
            },
            "hash": "c5028e9aad7b0964",
            "authors": [
                "Minghao Fu",
                "Guo-Hua Wang",
                "Xiaohao Chen",
                "Qing-Guo Chen",
                "Zhao Xu",
                "Weihua Luo",
                "Kaifu Zhang"
            ],
            "affiliations": [
                "Alibaba International Digital Commerce Group",
                "National Key Laboratory for Novel Software Technology, Nanjing University",
                "School of Artificial Intelligence, Nanjing University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.18192.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#open_source",
                    "#inference",
                    "#cv"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "TeEFusion: быстрый синтез изображений без потери качества",
                    "desc": "TeEFusion - это новый метод дистилляции для синтеза изображений по тексту. Он объединяет условные и безусловные текстовые эмбеддинги, позволяя эффективно применять classifier-free guidance без дополнительных параметров. Метод позволяет ученической модели имитировать сложную стратегию сэмплирования учительской модели, значительно ускоряя инференс. Эксперименты на современных моделях вроде SD3 показывают ускорение до 6 раз при сохранении качества изображений."
                },
                "en": {
                    "title": "TeEFusion: Fast and Efficient Text-to-Image Synthesis",
                    "desc": "TeEFusion is a new method that improves text-to-image synthesis by integrating classifier-free guidance directly into text embeddings. This approach reduces the need for multiple forward passes, which are costly in terms of computation, while still producing high-quality images. By fusing conditional and unconditional text embeddings through simple linear operations, TeEFusion allows a student model to learn from a more complex teacher model without increasing the number of parameters. As a result, the student model can generate images up to six times faster than the teacher model, while maintaining similar image quality."
                },
                "zh": {
                    "title": "TeEFusion：高效的文本到图像合成方法",
                    "desc": "TeEFusion是一种新颖的文本嵌入融合方法，旨在提高文本到图像合成的效率。它通过将无分类器引导直接融入文本嵌入中，减少了推理成本，同时保持了图像质量。该方法通过线性操作简单地融合条件和无条件文本嵌入，避免了额外参数的增加。实验表明，TeEFusion使得学生模型在推理速度上比教师模型快6倍，同时图像质量与教师模型相当。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2507.14988",
            "title": "DMOSpeech 2: Reinforcement Learning for Duration Prediction in\n  Metric-Optimized Speech Synthesis",
            "url": "https://huggingface.co/papers/2507.14988",
            "abstract": "DMOSpeech 2 optimizes duration prediction and introduces teacher-guided sampling to enhance speech synthesis performance and diversity.  \t\t\t\t\tAI-generated summary \t\t\t\t Diffusion-based text-to-speech (TTS) systems have made remarkable progress in zero-shot speech synthesis, yet optimizing all components for perceptual metrics remains challenging. Prior work with DMOSpeech demonstrated direct metric optimization for speech generation components, but duration prediction remained unoptimized. This paper presents DMOSpeech 2, which extends metric optimization to the duration predictor through a reinforcement learning approach. The proposed system implements a novel duration policy framework using group relative preference optimization (GRPO) with speaker similarity and word error rate as reward signals. By optimizing this previously unoptimized component, DMOSpeech 2 creates a more complete metric-optimized synthesis pipeline. Additionally, this paper introduces teacher-guided sampling, a hybrid approach leveraging a teacher model for initial denoising steps before transitioning to the student model, significantly improving output diversity while maintaining efficiency. Comprehensive evaluations demonstrate superior performance across all metrics compared to previous systems, while reducing sampling steps by half without quality degradation. These advances represent a significant step toward speech synthesis systems with metric optimization across multiple components. The audio samples, code and pre-trained models are available at https://dmospeech2.github.io/.",
            "score": 0,
            "issue_id": 5005,
            "pub_date": "2025-07-20",
            "pub_date_card": {
                "ru": "20 июля",
                "en": "July 20",
                "zh": "7月20日"
            },
            "hash": "27df664b6cc093b4",
            "authors": [
                "Yinghao Aaron Li",
                "Xilin Jiang",
                "Fei Tao",
                "Cheng Niu",
                "Kaifeng Xu",
                "Juntong Song",
                "Nima Mesgarani"
            ],
            "affiliations": [
                "Columbia University",
                "NewsBreak"
            ],
            "pdf_title_img": "assets/pdf/title_img/2507.14988.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#training",
                    "#rl",
                    "#audio",
                    "#optimization"
                ],
                "emoji": "🎙️",
                "ru": {
                    "title": "Оптимизация синтеза речи на всех уровнях",
                    "desc": "DMOSpeech 2 - это улучшенная система синтеза речи, оптимизирующая предсказание длительности звуков с помощью обучения с подкреплением. Система использует новый подход к политике длительности, основанный на групповой оптимизации относительных предпочтений (GRPO) с использованием схожести голоса диктора и уровня ошибок распознавания слов в качестве сигналов вознаграждения. DMOSpeech 2 также вводит метод выборки с учительским руководством, что улучшает разнообразие выходных данных при сохранении эффективности. Комплексные оценки показывают превосходную производительность по всем метрикам по сравнению с предыдущими системами."
                },
                "en": {
                    "title": "Optimizing Duration for Diverse Speech Synthesis",
                    "desc": "DMOSpeech 2 enhances speech synthesis by optimizing duration prediction, which was previously unaddressed. It employs a reinforcement learning strategy with group relative preference optimization (GRPO) to improve the duration predictor using metrics like speaker similarity and word error rate. Additionally, the paper introduces teacher-guided sampling, which combines a teacher model for initial processing with a student model for efficiency, leading to greater output diversity. Overall, DMOSpeech 2 achieves superior performance in speech synthesis while reducing the number of sampling steps needed, marking a significant advancement in metric-optimized TTS systems."
                },
                "zh": {
                    "title": "优化语音合成，提升多样性与效率",
                    "desc": "DMOSpeech 2 是一种优化语音合成中持续时间预测的新方法，采用了强化学习的策略来提升合成效果。该系统引入了基于组相对偏好的优化框架，利用说话者相似性和词错误率作为奖励信号，从而优化了之前未优化的持续时间预测组件。除此之外，DMOSpeech 2 还采用了教师引导采样的方法，通过教师模型进行初步去噪，再转向学生模型，从而显著提高了输出的多样性。综合评估结果显示，该系统在各项指标上均优于之前的系统，同时将采样步骤减少了一半，且没有降低质量。"
                }
            }
        }
    ],
    "link_prev": "2025-07-24.html",
    "link_next": "2025-07-28.html",
    "link_month": "2025-07.html",
    "short_date_prev": {
        "ru": "24.07",
        "en": "07/24",
        "zh": "7月24日"
    },
    "short_date_next": {
        "ru": "28.07",
        "en": "07/28",
        "zh": "7月28日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 0,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 2,
        "#rl": 3,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 1,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 1,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 5,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 5,
        "#survey": 0,
        "#diffusion": 3,
        "#alignment": 0,
        "#story_generation": 1,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}