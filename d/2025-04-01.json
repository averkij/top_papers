{
    "date": {
        "ru": "1 апреля",
        "en": "April 1",
        "zh": "4月1日"
    },
    "time_utc": "2025-04-01 02:42",
    "weekday": 1,
    "issue_id": 2994,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2503.18809",
            "title": "Classical Planning with LLM-Generated Heuristics: Challenging the State\n  of the Art with Python Code",
            "url": "https://huggingface.co/papers/2503.18809",
            "abstract": "In recent years, large language models (LLMs) have shown remarkable capabilities in various artificial intelligence problems. However, they fail to plan reliably, even when prompted with a detailed definition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, fine-tuning, and explicit \"reasoning\" still yield incorrect plans and usually fail to generalize to larger tasks. In this paper, we show how to use LLMs to generate correct plans, even for out-of-distribution tasks of increasing size. For a given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on a set of training tasks within a greedy best-first search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These findings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efficiently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling a set of planning heuristic function programs can significantly improve the planning capabilities of LLMs.",
            "score": 6,
            "issue_id": 2994,
            "pub_date": "2025-03-24",
            "pub_date_card": {
                "ru": "24 марта",
                "en": "March 24",
                "zh": "3月24日"
            },
            "hash": "28288adc69a019ac",
            "authors": [
                "Augusto B. Corrêa",
                "André G. Pereira",
                "Jendrik Seipp"
            ],
            "affiliations": [
                "Federal University of Rio Grande do Sul",
                "Linköping University",
                "University of Oxford"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.18809.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#training",
                    "#rl"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "LLM как генераторы эффективных эвристик для задач планирования",
                    "desc": "Исследователи разработали метод использования больших языковых моделей (LLM) для генерации эвристических функций в задачах планирования. LLM создают несколько эвристик в виде Python-кода, которые затем оцениваются на тренировочных задачах. Выбранные эвристики показывают высокую эффективность на новых задачах, превосходя современные методы доменно-независимого планирования. Этот подход позволяет значительно улучшить способности LLM к планированию, даже для задач возрастающей сложности."
                },
                "en": {
                    "title": "Empowering LLMs with Domain-Specific Heuristics for Better Planning",
                    "desc": "This paper addresses the limitations of large language models (LLMs) in planning tasks, which often lead to incorrect and non-generalizable plans. The authors propose a novel approach where LLMs generate domain-specific heuristic functions in Python code, which are then evaluated using a greedy best-first search algorithm. Their method demonstrates that LLM-generated heuristics can outperform traditional domain-independent heuristics and compete with advanced learning algorithms in planning. The results indicate that these heuristics are not only efficient but also provide more informative guidance in certain planning domains."
                },
                "zh": {
                    "title": "提升大型语言模型的规划能力",
                    "desc": "近年来，大型语言模型（LLMs）在各种人工智能问题上展现了卓越的能力。然而，即使在详细定义规划任务的情况下，它们在规划方面仍然不可靠。本文展示了如何利用LLMs生成正确的规划，即使对于越来越大的分布外任务。通过生成领域相关的启发式函数并在贪婪优先搜索中评估，LLM生成的启发式函数在解决未见测试任务方面表现优于传统的领域无关启发式方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.23307",
            "title": "MoCha: Towards Movie-Grade Talking Character Synthesis",
            "url": "https://huggingface.co/papers/2503.23307",
            "abstract": "Recent advancements in video generation have achieved impressive motion realism, yet they often overlook character-driven storytelling, a crucial task for automated film, animation generation. We introduce Talking Characters, a more realistic task to generate talking character animations directly from speech and text. Unlike talking head, Talking Characters aims at generating the full portrait of one or more characters beyond the facial region. In this paper, we propose MoCha, the first of its kind to generate talking characters. To ensure precise synchronization between video and speech, we propose a speech-video window attention mechanism that effectively aligns speech and video tokens. To address the scarcity of large-scale speech-labeled video datasets, we introduce a joint training strategy that leverages both speech-labeled and text-labeled video data, significantly improving generalization across diverse character actions. We also design structured prompt templates with character tags, enabling, for the first time, multi-character conversation with turn-based dialogue-allowing AI-generated characters to engage in context-aware conversations with cinematic coherence. Extensive qualitative and quantitative evaluations, including human preference studies and benchmark comparisons, demonstrate that MoCha sets a new standard for AI-generated cinematic storytelling, achieving superior realism, expressiveness, controllability and generalization.",
            "score": 5,
            "issue_id": 2994,
            "pub_date": "2025-03-30",
            "pub_date_card": {
                "ru": "30 марта",
                "en": "March 30",
                "zh": "3月30日"
            },
            "hash": "6ce9b3642bf3ace3",
            "authors": [
                "Cong Wei",
                "Bo Sun",
                "Haoyu Ma",
                "Ji Hou",
                "Felix Juefei-Xu",
                "Zecheng He",
                "Xiaoliang Dai",
                "Luxin Zhang",
                "Kunpeng Li",
                "Tingbo Hou",
                "Animesh Sinha",
                "Peter Vajda",
                "Wenhu Chen"
            ],
            "affiliations": [
                "GenAI, Meta",
                "University of Waterloo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.23307.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#video",
                    "#benchmark",
                    "#story_generation"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "MoCha: новый уровень ИИ-генерации кинематографических историй",
                    "desc": "Представлена система MoCha для генерации анимированных разговаривающих персонажей на основе речи и текста. Использован механизм внимания для синхронизации речи и видео, а также совместное обучение на данных с речевой и текстовой разметкой. Система позволяет генерировать диалоги нескольких персонажей с учетом контекста. Результаты превосходят существующие подходы по реалистичности и выразительности генерируемых анимаций."
                },
                "en": {
                    "title": "Revolutionizing Character Animation with MoCha",
                    "desc": "This paper presents MoCha, a novel approach for generating talking character animations from speech and text, focusing on full character portrayal rather than just facial movements. It introduces a speech-video window attention mechanism to ensure that the generated video aligns accurately with the spoken words. To tackle the challenge of limited speech-labeled video datasets, the authors propose a joint training strategy that utilizes both speech and text-labeled data, enhancing the model's ability to generalize across various character actions. Additionally, structured prompt templates with character tags allow for multi-character dialogues, enabling AI-generated characters to engage in coherent conversations, thus advancing the field of automated cinematic storytelling."
                },
                "zh": {
                    "title": "会说话的角色：AI生成电影叙事的新标准",
                    "desc": "本论文介绍了一种新的视频生成任务，称为“会说话的角色”，旨在从语音和文本直接生成角色动画。与传统的“说话头”不同，这种方法生成的不仅仅是面部表情，而是完整的角色形象。我们提出了MoCha，这是首个能够生成会说话角色的模型，并引入了一种语音-视频窗口注意机制，以确保视频与语音的精确同步。此外，我们还设计了结构化的提示模板，使得多个角色能够进行基于回合的对话，从而实现更具电影感的情境对话。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.24370",
            "title": "Effectively Controlling Reasoning Models through Thinking Intervention",
            "url": "https://huggingface.co/papers/2503.24370",
            "abstract": "Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We conduct comprehensive evaluations across multiple tasks, including instruction following on IFEval, instruction hierarchy on SEP, and safety alignment on XSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs.",
            "score": 3,
            "issue_id": 2994,
            "pub_date": "2025-03-31",
            "pub_date_card": {
                "ru": "31 марта",
                "en": "March 31",
                "zh": "3月31日"
            },
            "hash": "5f218f08538c601f",
            "authors": [
                "Tong Wu",
                "Chong Xiang",
                "Jiachen T. Wang",
                "Prateek Mittal"
            ],
            "affiliations": [
                "NVIDIA",
                "Princeton University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.24370.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#rlhf",
                    "#architecture",
                    "#open_source",
                    "#training",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Управление мышлением ИИ: новый путь к улучшению языковых моделей",
                    "desc": "Статья представляет новый подход к управлению языковыми моделями (LLM) под названием 'Thinking Intervention'. Этот метод позволяет вмешиваться в процесс рассуждений модели, стратегически вставляя или изменяя определенные токены мышления. Авторы провели обширные эксперименты на различных задачах, включая следование инструкциям и безопасность. Результаты показывают значительное улучшение производительности по сравнению с базовыми методами промптинга, открывая новые возможности для контроля над рассуждающими языковыми моделями."
                },
                "en": {
                    "title": "Enhancing LLM Reasoning with Thinking Intervention",
                    "desc": "This paper introduces a new method called Thinking Intervention, which enhances the reasoning capabilities of large language models (LLMs) by allowing explicit control over their internal thought processes. By inserting or modifying specific reasoning tokens, the model can generate more accurate and contextually relevant answers. The authors conducted extensive tests on various tasks, showing that this approach leads to significant improvements in performance, such as higher accuracy in following instructions and better handling of unsafe prompts. Overall, the findings suggest that Thinking Intervention provides a valuable framework for refining how LLMs reason and respond to complex queries."
                },
                "zh": {
                    "title": "思维干预：提升大型语言模型推理能力的新方法",
                    "desc": "本文提出了一种新的思维干预（Thinking Intervention）方法，旨在通过插入或修改特定的思维标记来引导大型语言模型（LLMs）的内部推理过程。这种方法使得模型在复杂问题解决中能够更好地生成中间推理步骤，从而提高最终答案的准确性。我们在多个任务上进行了全面评估，结果显示思维干预显著优于传统的提示方法，尤其在指令遵循和推理层次方面取得了显著的准确率提升。我们的研究为控制推理过程中的大型语言模型开辟了新的研究方向。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.24115",
            "title": "TeleAntiFraud-28k: A Audio-Text Slow-Thinking Dataset for Telecom Fraud\n  Detection",
            "url": "https://huggingface.co/papers/2503.24115",
            "abstract": "The detection of telecom fraud faces significant challenges due to the lack of high-quality multimodal training data that integrates audio signals with reasoning-oriented textual analysis. To address this gap, we present TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset specifically designed for automated telecom fraud analysis. Our dataset is constructed through three strategies: (1) Privacy-preserved text-truth sample generation using automatically speech recognition (ASR)-transcribed call recordings (with anonymized original audio), ensuring real-world consistency through text-to-speech (TTS) model regeneration; (2) Semantic enhancement via large language model (LLM)-based self-instruction sampling on authentic ASR outputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that simulates emerging fraud tactics through predefined communication scenarios and fraud typologies. The generated dataset contains 28,511 rigorously processed speech-text pairs, complete with detailed annotations for fraud reasoning. The dataset is divided into three tasks: scenario classification, fraud detection, fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a standardized evaluation benchmark comprising proportionally sampled instances from the dataset, to facilitate systematic testing of model performance on telecom fraud detection tasks. We also contribute a production-optimized supervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while open-sourcing the data processing framework to enable community-driven dataset expansion. This work establishes a foundational framework for multimodal anti-fraud research while addressing critical challenges in data privacy and scenario diversity. The project will be released at https://github.com/JimmyMa99/TeleAntiFraud.",
            "score": 2,
            "issue_id": 2994,
            "pub_date": "2025-03-31",
            "pub_date_card": {
                "ru": "31 марта",
                "en": "March 31",
                "zh": "3月31日"
            },
            "hash": "61845428f5c3d9df",
            "authors": [
                "Zhiming Ma",
                "Peidong Wang",
                "Minhua Huang",
                "Jingpeng Wang",
                "Kai Wu",
                "Xiangzhao Lv",
                "Yachun Pang",
                "Yin Yang",
                "Wenjie Tang",
                "Yuchen Kang"
            ],
            "affiliations": [
                "China Mobile Internet Company Ltd. Guangzhou, Guangdong, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.24115.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#synthetic",
                    "#open_source",
                    "#benchmark",
                    "#data"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "Мультимодальный датасет для борьбы с телефонным мошенничеством",
                    "desc": "Статья представляет TeleAntiFraud-28k - первый открытый аудио-текстовый датасет для анализа телекоммуникационного мошенничества. Датасет создан с использованием генерации образцов на основе ASR и TTS, семантического расширения с помощью LLM и многоагентного состязательного синтеза. Он содержит 28,511 пар речь-текст с аннотациями для рассуждений о мошенничестве и разделен на три задачи. Авторы также представляют TeleAntiFraud-Bench для оценки производительности моделей и открытую модель SFT."
                },
                "en": {
                    "title": "Revolutionizing Telecom Fraud Detection with TeleAntiFraud-28k",
                    "desc": "This paper introduces TeleAntiFraud-28k, a novel dataset designed to enhance telecom fraud detection by combining audio signals with textual analysis. The dataset is created using three innovative strategies, including privacy-preserved text generation from speech recordings and semantic enhancement through large language models. It consists of over 28,000 annotated speech-text pairs, enabling tasks like scenario classification and fraud detection. Additionally, the authors provide a benchmark for evaluating model performance and a fine-tuned model for practical applications, promoting further research in multimodal anti-fraud techniques."
                },
                "zh": {
                    "title": "构建电信欺诈检测的新基石",
                    "desc": "本论文提出了TeleAntiFraud-28k数据集，这是第一个专为电信欺诈分析设计的开源音频-文本慢思考数据集。该数据集通过三种策略构建，确保了数据的隐私保护和真实场景的一致性。我们还建立了TeleAntiFraud-Bench评估基准，以便系统地测试模型在电信欺诈检测任务上的表现。此项工作为多模态反欺诈研究奠定了基础，同时解决了数据隐私和场景多样性等关键挑战。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2503.20286",
            "title": "Bridging Evolutionary Multiobjective Optimization and GPU Acceleration\n  via Tensorization",
            "url": "https://huggingface.co/papers/2503.20286",
            "abstract": "Evolutionary multiobjective optimization (EMO) has made significant strides over the past two decades. However, as problem scales and complexities increase, traditional EMO algorithms face substantial performance limitations due to insufficient parallelism and scalability. While most work has focused on algorithm design to address these challenges, little attention has been given to hardware acceleration, thereby leaving a clear gap between EMO algorithms and advanced computing devices, such as GPUs. To bridge the gap, we propose to parallelize EMO algorithms on GPUs via the tensorization methodology. By employing tensorization, the data structures and operations of EMO algorithms are transformed into concise tensor representations, which seamlessly enables automatic utilization of GPU computing. We demonstrate the effectiveness of our approach by applying it to three representative EMO algorithms: NSGA-III, MOEA/D, and HypE. To comprehensively assess our methodology, we introduce a multiobjective robot control benchmark using a GPU-accelerated physics engine. Our experiments show that the tensorized EMO algorithms achieve speedups of up to 1113x compared to their CPU-based counterparts, while maintaining solution quality and effectively scaling population sizes to hundreds of thousands. Furthermore, the tensorized EMO algorithms efficiently tackle complex multiobjective robot control tasks, producing high-quality solutions with diverse behaviors. Source codes are available at https://github.com/EMI-Group/evomo.",
            "score": 1,
            "issue_id": 2994,
            "pub_date": "2025-03-26",
            "pub_date_card": {
                "ru": "26 марта",
                "en": "March 26",
                "zh": "3月26日"
            },
            "hash": "bf1debfaa462fca8",
            "authors": [
                "Zhenyu Liang",
                "Hao Li",
                "Naiwei Yu",
                "Kebin Sun",
                "Ran Cheng"
            ],
            "affiliations": [
                "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China",
                "Department of Data Science and Artificial Intelligence and the Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2503.20286.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#architecture",
                    "#robotics",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Тензоризация EMO: революция в скорости многоцелевой оптимизации",
                    "desc": "Статья представляет новый подход к эволюционной многоцелевой оптимизации (EMO) с использованием тензоризации для ускорения алгоритмов на GPU. Авторы применили эту методологию к трем известным алгоритмам EMO: NSGA-III, MOEA/D и HypE. Эксперименты показали ускорение до 1113 раз по сравнению с версиями для CPU при сохранении качества решений. Также был представлен новый бенчмарк многоцелевого управления роботом с использованием физического движка на GPU для оценки эффективности предложенного подхода."
                },
                "en": {
                    "title": "Accelerating EMO with GPU Tensorization for Enhanced Performance",
                    "desc": "This paper addresses the limitations of traditional evolutionary multiobjective optimization (EMO) algorithms when faced with complex and large-scale problems. It highlights the lack of hardware acceleration in existing EMO approaches and proposes a novel method to parallelize these algorithms using GPUs through tensorization. By transforming EMO data structures into tensor representations, the authors enable efficient GPU computing, resulting in significant performance improvements. The proposed tensorized EMO algorithms demonstrate remarkable speedups while maintaining solution quality in multiobjective robot control tasks."
                },
                "zh": {
                    "title": "张量化提升EMO算法性能，GPU加速显著",
                    "desc": "进化多目标优化（EMO）在过去二十年取得了显著进展，但随着问题规模和复杂性的增加，传统的EMO算法面临性能限制。本文提出了一种通过张量化方法在GPU上并行化EMO算法的方案，以解决传统算法的并行性和可扩展性不足的问题。通过张量化，EMO算法的数据结构和操作被转化为简洁的张量表示，从而实现了GPU计算的自动利用。实验结果表明，张量化的EMO算法在速度上比基于CPU的算法快了多达1113倍，同时保持了解决方案的质量，并有效处理复杂的多目标机器人控制任务。"
                }
            }
        }
    ],
    "link_prev": "2025-03-31.html",
    "link_next": "2025-04-02.html",
    "link_month": "2025-04.html",
    "short_date_prev": {
        "ru": "31.03",
        "en": "03/31",
        "zh": "3月31日"
    },
    "short_date_next": {
        "ru": "02.04",
        "en": "04/02",
        "zh": "4月2日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 3,
        "#agents": 0,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 2,
        "#robotics": 1,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 1,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了一种新的推荐系统框架 ReaRec。它旨在通过多步推理来增强用户表示，从而更好地捕捉用户偏好的复杂变化。ReaRec 使用自回归的方式将序列的最后隐藏状态反馈到推荐系统中，并引入了两种轻量级的推理学习方法。实验结果显示，ReaRec 能够显著提高多种顺序推荐模型的性能。作者相信这项工作为未来的推荐系统研究开辟了新的方向。",
        "title": "Think Before Recommend: Unleashing the Latent Reasoning Power for\n  Sequential Recommendation",
        "pinyin": "这篇文章介绍了一种新的推荐系统框架 ReaRec。它旨在通过多步推理来增强用户表示，从而更好地捕捉用户偏好的复杂变化。ReaRec 使用自回归的方式将序列的最后隐藏状态反馈到推荐系统中，并引入了两种轻量级的推理学习方法。实验结果显示，ReaRec 能够显著提高多种顺序推荐模型的性能。作者相信这项工作为未来的推荐系统研究开辟了新的方向。\n\nzhè piān wén zhāng jiè shào le yī zhǒng xīn de tuī jiàn xì tǒng kuàng jià ReaRec。tā zhǐ yú tōng guò duō bù tuī lǐ lái zēng qiáng yòng hù biǎo shì, cóng ér gèng hǎo de bīng zhuō yòng hù piān hào de fú zà biàn huà。ReaRec shǐ yòng zì huí guī de fāng shì jiāng xù liè de zuì hòu yǐn cáng zhuàng tài fǎn kuì dào tuī jiàn xì tǒng zhōng, bìng yǐn rù le liǎng zhǒng qīng liàng jí de tuī lǐ xué xí fāng fǎ。shí yàn jié guǒ xiǎn shì, ReaRec néng gòu xiǎn zhù tí gāo duō zhǒng shùn xù tuī jiàn mó xíng de xìng néng。zuò zhě xiāng xìn zhè xiàng gōng zuò wèi wèi lái de tuī jiàn xì tǒng yán jiū kāi pì le xīn de fāng xiàng。",
        "vocab": "[\n    {\"word\": \"推荐系统\", \"pinyin\": \"tuī jiàn xì tǒng\", \"trans\": \"recommendation system\"},\n    {\"word\": \"框架\", \"pinyin\": \"kuàng jià\", \"trans\": \"framework\"},\n    {\"word\": \"旨在\", \"pinyin\": \"zhǐ zài\", \"trans\": \"aim to\"},\n    {\"word\": \"通过\", \"pinyin\": \"tōng guò\", \"trans\": \"through\"},\n    {\"word\": \"多步\", \"pinyin\": \"duō bù\", \"trans\": \"multi-step\"},\n    {\"word\": \"推理\", \"pinyin\": \"tuī lǐ\", \"trans\": \"reasoning\"},\n    {\"word\": \"增强\", \"pinyin\": \"zēng qiáng\", \"trans\": \"enhance\"},\n    {\"word\": \"用户\", \"pinyin\": \"yòng hù\", \"trans\": \"user\"},\n    {\"word\": \"表示\", \"pinyin\": \"biǎo shì\", \"trans\": \"representation\"},\n    {\"word\": \"从而\", \"pinyin\": \"cóng ér\", \"trans\": \"thus\"},\n    {\"word\": \"捕捉\", \"pinyin\": \"bǔ zhuō\", \"trans\": \"capture\"},\n    {\"word\": \"偏好\", \"pinyin\": \"piān hào\", \"trans\": \"preference\"},\n    {\"word\": \"复杂\", \"pinyin\": \"fù zá\", \"trans\": \"complex\"},\n    {\"word\": \"变化\", \"pinyin\": \"biàn huà\", \"trans\": \"change\"},\n    {\"word\": \"自回归\", \"pinyin\": \"zì huí guī\", \"trans\": \"autoregressive\"},\n    {\"word\": \"方式\", \"pinyin\": \"fāng shì\", \"trans\": \"manner\"},\n    {\"word\": \"序列\", \"pinyin\": \"xù liè\", \"trans\": \"sequence\"},\n    {\"word\": \"隐藏状态\", \"pinyin\": \"yǐn cáng zhuàng tài\", \"trans\": \"hidden state\"},\n    {\"word\": \"反馈\", \"pinyin\": \"fǎn kuì\", \"trans\": \"feedback\"},\n    {\"word\": \"引入\", \"pinyin\": \"yǐn rù\", \"trans\": \"introduce\"},\n    {\"word\": \"轻量级\", \"pinyin\": \"qīng liàng jí\", \"trans\": \"lightweight\"},\n    {\"word\": \"学习方法\", \"pinyin\": \"xué xí fāng fǎ\", \"trans\": \"learning method\"},\n    {\"word\": \"实验结果\", \"pinyin\": \"shí yàn jié guǒ\", \"trans\": \"experimental results\"},\n    {\"word\": \"显著\", \"pinyin\": \"xiǎn zhù\", \"trans\": \"significant\"},\n    {\"word\": \"提高\", \"pinyin\": \"tí gāo\", \"trans\": \"improve\"},\n    {\"word\": \"顺序\", \"pinyin\": \"shùn xù\", \"trans\": \"sequential\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"性能\", \"pinyin\": \"xìng néng\", \"trans\": \"performance\"},\n    {\"word\": \"作者\", \"pinyin\": \"zuò zhě\", \"trans\": \"author\"},\n    {\"word\": \"相信\", \"pinyin\": \"xiāng xìn\", \"trans\": \"believe\"},\n    {\"word\": \"工作\", \"pinyin\": \"gōng zuò\", \"trans\": \"work\"},\n    {\"word\": \"未来\", \"pinyin\": \"wèi lái\", \"trans\": \"future\"},\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"开辟\", \"pinyin\": \"kāi pì\", \"trans\": \"open up\"},\n    {\"word\": \"方向\", \"pinyin\": \"fāng xiàng\", \"trans\": \"direction\"}\n]",
        "trans": "This article introduces a new recommendation system framework called ReaRec. It aims to enhance user representation through multi-step reasoning, thereby better capturing the complex changes in user preferences. ReaRec employs an autoregressive approach to feed the final hidden state of the sequence back into the recommendation system and introduces two lightweight reasoning learning methods. Experimental results demonstrate that ReaRec can significantly improve the performance of various sequential recommendation models. The authors believe that this work opens up new directions for future research in recommendation systems.",
        "update_ts": "2025-03-31 09:12"
    }
}