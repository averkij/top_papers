
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 8 papers. June 12.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">12 июня</span> | <span id="title-articles-count">8 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-06-11.html">⬅️ <span id="prev-date">11.06</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-06-13.html">➡️ <span id="next-date">13.06</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-06.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '12 июня', 'en': 'June 12', 'zh': '6月12日'};
        let feedDateNext = {'ru': '13.06', 'en': '06/13', 'zh': '6月13日'};
        let feedDatePrev = {'ru': '11.06', 'en': '06/11', 'zh': '6月11日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2506.09995', 'title': 'PlayerOne: Egocentric World Simulator', 'url': 'https://huggingface.co/papers/2506.09995', 'abstract': 'PlayerOne is an egocentric realistic world simulator that constructs and generates videos from user-captured images, using a coarse-to-fine training pipeline and advanced motion injection and reconstruction frameworks.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce PlayerOne, the first egocentric realistic world simulator, facilitating immersive and unrestricted exploration within vividly dynamic environments. Given an egocentric scene image from the user, PlayerOne can accurately construct the corresponding world and generate egocentric videos that are strictly aligned with the real scene human motion of the user captured by an exocentric camera. PlayerOne is trained in a coarse-to-fine pipeline that first performs pretraining on large-scale egocentric text-video pairs for coarse-level egocentric understanding, followed by finetuning on synchronous motion-video data extracted from egocentric-exocentric video datasets with our automatic construction pipeline. Besides, considering the varying importance of different components, we design a part-disentangled motion injection scheme, enabling precise control of part-level movements. In addition, we devise a joint reconstruction framework that progressively models both the 4D scene and video frames, ensuring scene consistency in the long-form video generation. Experimental results demonstrate its great generalization ability in precise control of varying human movements and worldconsistent modeling of diverse scenarios. It marks the first endeavor into egocentric real-world simulation and can pave the way for the community to delve into fresh frontiers of world modeling and its diverse applications.', 'score': 16, 'issue_id': 4251, 'pub_date': '2025-06-11', 'pub_date_card': {'ru': '11 июня', 'en': 'June 11', 'zh': '6月11日'}, 'hash': 'e7cba5eb3e340a0f', 'authors': ['Yuanpeng Tu', 'Hao Luo', 'Xi Chen', 'Xiang Bai', 'Fan Wang', 'Hengshuang Zhao'], 'affiliations': ['DAMO Academy, Alibaba Group', 'HKU', 'HUST', 'Hupan Lab'], 'pdf_title_img': 'assets/pdf/title_img/2506.09995.jpg', 'data': {'categories': ['#video', '#optimization', '#multimodal', '#training', '#games'], 'emoji': '🎥', 'ru': {'title': 'Погружение в реальность: эгоцентрическая симуляция мира с PlayerOne', 'desc': 'PlayerOne - это первый эгоцентрический симулятор реалистичного мира, способный генерировать видео на основе изображений, снятых пользователем. Система использует каскадный процесс обучения, начиная с предварительной тренировки на больших наборах эгоцентрических видео с текстовыми описаниями, а затем выполняет тонкую настройку на синхронизированных данных движения и видео. PlayerOne применяет усовершенствованные методы внедрения движения и реконструкции сцены для обеспечения точного контроля над движениями и согласованности сцены при генерации длительных видео. Эта система открывает новые возможности для моделирования мира и имеет широкий спектр потенциальных применений.'}, 'en': {'title': 'Revolutionizing Egocentric World Simulation with PlayerOne', 'desc': 'PlayerOne is an innovative egocentric realistic world simulator that generates videos based on user-captured images. It employs a coarse-to-fine training approach, initially pretraining on large datasets of egocentric text-video pairs, followed by fine-tuning with motion-video data for enhanced accuracy. The system features a part-disentangled motion injection scheme, allowing for detailed control over individual movements, and a joint reconstruction framework that maintains scene consistency across video frames. This pioneering work opens new avenues for world modeling and applications in immersive environments.'}, 'zh': {'title': '开创自我中心现实世界模拟的新纪元', 'desc': 'PlayerOne是一个以自我为中心的现实世界模拟器，能够根据用户捕捉的图像构建和生成视频。它采用粗到细的训练流程，首先在大规模的自我中心文本-视频对上进行预训练，然后在同步运动-视频数据上进行微调。该系统设计了部分解耦的运动注入方案，以实现对部分运动的精确控制，并通过联合重建框架确保长视频生成中的场景一致性。实验结果表明，PlayerOne在控制人类运动和建模多样场景方面具有出色的泛化能力。'}}}, {'id': 'https://huggingface.co/papers/2506.09003', 'title': 'SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner', 'url': 'https://huggingface.co/papers/2506.09003', 'abstract': 'A novel data synthesis framework, SWE-Flow, uses unit tests to automatically infer development steps and generate a structured schedule for Test-Driven Development (TDD), significantly improving the performance of open models fine-tuned on real-world projects.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce **SWE-Flow**, a novel data synthesis framework grounded in Test-Driven Development (TDD). Unlike existing software engineering data that rely on human-submitted issues, **SWE-Flow** automatically infers incremental development steps directly from unit tests, which inherently encapsulate high-level requirements. The core of **SWE-Flow** is the construction of a Runtime Dependency Graph (RDG), which precisely captures function interactions, enabling the generation of a structured, step-by-step *development schedule*. At each step, **SWE-Flow** produces a partial codebase, the corresponding unit tests, and the necessary code modifications, resulting in fully verifiable TDD tasks. With this approach, we generated 16,061 training instances and 2,020 test instances from real-world GitHub projects, creating the **SWE-Flow-Eval** benchmark. Our experiments show that fine-tuning open model on this dataset significantly improves performance in TDD-based coding. To facilitate further research, we release all code, datasets, models, and Docker images at [Github](https://github.com/Hambaobao/SWE-Flow).', 'score': 12, 'issue_id': 4251, 'pub_date': '2025-06-10', 'pub_date_card': {'ru': '10 июня', 'en': 'June 10', 'zh': '6月10日'}, 'hash': '794ea1a282cfa727', 'authors': ['Lei Zhang', 'Jiaxi Yang', 'Min Yang', 'Jian Yang', 'Mouxiang Chen', 'Jiajun Zhang', 'Zeyu Cui', 'Binyuan Hui', 'Junyang Lin'], 'affiliations': ['Alibaba Group, Beijing, China', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China', 'University of Science and Technology of China, Hefei, China', 'Zhejiang University, Hangzhou, China'], 'pdf_title_img': 'assets/pdf/title_img/2506.09003.jpg', 'data': {'categories': ['#dataset', '#open_source', '#benchmark', '#data', '#training', '#synthetic'], 'emoji': '🧪', 'ru': {'title': 'SWE-Flow: автоматизация TDD для улучшения ИИ-моделей в программировании', 'desc': 'SWE-Flow - это новая система синтеза данных для разработки программного обеспечения, основанная на разработке через тестирование (TDD). Она автоматически выводит этапы разработки из модульных тестов, создавая структурированный график разработки с помощью графа зависимостей времени выполнения (RDG). SWE-Flow генерирует частичную кодовую базу, соответствующие модульные тесты и необходимые изменения кода на каждом этапе. Эксперименты показывают, что дообучение открытых моделей на созданном наборе данных значительно улучшает их производительность в TDD-задачах.'}, 'en': {'title': 'Automating TDD with SWE-Flow: Smarter Development Schedules', 'desc': 'SWE-Flow is a new framework designed to enhance Test-Driven Development (TDD) by automatically generating development schedules from unit tests. It infers development steps directly from these tests, which represent high-level requirements, rather than relying on human-submitted issues. The framework constructs a Runtime Dependency Graph (RDG) to capture function interactions, allowing for a structured approach to coding tasks. By generating a large dataset from real-world projects, SWE-Flow significantly improves the performance of models fine-tuned for TDD-based coding.'}, 'zh': {'title': 'SWE-Flow：自动化测试驱动开发的创新框架', 'desc': 'SWE-Flow是一种新颖的数据合成框架，基于测试驱动开发（TDD）方法。它通过自动推断单元测试中的开发步骤，生成结构化的开发计划，从而提高了在真实项目上微调开放模型的性能。SWE-Flow的核心是构建运行时依赖图（RDG），准确捕捉函数之间的交互，确保每一步生成部分代码库及相应的单元测试。通过这种方法，我们从真实的GitHub项目中生成了大量的训练和测试实例，显著提升了基于TDD的编码性能。'}}}, {'id': 'https://huggingface.co/papers/2506.09113', 'title': 'Seedance 1.0: Exploring the Boundaries of Video Generation Models', 'url': 'https://huggingface.co/papers/2506.09113', 'abstract': 'Seedance 1.0 offers high-performance video generation by integrating advanced data curation, efficient architecture, post-training optimization, and model acceleration, resulting in superior quality and speed.  \t\t\t\t\tAI-generated summary \t\t\t\t Notable breakthroughs in diffusion modeling have propelled rapid improvements in video generation, yet current foundational model still face critical challenges in simultaneously balancing prompt following, motion plausibility, and visual quality. In this report, we introduce Seedance 1.0, a high-performance and inference-efficient video foundation generation model that integrates several core technical improvements: (i) multi-source data curation augmented with precision and meaningful video captioning, enabling comprehensive learning across diverse scenarios; (ii) an efficient architecture design with proposed training paradigm, which allows for natively supporting multi-shot generation and jointly learning of both text-to-video and image-to-video tasks. (iii) carefully-optimized post-training approaches leveraging fine-grained supervised fine-tuning, and video-specific RLHF with multi-dimensional reward mechanisms for comprehensive performance improvements; (iv) excellent model acceleration achieving ~10x inference speedup through multi-stage distillation strategies and system-level optimizations. Seedance 1.0 can generate a 5-second video at 1080p resolution only with 41.4 seconds (NVIDIA-L20). Compared to state-of-the-art video generation models, Seedance 1.0 stands out with high-quality and fast video generation having superior spatiotemporal fluidity with structural stability, precise instruction adherence in complex multi-subject contexts, native multi-shot narrative coherence with consistent subject representation.', 'score': 11, 'issue_id': 4251, 'pub_date': '2025-06-10', 'pub_date_card': {'ru': '10 июня', 'en': 'June 10', 'zh': '6月10日'}, 'hash': 'd44df125bd718f2f', 'authors': ['Yu Gao', 'Haoyuan Guo', 'Tuyen Hoang', 'Weilin Huang', 'Lu Jiang', 'Fangyuan Kong', 'Huixia Li', 'Jiashi Li', 'Liang Li', 'Xiaojie Li', 'Xunsong Li', 'Yifu Li', 'Shanchuan Lin', 'Zhijie Lin', 'Jiawei Liu', 'Shu Liu', 'Xiaonan Nie', 'Zhiwu Qing', 'Yuxi Ren', 'Li Sun', 'Zhi Tian', 'Rui Wang', 'Sen Wang', 'Guoqiang Wei', 'Guohong Wu', 'Jie Wu', 'Ruiqi Xia', 'Fei Xiao', 'Xuefeng Xiao', 'Jiangqiao Yan', 'Ceyuan Yang', 'Jianchao Yang', 'Runkai Yang', 'Tao Yang', 'Yihang Yang', 'Zilyu Ye', 'Xuejiao Zeng', 'Yan Zeng', 'Heng Zhang', 'Yang Zhao', 'Xiaozheng Zheng', 'Peihao Zhu', 'Jiaxin Zou', 'Feilong Zuo'], 'affiliations': [], 'pdf_title_img': 'assets/pdf/title_img/2506.09113.jpg', 'data': {'categories': ['#video', '#dataset', '#optimization', '#architecture', '#benchmark', '#data', '#training', '#rlhf', '#diffusion', '#inference'], 'emoji': '🎬', 'ru': {'title': 'Революция в генерации видео: быстро, качественно, многозадачно', 'desc': 'Seedance 1.0 - это высокопроизводительная модель генерации видео, объединяющая несколько ключевых технических улучшений. Она включает в себя многоисточниковую курацию данных с точными видеоподписями, эффективную архитектуру с поддержкой многокадровой генерации и совместным обучением задачам текст-в-видео и изображение-в-видео. Модель использует оптимизированные пост-тренировочные подходы, включая тонкую настройку под наблюдением и видео-специфичное RLHF. Благодаря многоэтапным стратегиям дистилляции и системным оптимизациям, Seedance 1.0 достигает ~10-кратного ускорения вывода.'}, 'en': {'title': 'Seedance 1.0: Fast and High-Quality Video Generation Revolutionized', 'desc': 'Seedance 1.0 is a cutting-edge video generation model that enhances performance through advanced data curation and an efficient architecture. It addresses key challenges in video generation, such as prompt adherence and visual quality, by integrating multi-source data and a novel training paradigm. The model employs optimized post-training techniques, including fine-tuning and reinforcement learning with multi-dimensional rewards, to boost its capabilities. With a remarkable inference speedup of approximately 10 times, Seedance 1.0 can produce high-quality 5-second videos at 1080p resolution in just 41.4 seconds.'}, 'zh': {'title': 'Seedance 1.0：高效视频生成的新标杆', 'desc': 'Seedance 1.0 是一种高性能的视频生成模型，结合了先进的数据整理、有效的架构设计、后训练优化和模型加速技术，提供了卓越的质量和速度。该模型通过多源数据整理和精准的视频字幕，增强了对多样场景的全面学习能力。它的高效架构支持多镜头生成，并同时学习文本到视频和图像到视频的任务。Seedance 1.0 通过多阶段蒸馏策略实现了约10倍的推理加速，能够在41.4秒内生成5秒的1080p视频。'}}}, {'id': 'https://huggingface.co/papers/2506.09790', 'title': 'ComfyUI-R1: Exploring Reasoning Models for Workflow Generation', 'url': 'https://huggingface.co/papers/2506.09790', 'abstract': 'ComfyUI-R1, a large reasoning model for automated workflow generation, demonstrates superior performance in creating AI art workflows through long chain-of-thought reasoning and reinforcement learning.  \t\t\t\t\tAI-generated summary \t\t\t\t AI-generated content has evolved from monolithic models to modular workflows, particularly on platforms like ComfyUI, enabling customization in creative pipelines. However, crafting effective workflows requires great expertise to orchestrate numerous specialized components, presenting a steep learning curve for users. To address this challenge, we introduce ComfyUI-R1, the first large reasoning model for automated workflow generation. Starting with our curated dataset of 4K workflows, we construct long chain-of-thought (CoT) reasoning data, including node selection, workflow planning, and code-level workflow representation. ComfyUI-R1 is trained through a two-stage framework: (1) CoT fine-tuning for cold start, adapting models to the ComfyUI domain; (2) reinforcement learning for incentivizing reasoning capability, guided by a fine-grained rule-metric hybrid reward, ensuring format validity, structural integrity, and node-level fidelity. Experiments show that our 7B-parameter model achieves a 97\\% format validity rate, along with high pass rate, node-level and graph-level F1 scores, significantly surpassing prior state-of-the-art methods that employ leading closed-source models such as GPT-4o and Claude series. Further analysis highlights the critical role of the reasoning process and the advantage of transforming workflows into code. Qualitative comparison reveals our strength in synthesizing intricate workflows with diverse nodes, underscoring the potential of long CoT reasoning in AI art creation.', 'score': 8, 'issue_id': 4251, 'pub_date': '2025-06-11', 'pub_date_card': {'ru': '11 июня', 'en': 'June 11', 'zh': '6月11日'}, 'hash': '6fb3fee31c3739a5', 'authors': ['Zhenran Xu', 'Yiyu Wang', 'Xue Yang', 'Longyue Wang', 'Weihua Luo', 'Kaifu Zhang', 'Baotian Hu', 'Min Zhang'], 'affiliations': ['Alibaba International Digital Commerce, China', 'Harbin Institute of Technology (Shenzhen), China'], 'pdf_title_img': 'assets/pdf/title_img/2506.09790.jpg', 'data': {'categories': ['#rl', '#dataset', '#optimization', '#architecture', '#reasoning', '#training', '#long_context'], 'emoji': '🎨', 'ru': {'title': 'ComfyUI-R1: ИИ-художник нового поколения', 'desc': 'ComfyUI-R1 - это крупная модель машинного обучения для автоматической генерации рабочих процессов в сфере ИИ-искусства. Модель использует длинные цепочки рассуждений и обучение с подкреплением для создания эффективных рабочих процессов. ComfyUI-R1 обучается на наборе данных из 4000 рабочих процессов с использованием двухэтапного подхода: тонкая настройка цепочек рассуждений и обучение с подкреплением. Эксперименты показывают, что 7-миллиардная модель значительно превосходит существующие методы по различным метрикам.'}, 'en': {'title': 'Automating AI Art Workflows with ComfyUI-R1', 'desc': 'ComfyUI-R1 is a large reasoning model designed to automate the generation of workflows for creating AI art. It utilizes long chain-of-thought (CoT) reasoning and reinforcement learning to improve the process of workflow creation, making it easier for users to customize their creative pipelines. The model is trained on a dataset of 4,000 workflows and employs a two-stage framework that includes CoT fine-tuning and reinforcement learning with a hybrid reward system. Experimental results show that ComfyUI-R1 outperforms existing models in terms of format validity and overall workflow quality, highlighting the effectiveness of its reasoning capabilities.'}, 'zh': {'title': 'ComfyUI-R1：自动化工作流生成的推理模型', 'desc': 'ComfyUI-R1 是一个大型推理模型，专注于自动化工作流生成，特别是在 AI 艺术创作中表现出色。它通过长链推理和强化学习，帮助用户创建定制化的工作流，降低了学习曲线。该模型使用了 4K 工作流的数据集，经过两阶段的训练，确保了工作流的格式有效性和结构完整性。实验结果显示，ComfyUI-R1 在格式有效性和 F1 分数上显著超越了之前的先进方法，展示了长链推理在 AI 艺术创作中的潜力。'}}}, {'id': 'https://huggingface.co/papers/2506.08889', 'title': 'SeerAttention-R: Sparse Attention Adaptation for Long Reasoning', 'url': 'https://huggingface.co/papers/2506.08889', 'abstract': 'SeerAttention-R is a sparse attention framework for reasoning models that maintains high accuracy and achieves significant speedups through optimized sparse decoding kernels.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce SeerAttention-R, a sparse attention framework specifically tailored for the long decoding of reasoning models. Extended from SeerAttention, SeerAttention-R retains the design of learning attention sparsity through a self-distilled gating mechanism, while removing query pooling to accommodate auto-regressive decoding. With a lightweight plug-in gating, SeerAttention-R is flexible and can be easily integrated into existing pretrained model without modifying the original parameters. We demonstrate that SeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning accuracy with 4K token budget in AIME benchmark under large sparse attention block sizes (64/128). Using TileLang, we develop a highly optimized sparse decoding kernel that achieves near-theoretical speedups of up to 9x over FlashAttention-3 on H100 GPU at 90% sparsity. Code is available at: https://github.com/microsoft/SeerAttention.', 'score': 8, 'issue_id': 4251, 'pub_date': '2025-06-10', 'pub_date_card': {'ru': '10 июня', 'en': 'June 10', 'zh': '6月10日'}, 'hash': 'a6e46d58b91f0fad', 'authors': ['Yizhao Gao', 'Shuming Guo', 'Shijie Cao', 'Yuqing Xia', 'Yu Cheng', 'Lei Wang', 'Lingxiao Ma', 'Yutao Sun', 'Tianzhu Ye', 'Li Dong', 'Hayden Kwok-Hay So', 'Yu Hua', 'Ting Cao', 'Fan Yang', 'Mao Yang'], 'affiliations': ['Huazhong University of Science and Technology', 'Microsoft Research', 'Peking University', 'The University of Hong Kong', 'Tsinghua University'], 'pdf_title_img': 'assets/pdf/title_img/2506.08889.jpg', 'data': {'categories': ['#optimization', '#architecture', '#benchmark', '#reasoning', '#training', '#long_context'], 'emoji': '🧠', 'ru': {'title': 'Эффективное разреженное внимание для моделей рассуждения', 'desc': 'SeerAttention-R - это разреженная система внимания для моделей рассуждения, которая сохраняет высокую точность и достигает значительного ускорения с помощью оптимизированных ядер разреженного декодирования. Она обучается на всего 0,4 миллиардах токенов и поддерживает точность рассуждений почти без потерь с бюджетом в 4000 токенов в тесте AIME при больших размерах блоков разреженного внимания. Используя TileLang, авторы разработали высокооптимизированное ядро разреженного декодирования, которое достигает почти теоретического ускорения до 9 раз по сравнению с FlashAttention-3 на GPU H100 при 90% разреженности. SeerAttention-R можно легко интегрировать в существующие предобученные модели без изменения исходных параметров.'}, 'en': {'title': 'SeerAttention-R: Speed and Accuracy in Sparse Attention for Reasoning Models', 'desc': 'SeerAttention-R is a new framework designed for sparse attention in reasoning models, focusing on efficient long decoding. It builds on the original SeerAttention by using a self-distilled gating mechanism to learn attention sparsity while eliminating query pooling for better auto-regressive decoding. This framework is lightweight and can be easily integrated into existing pretrained models without altering their parameters. Our experiments show that SeerAttention-R achieves high accuracy with significant speed improvements, processing up to 4K tokens efficiently on advanced hardware.'}, 'zh': {'title': 'SeerAttention-R：高效稀疏注意力推理框架', 'desc': 'SeerAttention-R是一种稀疏注意力框架，专为推理模型的长解码而设计。它通过自蒸馏门控机制学习注意力稀疏性，同时去除了查询池化，以适应自回归解码。该框架轻量且灵活，可以无缝集成到现有的预训练模型中，而无需修改原始参数。实验表明，SeerAttention-R在AIME基准测试中以4K令牌预算保持接近无损的推理准确性，并在H100 GPU上实现了高达9倍的速度提升。'}}}, {'id': 'https://huggingface.co/papers/2506.09984', 'title': 'InterActHuman: Multi-Concept Human Animation with Layout-Aligned Audio\n  Conditions', 'url': 'https://huggingface.co/papers/2506.09984', 'abstract': "A novel framework for end-to-end human animation with multi-modal conditions enables high-quality video generation through explicit layout control and region-specific modality matching.  \t\t\t\t\tAI-generated summary \t\t\t\t End-to-end human animation with rich multi-modal conditions, e.g., text, image and audio has achieved remarkable advancements in recent years. However, most existing methods could only animate a single subject and inject conditions in a global manner, ignoring scenarios that multiple concepts could appears in the same video with rich human-human interactions and human-object interactions. Such global assumption prevents precise and per-identity control of multiple concepts including humans and objects, therefore hinders applications. In this work, we discard the single-entity assumption and introduce a novel framework that enforces strong, region-specific binding of conditions from modalities to each identity's spatiotemporal footprint. Given reference images of multiple concepts, our method could automatically infer layout information by leveraging a mask predictor to match appearance cues between the denoised video and each reference appearance. Furthermore, we inject local audio condition into its corresponding region to ensure layout-aligned modality matching in a iterative manner. This design enables the high-quality generation of controllable multi-concept human-centric videos. Empirical results and ablation studies validate the effectiveness of our explicit layout control for multi-modal conditions compared to implicit counterparts and other existing methods.", 'score': 4, 'issue_id': 4252, 'pub_date': '2025-06-11', 'pub_date_card': {'ru': '11 июня', 'en': 'June 11', 'zh': '6月11日'}, 'hash': '97a59a9be9ba0dc3', 'authors': ['Zhenzhi Wang', 'Jiaqi Yang', 'Jianwen Jiang', 'Chao Liang', 'Gaojie Lin', 'Zerong Zheng', 'Ceyuan Yang', 'Dahua Lin'], 'affiliations': ['ByteDance', 'CUHK MMLab'], 'pdf_title_img': 'assets/pdf/title_img/2506.09984.jpg', 'data': {'categories': ['#multimodal', '#video', '#games', '#diffusion'], 'emoji': '🎭', 'ru': {'title': 'Мультимодальная анимация множества людей с точным контролем расположения', 'desc': 'Статья представляет новую систему для анимации людей с использованием мультимодальных условий. Эта система позволяет генерировать высококачественные видео с точным контролем расположения и сопоставлением модальностей для конкретных областей. В отличие от существующих методов, данный подход может анимировать несколько субъектов одновременно, учитывая взаимодействия между людьми и объектами. Система использует маскированный предиктор для автоматического определения информации о расположении, что обеспечивает точное соответствие между сгенерированным видео и эталонными изображениями.'}, 'en': {'title': 'Revolutionizing Human Animation with Multi-Modal Control', 'desc': "This paper presents a new framework for creating human animations that can incorporate multiple types of input, such as text, images, and audio. Unlike previous methods that only animate one subject at a time, this approach allows for complex interactions between multiple characters and objects in a video. The framework uses a mask predictor to accurately match visual elements to specific regions in the video, ensuring that each character's appearance is correctly represented. Additionally, it integrates audio cues in a way that aligns with the visual layout, resulting in high-quality, controllable animations that reflect rich human interactions."}, 'zh': {'title': '多模态条件下的高质量人类动画生成', 'desc': '本文提出了一种新颖的端到端人类动画框架，能够在多模态条件下生成高质量视频。与传统方法不同，该框架支持多个概念的精确控制，允许人类与物体之间的丰富交互。通过区域特定的条件绑定，我们的方法能够自动推断布局信息，并确保不同模态之间的匹配。实验结果表明，该框架在多模态条件下的显式布局控制优于现有的隐式方法。'}}}, {'id': 'https://huggingface.co/papers/2506.09937', 'title': 'SAFE: Multitask Failure Detection for Vision-Language-Action Models', 'url': 'https://huggingface.co/papers/2506.09937', 'abstract': 'SAFE is a failure detector for vision-language-action models that generalizes to unseen tasks by learning from high-level internal features of the models.  \t\t\t\t\tAI-generated summary \t\t\t\t While vision-language-action models (VLAs) have shown promising robotic behaviors across a diverse set of manipulation tasks, they achieve limited success rates when deployed on novel tasks out-of-the-box. To allow these policies to safely interact with their environments, we need a failure detector that gives a timely alert such that the robot can stop, backtrack, or ask for help. However, existing failure detectors are trained and tested only on one or a few specific tasks, while VLAs require the detector to generalize and detect failures also in unseen tasks and novel environments. In this paper, we introduce the multitask failure detection problem and propose SAFE, a failure detector for generalist robot policies such as VLAs. We analyze the VLA feature space and find that VLAs have sufficient high-level knowledge about task success and failure, which is generic across different tasks. Based on this insight, we design SAFE to learn from VLA internal features and predict a single scalar indicating the likelihood of task failure. SAFE is trained on both successful and failed rollouts, and is evaluated on unseen tasks. SAFE is compatible with different policy architectures. We test it on OpenVLA, pi_0, and pi_0-FAST in both simulated and real-world environments extensively. We compare SAFE with diverse baselines and show that SAFE achieves state-of-the-art failure detection performance and the best trade-off between accuracy and detection time using conformal prediction. More qualitative results can be found at https://vla-safe.github.io/.', 'score': 1, 'issue_id': 4251, 'pub_date': '2025-06-11', 'pub_date_card': {'ru': '11 июня', 'en': 'June 11', 'zh': '6月11日'}, 'hash': '2a59fafef3ba118c', 'authors': ['Qiao Gu', 'Yuanliang Ju', 'Shengxiang Sun', 'Igor Gilitschenski', 'Haruki Nishimura', 'Masha Itkina', 'Florian Shkurti'], 'affiliations': ['Toyota Research Institute (TRI)', 'University of Toronto (UofT)', 'UofT Robotics Institute', 'Vector Institute'], 'pdf_title_img': 'assets/pdf/title_img/2506.09937.jpg', 'data': {'categories': ['#security', '#optimization', '#agents', '#robotics', '#agi'], 'emoji': '🤖', 'ru': {'title': 'SAFE: универсальный детектор ошибок для роботов-генералистов', 'desc': 'SAFE - это детектор ошибок для моделей зрения-языка-действия (VLA), который обобщается на новые задачи, обучаясь на высокоуровневых внутренних признаках моделей. Он анализирует пространство признаков VLA и обнаруживает, что эти модели имеют достаточные знания об успехе и неудаче задач, которые являются общими для разных задач. SAFE обучается на успешных и неудачных прогонах и оценивается на невиденных задачах. Детектор показывает лучшие результаты по сравнению с базовыми методами и обеспечивает оптимальный компромисс между точностью и временем обнаружения.'}, 'en': {'title': 'SAFE: Generalizing Failure Detection for Vision-Language-Action Models', 'desc': 'SAFE is a novel failure detector designed for vision-language-action models (VLAs) that enables them to generalize to new tasks. It leverages high-level internal features of VLAs to predict the likelihood of task failure, allowing robots to respond appropriately in unfamiliar environments. Unlike traditional failure detectors that are limited to specific tasks, SAFE is trained on both successful and failed attempts across various tasks, enhancing its adaptability. The effectiveness of SAFE is demonstrated through extensive testing on multiple policy architectures, achieving superior performance in failure detection compared to existing methods.'}, 'zh': {'title': 'SAFE：智能机器人故障检测的新方法', 'desc': 'SAFE是一个用于视觉-语言-行动模型的故障检测器，它能够通过学习模型的高层内部特征来推广到未见过的任务。尽管视觉-语言-行动模型在多种操作任务中表现出色，但在新任务上的成功率有限。为了让机器人安全地与环境互动，我们需要一个能够及时发出警报的故障检测器，以便机器人可以停止、回溯或请求帮助。我们提出的SAFE能够从VLA的内部特征中学习，并预测任务失败的可能性，经过广泛测试，显示出优越的故障检测性能。'}}}, {'id': 'https://huggingface.co/papers/2506.09007', 'title': 'Branched Schrödinger Bridge Matching', 'url': 'https://huggingface.co/papers/2506.09007', 'abstract': 'BranchSBM, a novel generative modeling framework, extends Schr\\"odinger Bridge Matching to model branched stochastic paths and multi-path evolution from a single initial distribution to multiple outcomes.  \t\t\t\t\tAI-generated summary \t\t\t\t Predicting the intermediate trajectories between an initial and target distribution is a central problem in generative modeling. Existing approaches, such as flow matching and Schr\\"odinger Bridge Matching, effectively learn mappings between two distributions by modeling a single stochastic path. However, these methods are inherently limited to unimodal transitions and cannot capture branched or divergent evolution from a common origin to multiple distinct outcomes. To address this, we introduce Branched Schr\\"odinger Bridge Matching (BranchSBM), a novel framework that learns branched Schr\\"odinger bridges. BranchSBM parameterizes multiple time-dependent velocity fields and growth processes, enabling the representation of population-level divergence into multiple terminal distributions. We show that BranchSBM is not only more expressive but also essential for tasks involving multi-path surface navigation, modeling cell fate bifurcations from homogeneous progenitor states, and simulating diverging cellular responses to perturbations.', 'score': 0, 'issue_id': 4252, 'pub_date': '2025-06-10', 'pub_date_card': {'ru': '10 июня', 'en': 'June 10', 'zh': '6月10日'}, 'hash': '8f3c4a6be505cd98', 'authors': ['Sophia Tang', 'Yinuo Zhang', 'Alexander Tong', 'Pranam Chatterjee'], 'affiliations': ['Center of Computational Biology, Duke-NUS Medical School', 'Department of Biomedical Engineering, Duke University', 'Department of Computer Science, Duke University', 'Department of Computer and Information Science, University of Pennsylvania', 'Mila, Quebec AI Institute', 'Université de Montréal'], 'pdf_title_img': 'assets/pdf/title_img/2506.09007.jpg', 'data': {'categories': ['#multimodal', '#diffusion', '#dataset', '#data'], 'emoji': '🌳', 'ru': {'title': 'BranchSBM: моделирование разветвленных путей в генеративных моделях', 'desc': 'BranchSBM - это новая система генеративного моделирования, расширяющая метод Schrödinger Bridge Matching для моделирования разветвленных стохастических путей. Она позволяет моделировать эволюцию от одного начального распределения к нескольким конечным состояниям. BranchSBM параметризует несколько зависящих от времени полей скоростей и процессов роста, что дает возможность представлять расхождение на уровне популяции в несколько конечных распределений. Этот метод особенно полезен для задач, связанных с навигацией по поверхности по нескольким путям, моделированием бифуркаций клеточных судеб и симуляцией расходящихся клеточных реакций на возмущения.'}, 'en': {'title': 'Branching Out: Modeling Multiple Outcomes with BranchSBM', 'desc': 'BranchSBM is a new framework in generative modeling that enhances the traditional Schr"odinger Bridge Matching by allowing for branched stochastic paths. Unlike previous methods that only model single paths between two distributions, BranchSBM can represent multiple outcomes from a single starting point. This is achieved by using multiple time-dependent velocity fields and growth processes, which capture the complexity of population-level divergence. The framework is particularly useful for applications like simulating cell fate decisions and navigating multi-path scenarios.'}, 'zh': {'title': '分支薛定谔桥匹配：捕捉多路径演化的生成建模新框架', 'desc': 'BranchSBM是一种新颖的生成建模框架，扩展了薛定谔桥匹配方法，以建模从单一初始分布到多个结果的分支随机路径和多路径演化。该方法通过参数化多个时间依赖的速度场和生长过程，能够表示从共同起源到多个不同结果的人口级别的分歧。与现有的单模态过渡方法相比，BranchSBM在处理多路径表面导航、细胞命运分叉建模以及模拟细胞对扰动的不同反应等任务中表现出更强的表达能力。总之，BranchSBM为生成建模提供了更丰富的工具，能够捕捉复杂的演化过程。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d', '#agents (1)', '#agi (1)', '#alignment', '#architecture (3)', '#audio', '#benchmark (3)', '#cv', '#data (3)', '#dataset (4)', '#diffusion (3)', '#ethics', '#games (2)', '#graphs', '#hallucinations', '#healthcare', '#inference (1)', '#interpretability', '#leakage', '#long_context (2)', '#low_resource', '#machine_translation', '#math', '#multilingual', '#multimodal (3)', '#open_source (1)', '#optimization (5)', '#plp', '#rag', '#reasoning (2)', '#rl (1)', '#rlhf (1)', '#robotics (1)', '#science', '#security (1)', '#small_models', '#story_generation', '#survey', '#synthetic (1)', '#training (5)', '#transfer_learning', '#video (3)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-06-12 05:12',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-06-12 05:12')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-06-12 05:12')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    