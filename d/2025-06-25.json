{
    "date": {
        "ru": "25 июня",
        "en": "June 25",
        "zh": "6月25日"
    },
    "time_utc": "2025-06-25 03:46",
    "weekday": 2,
    "issue_id": 4471,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2506.19851",
            "title": "AnimaX: Animating the Inanimate in 3D with Joint Video-Pose Diffusion\n  Models",
            "url": "https://huggingface.co/papers/2506.19851",
            "abstract": "AnimaX creates multi-skeleton 3D animations by blending video diffusion model priors with skeleton-based control, using joint video-pose diffusion and shared positional encodings.  \t\t\t\t\tAI-generated summary \t\t\t\t We present AnimaX, a feed-forward 3D animation framework that bridges the motion priors of video diffusion models with the controllable structure of skeleton-based animation. Traditional motion synthesis methods are either restricted to fixed skeletal topologies or require costly optimization in high-dimensional deformation spaces. In contrast, AnimaX effectively transfers video-based motion knowledge to the 3D domain, supporting diverse articulated meshes with arbitrary skeletons. Our method represents 3D motion as multi-view, multi-frame 2D pose maps, and enables joint video-pose diffusion conditioned on template renderings and a textual motion prompt. We introduce shared positional encodings and modality-aware embeddings to ensure spatial-temporal alignment between video and pose sequences, effectively transferring video priors to motion generation task. The resulting multi-view pose sequences are triangulated into 3D joint positions and converted into mesh animation via inverse kinematics. Trained on a newly curated dataset of 160,000 rigged sequences, AnimaX achieves state-of-the-art results on VBench in generalization, motion fidelity, and efficiency, offering a scalable solution for category-agnostic 3D animation. Project page: https://anima-x.github.io/{https://anima-x.github.io/}.",
            "score": 10,
            "issue_id": 4470,
            "pub_date": "2025-06-24",
            "pub_date_card": {
                "ru": "24 июня",
                "en": "June 24",
                "zh": "6月24日"
            },
            "hash": "ce9a811b1a9e7d9d",
            "authors": [
                "Zehuan Huang",
                "Haoran Feng",
                "Yangtian Sun",
                "Yuanchen Guo",
                "Yanpei Cao",
                "Lu Sheng"
            ],
            "affiliations": [
                "Beihang University, China",
                "The University of Hong Kong, China",
                "Tsinghua University, China",
                "VAST, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.19851.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#3d",
                    "#transfer_learning",
                    "#diffusion",
                    "#dataset"
                ],
                "emoji": "🦾",
                "ru": {
                    "title": "AnimaX: универсальная 3D-анимация с помощью диффузионных моделей видео",
                    "desc": "AnimaX - это фреймворк для создания 3D-анимации, объединяющий преимущества диффузионных моделей видео с контролируемой структурой скелетной анимации. Метод представляет 3D-движение в виде многоракурсных 2D-карт поз и позволяет выполнять совместную диффузию видео и поз на основе шаблонных рендеров и текстового описания движения. AnimaX использует общие позиционные кодировки и модально-специфичные эмбеддинги для обеспечения пространственно-временного выравнивания между видео и последовательностями поз. Результаты демонстрируют передовую производительность в обобщении, точности движений и эффективности для анимации различных 3D-моделей."
                },
                "en": {
                    "title": "Bridging Video Motion and 3D Animation with AnimaX",
                    "desc": "AnimaX is a novel framework for creating 3D animations that combines the strengths of video diffusion models with skeleton-based control. It allows for the generation of animations without being limited to fixed skeletal structures, overcoming the challenges of high-dimensional optimization. By using multi-view, multi-frame 2D pose maps and shared positional encodings, AnimaX ensures that video motion knowledge is effectively transferred to 3D motion generation. This method has been trained on a large dataset and demonstrates superior performance in terms of generalization, motion fidelity, and efficiency for diverse animated characters."
                },
                "zh": {
                    "title": "AnimaX：无类别 3D 动画的创新解决方案",
                    "desc": "AnimaX 是一个前馈式的 3D 动画框架，它结合了视频扩散模型的运动先验和基于骨骼的可控结构。与传统的运动合成方法不同，AnimaX 支持任意骨骼的多样化关节网格，并有效地将视频中的运动知识转移到 3D 领域。该方法通过多视角、多帧的 2D 姿态图表示 3D 运动，并利用共享位置编码和模态感知嵌入确保视频和姿态序列之间的时空对齐。经过在一个包含 160,000 个绑定序列的新数据集上训练，AnimaX 在 VBench 上实现了最先进的结果，提供了一种可扩展的无类别 3D 动画解决方案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.16141",
            "title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal\n  Reasoning",
            "url": "https://huggingface.co/papers/2506.16141",
            "abstract": "GRPO-CARE, a reinforcement learning framework optimizing for consistency and correctness, outperforms standard GRPO on a new video understanding benchmark, SEED-Bench-R1, improving both performance and logical coherence in multimodal large language models.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting exploration.To address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group peers.This dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.",
            "score": 10,
            "issue_id": 4471,
            "pub_date": "2025-06-19",
            "pub_date_card": {
                "ru": "19 июня",
                "en": "June 19",
                "zh": "6月19日"
            },
            "hash": "0d8fc795754c4210",
            "authors": [
                "Yi Chen",
                "Yuying Ge",
                "Rui Wang",
                "Yixiao Ge",
                "Junhao Cheng",
                "Ying Shan",
                "Xihui Liu"
            ],
            "affiliations": [
                "ARC Lab, Tencent PCG",
                "The Chinese University of Hong Kong",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.16141.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#rl",
                    "#interpretability",
                    "#multimodal",
                    "#benchmark",
                    "#training",
                    "#optimization",
                    "#video",
                    "#reasoning"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "GRPO-CARE: Согласованное обучение с подкреплением для мультимодальных ИИ",
                    "desc": "GRPO-CARE - это новый фреймворк обучения с подкреплением для мультимодальных больших языковых моделей. Он оптимизирует как точность ответов, так и логическую согласованность рассуждений без явного контроля. GRPO-CARE вводит двухуровневую систему вознаграждений: базовую за правильность ответа и адаптивный бонус за согласованность. Фреймворк превосходит стандартный GRPO на новом бенчмарке SEED-Bench-R1 для понимания видео, улучшая производительность и логическую связность."
                },
                "en": {
                    "title": "Enhancing Consistency and Correctness in Multimodal Learning",
                    "desc": "The paper introduces GRPO-CARE, a new reinforcement learning framework that enhances the performance and logical coherence of multimodal large language models (MLLMs) in video understanding tasks. It addresses the limitations of standard GRPO, which often sacrifices reasoning consistency for accuracy, by implementing a two-tiered reward system that promotes both correct answers and coherent reasoning. The authors present SEED-Bench-R1, a benchmark designed to rigorously evaluate MLLMs on complex video tasks, revealing that GRPO-CARE significantly outperforms GRPO with a notable increase in consistency and performance. This work not only proposes a novel framework but also contributes a valuable benchmark for future research in MLLM development."
                },
                "zh": {
                    "title": "提升一致性与正确性的强化学习框架",
                    "desc": "GRPO-CARE是一种强化学习框架，旨在优化一致性和正确性，超越了标准的GRPO方法。它在新的视频理解基准SEED-Bench-R1上表现出色，提升了多模态大语言模型的性能和逻辑连贯性。通过引入双重奖励机制，GRPO-CARE不仅关注答案的正确性，还鼓励推理过程的逻辑一致性。该框架在复杂的真实世界视频任务中展现了强大的迁移能力，推动了更具可解释性和鲁棒性的多模态大语言模型的发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.19767",
            "title": "SRFT: A Single-Stage Method with Supervised and Reinforcement\n  Fine-Tuning for Reasoning",
            "url": "https://huggingface.co/papers/2506.19767",
            "abstract": "Supervised Reinforcement Fine-Tuning (SRFT) integrates Supervised Fine-Tuning and Reinforcement Learning through entropy-aware weighting to achieve high accuracy in language model optimization.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) have achieved remarkable progress in reasoning tasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) remains a fundamental challenge. Through comprehensive analysis of token distributions, learning dynamics, and integration mechanisms from entropy-based perspectives, we reveal key differences between these paradigms: SFT induces coarse-grained global changes to LLM policy distributions, while RL performs fine-grained selective optimizations, with entropy serving as a critical indicator of training effectiveness. Building on these observations, we propose Supervised Reinforcement Fine-Tuning (SRFT), a single-stage method that unifies both fine-tuning paradigms through entropy-aware weighting mechanisms. Our approach simultaneously applies SFT and RL to directly optimize the LLM using demonstrations and self-exploration rollouts rather than through two-stage sequential methods. Extensive experiments show that SRFT achieves 59.1% average accuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning benchmarks and 10.9% on three out-of-distribution benchmarks.",
            "score": 4,
            "issue_id": 4471,
            "pub_date": "2025-06-24",
            "pub_date_card": {
                "ru": "24 июня",
                "en": "June 24",
                "zh": "6月24日"
            },
            "hash": "dfdf02be41523939",
            "authors": [
                "Yuqian Fu",
                "Tinghong Chen",
                "Jiajun Chai",
                "Xihuai Wang",
                "Songjun Tu",
                "Guojun Yin",
                "Wei Lin",
                "Qichao Zhang",
                "Yuanheng Zhu",
                "Dongbin Zhao"
            ],
            "affiliations": [
                "Institute of Automation, Chinese Academy of Sciences",
                "Meituan",
                "School of Artificial Intelligence, University of Chinese Academy of Sciences",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.19767.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#rlhf",
                    "#training",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Объединение supervised и reinforcement learning для улучшения языковых моделей",
                    "desc": "Статья представляет новый метод обучения языковых моделей - Supervised Reinforcement Fine-Tuning (SRFT). Этот подход объединяет Supervised Fine-Tuning и Reinforcement Learning, используя механизм взвешивания на основе энтропии. SRFT применяет оба метода одновременно, оптимизируя языковую модель напрямую с помощью демонстраций и самоисследования. Эксперименты показывают, что SRFT превосходит другие методы на задачах математических рассуждений и вне распределения обучающих данных."
                },
                "en": {
                    "title": "Unifying Fine-Tuning for Superior Language Model Performance",
                    "desc": "Supervised Reinforcement Fine-Tuning (SRFT) combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to enhance the performance of language models. It uses entropy-aware weighting to balance the strengths of both methods, allowing for better optimization of model policies. The paper highlights how SFT makes broad changes to model behavior, while RL focuses on specific improvements, with entropy being a key measure of success. SRFT has been shown to significantly improve accuracy on various reasoning tasks compared to traditional methods."
                },
                "zh": {
                    "title": "监督强化微调：优化语言模型的新方法",
                    "desc": "监督强化微调（SRFT）结合了监督微调和强化学习，通过熵感知加权实现语言模型优化的高准确性。研究表明，监督微调会对语言模型的策略分布产生粗粒度的全局变化，而强化学习则进行细粒度的选择性优化，熵是训练效果的重要指标。SRFT方法通过熵感知加权机制，将这两种微调范式统一为单阶段方法，直接优化语言模型。实验结果显示，SRFT在五个数学推理基准上平均准确率达到59.1%，比零强化学习方法提高了9.0%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.19290",
            "title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in\n  LLMs",
            "url": "https://huggingface.co/papers/2506.19290",
            "abstract": "An automated data-curation pipeline for software engineering improves large language model performance on SWE tasks, achieving state-of-the-art results with and without test-time scaling techniques.  \t\t\t\t\tAI-generated summary \t\t\t\t Software engineering (SWE) has recently emerged as a crucial testbed for next-generation LLM agents, demanding inherent capabilities in two critical dimensions: sustained iterative problem-solving (e.g., >50 interaction rounds) and long-context dependency resolution (e.g., >32k tokens). However, the data curation process in SWE remains notoriously time-consuming, as it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments to execute and validate unit tests. Consequently, most existing datasets are limited to only a few thousand GitHub-sourced instances. To this end, we propose an incremental, automated data-curation pipeline that systematically scales both the volume and diversity of SWE datasets. Our dataset comprises 10,169 real-world Python task instances from 2,531 distinct GitHub repositories, each accompanied by a task specified in natural language and a dedicated runtime-environment image for automated unit-test validation. We have carefully curated over 8,000 successfully runtime-validated training trajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE model on these trajectories, we uncover a striking data scaling phenomenon: the trained model's performance for software engineering capabilities in LLMs continues to improve as the data size increases, showing no signs of saturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on the SWE-bench Verified benchmark without using verifiers or multiple rollouts, establishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based LLMs built on the OpenHands agent framework. Furthermore, with the incorporation of test-time scaling techniques, the performance further improves to 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter models. We release the Skywork-SWE-32B model checkpoint to accelerate future research.",
            "score": 2,
            "issue_id": 4471,
            "pub_date": "2025-06-24",
            "pub_date_card": {
                "ru": "24 июня",
                "en": "June 24",
                "zh": "6月24日"
            },
            "hash": "7c26a879c3db6096",
            "authors": [
                "Liang Zeng",
                "Yongcong Li",
                "Yuzhen Xiao",
                "Changshi Li",
                "Chris Yuhao Liu",
                "Rui Yan",
                "Tianwen Wei",
                "Jujie He",
                "Xuchen Song",
                "Yang Liu",
                "Yahui Zhou"
            ],
            "affiliations": [
                "Skywork AI, Kunlun Inc"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.19290.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#dataset",
                    "#data",
                    "#long_context",
                    "#benchmark",
                    "#training"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Автоматизация курирования данных поднимает LLM на новый уровень в программной инженерии",
                    "desc": "Исследователи разработали автоматизированный конвейер для курирования данных в области программной инженерии, что позволило значительно улучшить производительность больших языковых моделей (LLM) на задачах разработки программного обеспечения. Новый подход позволил создать набор данных из более чем 10 000 реальных задач Python с автоматизированной валидацией через модульные тесты. Обучение модели Skywork-SWE на этих данных показало непрерывное улучшение производительности с увеличением объема данных. Модель достигла наилучших результатов среди LLM на базе Qwen2.5-Coder-32B, как с применением техник масштабирования во время тестирования, так и без них."
                },
                "en": {
                    "title": "Automating Data Curation to Boost LLMs in Software Engineering",
                    "desc": "This paper presents an automated data-curation pipeline designed to enhance the performance of large language models (LLMs) in software engineering (SWE) tasks. The pipeline addresses the challenges of manual data annotation and environment setup by providing a diverse dataset of over 10,000 real-world Python task instances from GitHub. The authors demonstrate that increasing the dataset size leads to improved model performance, with their Skywork-SWE model achieving state-of-the-art accuracy on the SWE-bench Verified benchmark. Additionally, the incorporation of test-time scaling techniques further boosts the model's performance, establishing new benchmarks for LLMs in SWE."
                },
                "zh": {
                    "title": "自动化数据整理，提升软件工程模型表现",
                    "desc": "本文提出了一种自动化数据整理管道，旨在提升大型语言模型（LLM）在软件工程（SWE）任务上的表现。该管道通过系统性地扩展数据集的规模和多样性，解决了传统数据整理过程中的时间消耗问题。我们构建了一个包含10,169个真实Python任务实例的数据集，并成功验证了超过8,000个训练轨迹。实验结果表明，随着数据量的增加，模型在软件工程能力上的表现持续提升，最终在SWE-bench Verified基准测试中达到了38.0%的准确率，创造了新的最先进水平。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2506.19838",
            "title": "SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution",
            "url": "https://huggingface.co/papers/2506.19838",
            "abstract": "Researchers propose design principles for cascaded video super-resolution models to improve high-resolution video generation by introduces degradation strategies, timestep sampling, noise augmentation, and interleaving temporal units with sparse local attention.  \t\t\t\t\tAI-generated summary \t\t\t\t Latent diffusion models have emerged as a leading paradigm for efficient video generation. However, as user expectations shift toward higher-resolution outputs, relying solely on latent computation becomes inadequate. A promising approach involves decoupling the process into two stages: semantic content generation and detail synthesis. The former employs a computationally intensive base model at lower resolutions, while the latter leverages a lightweight cascaded video super-resolution (VSR) model to achieve high-resolution output. In this work, we focus on studying key design principles for latter cascaded VSR models, which are underexplored currently. First, we propose two degradation strategies to generate training pairs that better mimic the output characteristics of the base model, ensuring alignment between the VSR model and its upstream generator. Second, we provide critical insights into VSR model behavior through systematic analysis of (1) timestep sampling strategies, (2) noise augmentation effects on low-resolution (LR) inputs. These findings directly inform our architectural and training innovations. Finally, we introduce interleaving temporal unit and sparse local attention to achieve efficient training and inference, drastically reducing computational overhead. Extensive experiments demonstrate the superiority of our framework over existing methods, with ablation studies confirming the efficacy of each design choice. Our work establishes a simple yet effective baseline for cascaded video super-resolution generation, offering practical insights to guide future advancements in efficient cascaded synthesis systems.",
            "score": 0,
            "issue_id": 4470,
            "pub_date": "2025-06-24",
            "pub_date_card": {
                "ru": "24 июня",
                "en": "June 24",
                "zh": "6月24日"
            },
            "hash": "a00bfa00a7f0f869",
            "authors": [
                "Liangbin Xie",
                "Yu Li",
                "Shian Du",
                "Menghan Xia",
                "Xintao Wang",
                "Fanghua Yu",
                "Ziyan Chen",
                "Pengfei Wan",
                "Jiantao Zhou",
                "Chao Dong"
            ],
            "affiliations": [
                "Kuaishou Technology",
                "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
                "Shenzhen University of Advanced Technology",
                "State Key Laboratory of Internet of Things for Smart City, University of Macau",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2506.19838.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#video",
                    "#diffusion",
                    "#architecture"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Эффективное сверхразрешение видео с помощью каскадных моделей",
                    "desc": "Исследователи предлагают принципы проектирования каскадных моделей сверхразрешения видео для улучшения генерации видео высокого разрешения. Они вводят стратегии деградации, выборку временных шагов, аугментацию шума и чередование временных блоков с разреженным локальным вниманием. Эти методы позволяют эффективно обучать и использовать модели, значительно снижая вычислительные затраты. Эксперименты показывают превосходство предложенного подхода над существующими методами."
                },
                "en": {
                    "title": "Enhancing Video Quality with Smart Cascaded Super-Resolution",
                    "desc": "This paper presents new design principles for improving cascaded video super-resolution (VSR) models, which are essential for generating high-resolution videos. The authors introduce innovative degradation strategies and timestep sampling methods to enhance the training process, ensuring that the VSR model aligns well with the base model's output. They also explore the impact of noise augmentation on low-resolution inputs and propose techniques like interleaving temporal units and sparse local attention to optimize training efficiency. The results show that their framework outperforms existing methods, providing a solid foundation for future developments in video super-resolution."
                },
                "zh": {
                    "title": "提升视频超分辨率生成的设计原则",
                    "desc": "本研究提出了级联视频超分辨率模型的设计原则，以提高高分辨率视频生成的效果。我们引入了退化策略、时间步采样、噪声增强和稀疏局部注意力等方法，来优化模型的训练和推理过程。通过系统分析，我们揭示了时间步采样策略和噪声增强对低分辨率输入的影响，从而指导模型架构和训练创新。实验结果表明，我们的方法在现有技术中具有显著优势，为未来高效级联合成系统的发展提供了实用的见解。"
                }
            }
        }
    ],
    "link_prev": "2025-06-24.html",
    "link_next": "2025-06-26.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "24.06",
        "en": "06/24",
        "zh": "6月24日"
    },
    "short_date_next": {
        "ru": "26.06",
        "en": "06/26",
        "zh": "6月26日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 0,
        "#rl": 2,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 1,
        "#audio": 0,
        "#video": 2,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 1,
        "#healthcare": 0,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 2,
        "#transfer_learning": 2,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 4,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    }
}