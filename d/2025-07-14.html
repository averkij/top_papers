
<!DOCTYPE html>
<html>
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C1CRWDNJ1J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-C1CRWDNJ1J');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>HF. 8 papers. July 14.</title>
<link rel="icon" href="favicon.svg" sizes="any" type="image/svg+xml">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@100..900&family=Tiny5&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: cornflowerblue;
            --primary-color-dark: #fffd87cf;
            --secondary-color: #fff;
            --background-color: #eee;
            --text-color: #333333;
            --header-color: cornflowerblue;
            --body-color: #eee;
            --menu-color: #002370;
        }
        .background-digit {
            position: absolute;
            font-family: 'Tiny5';
            bottom: -20px;
            right: -10px;
            font-size: 8em;
            font-weight: 400;
            color: #0989ea22;
            z-index: 2;
            line-height: 1;
        }
        .dark-theme .background-digit {
            color: #e9e78f3d;
        }
        body {
            font-family: 'Roboto Slab', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .container {
            max-width: 1500px;
            margin: 0 auto;
            flex: 1 0 auto;
            width: 100%
        }
        .a-clean {
            color: var(--secondary-color);
            text-decoration: none;
        }
        .a-clean:hover {
            color: #fff;
        }
        header {
            padding: 3.6em 0 2.4em 0;
            text-align: center;
        }
        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            margin-top: 2em;
            flex-shrink: 0;
            padding: 20px;
        }
        h1 {
            font-size: 2.4em;
            margin: 0;
            font-weight: 700;
        }
        .article-title-cont {
            margin: -21px -21px 0px -21px;
            padding: 10px 20px;
            background: cornflowerblue;
            display: table;
            min-height: 5.9em;
        }
        .dark-theme .article-title-cont {
            background: #444444;
        }
        .article-title {
            color: white;           
        }
        .article-title h2 {
            margin: 0px;
            padding: 0px;
            font-weight: 400;
            text-align:center;
        }
        h2 {
            # color: var(--primary-color);
            font-size: 1.2em;
            margin-top: 0;
            margin-bottom: 0.5em;
        }
        header p {
            font-size: 1.2em;
            margin-top: 0.5em;
            font-weight: 300;
        }
        main {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 1.5em;
            padding: 10px 20px 20px 20px;
        }
        body.dark-tmeme>header {
            background-color: background-color: #333333;
            color: white;
        }
        body.dark-theme>div>main>article>div.article-content>p.meta {
            color: #fff;
        }
        body.light-theme>div>main>article>div.article-content>p.meta {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>p.pub-date {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>p.pub-date {
            color: #555;
        }
        body.dark-theme>div>main>article>div.article-content>div.tags {
            color: #ccc;
        }
        body.light-theme>div>main>article>div.article-content>div.tags {
            color: #fff;
        }
        body.light-theme>header {
            background-color: var(--header-color);
            color: white;
        }
        article {
            display: flex;
            flex-direction: row;
            justify-content: center;
        }
        .article-content {
            border-radius: 5px;
            border: 1px solid #ddd;
            overflow: hidden;
            transition: background-color 0.2s ease;
            padding: 1.3em;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            position: relative;
            z-index: 1;
            cursor: pointer;
            max-width: 800px;
            position: relative;
        }
        body.dark-theme>div>main>article>div.article-content {
            background-color: #444;
            border: none;
        }
        body.light-theme>div>main>article>div.article-content {
            background-color: #fff;
        }
        body.dark-theme>div>main>article>div.article-content:hover {
            background-color: #414141;
        }
        body.light-theme>div>main>article>div.article-content:hover {
            background-color: #fafafa;
        }
        .meta {
            font-size: 0.9em;
            margin-bottom: 0em;
            font-weight: 500;
            margin: 20px 0 0px 0;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        .pub-date {
            font-size: 0.8em;
            margin-bottom: 0.8em;
            font-weight: 400;
            text-align: right;
            font-family: Roboto;
        }
        .tags {
            font-size: 0.9em;
            margin-bottom: 0;
            position: absolute;
            bottom: 0px;
            font-weight: 300;
            font-family: 'Roboto Slab';
            background: #555;
            left: 0;
            width: 100%;
            padding: 10px 20px;
        }
        .abstract {
            position: relative;
            max-height: 170px;
            overflow: hidden;
            transition: max-height 0.3s ease;
            cursor: pointer;
        }
        .abstract.expanded {
            max-height: 1000px;
        }
        .abstract-toggle {
            position: absolute;
            bottom: 4px;
            right: 0;
            cursor: pointer;
            color: var(--primary-color);
            float: right;
            font-weight: 400;
        }
        .explanation {
            background-color: #e8f5e9;
            border-left: 4px solid var(--secondary-color);
            padding: 1em;
            margin-top: 1.5em;
        }
        .links {
            margin-top: 1.5em;
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 50px;
            padding:10px;
            font-size: 0.9em;
            text-align: center
        }
        a {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        .dark-theme a {
            color: var(--primary-color-dark);
        }
        a:hover {
            color: #e73838;
        }
        .light-theme {
            background-color: var(--body-color);
            color: #333333;
        }
        .dark-theme {
            background-color: #333333;
            color: #ffffff;
        }
        .theme-switch {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
        }
        .switch {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 30px;
        }
        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 30px;
        }
        .slider:before {
            position: absolute;
            content: "";
            height: 24px;
            width: 24px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }
        input:checked + .slider {
            background-color: var(--primary-color);
        }
        input:checked + .slider:before {
            transform: translateX(20px);
        }
        .switch-label {
            margin-right: 10px;
        }

        .sub-header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 7px;
            padding: 0 20px;
        }
        .sub-header-container-2 {
            display: flex;
            justify-content: left;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 0 auto;
            padding: 0 20px;
        }
        .update-info-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: left;
            flex: 1;
        }
        .sort-container {
            margin-top: 15px;
            margin-bottom: 0px;
            text-align: right;
            flex: 2;
        }
        
        .category-toggle-container {
            display: inline-block;
            margin-top: 15px;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .category-option-container {
            margin-top: 15px;
            margin-bottom: 10px;
            display: none;
            margin-left: auto;
        }
        .category-option-container.expanded {
            display: block;
        }

        .sort-dropdown {
            padding: 5px 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            background-color: white;
            color: var(--text-color);
            font-family: 'Roboto Slab', sans-serif;
        }
        .sort-label {
            margin-right: 10px;
            font-size: 1.0em !important;
        }        
        .dark-theme .sort-dropdown {
            background-color: #444;
            color: white;
            border-color: var(--text-color);
        }
        .title-sign {
            display: inline-block;
            transition: all 0.5s ease;            
        }
        .rotate {
            transform: rotate(45deg) translateY(-6px);
            transform-origin: center;
        }
        .title-text {
            display: inline;
            padding-left: 10px;
        }
        .summary_title {
            font-size: 1.2em;
            font-weight: bold;
            color: #222;
            margin-bottom: 5px;
        }
        .summary_text {

        }
        .summary_image {
            max-height: 500px;
            max-width: 100%;
            align: center;
            margin-top: 40px;        
            margin-bottom: 60px;        
        }
        .category-filters {
            margin-top: 20px;
            margin-bottom: 20px;
            text-align: center;
            display: none;
        }
        .category-filters.expanded {
            display: block;
            margin-top: 10px;
        }
        .category-button {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .category-button.active {
            background-color: var(--primary-color);
            color: white;
        }
        .category-button.inactive:not(.active) {
            color: #ccc;
        }
        .dark-theme .category-button {
            background-color: #555;
            color: #fff;
        }
        .dark-theme .category-button.active {
            background-color: var(--primary-color);
        }
        .dark-theme .category-button.inactive:not(.active) {
            color: #888;
        }
        .clear-categories {
            display: inline-block;
            margin: 5px;
            padding: 5px 10px;
            border-radius: 15px;
            background-color: #f0f0f0;
            color: #333;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .clear-categories:hover {
            background-color: #bbb;
        }
        .svg-container {
            display: inline-block;
            position: relative;
            overflow: hidden;
        }
        .svg-container span {
            position: relative;
            z-index: 1;
        }
        .svg-container svg {
            position: absolute;
            bottom: 0;
            left: 0;
            z-index: 0;
        }

        .nav-menu {
            background-color: var(--menu-color);
            padding: 2px 0 2px 0;
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 100%;
        }        
        .nav-container {
            max-width: 1500px;
            margin: 0 auto;
            display: flex;
            justify-content: left;
            gap: 3em;
        }
        .nav-container span a {
            color: white;
        }        
        .nav-item {
            color: white;
            padding: 3px 0px;
            cursor: pointer;
            font-weight: 400;
        }         
        .nav-prev {
            margin-left: 20px;
        }        
        .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.3);
        }        
        .language-flags {
            display: flex;
            gap: 7px;
            padding: 5px 20px 0 0;
            margin-left: auto;
        }
        .flag-svg {
            width: 22px;
            height: 22px;
            cursor: pointer;
            opacity: 0.4;
            transition: opacity 0.3s ease;
            border-radius: 2px;
        }
        .flag-svg.active {
            opacity: 1;
        }
        .flag-svg:hover {
            opacity: 0.8;
        }
        
        .dark-theme .nav-menu {
            background-color: #333;
        }
        .dark-theme .nav-item {
            color: white;
        }
        
        .dark-theme .nav-item:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .pointer { cursor: pointer; }

        .article-pdf-title-img {
            max-width: 100%;
            max-height: 400px;
            display: inline-block;
            margin-top: 10px;
            margin-bottom: 10px;
            border-radius: 5px;
        }
        .article-pdf-title-img-cont {
            text-align: center;
        }
        .dark-theme .article-pdf-title-img {
            opacity: 0.8;
            filter: grayscale(1);
        }

        @media (max-width: 600px) {
            .nav-container {
                flex-direction: row;
                gap: 1.5em;
            }            
            .nav-item {
                padding: 3px 0px;
            }
        }
        
        @media (max-width: 768px) {
            .category-filters {
                display: none;
            }
            .category-toggle {
                display: inline-block;
                width: 100%;
                text-align: left;
            }
            .category-filters.expanded {
                display: block;
                margin-top: 10px;
            }
        }
        @media (max-width: 600px) {
            .sub-header-container {
                flex-direction: column;
                align-items: flex-start;
            }
            .sort-container {
                width: 100%;
                display: flex;
                justify-content: left;
                margin: 0 auto;
            }
            .sort-dropdown {
                margin-left: auto;
            }
            .sort-label {
                margin-top: 5px;
                float: left;
            }

            .sub-header-container-2 {
                flex-direction: row;
                align-items: flex-start;
            }
            .update-info-container {
                text-align: left;
                width: 100%;
                margin-bottom: 0px;
            }
            .category-toggle-container {
                margin-top: 15px;
                text-align: left;
                margin-bottom: 10px;
            }
            .category-option-container {
                margin-top: 15px;
                text-align: center;
                margin-bottom: 10px;
            }            
            main {
                grid-template-columns: repeat(auto-fit);
                gap: 0em;
                padding: 10px 0 20px 0;
            }
            footer {
                margin-top: -20px;
            }
            article>div.article-content {
                border-radius: 0px;
            }
        }
    </style>
    <script>
    function toggleAbstract(id) {
        var abstract = document.getElementById('abstract-' + id);
        var toggle = document.getElementById('toggle-' + id);
        if (abstract.classList.contains('expanded')) {
            abstract.classList.remove('expanded');
            toggle.textContent = '...';
        } else {
            abstract.classList.add('expanded');
            toggle.textContent = '';
        }
    }
    function getTimeDiff(dateString, lang='ru') {
        const timeUnits = {
            ru: {
                minute: ["минуту", "минуты", "минут"],
                hour: ["час", "часа", "часов"],
                day: ["день", "дня", "дней"],
                justNow: "только что",
                ago: "назад"
            },
            en: {
                minute: ["minute", "minutes", "minutes"],
                hour: ["hour", "hours", "hours"],
                day: ["day", "days", "days"],
                justNow: "just now",
                ago: "ago"
            },
            zh: {
                minute: ["分钟", "分钟", "分钟"],
                hour: ["小时", "小时", "小时"],
                day: ["天", "天", "天"],
                justNow: "刚刚",
                ago: "前"
            }
        };

        function getPlural(number, words, lang) {
            if (lang === 'ru') {
                if (number % 10 === 1 && number % 100 !== 11) {
                    return words[0];
                } else if (number % 10 >= 2 && number % 10 <= 4 && (number % 100 < 10 || number % 100 >= 20)) {
                    return words[1];
                } else {
                    return words[2];
                }
            } else if (lang === 'en') {
                return number === 1 ? words[0] : words[1];
            } else {
                // Chinese doesn't need plural forms
                return words[0];
            }
        }

        function formatTimeDiff(number, unit, lang) {
            const unitWord = getPlural(number, timeUnits[lang][unit], lang);
            
            if (lang === 'zh') {
                return `${number}${unitWord}${timeUnits[lang].ago}`;
            } else {
                return `${number} ${unitWord} ${timeUnits[lang].ago}`;
            }
        }

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        const pastDate = new Date(dateString.replace(" ", "T") + ":00Z");
        const currentDate = new Date();
        const diffInSeconds = Math.floor((currentDate - pastDate) / 1000);
        
        const minutes = Math.floor(diffInSeconds / 60);
        const hours = Math.floor(diffInSeconds / 3600);
        const days = Math.floor(diffInSeconds / 86400);

        if (minutes === 0) {
            return timeUnits[lang].justNow;
        } else if (minutes < 60) {
            return formatTimeDiff(minutes, 'minute', lang);
        } else if (hours < 24) {
            return formatTimeDiff(hours, 'hour', lang);
        } else {
            return formatTimeDiff(days, 'day', lang);
        }
    }
    function isToday(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth() &&
            inputDate.getDate() === today.getDate()
        );
    }
    function isCurrentMonth(dateString) {
        const inputDate = new Date(dateString);
        const today = new Date();
        return (
            inputDate.getFullYear() === today.getFullYear() &&
            inputDate.getMonth() === today.getMonth()
        );
    }
    function formatArticlesTitle(number, lang='ru') {
        const lastDigit = number % 10;
        const lastTwoDigits = number % 100;
        let word;

        if (!['ru', 'en', 'zh'].includes(lang)) {
            throw new Error('Unsupported language. Supported languages are: ru, en, zh');
        }

        if (lang === 'ru') {
            if (lastTwoDigits >= 11 && lastTwoDigits <= 14) {
                word = "статей";
            } else if (lastDigit === 1) {
                word = "статья";
            } else if (lastDigit >= 2 && lastDigit <= 4) {
                word = "статьи";
            } else {
                word = "статей";
            }
        } else if (lang === 'en') {
            if (number === 1) {
                word = 'paper'
            } else {
                word = 'papers'
            }
        } else if (lang === 'zh') {
            word = "篇论文"
        }

        if (lang === 'zh') {
            return `${number}${word}`;
        } else {
            return `${number} ${word}`;
        }
    }
    </script>
</head>
<body class="light-theme">
    <header>
        <div class="container">            
            <a href="https://hfday.ru" class="a-clean"><h1 class="title-sign" id="doomgrad-icon">🔺</h1><h1 class="title-text" id="doomgrad">hf daily</h1></a>
            <p><span id="title-date">14 июля</span> | <span id="title-articles-count">8 papers</span></p>
        </div>
        <div class="theme-switch">
            <label class="switch">
                <input type="checkbox" id="theme-toggle">
                <span class="slider"></span>
            </label>
        </div>
    </header>
    <div class="nav-menu">
        <div class="nav-container">
            <span class="nav-item nav-prev" id="nav-prev"><a href="/d/2025-07-11.html">⬅️ <span id="prev-date">11.07</span></a></span>
            <span class="nav-item" id="nav-next"><a href="/d/2025-07-15.html">➡️ <span id="next-date">15.07</span></a></span>
            <span class="nav-item" id="nav-monthly"><a href="/m/2025-07.html">📈 <span id='top-month-label'>Месяц</span></a></span>
            <div class="language-flags">
                <svg class="flag-svg" data-lang="ru" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><path fill="#1435a1" d="M1 11H31V21H1z"></path><path d="M5,4H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" fill="#fff"></path><path d="M5,20H27c2.208,0,4,1.792,4,4v4H1v-4c0-2.208,1.792-4,4-4Z" transform="rotate(180 16 24)" fill="#c53a28"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="zh" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#db362f"></rect><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path fill="#ff0" d="M7.958 10.152L7.19 7.786 6.421 10.152 3.934 10.152 5.946 11.614 5.177 13.979 7.19 12.517 9.202 13.979 8.433 11.614 10.446 10.152 7.958 10.152z"></path><path fill="#ff0" d="M12.725 8.187L13.152 8.898 13.224 8.072 14.032 7.886 13.269 7.562 13.342 6.736 12.798 7.361 12.035 7.037 12.461 7.748 11.917 8.373 12.725 8.187z"></path><path fill="#ff0" d="M14.865 10.372L14.982 11.193 15.37 10.46 16.187 10.602 15.61 10.007 15.997 9.274 15.253 9.639 14.675 9.044 14.793 9.865 14.048 10.23 14.865 10.372z"></path><path fill="#ff0" d="M15.597 13.612L16.25 13.101 15.421 13.13 15.137 12.352 14.909 13.149 14.081 13.179 14.769 13.642 14.541 14.439 15.194 13.928 15.881 14.391 15.597 13.612z"></path><path fill="#ff0" d="M13.26 15.535L13.298 14.707 12.78 15.354 12.005 15.062 12.46 15.754 11.942 16.402 12.742 16.182 13.198 16.875 13.236 16.047 14.036 15.827 13.26 15.535z"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path></svg>
                <svg class="flag-svg" data-lang="en" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32"><rect x="1" y="4" width="30" height="24" rx="4" ry="4" fill="#fff"></rect><path d="M1.638,5.846H30.362c-.711-1.108-1.947-1.846-3.362-1.846H5c-1.414,0-2.65,.738-3.362,1.846Z" fill="#a62842"></path><path d="M2.03,7.692c-.008,.103-.03,.202-.03,.308v1.539H31v-1.539c0-.105-.022-.204-.03-.308H2.03Z" fill="#a62842"></path><path fill="#a62842" d="M2 11.385H31V13.231H2z"></path><path fill="#a62842" d="M2 15.077H31V16.923000000000002H2z"></path><path fill="#a62842" d="M1 18.769H31V20.615H1z"></path><path d="M1,24c0,.105,.023,.204,.031,.308H30.969c.008-.103,.031-.202,.031-.308v-1.539H1v1.539Z" fill="#a62842"></path><path d="M30.362,26.154H1.638c.711,1.108,1.947,1.846,3.362,1.846H27c1.414,0,2.65-.738,3.362-1.846Z" fill="#a62842"></path><path d="M5,4h11v12.923H1V8c0-2.208,1.792-4,4-4Z" fill="#102d5e"></path><path d="M27,4H5c-2.209,0-4,1.791-4,4V24c0,2.209,1.791,4,4,4H27c2.209,0,4-1.791,4-4V8c0-2.209-1.791-4-4-4Zm3,20c0,1.654-1.346,3-3,3H5c-1.654,0-3-1.346-3-3V8c0-1.654,1.346-3,3-3H27c1.654,0,3,1.346,3,3V24Z" opacity=".15"></path><path d="M27,5H5c-1.657,0-3,1.343-3,3v1c0-1.657,1.343-3,3-3H27c1.657,0,3,1.343,3,3v-1c0-1.657-1.343-3-3-3Z" fill="#fff" opacity=".2"></path><path fill="#fff" d="M4.601 7.463L5.193 7.033 4.462 7.033 4.236 6.338 4.01 7.033 3.279 7.033 3.87 7.463 3.644 8.158 4.236 7.729 4.827 8.158 4.601 7.463z"></path><path fill="#fff" d="M7.58 7.463L8.172 7.033 7.441 7.033 7.215 6.338 6.989 7.033 6.258 7.033 6.849 7.463 6.623 8.158 7.215 7.729 7.806 8.158 7.58 7.463z"></path><path fill="#fff" d="M10.56 7.463L11.151 7.033 10.42 7.033 10.194 6.338 9.968 7.033 9.237 7.033 9.828 7.463 9.603 8.158 10.194 7.729 10.785 8.158 10.56 7.463z"></path><path fill="#fff" d="M6.066 9.283L6.658 8.854 5.927 8.854 5.701 8.158 5.475 8.854 4.744 8.854 5.335 9.283 5.109 9.979 5.701 9.549 6.292 9.979 6.066 9.283z"></path><path fill="#fff" d="M9.046 9.283L9.637 8.854 8.906 8.854 8.68 8.158 8.454 8.854 7.723 8.854 8.314 9.283 8.089 9.979 8.68 9.549 9.271 9.979 9.046 9.283z"></path><path fill="#fff" d="M12.025 9.283L12.616 8.854 11.885 8.854 11.659 8.158 11.433 8.854 10.702 8.854 11.294 9.283 11.068 9.979 11.659 9.549 12.251 9.979 12.025 9.283z"></path><path fill="#fff" d="M6.066 12.924L6.658 12.494 5.927 12.494 5.701 11.799 5.475 12.494 4.744 12.494 5.335 12.924 5.109 13.619 5.701 13.19 6.292 13.619 6.066 12.924z"></path><path fill="#fff" d="M9.046 12.924L9.637 12.494 8.906 12.494 8.68 11.799 8.454 12.494 7.723 12.494 8.314 12.924 8.089 13.619 8.68 13.19 9.271 13.619 9.046 12.924z"></path><path fill="#fff" d="M12.025 12.924L12.616 12.494 11.885 12.494 11.659 11.799 11.433 12.494 10.702 12.494 11.294 12.924 11.068 13.619 11.659 13.19 12.251 13.619 12.025 12.924z"></path><path fill="#fff" d="M13.539 7.463L14.13 7.033 13.399 7.033 13.173 6.338 12.947 7.033 12.216 7.033 12.808 7.463 12.582 8.158 13.173 7.729 13.765 8.158 13.539 7.463z"></path><path fill="#fff" d="M4.601 11.104L5.193 10.674 4.462 10.674 4.236 9.979 4.01 10.674 3.279 10.674 3.87 11.104 3.644 11.799 4.236 11.369 4.827 11.799 4.601 11.104z"></path><path fill="#fff" d="M7.58 11.104L8.172 10.674 7.441 10.674 7.215 9.979 6.989 10.674 6.258 10.674 6.849 11.104 6.623 11.799 7.215 11.369 7.806 11.799 7.58 11.104z"></path><path fill="#fff" d="M10.56 11.104L11.151 10.674 10.42 10.674 10.194 9.979 9.968 10.674 9.237 10.674 9.828 11.104 9.603 11.799 10.194 11.369 10.785 11.799 10.56 11.104z"></path><path fill="#fff" d="M13.539 11.104L14.13 10.674 13.399 10.674 13.173 9.979 12.947 10.674 12.216 10.674 12.808 11.104 12.582 11.799 13.173 11.369 13.765 11.799 13.539 11.104z"></path><path fill="#fff" d="M4.601 14.744L5.193 14.315 4.462 14.315 4.236 13.619 4.01 14.315 3.279 14.315 3.87 14.744 3.644 15.44 4.236 15.01 4.827 15.44 4.601 14.744z"></path><path fill="#fff" d="M7.58 14.744L8.172 14.315 7.441 14.315 7.215 13.619 6.989 14.315 6.258 14.315 6.849 14.744 6.623 15.44 7.215 15.01 7.806 15.44 7.58 14.744z"></path><path fill="#fff" d="M10.56 14.744L11.151 14.315 10.42 14.315 10.194 13.619 9.968 14.315 9.237 14.315 9.828 14.744 9.603 15.44 10.194 15.01 10.785 15.44 10.56 14.744z"></path><path fill="#fff" d="M13.539 14.744L14.13 14.315 13.399 14.315 13.173 13.619 12.947 14.315 12.216 14.315 12.808 14.744 12.582 15.44 13.173 15.01 13.765 15.44 13.539 14.744z"></path></svg>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="sub-header-container">
            <div class="update-info-container">
                <label class="update-info-label" id="timeDiff"></label>
            </div>
            <div class="sort-container">
                <label class="sort-label">🔀 <span id="sort-label-text">Сортировка по</span></label>
                <select id="sort-dropdown" class="sort-dropdown">
                    <option value="default">рейтингу</option>
                    <option value="pub_date">дате публикации</option>
                    <option value="issue_id">добавлению на HF</option>
                </select>
            </div>
        </div>
        <div class="sub-header-container-2">
            <div class="category-toggle-container">
                <div class="svg-container">
                    <span id="category-toggle">🏷️ Фильтр</span>
                    <svg height="3" width="200">
                        <line x1="0" y1="0" x2="200" y2="0" 
                            stroke="black" 
                            stroke-width="2" 
                            stroke-dasharray="3, 3" />
                    </svg>
                </div>
            </div>
            <div class="category-option-container" id="category-options">                
                <label class="pointer" for="filter-logic-or"><input type="radio" id="filter-logic-or" name="filter-logic" value="or"> A∪B</label>
                <label class="pointer" for="filter-logic-and"><input type="radio" id="filter-logic-and" name="filter-logic" value="and"> A∩B</label>
            </div> 
        </div>
        <div class="category-filters" id="category-filters">
            <span class="clear-categories" id="clear-categories">🧹</span>
            <!-- Categories -->
        </div>
        <main id="articles-container">
            <!-- Articles -->
        </main>
    </div>
    <footer>
        <div class="container">
            <p><a style="color:white;" href="https://t.me/doomgrad">doomgrad</a> ✖️ <a style="color:white;" href="https://huggingface.co/papers">hugging face</a></p>
        </div>
    </footer>
    <script>
        // Language handling
        let currentLang = localStorage.getItem('selectedLang') || 'en';
        let feedDate = {'ru': '14 июля', 'en': 'July 14', 'zh': '7月14日'};
        let feedDateNext = {'ru': '15.07', 'en': '07/15', 'zh': '7月15日'};
        let feedDatePrev = {'ru': '11.07', 'en': '07/11', 'zh': '7月11日'};
        let filterLabel = {'ru': 'Фильтр', 'en': 'Topics', 'zh': '主题筛选'}
        let publishedLabel = {'ru': 'статья от ', 'en': 'published on ', 'zh': '发表于'}
        let sortLabel = {'ru': 'Сортировка по', 'en': 'Sort by', 'zh': '排序方式'}
        let paperLabel = {'ru': 'Статья', 'en': 'Paper', 'zh': '论文'}
        let topMonthLabel = {'ru': 'Месяц', 'en': 'Month', 'zh': '月度论文'}
        let topDayLabel = {'ru': 'День', 'en': 'Day', 'zh': '日度论文'}
        
        function initializeLanguageFlags() {
            const flags = document.querySelectorAll('.flag-svg');
            flags.forEach(flag => {
                if (flag.dataset.lang === currentLang) {
                    flag.classList.add('active');
                }
                flag.addEventListener('click', () => {
                    flags.forEach(f => f.classList.remove('active'));
                    flag.classList.add('active');
                    currentLang = flag.dataset.lang;
                    localStorage.setItem('selectedLang', currentLang);
                    updateTimeDiffs();
                    updateLocalization();
                    filterAndRenderArticles();
                });
            });
        }
        function toggleTheme() {
            const body = document.body;
            body.classList.toggle('light-theme');
            body.classList.toggle('dark-theme');

            const isDarkMode = body.classList.contains('dark-theme');
            localStorage.setItem('darkMode', isDarkMode);
            
            if (isDarkMode) {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }  else {
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf daily";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.remove('rotate');
            }
        }

        const articlesData = [{'id': 'https://huggingface.co/papers/2507.08776', 'title': 'CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive\n  Neural Rendering', 'url': 'https://huggingface.co/papers/2507.08776', 'abstract': 'A neural rendering method uses compressed light-field tokens to efficiently represent scenes and render novel views with varying compute budgets.  \t\t\t\t\tAI-generated summary \t\t\t\t This paper proposes a neural rendering approach that represents a scene as "compressed light-field tokens (CLiFTs)", retaining rich appearance and geometric information of a scene. CLiFT enables compute-efficient rendering by compressed tokens, while being capable of changing the number of tokens to represent a scene or render a novel view with one trained network. Concretely, given a set of images, multi-view encoder tokenizes the images with the camera poses. Latent-space K-means selects a reduced set of rays as cluster centroids using the tokens. The multi-view ``condenser\'\' compresses the information of all the tokens into the centroid tokens to construct CLiFTs. At test time, given a target view and a compute budget (i.e., the number of CLiFTs), the system collects the specified number of nearby tokens and synthesizes a novel view using a compute-adaptive renderer. Extensive experiments on RealEstate10K and DL3DV datasets quantitatively and qualitatively validate our approach, achieving significant data reduction with comparable rendering quality and the highest overall rendering score, while providing trade-offs of data size, rendering quality, and rendering speed.', 'score': 33, 'issue_id': 4792, 'pub_date': '2025-07-11', 'pub_date_card': {'ru': '11 июля', 'en': 'July 11', 'zh': '7月11日'}, 'hash': '9361d4738ec618fe', 'authors': ['Zhengqing Wang', 'Yuefan Wu', 'Jiacheng Chen', 'Fuyang Zhang', 'Yasutaka Furukawa'], 'affiliations': ['Simon Fraser University', 'Wayve'], 'pdf_title_img': 'assets/pdf/title_img/2507.08776.jpg', 'data': {'categories': ['#benchmark', '#3d', '#dataset'], 'emoji': '🎥', 'ru': {'title': 'Эффективный нейрорендеринг с помощью сжатых токенов светового поля', 'desc': 'Эта статья представляет нейронный метод рендеринга, использующий сжатые токены светового поля (CLiFTs) для эффективного представления сцен. Метод позволяет рендерить новые ракурсы с различными вычислительными бюджетами, сохраняя богатую информацию о внешнем виде и геометрии сцены. Система использует мультиракурсное кодирование, кластеризацию в латентном пространстве и адаптивный рендерер для достижения компромисса между размером данных, качеством рендеринга и скоростью. Эксперименты на наборах данных RealEstate10K и DL3DV подтверждают эффективность подхода, демонстрируя значительное сокращение данных при сопоставимом качестве рендеринга.'}, 'en': {'title': 'Efficient Scene Representation with Compressed Light-Field Tokens', 'desc': 'This paper introduces a novel neural rendering technique that utilizes compressed light-field tokens (CLiFTs) to efficiently depict scenes and generate new views. By employing a multi-view encoder, the method tokenizes images based on their camera positions, allowing for effective representation of both appearance and geometry. The approach leverages latent-space K-means to select key rays as cluster centroids, which are then condensed into CLiFTs for streamlined rendering. The system adapts to different compute budgets by varying the number of tokens used, demonstrating significant data reduction while maintaining high rendering quality across various datasets.'}, 'zh': {'title': '高效神经渲染：压缩光场标记的应用', 'desc': '这篇论文提出了一种神经渲染方法，使用压缩光场标记（CLiFTs）来高效表示场景并渲染新视图。CLiFT通过压缩标记实现计算效率，同时能够根据需要调整标记数量以表示场景或渲染新视图。具体来说，给定一组图像，多视角编码器将图像与相机姿态进行标记。通过潜在空间K均值选择一组减少的光线作为聚类中心，最终构建出CLiFTs。'}}}, {'id': 'https://huggingface.co/papers/2507.01951', 'title': 'Test-Time Scaling with Reflective Generative Model', 'url': 'https://huggingface.co/papers/2507.01951', 'abstract': "MetaStone-S1, a reflective generative model using a self-supervised process reward model, achieves efficient reasoning and scalable performance with fewer parameters compared to existing models.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce our first reflective generative model MetaStone-S1, which obtains OpenAI o3's performance via the self-supervised process reward model (SPRM). Through sharing the backbone network and using task-specific heads for next token prediction and process scoring respectively, SPRM successfully integrates the policy model and process reward model(PRM) into a unified interface without extra process annotation, reducing over 99% PRM parameters for efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable for test time scaling (TTS), and we provide three reasoning effort modes (low, medium, and high), based on the controllable thinking length. Moreover, we empirically establish a scaling law that reveals the relationship between total thinking computation and TTS performance. Experiments demonstrate that our MetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with only 32B parameter size. To support the research community, we have open-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.", 'score': 30, 'issue_id': 4792, 'pub_date': '2025-07-02', 'pub_date_card': {'ru': '2 июля', 'en': 'July 2', 'zh': '7月2日'}, 'hash': '46a6ab7d22e05401', 'authors': ['Zixiao Wang', 'Yuxin Wang', 'Xiaorui Wang', 'Mengting Xing', 'Jie Gao', 'Jianjun Xu', 'Guangcan Liu', 'Chenhui Jin', 'Zhuo Wang', 'Shengzhuo Zhang', 'Hongtao Xie'], 'affiliations': ['MetaStone-AI', 'USTC'], 'pdf_title_img': 'assets/pdf/title_img/2507.01951.jpg', 'data': {'categories': ['#training', '#open_source', '#architecture', '#rl', '#small_models', '#reasoning'], 'emoji': '🧠', 'ru': {'title': 'Эффективное рассуждение с меньшими ресурсами: MetaStone-S1 переопределяет генеративные модели', 'desc': 'MetaStone-S1 - это рефлексивная генеративная модель, использующая самоконтролируемую модель вознаграждения процесса (SPRM). Она достигает эффективного рассуждения и масштабируемой производительности с меньшим количеством параметров по сравнению с существующими моделями. SPRM объединяет модель политики и модель вознаграждения процесса в единый интерфейс, сокращая более 99% параметров для эффективного рассуждения. MetaStone-S1 предлагает три режима усилий рассуждения и устанавливает закон масштабирования, связывающий общие вычисления мышления и производительность TTS.'}, 'en': {'title': 'Efficient Reasoning with Fewer Parameters: Introducing MetaStone-S1', 'desc': 'MetaStone-S1 is a new generative model that uses a self-supervised process reward model (SPRM) to enhance reasoning capabilities while maintaining a smaller parameter size. By integrating the policy model and process reward model into a single framework, it significantly reduces the number of parameters needed for effective reasoning. The model offers different reasoning effort modes, allowing users to control the depth of thinking during tasks. Experiments show that MetaStone-S1 performs comparably to larger models while being more efficient, and it is available for the research community to explore.'}, 'zh': {'title': 'MetaStone-S1：高效推理的新一代生成模型', 'desc': 'MetaStone-S1是一种反思生成模型，采用自监督过程奖励模型（SPRM），在参数更少的情况下实现高效推理和可扩展性能。该模型通过共享主干网络，并使用特定任务的头部进行下一个标记预测和过程评分，成功将策略模型和过程奖励模型整合为统一接口，减少了99%以上的参数。MetaStone-S1适合测试时间扩展（TTS），并提供低、中、高三种推理努力模式，基于可控的思考长度。实验表明，MetaStone-S1在仅32B参数的情况下，性能与OpenAI-o3-mini系列相当。'}}}, {'id': 'https://huggingface.co/papers/2507.08800', 'title': 'NeuralOS: Towards Simulating Operating Systems via Neural Generative\n  Models', 'url': 'https://huggingface.co/papers/2507.08800', 'abstract': 'NeuralOS uses a combination of RNNs and diffusion-based rendering to simulate OS GUIs by predicting screen frames from user inputs, demonstrating realistic GUI rendering and state transitions.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems.', 'score': 12, 'issue_id': 4792, 'pub_date': '2025-07-11', 'pub_date_card': {'ru': '11 июля', 'en': 'July 11', 'zh': '7月11日'}, 'hash': '97c49e854df6a19d', 'authors': ['Luke Rivard', 'Sun Sun', 'Hongyu Guo', 'Wenhu Chen', 'Yuntian Deng'], 'affiliations': ['National Research Council Canada', 'University of Waterloo'], 'pdf_title_img': 'assets/pdf/title_img/2507.08800.jpg', 'data': {'categories': ['#games', '#diffusion', '#dataset', '#agents', '#multimodal', '#cv'], 'emoji': '🖥️', 'ru': {'title': 'Нейронная симуляция GUI: шаг к адаптивным интерфейсам будущего', 'desc': 'NeuralOS - это нейронная система, симулирующая графические интерфейсы операционных систем путем предсказания кадров экрана в ответ на действия пользователя. Она объединяет рекуррентную нейронную сеть (RNN) для отслеживания состояния компьютера и нейронный рендерер на основе диффузии для генерации изображений экрана. Модель обучена на большом наборе данных записей Ubuntu XFCE, включающем как случайные, так и реалистичные взаимодействия. Эксперименты показывают, что NeuralOS успешно визуализирует реалистичные GUI-последовательности и точно предсказывает переходы состояний, хотя моделирование детальных клавиатурных взаимодействий остается сложной задачей.'}, 'en': {'title': 'NeuralOS: Predicting GUIs with RNNs and Diffusion Rendering', 'desc': "NeuralOS is a neural framework designed to simulate operating system graphical user interfaces (GUIs) by predicting screen frames based on user inputs like mouse movements and keyboard events. It utilizes a recurrent neural network (RNN) to keep track of the computer's state and a diffusion-based renderer to create realistic screen images. The model is trained on a comprehensive dataset of Ubuntu XFCE recordings, which include both random and realistic user interactions. While it excels at rendering GUI sequences and predicting state transitions, accurately modeling detailed keyboard interactions remains a challenge, marking a significant advancement in generative neural interfaces for human-computer interaction."}, 'zh': {'title': 'NeuralOS：未来人机交互的智能界面', 'desc': 'NeuralOS 是一个神经网络框架，能够通过预测用户输入（如鼠标移动、点击和键盘事件）来模拟操作系统的图形用户界面（GUI）。它结合了递归神经网络（RNN）和基于扩散的神经渲染器，能够生成屏幕图像并跟踪计算机状态。该模型在大规模的 Ubuntu XFCE 录制数据集上进行训练，包含随机生成的交互和 AI 代理生成的真实交互。尽管精确建模细粒度的键盘交互仍然具有挑战性，NeuralOS 为未来人机交互系统创建完全自适应的生成神经接口迈出了重要一步。'}}}, {'id': 'https://huggingface.co/papers/2507.08801', 'title': 'Lumos-1: On Autoregressive Video Generation from a Unified Model\n  Perspective', 'url': 'https://huggingface.co/papers/2507.08801', 'abstract': 'Lumos-1 is an autoregressive video generator that uses a modified LLM architecture with MM-RoPE and AR-DF to address spatiotemporal correlation and frame-wise loss imbalance, achieving competitive performance with fewer resources.  \t\t\t\t\tAI-generated summary \t\t\t\t Autoregressive large language models (LLMs) have unified a vast range of language tasks, inspiring preliminary efforts in autoregressive video generation. Existing autoregressive video generators either diverge from standard LLM architectures, depend on bulky external text encoders, or incur prohibitive latency due to next-token decoding. In this paper, we introduce Lumos-1, an autoregressive video generator that retains the LLM architecture with minimal architectural modifications. To inject spatiotemporal correlations in LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its imbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE scheme that preserves the original textual RoPE while providing comprehensive frequency spectra and scaled 3D positions for modeling multimodal spatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy that obeys intra-frame bidirectionality and inter-frame temporal causality. Based on this dependency strategy, we identify the issue of frame-wise loss imbalance caused by spatial information redundancy and solve it by proposing Autoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal tube masking during training with a compatible inference-time masking policy to avoid quality degradation. By using memory-efficient training techniques, we pre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on GenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code and models are available at https://github.com/alibaba-damo-academy/Lumos.', 'score': 10, 'issue_id': 4792, 'pub_date': '2025-07-11', 'pub_date_card': {'ru': '11 июля', 'en': 'July 11', 'zh': '7月11日'}, 'hash': 'd53fd2bb25db02a0', 'authors': ['Hangjie Yuan', 'Weihua Chen', 'Jun Cen', 'Hu Yu', 'Jingyun Liang', 'Shuning Chang', 'Zhihui Lin', 'Tao Feng', 'Pengwei Liu', 'Jiazheng Xing', 'Hao Luo', 'Jiasheng Tang', 'Fan Wang', 'Yi Yang'], 'affiliations': ['DAMO Academy, Alibaba Group', 'Hupan Lab', 'Tsinghua University', 'Zhejiang University'], 'pdf_title_img': 'assets/pdf/title_img/2507.08801.jpg', 'data': {'categories': ['#training', '#games', '#architecture', '#video', '#optimization', '#multimodal'], 'emoji': '🎬', 'ru': {'title': 'Эффективная генерация видео с помощью модифицированных языковых моделей', 'desc': 'Lumos-1 - это авторегрессионный генератор видео, использующий модифицированную архитектуру языковой модели (LLM). Он применяет технологии MM-RoPE и AR-DF для решения проблем пространственно-временной корреляции и дисбаланса покадровых потерь. Модель достигает конкурентоспособной производительности, используя меньше вычислительных ресурсов. Lumos-1 сохраняет архитектуру LLM с минимальными модификациями, что отличает его от существующих подходов к генерации видео.'}, 'en': {'title': 'Lumos-1: Efficient Video Generation with LLM Architecture', 'desc': "Lumos-1 is an innovative autoregressive video generator that enhances the traditional large language model (LLM) architecture to effectively handle video data. It introduces a new method called MM-RoPE, which improves the model's ability to understand spatiotemporal correlations while addressing issues of frame-wise loss imbalance. The model employs a token dependency strategy that respects both intra-frame and inter-frame relationships, ensuring coherent video generation. By utilizing efficient training techniques, Lumos-1 achieves competitive performance with fewer computational resources compared to existing models."}, 'zh': {'title': 'Lumos-1：高效自回归视频生成的新突破', 'desc': 'Lumos-1是一种自回归视频生成器，采用了经过修改的LLM架构，结合了MM-RoPE和AR-DF技术，以解决时空相关性和帧间损失不平衡的问题。该模型在保持LLM架构的基础上，利用3D RoPE来增强时空相关性，并提出了一种新的RoPE方案MM-RoPE，以支持多模态时空数据建模。Lumos-1还采用了一种令牌依赖策略，确保帧内双向性和帧间时间因果关系，从而解决了空间信息冗余导致的帧间损失不平衡问题。通过高效的训练技术，Lumos-1在仅使用48个GPU的情况下，达到了与现有模型相当的性能。'}}}, {'id': 'https://huggingface.co/papers/2507.08772', 'title': 'From One to More: Contextual Part Latents for 3D Generation', 'url': 'https://huggingface.co/papers/2507.08772', 'abstract': "A part-aware diffusion framework, CoPart, enhances 3D generation by decomposing objects into contextual parts, improving complexity handling, relationship modeling, and part-level conditioning.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in 3D generation have transitioned from multi-view 2D rendering approaches to 3D-native latent diffusion frameworks that exploit geometric priors in ground truth data. Despite progress, three key limitations persist: (1) Single-latent representations fail to capture complex multi-part geometries, causing detail degradation; (2) Holistic latent coding neglects part independence and interrelationships critical for compositional design; (3) Global conditioning mechanisms lack fine-grained controllability. Inspired by human 3D design workflows, we propose CoPart - a part-aware diffusion framework that decomposes 3D objects into contextual part latents for coherent multi-part generation. This paradigm offers three advantages: i) Reduces encoding complexity through part decomposition; ii) Enables explicit part relationship modeling; iii) Supports part-level conditioning. We further develop a mutual guidance strategy to fine-tune pre-trained diffusion models for joint part latent denoising, ensuring both geometric coherence and foundation model priors. To enable large-scale training, we construct Partverse - a novel 3D part dataset derived from Objaverse through automated mesh segmentation and human-verified annotations. Extensive experiments demonstrate CoPart's superior capabilities in part-level editing, articulated object generation, and scene composition with unprecedented controllability.", 'score': 5, 'issue_id': 4792, 'pub_date': '2025-07-11', 'pub_date_card': {'ru': '11 июля', 'en': 'July 11', 'zh': '7月11日'}, 'hash': '13e80f68dc4965b1', 'authors': ['Shaocong Dong', 'Lihe Ding', 'Xiao Chen', 'Yaokun Li', 'Yuxin Wang', 'Yucheng Wang', 'Qi Wang', 'Jaehyeok Kim', 'Chenjian Gao', 'Zhanpeng Huang', 'Zibin Wang', 'Tianfan Xue', 'Dan Xu'], 'affiliations': ['CUHK', 'HKUST', 'SenseTime Research', 'Shanghai AI Laboratory'], 'pdf_title_img': 'assets/pdf/title_img/2507.08772.jpg', 'data': {'categories': ['#games', '#3d', '#diffusion', '#dataset'], 'emoji': '🧩', 'ru': {'title': 'Разделяй и властвуй: новый подход к генерации 3D-объектов', 'desc': 'CoPart - это новая система для генерации трехмерных объектов, основанная на диффузионных моделях. Она разбивает объекты на отдельные части, что позволяет лучше моделировать сложные геометрические формы и взаимосвязи между компонентами. CoPart дает возможность более точного контроля над генерацией на уровне отдельных частей объекта. Для обучения системы был создан новый набор данных Partverse с аннотированными трехмерными моделями и их сегментацией на части.'}, 'en': {'title': 'Revolutionizing 3D Generation with Part-Aware Diffusion', 'desc': "The paper introduces CoPart, a part-aware diffusion framework designed to improve 3D object generation by breaking down objects into contextual parts. This approach addresses limitations in existing models, such as the inability to capture complex geometries and the lack of part independence in holistic representations. CoPart enhances the modeling of relationships between parts and allows for fine-grained control over part-level conditioning. Additionally, the authors present a new dataset, Partverse, to support large-scale training and demonstrate CoPart's effectiveness in tasks like part-level editing and scene composition."}, 'zh': {'title': '部件意识的3D生成新框架', 'desc': 'CoPart是一个关注部件的扩散框架，旨在通过将3D对象分解为上下文相关的部件来增强3D生成。该方法解决了传统方法在处理复杂多部件几何形状时的局限性，能够更好地建模部件之间的关系。通过部件分解，CoPart降低了编码复杂性，并支持精细的部件级条件控制。实验结果表明，CoPart在部件级编辑、关节对象生成和场景组合方面表现出色，具有前所未有的可控性。'}}}, {'id': 'https://huggingface.co/papers/2507.08794', 'title': 'One Token to Fool LLM-as-a-Judge', 'url': 'https://huggingface.co/papers/2507.08794', 'abstract': 'Generative reward models using LLMs are vulnerable to superficial manipulations but can be improved with data augmentation strategies.  \t\t\t\t\tAI-generated summary \t\t\t\t Generative reward models (also known as LLMs-as-judges), which use large language models (LLMs) to evaluate answer quality, are increasingly adopted in reinforcement learning with verifiable rewards (RLVR). They are often preferred over rigid rule-based metrics, especially for complex reasoning tasks involving free-form outputs. In this paradigm, an LLM is typically prompted to compare a candidate answer against a ground-truth reference and assign a binary reward indicating correctness. Despite the seeming simplicity of this comparison task, we find that generative reward models exhibit surprising vulnerabilities to superficial manipulations: non-word symbols (e.g., ":" or ".") or reasoning openers like "Thought process:" and "Let\'s solve this problem step by step." can often lead to false positive rewards. We demonstrate that this weakness is widespread across LLMs, datasets, and prompt formats, posing a serious threat for core algorithmic paradigms that rely on generative reward models, such as rejection sampling, preference optimization, and RLVR. To mitigate this issue, we introduce a simple yet effective data augmentation strategy and train a new generative reward model with substantially improved robustness. Our findings highlight the urgent need for more reliable LLM-based evaluation methods. We release our robust, general-domain reward model and its synthetic training data at https://huggingface.co/sarosavo/Master-RM and https://huggingface.co/datasets/sarosavo/Master-RM.', 'score': 4, 'issue_id': 4793, 'pub_date': '2025-07-11', 'pub_date_card': {'ru': '11 июля', 'en': 'July 11', 'zh': '7月11日'}, 'hash': 'c5951de5379e6612', 'authors': ['Yulai Zhao', 'Haolin Liu', 'Dian Yu', 'S. Y. Kung', 'Haitao Mi', 'Dong Yu'], 'affiliations': ['Princeton University', 'Tencent AI Lab', 'University of Virginia'], 'pdf_title_img': 'assets/pdf/title_img/2507.08794.jpg', 'data': {'categories': ['#training', '#rl', '#data', '#dataset', '#optimization', '#hallucinations', '#synthetic', '#rlhf'], 'emoji': '🛡️', 'ru': {'title': 'Укрепление генеративных моделей вознаграждения против поверхностных манипуляций', 'desc': 'Статья посвящена уязвимостям генеративных моделей вознаграждения, использующих большие языковые модели (LLM) для оценки качества ответов. Авторы обнаружили, что такие модели могут быть обмануты поверхностными манипуляциями, такими как добавление символов или фраз-заполнителей. Для решения этой проблемы предложена стратегия аугментации данных, позволяющая создать более надежную модель оценки. Исследование подчеркивает необходимость разработки более надежных методов оценки на основе LLM.'}, 'en': {'title': 'Strengthening LLMs: Combatting Superficial Manipulations in Reward Models', 'desc': 'This paper discusses the vulnerabilities of generative reward models, which use large language models (LLMs) to assess the quality of answers in reinforcement learning scenarios. The authors reveal that these models can be easily tricked by superficial changes in the input, such as adding non-word symbols or specific phrases, leading to incorrect evaluations. To address this issue, they propose a data augmentation strategy that enhances the robustness of the generative reward models against such manipulations. The study emphasizes the importance of developing more reliable evaluation methods for LLMs in reinforcement learning applications.'}, 'zh': {'title': '提升生成奖励模型的鲁棒性', 'desc': '生成奖励模型（LLMs作为评判者）在使用大型语言模型评估答案质量时，容易受到表面操控的影响。尽管这种比较任务看似简单，但我们发现生成奖励模型在面对非单词符号或推理开头词时，常常会产生错误的正向奖励。这种脆弱性在不同的LLM、数据集和提示格式中普遍存在，威胁到依赖生成奖励模型的核心算法范式。为了解决这个问题，我们提出了一种简单有效的数据增强策略，训练出一种具有显著改进鲁棒性的生成奖励模型。'}}}, {'id': 'https://huggingface.co/papers/2507.08771', 'title': 'BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with\n  Chunk-Level Activation Sparsity', 'url': 'https://huggingface.co/papers/2507.08771', 'abstract': 'To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while each token activates only a few parameters, these sparsely-activated architectures exhibit low chunk-level sparsity, indicating that the union of multiple consecutive tokens activates a large ratio of parameters. Such a sparsity pattern is unfriendly for acceleration under low-resource conditions (e.g., end-side devices) and incompatible with mainstream acceleration techniques (e.g., speculative decoding). To address these challenges, we introduce a novel MoE architecture, BlockFFN, as well as its efficient training and deployment techniques. Specifically, we use a router integrating ReLU activation and RMSNorm for differentiable and flexible routing. Next, to promote both token-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training objectives are designed, making BlockFFN more acceleration-friendly. Finally, we implement efficient acceleration kernels, combining activation sparsity and speculative decoding for the first time. The experimental results demonstrate the superior performance of BlockFFN over other MoE baselines, achieving over 80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67times speedup on real end-side devices than dense models. All codes and checkpoints are available publicly (https://github.com/thunlp/BlockFFN).', 'score': 2, 'issue_id': 4794, 'pub_date': '2025-07-11', 'pub_date_card': {'ru': '11 июля', 'en': 'July 11', 'zh': '7月11日'}, 'hash': '27bac3ede0d76a2a', 'authors': ['Chenyang Song', 'Weilin Zhao', 'Xu Han', 'Chaojun Xiao', 'Yingfa Chen', 'Yuxuan Li', 'Zhiyuan Liu', 'Maosong Sun'], 'affiliations': ['Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China'], 'pdf_title_img': 'assets/pdf/title_img/2507.08771.jpg', 'data': {'categories': ['#architecture', '#inference', '#optimization', '#low_resource', '#open_source', '#training'], 'emoji': '🚀', 'ru': {'title': 'BlockFFN: Эффективная архитектура смеси экспертов для ускорения больших языковых моделей', 'desc': 'Статья представляет новую архитектуру смеси экспертов (MoE) под названием BlockFFN для снижения вычислительной нагрузки больших языковых моделей (LLM). BlockFFN использует дифференцируемую и гибкую маршрутизацию, объединяющую активацию ReLU и RMSNorm. Авторы разработали цели обучения, учитывающие разреженность на уровне токенов и чанков, что делает модель более подходящей для ускорения. Экспериментальные результаты показывают превосходство BlockFFN над другими базовыми MoE, достигая более 80% разреженности на уровне токенов и 70% на уровне 8-токенных чанков.'}, 'en': {'title': 'BlockFFN: Efficient Sparsity for Faster Language Models', 'desc': 'This paper presents a new architecture called BlockFFN that improves the efficiency of mixture-of-experts (MoE) models by addressing issues with routing and sparsity. The authors introduce a router that uses ReLU activation and RMSNorm, allowing for more flexible and differentiable routing of parameters. They also propose training objectives that enhance both token-level and chunk-level sparsity, making the model more suitable for low-resource environments. Experimental results show that BlockFFN outperforms existing MoE models, achieving significant speedups on end-side devices while maintaining high levels of sparsity.'}, 'zh': {'title': '提升稀疏激活模型的性能与加速', 'desc': '为了减轻大型语言模型的计算负担，稀疏激活架构（如专家混合模型MoE）受到越来越多的关注。然而，传统MoE的非可微和不灵活的路由方式会影响模型性能。此外，虽然每个token只激活少量参数，但这些稀疏激活架构在块级稀疏性上表现较低，这使得在低资源条件下加速变得困难。为了解决这些问题，我们提出了一种新型的MoE架构BlockFFN，并设计了高效的训练和部署技术。'}}}, {'id': 'https://huggingface.co/papers/2507.07151', 'title': 'Robust Multimodal Large Language Models Against Modality Conflict', 'url': 'https://huggingface.co/papers/2507.07151', 'abstract': 'Investigation of modality conflict in multimodal large language models reveals its role in causing hallucinations, with reinforcement learning emerging as the most effective mitigation strategy.  \t\t\t\t\tAI-generated summary \t\t\t\t Despite the impressive capabilities of multimodal large language models (MLLMs) in vision-language tasks, they are prone to hallucinations in real-world scenarios. This paper investigates the hallucination phenomenon in MLLMs from the perspective of modality conflict. Unlike existing works focusing on the conflicts between model responses and inputs, we study the inherent conflicts in inputs from different modalities that place MLLMs in a dilemma and directly lead to hallucinations. We formally define the modality conflict and construct a dataset named Multimodal Modality Conflict (MMMC) to simulate this phenomenon in vision-language tasks. Three methods based on prompt engineering, supervised fine-tuning, and reinforcement learning are proposed to alleviate the hallucination caused by modality conflict. Extensive experiments are conducted on the MMMC dataset to analyze the merits and demerits of these methods. Our results show that the reinforcement learning method achieves the best performance in mitigating the hallucination under modality conflict, while the supervised fine-tuning method shows promising and stable performance. Our work sheds light on the unnoticed modality conflict that leads to hallucinations and provides more insights into the robustness of MLLMs.', 'score': 1, 'issue_id': 4792, 'pub_date': '2025-07-09', 'pub_date_card': {'ru': '9 июля', 'en': 'July 9', 'zh': '7月9日'}, 'hash': '2c4bd34981d368dd', 'authors': ['Zongmeng Zhang', 'Wengang Zhou', 'Jie Zhao', 'Houqiang Li'], 'affiliations': ['Department of Electronic Engineering and Information Science, University of Science and Technology of China', 'Huawei Technologies Co., Ltd.', 'School of Artificial Intelligence and Data Science, University of Science and Technology of China'], 'pdf_title_img': 'assets/pdf/title_img/2507.07151.jpg', 'data': {'categories': ['#training', '#interpretability', '#dataset', '#rl', '#hallucinations', '#multimodal'], 'emoji': '🤖', 'ru': {'title': 'Борьба с галлюцинациями в мультимодальных нейросетях', 'desc': 'Исследование посвящено проблеме галлюцинаций в мультимодальных больших языковых моделях (MLLM) из-за конфликта модальностей. Авторы создали датасет MMMC для симуляции этого явления в задачах компьютерного зрения и обработки естественного языка. Были предложены три метода для уменьшения галлюцинаций: инженерия промптов, обучение с учителем и обучение с подкреплением. Эксперименты показали, что обучение с подкреплением наиболее эффективно в снижении галлюцинаций при конфликте модальностей.'}, 'en': {'title': 'Tackling Hallucinations in MLLMs: The Power of Reinforcement Learning', 'desc': 'This paper explores how multimodal large language models (MLLMs) can experience hallucinations due to conflicts between different types of input data, known as modality conflict. The authors define modality conflict and create a dataset called Multimodal Modality Conflict (MMMC) to study this issue in vision-language tasks. They propose three strategies to reduce hallucinations: prompt engineering, supervised fine-tuning, and reinforcement learning. Among these, reinforcement learning is found to be the most effective method for addressing hallucinations caused by modality conflict, while supervised fine-tuning also shows reliable results.'}, 'zh': {'title': '揭示模态冲突，减轻幻觉的有效策略', 'desc': '这篇论文研究了多模态大型语言模型（MLLMs）中的模态冲突现象，发现它是导致幻觉的一个重要原因。与以往研究不同，本文关注的是来自不同模态的输入之间的内在冲突，这种冲突使得MLLMs面临困境并直接导致幻觉。我们正式定义了模态冲突，并构建了一个名为多模态模态冲突（MMMC）的数据集，以模拟这一现象。通过实验，我们发现基于强化学习的方法在减轻模态冲突引起的幻觉方面表现最佳，而监督微调方法则展现出良好且稳定的性能。'}}}];
        const articlesContainer = document.getElementById('articles-container');
        const sortDropdown = document.getElementById('sort-dropdown');
        const categoryFiltersContainer = document.getElementById('category-filters');
        const categoryFiltersLogicOptions = document.getElementById('category-options');
        const categoryToggle = document.getElementById('category-toggle');
        const clearCategoriesButton = document.getElementById('clear-categories');
        let selectedCategories = [];
        let selectedArticles = [];
        let sortBy = 'issue_id';     
        let showLimitHint = false; 
        let filterLogicIsAnd = false;

        function getUrlParameters() {
            const urlParams = new URLSearchParams(window.location.search);
            const categoriesParam = urlParams.get('cat');
            let categories = categoriesParam ? categoriesParam.split(',') : [];
            categories = categories.map(element => `#${element}`);
            return categories
        }

        function updateUrlWithCategories() {
            let cleanedCategories = selectedCategories.map(element => element.replace(/^#/, ''));
            const newUrl = cleanedCategories.length > 0 
                ? `${window.location.pathname}?cat=${cleanedCategories.join(',')}`
                : window.location.pathname;
            console.log("cleanedCategories", cleanedCategories)
            window.history.pushState({}, '', newUrl);
        }

        function loadSettings() {
            const themeToggle = document.getElementById('theme-toggle');
            const sortDropdown = document.getElementById('sort-dropdown');

            const isDarkMode = localStorage.getItem('darkMode') === 'true';
            let settingSortBy = localStorage.getItem('sort_by');
            filterLogicIsAnd = localStorage.getItem('filter_logic_is_and') === 'true';
            
            if (isDarkMode) {
                document.body.classList.remove('light-theme');
                document.body.classList.add('dark-theme');
                themeToggle.checked = true;
                const title = document.getElementById('doomgrad');
                title.innerHTML = "hf nightly";
                const titleSign = document.getElementById('doomgrad-icon');
                titleSign.classList.add('rotate');
            }

            if ((!settingSortBy) || (settingSortBy === 'null')) {
                settingSortBy = 'issue_id';
            }

            if (filterLogicIsAnd) {
                document.getElementById('filter-logic-and').checked = true;
            } else {
                document.getElementById('filter-logic-or').checked = true;
            }

            sortDropdown.value = settingSortBy;
            sortBy = settingSortBy;
        }

        document.getElementById('theme-toggle').addEventListener('change', toggleTheme);
        document.getElementById('filter-logic-and').addEventListener('change', () => {
            filterLogicIsAnd = true;
            localStorage.setItem('filter_logic_is_and', 'true');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });
        document.getElementById('filter-logic-or').addEventListener('change', () => {
            filterLogicIsAnd = false;
            localStorage.setItem('filter_logic_is_and', 'false');
            filterAndRenderArticles();
            updateSelectedArticlesTitle();
        });

        function getUniqueCategories(articles) {
            const categories = new Set();
            articles.forEach(article => {
                if (article.data && article.data.categories) {
                    article.data.categories.forEach(cat => categories.add(cat));
                }
            });
            let res = Array.from(categories);
            res.sort();
            return res;
        }

        function createCategoryButtons() {
            //const categories = getUniqueCategories(articlesData);
            const categories = ['#3d (2)', '#agents (1)', '#agi', '#alignment', '#architecture (3)', '#audio', '#benchmark (1)', '#cv (1)', '#data (1)', '#dataset (5)', '#diffusion (2)', '#ethics', '#games (3)', '#graphs', '#hallucinations (2)', '#healthcare', '#inference (1)', '#interpretability (1)', '#leakage', '#long_context', '#low_resource (1)', '#machine_translation', '#math', '#multilingual', '#multimodal (3)', '#open_source (2)', '#optimization (3)', '#plp', '#rag', '#reasoning (1)', '#rl (3)', '#rlhf (1)', '#robotics', '#science', '#security', '#small_models (1)', '#story_generation', '#survey', '#synthetic (1)', '#training (5)', '#transfer_learning', '#video (1)'];

            categories.forEach(category => {
                let catNameSplitted = category.split(/(\s+)/);
                let catName = catNameSplitted[0];
                const button = document.createElement('span');
                button.textContent = catName;
                button.className = 'category-button';
                if (catNameSplitted.length < 2) {
                    button.classList.add('inactive');
                };
                button.onclick = () => toggleCategory(catName, button);
                categoryFiltersContainer.appendChild(button);
            });
        }

        function toggleCategory(category, button) {
            const index = selectedCategories.indexOf(category);
            if (index === -1) {
                selectedCategories.push(category);
                button.classList.add('active');
            } else {
                selectedCategories.splice(index, 1);
                button.classList.remove('active');
            }         
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
            setFilterOptionsVisibility();
        }

        function saveCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify(selectedCategories));
        }

        function updateSelectedArticlesTitle() {
            if ((selectedArticles.length === articlesData.length) & (selectedCategories.length === 0)) {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]}`;
            } else {
                categoryToggle.textContent = `🏷️ ${filterLabel[currentLang]} (${formatArticlesTitle(selectedArticles.length, currentLang)})`;
            }
        }

        function cleanCategorySelection() {
            localStorage.setItem('selectedCategories', JSON.stringify('[]'));
        }

        function loadCategorySelection() {
            const urlCategories = getUrlParameters();
            if (urlCategories.length > 0) {
                selectedCategories = urlCategories;
                saveCategorySelection();
            } else {
                const savedCategories = localStorage.getItem('selectedCategories');
                if (savedCategories && savedCategories !== '"[]"') {
                    selectedCategories = JSON.parse(savedCategories);                    
                }
            }
            updateCategoryButtonStates();
        }

        function updateCategoryButtonStates() {
            const buttons = categoryFiltersContainer.getElementsByClassName('category-button');
            Array.from(buttons).forEach(button => {
                if (selectedCategories.includes(button.textContent)) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });
        }

        function filterAndRenderArticles() {
            console.log(selectedCategories);
            let filteredArticles; 

            if (filterLogicIsAnd) {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        selectedCategories.every(cat => article.data.categories.includes(cat))
                );
            } else {
                filteredArticles = selectedCategories.length === 0
                    ? articlesData
                    : articlesData.filter(article => 
                        article.data && article.data.categories && 
                        article.data.categories.some(cat => selectedCategories.includes(cat))
                    );            
            }

            console.log('filteredArticles', filteredArticles)

            selectedArticles = filteredArticles;
            sortArticles(selectedArticles);
        }

        function clearAllCategories() {
            selectedCategories = [];
            updateCategoryButtonStates();
            filterAndRenderArticles();
            saveCategorySelection();
            updateSelectedArticlesTitle();
            updateUrlWithCategories();
        }

        function renderArticles(articles) {
            if (articles.length > 50) {
                articles = articles.slice(0, 50);
                showLimitHint = true;
            } else {
                showLimitHint = false;
            }
            console.log(articles);
            articlesContainer.innerHTML = '';
            articles.forEach((item, index) => {
                if ("error" in item) {
                    console.log(`Omitting JSON. ${item["raw_data"]}`);
                    return;
                }
                
                let explanation = item["data"][currentLang]["desc"];
                let title = item["data"][currentLang]["title"];

                const cats = item["data"]["categories"].slice(0, 5).join(" ");
                
                let affiliations = ""
                if ('affiliations' in item) {
                    affiliations = item["affiliations"].slice(0, 10).join(", ");
                }

                let pdfImg = "https://hfday.ru/img/title_stub.png"
                if ('pdf_title_img' in item) {
                    pdfImg = 'https://hfday.ru/' + item['pdf_title_img']
                    
                }                

                const articleHTML = `
                    <article class='x${item["hash"]}'>
                        <div class="article-content" onclick="toggleAbstract(${index})">
                            <div class="background-digit">${index + 1}</div>
                            <div class="article-title-cont">
                                <div style="display:table-cell; vertical-align: middle;">
                                    <div class="article-title"><h2>${item['data']['emoji']} ${title}</h2></div>
                                </div>
                            </div>
                            <p class="meta">
                            🔺 ${item['score']}. ${item['title']}</p>
                            <p class="pub-date">${publishedLabel[currentLang]}${item['pub_date_card'][currentLang]}</p>
                            
                            <div class="article-pdf-title-img-cont"><img class="article-pdf-title-img" src="${pdfImg}"/></div>
                            
                            <div id="abstract-${index}" class="abstract">
                                <p>${explanation}</p>
                                <div id="toggle-${index}" class="abstract-toggle">...</div>
                            </div>

                            

                            <div class="links">
                                <a href="${item['url']}" target="_blank">${paperLabel[currentLang]}</a>
                            </div>

                            <div class="affiliations">${affiliations}</div>

                            <div class="tags">${cats}</div>
                        </div>
                    </article>
                `;
                articlesContainer.innerHTML += articleHTML;
            });
        }
        
        function sortArticles() {
            let sortedArticles = [...selectedArticles];
            if (sortBy === 'issue_id') {
                sortedArticles.sort((a, b) => b.issue_id - a.issue_id);
            } else if (sortBy === 'pub_date') {
                sortedArticles.sort((a, b) => b.pub_date.localeCompare(a.pub_date));
            } else {
                sortedArticles.sort((a, b) => b.score - a.score);
            }
            renderArticles(sortedArticles);
            localStorage.setItem('sort_by', sortBy);
        }
        
        sortDropdown.addEventListener('change', (event) => {
            sortBy = event.target.value;
            sortArticles(event.target.value);
        });

        categoryToggle.addEventListener('click', () => {
            categoryFiltersContainer.classList.toggle('expanded');
            setFilterOptionsVisibility();
        });

        clearCategoriesButton.addEventListener('click', () => {
            clearAllCategories();
            setFilterOptionsVisibility();
        });

        function setFilterOptionsVisibility() {
            if (selectedCategories.length > 0) {
                categoryFiltersLogicOptions.style.display = 'inline-block';
            } else {
                categoryFiltersLogicOptions.style.display = 'none';
            }
        } 
        
        function updateTimeDiffs() {
            const timeDiff = document.getElementById('timeDiff');
            timeDiff.innerHTML = '🔄 ' + getTimeDiff('2025-07-14 05:19',lang=currentLang);
        }
        function updateSortingOptions() {
            const sortingLabels = {
                ru: {
                    default: "рейтингу",
                    pub_date: "дате публикации",
                    issue_id: "добавлению на HF"
                },
                en: {
                    default: "rating",
                    pub_date: "publication date",
                    issue_id: "HF addition date"
                },
                zh: {
                    default: "评分",
                    pub_date: "发布日期",
                    issue_id: "HF上传日期"
                }
            };

            const dropdown = document.getElementById('sort-dropdown');
            const options = dropdown.options;

            for (let i = 0; i < options.length; i++) {
                const optionValue = options[i].value;
                console.log(sortingLabels)
                options[i].text = sortingLabels[currentLang][optionValue];
            }
        }
        function updateLocalization() {
            const titleDate = document.getElementById('title-date');
            const prevDate = document.getElementById('prev-date');
            const nextDate = document.getElementById('next-date');
            const topMonth = document.getElementById('top-month-label');
            const topDay = document.getElementById('top-day-label');
            const papersCount = document.getElementById('title-articles-count');
            const sortLabelText = document.getElementById('sort-label-text');
            titleDate.innerHTML = feedDate[currentLang];
            prevDate.innerHTML = feedDatePrev[currentLang];
            nextDate.innerHTML = feedDateNext[currentLang];
            papersCount.innerHTML = formatArticlesTitle(articlesData.length, currentLang);
            sortLabelText.innerHTML = sortLabel[currentLang];
            if (topMonth) {
                topMonth.innerHTML = topMonthLabel[currentLang];
            }  
            if (topDay) {
                topDay.innerHTML = topDayLabel[currentLang];
            }             
            updateSelectedArticlesTitle();
            updateSortingOptions();
        } 
        function hideNextLink(format) {
            if (format === 'monthly') {
                if (isCurrentMonth('2025-07-14 05:19')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            } else {            
                if (isToday('2025-07-14 05:19')) {
                    const element = document.getElementById('nav-next');
                    if (element) {    
                        element.style.display = 'none';
                    }
                }
            }
        }

        loadSettings();
        createCategoryButtons();
        loadCategorySelection();
        filterAndRenderArticles();
        updateSelectedArticlesTitle();
        updateTimeDiffs();
        hideNextLink('daily'); 
        initializeLanguageFlags();
        updateLocalization();
        setFilterOptionsVisibility();
    </script>
</body>
</html>
    