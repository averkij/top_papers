{
    "date": {
        "ru": "28 октября",
        "en": "October 28",
        "zh": "10月28日"
    },
    "time_utc": "2024-10-28 09:00",
    "weekday": 0,
    "issue_id": 319,
    "home_page_url": "https://huggingface.co/papers?date=2024-10-28",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2410.17856",
            "title": "ROCKET-1: Master Open-World Interaction with Visual-Temporal Context Prompting",
            "url": "https://huggingface.co/papers/2410.17856",
            "abstract": "Vision-language models (VLMs) have excelled in multimodal tasks, but adapting them to embodied decision-making in open-world environments presents challenges. A key issue is the difficulty in smoothly connecting individual entities in low-level observations with abstract concepts required for planning. A common approach to address this problem is through the use of hierarchical agents, where VLMs serve as high-level reasoners that break down tasks into executable sub-tasks, typically specified using language and imagined observations. However, language often fails to effectively convey spatial information, while generating future images with sufficient accuracy remains challenging. To address these limitations, we propose visual-temporal context prompting, a novel communication protocol between VLMs and policy models. This protocol leverages object segmentation from both past and present observations to guide policy-environment interactions. Using this approach, we train ROCKET-1, a low-level policy that predicts actions based on concatenated visual observations and segmentation masks, with real-time object tracking provided by SAM-2. Our method unlocks the full potential of VLMs visual-language reasoning abilities, enabling them to solve complex creative tasks, especially those heavily reliant on spatial understanding. Experiments in Minecraft demonstrate that our approach allows agents to accomplish previously unattainable tasks, highlighting the effectiveness of visual-temporal context prompting in embodied decision-making. Codes and demos will be available on the project page: https://craftjarvis.github.io/ROCKET-1.",
            "score": 48,
            "issue_id": 302,
            "pub_date": "2024-10-23",
            "pub_date_card": {
                "ru": "23 октября",
                "en": "October 23",
                "zh": "10月23日"
            },
            "hash": "0a477d46d035f1d4",
            "data": {
                "categories": [
                    "#agents",
                    "#cv",
                    "#multimodal",
                    "#rl"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Визуально-временной контекст открывает новые горизонты для VLM в воплощенном ИИ",
                    "desc": "Статья представляет новый подход к использованию визуально-языковых моделей (VLM) в задачах принятия решений в открытых средах. Авторы предлагают протокол визуально-временного контекстного промптинга для улучшения взаимодействия между VLM и моделями политик. Метод использует сегментацию объектов из прошлых и текущих наблюдений для управления взаимодействием политики и среды. Эксперименты в Minecraft показывают, что подход позволяет агентам решать ранее недостижимые задачи, особенно требующие пространственного понимания."
                },
                "en": {
                    "title": "Unlocking Spatial Reasoning in Decision-Making with VLMs",
                    "desc": "This paper addresses the challenges of using vision-language models (VLMs) for decision-making in dynamic environments. It highlights the difficulty of linking low-level visual data with high-level abstract concepts necessary for planning. The authors introduce a new method called visual-temporal context prompting, which enhances communication between VLMs and policy models by utilizing object segmentation from past and present observations. Their approach, implemented in the ROCKET-1 model, demonstrates improved performance in complex tasks that require spatial reasoning, as shown in experiments conducted in Minecraft."
                },
                "zh": {
                    "title": "视觉-时间上下文提示：提升具身决策能力的关键",
                    "desc": "视觉语言模型（VLMs）在多模态任务中表现出色，但在开放世界环境中进行具身决策时面临挑战。主要问题是如何将低级观察中的个体实体与规划所需的抽象概念顺利连接。为了解决这个问题，本文提出了一种视觉-时间上下文提示的新通信协议，利用过去和现在观察中的物体分割来指导策略与环境的交互。通过这种方法，我们训练了ROCKET-1，一个基于视觉观察和分割掩码预测动作的低级策略，展示了在复杂创意任务中，尤其是依赖空间理解的任务中的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.16048",
            "title": "Continuous Speech Synthesis using per-token Latent Diffusion",
            "url": "https://huggingface.co/papers/2410.16048",
            "abstract": "The success of autoregressive transformer models with discrete tokens has inspired quantization-based approaches for continuous modalities, though these often limit reconstruction quality. We therefore introduce SALAD, a per-token latent diffusion model for zero-shot text-to-speech, that operates on continuous representations. SALAD builds upon the recently proposed expressive diffusion head for image generation, and extends it to generate variable-length outputs. Our approach utilizes semantic tokens for providing contextual information and determining the stopping condition. We suggest three continuous variants for our method, extending popular discrete speech synthesis techniques. Additionally, we implement discrete baselines for each variant and conduct a comparative analysis of discrete versus continuous speech modeling techniques. Our results demonstrate that both continuous and discrete approaches are highly competent, and that SALAD achieves a superior intelligibility score while obtaining speech quality and speaker similarity on par with the ground-truth audio.",
            "score": 28,
            "issue_id": 308,
            "pub_date": "2024-10-21",
            "pub_date_card": {
                "ru": "21 октября",
                "en": "October 21",
                "zh": "10月21日"
            },
            "hash": "8d8228e9ec5fdf77",
            "data": {
                "categories": [
                    "#audio",
                    "#benchmark",
                    "#diffusion"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "SALAD: непрерывная диффузия для качественного синтеза речи",
                    "desc": "SALAD - это новая модель латентной диффузии для синтеза речи без предварительного обучения. Она работает с непрерывными представлениями, что позволяет достичь высокого качества реконструкции. Модель использует семантические токены для контекстной информации и определения условия остановки. Авторы сравнили непрерывный и дискретный подходы к моделированию речи, показав высокую эффективность обоих методов."
                },
                "en": {
                    "title": "SALAD: Revolutionizing Text-to-Speech with Continuous Representations",
                    "desc": "This paper presents SALAD, a novel per-token latent diffusion model designed for zero-shot text-to-speech synthesis using continuous representations. Unlike traditional methods that rely on discrete tokens, SALAD leverages semantic tokens to enhance contextual understanding and manage output length. The model builds on recent advancements in diffusion techniques for image generation, adapting them for speech synthesis. Comparative analysis shows that SALAD not only matches the quality of existing discrete methods but also excels in intelligibility, making it a promising approach for high-quality speech generation."
                },
                "zh": {
                    "title": "SALAD：提升文本到语音转换的新方法",
                    "desc": "本文介绍了一种名为SALAD的模型，它是一种基于每个标记的潜在扩散模型，旨在实现零-shot文本到语音转换。SALAD利用连续表示，克服了传统离散标记模型在重建质量上的限制。该模型借鉴了用于图像生成的扩散头，并扩展到生成可变长度的输出。我们的实验表明，SALAD在语音可懂度上表现优越，同时在语音质量和说话人相似性方面与真实音频相当。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19008",
            "title": "Teach Multimodal LLMs to Comprehend Electrocardiographic Images",
            "url": "https://huggingface.co/papers/2410.19008",
            "abstract": "The electrocardiogram (ECG) is an essential non-invasive diagnostic tool for assessing cardiac conditions. Existing automatic interpretation methods suffer from limited generalizability, focusing on a narrow range of cardiac conditions, and typically depend on raw physiological signals, which may not be readily available in resource-limited settings where only printed or digital ECG images are accessible. Recent advancements in multimodal large language models (MLLMs) present promising opportunities for addressing these challenges. However, the application of MLLMs to ECG image interpretation remains challenging due to the lack of instruction tuning datasets and well-established ECG image benchmarks for quantitative evaluation. To address these challenges, we introduce ECGInstruct, a comprehensive ECG image instruction tuning dataset of over one million samples, covering a wide range of ECG-related tasks from diverse data sources. Using ECGInstruct, we develop PULSE, an MLLM tailored for ECG image comprehension. In addition, we curate ECGBench, a new evaluation benchmark covering four key ECG image interpretation tasks across nine different datasets. Our experiments show that PULSE sets a new state-of-the-art, outperforming general MLLMs with an average accuracy improvement of 15% to 30%. This work highlights the potential of PULSE to enhance ECG interpretation in clinical practice.",
            "score": 22,
            "issue_id": 300,
            "pub_date": "2024-10-21",
            "pub_date_card": {
                "ru": "21 октября",
                "en": "October 21",
                "zh": "10月21日"
            },
            "hash": "85936de603f8cc7a",
            "data": {
                "categories": [
                    "#benchmark",
                    "#dataset",
                    "#medicine",
                    "#multimodal"
                ],
                "emoji": "❤️",
                "ru": {
                    "title": "PULSE: Революция в автоматическом анализе ЭКГ с помощью мультимодальных языковых моделей",
                    "desc": "Статья представляет новый подход к автоматической интерпретации ЭКГ с использованием мультимодальных больших языковых моделей (MLLM). Авторы создали ECGInstruct - набор данных из более чем миллиона образцов ЭКГ для обучения моделей, и разработали PULSE - специализированную MLLM для понимания изображений ЭКГ. Также был создан бенчмарк ECGBench для оценки моделей по четырем ключевым задачам интерпретации ЭКГ. Эксперименты показали, что PULSE превосходит общие MLLM на 15-30% по точности, демонстрируя потенциал для улучшения интерпретации ЭКГ в клинической практике."
                },
                "en": {
                    "title": "Revolutionizing ECG Interpretation with PULSE and ECGInstruct",
                    "desc": "This paper presents ECGInstruct, a large dataset designed for instruction tuning of multimodal large language models (MLLMs) specifically for interpreting ECG images. The authors introduce PULSE, an MLLM that leverages ECGInstruct to improve the understanding of ECG images, addressing the limitations of existing methods that rely on raw signals. Additionally, they create ECGBench, a benchmark for evaluating ECG image interpretation across various tasks and datasets. The results demonstrate that PULSE significantly enhances accuracy in ECG interpretation, showcasing its potential for clinical applications."
                },
                "zh": {
                    "title": "PULSE：提升心电图解读的新方法",
                    "desc": "心电图（ECG）是评估心脏状况的重要非侵入性诊断工具。现有的自动解读方法在通用性上存在局限，通常只关注少数心脏疾病，并依赖于生理信号，这在资源有限的环境中难以获取。为了解决这些问题，我们提出了ECGInstruct，这是一个包含超过一百万个样本的心电图图像指令调优数据集，涵盖了多种心电图相关任务。基于ECGInstruct，我们开发了PULSE，一个专为心电图图像理解而设计的大型多模态语言模型，实验结果显示PULSE在准确性上超越了通用模型，提升幅度达到15%到30%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19355",
            "title": "FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality",
            "url": "https://huggingface.co/papers/2410.19355",
            "abstract": "In this paper, we present \\textit{FasterCache}, a novel training-free strategy designed to accelerate the inference of video diffusion models with high-quality generation. By analyzing existing cache-based methods, we observe that directly reusing adjacent-step features degrades video quality due to the loss of subtle variations. We further perform a pioneering investigation of the acceleration potential of classifier-free guidance (CFG) and reveal significant redundancy between conditional and unconditional features within the same timestep. Capitalizing on these observations, we introduce FasterCache to substantially accelerate diffusion-based video generation. Our key contributions include a dynamic feature reuse strategy that preserves both feature distinction and temporal continuity, and CFG-Cache which optimizes the reuse of conditional and unconditional outputs to further enhance inference speed without compromising video quality. We empirically evaluate FasterCache on recent video diffusion models. Experimental results show that FasterCache can significantly accelerate video generation (\\eg 1.67times speedup on Vchitect-2.0) while keeping video quality comparable to the baseline, and consistently outperform existing methods in both inference speed and video quality.",
            "score": 20,
            "issue_id": 301,
            "pub_date": "2024-10-25",
            "pub_date_card": {
                "ru": "25 октября",
                "en": "October 25",
                "zh": "10月25日"
            },
            "hash": "2de0b0700140bc7e",
            "data": {
                "categories": [
                    "#diffusion",
                    "#inference",
                    "#video"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "FasterCache: Ускорение видео-диффузии без потери качества",
                    "desc": "FasterCache - это новая стратегия для ускорения вывода видео-моделей диффузии без дополнительного обучения. Метод анализирует существующие кэш-подходы и оптимизирует повторное использование условных и безусловных признаков. FasterCache включает динамическую стратегию переиспользования признаков и CFG-кэш для сохранения качества видео. Эксперименты показали значительное ускорение генерации видео (например, в 1,67 раза для Vchitect-2.0) при сохранении качества на уровне базовой модели."
                },
                "en": {
                    "title": "Accelerating Video Generation with FasterCache!",
                    "desc": "This paper introduces FasterCache, a new method to speed up video generation using diffusion models without needing extra training. The authors found that reusing features from adjacent steps can hurt video quality by losing important details. They also discovered that there is a lot of overlap between features used for conditional and unconditional generation, which can be optimized. FasterCache uses a smart way to reuse features that maintains quality and speed, achieving significant improvements in video generation speed while keeping the quality high."
                },
                "zh": {
                    "title": "FasterCache：加速视频生成的新策略",
                    "desc": "本文提出了一种名为FasterCache的新策略，旨在加速视频扩散模型的推理过程，同时保持高质量的生成效果。通过分析现有的基于缓存的方法，我们发现直接重用相邻步骤的特征会导致视频质量下降，因为细微变化会丢失。我们还首次研究了无分类器引导（CFG）的加速潜力，揭示了同一时间步内条件特征和无条件特征之间的显著冗余。FasterCache通过动态特征重用策略和优化条件与无条件输出的缓存，显著提高了扩散视频生成的速度，同时保持了视频质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19168",
            "title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark",
            "url": "https://huggingface.co/papers/2410.19168",
            "abstract": "The ability to comprehend audio--which includes speech, non-speech sounds, and music--is crucial for AI agents to interact effectively with the world. We present MMAU, a novel benchmark designed to evaluate multimodal audio understanding models on tasks requiring expert-level knowledge and complex reasoning. MMAU comprises 10k carefully curated audio clips paired with human-annotated natural language questions and answers spanning speech, environmental sounds, and music. It includes information extraction and reasoning questions, requiring models to demonstrate 27 distinct skills across unique and challenging tasks. Unlike existing benchmarks, MMAU emphasizes advanced perception and reasoning with domain-specific knowledge, challenging models to tackle tasks akin to those faced by experts. We assess 18 open-source and proprietary (Large) Audio-Language Models, demonstrating the significant challenges posed by MMAU. Notably, even the most advanced Gemini Pro v1.5 achieves only 52.97% accuracy, and the state-of-the-art open-source Qwen2-Audio achieves only 52.50%, highlighting considerable room for improvement. We believe MMAU will drive the audio and multimodal research community to develop more advanced audio understanding models capable of solving complex audio tasks.",
            "score": 19,
            "issue_id": 300,
            "pub_date": "2024-10-24",
            "pub_date_card": {
                "ru": "24 октября",
                "en": "October 24",
                "zh": "10月24日"
            },
            "hash": "7a747d9a9b0717cc",
            "data": {
                "categories": [
                    "#audio",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "🎵",
                "ru": {
                    "title": "MMAU: новый рубеж в понимании аудио для ИИ",
                    "desc": "MMAU - это новый эталонный тест для оценки моделей мультимодального понимания аудио. Он включает 10 тысяч аудиоклипов с вопросами и ответами, охватывающими речь, звуки окружающей среды и музыку. MMAU требует от моделей демонстрации 27 различных навыков и экспертных знаний в области аудио. Даже самые продвинутые модели, такие как Gemini Pro v1.5 и Qwen2-Audio, достигают точности лишь около 53%, что указывает на значительное пространство для улучшения в этой области."
                },
                "en": {
                    "title": "MMAU: Raising the Bar for Audio Understanding in AI",
                    "desc": "The paper introduces MMAU, a new benchmark for evaluating multimodal audio understanding models, which is essential for AI to interpret various audio types like speech and music. It consists of 10,000 audio clips with corresponding human-annotated questions and answers that require advanced reasoning and domain-specific knowledge. The benchmark tests models on 27 distinct skills through complex tasks, pushing the limits of current audio understanding capabilities. Results show that even leading models struggle, indicating a need for further advancements in the field."
                },
                "zh": {
                    "title": "MMAU：推动音频理解模型的进步",
                    "desc": "MMAU是一个新颖的基准，旨在评估多模态音频理解模型在需要专家级知识和复杂推理的任务上的表现。它包含1万个精心策划的音频片段，并配有人工标注的自然语言问题和答案，涵盖了语音、环境声音和音乐。MMAU要求模型展示27种不同的技能，处理独特且具有挑战性的任务，强调高级感知和推理能力。通过评估18个开源和专有的音频语言模型，结果显示即使是最先进的模型也面临显著挑战，表明在音频理解领域还有很大的改进空间。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.18558",
            "title": "Infinity-MM: Scaling Multimodal Performance with Large-Scale and High-Quality Instruction Data",
            "url": "https://huggingface.co/papers/2410.18558",
            "abstract": "Vision-Language Models (VLMs) have recently made significant progress, but the limited scale and quality of open-source instruction data hinder their performance compared to closed-source models. In this work, we address this limitation by introducing Infinity-MM, a large-scale multimodal instruction dataset with 40 million samples, enhanced through rigorous quality filtering and deduplication. We also propose a synthetic instruction generation method based on open-source VLMs, using detailed image annotations and diverse question generation. Using this data, we trained a 2-billion-parameter VLM, Aquila-VL-2B, achieving state-of-the-art (SOTA) performance for models of similar scale. This demonstrates that expanding instruction data and generating synthetic data can significantly improve the performance of open-source models.",
            "score": 17,
            "issue_id": 300,
            "pub_date": "2024-10-24",
            "pub_date_card": {
                "ru": "24 октября",
                "en": "October 24",
                "zh": "10月24日"
            },
            "hash": "18e760a965f56e6d",
            "data": {
                "categories": [
                    "#data",
                    "#dataset",
                    "#multimodal",
                    "#synthetic",
                    "#training"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Большие данные - ключ к улучшению открытых визуально-языковых моделей",
                    "desc": "Исследователи представили Infinity-MM - крупномасштабный мультимодальный набор данных с инструкциями, содержащий 40 миллионов образцов. Они также предложили метод генерации синтетических инструкций на основе открытых визуально-языковых моделей. Используя эти данные, они обучили 2-миллиардную модель Aquila-VL-2B, достигшую наилучших результатов среди моделей аналогичного масштаба. Это демонстрирует, что расширение обучающих данных и генерация синтетических данных могут значительно улучшить производительность открытых моделей."
                },
                "en": {
                    "title": "Unlocking VLM Potential with Infinity-MM Dataset",
                    "desc": "This paper presents Infinity-MM, a large-scale multimodal instruction dataset containing 40 million samples, aimed at improving the performance of Vision-Language Models (VLMs). The authors highlight the challenges faced by open-source VLMs due to limited instruction data quality and scale. They introduce a synthetic instruction generation method that leverages detailed image annotations and diverse question generation to enhance the dataset. Training their 2-billion-parameter model, Aquila-VL-2B, on this enriched dataset resulted in state-of-the-art performance, showcasing the potential of expanded and synthetic instruction data for open-source models."
                },
                "zh": {
                    "title": "扩展数据，提升开源模型性能！",
                    "desc": "本文介绍了一种新的多模态指令数据集Infinity-MM，包含4000万条样本，旨在提升开源视觉语言模型（VLM）的性能。通过严格的质量过滤和去重，该数据集的质量得到了显著提高。我们还提出了一种基于开源VLM的合成指令生成方法，利用详细的图像注释和多样的问题生成。最终，我们训练了一个具有20亿参数的VLM模型Aquila-VL-2B，达到了同规模模型的最新性能，证明了扩展指令数据和生成合成数据的重要性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19123",
            "title": "Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design",
            "url": "https://huggingface.co/papers/2410.19123",
            "abstract": "The proliferation of large language models (LLMs) has led to the adoption of Mixture-of-Experts (MoE) architectures that dynamically leverage specialized subnetworks for improved efficiency and performance. Despite their benefits, MoE models face significant challenges during inference, including inefficient memory management and suboptimal batching, due to misaligned design choices between the model architecture and the system policies. Furthermore, the conventional approach of training MoEs from scratch is increasingly prohibitive in terms of cost. In this paper, we propose a novel framework Read-ME that transforms pre-trained dense LLMs into smaller MoE models (in contrast to \"upcycling\" generalist MoEs), avoiding the high costs of ground-up training. Our approach employs activation sparsity to extract experts. To compose experts, we examine the widely-adopted layer-wise router design and show its redundancy, and thus we introduce the pre-gating router decoupled from the MoE backbone that facilitates system-friendly pre-computing and lookahead scheduling, enhancing expert-aware batching and caching. Our codesign therefore addresses critical gaps on both the algorithmic and system fronts, establishing a scalable and efficient alternative for LLM inference in resource-constrained settings. Read-ME outperforms other popular open-source dense models of similar scales, achieving improvements of up to 10.1% on MMLU, and improving mean end-to-end latency up to 6.1%. Codes are available at: https://github.com/VITA-Group/READ-ME.",
            "score": 15,
            "issue_id": 319,
            "pub_date": "2024-10-24",
            "pub_date_card": {
                "ru": "24 октября",
                "en": "October 24",
                "zh": "10月24日"
            },
            "hash": "94c8bf1991abe8b0",
            "data": {
                "categories": [
                    "#architecture",
                    "#inference",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное преобразование языковых моделей в MoE для оптимизации вывода",
                    "desc": "В этой статье представлен новый фреймворк Read-ME, который трансформирует предварительно обученные плотные языковые модели в меньшие модели Mixture-of-Experts (MoE). Авторы предлагают использовать разреженность активаций для извлечения экспертов и вводят концепцию предварительного роутинга, отделенного от основной структуры MoE. Этот подход позволяет эффективно предвычислять и планировать выполнение, улучшая пакетную обработку и кэширование с учетом экспертов. Read-ME превосходит другие популярные открытые плотные модели аналогичного масштаба, показывая улучшение до 10.1% на бенчмарке MMLU и снижение среднего времени выполнения до 6.1%."
                },
                "en": {
                    "title": "Transforming Dense Models into Efficient MoE with Read-ME",
                    "desc": "This paper introduces Read-ME, a framework that converts pre-trained dense large language models (LLMs) into smaller Mixture-of-Experts (MoE) models, which enhances efficiency and performance. The authors address challenges in MoE models during inference, such as memory management and batching issues, by proposing a new pre-gating router design that allows for better system integration. By utilizing activation sparsity, Read-ME effectively extracts and composes experts, leading to improved resource utilization. The results show that Read-ME significantly outperforms existing dense models, achieving notable gains in accuracy and reduced latency."
                },
                "zh": {
                    "title": "Read-ME：高效的混合专家模型转换框架",
                    "desc": "本文提出了一种新框架Read-ME，旨在将预训练的密集型大语言模型（LLMs）转化为更小的混合专家（MoE）模型，从而避免从头训练的高成本。我们利用激活稀疏性来提取专家，并提出了一种与MoE主干解耦的预门控路由器，以优化系统友好的预计算和前瞻调度。该方法解决了模型架构与系统策略之间的不匹配问题，提高了专家感知的批处理和缓存效率。实验结果表明，Read-ME在MMLU上比其他流行的开源密集模型提高了10.1%的性能，并将平均端到端延迟降低了6.1%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.18889",
            "title": "Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance",
            "url": "https://huggingface.co/papers/2410.18889",
            "abstract": "NLP benchmarks rely on standardized datasets for training and evaluating models and are crucial for advancing the field. Traditionally, expert annotations ensure high-quality labels; however, the cost of expert annotation does not scale well with the growing demand for larger datasets required by modern models. While crowd-sourcing provides a more scalable solution, it often comes at the expense of annotation precision and consistency. Recent advancements in large language models (LLMs) offer new opportunities to enhance the annotation process, particularly for detecting label errors in existing datasets. In this work, we consider the recent approach of LLM-as-a-judge, leveraging an ensemble of LLMs to flag potentially mislabeled examples. Through a case study of four datasets from the TRUE benchmark, covering different tasks and domains, we empirically analyze the labeling quality of existing datasets, and compare expert, crowd-sourced, and our LLM-based annotations in terms of agreement, label quality, and efficiency, demonstrating the strengths and limitations of each annotation method. Our findings reveal a substantial number of label errors, which, when corrected, induce a significant upward shift in reported model performance. This suggests that many of the LLMs so-called mistakes are due to label errors rather than genuine model failures. Additionally, we discuss the implications of mislabeled data and propose methods to mitigate them in training to improve model performance.",
            "score": 15,
            "issue_id": 315,
            "pub_date": "2024-10-24",
            "pub_date_card": {
                "ru": "24 октября",
                "en": "October 24",
                "zh": "10月24日"
            },
            "hash": "9deca7d98b0025ca",
            "data": {
                "categories": [
                    "#benchmark",
                    "#data",
                    "#dataset"
                ],
                "emoji": "🏷️",
                "ru": {
                    "title": "LLM как судья: повышение качества аннотаций в NLP-датасетах",
                    "desc": "Статья описывает использование больших языковых моделей (LLM) для повышения качества аннотаций в наборах данных для NLP-задач. Авторы сравнивают экспертные, краудсорсинговые и LLM-аннотации на примере четырех датасетов из бенчмарка TRUE. Исследование выявило значительное количество ошибок в существующих метках, исправление которых приводит к повышению оценок производительности моделей. Авторы также предлагают методы смягчения влияния неправильно размеченных данных при обучении моделей."
                },
                "en": {
                    "title": "Enhancing NLP Dataset Quality with LLMs",
                    "desc": "This paper addresses the challenges of labeling quality in NLP datasets, which are essential for training and evaluating machine learning models. It highlights the limitations of traditional expert annotations and the trade-offs of crowd-sourced labeling, which can compromise precision. The authors propose using large language models (LLMs) as a tool to identify mislabeled data, demonstrating their effectiveness through a case study on various datasets. The results indicate that correcting label errors can significantly enhance model performance, suggesting that many perceived model failures may actually stem from poor labeling rather than model deficiencies."
                },
                "zh": {
                    "title": "利用大型语言模型提升数据集标注质量",
                    "desc": "这篇论文探讨了自然语言处理（NLP）基准测试中数据集标注的重要性。传统上，专家标注确保了高质量的标签，但随着数据集需求的增加，专家标注的成本难以扩展。虽然众包提供了更具可扩展性的解决方案，但常常牺牲了标注的精确性和一致性。本文提出利用大型语言模型（LLM）作为评判者，通过多个LLM的组合来识别潜在的错误标签，从而提高标注质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19133",
            "title": "Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback",
            "url": "https://huggingface.co/papers/2410.19133",
            "abstract": "Learning from human feedback has enabled the alignment of language models (LMs) with human preferences. However, directly collecting human preferences can be expensive, time-consuming, and can have high variance. An appealing alternative is to distill preferences from LMs as a source of synthetic annotations as they are more consistent, cheaper, and scale better than human annotation; however, they are also prone to biases and errors. In this work, we introduce a routing framework that combines inputs from humans and LMs to achieve better annotation quality, while reducing the total cost of human annotation. The crux of our approach is to identify preference instances that will benefit from human annotations. We formulate this as an optimization problem: given a preference dataset and an evaluation metric, we train a performance prediction model to predict a reward model's performance on an arbitrary combination of human and LM annotations and employ a routing strategy that selects a combination that maximizes predicted performance. We train the performance prediction model on MultiPref, a new preference dataset with 10K instances paired with human and LM labels. We show that the selected hybrid mixture of LM and direct human preferences using our routing framework achieves better reward model performance compared to using either one exclusively. We simulate selective human preference collection on three other datasets and show that our method generalizes well to all three. We analyze features from the routing model to identify characteristics of instances that can benefit from human feedback, e.g., prompts with a moderate safety concern or moderate intent complexity. We release the dataset, annotation platform, and source code used in this study to foster more efficient and accurate preference collection in the future.",
            "score": 11,
            "issue_id": 301,
            "pub_date": "2024-10-24",
            "pub_date_card": {
                "ru": "24 октября",
                "en": "October 24",
                "zh": "10月24日"
            },
            "hash": "f6e6f7e5b9e467fe",
            "data": {
                "categories": [
                    "#data",
                    "#dataset",
                    "#optimization",
                    "#rlhf",
                    "#synthetic",
                    "#training"
                ],
                "emoji": "🔀",
                "ru": {
                    "title": "Оптимальное сочетание человеческого и машинного интеллекта для обучения ИИ",
                    "desc": "Статья представляет новый подход к обучению языковых моделей на основе предпочтений. Авторы предлагают гибридный метод, сочетающий аннотации от людей и языковых моделей для повышения качества обучения. Ключевая идея заключается в использовании модели маршрутизации, которая определяет, какие примеры требуют человеческой оценки. Эксперименты показывают, что такой подход позволяет добиться лучших результатов по сравнению с использованием только человеческих или только машинных аннотаций."
                },
                "en": {
                    "title": "Optimizing Language Model Annotations with Human and Synthetic Feedback",
                    "desc": "This paper presents a novel routing framework that enhances the quality of annotations for language models by intelligently combining human feedback and synthetic annotations from other language models. The authors address the challenges of collecting human preferences, which can be costly and inconsistent, by proposing a method that identifies which instances would benefit most from human input. They introduce a performance prediction model trained on a new dataset called MultiPref, which helps optimize the selection of human and LM annotations to maximize overall performance. The results demonstrate that this hybrid approach outperforms using either source of annotations alone, and the authors provide tools and datasets to support future research in this area."
                },
                "zh": {
                    "title": "结合人类与模型，提升注释质量！",
                    "desc": "本研究提出了一种新的路由框架，旨在结合人类和语言模型（LM）的输入，以提高注释质量并降低人类注释的总成本。我们通过优化问题来识别需要人类注释的偏好实例，并训练一个性能预测模型来预测奖励模型在不同人类和LM注释组合下的表现。实验结果表明，使用我们的路由框架选择的混合注释组合在奖励模型性能上优于单独使用人类或LM注释。我们还分析了路由模型的特征，以识别哪些实例更能从人类反馈中受益。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19730",
            "title": "Counting Ability of Large Language Models and Impact of Tokenization",
            "url": "https://huggingface.co/papers/2410.19730",
            "abstract": "Transformers, the backbone of modern large language models (LLMs), face inherent architectural limitations that impede their reasoning capabilities. Unlike recurrent networks, Transformers lack recurrent connections, confining them to constant-depth computation. This restriction places them in the complexity class TC^0, making them theoretically incapable of solving tasks that demand increasingly deep reasoning as input length grows. Counting, a fundamental component of many reasoning tasks, also requires reasoning depth to grow linearly to be performed inductively. While previous studies have established the upper limits of counting ability in Transformer-based expert models (i.e., models specifically trained for counting tasks), these findings do not directly extend to general-purpose LLMs due to differences in reasoning mechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning can help alleviate some of the architectural limitations of Transformers in counting tasks. However, little attention has been paid to the role of tokenization in these models. Unlike expert models that often use character-level tokenization, LLMs typically rely on byte-level (BPE) tokenizers, which fundamentally alters the way reasoning is processed. Our work investigates the impact of tokenization on the counting abilities of LLMs, uncovering substantial performance variations based on input tokenization differences. We provide both theoretical and experimental analyses, offering insights into how tokenization choices can undermine models' theoretical computability, thereby inspiring the design of new tokenization methods to enhance reasoning in LLMs.",
            "score": 10,
            "issue_id": 308,
            "pub_date": "2024-10-25",
            "pub_date_card": {
                "ru": "25 октября",
                "en": "October 25",
                "zh": "10月25日"
            },
            "hash": "103500d45390097e",
            "data": {
                "categories": [
                    "#architecture",
                    "#reasoning"
                ],
                "emoji": "🧮",
                "ru": {
                    "title": "Токенизация как ключ к улучшению рассуждений в больших языковых моделях",
                    "desc": "Это исследование посвящено влиянию токенизации на способность больших языковых моделей (LLM) к подсчету. Авторы утверждают, что архитектурные ограничения трансформеров затрудняют выполнение задач, требующих глубокого рассуждения. Они анализируют, как выбор метода токенизации может существенно повлиять на производительность моделей в задачах подсчета. Исследование предлагает теоретический и экспериментальный анализ, демонстрируя, как токенизация может подорвать теоретическую вычислимость моделей."
                },
                "en": {
                    "title": "Unlocking Reasoning: The Impact of Tokenization on LLMs",
                    "desc": "This paper explores the limitations of Transformers, which are widely used in large language models (LLMs), particularly in their reasoning capabilities. It highlights that Transformers, unlike recurrent networks, cannot perform deep reasoning due to their constant-depth computation structure. The study focuses on how tokenization methods, specifically byte-level tokenization, affect the counting abilities of LLMs, revealing significant performance differences. The authors propose that understanding these tokenization impacts can lead to better design choices that enhance reasoning in LLMs."
                },
                "zh": {
                    "title": "优化标记化以提升大型语言模型的推理能力",
                    "desc": "本文探讨了现代大型语言模型（LLMs）中变换器架构的局限性，特别是在推理能力方面。变换器缺乏递归连接，导致其计算深度受限，无法有效处理需要深度推理的任务。研究表明，计数任务的推理深度需要线性增长，而变换器在这方面存在理论上的不足。我们分析了输入的标记化方式如何影响LLMs的计数能力，并提出新的标记化方法以提升推理性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.19290",
            "title": "Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning",
            "url": "https://huggingface.co/papers/2410.19290",
            "abstract": "Recent studies have identified one aggravating factor of LLM hallucinations as the knowledge inconsistency between pre-training and fine-tuning, where unfamiliar fine-tuning data mislead the LLM to fabricate plausible but wrong outputs. In this paper, we propose a novel fine-tuning strategy called Prereq-Tune to address this knowledge inconsistency and reduce hallucinations. Fundamentally, Prereq-Tune disentangles the learning of skills and knowledge, so the model learns only the task skills without being impacted by the knowledge inconsistency. To achieve this, Prereq-Tune introduces an additional prerequisite learning stage to learn the necessary knowledge for SFT, allowing subsequent SFT to focus only on task skills. Prereq-Tune can also be combined with fictitious synthetic data to enhance the grounding of LLM outputs to their internal knowledge. Experiments show that Prereq-Tune outperforms existing baselines in improving LLM's factuality across short QA and long-form generation tasks. It also opens new possibilities for knowledge-controlled generation in LLMs. Our code is available at https://github.com/UCSB-NLP-Chang/Prereq_tune.git.",
            "score": 10,
            "issue_id": 302,
            "pub_date": "2024-10-25",
            "pub_date_card": {
                "ru": "25 октября",
                "en": "October 25",
                "zh": "10月25日"
            },
            "hash": "a11e3c6587db25fc",
            "data": {
                "categories": [
                    "#alignment",
                    "#hallucinations",
                    "#synthetic",
                    "#training"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Prereq-Tune: Уменьшение галлюцинаций в языковых моделях путем разделения обучения навыкам и знаниям",
                    "desc": "В статье представлена новая стратегия дообучения языковых моделей под названием Prereq-Tune, направленная на уменьшение галлюцинаций. Метод разделяет обучение навыкам и знаниям, вводя дополнительный этап предварительного обучения необходимым знаниям перед основным дообучением. Prereq-Tune также может использоваться с синтетическими данными для улучшения привязки выходных данных модели к ее внутренним знаниям. Эксперименты показывают, что Prereq-Tune превосходит существующие базовые методы в повышении фактической точности языковых моделей при решении задач вопросно-ответных систем и генерации длинных текстов."
                },
                "en": {
                    "title": "Enhancing LLM Factuality with Prereq-Tune",
                    "desc": "This paper addresses the issue of hallucinations in large language models (LLMs) caused by inconsistencies between the knowledge learned during pre-training and fine-tuning. The authors introduce a new fine-tuning method called Prereq-Tune, which separates the learning of task skills from knowledge acquisition. By adding a prerequisite learning stage, the model can first acquire necessary knowledge before focusing on specific task skills during supervised fine-tuning (SFT). The results demonstrate that Prereq-Tune significantly improves the factual accuracy of LLM outputs in various tasks, paving the way for better knowledge-controlled generation."
                },
                "zh": {
                    "title": "解决LLM幻觉的知识不一致性",
                    "desc": "最近的研究发现，LLM（大型语言模型）幻觉的一个加重因素是预训练和微调之间的知识不一致，这导致模型在面对不熟悉的微调数据时产生错误的输出。为了解决这个问题，本文提出了一种新的微调策略，称为Prereq-Tune，旨在减少这种知识不一致性。Prereq-Tune通过引入额外的先决学习阶段，使模型在微调之前先学习必要的知识，从而专注于任务技能的学习。实验表明，Prereq-Tune在提高LLM的事实性方面优于现有的基线方法，并为知识控制生成开辟了新的可能性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.16090",
            "title": "Analysing the Residual Stream of Language Models Under Knowledge Conflicts",
            "url": "https://huggingface.co/papers/2410.16090",
            "abstract": "Large language models (LLMs) can store a significant amount of factual knowledge in their parameters. However, their parametric knowledge may conflict with the information provided in the context. Such conflicts can lead to undesirable model behaviour, such as reliance on outdated or incorrect information. In this work, we investigate whether LLMs can identify knowledge conflicts and whether it is possible to know which source of knowledge the model will rely on by analysing the residual stream of the LLM. Through probing tasks, we find that LLMs can internally register the signal of knowledge conflict in the residual stream, which can be accurately detected by probing the intermediate model activations. This allows us to detect conflicts within the residual stream before generating the answers without modifying the input or model parameters. Moreover, we find that the residual stream shows significantly different patterns when the model relies on contextual knowledge versus parametric knowledge to resolve conflicts. This pattern can be employed to estimate the behaviour of LLMs when conflict happens and prevent unexpected answers before producing the answers. Our analysis offers insights into how LLMs internally manage knowledge conflicts and provides a foundation for developing methods to control the knowledge selection processes.",
            "score": 6,
            "issue_id": 316,
            "pub_date": "2024-10-21",
            "pub_date_card": {
                "ru": "21 октября",
                "en": "October 21",
                "zh": "10月21日"
            },
            "hash": "cddfaa4779e86373",
            "data": {
                "categories": [
                    "#alignment",
                    "#hallucinations",
                    "#interpretability"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Распознавание конфликтов знаний в больших языковых моделях",
                    "desc": "Это исследование посвящено способности больших языковых моделей (LLM) распознавать конфликты между знаниями, хранящимися в их параметрах, и информацией из контекста. Ученые обнаружили, что LLM могут внутренне регистрировать сигнал о конфликте знаний в остаточном потоке, который можно точно обнаружить путем анализа промежуточных активаций модели. Кроме того, было выявлено, что остаточный поток показывает значительно различные паттерны, когда модель опирается на контекстуальные знания по сравнению с параметрическими знаниями для разрешения конфликтов. Эти результаты предоставляют основу для разработки методов контроля процессов выбора знаний в LLM."
                },
                "en": {
                    "title": "Understanding and Managing Knowledge Conflicts in LLMs",
                    "desc": "This paper explores how large language models (LLMs) manage conflicting information between their stored knowledge and the context they are given. It reveals that LLMs can detect these knowledge conflicts by analyzing the residual stream, which is the internal signal that reflects the model's processing. By using probing tasks, the authors demonstrate that different patterns in the residual stream indicate whether the model is relying on its internal knowledge or the contextual information. This understanding can help in predicting model behavior during conflicts and in developing strategies to improve knowledge selection in LLMs."
                },
                "zh": {
                    "title": "识别知识冲突，优化模型行为",
                    "desc": "大型语言模型（LLMs）能够在其参数中存储大量的事实知识。然而，这些参数知识可能与上下文中提供的信息发生冲突。这种冲突可能导致模型产生不理想的行为，例如依赖过时或不正确的信息。我们的研究表明，LLMs能够识别知识冲突，并通过分析残差流来了解模型将依赖于哪个知识来源，从而在生成答案之前检测到冲突。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.18912",
            "title": "Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling",
            "url": "https://huggingface.co/papers/2410.18912",
            "abstract": "Videos of robots interacting with objects encode rich information about the objects' dynamics. However, existing video prediction approaches typically do not explicitly account for the 3D information from videos, such as robot actions and objects' 3D states, limiting their use in real-world robotic applications. In this work, we introduce a framework to learn object dynamics directly from multi-view RGB videos by explicitly considering the robot's action trajectories and their effects on scene dynamics. We utilize the 3D Gaussian representation of 3D Gaussian Splatting (3DGS) to train a particle-based dynamics model using Graph Neural Networks. This model operates on sparse control particles downsampled from the densely tracked 3D Gaussian reconstructions. By learning the neural dynamics model on offline robot interaction data, our method can predict object motions under varying initial configurations and unseen robot actions. The 3D transformations of Gaussians can be interpolated from the motions of control particles, enabling the rendering of predicted future object states and achieving action-conditioned video prediction. The dynamics model can also be applied to model-based planning frameworks for object manipulation tasks. We conduct experiments on various kinds of deformable materials, including ropes, clothes, and stuffed animals, demonstrating our framework's ability to model complex shapes and dynamics. Our project page is available at https://gs-dynamics.github.io.",
            "score": 6,
            "issue_id": 313,
            "pub_date": "2024-10-24",
            "pub_date_card": {
                "ru": "24 октября",
                "en": "October 24",
                "zh": "10月24日"
            },
            "hash": "2fd905b5809fea40",
            "data": {
                "categories": [
                    "#3d",
                    "#cv",
                    "#robots"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "3D-динамика объектов из видео для управления роботами",
                    "desc": "Эта статья представляет новый подход к обучению динамики объектов непосредственно из многоракурсных RGB-видео, учитывая траектории действий робота. Авторы используют 3D гауссово представление для обучения модели динамики на основе частиц с применением графовых нейронных сетей. Модель обучается на офлайн-данных взаимодействия робота и может предсказывать движения объектов при различных начальных конфигурациях и невиданных ранее действиях робота. Этот метод позволяет осуществлять видеопрогнозирование с учетом действий и может применяться для планирования задач манипуляции объектами."
                },
                "en": {
                    "title": "Predicting Object Dynamics in Robot Interactions Using 3D Video Analysis",
                    "desc": "This paper presents a new framework for predicting how objects move when robots interact with them, using videos from multiple angles. It focuses on understanding the 3D aspects of these interactions, such as the robot's actions and the 3D states of the objects. The authors employ a particle-based dynamics model trained with Graph Neural Networks, which allows for accurate predictions of object motions based on robot actions. Their approach is tested on various deformable materials, showing its effectiveness in modeling complex dynamics and shapes in real-world scenarios."
                },
                "zh": {
                    "title": "通过3D动态建模提升机器人交互能力",
                    "desc": "本研究提出了一种新框架，通过多视角RGB视频直接学习物体的动态，特别关注机器人动作轨迹及其对场景动态的影响。我们利用3D高斯表示法和图神经网络训练基于粒子的动态模型，从稀疏控制粒子中提取信息。该模型能够在不同初始配置和未见过的机器人动作下预测物体运动，并实现基于动作的未来状态渲染。实验表明，我们的方法在建模复杂形状和动态方面表现出色，适用于各种可变形材料的操作任务。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.17655",
            "title": "Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions",
            "url": "https://huggingface.co/papers/2410.17655",
            "abstract": "Bias assessment of news sources is paramount for professionals, organizations, and researchers who rely on truthful evidence for information gathering and reporting. While certain bias indicators are discernible from content analysis, descriptors like political bias and fake news pose greater challenges. In this paper, we propose an extension to a recently presented news media reliability estimation method that focuses on modeling outlets and their longitudinal web interactions. Concretely, we assess the classification performance of four reinforcement learning strategies on a large news media hyperlink graph. Our experiments, targeting two challenging bias descriptors, factual reporting and political bias, showed a significant performance improvement at the source media level. Additionally, we validate our methods on the CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in both, F1-score and the official MAE metric. Furthermore, we contribute by releasing the largest annotated dataset of news source media, categorized with factual reporting and political bias labels. Our findings suggest that profiling news media sources based on their hyperlink interactions over time is feasible, offering a bird's-eye view of evolving media landscapes.",
            "score": 5,
            "issue_id": 316,
            "pub_date": "2024-10-23",
            "pub_date_card": {
                "ru": "23 октября",
                "en": "October 23",
                "zh": "10月23日"
            },
            "hash": "0fce9f46807b7f5b",
            "data": {
                "categories": [
                    "#benchmark",
                    "#data",
                    "#dataset",
                    "#rl"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Анализ новостных источников с помощью ИИ: новый взгляд на медиаландшафт",
                    "desc": "В статье представлен метод оценки надежности новостных источников с использованием обучения с подкреплением. Авторы анализируют гиперссылки между новостными сайтами для определения уровня фактической достоверности и политической предвзятости. Эксперименты показали значительное улучшение классификации по сравнению с существующими методами. Также был создан крупнейший аннотированный датасет новостных источников с метками фактической достоверности и политической предвзятости."
                },
                "en": {
                    "title": "Enhancing News Bias Detection through Web Interaction Analysis",
                    "desc": "This paper focuses on assessing bias in news sources, which is crucial for accurate information gathering. It introduces an enhanced method for estimating the reliability of news media by analyzing their web interactions over time. The authors evaluate four reinforcement learning strategies on a large graph of news media hyperlinks, achieving improved classification of factual reporting and political bias. They also provide a new, extensive dataset of news sources labeled by bias, demonstrating that tracking hyperlink interactions can effectively profile media bias."
                },
                "zh": {
                    "title": "基于超链接互动的新闻媒体偏见评估",
                    "desc": "本论文探讨了新闻来源的偏见评估，强调了对真实信息收集和报告的重要性。我们提出了一种扩展的新闻媒体可靠性估计方法，专注于建模媒体及其长期的网络互动。通过对大型新闻媒体超链接图的实验，我们评估了四种强化学习策略的分类性能，特别针对事实报道和政治偏见这两个挑战性偏见指标。我们的研究结果表明，基于超链接互动的新闻媒体源分析是可行的，能够提供对媒体环境演变的全局视角。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.16270",
            "title": "Reflection-Bench: probing AI intelligence with reflection",
            "url": "https://huggingface.co/papers/2410.16270",
            "abstract": "The ability to adapt beliefs or behaviors in response to unexpected outcomes, reflection, is fundamental to intelligent systems' interaction with the world. From a cognitive science perspective, this serves as a core principle of intelligence applicable to both human and AI systems. To address the debate on the intelligence of large language models (LLMs), we propose Reflection-Bench, a comprehensive benchmark comprising 7 tasks spanning core cognitive functions crucial for reflection, including perception, memory, belief updating, decision-making, prediction, counterfactual thinking, and meta-reflection. We evaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude 3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory reflection ability. We discuss the underlying causes of these results and suggest potential avenues for future research. In conclusion, Reflection-Bench offers both evaluation tools and inspiration for developing AI capable of reliably interacting with the environment. Our data and code are available at https://github.com/YabYum/ReflectionBench.",
            "score": 5,
            "issue_id": 310,
            "pub_date": "2024-10-21",
            "pub_date_card": {
                "ru": "21 октября",
                "en": "October 21",
                "zh": "10月21日"
            },
            "hash": "2e170064cac1a857",
            "data": {
                "categories": [
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "🤔",
                "ru": {
                    "title": "Reflection-Bench: измеряя способность ИИ к самоанализу",
                    "desc": "Исследователи представили Reflection-Bench - комплексный набор тестов для оценки способности больших языковых моделей (LLM) к рефлексии. Бенчмарк включает 7 заданий, охватывающих ключевые когнитивные функции, такие как восприятие, память, обновление убеждений и метарефлексия. Результаты тестирования 13 ведущих LLM показали, что текущие модели все еще не обладают удовлетворительной способностью к рефлексии. Авторы обсуждают причины полученных результатов и предлагают направления для дальнейших исследований в этой области."
                },
                "en": {
                    "title": "Enhancing AI Reflection: Introducing Reflection-Bench",
                    "desc": "This paper introduces Reflection-Bench, a new benchmark designed to evaluate the reflection capabilities of large language models (LLMs). Reflection is a key cognitive function that allows intelligent systems to adapt their beliefs and behaviors based on unexpected outcomes. The benchmark includes seven tasks that assess various cognitive functions such as memory, decision-making, and counterfactual thinking. The evaluation of 13 leading LLMs reveals that they currently struggle with reflection, highlighting areas for improvement and future research in AI development."
                },
                "zh": {
                    "title": "反思能力：智能系统的核心",
                    "desc": "本文提出了一个名为Reflection-Bench的基准测试，旨在评估大型语言模型（LLMs）在反思能力方面的表现。反思能力是智能系统与世界互动的核心原则，涉及感知、记忆、信念更新、决策、预测、反事实思维和元反思等认知功能。通过对13个知名LLM的评估，结果显示当前的LLM在反思能力上仍然不足。我们讨论了这些结果的原因，并提出了未来研究的潜在方向。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2410.18076",
            "title": "Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration",
            "url": "https://huggingface.co/papers/2410.18076",
            "abstract": "Unsupervised pretraining has been transformative in many supervised domains. However, applying such ideas to reinforcement learning (RL) presents a unique challenge in that fine-tuning does not involve mimicking task-specific data, but rather exploring and locating the solution through iterative self-improvement. In this work, we study how unlabeled prior trajectory data can be leveraged to learn efficient exploration strategies. While prior data can be used to pretrain a set of low-level skills, or as additional off-policy data for online RL, it has been unclear how to combine these ideas effectively for online exploration. Our method SUPE (Skills from Unlabeled Prior data for Exploration) demonstrates that a careful combination of these ideas compounds their benefits. Our method first extracts low-level skills using a variational autoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an optimistic reward model, transforming prior data into high-level, task-relevant examples. Finally, SUPE uses these transformed examples as additional off-policy data for online RL to learn a high-level policy that composes pretrained low-level skills to explore efficiently. We empirically show that SUPE reliably outperforms prior strategies, successfully solving a suite of long-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.",
            "score": 4,
            "issue_id": 300,
            "pub_date": "2024-10-23",
            "pub_date_card": {
                "ru": "23 октября",
                "en": "October 23",
                "zh": "10月23日"
            },
            "hash": "4c364a800e98d62f",
            "data": {
                "categories": [
                    "#rl",
                    "#rlhf"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Эффективное исследование в RL с помощью непомеченных данных",
                    "desc": "Эта статья представляет метод SUPE для эффективного исследования в обучении с подкреплением, используя непомеченные предварительные данные траекторий. SUPE сначала извлекает низкоуровневые навыки с помощью вариационного автоэнкодера (VAE), затем псевдо-размечает непомеченные траектории с использованием оптимистичной модели вознаграждения. Затем метод использует эти преобразованные примеры как дополнительные офф-полиси данные для онлайн-обучения с подкреплением. SUPE превосходит предыдущие стратегии в решении задач с долгосрочным горизонтом и редкими вознаграждениями."
                },
                "en": {
                    "title": "Unlocking Exploration with Unlabeled Data in RL",
                    "desc": "This paper introduces a method called SUPE, which stands for Skills from Unlabeled Prior data for Exploration, aimed at improving exploration strategies in reinforcement learning (RL). The approach utilizes unlabeled trajectory data to pretrain low-level skills using a variational autoencoder (VAE) and then pseudo-labels this data with an optimistic reward model. By transforming prior data into high-level, task-relevant examples, SUPE enhances the learning process in online RL by providing additional off-policy data. The results demonstrate that SUPE outperforms existing methods in solving complex tasks with long horizons and sparse rewards."
                },
                "zh": {
                    "title": "利用未标记数据提升强化学习探索效率",
                    "desc": "这篇论文探讨了如何利用未标记的先前轨迹数据来学习有效的探索策略，特别是在强化学习（RL）中。研究者提出了一种名为SUPE的方法，通过变分自编码器（VAE）提取低级技能，并使用乐观奖励模型对未标记的轨迹进行伪标签化，从而将先前数据转化为高层次的任务相关示例。SUPE将这些转化后的示例作为额外的离线数据，用于在线强化学习，以学习一个高层次的策略，从而有效地组合预训练的低级技能进行探索。实验结果表明，SUPE在解决一系列长时间跨度和稀疏奖励的任务中，表现优于之前的策略。"
                }
            }
        }
    ],
    "link_prev": "2024-10-25.html",
    "link_next": "2024-10-29.html",
    "link_month": "2024-10.html",
    "short_date_prev": {
        "ru": "25.10",
        "en": "10/25",
        "zh": "10月25日"
    },
    "short_date_next": {
        "ru": "29.10",
        "en": "10/29",
        "zh": "10月29日"
    },
    "categories": {
        "#dataset": 5,
        "#data": 4,
        "#benchmark": 6,
        "#agents": 1,
        "#cv": 2,
        "#rl": 3,
        "#rlhf": 2,
        "#rag": 0,
        "#plp": 0,
        "#inference": 2,
        "#3d": 1,
        "#audio": 2,
        "#video": 1,
        "#multimodal": 4,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 2,
        "#medicine": 1,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 2,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#edge_computing": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 2,
        "#long_context": 0,
        "#synthetic": 3,
        "#translation": 0,
        "#robots": 0
    }
}