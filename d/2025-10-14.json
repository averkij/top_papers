{
    "date": {
        "ru": "14 октября",
        "en": "October 14",
        "zh": "10月14日"
    },
    "time_utc": "2025-10-14 02:19",
    "weekday": 1,
    "issue_id": 6398,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2510.08886",
            "title": "FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark\n  for Evaluating LLMs",
            "url": "https://huggingface.co/papers/2510.08886",
            "abstract": "FinAuditing is a benchmark for evaluating LLMs on structured financial auditing tasks, revealing their limitations in handling taxonomy-driven, hierarchical financial documents.  \t\t\t\t\tAI-generated summary \t\t\t\t The complexity of the Generally Accepted Accounting Principles (GAAP) and the hierarchical structure of eXtensible Business Reporting Language (XBRL) filings make financial auditing increasingly difficult to automate and verify. While large language models (LLMs) have demonstrated strong capabilities in unstructured text understanding, their ability to reason over structured, interdependent, and taxonomy-driven financial documents remains largely unexplored. To fill this gap, we introduce FinAuditing, the first taxonomy-aligned, structure-aware, multi-document benchmark for evaluating LLMs on financial auditing tasks. Built from real US-GAAP-compliant XBRL filings, FinAuditing defines three complementary subtasks, FinSM for semantic consistency, FinRE for relational consistency, and FinMR for numerical consistency, each targeting a distinct aspect of structured auditing reasoning. We further propose a unified evaluation framework integrating retrieval, classification, and reasoning metrics across these subtasks. Extensive zero-shot experiments on 13 state-of-the-art LLMs reveal that current models perform inconsistently across semantic, relational, and mathematical dimensions, with accuracy drops of up to 60-90% when reasoning over hierarchical multi-document structures. Our findings expose the systematic limitations of modern LLMs in taxonomy-grounded financial reasoning and establish FinAuditing as a foundation for developing trustworthy, structure-aware, and regulation-aligned financial intelligence systems. The benchmark dataset is available at Hugging Face.",
            "score": 7,
            "issue_id": 6398,
            "pub_date": "2025-10-10",
            "pub_date_card": {
                "ru": "10 октября",
                "en": "October 10",
                "zh": "10月10日"
            },
            "hash": "af8af45f11c7cfc5",
            "authors": [
                "Yan Wang",
                "Keyi Wang",
                "Shanshan Yang",
                "Jaisal Patel",
                "Jeff Zhao",
                "Fengran Mo",
                "Xueqing Peng",
                "Lingfei Qian",
                "Jimin Huang",
                "Guojun Xiong",
                "Xiao-Yang Liu",
                "Jian-Yun Nie"
            ],
            "affiliations": [
                "Columbia University USA",
                "The Fin AI USA",
                "University of Montreal Canada"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.08886.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#dataset",
                    "#survey",
                    "#benchmark"
                ],
                "emoji": "📊",
                "ru": {
                    "title": "LLM провалили экзамен по финансовому аудиту",
                    "desc": "Исследователи создали бенчмарк FinAuditing для проверки способности больших языковых моделей работать со структурированными финансовыми документами в формате XBRL. Бенчмарк включает три задачи: проверку семантической, реляционной и численной согласованности данных в иерархических документах, составленных по стандартам US-GAAP. Тестирование 13 современных LLM показало катастрофические результаты — точность падала на 60-90% при работе с многодокументными иерархическими структурами. Результаты выявили системные ограничения AI в понимании таксономий и структурированного финансового анализа, что критично для создания надёжных систем автоматизации аудита."
                },
                "en": {
                    "title": "FinAuditing: Bridging the Gap in Financial Reasoning for LLMs",
                    "desc": "FinAuditing is a new benchmark designed to assess large language models (LLMs) on structured financial auditing tasks, particularly focusing on the challenges posed by hierarchical financial documents. It highlights the difficulties LLMs face in reasoning over complex, taxonomy-driven structures like those found in Generally Accepted Accounting Principles (GAAP) and eXtensible Business Reporting Language (XBRL) filings. The benchmark includes three specific subtasks: FinSM for semantic consistency, FinRE for relational consistency, and FinMR for numerical consistency, each addressing different aspects of financial auditing. Results from testing 13 advanced LLMs show significant performance drops, revealing their limitations in handling structured financial reasoning, thus paving the way for improved financial intelligence systems."
                },
                "zh": {
                    "title": "FinAuditing：揭示LLMs在财务审计中的局限性",
                    "desc": "FinAuditing是一个用于评估大型语言模型（LLMs）在结构化财务审计任务中的基准测试。该基准揭示了LLMs在处理基于分类法的层次财务文档时的局限性。通过定义三个互补的子任务，FinSM、FinRE和FinMR，FinAuditing专注于语义一致性、关系一致性和数值一致性。我们的实验表明，当前模型在处理层次多文档结构时，准确率下降高达60-90%，显示出现代LLMs在财务推理方面的系统性局限性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.10670",
            "title": "AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning\n  in 4D Scenes",
            "url": "https://huggingface.co/papers/2510.10670",
            "abstract": "A two-stage paradigm adapts pre-trained Text-to-Video models for viewpoint prediction in 4D scenes by integrating an adaptive learning branch and a camera extrinsic diffusion branch.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent Text-to-Video (T2V) models have demonstrated powerful capability in visual simulation of real-world geometry and physical laws, indicating its potential as implicit world models. Inspired by this, we explore the feasibility of leveraging the video generation prior for viewpoint planning from given 4D scenes, since videos internally accompany dynamic scenes with natural viewpoints. To this end, we propose a two-stage paradigm to adapt pre-trained T2V models for viewpoint prediction, in a compatible manner. First, we inject the 4D scene representation into the pre-trained T2V model via an adaptive learning branch, where the 4D scene is viewpoint-agnostic and the conditional generated video embeds the viewpoints visually. Then, we formulate viewpoint extraction as a hybrid-condition guided camera extrinsic denoising process. Specifically, a camera extrinsic diffusion branch is further introduced onto the pre-trained T2V model, by taking the generated video and 4D scene as input. Experimental results show the superiority of our proposed method over existing competitors, and ablation studies validate the effectiveness of our key technical designs. To some extent, this work proves the potential of video generation models toward 4D interaction in real world.",
            "score": 6,
            "issue_id": 6398,
            "pub_date": "2025-10-12",
            "pub_date_card": {
                "ru": "12 октября",
                "en": "October 12",
                "zh": "10月12日"
            },
            "hash": "e9218d263c01e3bc",
            "authors": [
                "Yu Li",
                "Menghan Xia",
                "Gongye Liu",
                "Jianhong Bai",
                "Xintao Wang",
                "Conglang Zhang",
                "Yuxuan Lin",
                "Ruihang Chu",
                "Pengfei Wan",
                "Yujiu Yang"
            ],
            "affiliations": [
                "HKUST",
                "HUST",
                "Kling Team, Kuaishou Technology",
                "Tsinghua University",
                "Wuhan University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.10670.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#games",
                    "#diffusion",
                    "#multimodal"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Видео-генерация для планирования траектории камеры в 4D сценах",
                    "desc": "Исследователи предлагают двухэтапный метод адаптации предобученных Text-to-Video моделей для предсказания точек обзора в 4D сценах. На первом этапе 4D сцена интегрируется в T2V модель через адаптивную ветку обучения, которая генерирует видео с визуально встроенными точками обзора. На втором этапе извлечение точек обзора формулируется как процесс диффузионного шумоподавления внешних параметров камеры с гибридным условием. Работа демонстрирует потенциал моделей видео-генерации как неявных world models для взаимодействия с реальным миром в 4D пространстве."
                },
                "en": {
                    "title": "Harnessing Video Generation for 4D Viewpoint Prediction",
                    "desc": "This paper presents a two-stage approach to adapt pre-trained Text-to-Video (T2V) models for predicting viewpoints in 4D scenes. The first stage involves integrating a 4D scene representation into the T2V model using an adaptive learning branch, allowing the model to generate videos that visually represent different viewpoints. The second stage formulates viewpoint extraction as a denoising process, utilizing a camera extrinsic diffusion branch that processes both the generated video and the 4D scene. The results demonstrate that this method outperforms existing techniques, highlighting the potential of T2V models for real-world 4D interactions."
                },
                "zh": {
                    "title": "利用视频生成模型进行4D视角预测的创新方法",
                    "desc": "本文提出了一种两阶段的范式，旨在通过适应性学习分支和相机外部扩散分支，将预训练的文本到视频模型（T2V）应用于4D场景的视角预测。首先，通过适应性学习分支将4D场景表示注入到预训练的T2V模型中，使得生成的视频能够自然地嵌入视角信息。接着，将视角提取过程视为一种混合条件引导的相机外部去噪过程，进一步引入相机外部扩散分支。实验结果表明，所提方法在性能上优于现有竞争者，验证了视频生成模型在现实世界4D交互中的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.07841",
            "title": "Self-Improving LLM Agents at Test-Time",
            "url": "https://huggingface.co/papers/2510.07841",
            "abstract": "A test-time self-improvement method enhances language models by generating additional training examples from uncertain cases, leading to better performance with fewer samples.  \t\t\t\t\tAI-generated summary \t\t\t\t One paradigm of language model (LM) fine-tuning relies on creating large training datasets, under the assumption that high quantity and diversity will enable models to generalize to novel tasks after post-training. In practice, gathering large sets of data is inefficient, and training on them is prohibitively expensive; worse, there is no guarantee that the resulting model will handle complex scenarios or generalize better. Moreover, existing techniques rarely assess whether a training sample provides novel information or is redundant with the knowledge already acquired by the model, resulting in unnecessary costs. In this work, we explore a new test-time self-improvement method to create more effective and generalizable agentic LMs on-the-fly. The proposed algorithm can be summarized in three steps: (i) first it identifies the samples that model struggles with (self-awareness), (ii) then generates similar examples from detected uncertain samples (self-data augmentation), and (iii) uses these newly generated samples at test-time fine-tuning (self-improvement). We study two variants of this approach: Test-Time Self-Improvement (TT-SI), where the same model generates additional training examples from its own uncertain cases and then learns from them, and contrast this approach with Test-Time Distillation (TT-D), where a stronger model generates similar examples for uncertain cases, enabling student to adapt using distilled supervision. Empirical evaluations across different agent benchmarks demonstrate that TT-SI improves the performance with +5.48% absolute accuracy gain on average across all benchmarks and surpasses other standard learning methods, yet using 68x less training samples. Our findings highlight the promise of TT-SI, demonstrating the potential of self-improvement algorithms at test-time as a new paradigm for building more capable agents toward self-evolution.",
            "score": 4,
            "issue_id": 6398,
            "pub_date": "2025-10-09",
            "pub_date_card": {
                "ru": "9 октября",
                "en": "October 9",
                "zh": "10月9日"
            },
            "hash": "60bb755e99449195",
            "authors": [
                "Emre Can Acikgoz",
                "Cheng Qian",
                "Heng Ji",
                "Dilek Hakkani-Tür",
                "Gokhan Tur"
            ],
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.07841.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#agents",
                    "#transfer_learning"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Самообучение на лету: как модели учатся на своих ошибках во время тестирования",
                    "desc": "Статья предлагает метод самосовершенствования языковых моделей во время тестирования (TT-SI). Модель сначала определяет примеры, с которыми она справляется плохо, затем генерирует похожие примеры для дообучения, и наконец использует их для улучшения своей работы прямо в момент тестирования. Этот подход показывает прирост точности в среднем на 5.48% при использовании в 68 раз меньшего количества обучающих примеров по сравнению со стандартными методами. Метод открывает новую парадигму создания AI-агентов, способных к самостоятельной эволюции без необходимости в больших датасетах."
                },
                "en": {
                    "title": "Empowering Language Models Through Self-Improvement at Test-Time",
                    "desc": "This paper introduces a novel method called Test-Time Self-Improvement (TT-SI) for enhancing language models by generating additional training examples from uncertain cases. The approach involves three key steps: identifying challenging samples, creating similar examples from these samples, and fine-tuning the model using the newly generated data. By focusing on self-awareness and self-data augmentation, TT-SI allows models to improve their performance significantly while using far fewer training samples. Empirical results show that this method leads to an average accuracy gain of 5.48% across various benchmarks, demonstrating its effectiveness compared to traditional learning techniques."
                },
                "zh": {
                    "title": "测试时自我改进：提升语言模型的新方法",
                    "desc": "本文提出了一种测试时自我改进的方法，通过从不确定的案例中生成额外的训练样本，增强语言模型的性能。该方法包括三个步骤：首先识别模型难以处理的样本，其次从这些不确定样本中生成相似的例子，最后在测试时进行微调。实验结果表明，该方法在多个基准测试中平均提高了5.48%的准确率，同时使用的训练样本减少了68倍。研究表明，测试时自我改进算法为构建更强大的智能体提供了新的思路。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.08026",
            "title": "PEAR: Phase Entropy Aware Reward for Efficient Reasoning",
            "url": "https://huggingface.co/papers/2510.08026",
            "abstract": "A reward mechanism called Phase Entropy Aware Reward (PEAR) controls the length of reasoning in large models by adjusting entropy at different stages, balancing conciseness and accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Reasoning Models (LRMs) have achieved impressive performance on complex reasoning tasks by generating detailed chain-of-thought (CoT) explanations. However, these responses are often excessively long, containing redundant reasoning steps that inflate inference cost and reduce usability. Controlling the length of generated reasoning without sacrificing accuracy remains an open challenge. Through a systematic empirical analysis, we reveal a consistent positive correlation between model entropy and response length at different reasoning stages across diverse LRMs: the thinking phase exhibits higher entropy, reflecting exploratory behavior of longer responses, while the final answer phase shows lower entropy, indicating a more deterministic solution. This observation suggests that entropy at different reasoning stages can serve as a control knob for balancing conciseness and performance. Based on this insight, this paper introduces Phase Entropy Aware Reward (PEAR), a reward mechanism that incorporating phase-dependent entropy into the reward design. Instead of treating all tokens uniformly, PEAR penalize excessive entropy during the thinking phase and allowing moderate exploration at the final answer phase, which encourages models to generate concise reasoning traces that retain sufficient flexibility to solve the task correctly. This enables adaptive control of response length without relying on explicit length targets or rigid truncation rules. Extensive experiments across four benchmarks demonstrate that PEAR consistently reduces response length while sustaining competitive accuracy across model scales. In addition, PEAR demonstrates strong out-of-distribution (OOD) robustness beyond the training distribution. Our code is available at: https://github.com/iNLP-Lab/PEAR.",
            "score": 2,
            "issue_id": 6398,
            "pub_date": "2025-10-09",
            "pub_date_card": {
                "ru": "9 октября",
                "en": "October 9",
                "zh": "10月9日"
            },
            "hash": "f4c7a863b396ac9a",
            "authors": [
                "Chen Huang",
                "Wei Lu",
                "Wenxuan Zhang"
            ],
            "affiliations": [
                "Nanyang Technological University",
                "Singapore University of Technology and Design"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.08026.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#benchmark",
                    "#training",
                    "#reasoning",
                    "#optimization"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Контроль длины рассуждений через энтропию на разных фазах",
                    "desc": "Исследователи обнаружили, что энтропия модели коррелирует с длиной ответа на разных этапах рассуждения: высокая энтропия в фазе размышления приводит к длинным ответам, низкая в финальной фазе — к точным решениям. На основе этого наблюдения они разработали механизм наград PEAR, который штрафует избыточную энтропию в фазе размышления и допускает умеренную гибкость в финальной фазе. Такой подход позволяет Large Reasoning Models генерировать более короткие объяснения без потери точности, избегая избыточных шагов рассуждения. Эксперименты показали, что PEAR успешно сокращает длину ответов при сохранении конкурентной точности и демонстрирует хорошую устойчивость на данных вне обучающего распределения."
                },
                "en": {
                    "title": "Balancing Conciseness and Accuracy with PEAR",
                    "desc": "The paper introduces a new reward mechanism called Phase Entropy Aware Reward (PEAR) that helps large reasoning models (LRMs) generate concise yet accurate responses. It identifies a relationship between model entropy and response length, where higher entropy during the thinking phase leads to longer, more exploratory responses, while lower entropy in the final answer phase results in more deterministic outputs. PEAR adjusts the reward based on the entropy at different reasoning stages, penalizing excessive exploration in the thinking phase while allowing some flexibility in the final answer phase. This approach effectively reduces response length without compromising accuracy, demonstrating improved performance across various benchmarks and robustness to out-of-distribution scenarios."
                },
                "zh": {
                    "title": "控制推理长度，提升模型性能的PEAR机制",
                    "desc": "本文提出了一种名为阶段熵感知奖励（PEAR）的奖励机制，用于控制大型推理模型的推理长度。通过调整不同阶段的熵，PEAR在简洁性和准确性之间取得平衡。研究表明，模型的熵与响应长度之间存在正相关关系，思考阶段的熵较高，而最终答案阶段的熵较低。PEAR通过在思考阶段惩罚过高的熵，鼓励模型生成简洁的推理过程，同时保持足够的灵活性以正确解决任务。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04617",
            "title": "Making Mathematical Reasoning Adaptive",
            "url": "https://huggingface.co/papers/2510.04617",
            "abstract": "AdaR framework enhances LLMs' robustness and generalization in mathematical reasoning by synthesizing logically equivalent queries and using RLVR to penalize spurious logic.  \t\t\t\t\tAI-generated summary \t\t\t\t Mathematical reasoning is a primary indicator of large language models (LLMs) intelligence. However, existing LLMs exhibit failures of robustness and generalization. This paper attributes these deficiencies to spurious reasoning, i.e., producing answers from superficial features. To address this challenge, we propose the AdaR framework to enable adaptive reasoning, wherein models rely on problem-solving logic to produce answers. AdaR synthesizes logically equivalent queries by varying variable values, and trains models with RLVR on these data to penalize spurious logic while encouraging adaptive logic. To improve data quality, we extract the problem-solving logic from the original query and generate the corresponding answer by code execution, then apply a sanity check. Experimental results demonstrate that AdaR improves robustness and generalization, achieving substantial improvement in mathematical reasoning while maintaining high data efficiency. Analysis indicates that data synthesis and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs. Subsequent analyses derive key design insights into the effect of critical factors and the applicability to instruct LLMs. Our project is available at https://github.com/LaiZhejian/AdaR",
            "score": 1,
            "issue_id": 6398,
            "pub_date": "2025-10-06",
            "pub_date_card": {
                "ru": "6 октября",
                "en": "October 6",
                "zh": "10月6日"
            },
            "hash": "82cf47c00d882ce9",
            "authors": [
                "Zhejian Lai",
                "Xiang Geng",
                "Zhijun Wang",
                "Yang Bai",
                "Jiahuan Li",
                "Rongxiang Weng",
                "Jingang Wang",
                "Xuezhi Cao",
                "Xunliang Cai",
                "Shujian Huang"
            ],
            "affiliations": [
                "Meituan Inc., China",
                "Nanjing University, Nanjing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04617.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#reasoning",
                    "#optimization",
                    "#data",
                    "#math"
                ],
                "emoji": "🔢",
                "ru": {
                    "title": "Адаптивный reasoning вместо поверхностных решений в математике",
                    "desc": "Статья представляет фреймворк AdaR для улучшения математического reasoning в LLM путём борьбы с ложной логикой (spurious reasoning), когда модель опирается на поверхностные признаки вместо настоящего решения. Метод синтезирует логически эквивалентные запросы с изменёнными значениями переменных и использует RLVR (reinforcement learning) для штрафования ложной логики и поощрения адаптивного reasoning. Для обеспечения качества данных авторы извлекают логику решения из исходной задачи, генерируют ответ через выполнение кода и применяют проверку корректности. Эксперименты показывают, что AdaR значительно улучшает робастность и способность к обобщению в математических задачах при высокой эффективности использования данных."
                },
                "en": {
                    "title": "Enhancing LLMs' Reasoning with AdaR Framework",
                    "desc": "The AdaR framework aims to improve the robustness and generalization of large language models (LLMs) in mathematical reasoning tasks. It addresses the issue of spurious reasoning by synthesizing logically equivalent queries and employing Reinforcement Learning with Value Regularization (RLVR) to penalize incorrect logic. By extracting problem-solving logic and generating answers through code execution, AdaR enhances data quality and encourages models to rely on sound reasoning. Experimental results show that AdaR significantly boosts performance in mathematical reasoning while ensuring efficient use of data."
                },
                "zh": {
                    "title": "AdaR框架：提升LLMs数学推理的鲁棒性与泛化能力",
                    "desc": "本论文提出了AdaR框架，以增强大型语言模型（LLMs）在数学推理中的鲁棒性和泛化能力。现有的LLMs常常因表面特征导致错误推理，缺乏深层次的逻辑思考。AdaR通过合成逻辑等价的查询并使用强化学习变体（RLVR）来惩罚虚假逻辑，从而促进模型的自适应推理。实验结果表明，AdaR显著提高了数学推理的表现，同时保持了高数据效率。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2510.04587",
            "title": "Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole\n  Slide Image Diagnosis Behavior",
            "url": "https://huggingface.co/papers/2510.04587",
            "abstract": "A framework records and utilizes expert navigation behavior in whole-slide imaging to build an agentic system for pathology diagnosis, achieving high precision and recall in metastasis detection.  \t\t\t\t\tAI-generated summary \t\t\t\t Diagnosing a whole-slide image is an interactive, multi-stage process involving changes in magnification and movement between fields. Although recent pathology foundation models are strong, practical agentic systems that decide what field to examine next, adjust magnification, and deliver explainable diagnoses are still lacking. The blocker is data: scalable, clinically aligned supervision of expert viewing behavior that is tacit and experience-based, not written in textbooks or online, and therefore absent from large language model training. We introduce the AI Session Recorder, which works with standard WSI viewers to unobtrusively record routine navigation and convert the viewer logs into standardized behavioral commands (inspect or peek at discrete magnifications) and bounding boxes. A lightweight human-in-the-loop review turns AI-drafted rationales into the Pathology-CoT dataset, a form of paired \"where to look\" and \"why it matters\" supervision produced at roughly six times lower labeling time. Using this behavioral data, we build Pathologist-o3, a two-stage agent that first proposes regions of interest and then performs behavior-guided reasoning. On gastrointestinal lymph-node metastasis detection, it achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the state-of-the-art OpenAI o3 model and generalizing across backbones. To our knowledge, this constitutes one of the first behavior-grounded agentic systems in pathology. Turning everyday viewer logs into scalable, expert-validated supervision, our framework makes agentic pathology practical and establishes a path to human-aligned, upgradeable clinical AI.",
            "score": 0,
            "issue_id": 6398,
            "pub_date": "2025-10-06",
            "pub_date_card": {
                "ru": "6 октября",
                "en": "October 6",
                "zh": "10月6日"
            },
            "hash": "89586b8e177d522a",
            "authors": [
                "Sheng Wang",
                "Ruiming Wu",
                "Charles Herndon",
                "Yihang Liu",
                "Shunsuke Koga",
                "Jeanne Shen",
                "Zhi Huang"
            ],
            "affiliations": [
                "Department of Biostatistics, Epidemiology & Informatics, University of Pennsylvania",
                "Department of Electrical and System Engineering, University of Pennsylvania",
                "Department of Pathology and Laboratory Medicine, University of Pennsylvania",
                "Department of Pathology, Stanford University",
                "Department of Pathology, University of California at San Francisco"
            ],
            "pdf_title_img": "assets/pdf/title_img/2510.04587.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#agi",
                    "#reasoning",
                    "#healthcare",
                    "#interpretability",
                    "#science",
                    "#dataset"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "Агентная система патологии учится у экспертов через запись их навигации",
                    "desc": "Исследователи создали AI Session Recorder — систему, которая незаметно записывает действия патологов при просмотре гистологических снимков и превращает эти данные в обучающий датасет. На основе записанного поведения экспертов построен агент Pathologist-o3, который сначала предлагает области интереса, а затем проводит анализ, имитируя логику специалиста. Система достигла 100% полноты и 84.5% точности в обнаружении метастазов в лимфоузлах, превзойдя OpenAI o3. Это один из первых агентных AI-систем в патологии, которая учится на реальном поведении врачей, а не только на текстовых описаниях."
                },
                "en": {
                    "title": "Transforming Expert Navigation into Smart Pathology Diagnosis",
                    "desc": "This paper presents a new framework that captures expert navigation behavior in whole-slide imaging to enhance pathology diagnosis. It introduces the AI Session Recorder, which records how pathologists interact with images and converts this data into actionable commands for an AI system. The resulting model, Pathologist-o3, uses this behavioral data to identify areas of interest and provide reasoning for its decisions, achieving impressive metrics in detecting metastasis. This approach not only improves diagnostic accuracy but also paves the way for more practical and explainable AI systems in clinical settings."
                },
                "zh": {
                    "title": "智能病理诊断的新路径",
                    "desc": "本研究提出了一种框架，通过记录和利用专家在全切片成像中的导航行为，构建了一种用于病理诊断的智能系统。该系统在转移性肿瘤检测中实现了高精度和高召回率。我们引入了AI会话记录器，能够无缝记录专家的常规导航，并将其转化为标准化的行为命令和边界框。最终，基于这些行为数据，我们构建了Pathologist-o3，一个能够提出感兴趣区域并进行行为引导推理的双阶段智能体。"
                }
            }
        }
    ],
    "link_prev": "2025-10-13.html",
    "link_next": "2025-10-15.html",
    "link_month": "2025-10.html",
    "short_date_prev": {
        "ru": "13.10",
        "en": "10/13",
        "zh": "10月13日"
    },
    "short_date_next": {
        "ru": "15.10",
        "en": "10/15",
        "zh": "10月15日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 2,
        "#cv": 0,
        "#rl": 2,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 2,
        "#robotics": 0,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 4,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 1,
        "#diffusion": 1,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    }
}