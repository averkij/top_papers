{
    "date": {
        "ru": "21 апреля",
        "en": "April 21",
        "zh": "4月21日"
    },
    "time_utc": "2025-04-21 22:11",
    "weekday": 0,
    "issue_id": 3354,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2504.13837",
            "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in\n  LLMs Beyond the Base Model?",
            "url": "https://huggingface.co/papers/2504.13837",
            "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning capabilities of LLMs, particularly in mathematics and programming tasks. It is widely believed that RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed corresponding base models' capacity. In this study, however, we critically re-examines this assumption by measuring the pass@k metric with large values of k to explore the reasoning capability boundary of the models across a wide range of model families and benchmarks. Surprisingly, the RL does not, in fact, elicit fundamentally new reasoning patterns. While RL-trained models outperform their base models at smaller values of k (\\eg, k=1), base models can achieve a comparable or even higher pass@k score compared to their RL counterparts at large k values. The reasoning paths generated by RL-trained models are already included in the base models' sampling distribution, suggesting that most reasoning abilities manifested in RL-trained models are already obtained by base models. Further analysis shows that RL training boosts the performance by biasing the model's output distribution toward paths that are more likely to yield rewards, therefore sampling correct responses more efficiently. But this also results in a narrower reasoning capability boundary compared to base models. Similar results are observed in visual reasoning tasks trained with RLVR. Moreover, we find that distillation can genuinely introduce new knowledge into the model, different from RLVR. These findings underscore a critical limitation of RLVR in advancing LLM reasoning abilities which requires us to fundamentally rethink the impact of RL training in reasoning LLMs and the need of a better paradigm. Project Page: https://limit-of-RLVR.github.io",
            "score": 60,
            "issue_id": 3335,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "2fe56493fe3aec80",
            "authors": [
                "Yang Yue",
                "Zhiqi Chen",
                "Rui Lu",
                "Andrew Zhao",
                "Zhaokai Wang",
                "Yang Yue",
                "Shiji Song",
                "Gao Huang"
            ],
            "affiliations": [
                "LeapLab, Tsinghua University",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13837.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#optimization"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Обучение с подкреплением не расширяет границы рассуждений ИИ",
                    "desc": "Исследование показывает, что обучение с подкреплением с верифицируемыми наградами (RLVR) не приводит к появлению принципиально новых способностей рассуждения у языковых моделей. Хотя модели, обученные с помощью RL, превосходят базовые модели при небольших значениях k в метрике pass@k, базовые модели могут достичь сопоставимых или даже более высоких показателей при больших k. Анализ выявил, что RL-обучение смещает распределение выходных данных модели в сторону путей, которые с большей вероятностью приносят награды, но это также приводит к сужению границ способностей рассуждения. Результаты подчеркивают ограниченность RLVR в улучшении способностей рассуждения языковых моделей."
                },
                "en": {
                    "title": "Rethinking RLVR: Limits of Reinforcement Learning in Reasoning",
                    "desc": "This paper critically evaluates the effectiveness of Reinforcement Learning with Verifiable Rewards (RLVR) in enhancing the reasoning capabilities of large language models (LLMs). The authors find that while RLVR improves performance at lower complexity tasks, it does not introduce fundamentally new reasoning patterns compared to base models when evaluated at higher complexity levels. Instead, RL-trained models tend to sample reasoning paths that are already present in base models, leading to a narrower range of reasoning capabilities. The study suggests that distillation may be a more effective method for introducing new knowledge into models, highlighting the limitations of RLVR in advancing LLM reasoning."
                },
                "zh": {
                    "title": "重新思考强化学习在推理中的作用",
                    "desc": "强化学习与可验证奖励（RLVR）在提升大型语言模型（LLM）推理能力方面取得了一定成功，尤其是在数学和编程任务中。然而，本研究重新审视了这一假设，发现RLVR并未真正引入新的推理模式。尽管RL训练的模型在小的k值下表现优于基础模型，但在较大的k值下，基础模型的表现可以与RL模型相媲美，甚至更好。这表明，RL训练模型的推理路径实际上已经包含在基础模型的采样分布中，强调了RLVR在提升LLM推理能力方面的局限性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13835",
            "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing\n  Information Gain in Semantic Space",
            "url": "https://huggingface.co/papers/2504.13835",
            "abstract": "Data quality and diversity are key to the construction of effective instruction-tuning datasets. % With the increasing availability of open-source instruction-tuning datasets, it is advantageous to automatically select high-quality and diverse subsets from a vast amount of data. % Existing methods typically prioritize instance quality and use heuristic rules to maintain diversity. % However, this absence of a comprehensive view of the entire collection often leads to suboptimal results. % Moreover, heuristic rules generally focus on distance or clustering within the embedding space, which fails to accurately capture the intent of complex instructions in the semantic space. % To bridge this gap, we propose a unified method for quantifying the information content of datasets. This method models the semantic space by constructing a label graph and quantifies diversity based on the distribution of information within the graph. % Based on such a measurement, we further introduce an efficient sampling method that selects data samples iteratively to Maximize the Information Gain (MIG) in semantic space. % Experiments on various datasets and base models demonstrate that MIG consistently outperforms state-of-the-art methods. % Notably, the model fine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance to the official SFT model trained on the full dataset, with improvements of +5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
            "score": 30,
            "issue_id": 3335,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "12926d762a03519c",
            "authors": [
                "Yicheng Chen",
                "Yining Li",
                "Kai Hu",
                "Zerun Ma",
                "Haochen Ye",
                "Kai Chen"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Fudan University",
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13835.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#open_source",
                    "#training",
                    "#dataset",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Максимизация информационного прироста для эффективного обучения языковых моделей",
                    "desc": "Статья представляет новый метод для отбора высококачественных и разнообразных подмножеств данных для обучения языковых моделей с инструкциями. Авторы предлагают унифицированный подход к измерению информационного содержания наборов данных, моделируя семантическое пространство с помощью графа меток. На основе этого измерения разработан эффективный метод выборки, максимизирующий прирост информации в семантическом пространстве. Эксперименты показывают, что предложенный метод превосходит современные подходы, позволяя достичь сопоставимой производительности при использовании лишь 5% данных."
                },
                "en": {
                    "title": "Maximizing Information for Better Instruction-Tuning Datasets",
                    "desc": "This paper addresses the importance of data quality and diversity in creating effective instruction-tuning datasets for machine learning. It critiques existing methods that rely on heuristic rules for maintaining diversity, which often leads to suboptimal dataset selections. The authors propose a new approach that quantifies the information content of datasets by modeling the semantic space with a label graph, allowing for a more comprehensive understanding of data diversity. Their method, called Maximize the Information Gain (MIG), iteratively selects samples that enhance the dataset's information content, showing significant performance improvements in experiments compared to traditional methods."
                },
                "zh": {
                    "title": "提升数据集质量与多样性的统一方法",
                    "desc": "数据质量和多样性是构建有效指令调优数据集的关键。随着开源指令调优数据集的增加，自动选择高质量和多样化的子集变得尤为重要。现有方法通常优先考虑实例质量，并使用启发式规则来维持多样性，但缺乏对整个数据集的全面视角，导致结果不理想。我们提出了一种统一的方法，通过构建标签图来量化数据集的信息内容，并基于信息分布来量化多样性，从而引入了一种高效的采样方法，以最大化语义空间中的信息增益。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.11544",
            "title": "NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes",
            "url": "https://huggingface.co/papers/2504.11544",
            "abstract": "Retrieval-augmented generation (RAG) empowers large language models to access external and private corpus, enabling factually consistent responses in specific domains. By exploiting the inherent structure of the corpus, graph-based RAG methods further enrich this process by building a knowledge graph index and leveraging the structural nature of graphs. However, current graph-based RAG approaches seldom prioritize the design of graph structures. Inadequately designed graph not only impede the seamless integration of diverse graph algorithms but also result in workflow inconsistencies and degraded performance. To further unleash the potential of graph for RAG, we propose NodeRAG, a graph-centric framework introducing heterogeneous graph structures that enable the seamless and holistic integration of graph-based methodologies into the RAG workflow. By aligning closely with the capabilities of LLMs, this framework ensures a fully cohesive and efficient end-to-end process. Through extensive experiments, we demonstrate that NodeRAG exhibits performance advantages over previous methods, including GraphRAG and LightRAG, not only in indexing time, query time, and storage efficiency but also in delivering superior question-answering performance on multi-hop benchmarks and open-ended head-to-head evaluations with minimal retrieval tokens. Our GitHub repository could be seen at https://github.com/Terry-Xu-666/NodeRAG.",
            "score": 24,
            "issue_id": 3335,
            "pub_date": "2025-04-15",
            "pub_date_card": {
                "ru": "15 апреля",
                "en": "April 15",
                "zh": "4月15日"
            },
            "hash": "86dd4da356ad5ef0",
            "authors": [
                "Tianyang Xu",
                "Haojie Zheng",
                "Chengze Li",
                "Haoxiang Chen",
                "Yixin Liu",
                "Ruoxi Chen",
                "Lichao Sun"
            ],
            "affiliations": [
                "Columbia University",
                "Lehigh University",
                "University of Pennsylvania"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.11544.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#graphs",
                    "#open_source",
                    "#rag",
                    "#multimodal",
                    "#optimization"
                ],
                "emoji": "🕸️",
                "ru": {
                    "title": "NodeRAG: Графовый подход к улучшению генерации с дополнением из источников",
                    "desc": "NodeRAG - это новый подход к генерации с дополнением из источников (RAG), использующий гетерогенные графовые структуры для улучшения работы больших языковых моделей. Эта система позволяет эффективно интегрировать графовые алгоритмы в процесс RAG, обеспечивая более согласованный и производительный рабочий процесс. Эксперименты показывают, что NodeRAG превосходит предыдущие методы по скорости индексации, времени запросов и эффективности хранения. Кроме того, система демонстрирует улучшенные результаты в задачах ответов на вопросы и открытых сравнениях, используя минимальное количество токенов для извлечения информации."
                },
                "en": {
                    "title": "NodeRAG: Enhancing RAG with Smart Graph Structures",
                    "desc": "This paper introduces NodeRAG, a new framework that enhances retrieval-augmented generation (RAG) by using heterogeneous graph structures. By focusing on the design of graph structures, NodeRAG improves the integration of various graph algorithms into the RAG workflow, leading to better performance. The framework aligns with the capabilities of large language models (LLMs), ensuring a smooth and efficient process for generating responses. Experimental results show that NodeRAG outperforms existing methods like GraphRAG and LightRAG in terms of indexing time, query time, storage efficiency, and question-answering accuracy."
                },
                "zh": {
                    "title": "NodeRAG：图结构助力检索增强生成",
                    "desc": "检索增强生成（RAG）使大型语言模型能够访问外部和私有语料库，从而在特定领域提供事实一致的响应。通过利用语料库的内在结构，基于图的RAG方法通过构建知识图谱索引进一步丰富了这一过程。然而，目前的基于图的RAG方法很少重视图结构的设计。为了解放图在RAG中的潜力，我们提出了NodeRAG，一个以图为中心的框架，引入异构图结构，实现图方法与RAG工作流程的无缝整合。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.11833",
            "title": "Could Thinking Multilingually Empower LLM Reasoning?",
            "url": "https://huggingface.co/papers/2504.11833",
            "abstract": "Previous work indicates that large language models exhibit a significant \"English bias\", i.e. they often perform better when tasks are presented in English. Interestingly, we have observed that using certain other languages in reasoning tasks can yield better performance than English. However, this phenomenon remains under-explored. In this paper, we explore the upper bound of harnessing multilingualism in reasoning tasks, suggesting that multilingual reasoning promises significantly (by nearly 10 Acc@k points) and robustly (tolerance for variations in translation quality and language choice) higher upper bounds than English-only reasoning. Besides analyzing the reason behind the upper bound and challenges in reaching it, we also find that common answer selection methods cannot achieve this upper bound, due to their limitations and biases. These insights could pave the way for future research aimed at fully harnessing the potential of multilingual reasoning in LLMs.",
            "score": 15,
            "issue_id": 3335,
            "pub_date": "2025-04-16",
            "pub_date_card": {
                "ru": "16 апреля",
                "en": "April 16",
                "zh": "4月16日"
            },
            "hash": "463f5ddc1d75970e",
            "authors": [
                "Changjiang Gao",
                "Xu Huang",
                "Wenhao Zhu",
                "Shujian Huang",
                "Lei Li",
                "Fei Yuan"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "National Key Laboratory for Novel Software Technology, Nanjing University",
                "Shanghai Artificial Intelligence Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.11833.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#low_resource",
                    "#multilingual"
                ],
                "emoji": "🌍",
                "ru": {
                    "title": "Многоязычное рассуждение - ключ к улучшению больших языковых моделей",
                    "desc": "Это исследование показывает, что использование нескольких языков в задачах рассуждения может значительно повысить эффективность больших языковых моделей по сравнению с использованием только английского языка. Авторы обнаружили, что многоязычное рассуждение может улучшить точность на 10 процентных пунктов. Однако существующие методы выбора ответов не могут полностью реализовать этот потенциал из-за своих ограничений и предвзятостей. Эти выводы открывают новые направления для исследований в области многоязычного рассуждения в больших языковых моделях."
                },
                "en": {
                    "title": "Unlocking the Power of Multilingual Reasoning in LLMs",
                    "desc": "This paper investigates the performance of large language models (LLMs) in reasoning tasks across multiple languages. It reveals that using certain non-English languages can lead to better outcomes than relying solely on English, highlighting a significant opportunity for multilingual reasoning. The authors suggest that multilingual approaches can achieve higher accuracy and robustness compared to English-only methods, even when translation quality varies. Additionally, they identify limitations in current answer selection methods that prevent reaching the full potential of multilingual reasoning, setting the stage for future research in this area."
                },
                "zh": {
                    "title": "多语言推理的潜力超越英语",
                    "desc": "本论文探讨了大型语言模型在推理任务中的多语言能力，发现某些语言在推理任务中的表现优于英语。研究表明，多语言推理的上限比仅使用英语的推理高出近10个准确率点，并且对翻译质量和语言选择的变化具有更强的容忍度。我们分析了达到这一上限的原因和挑战，并指出常见的答案选择方法由于其局限性和偏见，无法实现这一上限。这些发现为未来研究充分利用大型语言模型的多语言推理潜力铺平了道路。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.10823",
            "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from\n  Multiple Perspectives",
            "url": "https://huggingface.co/papers/2504.10823",
            "abstract": "Navigating high-stakes dilemmas involving conflicting values is challenging even for humans, let alone for AI. Yet prior work in evaluating the reasoning capabilities of large language models (LLMs) in such situations has been limited to everyday scenarios. To close this gap, this work first introduces CLASH (Character perspective-based LLM Assessments in Situations with High-stakes), a meticulously curated dataset consisting of 345 high-impact dilemmas along with 3,795 individual perspectives of diverse values. In particular, we design CLASH in a way to support the study of critical aspects of value-based decision-making processes which are missing from prior work, including understanding decision ambivalence and psychological discomfort as well as capturing the temporal shifts of values in characters' perspectives. By benchmarking 10 open and closed frontier models, we uncover several key findings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet, achieve less than 50% accuracy in identifying situations where the decision should be ambivalent, while they perform significantly better in clear-cut scenarios. (2) While LLMs reasonably predict psychological discomfort as marked by human, they inadequately comprehend perspectives involving value shifts, indicating a need for LLMs to reason over complex values. (3) Our experiments also reveal a significant correlation between LLMs' value preferences and their steerability towards a given value. (4) Finally, LLMs exhibit greater steerability when engaged in value reasoning from a third-party perspective, compared to a first-person setup, though certain value pairs benefit uniquely from the first-person framing.",
            "score": 10,
            "issue_id": 3345,
            "pub_date": "2025-04-15",
            "pub_date_card": {
                "ru": "15 апреля",
                "en": "April 15",
                "zh": "4月15日"
            },
            "hash": "9e69138c0a313b09",
            "authors": [
                "Ayoung Lee",
                "Ryan Sungmo Kwon",
                "Peter Railton",
                "Lu Wang"
            ],
            "affiliations": [
                "Department of Computer Science and Engineering, University of Michigan",
                "Department of Philosophy, University of Michigan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.10823.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#reasoning",
                    "#dataset",
                    "#benchmark"
                ],
                "emoji": "🤔",
                "ru": {
                    "title": "Испытание искусственного интеллекта этическими дилеммами",
                    "desc": "Статья представляет набор данных CLASH для оценки способности языковых моделей решать сложные этические дилеммы. Исследование выявило, что даже продвинутые модели, такие как GPT-4 и Claude-Sonnet, имеют трудности с определением неоднозначных ситуаций и пониманием изменения ценностей. Эксперименты показали корреляцию между предпочтениями моделей и их управляемостью в отношении определенных ценностей. Также обнаружено, что модели лучше рассуждают о ценностях с точки зрения третьего лица, чем от первого лица."
                },
                "en": {
                    "title": "Navigating Complex Values: Evaluating AI in High-Stakes Dilemmas",
                    "desc": "This paper introduces CLASH, a new dataset designed to evaluate large language models (LLMs) on high-stakes dilemmas that involve conflicting values. It contains 345 dilemmas and 3,795 perspectives, focusing on aspects like decision ambivalence and psychological discomfort. The study benchmarks various LLMs, revealing that even advanced models struggle with ambivalent decisions, achieving less than 50% accuracy. Additionally, while LLMs can predict psychological discomfort, they have difficulty understanding shifts in values, highlighting the need for improved reasoning in complex value scenarios."
                },
                "zh": {
                    "title": "应对高风险困境中的价值冲突",
                    "desc": "本研究提出了CLASH数据集，专注于高风险困境中的价值冲突，包含345个高影响力的困境和3795个不同价值观的个体视角。我们发现，即使是最强大的语言模型，如GPT-4o和Claude-Sonnet，在识别决策模糊性方面的准确率也不足50%。此外，虽然这些模型能够合理预测人类的心理不适，但在理解涉及价值转变的视角时表现不佳，显示出它们在复杂价值推理上的不足。最后，模型在第三方视角下进行价值推理时的可操控性更强，而某些价值对在第一人称框架下则表现更好。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13173",
            "title": "It's All Connected: A Journey Through Test-Time Memorization,\n  Attentional Bias, Retention, and Online Optimization",
            "url": "https://huggingface.co/papers/2504.13173",
            "abstract": "Designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neural architectures, including Transformers, Titans, and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequence models. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.",
            "score": 9,
            "issue_id": 3336,
            "pub_date": "2025-04-17",
            "pub_date_card": {
                "ru": "17 апреля",
                "en": "April 17",
                "zh": "4月17日"
            },
            "hash": "809d2f1facd3aed9",
            "authors": [
                "Ali Behrouz",
                "Meisam Razaviyayn",
                "Peilin Zhong",
                "Vahab Mirrokni"
            ],
            "affiliations": [
                "Google Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13173.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#reasoning",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Переосмысление архитектур нейронных сетей через призму селективного внимания",
                    "desc": "Статья представляет новый подход к проектированию архитектур нейронных сетей, вдохновленный когнитивным феноменом селективного внимания. Авторы предлагают framework Miras для создания моделей на основе ассоциативной памяти с различными конфигурациями внимания и механизмами забывания. Представлены три новые модели последовательностей - Moneta, Yaad и Memora, которые превосходят существующие линейные RNN. Эксперименты показывают, что некоторые варианты Miras достигают исключительной производительности в задачах языкового моделирования, здравого смысла и интенсивного запоминания."
                },
                "en": {
                    "title": "Revolutionizing Neural Architectures with Attentional Bias",
                    "desc": "This paper explores new ways to design neural network architectures, particularly focusing on how they can mimic human attention. It introduces the concept of attentional bias, which helps models prioritize important information, and critiques existing methods that rely on simple similarity measures. The authors propose a framework called Miras, which allows for flexible design choices in memory architecture and training objectives. They also present new models that outperform traditional approaches in specific tasks, demonstrating the effectiveness of their innovative strategies."
                },
                "zh": {
                    "title": "基于注意偏向的深度学习架构设计",
                    "desc": "本文探讨了如何设计高效且有效的基础模型架构，灵感来源于人类的注意偏向现象。我们将神经网络架构重新概念化为关联记忆模块，利用内部目标（注意偏向）来学习键值映射。研究发现，现有序列模型主要依赖点积相似性或L2回归目标，而我们提出了一系列替代的注意偏向配置及其有效近似，以稳定训练过程。基于这些见解，我们提出了Miras框架，设计深度学习架构，并展示了三种新型序列模型，超越了现有线性RNN的能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13157",
            "title": "AerialMegaDepth: Learning Aerial-Ground Reconstruction and View\n  Synthesis",
            "url": "https://huggingface.co/papers/2504.13157",
            "abstract": "We explore the task of geometric reconstruction of images captured from a mixture of ground and aerial views. Current state-of-the-art learning-based approaches fail to handle the extreme viewpoint variation between aerial-ground image pairs. Our hypothesis is that the lack of high-quality, co-registered aerial-ground datasets for training is a key reason for this failure. Such data is difficult to assemble precisely because it is difficult to reconstruct in a scalable way. To overcome this challenge, we propose a scalable framework combining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google Earth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The pseudo-synthetic data simulates a wide range of aerial viewpoints, while the real, crowd-sourced images help improve visual fidelity for ground-level images where mesh-based renderings lack sufficient detail, effectively bridging the domain gap between real images and pseudo-synthetic renderings. Using this hybrid dataset, we fine-tune several state-of-the-art algorithms and achieve significant improvements on real-world, zero-shot aerial-ground tasks. For example, we observe that baseline DUSt3R localizes fewer than 5% of aerial-ground pairs within 5 degrees of camera rotation error, while fine-tuning with our data raises accuracy to nearly 56%, addressing a major failure point in handling large viewpoint changes. Beyond camera estimation and scene reconstruction, our dataset also improves performance on downstream tasks like novel-view synthesis in challenging aerial-ground scenarios, demonstrating the practical value of our approach in real-world applications.",
            "score": 8,
            "issue_id": 3335,
            "pub_date": "2025-04-17",
            "pub_date_card": {
                "ru": "17 апреля",
                "en": "April 17",
                "zh": "4月17日"
            },
            "hash": "bbd51434265e3614",
            "authors": [
                "Khiem Vuong",
                "Anurag Ghosh",
                "Deva Ramanan",
                "Srinivasa Narasimhan",
                "Shubham Tulsiani"
            ],
            "affiliations": [
                "Carnegie Mellon University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13157.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#transfer_learning",
                    "#synthetic",
                    "#dataset",
                    "#3d"
                ],
                "emoji": "🏙️",
                "ru": {
                    "title": "Преодоление разрыва между землей и небом в компьютерном зрении",
                    "desc": "Статья посвящена геометрической реконструкции изображений с наземных и аэросъемок. Авторы предлагают масштабируемый подход, комбинирующий псевдо-синтетические рендеры из 3D-моделей городов с реальными наземными изображениями. Этот гибридный набор данных используется для дообучения современных алгоритмов компьютерного зрения. Результаты показывают значительное улучшение в задачах локализации камеры и реконструкции сцены при экстремальных изменениях ракурса между наземными и аэроснимками."
                },
                "en": {
                    "title": "Bridging the Viewpoint Gap: Enhanced Aerial-Ground Image Reconstruction",
                    "desc": "This paper addresses the challenge of reconstructing images from both ground and aerial perspectives, which current machine learning methods struggle with due to significant viewpoint differences. The authors suggest that the lack of high-quality datasets that pair aerial and ground images is a major obstacle. To tackle this, they introduce a scalable framework that combines pseudo-synthetic images generated from 3D city models with real ground-level images, effectively bridging the gap between these two domains. By fine-tuning existing algorithms with this hybrid dataset, they achieve substantial improvements in accuracy for aerial-ground tasks, demonstrating the framework's effectiveness in real-world applications."
                },
                "zh": {
                    "title": "打破视角限制，实现图像几何重建",
                    "desc": "本文探讨了从地面和空中视角捕获的图像进行几何重建的任务。现有的基于学习的方法在处理空中与地面图像对之间的极端视角变化时表现不佳。我们认为，缺乏高质量的、共同注册的空中-地面数据集是导致这一失败的关键原因。为了解决这个问题，我们提出了一种可扩展的框架，结合了来自3D城市网格的伪合成渲染和真实的地面众包图像，从而有效地缩小了真实图像与伪合成渲染之间的领域差距。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.09621",
            "title": "Tokenize Image Patches: Global Context Fusion for Effective Haze Removal\n  in Large Images",
            "url": "https://huggingface.co/papers/2504.09621",
            "abstract": "Global contextual information and local detail features are essential for haze removal tasks. Deep learning models perform well on small, low-resolution images, but they encounter difficulties with large, high-resolution ones due to GPU memory limitations. As a compromise, they often resort to image slicing or downsampling. The former diminishes global information, while the latter discards high-frequency details. To address these challenges, we propose DehazeXL, a haze removal method that effectively balances global context and local feature extraction, enabling end-to-end modeling of large images on mainstream GPU hardware. Additionally, to evaluate the efficiency of global context utilization in haze removal performance, we design a visual attribution method tailored to the characteristics of haze removal tasks. Finally, recognizing the lack of benchmark datasets for haze removal in large images, we have developed an ultra-high-resolution haze removal dataset (8KDehaze) to support model training and testing. It includes 10000 pairs of clear and hazy remote sensing images, each sized at 8192 times 8192 pixels. Extensive experiments demonstrate that DehazeXL can infer images up to 10240 times 10240 pixels with only 21 GB of memory, achieving state-of-the-art results among all evaluated methods. The source code and experimental dataset are available at https://github.com/CastleChen339/DehazeXL.",
            "score": 6,
            "issue_id": 3340,
            "pub_date": "2025-04-13",
            "pub_date_card": {
                "ru": "13 апреля",
                "en": "April 13",
                "zh": "4月13日"
            },
            "hash": "6c9f2fe055ad92dc",
            "authors": [
                "Jiuchen Chen",
                "Xinyu Yan",
                "Qizhi Xu",
                "Kaiqi Li"
            ],
            "affiliations": [
                "Beijing Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.09621.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#open_source",
                    "#optimization",
                    "#data",
                    "#cv"
                ],
                "emoji": "🌫️",
                "ru": {
                    "title": "DehazeXL: эффективное удаление дымки на больших изображениях",
                    "desc": "DehazeXL - это новый метод удаления дымки, который эффективно балансирует глобальный контекст и извлечение локальных признаков, позволяя обрабатывать большие изображения на обычных GPU. Авторы также разработали метод визуальной атрибуции для оценки эффективности использования глобального контекста. Кроме того, они создали набор данных 8KDehaze с 10000 пар четких и дымчатых изображений размером 8192x8192 пикселей. Эксперименты показали, что DehazeXL может обрабатывать изображения до 10240x10240 пикселей, используя всего 21 ГБ памяти, и достигает лучших результатов среди всех оцененных методов."
                },
                "en": {
                    "title": "DehazeXL: Mastering Haze Removal with Global Context and Local Detail",
                    "desc": "The paper introduces DehazeXL, a novel method for haze removal that effectively integrates global contextual information with local detail features. Traditional deep learning models struggle with high-resolution images due to memory constraints, often leading to a loss of important information. DehazeXL overcomes these limitations by allowing end-to-end processing of large images while maintaining high-quality outputs. Additionally, the authors present a new ultra-high-resolution dataset, 8KDehaze, to facilitate training and testing of haze removal models, demonstrating that their approach achieves superior performance on large images."
                },
                "zh": {
                    "title": "DehazeXL：高效去雾的新方法",
                    "desc": "本文提出了一种新的去雾方法DehazeXL，旨在平衡全局上下文信息和局部细节特征，以提高大图像的去雾效果。传统深度学习模型在处理高分辨率图像时面临GPU内存限制，通常采用图像切片或下采样的方法，但这会导致信息损失。DehazeXL能够在主流GPU硬件上实现端到端的大图像建模，并通过设计视觉归因方法来评估全局上下文在去雾性能中的有效性。此外，我们还开发了一个超高分辨率去雾数据集（8KDehaze），包含10000对8192x8192像素的清晰和模糊遥感图像，以支持模型的训练和测试。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13072",
            "title": "HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation",
            "url": "https://huggingface.co/papers/2504.13072",
            "abstract": "Scene-level 3D generation represents a critical frontier in multimedia and computer graphics, yet existing approaches either suffer from limited object categories or lack editing flexibility for interactive applications. In this paper, we present HiScene, a novel hierarchical framework that bridges the gap between 2D image generation and 3D object generation and delivers high-fidelity scenes with compositional identities and aesthetic scene content. Our key insight is treating scenes as hierarchical \"objects\" under isometric views, where a room functions as a complex object that can be further decomposed into manipulatable items. This hierarchical approach enables us to generate 3D content that aligns with 2D representations while maintaining compositional structure. To ensure completeness and spatial alignment of each decomposed instance, we develop a video-diffusion-based amodal completion technique that effectively handles occlusions and shadows between objects, and introduce shape prior injection to ensure spatial coherence within the scene. Experimental results demonstrate that our method produces more natural object arrangements and complete object instances suitable for interactive applications, while maintaining physical plausibility and alignment with user inputs.",
            "score": 5,
            "issue_id": 3337,
            "pub_date": "2025-04-17",
            "pub_date_card": {
                "ru": "17 апреля",
                "en": "April 17",
                "zh": "4月17日"
            },
            "hash": "6eb45708f6cb0c26",
            "authors": [
                "Wenqi Dong",
                "Bangbang Yang",
                "Zesong Yang",
                "Yuan Li",
                "Tao Hu",
                "Hujun Bao",
                "Yuewen Ma",
                "Zhaopeng Cui"
            ],
            "affiliations": [
                "ByteDance",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13072.jpg",
            "data": {
                "categories": [
                    "#3d"
                ],
                "emoji": "🏠",
                "ru": {
                    "title": "HiScene: Иерархическая 3D-генерация сцен с композиционной структурой",
                    "desc": "HiScene - это новый иерархический подход к генерации 3D-сцен, который объединяет 2D-генерацию изображений и 3D-генерацию объектов. Метод рассматривает сцены как иерархические 'объекты' в изометрической проекции, где комната функционирует как сложный объект, который можно разложить на отдельные предметы. Используется видео-диффузионная техника для заполнения скрытых частей объектов и инъекция априорной информации о форме для обеспечения пространственной согласованности. Результаты показывают, что HiScene создает более естественные компоновки объектов, подходящие для интерактивных приложений."
                },
                "en": {
                    "title": "HiScene: Bridging 2D and 3D for Interactive Scene Generation",
                    "desc": "This paper introduces HiScene, a new framework for generating 3D scenes that combines the strengths of 2D image generation with 3D object creation. It treats scenes as hierarchical structures, allowing for detailed manipulation of individual elements within a room. The method employs a video-diffusion-based technique for amodal completion, addressing issues like occlusions and shadows to ensure realistic object interactions. Experimental results show that HiScene produces coherent and aesthetically pleasing 3D scenes that are well-suited for interactive applications."
                },
                "zh": {
                    "title": "HiScene：层次化的3D场景生成新方法",
                    "desc": "本论文提出了一种名为HiScene的层次框架，用于场景级3D生成，旨在解决现有方法在对象类别和编辑灵活性方面的局限。我们将场景视为在等距视图下的层次“对象”，使得房间可以被进一步分解为可操作的物品。通过这种层次化的方法，我们能够生成与2D表示相一致的3D内容，同时保持组合结构。我们还开发了一种基于视频扩散的模态补全技术，以处理对象之间的遮挡和阴影，确保每个分解实例的完整性和空间对齐。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13828",
            "title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering",
            "url": "https://huggingface.co/papers/2504.13828",
            "abstract": "The first generation of Large Language Models - what might be called \"Act I\" of generative AI (2020-2023) - achieved remarkable success through massive parameter and data scaling, yet exhibited fundamental limitations in knowledge latency, shallow reasoning, and constrained cognitive processes. During this era, prompt engineering emerged as our primary interface with AI, enabling dialogue-level communication through natural language. We now witness the emergence of \"Act II\" (2024-present), where models are transitioning from knowledge-retrieval systems (in latent space) to thought-construction engines through test-time scaling techniques. This new paradigm establishes a mind-level connection with AI through language-based thoughts. In this paper, we clarify the conceptual foundations of cognition engineering and explain why this moment is critical for its development. We systematically break down these advanced approaches through comprehensive tutorials and optimized implementations, democratizing access to cognition engineering and enabling every practitioner to participate in AI's second act. We provide a regularly updated collection of papers on test-time scaling in the GitHub Repository: https://github.com/GAIR-NLP/cognition-engineering",
            "score": 4,
            "issue_id": 3346,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "f0a8bce0c75eeac0",
            "authors": [
                "Shijie Xia",
                "Yiwei Qin",
                "Xuefeng Li",
                "Yan Ma",
                "Run-Ze Fan",
                "Steffi Chern",
                "Haoyang Zou",
                "Fan Zhou",
                "Xiangkun Hu",
                "Jiahe Jin",
                "Yanheng He",
                "Yixin Ye",
                "Yixiu Liu",
                "Pengfei Liu"
            ],
            "affiliations": [
                "Generative AI Research Lab (GAIR)",
                "SII",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13828.jpg",
            "data": {
                "categories": [
                    "#agi",
                    "#multimodal",
                    "#survey",
                    "#optimization",
                    "#training",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "От извлечения знаний к конструированию мыслей: новая эра ИИ",
                    "desc": "Статья описывает переход от первого поколения больших языковых моделей (LLM) к новому этапу развития искусственного интеллекта. Авторы выделяют ограничения ранних моделей и появление новых методов масштабирования во время выполнения (test-time scaling). Рассматривается концепция 'инженерии познания' (cognition engineering) как нового подхода к взаимодействию с ИИ на уровне мышления. Статья предлагает туториалы и оптимизированные реализации для демократизации доступа к этим передовым технологиям."
                },
                "en": {
                    "title": "From Knowledge Retrieval to Thought Construction in AI",
                    "desc": "This paper discusses the evolution of Large Language Models (LLMs) from their initial phase, termed 'Act I', to a new phase called 'Act II'. In 'Act I', LLMs relied heavily on large datasets and parameters but faced issues like slow knowledge updates and limited reasoning abilities. The current phase, 'Act II', focuses on enhancing these models into thought-construction engines that can generate ideas and insights in real-time. The authors aim to make cognition engineering accessible to all practitioners by providing tutorials and resources for implementing these advanced techniques."
                },
                "zh": {
                    "title": "认知工程的新时代：从知识检索到思维构建",
                    "desc": "本文讨论了大型语言模型的第一代（2020-2023年）和第二代（2024年至今）的发展。第一代模型通过大规模参数和数据扩展取得了显著成功，但在知识延迟、推理浅显和认知过程受限等方面存在基本局限。第二代模型正在通过测试时扩展技术，从知识检索系统转变为思维构建引擎，建立与AI的语言思维连接。我们系统地分析了这些先进方法，并提供了全面的教程和优化实现，以促进认知工程的发展。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13626",
            "title": "Thought Manipulation: External Thought Can Be Efficient for Large\n  Reasoning Models",
            "url": "https://huggingface.co/papers/2504.13626",
            "abstract": "Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities in multiple tasks. However, LRMs typically suffer from \"overthinking\" problems, where models generate significantly redundant reasoning steps while bringing limited performance gains. Existing work relies on fine-tuning to mitigate overthinking, which requires additional data, unconventional training setups, risky safety misalignment, and poor generalization.   Through empirical analysis, we reveal an important characteristic of LRM behaviors that placing external CoTs generated by smaller models between the thinking token (<think> and </think>) can effectively manipulate the model to generate fewer thoughts. Building on these insights, we propose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass unnecessary intermediate steps and reduce computational costs significantly. We conduct extensive experiments to validate the utility and efficiency of ThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code dataset, ThoughtMani keeps the original performance and reduces output token counts by approximately 30%, with little overhead from the CoT generator. Furthermore, we find that ThoughtMani enhances safety alignment by an average of 10%. Since model vendors typically serve models of different sizes simultaneously, ThoughtMani provides an effective way to construct more efficient and accessible LRMs for real-world applications.",
            "score": 4,
            "issue_id": 3340,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "a0b61093ea88a6d7",
            "authors": [
                "Yule Liu",
                "Jingyi Zheng",
                "Zhen Sun",
                "Zifan Peng",
                "Wenhan Dong",
                "Zeyang Sha",
                "Shiwen Cui",
                "Weiqiang Wang",
                "Xinlei He"
            ],
            "affiliations": [
                "Ant Group",
                "Hong Kong University of Science and Technology (Guangzhou)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13626.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#alignment"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Оптимизация рассуждений больших языковых моделей без переобучения",
                    "desc": "Статья представляет метод ThoughtMani для оптимизации работы больших моделей рассуждений (LRM). Авторы обнаружили, что размещение внешних цепочек рассуждений от меньших моделей между специальными токенами позволяет сократить избыточные шаги рассуждений LRM. ThoughtMani снижает количество выходных токенов примерно на 30% без потери производительности и улучшает согласование с требованиями безопасности. Этот подход не требует дополнительного обучения и позволяет эффективно использовать LRM в реальных приложениях."
                },
                "en": {
                    "title": "Streamlining Reasoning: ThoughtMani Reduces Overthinking in LRMs",
                    "desc": "This paper discusses the challenges faced by large reasoning models (LRMs), particularly the issue of 'overthinking' where models produce excessive reasoning steps with minimal performance improvement. The authors propose a novel approach called ThoughtMani, which strategically places external Chains of Thought (CoTs) generated by smaller models to streamline the reasoning process. This method not only reduces the number of unnecessary intermediate steps but also maintains the model's performance while cutting down computational costs by about 30%. Additionally, ThoughtMani improves safety alignment, making it a practical solution for enhancing the efficiency of LRMs in real-world applications."
                },
                "zh": {
                    "title": "ThoughtMani：减少推理步骤，提升效率",
                    "desc": "最近的大型推理模型（LRMs）在多个任务中展示了通过扩展测试时计算来增强推理能力的有效性。然而，LRMs通常会出现“过度思考”问题，模型生成的推理步骤冗余且性能提升有限。现有的研究依赖于微调来缓解过度思考，但这需要额外的数据和复杂的训练设置。我们提出了一种简单高效的管道，ThoughtMani，通过在思考标记之间放置小模型生成的外部链条（CoTs），有效减少不必要的推理步骤，从而显著降低计算成本。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13816",
            "title": "Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through\n  the Lens of Internal Representations",
            "url": "https://huggingface.co/papers/2504.13816",
            "abstract": "While understanding the knowledge boundaries of LLMs is crucial to prevent hallucination, research on knowledge boundaries of LLMs has predominantly focused on English. In this work, we present the first study to analyze how LLMs recognize knowledge boundaries across different languages by probing their internal representations when processing known and unknown questions in multiple languages. Our empirical studies reveal three key findings: 1) LLMs' perceptions of knowledge boundaries are encoded in the middle to middle-upper layers across different languages. 2) Language differences in knowledge boundary perception follow a linear structure, which motivates our proposal of a training-free alignment method that effectively transfers knowledge boundary perception ability across languages, thereby helping reduce hallucination risk in low-resource languages; 3) Fine-tuning on bilingual question pair translation further enhances LLMs' recognition of knowledge boundaries across languages. Given the absence of standard testbeds for cross-lingual knowledge boundary analysis, we construct a multilingual evaluation suite comprising three representative types of knowledge boundary data. Our code and datasets are publicly available at https://github.com/DAMO-NLP-SG/LLM-Multilingual-Knowledge-Boundaries.",
            "score": 2,
            "issue_id": 3347,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "9243c69083d55578",
            "authors": [
                "Chenghao Xiao",
                "Hou Pong Chan",
                "Hao Zhang",
                "Mahani Aljunied",
                "Lidong Bing",
                "Noura Al Moubayed",
                "Yu Rong"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group",
                "Department of Computer Science, Durham University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13816.jpg",
            "data": {
                "categories": [
                    "#hallucinations",
                    "#dataset",
                    "#transfer_learning",
                    "#low_resource",
                    "#open_source",
                    "#training",
                    "#multilingual"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "Преодоление языковых барьеров в понимании пределов знаний ИИ",
                    "desc": "Исследование посвящено анализу восприятия границ знаний языковыми моделями (LLM) в разных языках. Авторы обнаружили, что это восприятие кодируется в средних и верхних слоях моделей и имеет линейную структуру между языками. Предложен метод переноса способности распознавания границ знаний между языками без дополнительного обучения. Также создан многоязычный набор данных для оценки границ знаний LLM."
                },
                "en": {
                    "title": "Bridging Language Gaps in LLM Knowledge Boundaries",
                    "desc": "This paper investigates how large language models (LLMs) understand their limits of knowledge in various languages, addressing a gap in previous research that mainly focused on English. The authors find that LLMs encode their knowledge boundaries in specific layers of their architecture, and that these perceptions vary in a structured way across languages. They propose a method to align knowledge boundary recognition without additional training, which can help reduce inaccuracies in languages with fewer resources. Additionally, fine-tuning LLMs with bilingual question pairs improves their ability to recognize knowledge boundaries, and the authors provide a new multilingual evaluation suite for further research."
                },
                "zh": {
                    "title": "跨语言知识边界的识别与转移",
                    "desc": "本研究首次分析了大型语言模型（LLMs）在不同语言中识别知识边界的能力。研究发现，LLMs对知识边界的感知主要编码在中间层到中上层。不同语言之间的知识边界感知呈线性结构，这促使我们提出了一种无训练的对齐方法，有效地在语言间转移知识边界感知能力，从而降低低资源语言中的幻觉风险。此外，双语问题对翻译的微调进一步增强了LLMs在跨语言识别知识边界的能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.12083",
            "title": "Self-alignment of Large Video Language Models with Refined Regularized\n  Preference Optimization",
            "url": "https://huggingface.co/papers/2504.12083",
            "abstract": "Despite recent advances in Large Video Language Models (LVLMs), they still struggle with fine-grained temporal understanding, hallucinate, and often make simple mistakes on even simple video question-answering tasks, all of which pose significant challenges to their safe and reliable deployment in real-world applications. To address these limitations, we propose a self-alignment framework that enables LVLMs to learn from their own errors. Our proposed framework first obtains a training set of preferred and non-preferred response pairs, where non-preferred responses are generated by incorporating common error patterns that often occur due to inadequate spatio-temporal understanding, spurious correlations between co-occurring concepts, and over-reliance on linguistic cues while neglecting the vision modality, among others. To facilitate self-alignment of LVLMs with the constructed preferred and non-preferred response pairs, we introduce Refined Regularized Preference Optimization (RRPO), a novel preference optimization method that utilizes sub-sequence-level refined rewards and token-wise KL regularization to address the limitations of Direct Preference Optimization (DPO). We demonstrate that RRPO achieves more precise alignment and more stable training compared to DPO. Our experiments and analysis validate the effectiveness of our approach across diverse video tasks, including video hallucination, short- and long-video understanding, and fine-grained temporal reasoning.",
            "score": 1,
            "issue_id": 3351,
            "pub_date": "2025-04-16",
            "pub_date_card": {
                "ru": "16 апреля",
                "en": "April 16",
                "zh": "4月16日"
            },
            "hash": "1ac44e2a3e2a77c4",
            "authors": [
                "Pritam Sarkar",
                "Ali Etemad"
            ],
            "affiliations": [
                "Queens University, Canada",
                "Vector Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.12083.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#hallucinations",
                    "#reasoning",
                    "#rlhf",
                    "#training",
                    "#video",
                    "#alignment"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Самонастройка видеоязыковых моделей для повышения точности и надежности",
                    "desc": "Статья представляет новый метод самонастройки для крупных видеоязыковых моделей (LVLM). Авторы предлагают фреймворк, который позволяет LVLM учиться на собственных ошибках, используя пары предпочтительных и нежелательных ответов. Они вводят новый метод оптимизации предпочтений - Refined Regularized Preference Optimization (RRPO), который улучшает точность настройки и стабильность обучения. Эксперименты подтверждают эффективность подхода для различных задач видеопонимания."
                },
                "en": {
                    "title": "Enhancing Video Language Models Through Self-Alignment",
                    "desc": "This paper addresses the challenges faced by Large Video Language Models (LVLMs) in understanding video content accurately. The authors introduce a self-alignment framework that allows LVLMs to learn from their mistakes by generating preferred and non-preferred response pairs based on common error patterns. They propose a new optimization method called Refined Regularized Preference Optimization (RRPO), which improves the alignment of LVLMs by using refined rewards and regularization techniques. The results show that RRPO enhances training stability and precision in various video-related tasks, including temporal reasoning and video understanding."
                },
                "zh": {
                    "title": "自对齐框架提升视频语言模型的理解能力",
                    "desc": "尽管大型视频语言模型（LVLMs）在技术上取得了进展，但它们在细粒度时间理解方面仍然存在困难，容易产生幻觉，并且在简单的视频问答任务中常常犯错。为了解决这些问题，我们提出了一种自对齐框架，使LVLMs能够从自身错误中学习。该框架首先生成一组包含优选和非优选响应对的训练集，非优选响应是通过引入常见错误模式生成的，这些模式通常由于时空理解不足、共现概念之间的虚假相关性以及过度依赖语言线索而忽视视觉模态等原因而产生。我们引入了一种新的偏好优化方法——精细正则化偏好优化（RRPO），通过子序列级别的精细奖励和逐标记KL正则化来解决直接偏好优化（DPO）的局限性，实验结果表明RRPO在对齐精度和训练稳定性方面优于DPO。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13677",
            "title": "Revisiting Uncertainty Quantification Evaluation in Language Models:\n  Spurious Interactions with Response Length Bias Results",
            "url": "https://huggingface.co/papers/2504.13677",
            "abstract": "Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases.",
            "score": 0,
            "issue_id": 3352,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "cf5640eea0b24520",
            "authors": [
                "Andrea Santilli",
                "Adam Golinski",
                "Michael Kirchhof",
                "Federico Danieli",
                "Arno Blaas",
                "Miao Xiong",
                "Luca Zappella",
                "Sinead Williamson"
            ],
            "affiliations": [
                "Apple",
                "National University of Singapore",
                "Sapienza University of Rome"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13677.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#data",
                    "#hallucinations",
                    "#interpretability"
                ],
                "emoji": "🎭",
                "ru": {
                    "title": "Борьба со смещениями в оценке неопределенности языковых моделей",
                    "desc": "Данная статья исследует проблему оценки неопределенности в языковых моделях. Авторы обнаружили, что распространенные функции корректности искажают оценку методов количественной оценки неопределенности из-за смещений, связанных с длиной текста. Было проанализировано 7 функций корректности на 4 наборах данных с использованием 4 моделей и 6 методов оценки неопределенности. Исследование показало, что подход 'LLM-as-a-judge' наименее подвержен смещению по длине и может помочь снизить эти искажения."
                },
                "en": {
                    "title": "Mitigating Biases in UQ Evaluations with LLM-as-a-Judge",
                    "desc": "This paper discusses the importance of Uncertainty Quantification (UQ) in Language Models (LMs) for enhancing their safety and reliability. It highlights how traditional correctness functions, such as ROUGE-L, can introduce biases that inflate the perceived performance of UQ methods. The authors evaluate various correctness functions across multiple datasets and models, revealing that length biases in these functions distort UQ assessments. They propose LLM-as-a-judge approaches as a promising solution to reduce these biases and improve UQ evaluations."
                },
                "zh": {
                    "title": "提升语言模型安全性的关键：不确定性量化",
                    "desc": "在语言模型中的不确定性量化（UQ）对于提高其安全性和可靠性至关重要。本文展示了常用的正确性函数会通过夸大某些UQ方法的性能来偏见UQ评估。我们评估了7种正确性函数，并发现这些函数的长度偏差会扭曲UQ评估结果。我们指出，LLM作为评判者的方法是最少受长度偏差影响的选择，可能是缓解这些偏差的解决方案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13519",
            "title": "Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for\n  Low-Dose CT with Attention-Guided Bilateral Filtering",
            "url": "https://huggingface.co/papers/2504.13519",
            "abstract": "Effective denoising is crucial in low-dose CT to enhance subtle structures and low-contrast lesions while preventing diagnostic errors. Supervised methods struggle with limited paired datasets, and self-supervised approaches often require multiple noisy images and rely on deep networks like U-Net, offering little insight into the denoising mechanism. To address these challenges, we propose an interpretable self-supervised single-image denoising framework -- Filter2Noise (F2N). Our approach introduces an Attention-Guided Bilateral Filter that adapted to each noisy input through a lightweight module that predicts spatially varying filter parameters, which can be visualized and adjusted post-training for user-controlled denoising in specific regions of interest. To enable single-image training, we introduce a novel downsampling shuffle strategy with a new self-supervised loss function that extends the concept of Noise2Noise to a single image and addresses spatially correlated noise. On the Mayo Clinic 2016 low-dose CT dataset, F2N outperforms the leading self-supervised single-image method (ZS-N2N) by 4.59 dB PSNR while improving transparency, user control, and parametric efficiency. These features provide key advantages for medical applications that require precise and interpretable noise reduction. Our code is demonstrated at https://github.com/sypsyp97/Filter2Noise.git .",
            "score": 0,
            "issue_id": 3348,
            "pub_date": "2025-04-18",
            "pub_date_card": {
                "ru": "18 апреля",
                "en": "April 18",
                "zh": "4月18日"
            },
            "hash": "54a6d11b3dfb1ed4",
            "authors": [
                "Yipeng Sun",
                "Linda-Sophie Schneider",
                "Mingxuan Gu",
                "Siyuan Mei",
                "Chengze Ye",
                "Fabian Wagner",
                "Siming Bayer",
                "Andreas Maier"
            ],
            "affiliations": [
                "Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany",
                "Siemens Healthineers AG, Forchheim, Germany"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13519.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#training",
                    "#interpretability",
                    "#low_resource",
                    "#healthcare",
                    "#dataset"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "Интерпретируемое шумоподавление для КТ: от фильтра к чистоте",
                    "desc": "Статья представляет новый метод шумоподавления для низкодозовой компьютерной томографии под названием Filter2Noise (F2N). Авторы предлагают интерпретируемый самоконтролируемый подход к шумоподавлению, основанный на адаптивном билатеральном фильтре с механизмом внимания. F2N использует инновационную стратегию понижения разрешения и новую функцию потерь для обучения на одном изображении. Метод превосходит существующие подходы, обеспечивая лучшее качество шумоподавления, интерпретируемость и контроль пользователя."
                },
                "en": {
                    "title": "Revolutionizing Low-Dose CT Denoising with Filter2Noise",
                    "desc": "This paper presents Filter2Noise (F2N), a self-supervised framework for denoising low-dose CT images using a single noisy input. Unlike traditional supervised methods that require paired datasets, F2N employs an Attention-Guided Bilateral Filter that adapts to the noise characteristics of each image, allowing for user-controlled adjustments. The framework introduces a novel downsampling shuffle strategy and a self-supervised loss function that effectively handles spatially correlated noise. Experimental results show that F2N significantly improves denoising performance, achieving higher PSNR compared to existing methods while enhancing interpretability and control for medical applications."
                },
                "zh": {
                    "title": "自监督去噪，精准可控！",
                    "desc": "在低剂量CT中，有效去噪对于增强细微结构和低对比度病变至关重要。传统的监督学习方法在有限的配对数据集上表现不佳，而自监督方法通常需要多张噪声图像，并依赖深度网络如U-Net，缺乏对去噪机制的深入理解。为了解决这些问题，我们提出了一种可解释的自监督单图像去噪框架——Filter2Noise (F2N)。该方法引入了一种基于注意力的双边滤波器，能够根据每个噪声输入自适应调整滤波参数，用户可以在训练后可视化和调整这些参数，以实现特定区域的去噪控制。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2504.13359",
            "title": "Cost-of-Pass: An Economic Framework for Evaluating Language Models",
            "url": "https://huggingface.co/papers/2504.13359",
            "abstract": "The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce \"cost-of-pass\", the expected monetary cost of generating a correct solution. We then define the \"frontier cost-of-pass\" as the minimum cost-of-pass achievable across available models or the \"human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers: estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledge-intensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides a principled tool for measuring this progress and guiding deployment.",
            "score": 0,
            "issue_id": 3352,
            "pub_date": "2025-04-17",
            "pub_date_card": {
                "ru": "17 апреля",
                "en": "April 17",
                "zh": "4月17日"
            },
            "hash": "ff1639bd69b70cc7",
            "authors": [
                "Mehmet Hamza Erol",
                "Batu El",
                "Mirac Suzgun",
                "Mert Yuksekgonul",
                "James Zou"
            ],
            "affiliations": [
                "Stanford University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2504.13359.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#benchmark",
                    "#reasoning",
                    "#inference"
                ],
                "emoji": "💹",
                "ru": {
                    "title": "Экономическая эффективность ИИ: новый подход к оценке языковых моделей",
                    "desc": "Статья предлагает новый подход к оценке языковых моделей, основанный на теории производства, который учитывает как точность, так и стоимость вывода. Авторы вводят метрику 'cost-of-pass' - ожидаемую денежную стоимость генерации правильного решения, и 'frontier cost-of-pass' - минимальную достижимую стоимость среди доступных моделей или экспертов-людей. Анализ показывает, что легковесные модели наиболее эффективны для базовых количественных задач, крупные модели - для задач, требующих обширных знаний, а модели рассуждений - для сложных количественных проблем. Исследование также демонстрирует значительный прогресс в снижении 'frontier cost-of-pass' за последний год, особенно для сложных количественных задач."
                },
                "en": {
                    "title": "Balancing Performance and Cost in AI: A New Economic Framework",
                    "desc": "This paper presents a framework for evaluating language models based on their economic value, balancing performance and inference costs. It introduces the concept of 'cost-of-pass', which quantifies the expected monetary cost of producing a correct output. The authors analyze how different types of models—lightweight, large, and reasoning—perform across various tasks, revealing that each type excels in specific areas despite differing costs. Additionally, they highlight the importance of model innovations in improving cost-efficiency and provide insights into the effectiveness of inference-time techniques."
                },
                "zh": {
                    "title": "评估语言模型的经济价值与推理成本",
                    "desc": "本文探讨了人工智能系统在经济中的应用，强调了生成经济价值与推理成本之间的权衡。我们提出了一种基于生产理论的框架，用于评估语言模型的准确性和推理成本。引入了“成本-通过”的概念，表示生成正确解决方案的预期货币成本，并定义了“前沿成本-通过”，即在可用模型中实现的最低成本。我们的分析显示，轻量级模型在基本定量任务中最具成本效益，而大型模型适用于知识密集型任务，推理模型则适合复杂定量问题。"
                }
            }
        }
    ],
    "link_prev": "2025-04-18.html",
    "link_next": "2025-04-22.html",
    "link_month": "2025-04.html",
    "short_date_prev": {
        "ru": "18.04",
        "en": "04/18",
        "zh": "4月18日"
    },
    "short_date_next": {
        "ru": "22.04",
        "en": "04/22",
        "zh": "4月22日"
    },
    "categories": {
        "#dataset": 8,
        "#data": 5,
        "#benchmark": 5,
        "#agents": 0,
        "#cv": 1,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 1,
        "#3d": 2,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 2,
        "#math": 0,
        "#multilingual": 2,
        "#architecture": 1,
        "#healthcare": 1,
        "#training": 8,
        "#robotics": 0,
        "#agi": 1,
        "#games": 1,
        "#interpretability": 2,
        "#reasoning": 8,
        "#transfer_learning": 2,
        "#graphs": 1,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 9,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 3,
        "#story_generation": 0,
        "#hallucinations": 3,
        "#long_context": 0,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 4,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 3
    },
    "zh": {
        "text": "这篇文章讨论了构建有效指令调整数据集的关键因素：数据质量和多样性。随着开源数据集的增加，自动选择高质量且多样的子集变得重要。现有方法主要关注实例质量，使用启发式规则维持多样性，但 often 效果不佳。作者提出了一种新方法，通过构建标签图来模拟语义空间，并基于图中的信息分布量化多样性。实验显示，这种方法在多个数据集和基础模型上都优于现有方法。",
        "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing\n  Information Gain in Semantic Space",
        "pinyin": "这篇文章讨论了构建有效指令调整数据集的关键因素：数据质量和多样性。\nzhè piān wén zhāng tǎo lùn le gòu jiàn yǒu xiào zhǐ lìng tiáo zhěng shù jù de guǎn jiàn yīn sù: shù jù zhì liàng hé duō yàng xìng.\n\n随着开源数据集的增加，自动选择高质量且多样的子集变得重要。\nsuí zhe kāi yuán shù jù jí de zēng jiā, zì dòng xuǎn zé gāo zhì liàng qiě duō yàng de zǐ jí biàn de zhòng yào.\n\n现有方法主要关注实例质量，使用启发式规则维持多样性，但 often 效果不佳。\nxiàn yǒu fāng fǎ zhǔ yào guān zhù shí lì zhì liàng, shǐ yòng qǐ fā shì guī zé wéi chí duō yàng xìng, dàn often xiào guǒ bù jiā.\n\n作者提出了一种新方法，通过构建标签图来模拟语义空间，并基于图中的信息分布量化多样性。\nzuò zhě tí chū le yī zhǒng xīn fāng fǎ, tōng guò gòu jiàn biāo qiān tú lái mó nǐ yǔ yì kōng jiān, bìng jī yú tú zhōng de xìn xī fēn bù liàng huà duō yàng xìng.\n\n实验显示，这种方法在多个数据集和基础模型上都优于现有方法。\nshí yàn xiǎn shì, zhè zhǒng fāng fǎ zài duō gè shù jù jí hé jī chǔ mó xíng shàng dōu yōu yú xiàn yǒu fāng fǎ.",
        "vocab": "[\n    {\"word\": \"构建\", \"pinyin\": \"gòujiàn\", \"trans\": \"construct\"},\n    {\"word\": \"有效\", \"pinyin\": \"yǒuxiào\", \"trans\": \"effective\"},\n    {\"word\": \"指令\", \"pinyin\": \"zhǐlìng\", \"trans\": \"instruction\"},\n    {\"word\": \"调整\", \"pinyin\": \"tiáozhěng\", \"trans\": \"adjust\"},\n    {\"word\": \"数据集\", \"pinyin\": \"shùjùjí\", \"trans\": \"dataset\"},\n    {\"word\": \"关键因素\", \"pinyin\": \"guǎnjiàn yīnsù\", \"trans\": \"key factors\"},\n    {\"word\": \"质量\", \"pinyin\": \"zhìliàng\", \"trans\": \"quality\"},\n    {\"word\": \"多样性\", \"pinyin\": \"duōyàngxìng\", \"trans\": \"diversity\"},\n    {\"word\": \"开源\", \"pinyin\": \"kāiyuán\", \"trans\": \"open-source\"},\n    {\"word\": \"自动\", \"pinyin\": \"zìdòng\", \"trans\": \"automatic\"},\n    {\"word\": \"选择\", \"pinyin\": \"xuǎnzé\", \"trans\": \"select\"},\n    {\"word\": \"子集\", \"pinyin\": \"zǐjí\", \"trans\": \"subset\"},\n    {\"word\": \"变得\", \"pinyin\": \"biàndé\", \"trans\": \"become\"},\n    {\"word\": \"重要\", \"pinyin\": \"zhòngyào\", \"trans\": \"important\"},\n    {\"word\": \"现有\", \"pinyin\": \"xiànyǒu\", \"trans\": \"existing\"},\n    {\"word\": \"方法\", \"pinyin\": \"fāngfǎ\", \"trans\": \"method\"},\n    {\"word\": \"主要\", \"pinyin\": \"zhǔyào\", \"trans\": \"main\"},\n    {\"word\": \"关注\", \"pinyin\": \"guānzhù\", \"trans\": \"focus on\"},\n    {\"word\": \"实例\", \"pinyin\": \"shílì\", \"trans\": \"instance\"},\n    {\"word\": \"启发式\", \"pinyin\": \"qǐfāshì\", \"trans\": \"heuristic\"},\n    {\"word\": \"规则\", \"pinyin\": \"guīzé\", \"trans\": \"rule\"},\n    {\"word\": \"维持\", \"pinyin\": \"wéichí\", \"trans\": \"maintain\"},\n    {\"word\": \"效果\", \"pinyin\": \"xiàoguǒ\", \"trans\": \"effect\"},\n    {\"word\": \"不佳\", \"pinyin\": \"bùjiā\", \"trans\": \"poor\"},\n    {\"word\": \"作者\", \"pinyin\": \"zuòzhě\", \"trans\": \"author\"},\n    {\"word\": \"提出\", \"pinyin\": \"tíchū\", \"trans\": \"propose\"},\n    {\"word\": \"新方法\", \"pinyin\": \"xīn fāngfǎ\", \"trans\": \"new method\"},\n    {\"word\": \"通过\", \"pinyin\": \"tōngguò\", \"trans\": \"through\"},\n    {\"word\": \"标签\", \"pinyin\": \"biāoqiān\", \"trans\": \"label\"},\n    {\"word\": \"图\", \"pinyin\": \"tú\", \"trans\": \"graph\"},\n    {\"word\": \"模拟\", \"pinyin\": \"mónǐ\", \"trans\": \"simulate\"},\n    {\"word\": \"语义\", \"pinyin\": \"yǔyì\", \"trans\": \"semantic\"},\n    {\"word\": \"空间\", \"pinyin\": \"kōngjiān\", \"trans\": \"space\"},\n    {\"word\": \"基于\", \"pinyin\": \"jīyú\", \"trans\": \"based on\"},\n    {\"word\": \"信息\", \"pinyin\": \"xìnxī\", \"trans\": \"information\"},\n    {\"word\": \"分布\", \"pinyin\": \"fēnbù\", \"trans\": \"distribution\"},\n    {\"word\": \"量化\", \"pinyin\": \"liànghuà\", \"trans\": \"quantify\"},\n    {\"word\": \"实验\", \"pinyin\": \"shíyàn\", \"trans\": \"experiment\"},\n    {\"word\": \"显示\", \"pinyin\": \"xiǎnshì\", \"trans\": \"show\"},\n    {\"word\": \"优于\", \"pinyin\": \"yōuyú\", \"trans\": \"superior to\"},\n    {\"word\": \"基础\", \"pinyin\": \"jīchǔ\", \"trans\": \"foundation\"},\n    {\"word\": \"模型\", \"pinyin\": \"móxíng\", \"trans\": \"model\"}\n]",
        "trans": "This article discusses the key factors in constructing an effective dataset for instruction tuning: data quality and diversity. As the number of open-source datasets increases, it becomes important to automatically select high-quality and diverse subsets. Existing methods primarily focus on instance quality, using heuristic rules to maintain diversity, but often with limited effectiveness. The authors propose a new method that constructs a label graph to simulate semantic space and quantifies diversity based on the distribution of information in the graph. Experiments show that this method outperforms existing methods across multiple datasets and base models.",
        "update_ts": "2025-04-21 09:12"
    }
}