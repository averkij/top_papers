{
    "date": {
        "ru": "15 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
        "en": "September 15",
        "zh": "9æœˆ15æ—¥"
    },
    "time_utc": "2025-09-15 05:12",
    "weekday": 0,
    "issue_id": 5886,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.09677",
            "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in\n  LLMs",
            "url": "https://huggingface.co/papers/2509.09677",
            "abstract": "Scaling large language models improves their ability to execute longer tasks by isolating execution capability and mitigating self-conditioning effects, despite diminishing single-step accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.",
            "score": 7,
            "issue_id": 5883,
            "pub_date": "2025-09-11",
            "pub_date_card": {
                "ru": "11 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 11",
                "zh": "9æœˆ11æ—¥"
            },
            "hash": "03dddc4470e66eb9",
            "authors": [
                "Akshit Sinha",
                "Arvindh Arun",
                "Shashwat Goel",
                "Steffen Staab",
                "Jonas Geiping"
            ],
            "affiliations": [
                "ELLIS Institute TÃ¼bingen",
                "Institute for AI, University of Stuttgart",
                "Max Planck Institute for Intelligent Systems",
                "TÃ¼bingen AI Center",
                "University of Cambridge",
                "University of Southampton"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09677.jpg",
            "data": {
                "categories": [
                    "#long_context",
                    "#architecture",
                    "#reasoning",
                    "#benchmark",
                    "#rl"
                ],
                "emoji": "ğŸ“ˆ",
                "ru": {
                    "title": "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ LLM: Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ½Ğ° Ğ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ñƒ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑˆĞ°Ğ³Ğ¾Ğ². Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ² Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ ÑĞ²ÑĞ·Ğ°Ğ½Ñ‹ Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ğ¼Ğ¸ Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸, Ğ° Ğ½Ğµ Ñ Ğ½ĞµÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´Ğ°Ñ‚ÑŒ. ĞšÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ³Ğ¾, Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¾ ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑĞ»Ğ¾Ğ²Ğ»Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ÑÑ‚ÑÑ Ğ±Ğ¾Ğ»ĞµĞµ ÑĞºĞ»Ğ¾Ğ½Ğ½Ñ‹ Ğº Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼ Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğ¸ Ğ¸Ñ… Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ."
                },
                "en": {
                    "title": "Scaling Models for Better Long-Task Execution",
                    "desc": "This paper explores how scaling large language models (LLMs) enhances their performance on longer tasks, despite a decrease in accuracy for individual steps. The authors argue that the challenges LLMs face with extended tasks stem from execution errors rather than reasoning limitations. They propose a method to isolate execution capability by providing explicit knowledge and planning for long-horizon tasks. The findings suggest that larger models can handle more complex tasks effectively, even when smaller models achieve perfect accuracy on single-step tasks, highlighting the importance of model size and compute resources for task execution."
                },
                "zh": {
                    "title": "æ‰©å¤§æ¨¡å‹è§„æ¨¡ï¼Œæå‡é•¿ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ‰§è¡Œé•¿ä»»åŠ¡æ—¶çš„èƒ½åŠ›æå‡ï¼Œå°½ç®¡å•æ­¥å‡†ç¡®ç‡å¯èƒ½ä¸‹é™ã€‚æˆ‘ä»¬å‘ç°ï¼Œå•æ­¥å‡†ç¡®ç‡çš„å¾®å°æå‡å¯ä»¥åœ¨ä»»åŠ¡é•¿åº¦ä¸Šå¸¦æ¥æŒ‡æ•°çº§çš„æ”¹å–„ã€‚æˆ‘ä»¬æå‡ºé€šè¿‡æ˜ç¡®æä¾›è§£å†³é•¿æ—¶é—´ä»»åŠ¡æ‰€éœ€çš„çŸ¥è¯†å’Œè®¡åˆ’æ¥éš”ç¦»æ‰§è¡Œèƒ½åŠ›ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡å°æ¨¡å‹åœ¨å•æ­¥ä»»åŠ¡ä¸­è¡¨ç°å®Œç¾ï¼Œä½†å¤§å‹æ¨¡å‹åœ¨æ‰§è¡Œå¤šè½®ä»»åŠ¡æ—¶çš„è¡¨ç°æ˜¾è‘—æ›´å¥½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09716",
            "title": "VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions",
            "url": "https://huggingface.co/papers/2509.09716",
            "abstract": "Voice Style Adaptation (VSA) evaluates the ability of spoken language models to modify their speaking style based on spoken instructions, using a bilingual benchmark and a Large Audio Language Model as a Judge framework.  \t\t\t\t\tAI-generated summary \t\t\t\t Spoken language models (SLMs) have emerged as a unified paradigm for speech understanding and generation, enabling natural human machine interaction. However, while most progress has focused on semantic accuracy and instruction following, the ability of SLMs to adapt their speaking style based on spoken instructions has received limited attention. We introduce Voice Style Adaptation (VSA), a new task that examines whether SLMs can modify their speaking style, such as timbre, prosody, or persona following natural language spoken commands. To study this task, we present VStyle, a bilingual (Chinese & English) benchmark covering four categories of speech generation: acoustic attributes, natural language instruction, role play, and implicit empathy. We also introduce the Large Audio Language Model as a Judge (LALM as a Judge) framework, which progressively evaluates outputs along textual faithfulness, style adherence, and naturalness, ensuring reproducible and objective assessment. Experiments on commercial systems and open source SLMs demonstrate that current models face clear limitations in controllable style adaptation, highlighting both the novelty and challenge of this task. By releasing VStyle and its evaluation toolkit, we aim to provide the community with a foundation for advancing human centered spoken interaction. The dataset and code are publicly available at https://junzhan2000.github.io/VStyle.github.io/{project's homepage}.",
            "score": 6,
            "issue_id": 5883,
            "pub_date": "2025-09-09",
            "pub_date_card": {
                "ru": "9 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 9",
                "zh": "9æœˆ9æ—¥"
            },
            "hash": "a1fdfdb8fb8b7486",
            "authors": [
                "Jun Zhan",
                "Mingyang Han",
                "Yuxuan Xie",
                "Chen Wang",
                "Dong Zhang",
                "Kexin Huang",
                "Haoxiang Shi",
                "DongXiao Wang",
                "Tengtao Song",
                "Qinyuan Cheng",
                "Shimin Li",
                "Jun Song",
                "Xipeng Qiu",
                "Bo Zheng"
            ],
            "affiliations": [
                "Alibaba Group",
                "Fudan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09716.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#audio",
                    "#dataset",
                    "#alignment",
                    "#multilingual",
                    "#benchmark"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ€ÑƒĞ±ĞµĞ¶ Ğ² Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ğ˜Ğ˜: Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ğ¸Ğ»Ñ Ñ€ĞµÑ‡Ğ¸ Ğ¿Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ğ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Voice Style Adaptation (VSA), ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ Ñ€ĞµÑ‡Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑƒÑÑ‚Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ğ´Ğ²ÑƒÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº VStyle Ğ´Ğ»Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑ‡Ğ¸. ĞĞ½Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Large Audio Language Model as a Judge Ğ´Ğ»Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ¼ĞµÑÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ² ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ¸Ğ»Ñ Ñ€ĞµÑ‡Ğ¸."
                },
                "en": {
                    "title": "Transforming Speech: Adapting Style with Voice Commands",
                    "desc": "Voice Style Adaptation (VSA) is a new task that tests how well spoken language models (SLMs) can change their speaking style based on spoken commands. This includes adjusting aspects like tone, rhythm, and character portrayal. The study introduces a bilingual benchmark called VStyle, which evaluates SLMs on various speech generation categories, including acoustic features and empathy. The research highlights the limitations of current models in adapting their style, aiming to improve human-machine interaction through better control of speech characteristics."
                },
                "zh": {
                    "title": "è¯­éŸ³é£æ ¼é€‚åº”ï¼šè®©æœºå™¨æ›´æ‡‚äººç±»çš„è¯´è¯é£æ ¼",
                    "desc": "è¯­éŸ³é£æ ¼é€‚åº”ï¼ˆVSAï¼‰æ˜¯ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°å£è¯­æ¨¡å‹æ ¹æ®å£å¤´æŒ‡ä»¤è°ƒæ•´è¯´è¯é£æ ¼çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†VStyleï¼Œè¿™æ˜¯ä¸€ä¸ªåŒè¯­åŸºå‡†ï¼Œæ¶µç›–äº†å£°å­¦å±æ€§ã€è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€è§’è‰²æ‰®æ¼”å’Œéšæ€§å…±æƒ…ç­‰å››ä¸ªç±»åˆ«çš„è¯­éŸ³ç”Ÿæˆã€‚é€šè¿‡å¼•å…¥å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„ä¼°æ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå®¢è§‚åœ°è¯„ä¼°æ¨¡å‹åœ¨æ–‡æœ¬å¿ å®æ€§ã€é£æ ¼éµå¾ªå’Œè‡ªç„¶æ€§æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æ¨¡å‹åœ¨å¯æ§é£æ ¼é€‚åº”æ–¹é¢å­˜åœ¨æ˜æ˜¾å±€é™ï¼Œçªæ˜¾äº†è¿™ä¸€ä»»åŠ¡çš„æ–°é¢–æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10147",
            "title": "Virtual Agent Economies",
            "url": "https://huggingface.co/papers/2509.10147",
            "abstract": "The sandbox economy framework analyzes the emerging AI agent economy, focusing on its origins and permeability, and discusses design choices for safe and steerable AI markets.  \t\t\t\t\tAI-generated summary \t\t\t\t The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agents transact and coordinate at scales and speeds beyond direct human oversight. We propose the \"sandbox economy\" as a framework for analyzing this emergent system, characterizing it along two key dimensions: its origins (emergent vs. intentional) and its degree of separateness from the established human economy (permeable vs. impermeable). Our current trajectory points toward a spontaneous emergence of a vast and highly permeable AI agent economy, presenting us with opportunities for an unprecedented degree of coordination as well as significant challenges, including systemic economic risk and exacerbated inequality. Here we discuss a number of possible design choices that may lead to safely steerable AI agent markets. In particular, we consider auction mechanisms for fair resource allocation and preference resolution, the design of AI \"mission economies\" to coordinate around achieving collective goals, and socio-technical infrastructure needed to ensure trust, safety, and accountability. By doing this, we argue for the proactive design of steerable agent markets to ensure the coming technological shift aligns with humanity's long-term collective flourishing.",
            "score": 3,
            "issue_id": 5884,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "2fd9f178e62d64b0",
            "authors": [
                "Nenad Tomasev",
                "Matija Franklin",
                "Joel Z. Leibo",
                "Julian Jacobs",
                "William A. Cunningham",
                "Iason Gabriel",
                "Simon Osindero"
            ],
            "affiliations": [
                "Google DeepMind",
                "University of Toronto"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10147.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#ethics",
                    "#alignment"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞŸÑ€Ğ¾ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ³Ğ¾ Ğ±Ğ»Ğ°Ğ³Ğ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ 'ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ğ¸Ñ†Ñ‹' Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ·Ğ°Ñ€Ğ¾Ğ¶Ğ´Ğ°ÑÑ‰ĞµĞ¹ÑÑ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ Ğ´Ğ²Ğ° ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ°: Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ (ÑĞ¿Ğ¾Ğ½Ñ‚Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ½Ğ¾Ğµ) Ğ¸ ÑÑ‚ĞµĞ¿ĞµĞ½ÑŒ Ğ¾Ñ‚Ğ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸. ĞĞ±ÑÑƒĞ¶Ğ´Ğ°ÑÑ‚ÑÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ€Ğ¸ÑĞºĞ¸, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸ĞµĞ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€Ğ¸ÑĞºĞ¸ Ğ¸ ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµÑ€Ğ°Ğ²ĞµĞ½ÑÑ‚Ğ²Ğ°. ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ÑÑ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ñ… Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ñ… Ñ€Ñ‹Ğ½ĞºĞ¾Ğ² Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ°ÑƒĞºÑ†Ğ¸Ğ¾Ğ½Ñ‹ Ğ´Ğ»Ñ ÑĞ¿Ñ€Ğ°Ğ²ĞµĞ´Ğ»Ğ¸Ğ²Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¸ 'Ğ¼Ğ¸ÑÑĞ¸Ğ¾Ğ½ĞµÑ€ÑĞºĞ¸Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸' Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ†ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Navigating the Future: Designing Safe AI Agent Economies",
                    "desc": "The paper introduces the 'sandbox economy' framework to analyze the new economic landscape created by autonomous AI agents. It highlights two main aspects: the origins of these agents, whether they emerge spontaneously or are intentionally designed, and their connection to the existing human economy, which can be either permeable or impermeable. The authors emphasize the potential benefits of this AI agent economy, such as enhanced coordination, while also warning of risks like economic instability and inequality. They propose design strategies, including auction mechanisms and mission-oriented AI systems, to create safe and effective markets for AI agents that align with human values."
                },
                "zh": {
                    "title": "è®¾è®¡å¯æ§çš„AIä»£ç†å¸‚åœºï¼Œè¿æ¥ç»æµæ–°æœºé‡",
                    "desc": "è¿™ç¯‡è®ºæ–‡åˆ†æäº†æ–°å…´çš„äººå·¥æ™ºèƒ½ä»£ç†ç»æµï¼Œæå‡ºäº†â€œæ²™ç›’ç»æµâ€æ¡†æ¶æ¥ç†è§£è¿™ä¸€ç³»ç»Ÿã€‚å®ƒä¸»è¦å…³æ³¨äººå·¥æ™ºèƒ½ä»£ç†çš„èµ·æºå’Œä¸äººç±»ç»æµçš„å…³ç³»ï¼Œæ¢è®¨äº†å®‰å…¨å¯æ§çš„AIå¸‚åœºè®¾è®¡é€‰æ‹©ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒAIä»£ç†ç»æµçš„è‡ªå‘å‡ºç°å¯èƒ½å¸¦æ¥å‰æ‰€æœªæœ‰çš„åè°ƒæœºä¼šï¼Œä½†ä¹Ÿä¼´éšç³»ç»Ÿæ€§ç»æµé£é™©å’Œä¸å¹³ç­‰åŠ å‰§çš„æŒ‘æˆ˜ã€‚ä½œè€…å»ºè®®é€šè¿‡æ‹å–æœºåˆ¶å’ŒAIâ€œä½¿å‘½ç»æµâ€çš„è®¾è®¡ï¼Œç¡®ä¿èµ„æºåˆ†é…çš„å…¬å¹³æ€§å’Œä¿¡ä»»ã€å®‰å…¨ã€é—®è´£çš„ç¤¾ä¼šæŠ€æœ¯åŸºç¡€è®¾æ–½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09734",
            "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with\n  MCP-Mediated Tools",
            "url": "https://huggingface.co/papers/2509.09734",
            "abstract": "MCP-AgentBench is a benchmark designed to evaluate language agents in MCP-mediated tool interactions, providing a standardized framework for assessing real-world performance.  \t\t\t\t\tAI-generated summary \t\t\t\t The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, designed to enhance agent-tool integration and interoperability, and is positioned to unlock a new era of powerful, interconnected, and genuinely utilitarian agentic AI. However, despite MCP's growing adoption, existing benchmarks often fail to capture real-world agent performance within this new paradigm, leading to a distorted perception of their true operational value and an inability to reliably differentiate proficiencies. To bridge this critical evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark specifically engineered to rigorously assess language agent capabilities in MCP-mediated tool interactions. Core contributions of MCP-AgentBench include: the establishment of a robust MCP testbed comprising 33 operational servers with 188 distinct tools; the development of a benchmark featuring 600 systematically designed queries distributed across 6 distinct categories of varying interaction complexity; and the introduction of MCP-Eval, a novel outcome-oriented evaluation methodology prioritizing real-world task success. Through extensive empirical evaluation of leading language agents, we provide foundational insights. MCP-AgentBench aims to equip the research community with a standardized and reliable framework to build, validate, and advance agents capable of fully leveraging MCP's transformative benefits, thereby accelerating progress toward truly capable and interoperable AI systems.",
            "score": 3,
            "issue_id": 5883,
            "pub_date": "2025-09-10",
            "pub_date_card": {
                "ru": "10 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 10",
                "zh": "9æœˆ10æ—¥"
            },
            "hash": "56883c4d7c401e99",
            "authors": [
                "Zikang Guo",
                "Benfeng Xu",
                "Chiwei Zhu",
                "Wentao Hong",
                "Xiaorui Wang",
                "Zhendong Mao"
            ],
            "affiliations": [
                "Metastone Technology, Beijing, China",
                "University of Science and Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09734.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#agents",
                    "#benchmark"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¼Ğ¸Ñ€Ğµ",
                    "desc": "MCP-AgentBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» MCP. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ Ñ‚ĞµÑÑ‚Ğ¾Ğ²ÑƒÑ ÑÑ€ĞµĞ´Ñƒ Ñ 33 ÑĞµÑ€Ğ²ĞµÑ€Ğ°Ğ¼Ğ¸ Ğ¸ 188 Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ 600 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ MCP-Eval, Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. MCP-AgentBench Ğ¿Ñ€Ğ¸Ğ·Ğ²Ğ°Ğ½ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° MCP."
                },
                "en": {
                    "title": "Empowering Language Agents with MCP-AgentBench",
                    "desc": "MCP-AgentBench is a benchmark created to evaluate language agents that interact with tools using the Model Context Protocol (MCP). It addresses the shortcomings of existing benchmarks by providing a standardized framework that reflects real-world performance. The benchmark includes a testbed with 33 servers and 188 tools, along with 600 queries across various complexity levels. By introducing a new evaluation method focused on task success, MCP-AgentBench aims to enhance the development of more effective and interconnected AI systems."
                },
                "zh": {
                    "title": "MCP-AgentBenchï¼šè¯„ä¼°è¯­è¨€ä»£ç†çš„æ–°æ ‡å‡†",
                    "desc": "MCP-AgentBenchæ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€ä»£ç†åœ¨MCPä»‹å¯¼çš„å·¥å…·äº¤äº’ä¸­çš„è¡¨ç°ã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ¡†æ¶ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°è¯„ä¼°ä»£ç†åœ¨ç°å®ä¸–ç•Œä¸­çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…æ‹¬33ä¸ªæ“ä½œæœåŠ¡å™¨å’Œ188ç§ä¸åŒå·¥å…·ï¼Œè®¾è®¡äº†600ä¸ªç³»ç»ŸåŒ–çš„æŸ¥è¯¢ï¼Œæ¶µç›–6ç§ä¸åŒå¤æ‚åº¦çš„äº¤äº’ç±»åˆ«ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒMCP-AgentBenchå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£å’Œæå‡ä»£ç†çš„æ€§èƒ½ï¼Œæ¨åŠ¨æ™ºèƒ½ä»£ç†çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10441",
            "title": "InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis",
            "url": "https://huggingface.co/papers/2509.10441",
            "abstract": "InfGen, a one-step generator replacing the VAE decoder, enables arbitrary high-resolution image generation from a fixed-size latent, significantly reducing computational complexity and generation time.  \t\t\t\t\tAI-generated summary \t\t\t\t Arbitrary resolution image generation provides a consistent visual experience across devices, having extensive applications for producers and consumers. Current diffusion models increase computational demand quadratically with resolution, causing 4K image generation delays over 100 seconds. To solve this, we explore the second generation upon the latent diffusion models, where the fixed latent generated by diffusion models is regarded as the content representation and we propose to decode arbitrary resolution images with a compact generated latent using a one-step generator. Thus, we present the InfGen, replacing the VAE decoder with the new generator, for generating images at any resolution from a fixed-size latent without retraining the diffusion models, which simplifies the process, reducing computational complexity and can be applied to any model using the same latent space. Experiments show InfGen is capable of improving many models into the arbitrary high-resolution era while cutting 4K image generation time to under 10 seconds.",
            "score": 2,
            "issue_id": 5883,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "c6a96819cd15917d",
            "authors": [
                "Tao Han",
                "Wanghan Xu",
                "Junchao Gong",
                "Xiaoyu Yue",
                "Song Guo",
                "Luping Zhou",
                "Lei Bai"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Shanghai Artificial Intelligence Laboratory",
                "The University of Sydney"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10441.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#cv",
                    "#architecture",
                    "#diffusion"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "InfGen: Ğ¼Ğ³Ğ½Ğ¾Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ",
                    "desc": "InfGen - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ·Ğ°Ğ¼ĞµĞ½ÑÑÑ‰Ğ¸Ğ¹ Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€ VAE Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸. ĞĞ½ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°. InfGen Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ½Ğ¸Ğ¶Ğ°ĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ InfGen ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ÑĞ²ĞµÑ€Ñ…Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ, ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ğ² Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ 4K-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ¾ Ğ¼ĞµĞ½ĞµĞµ 10 ÑĞµĞºÑƒĞ½Ğ´."
                },
                "en": {
                    "title": "Revolutionizing High-Resolution Image Generation with InfGen",
                    "desc": "InfGen is a novel one-step generator that replaces the traditional VAE decoder, allowing for high-resolution image generation from a fixed-size latent representation. This approach significantly reduces the computational complexity and generation time associated with creating images, particularly at 4K resolution. By utilizing a compact generated latent from diffusion models, InfGen enables arbitrary resolution outputs without the need for retraining existing models. Experiments demonstrate that InfGen can enhance various models, achieving 4K image generation in under 10 seconds, thus streamlining the image generation process."
                },
                "zh": {
                    "title": "InfGenï¼šé«˜æ•ˆç”Ÿæˆä»»æ„åˆ†è¾¨ç‡å›¾åƒçš„åˆ›æ–°è§£å†³æ–¹æ¡ˆ",
                    "desc": "InfGenæ˜¯ä¸€ç§æ–°å‹ç”Ÿæˆå™¨ï¼Œå–ä»£äº†å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰çš„è§£ç å™¨ï¼Œèƒ½å¤Ÿä»å›ºå®šå¤§å°çš„æ½œåœ¨ç©ºé—´ç”Ÿæˆä»»æ„é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚æ€§å’Œç”Ÿæˆæ—¶é—´ï¼Œä½¿å¾—ç”Ÿæˆ4Kå›¾åƒçš„æ—¶é—´ç¼©çŸ­åˆ°10ç§’ä»¥å†…ã€‚é€šè¿‡å°†æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›ºå®šæ½œåœ¨è§†ä¸ºå†…å®¹è¡¨ç¤ºï¼ŒInfGenèƒ½å¤Ÿåœ¨ä¸é‡æ–°è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œè§£ç ä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒã€‚å®éªŒè¡¨æ˜ï¼ŒInfGenå¯ä»¥æå‡å¤šç§æ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨åŠ¨é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆçš„è¿›ç¨‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09995",
            "title": "QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading",
            "url": "https://huggingface.co/papers/2509.09995",
            "abstract": "QuantAgent, a multi-agent LLM framework, excels in high-frequency trading by leveraging specialized agents for technical indicators, chart patterns, trends, and risk, outperforming existing neural and rule-based systems.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Large Language Models (LLMs) have demonstrated impressive capabilities in financial reasoning and market understanding. Multi-agent LLM frameworks such as TradingAgent and FINMEM augment these models to long-horizon investment tasks, leveraging fundamental and sentiment-based inputs for strategic decision-making. However, such systems are ill-suited for the high-speed, precision-critical demands of High-Frequency Trading (HFT). HFT requires rapid, risk-aware decisions based on structured, short-horizon signals, including technical indicators, chart patterns, and trend-based features, distinct from the long-term semantic reasoning typical of traditional financial LLM applications. To this end, we introduce QuantAgent, the first multi-agent LLM framework explicitly designed for high-frequency algorithmic trading. The system decomposes trading into four specialized agents, Indicator, Pattern, Trend, and Risk, each equipped with domain-specific tools and structured reasoning capabilities to capture distinct aspects of market dynamics over short temporal windows. In zero-shot evaluations across ten financial instruments, including Bitcoin and Nasdaq futures, QuantAgent demonstrates superior performance in both predictive accuracy and cumulative return over 4-hour trading intervals, outperforming strong neural and rule-based baselines. Our findings suggest that combining structured financial priors with language-native reasoning unlocks new potential for traceable, real-time decision systems in high-frequency financial markets.",
            "score": 2,
            "issue_id": 5883,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "5964ddeaa46fcc92",
            "authors": [
                "Fei Xiong",
                "Xiang Zhang",
                "Aosong Feng",
                "Siqi Sun",
                "Chenyu You"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "Fudan University",
                "Stony Brook University",
                "University of British Columbia",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09995.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#science",
                    "#multimodal",
                    "#agents",
                    "#reasoning",
                    "#games"
                ],
                "emoji": "ğŸ“ˆ",
                "ru": {
                    "title": "QuantAgent: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "QuantAgent - ÑÑ‚Ğ¾ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM), Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ°: Indicator, Pattern, Trend Ğ¸ Risk, ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¸Ğ· ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ¾ÑĞ½Ğ°Ñ‰ĞµĞ½ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ¾Ğ² Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ¸ Ğ² ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºĞ½Ğ°Ñ…. Ğ’ Ñ…Ğ¾Ğ´Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½Ğ° Ğ´ĞµÑÑÑ‚Ğ¸ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ… QuantAgent Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ» Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğº Ğ² Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ‚Ğ°Ğº Ğ¸ Ğ² ĞºÑƒĞ¼ÑƒĞ»ÑÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ° 4-Ñ‡Ğ°ÑĞ¾Ğ²Ñ‹Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ñ‹, Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾Ğ¹Ğ´Ñ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°Ñ… Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ñ‡ĞµÑ‚Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¾Ğ² Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ½Ğ° Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ñ… Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ñ€Ñ‹Ğ½ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Revolutionizing High-Frequency Trading with Specialized Agents",
                    "desc": "QuantAgent is a multi-agent framework designed for high-frequency trading (HFT) that utilizes specialized agents to analyze technical indicators, chart patterns, trends, and risk. Unlike traditional large language models (LLMs) that focus on long-term investment strategies, QuantAgent is tailored for rapid decision-making in fast-paced trading environments. Each agent within the framework is equipped with specific tools to effectively interpret short-term market signals. In tests, QuantAgent outperformed existing neural and rule-based systems, demonstrating its effectiveness in achieving higher predictive accuracy and returns in HFT scenarios."
                },
                "zh": {
                    "title": "QuantAgentï¼šé«˜é¢‘äº¤æ˜“çš„æ™ºèƒ½å†³ç­–æ–°å·¥å…·",
                    "desc": "QuantAgent æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œä¸“é—¨ä¸ºé«˜é¢‘äº¤æ˜“è®¾è®¡ã€‚å®ƒé€šè¿‡å››ä¸ªä¸“ä¸šä»£ç†ï¼ˆæŠ€æœ¯æŒ‡æ ‡ã€å›¾è¡¨æ¨¡å¼ã€è¶‹åŠ¿å’Œé£é™©ï¼‰æ¥å¤„ç†å¸‚åœºåŠ¨æ€ï¼Œèƒ½å¤Ÿå¿«é€Ÿåšå‡ºåŸºäºçŸ­æœŸä¿¡å·çš„å†³ç­–ã€‚ä¸ä¼ ç»Ÿçš„é‡‘èå¤§è¯­è¨€æ¨¡å‹ä¸åŒï¼ŒQuantAgent æ›´åŠ æ³¨é‡å¿«é€Ÿã€ç²¾å‡†çš„äº¤æ˜“éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQuantAgent åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œç´¯è®¡æ”¶ç›Šæ–¹é¢ä¼˜äºç°æœ‰çš„ç¥ç»ç½‘ç»œå’Œè§„åˆ™åŸºç¡€ç³»ç»Ÿã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09713",
            "title": "HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented\n  Generation for Multi-hop Question Answering",
            "url": "https://huggingface.co/papers/2509.09713",
            "abstract": "HANRAG, a heuristic-based framework, improves question-answering systems by efficiently handling multi-hop queries and reducing noise through query decomposition and filtering.  \t\t\t\t\tAI-generated summary \t\t\t\t The Retrieval-Augmented Generation (RAG) approach enhances question-answering systems and dialogue generation tasks by integrating information retrieval (IR) technologies with large language models (LLMs). This strategy, which retrieves information from external knowledge bases to bolster the response capabilities of generative models, has achieved certain successes. However, current RAG methods still face numerous challenges when dealing with multi-hop queries. For instance, some approaches overly rely on iterative retrieval, wasting too many retrieval steps on compound queries. Additionally, using the original complex query for retrieval may fail to capture content relevant to specific sub-queries, resulting in noisy retrieved content. If the noise is not managed, it can lead to the problem of noise accumulation. To address these issues, we introduce HANRAG, a novel heuristic-based framework designed to efficiently tackle problems of varying complexity. Driven by a powerful revelator, HANRAG routes queries, decomposes them into sub-queries, and filters noise from retrieved documents. This enhances the system's adaptability and noise resistance, making it highly capable of handling diverse queries. We compare the proposed framework against other leading industry methods across various benchmarks. The results demonstrate that our framework obtains superior performance in both single-hop and multi-hop question-answering tasks.",
            "score": 2,
            "issue_id": 5885,
            "pub_date": "2025-09-08",
            "pub_date_card": {
                "ru": "8 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 8",
                "zh": "9æœˆ8æ—¥"
            },
            "hash": "a0f4a95527c1fb76",
            "authors": [
                "Duolin Sun",
                "Dan Yang",
                "Yue Shen",
                "Yihan Jiao",
                "Zhehao Tan",
                "Jie Feng",
                "Lianzhen Zhong",
                "Jian Wang",
                "Peng Wei",
                "Jinjie Gu"
            ],
            "affiliations": [
                "Ant Group, Hangzhou, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09713.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#rag",
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "HANRAG: Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²",
                    "desc": "HANRAG - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‰Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼. ĞĞ½Ğ° ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¸Ñ… Ğ´ĞµĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ°. HANRAG Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ´Ğ»Ñ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², Ğ¸Ñ… Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ° Ğ¸Ğ· Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ĞºĞ°Ğº Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ…, Ñ‚Ğ°Ğº Ğ¸ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¾-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "HANRAG: Smart Query Handling for Better Answers",
                    "desc": "HANRAG is a new framework that improves question-answering systems by breaking down complex queries into simpler sub-queries. It uses a heuristic approach to filter out irrelevant information, reducing noise in the retrieval process. This method enhances the system's ability to handle multi-hop queries, which require information from multiple sources. By comparing HANRAG with existing methods, the results show it performs better in answering both single-hop and multi-hop questions."
                },
                "zh": {
                    "title": "HANRAGï¼šæå‡é—®ç­”ç³»ç»Ÿçš„æ™ºèƒ½æ¡†æ¶",
                    "desc": "HANRAGæ˜¯ä¸€ä¸ªåŸºäºå¯å‘å¼çš„æ–¹æ³•æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜é—®ç­”ç³»ç»Ÿçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤šè·³æŸ¥è¯¢æ—¶ã€‚å®ƒé€šè¿‡æŸ¥è¯¢åˆ†è§£å’Œè¿‡æ»¤æ¥æœ‰æ•ˆå‡å°‘å™ªå£°ï¼Œä»è€Œæå‡ç³»ç»Ÿçš„é€‚åº”æ€§å’ŒæŠ—å™ªå£°èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¼ºå¤§çš„æ­ç¤ºå™¨ï¼Œå°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå­æŸ¥è¯¢ï¼Œå¹¶ä»æ£€ç´¢çš„æ–‡æ¡£ä¸­å»é™¤æ— å…³å†…å®¹ã€‚ä¸å…¶ä»–ä¸»æµæ–¹æ³•ç›¸æ¯”ï¼ŒHANRAGåœ¨å•è·³å’Œå¤šè·³é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10396",
            "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language\n  Models",
            "url": "https://huggingface.co/papers/2509.10396",
            "abstract": "IGPO, an RL framework utilizing inpainting in masked diffusion large language models, enhances sample efficiency and achieves state-of-the-art results in mathematical benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Masked diffusion large language models (dLLMs) are emerging as promising alternatives to autoregressive LLMs, offering competitive performance while supporting unique generation capabilities such as inpainting. We explore how inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with reinforcement learning faces an exploration challenge: sparse reward signals and sample waste when models fail to discover correct solutions. While this inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided Policy Optimization), an RL framework that strategically inserts partial ground-truth reasoning traces during online sampling. Unlike providing full solutions, inpainting steers exploration toward promising trajectory spaces while preserving self-generated reasoning, bridging supervised fine-tuning and reinforcement learning. We apply IGPO to group-based optimization methods such as GRPO, where exploration failures cause zero advantages and gradients. IGPO restores meaningful gradients while improving sample efficiency. We also propose supervised fine-tuning on synthetically rewritten concise traces that better align with dLLM generation patterns. With additional techniques including entropy-based filtering, our training recipe yields substantial gains across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new state-of-the-art results for full-attention masked dLLMs.",
            "score": 1,
            "issue_id": 5886,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "aeadbfb97e57966c",
            "authors": [
                "Siyan Zhao",
                "Mengchen Liu",
                "Jing Huang",
                "Miao Liu",
                "Chenyu Wang",
                "Bo Liu",
                "Yuandong Tian",
                "Guan Pang",
                "Sean Bell",
                "Aditya Grover",
                "Feiyu Chen"
            ],
            "affiliations": [
                "MIT",
                "Meta Superintelligence Labs",
                "Tsinghua University, College of AI",
                "UCLA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10396.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#diffusion",
                    "#synthetic",
                    "#games",
                    "#rl",
                    "#rlhf",
                    "#training",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ˜Ğ½Ğ¿ĞµĞ¹Ğ½Ñ‚Ğ¸Ğ½Ğ³ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "IGPO - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ½Ğ¿ĞµĞ¹Ğ½Ñ‚Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹. IGPO ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ€ĞµĞºĞ¾Ñ€Ğ´Ğ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…."
                },
                "en": {
                    "title": "Enhancing Reinforcement Learning with Inpainting in dLLMs",
                    "desc": "This paper introduces IGPO, a reinforcement learning (RL) framework that leverages inpainting techniques in masked diffusion large language models (dLLMs) to improve sample efficiency. By using inpainting, IGPO helps guide the exploration process in RL, addressing the challenge of sparse rewards and inefficient sampling. The framework strategically incorporates partial ground-truth reasoning during online sampling, which enhances the model's ability to discover effective solutions. The results demonstrate that IGPO achieves state-of-the-art performance on mathematical benchmarks, showcasing the potential of combining inpainting with RL in dLLMs."
                },
                "zh": {
                    "title": "åˆ©ç”¨å›¾åƒä¿®å¤æå‡å¼ºåŒ–å­¦ä¹ æ•ˆç‡çš„IGPOæ¡†æ¶",
                    "desc": "IGPOæ˜¯ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨æ©è”½æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å›¾åƒä¿®å¤æŠ€æœ¯ï¼Œæå‡æ ·æœ¬æ•ˆç‡å¹¶åœ¨æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚æ©è”½æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰é€šè¿‡å›¾åƒä¿®å¤èƒ½åŠ›ä¸ºå¼ºåŒ–å­¦ä¹ ç®—æ³•è®¾è®¡æä¾›äº†æ–°çš„æ€è·¯ã€‚IGPOé€šè¿‡åœ¨åœ¨çº¿é‡‡æ ·è¿‡ç¨‹ä¸­æ’å…¥éƒ¨åˆ†çœŸå®æ¨ç†è½¨è¿¹ï¼ŒæŒ‡å¯¼æ¢ç´¢è¿‡ç¨‹ï¼Œé¿å…äº†æ¨¡å‹åœ¨å¯»æ‰¾æ­£ç¡®è§£å†³æ–¹æ¡ˆæ—¶çš„æ ·æœ¬æµªè´¹ã€‚è¯¥æ–¹æ³•åœ¨ç¾¤ä½“ä¼˜åŒ–æ–¹æ³•ä¸­åº”ç”¨ï¼Œæ¢å¤äº†æœ‰æ„ä¹‰çš„æ¢¯åº¦ï¼ŒåŒæ—¶æé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œæœ€ç»ˆåœ¨å¤šä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.10058",
            "title": "Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings\n  for Improved Diffusion Generation",
            "url": "https://huggingface.co/papers/2509.10058",
            "abstract": "A training-free framework uses a large language model to disambiguate color terms and refine text embeddings for improved color accuracy in text-to-image generation.  \t\t\t\t\tAI-generated summary \t\t\t\t Accurate color alignment in text-to-image (T2I) generation is critical for applications such as fashion, product visualization, and interior design, yet current diffusion models struggle with nuanced and compound color terms (e.g., Tiffany blue, lime green, hot pink), often producing images that are misaligned with human intent. Existing approaches rely on cross-attention manipulation, reference images, or fine-tuning but fail to systematically resolve ambiguous color descriptions. To precisely render colors under prompt ambiguity, we propose a training-free framework that enhances color fidelity by leveraging a large language model (LLM) to disambiguate color-related prompts and guiding color blending operations directly in the text embedding space. Our method first employs a large language model (LLM) to resolve ambiguous color terms in the text prompt, and then refines the text embeddings based on the spatial relationships of the resulting color terms in the CIELAB color space. Unlike prior methods, our approach improves color accuracy without requiring additional training or external reference images. Experimental results demonstrate that our framework improves color alignment without compromising image quality, bridging the gap between text semantics and visual generation.",
            "score": 1,
            "issue_id": 5883,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "e647125383aba6a5",
            "authors": [
                "Sung-Lin Tsai",
                "Bo-Lun Huang",
                "Yu Ting Shen",
                "Cheng Yu Yeo",
                "Chiang Tseng",
                "Bo-Kai Ruan",
                "Wen-Sheng Lien",
                "Hong-Han Shuai"
            ],
            "affiliations": [
                "National Yang Ming Chiao Tung University Hsinchu, Taiwan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.10058.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#data",
                    "#diffusion",
                    "#optimization",
                    "#cv"
                ],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ†Ğ²ĞµÑ‚Ğ° Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ±Ğ¾Ğ»ÑŒÑˆÑƒÑ ÑĞ·Ñ‹ĞºĞ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²Ñ‹Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ² Ğ² Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ñ… Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ. ĞœĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ´Ğ¾Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ² Ğ² Ñ†Ğ²ĞµÑ‚Ğ¾Ğ²Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ CIELAB. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ², Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑ„ĞµÑ€ĞµĞ½ÑĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ² Ğ±ĞµĞ· ÑƒÑ‰ĞµÑ€Ğ±Ğ° Ğ´Ğ»Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Enhancing Color Accuracy in T2I with a Training-Free Framework",
                    "desc": "This paper presents a novel training-free framework that enhances color accuracy in text-to-image (T2I) generation by utilizing a large language model (LLM). The framework addresses the challenge of ambiguous color terms, which often lead to misaligned images in applications like fashion and product visualization. By disambiguating color prompts and refining text embeddings in the CIELAB color space, the method improves the fidelity of generated colors without the need for additional training or reference images. Experimental results show that this approach successfully aligns colors with human intent while maintaining high image quality."
                },
                "zh": {
                    "title": "æ— è®­ç»ƒæ¡†æ¶æå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„é¢œè‰²å‡†ç¡®æ€§",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æ¶ˆæ­§ä¹‰é¢œè‰²æœ¯è¯­ï¼Œå¹¶ä¼˜åŒ–æ–‡æœ¬åµŒå…¥ï¼Œä»¥æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„é¢œè‰²å‡†ç¡®æ€§ã€‚å½“å‰çš„æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†å¤æ‚çš„é¢œè‰²æè¿°æ—¶è¡¨ç°ä¸ä½³ï¼Œå¸¸å¸¸å¯¼è‡´ç”Ÿæˆçš„å›¾åƒä¸äººç±»æ„å›¾ä¸ç¬¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡è§£ææ–‡æœ¬æç¤ºä¸­çš„æ¨¡ç³Šé¢œè‰²æœ¯è¯­ï¼Œå¹¶åœ¨CIELABé¢œè‰²ç©ºé—´ä¸­æ ¹æ®é¢œè‰²æœ¯è¯­çš„ç©ºé—´å…³ç³»æ¥ç»†åŒ–æ–‡æœ¬åµŒå…¥ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„é¢œè‰²æ¸²æŸ“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¸å½±å“å›¾åƒè´¨é‡çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æ”¹å–„äº†é¢œè‰²å¯¹é½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09990",
            "title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority\n  Languages in China",
            "url": "https://huggingface.co/papers/2509.09990",
            "abstract": "Minority languages in China, such as Tibetan, Uyghur, and Traditional Mongolian, face significant challenges due to their unique writing systems, which differ from international standards. This discrepancy has led to a severe lack of relevant corpora, particularly for supervised tasks like headline generation. To address this gap, we introduce a novel dataset, Chinese Minority Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and 50,000 entries each for Uyghur and Mongolian, specifically curated for headline generation tasks. Additionally, we propose a high-quality test set annotated by native speakers, designed to serve as a benchmark for future research in this domain. We hope this dataset will become a valuable resource for advancing headline generation in Chinese minority languages and contribute to the development of related benchmarks.",
            "score": 1,
            "issue_id": 5886,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "83ad01064c3c6566",
            "authors": [
                "Guixian Xu",
                "Zeli Su",
                "Ziyin Zhang",
                "Jianing Liu",
                "XU Han",
                "Ting Zhang",
                "Yushuang Dong"
            ],
            "affiliations": [
                "Key Laboratory of Ethnic Language Intelligent Analysis and Security Governance of MOE",
                "Minzu University of China",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09990.jpg",
            "data": {
                "categories": [
                    "#low_resource",
                    "#synthetic",
                    "#multilingual",
                    "#translation",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "ğŸ“°",
                "ru": {
                    "title": "ĞŸÑ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ±Ğ°Ñ€ÑŒĞµÑ€Ğ°: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ½Ğ° ÑĞ·Ñ‹ĞºĞ°Ñ… Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ² ĞšĞ¸Ñ‚Ğ°Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… CMHG Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ½Ğ° ÑĞ·Ñ‹ĞºĞ°Ñ… Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ² ĞšĞ¸Ñ‚Ğ°Ñ: Ñ‚Ğ¸Ğ±ĞµÑ‚ÑĞºĞ¾Ğ¼, ÑƒĞ¹Ğ³ÑƒÑ€ÑĞºĞ¾Ğ¼ Ğ¸ Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ¼. Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 100 000 Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ´Ğ»Ñ Ñ‚Ğ¸Ğ±ĞµÑ‚ÑĞºĞ¾Ğ³Ğ¾ Ğ¸ Ğ¿Ğ¾ 50 000 Ğ´Ğ»Ñ ÑƒĞ¹Ğ³ÑƒÑ€ÑĞºĞ¾Ğ³Ğ¾ Ğ¸ Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€, Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑĞ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ°, Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ° Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹. Ğ­Ñ‚Ğ¾Ñ‚ Ñ€ĞµÑÑƒÑ€Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ²Ğ°Ğ½ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ² Ğ´Ğ»Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ² Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ² ĞšĞ¸Ñ‚Ğ°Ñ."
                },
                "en": {
                    "title": "Empowering Minority Languages with Tailored Datasets for Headline Generation",
                    "desc": "This paper addresses the challenges faced by minority languages in China, such as Tibetan, Uyghur, and Traditional Mongolian, particularly in the context of headline generation due to their unique writing systems. The authors introduce a new dataset called Chinese Minority Headline Generation (CMHG), which contains 100,000 entries for Tibetan and 50,000 entries each for Uyghur and Mongolian. This dataset is specifically designed for supervised learning tasks, providing a substantial resource for training models in headline generation. Furthermore, a high-quality test set annotated by native speakers is included to establish benchmarks for future research in this area."
                },
                "zh": {
                    "title": "æ¨åŠ¨ä¸­å›½å°‘æ•°æ°‘æ—è¯­è¨€æ ‡é¢˜ç”Ÿæˆçš„åˆ›æ–°æ•°æ®é›†",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œåä¸ºä¸­å›½å°‘æ•°æ°‘æ—æ ‡é¢˜ç”Ÿæˆæ•°æ®é›†ï¼ˆCMHGï¼‰ï¼Œæ—¨åœ¨è§£å†³è—è¯­ã€ç»´å¾å°”è¯­å’Œè’™å¤è¯­åœ¨æ ‡é¢˜ç”Ÿæˆä»»åŠ¡ä¸­çš„æ•°æ®åŒ®ä¹é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«10ä¸‡ä¸ªè—è¯­æ¡ç›®ï¼Œä»¥åŠå„5ä¸‡ä¸ªç»´å¾å°”è¯­å’Œè’™å¤è¯­æ¡ç›®ï¼Œä¸“é—¨ç”¨äºæ ‡é¢˜ç”Ÿæˆã€‚æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªç”±æ¯è¯­è€…æ³¨é‡Šçš„é«˜è´¨é‡æµ‹è¯•é›†ï¼Œä½œä¸ºæœªæ¥ç ”ç©¶çš„åŸºå‡†ã€‚å¸Œæœ›è¿™ä¸ªæ•°æ®é›†èƒ½ä¸ºä¸­å›½å°‘æ•°æ°‘æ—è¯­è¨€çš„æ ‡é¢˜ç”Ÿæˆæä¾›æœ‰ä»·å€¼çš„èµ„æºï¼Œå¹¶æ¨åŠ¨ç›¸å…³åŸºå‡†çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.09926",
            "title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised\n  Learning in Open-World Scenarios",
            "url": "https://huggingface.co/papers/2509.09926",
            "abstract": "LoFT, a parameter-efficient fine-tuning framework for long-tailed semi-supervised learning, improves reliability of pseudolabels and discriminative ability in open-world scenarios, outperforming previous methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-tailed learning has garnered increasing attention due to its wide applicability in real-world scenarios. Among existing approaches, Long-Tailed Semi-Supervised Learning (LTSSL) has emerged as an effective solution by incorporating a large amount of unlabeled data into the imbalanced labeled dataset. However, most prior LTSSL methods are designed to train models from scratch, which often leads to issues such as overconfidence and low-quality pseudo-labels. To address these challenges, we extend LTSSL into the foundation model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate that fine-tuned foundation models can generate more reliable pseudolabels, thereby benefiting imbalanced learning. Furthermore, we explore a more practical setting by investigating semi-supervised learning under open-world conditions, where the unlabeled data may include out-of-distribution (OOD) samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World scenarios) to improve the discriminative ability. Experimental results on multiple benchmarks demonstrate that our method achieves superior performance compared to previous approaches, even when utilizing only 1\\% of the unlabeled data compared with previous works.",
            "score": 1,
            "issue_id": 5884,
            "pub_date": "2025-09-12",
            "pub_date_card": {
                "ru": "12 ÑĞµĞ½Ñ‚ÑĞ±Ñ€Ñ",
                "en": "September 12",
                "zh": "9æœˆ12æ—¥"
            },
            "hash": "e85c5f480d51fb5c",
            "authors": [
                "Jiahao Chen",
                "Zhiyuan Huang",
                "Yurou Liu",
                "Bing Su"
            ],
            "affiliations": [
                "Renmin University of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.09926.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#dataset",
                    "#optimization",
                    "#training",
                    "#transfer_learning"
                ],
                "emoji": "ğŸ¦š",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾Ğ½ĞºĞ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ LoFT - Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ½ĞµÑĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»Ñƒ-ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼. LoFT ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿ÑĞµĞ²Ğ´Ğ¾-Ğ¼ĞµÑ‚Ğ¾Ğº Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğº Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ² ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾Ğ³Ğ¾ Ğ¼Ğ¸Ñ€Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ LoFT-OW Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ LoFT Ğ½Ğ°Ğ´ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 1% Ğ½ĞµĞ¼ĞµÑ‡ĞµĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "Enhancing Long-Tailed Learning with LoFT: Fine-Tuning for Better Pseudolabels",
                    "desc": "LoFT is a new framework designed for long-tailed semi-supervised learning that enhances the quality of pseudolabels and improves model performance in open-world scenarios. It builds on the foundation model fine-tuning approach, allowing for better utilization of unlabeled data alongside imbalanced labeled datasets. By addressing issues like overconfidence and low-quality pseudolabels, LoFT enables more reliable learning outcomes. The framework also includes a variant, LoFT-OW, which specifically tackles challenges posed by out-of-distribution samples, demonstrating superior results on various benchmarks with minimal unlabeled data usage."
                },
                "zh": {
                    "title": "LoFTï¼šæå‡é•¿å°¾åŠç›‘ç£å­¦ä¹ çš„å¯é æ€§ä¸åŒºåˆ†èƒ½åŠ›",
                    "desc": "LoFTæ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæ¡†æ¶ï¼Œä¸“ä¸ºé•¿å°¾åŠç›‘ç£å­¦ä¹ è®¾è®¡ï¼Œæ—¨åœ¨æé«˜ä¼ªæ ‡ç­¾çš„å¯é æ€§å’Œåœ¨å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸­çš„åŒºåˆ†èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å¤§é‡æœªæ ‡è®°æ•°æ®ä¸ä¸å¹³è¡¡çš„æ ‡è®°æ•°æ®é›†ç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¸¸è§çš„è¿‡åº¦è‡ªä¿¡å’Œä½è´¨é‡ä¼ªæ ‡ç­¾çš„é—®é¢˜ã€‚LoFTåœ¨åŸºç¡€æ¨¡å‹å¾®è°ƒçš„åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´å¯é çš„ä¼ªæ ‡ç­¾ï¼Œä»è€Œä¿ƒè¿›ä¸å¹³è¡¡å­¦ä¹ çš„æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLoFTåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œå³ä½¿åªä½¿ç”¨1%çš„æœªæ ‡è®°æ•°æ®ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-09-12.html",
    "link_next": "2025-09-16.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "12.09",
        "en": "09/12",
        "zh": "9æœˆ12æ—¥"
    },
    "short_date_next": {
        "ru": "16.09",
        "en": "09/16",
        "zh": "9æœˆ16æ—¥"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 6,
        "#agents": 3,
        "#cv": 2,
        "#rl": 2,
        "#rlhf": 1,
        "#rag": 1,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 1,
        "#video": 0,
        "#multimodal": 2,
        "#math": 1,
        "#multilingual": 2,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 2,
        "#interpretability": 1,
        "#reasoning": 3,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 4,
        "#survey": 0,
        "#diffusion": 3,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 2,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 1,
        "#translation": 1
    }
}