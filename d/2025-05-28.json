{
    "date": {
        "ru": "28 Ğ¼Ğ°Ñ",
        "en": "May 28",
        "zh": "5æœˆ28æ—¥"
    },
    "time_utc": "2025-05-28 00:55",
    "weekday": 2,
    "issue_id": 3989,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.17894",
            "title": "Mutarjim: Advancing Bidirectional Arabic-English Translation with a\n  Small Language Model",
            "url": "https://huggingface.co/papers/2505.17894",
            "abstract": "Mutarjim is a compact Arabic-English translation model that outperforms larger models on established benchmarks and achieves state-of-the-art performance on a new comprehensive Tarjama-25 benchmark.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce Mutarjim, a compact yet powerful language model for bidirectional Arabic-English translation. While large-scale LLMs have shown impressive progress in natural language processing tasks, including machine translation, smaller models. Leveraging this insight, we developed Mutarjim based on Kuwain-1.5B , a language model tailored for both Arabic and English. Despite its modest size, Mutarjim outperforms much larger models on several established benchmarks, achieved through an optimized two-phase training approach and a carefully curated, high-quality training corpus.. Experimental results show that Mutarjim rivals models up to 20 times larger while significantly reducing computational costs and training requirements. We also introduce Tarjama-25, a new benchmark designed to overcome limitations in existing Arabic-English benchmarking datasets, such as domain narrowness, short sentence lengths, and English-source bias. Tarjama-25 comprises 5,000 expert-reviewed sentence pairs and spans a wide range of domains, offering a more comprehensive and balanced evaluation framework. Notably, Mutarjim achieves state-of-the-art performance on the English-to-Arabic task in Tarjama-25, surpassing even significantly larger and proprietary models like GPT-4o mini. We publicly release Tarjama-25 to support future research and advance the evaluation of Arabic-English translation systems.",
            "score": 175,
            "issue_id": 3974,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "9d9d296ef92faffb",
            "authors": [
                "Khalil Hennara",
                "Muhammad Hreden",
                "Mohamed Motaism Hamed",
                "Zeina Aldallal",
                "Sara Chrouf",
                "Safwan AlModhayan"
            ],
            "affiliations": [
                "Khobar, Saudi Arabia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.17894.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#dataset",
                    "#benchmark",
                    "#machine_translation",
                    "#multilingual",
                    "#small_models",
                    "#open_source"
                ],
                "emoji": "ğŸŒ",
                "ru": {
                    "title": "ĞœĞ°Ğ»ĞµĞ½ÑŒĞºĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ - Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ°Ñ€Ğ°Ğ±ÑĞºĞ¾-Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğµ",
                    "desc": "Mutarjim - ÑÑ‚Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ğ°Ñ€Ğ°Ğ±ÑĞºĞ¾Ğ³Ğ¾ Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ², Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Kuwain-1.5B. ĞĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€, Ğ¾Ğ½Ğ° Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ³Ğ¾Ñ€Ğ°Ğ·Ğ´Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ñ€ÑĞ´Ğµ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ¾Ğ² Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ´Ğ²ÑƒÑ…Ñ„Ğ°Ğ·Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚Ñ‰Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ ĞºĞ¾Ñ€Ğ¿ÑƒÑÑƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Tarjama-25, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ 5000 ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ¾Ğ¼ĞµĞ½Ğ¾Ğ². ĞĞ° ÑÑ‚Ğ¾Ğ¼ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ Mutarjim Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğµ Ñ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾ Ğ½Ğ° Ğ°Ñ€Ğ°Ğ±ÑĞºĞ¸Ğ¹, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ´Ğ°Ğ¶Ğµ Ñ‚Ğ°ĞºĞ¸Ğµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¿Ñ€Ğ¸ĞµÑ‚Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ĞºĞ°Ğº GPT-4."
                },
                "en": {
                    "title": "Mutarjim: Compact Power in Arabic-English Translation",
                    "desc": "Mutarjim is a compact language model designed for Arabic-English translation that achieves superior performance compared to larger models. It utilizes a two-phase training approach and a high-quality training corpus, allowing it to excel on established benchmarks. The introduction of the Tarjama-25 benchmark addresses previous limitations in Arabic-English translation datasets, providing a more diverse and comprehensive evaluation. Mutarjim not only rivals models up to 20 times its size but also significantly reduces computational costs, making it an efficient choice for translation tasks."
                },
                "zh": {
                    "title": "å°æ¨¡å‹ï¼Œå¤§èƒ½åŠ›ï¼šMutarjimçš„ç¿»è¯‘é©å‘½",
                    "desc": "Mutarjimæ˜¯ä¸€ç§ç´§å‡‘çš„é˜¿æ‹‰ä¼¯è¯­-è‹±è¯­åŒå‘ç¿»è¯‘æ¨¡å‹ï¼Œå°½ç®¡ä½“ç§¯è¾ƒå°ï¼Œä½†åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†æ›´å¤§çš„æ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸºäºKuwain-1.5Bæ„å»ºï¼Œé‡‡ç”¨äº†ä¼˜åŒ–çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³•å’Œé«˜è´¨é‡çš„è®­ç»ƒè¯­æ–™åº“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMutarjimåœ¨è®¡ç®—æˆæœ¬å’Œè®­ç»ƒéœ€æ±‚ä¸Šæ˜¾è‘—é™ä½ï¼ŒåŒæ—¶åœ¨Tarjama-25åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚Tarjama-25æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œæ—¨åœ¨å…‹æœç°æœ‰é˜¿æ‹‰ä¼¯è¯­-è‹±è¯­æ•°æ®é›†çš„å±€é™æ€§ï¼Œæä¾›æ›´å…¨é¢çš„è¯„ä¼°æ¡†æ¶ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19147",
            "title": "Shifting AI Efficiency From Model-Centric to Data-Centric Compression",
            "url": "https://huggingface.co/papers/2505.19147",
            "abstract": "The rapid advancement of large language models (LLMs) and multi-modal LLMs (MLLMs) has historically relied on model-centric scaling through increasing parameter counts from millions to hundreds of billions to drive performance gains. However, as we approach hardware limits on model size, the dominant computational bottleneck has fundamentally shifted to the quadratic cost of self-attention over long token sequences, now driven by ultra-long text contexts, high-resolution images, and extended videos. In this position paper, we argue that the focus of research for efficient AI is shifting from model-centric compression to data-centric compression. We position token compression as the new frontier, which improves AI efficiency via reducing the number of tokens during model training or inference. Through comprehensive analysis, we first examine recent developments in long-context AI across various domains and establish a unified mathematical framework for existing model efficiency strategies, demonstrating why token compression represents a crucial paradigm shift in addressing long-context overhead. Subsequently, we systematically review the research landscape of token compression, analyzing its fundamental benefits and identifying its compelling advantages across diverse scenarios. Furthermore, we provide an in-depth analysis of current challenges in token compression research and outline promising future directions. Ultimately, our work aims to offer a fresh perspective on AI efficiency, synthesize existing research, and catalyze innovative developments to address the challenges that increasing context lengths pose to the AI community's advancement.",
            "score": 121,
            "issue_id": 3968,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "74f14f3f2d4f73b6",
            "authors": [
                "Xuyang Liu",
                "Zichen Wen",
                "Shaobo Wang",
                "Junjie Chen",
                "Zhishan Tao",
                "Yubo Wang",
                "Xiangqi Jin",
                "Chang Zou",
                "Yiyu Wang",
                "Chenfei Liao",
                "Xu Zheng",
                "Honggang Chen",
                "Weijia Li",
                "Xuming Hu",
                "Conghui He",
                "Linfeng Zhang"
            ],
            "affiliations": [
                "EPIC Lab, Shanghai Jiao Tong University",
                "Hong Kong University of Science and Technology (Guangzhou)",
                "Shanghai AI Laboratory",
                "Sichuan University",
                "Sun Yat-sen University",
                "University of Electronic Science & Technology of China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19147.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#data",
                    "#math",
                    "#optimization",
                    "#long_context",
                    "#survey"
                ],
                "emoji": "ğŸ—œï¸",
                "ru": {
                    "title": "Ğ¡Ğ¶Ğ°Ñ‚Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ÑƒĞ±ĞµĞ¶ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ˜Ğ˜",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´ Ğ¾Ñ‚ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº ÑĞ¶Ğ°Ñ‚Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… LLM. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğ¼ Ñ„Ñ€Ğ¾Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ¼ Ğ² Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°. Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ˜Ğ˜ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ ĞµĞ´Ğ¸Ğ½Ğ°Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° ÑĞ¶Ğ°Ñ‚Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑÑ‚Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Token Compression: The Key to Efficient AI",
                    "desc": "This paper discusses the shift in focus from increasing the size of language models to improving efficiency through data-centric methods, specifically token compression. As models grow larger, the computational cost of processing long sequences of tokens becomes a significant bottleneck. The authors propose that reducing the number of tokens used during training and inference can enhance AI performance without solely relying on larger models. They provide a comprehensive review of token compression techniques, their benefits, and the challenges that remain, aiming to inspire future research in this area."
                },
                "zh": {
                    "title": "ä»¤ç‰Œå‹ç¼©ï¼šæå‡AIæ•ˆç‡çš„æ–°å‰æ²¿",
                    "desc": "éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæ¨¡å‹çš„è§„æ¨¡ä¸æ–­æ‰©å¤§ï¼Œå‚æ•°æ•°é‡ä»æ•°ç™¾ä¸‡å¢åŠ åˆ°æ•°ç™¾äº¿ã€‚ç„¶è€Œï¼Œéšç€ç¡¬ä»¶é™åˆ¶çš„æ¥è¿‘ï¼Œè®¡ç®—ç“¶é¢ˆå·²è½¬å‘è‡ªæ³¨æ„åŠ›æœºåˆ¶åœ¨é•¿åºåˆ—ä¸Šçš„äºŒæ¬¡æˆæœ¬ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†è¶…é•¿æ–‡æœ¬ã€é«˜åˆ†è¾¨ç‡å›¾åƒå’Œæ‰©å±•è§†é¢‘æ—¶ã€‚æœ¬æ–‡æå‡ºï¼Œç ”ç©¶çš„é‡ç‚¹åº”ä»ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„å‹ç¼©è½¬å‘ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å‹ç¼©ï¼Œç‰¹åˆ«æ˜¯ä»¤ç‰Œå‹ç¼©è¢«è§†ä¸ºæé«˜AIæ•ˆç‡çš„æ–°å‰æ²¿ã€‚é€šè¿‡å¯¹ä»¤ç‰Œå‹ç¼©çš„ç³»ç»Ÿæ€§å›é¡¾ï¼Œæˆ‘ä»¬åˆ†æäº†å…¶åŸºæœ¬ä¼˜åŠ¿å’Œé¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶å±•æœ›æœªæ¥çš„å‘å±•æ–¹å‘ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19297",
            "title": "Alchemist: Turning Public Text-to-Image Data into Generative Gold",
            "url": "https://huggingface.co/papers/2505.19297",
            "abstract": "A new method using a pre-trained generative model helps construct a high-impact SFT dataset, Alchemist, which improves the generative quality of text-to-image models while maintaining diversity.  \t\t\t\t\tAI-generated summary \t\t\t\t Pre-training equips text-to-image (T2I) models with broad world knowledge, but this alone is often insufficient to achieve high aesthetic quality and alignment. Consequently, supervised fine-tuning (SFT) is crucial for further refinement. However, its effectiveness highly depends on the quality of the fine-tuning dataset. Existing public SFT datasets frequently target narrow domains (e.g., anime or specific art styles), and the creation of high-quality, general-purpose SFT datasets remains a significant challenge. Current curation methods are often costly and struggle to identify truly impactful samples. This challenge is further complicated by the scarcity of public general-purpose datasets, as leading models often rely on large, proprietary, and poorly documented internal data, hindering broader research progress. This paper introduces a novel methodology for creating general-purpose SFT datasets by leveraging a pre-trained generative model as an estimator of high-impact training samples. We apply this methodology to construct and release Alchemist, a compact (3,350 samples) yet highly effective SFT dataset. Experiments demonstrate that Alchemist substantially improves the generative quality of five public T2I models while preserving diversity and style. Additionally, we release the fine-tuned models' weights to the public.",
            "score": 57,
            "issue_id": 3975,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "620ec57b5ad166ad",
            "authors": [
                "Valerii Startsev",
                "Alexander Ustyuzhanin",
                "Alexey Kirillov",
                "Dmitry Baranchuk",
                "Sergey Kastryulin"
            ],
            "affiliations": [
                "MSU",
                "Yandex",
                "Yandex Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19297.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#synthetic",
                    "#open_source",
                    "#training",
                    "#data"
                ],
                "emoji": "ğŸ§ª",
                "ru": {
                    "title": "ĞĞ»Ñ…Ğ¸Ğ¼Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ±Ñ‹Ğ» ÑĞ¾Ğ·Ğ´Ğ°Ğ½ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¹, Ğ½Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Alchemist. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Alchemist Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ÑÑ‚Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ text-to-image, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ¸ ÑÑ‚Ğ¸Ğ»ÑŒ."
                },
                "en": {
                    "title": "Alchemist: Elevating Text-to-Image Models with Quality SFT Datasets",
                    "desc": "This paper presents a new approach to creating a high-quality supervised fine-tuning (SFT) dataset called Alchemist, which enhances the performance of text-to-image (T2I) models. By utilizing a pre-trained generative model, the authors can identify impactful training samples that improve both the aesthetic quality and diversity of generated images. The Alchemist dataset consists of 3,350 carefully selected samples, addressing the limitations of existing narrow-domain datasets. The results show that models fine-tuned with Alchemist significantly outperform others while maintaining a wide range of styles."
                },
                "zh": {
                    "title": "åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æ„å»ºé«˜è´¨é‡SFTæ•°æ®é›†",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨é¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹æ¥æ„å»ºé«˜å½±å“åŠ›çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ•°æ®é›†Alchemistã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæé«˜æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ï¼ŒåŒæ—¶ä¿æŒå¤šæ ·æ€§ã€‚ç°æœ‰çš„å…¬å…±SFTæ•°æ®é›†é€šå¸¸åªé’ˆå¯¹ç‹­çª„é¢†åŸŸï¼Œåˆ›å»ºé«˜è´¨é‡çš„é€šç”¨SFTæ•°æ®é›†ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚å®éªŒè¡¨æ˜ï¼ŒAlchemistæ˜¾è‘—æå‡äº†äº”ä¸ªå…¬å…±T2Iæ¨¡å‹çš„ç”Ÿæˆè´¨é‡ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜å°†å¾®è°ƒåçš„æ¨¡å‹æƒé‡å…¬å¼€å‘å¸ƒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19457",
            "title": "BizFinBench: A Business-Driven Real-World Financial Benchmark for\n  Evaluating LLMs",
            "url": "https://huggingface.co/papers/2505.19457",
            "abstract": "BizFinBench is a benchmark for evaluating large language models in financial applications, revealing distinct performance patterns across various tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models excel in general tasks, yet assessing their reliability in logic-heavy, precision-critical domains like finance, law, and healthcare remains challenging. To address this, we introduce BizFinBench, the first benchmark specifically designed to evaluate LLMs in real-world financial applications. BizFinBench consists of 6,781 well-annotated queries in Chinese, spanning five dimensions: numerical calculation, reasoning, information extraction, prediction recognition, and knowledge-based question answering, grouped into nine fine-grained categories. The benchmark includes both objective and subjective metrics. We also introduce IteraJudge, a novel LLM evaluation method that reduces bias when LLMs serve as evaluators in objective metrics. We benchmark 25 models, including both proprietary and open-source systems. Extensive experiments show that no model dominates across all tasks. Our evaluation reveals distinct capability patterns: (1) In Numerical Calculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while smaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning, proprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with open-source models trailing by up to 19.49 points; (3) In Information Extraction, the performance spread is the largest, with DeepSeek-R1 scoring 71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition, performance variance is minimal, with top models scoring between 39.16 and 50.00. We find that while current LLMs handle routine finance queries competently, they struggle with complex scenarios requiring cross-concept reasoning. BizFinBench offers a rigorous, business-aligned benchmark for future research. The code and dataset are available at https://github.com/HiThink-Research/BizFinBench.",
            "score": 55,
            "issue_id": 3969,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "f565f3ceb53b6631",
            "authors": [
                "Guilong Lu",
                "Xuntao Guo",
                "Rongjunchen Zhang",
                "Wenqiao Zhu",
                "Ji Liu"
            ],
            "affiliations": [
                "Harbin Institute of Technology",
                "HiThink Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19457.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#science",
                    "#reasoning",
                    "#dataset",
                    "#open_source"
                ],
                "emoji": "ğŸ’¹",
                "ru": {
                    "title": "BizFinBench: ĞĞ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ LLM Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ°Ñ…",
                    "desc": "BizFinBench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ…. ĞĞ½ ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· 6781 Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ½Ğ° ĞºĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ñ… Ğ¿ÑÑ‚ÑŒ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğ¹: Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ, Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸, Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¾Ğ² Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ 25 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ¿Ñ€Ğ¸ĞµÑ‚Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹, Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ½Ğ¸ Ğ¾Ğ´Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¾ Ğ²ÑĞµÑ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ LLM Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ñ Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸, Ğ½Ğ¾ Ğ¸ÑĞ¿Ñ‹Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞ¾ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑĞ¼Ğ¸, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸ÑĞ¼Ğ¸."
                },
                "en": {
                    "title": "BizFinBench: Evaluating LLMs for Financial Precision",
                    "desc": "BizFinBench is a specialized benchmark designed to evaluate large language models (LLMs) in financial applications, highlighting their performance across various tasks. It includes 6,781 annotated queries in Chinese, covering areas such as numerical calculation, reasoning, information extraction, prediction recognition, and knowledge-based question answering. The benchmark employs both objective and subjective metrics, and introduces IteraJudge to minimize bias in evaluations. Results show that no single model excels in all tasks, with distinct performance patterns observed among different models, particularly in complex reasoning scenarios."
                },
                "zh": {
                    "title": "BizFinBenchï¼šé‡‘èåº”ç”¨ä¸­çš„è¯­è¨€æ¨¡å‹è¯„ä¼°æ–°åŸºå‡†",
                    "desc": "BizFinBenchæ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èåº”ç”¨ä¸­çš„åŸºå‡†æµ‹è¯•ã€‚å®ƒåŒ…å«6781ä¸ªç»è¿‡è‰¯å¥½æ ‡æ³¨çš„æŸ¥è¯¢ï¼Œæ¶µç›–äº†æ•°å€¼è®¡ç®—ã€æ¨ç†ã€ä¿¡æ¯æå–ã€é¢„æµ‹è¯†åˆ«å’ŒåŸºäºçŸ¥è¯†çš„é—®é¢˜å›ç­”ç­‰äº”ä¸ªç»´åº¦ã€‚é€šè¿‡å¯¹25ä¸ªæ¨¡å‹çš„è¯„ä¼°ï¼Œå‘ç°æ²¡æœ‰ä¸€ä¸ªæ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸”ä¸åŒæ¨¡å‹åœ¨å„ä¸ªä»»åŠ¡ä¸­çš„èƒ½åŠ›æ¨¡å¼å„å¼‚ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†ä¸¥æ ¼ä¸”ä¸å•†ä¸šç›¸å…³çš„è¯„ä¼°æ ‡å‡†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19250",
            "title": "PATS: Process-Level Adaptive Thinking Mode Switching",
            "url": "https://huggingface.co/papers/2505.19250",
            "abstract": "PATS enhances LLM efficiency by dynamically adjusting reasoning strategies based on task difficulty, leveraging PRMs and Beam Search.  \t\t\t\t\tAI-generated summary \t\t\t\t Current large-language models (LLMs) typically adopt a fixed reasoning strategy, either simple or complex, for all questions, regardless of their difficulty. This neglect of variation in task and reasoning process complexity leads to an imbalance between performance and efficiency. Existing methods attempt to implement training-free fast-slow thinking system switching to handle problems of varying difficulty, but are limited by coarse-grained solution-level strategy adjustments. To address this issue, we propose a novel reasoning paradigm: Process-Level Adaptive Thinking Mode Switching (PATS), which enables LLMs to dynamically adjust their reasoning strategy based on the difficulty of each step, optimizing the balance between accuracy and computational efficiency. Our approach integrates Process Reward Models (PRMs) with Beam Search, incorporating progressive mode switching and bad-step penalty mechanisms. Experiments on diverse mathematical benchmarks demonstrate that our methodology achieves high accuracy while maintaining moderate token usage. This study emphasizes the significance of process-level, difficulty-aware reasoning strategy adaptation, offering valuable insights into efficient inference for LLMs.",
            "score": 43,
            "issue_id": 3974,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "25678fe2f47d4d46",
            "authors": [
                "Yi Wang",
                "Junxiao Liu",
                "Shimao Zhang",
                "Jiajun Chen",
                "Shujian Huang"
            ],
            "affiliations": [
                "National Key Laboratory for Novel Software Technology, Nanjing University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19250.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#math",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ LLM: ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚ÑŒ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM) Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ PATS. Ğ­Ñ‚Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¸ĞºĞ° Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ LLM Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑˆĞ°Ğ³Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. PATS Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° (PRM) Ñ Ğ»ÑƒÑ‡ĞµĞ²Ñ‹Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ² Ğ¸ ÑˆÑ‚Ñ€Ğ°Ñ„Ğ° Ğ·Ğ° Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½Ñ‹Ğµ ÑˆĞ°Ğ³Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ PATS Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ ÑƒĞ¼ĞµÑ€ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ."
                },
                "en": {
                    "title": "Dynamic Reasoning for Efficient LLMs",
                    "desc": "This paper introduces a new method called Process-Level Adaptive Thinking Mode Switching (PATS) to improve the efficiency of large language models (LLMs). Unlike traditional models that use a fixed reasoning strategy, PATS allows LLMs to adapt their reasoning approach based on the difficulty of each task. By combining Process Reward Models (PRMs) with Beam Search, the model can switch strategies dynamically and penalize ineffective steps. The results show that PATS enhances accuracy while reducing computational costs, highlighting the importance of adapting reasoning strategies to task complexity."
                },
                "zh": {
                    "title": "åŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ï¼Œæé«˜LLMæ•ˆç‡",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†èŒƒå¼ï¼Œç§°ä¸ºè¿‡ç¨‹çº§è‡ªé€‚åº”æ€ç»´æ¨¡å¼åˆ‡æ¢ï¼ˆPATSï¼‰ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ•ˆç‡ã€‚PATSèƒ½å¤Ÿæ ¹æ®æ¯ä¸ªæ­¥éª¤çš„éš¾åº¦åŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ï¼Œä»è€Œä¼˜åŒ–å‡†ç¡®æ€§ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´çš„å¹³è¡¡ã€‚è¯¥æ–¹æ³•ç»“åˆäº†è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰å’ŒæŸæœç´¢ï¼Œé‡‡ç”¨æ¸è¿›æ¨¡å¼åˆ‡æ¢å’Œé”™è¯¯æ­¥éª¤æƒ©ç½šæœºåˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPATSåœ¨å¤šæ ·åŒ–çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†é«˜å‡†ç¡®ç‡ï¼ŒåŒæ—¶ä¿æŒäº†é€‚ä¸­çš„ä»¤ç‰Œä½¿ç”¨é‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16348",
            "title": "Embodied Agents Meet Personalization: Exploring Memory Utilization for\n  Personalized Assistance",
            "url": "https://huggingface.co/papers/2505.16348",
            "abstract": "MEMENTO evaluates personalized memory utilization in embodied agents, revealing limitations in understanding user semantics and routines.  \t\t\t\t\tAI-generated summary \t\t\t\t Embodied agents empowered by large language models (LLMs) have shown strong performance in household object rearrangement tasks. However, these tasks primarily focus on single-turn interactions with simplified instructions, which do not truly reflect the challenges of providing meaningful assistance to users. To provide personalized assistance, embodied agents must understand the unique semantics that users assign to the physical world (e.g., favorite cup, breakfast routine) by leveraging prior interaction history to interpret dynamic, real-world instructions. Yet, the effectiveness of embodied agents in utilizing memory for personalized assistance remains largely underexplored. To address this gap, we present MEMENTO, a personalized embodied agent evaluation framework designed to comprehensively assess memory utilization capabilities to provide personalized assistance. Our framework consists of a two-stage memory evaluation process design that enables quantifying the impact of memory utilization on task performance. This process enables the evaluation of agents' understanding of personalized knowledge in object rearrangement tasks by focusing on its role in goal interpretation: (1) the ability to identify target objects based on personal meaning (object semantics), and (2) the ability to infer object-location configurations from consistent user patterns, such as routines (user patterns). Our experiments across various LLMs reveal significant limitations in memory utilization, with even frontier models like GPT-4o experiencing a 30.5% performance drop when required to reference multiple memories, particularly in tasks involving user patterns. These findings, along with our detailed analyses and case studies, provide valuable insights for future research in developing more effective personalized embodied agents. Project website: https://connoriginal.github.io/MEMENTO",
            "score": 42,
            "issue_id": 3969,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "2293dd9e12554028",
            "authors": [
                "Taeyoon Kwon",
                "Dongwook Choi",
                "Sunghwan Kim",
                "Hyojun Kim",
                "Seungjun Moon",
                "Beong-woo Kwak",
                "Kuan-Hao Huang",
                "Jinyoung Yeo"
            ],
            "affiliations": [
                "Texas A&M University",
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16348.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#interpretability",
                    "#multimodal",
                    "#agi",
                    "#reasoning"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ¾Ğ²: Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸",
                    "desc": "MEMENTO - ÑÑ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ğ»Ğ¾Ñ‰ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ² Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¿ĞµÑ€ĞµÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ñƒ Ğ¿ĞµÑ€ĞµĞ´Ğ¾Ğ²Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº GPT-4. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸ 30.5% Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğº Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼ Ğ²Ğ¾ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸ÑĞ¼, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Enhancing Personalized Assistance in Embodied Agents through Memory Utilization",
                    "desc": "MEMENTO is a framework that evaluates how well embodied agents use memory to provide personalized assistance. It highlights the challenges these agents face in understanding the unique meanings users assign to objects and their routines. The framework includes a two-stage evaluation process that measures how effectively agents can identify objects based on personal significance and infer user patterns. Experiments show that even advanced models like GPT-4o struggle with memory utilization, particularly when dealing with multiple memories, leading to a notable drop in performance."
                },
                "zh": {
                    "title": "ä¸ªæ€§åŒ–è®°å¿†åˆ©ç”¨çš„è¯„ä¼°æ¡†æ¶",
                    "desc": "MEMENTOæ˜¯ä¸€ä¸ªè¯„ä¼°ä¸ªæ€§åŒ–è®°å¿†åˆ©ç”¨çš„æ¡†æ¶ï¼Œä¸“æ³¨äºå…·èº«æ™ºèƒ½ä½“åœ¨ç†è§£ç”¨æˆ·è¯­ä¹‰å’Œæ—¥å¸¸ä¹ æƒ¯æ–¹é¢çš„å±€é™æ€§ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®¶åº­ç‰©å“é‡æ’ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†è¿™äº›ä»»åŠ¡ä¸»è¦æ˜¯å•è½®äº¤äº’ï¼Œæœªèƒ½çœŸå®åæ˜ æä¾›æœ‰æ„ä¹‰å¸®åŠ©çš„æŒ‘æˆ˜ã€‚ä¸ºäº†æä¾›ä¸ªæ€§åŒ–çš„å¸®åŠ©ï¼Œå…·èº«æ™ºèƒ½ä½“éœ€è¦ç†è§£ç”¨æˆ·å¯¹ç‰©ç†ä¸–ç•Œçš„ç‹¬ç‰¹è¯­ä¹‰ï¼Œå¹¶åˆ©ç”¨å…ˆå‰çš„äº¤äº’å†å²æ¥è§£é‡ŠåŠ¨æ€çš„ç°å®æŒ‡ä»¤ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¦‚GPT-4oï¼Œåœ¨éœ€è¦å‚è€ƒå¤šä¸ªè®°å¿†æ—¶ï¼Œæ€§èƒ½ä¹Ÿä¼šä¸‹é™30.5%ï¼Œè¿™ä¸ºæœªæ¥å¼€å‘æ›´æœ‰æ•ˆçš„ä¸ªæ€§åŒ–å…·èº«æ™ºèƒ½ä½“æä¾›äº†é‡è¦çš„è§è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20258",
            "title": "ARM: Adaptive Reasoning Model",
            "url": "https://huggingface.co/papers/2505.20258",
            "abstract": "Adaptive Reasoning Model (ARM) uses Ada-GRPO to reduce token usage and improve efficiency across different reasoning modes.  \t\t\t\t\tAI-generated summary \t\t\t\t While large reasoning models demonstrate strong performance on complex tasks, they lack the ability to adjust reasoning token usage based on task difficulty. This often leads to the \"overthinking\" problem -- excessive and unnecessary reasoning -- which, although potentially mitigated by human intervention to control the token budget, still fundamentally contradicts the goal of achieving fully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a reasoning model capable of adaptively selecting appropriate reasoning formats based on the task at hand. These formats include three efficient ones -- Direct Answer, Short CoT, and Code -- as well as a more elaborate format, Long CoT. To train ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy Optimization (GRPO), which addresses the format collapse issue in traditional GRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by an average of 30%, and up to 70%, while maintaining performance comparable to the model that relies solely on Long CoT. Furthermore, not only does it improve inference efficiency through reduced token generation, but it also brings a 2x speedup in training. In addition to the default Adaptive Mode, ARM supports two additional reasoning modes: 1) Instruction-Guided Mode, which allows users to explicitly specify the reasoning format via special tokens -- ideal when the appropriate format is known for a batch of tasks. 2) Consensus-Guided Mode, which aggregates the outputs of the three efficient formats and resorts to Long CoT in case of disagreement, prioritizing performance with higher token usage.",
            "score": 40,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "f56b53bb4f61d90d",
            "authors": [
                "Siye Wu",
                "Jian Xie",
                "Yikai Zhang",
                "Aili Chen",
                "Kai Zhang",
                "Yu Su",
                "Yanghua Xiao"
            ],
            "affiliations": [
                "Fudan University",
                "The Ohio State University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20258.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#inference",
                    "#optimization",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ˜Ğ˜",
                    "desc": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (ARM) Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ada-GRPO Ğ´Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. ARM ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ° Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ñ‚Ñ€Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° (Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚, ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ°Ñ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ° Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ğ¸ ĞºĞ¾Ğ´) Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ¹ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ¸ Ğ¼Ñ‹ÑĞ»ĞµĞ¹. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², ÑĞ¾ĞºÑ€Ğ°Ñ‰Ğ°Ñ Ğ¸Ñ… Ğ² ÑÑ€ĞµĞ´Ğ½ĞµĞ¼ Ğ½Ğ° 30%, Ğ¸ Ğ´Ğ¾ 70% Ğ² Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ÑĞ»ÑƒÑ‡Ğ°ÑÑ…, Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ARM Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼Ñ‹ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼Ğ¸ Ğ¸ ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑĞ¾Ğ¼ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Smart Reasoning: Less Tokens, More Efficiency!",
                    "desc": "The Adaptive Reasoning Model (ARM) introduces a novel approach to optimize reasoning in AI by dynamically selecting reasoning formats based on task complexity. It addresses the common issue of excessive token usage, known as the 'overthinking' problem, by employing Ada-GRPO, a refined version of Group Relative Policy Optimization. ARM can utilize various reasoning formats, including Direct Answer and Short CoT, to enhance efficiency while maintaining performance levels similar to more complex methods like Long CoT. This model not only reduces token consumption by up to 70% but also accelerates training speed by two times, making it a significant advancement in autonomous AI reasoning."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”æ¨ç†ï¼Œæå‡æ•ˆç‡ä¸æ€§èƒ½",
                    "desc": "è‡ªé€‚åº”æ¨ç†æ¨¡å‹ï¼ˆARMï¼‰é€šè¿‡ä½¿ç”¨Ada-GRPOæ¥å‡å°‘ä»¤ç‰Œä½¿ç”¨é‡ï¼Œæé«˜ä¸åŒæ¨ç†æ¨¡å¼ä¸‹çš„æ•ˆç‡ã€‚å¤§å‹æ¨ç†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´æ¨ç†ä»¤ç‰Œä½¿ç”¨çš„èƒ½åŠ›ï¼Œå¯¼è‡´è¿‡åº¦æ¨ç†çš„é—®é¢˜ã€‚ARMèƒ½å¤Ÿæ ¹æ®å…·ä½“ä»»åŠ¡è‡ªé€‚åº”é€‰æ‹©åˆé€‚çš„æ¨ç†æ ¼å¼ï¼ŒåŒ…æ‹¬ç›´æ¥å›ç­”ã€ç®€çŸ­é“¾å¼æ¨ç†å’Œä»£ç ç­‰é«˜æ•ˆæ ¼å¼ï¼Œä»¥åŠæ›´å¤æ‚çš„é•¿é“¾å¼æ¨ç†ã€‚é€šè¿‡Ada-GRPOï¼ŒARMå®ç°äº†é«˜è¾¾70%çš„ä»¤ç‰ŒèŠ‚çœï¼ŒåŒæ—¶ä¿æŒä¸ä»…ä¾èµ–é•¿é“¾å¼æ¨ç†çš„æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19914",
            "title": "Enigmata: Scaling Logical Reasoning in Large Language Models with\n  Synthetic Verifiable Puzzles",
            "url": "https://huggingface.co/papers/2505.19914",
            "abstract": "Enigmata is a comprehensive suite for improving LLMs in puzzle reasoning through scalable multi-task RL training, leading to better performance on benchmarks and advanced math tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at advanced reasoning tasks like math and coding via Reinforcement Learning with Verifiable Rewards (RLVR), but still struggle with puzzles solvable by humans without domain knowledge. We introduce Enigmata, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks across seven categories, each with 1) a generator that produces unlimited examples with controllable difficulty and 2) a rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration. We further propose Enigmata-Eval, a rigorous benchmark, and develop optimized multi-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multi-tasking trade-off. When trained on larger models like Seed1.5-Thinking (20B activated parameters and 200B total parameters), puzzle data from Enigmata further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of Enigmata. This work offers a unified, controllable framework for advancing logical reasoning in LLMs. Resources of this work can be found at https://seed-enigmata.github.io.",
            "score": 33,
            "issue_id": 3970,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "607e56f504f7f777",
            "authors": [
                "Jiangjie Chen",
                "Qianyu He",
                "Siyu Yuan",
                "Aili Chen",
                "Zhicheng Cai",
                "Weinan Dai",
                "Hongli Yu",
                "Qiying Yu",
                "Xuefeng Li",
                "Jiaze Chen",
                "Hao Zhou",
                "Mingxuan Wang"
            ],
            "affiliations": [
                "ByteDance Seed",
                "Fudan University",
                "Institute for AI Industry Research (AIR), Tsinghua University",
                "Nanjing University",
                "SIA-Lab of Tsinghua AIR and ByteDance Seed",
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19914.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#math",
                    "#training",
                    "#rl",
                    "#optimization",
                    "#benchmark",
                    "#dataset"
                ],
                "emoji": "ğŸ§©",
                "ru": {
                    "title": "Enigmata: Ğ¿Ñ€Ğ¾ĞºĞ°Ñ‡ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğ»Ğ¾Ğ¼ĞºĞ¸",
                    "desc": "Enigmata - ÑÑ‚Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğ»Ğ¾Ğ¼Ğ¾Ğº Ñƒ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ 36 Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ² ÑĞµĞ¼Ğ¸ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑÑ…, ĞºĞ°Ğ¶Ğ´Ğ°Ñ Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¸ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Qwen2.5-32B-Enigmata, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Enigmata, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ğ¿Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğ»Ğ¾Ğ¼Ğ¾Ğº Ğ¸ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼. Ğ”Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆÑƒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² LLM."
                },
                "en": {
                    "title": "Enhancing Puzzle Reasoning in LLMs with Enigmata",
                    "desc": "Enigmata is a novel framework designed to enhance Large Language Models (LLMs) in solving puzzles through scalable multi-task Reinforcement Learning (RL) training. It features a suite of 36 tasks across seven categories, each equipped with a generator for creating diverse examples and a rule-based verifier for automatic assessment. This setup allows for efficient training and evaluation, leading to improved performance on puzzle reasoning benchmarks and advanced math tasks. The results demonstrate that models trained with Enigmata, like Qwen2.5-32B-Enigmata, outperform existing models and show strong generalization capabilities in various reasoning challenges."
                },
                "zh": {
                    "title": "æå‡è§£è°œæ¨ç†èƒ½åŠ›çš„ç»Ÿä¸€æ¡†æ¶",
                    "desc": "Enigmataæ˜¯ä¸€ä¸ªå…¨é¢çš„å·¥å…·å¥—ä»¶ï¼Œæ—¨åœ¨é€šè¿‡å¯æ‰©å±•çš„å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£è°œæ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚è¯¥å¥—ä»¶åŒ…å«36ä¸ªä»»åŠ¡ï¼Œåˆ†ä¸ºä¸ƒä¸ªç±»åˆ«ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œå¯ä»¥ç”Ÿæˆå¯æ§éš¾åº¦çš„æ— é™ç¤ºä¾‹ï¼Œä»¥åŠä¸€ä¸ªåŸºäºè§„åˆ™çš„éªŒè¯å™¨ï¼Œç”¨äºè‡ªåŠ¨è¯„ä¼°ã€‚é€šè¿‡è¿™ç§ç”Ÿæˆå™¨-éªŒè¯å™¨è®¾è®¡ï¼ŒEnigmataæ”¯æŒå¯æ‰©å±•çš„å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œå¹¶å®ç°äº†ç»†è‡´çš„åˆ†æå’Œæ— ç¼çš„å¯éªŒè¯å¥–åŠ±é›†æˆã€‚ç»è¿‡è®­ç»ƒçš„æ¨¡å‹Qwen2.5-32B-Enigmataåœ¨è§£è°œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å…¶ä»–æ¨¡å‹ï¼Œå±•ç¤ºäº†Enigmataåœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„ç»Ÿä¸€å’Œå¯æ§æ¡†æ¶ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19815",
            "title": "Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective",
            "url": "https://huggingface.co/papers/2505.19815",
            "abstract": "LLM reasoning is understood through a meta-learning framework, treating reasoning as pseudo-gradient descent and questions as individual tasks, which enhances generalization and provides practical insights for improvement.  \t\t\t\t\tAI-generated summary \t\t\t\t We propose a novel framework for comprehending the reasoning capabilities of large language models (LLMs) through the perspective of meta-learning. By conceptualizing reasoning trajectories as pseudo-gradient descent updates to the LLM's parameters, we identify parallels between LLM reasoning and various meta-learning paradigms. We formalize the training process for reasoning tasks as a meta-learning setup, with each question treated as an individual task, and reasoning trajectories serving as the inner loop optimization for adapting model parameters. Once trained on a diverse set of questions, the LLM develops fundamental reasoning capabilities that can generalize to previously unseen questions. Extensive empirical evaluations substantiate the strong connection between LLM reasoning and meta-learning, exploring several issues of significant interest from a meta-learning standpoint. Our work not only enhances the understanding of LLM reasoning but also provides practical insights for improving these models through established meta-learning techniques.",
            "score": 33,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "145614af2451e525",
            "authors": [
                "Junnan Liu",
                "Hongwei Liu",
                "Linchen Xiao",
                "Shudong Liu",
                "Taolin Zhang",
                "Zihan Ma",
                "Songyang Zhang",
                "Kai Chen"
            ],
            "affiliations": [
                "Shanghai AI Laboratory"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19815.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#math",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ LLM ĞºĞ°Ğº Ğ¼ĞµÑ‚Ğ°-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¸Ğ·Ğ¼Ñƒ Ğ¼ĞµÑ‚Ğ°-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ ĞºĞ°Ğº Ğ¿ÑĞµĞ²Ğ´Ğ¾-Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ ÑĞ¿ÑƒÑĞº Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸ LLM Ğ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ğ°Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ°-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ÑÑ ĞºĞ°Ğº Ğ¼ĞµÑ‚Ğ°-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ, Ğ³Ğ´Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚ ÑĞ¸Ğ»ÑŒĞ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸ LLM Ğ¸ Ğ¼ĞµÑ‚Ğ°-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Unlocking LLM Reasoning through Meta-Learning",
                    "desc": "This paper introduces a new way to understand how large language models (LLMs) reason by using a meta-learning framework. It treats reasoning as a process similar to pseudo-gradient descent, where each question is seen as a separate task. By training the LLM on a variety of questions, it learns to adapt its parameters effectively, improving its reasoning skills. The findings show a strong link between LLM reasoning and meta-learning, offering valuable strategies for enhancing model performance."
                },
                "zh": {
                    "title": "é€šè¿‡å…ƒå­¦ä¹ æå‡LLMæ¨ç†èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé€šè¿‡å…ƒå­¦ä¹ çš„è§†è§’æ¥ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬å°†æ¨ç†è¿‡ç¨‹è§†ä¸ºå¯¹LLMå‚æ•°çš„ä¼ªæ¢¯åº¦ä¸‹é™æ›´æ–°ï¼Œå°†æ¯ä¸ªé—®é¢˜è§†ä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡åœ¨å¤šæ ·åŒ–é—®é¢˜é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒLLMèƒ½å¤Ÿå‘å±•å‡ºåŸºæœ¬çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶èƒ½æ¨å¹¿åˆ°æœªè§è¿‡çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ä»…åŠ æ·±äº†å¯¹LLMæ¨ç†çš„ç†è§£ï¼Œè¿˜æä¾›äº†é€šè¿‡å·²å»ºç«‹çš„å…ƒå­¦ä¹ æŠ€æœ¯æ¥æ”¹è¿›è¿™äº›æ¨¡å‹çš„å®ç”¨è§è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18545",
            "title": "B-score: Detecting biases in large language models using response\n  history",
            "url": "https://huggingface.co/papers/2505.18545",
            "abstract": "Large language models (LLMs) often exhibit strong biases, e.g, against women or in favor of the number 7. We investigate whether LLMs would be able to output less biased answers when allowed to observe their prior answers to the same question in a multi-turn conversation. To understand which types of questions invite more biased answers, we test LLMs on our proposed set of questions that span 9 topics and belong to three types: (1) Subjective; (2) Random; and (3) Objective. Interestingly, LLMs are able to \"de-bias\" themselves in a multi-turn conversation in response to questions that seek an Random, unbiased answer. Furthermore, we propose B-score, a novel metric that is effective in detecting biases to Subjective, Random, Easy, and Hard questions. On MMLU, HLE, and CSQA, leveraging B-score substantially improves the verification accuracy of LLM answers (i.e, accepting LLM correct answers and rejecting incorrect ones) compared to using verbalized confidence scores or the frequency of single-turn answers alone. Code and data are available at: https://b-score.github.io.",
            "score": 25,
            "issue_id": 3967,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "60113080c6881b99",
            "authors": [
                "An Vo",
                "Mohammad Reza Taesiri",
                "Daeyoung Kim",
                "Anh Totti Nguyen"
            ],
            "affiliations": [
                "Auburn University, USA",
                "KAIST, South Korea",
                "University of Alberta, Canada"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18545.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#ethics",
                    "#hallucinations",
                    "#benchmark",
                    "#rlhf"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ¡Ğ°Ğ¼Ğ¾ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸ Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM) Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ĞµĞµ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ñ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğµ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ğ¾ 9 Ñ‚ĞµĞ¼Ğ°Ğ¼, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑÑƒĞ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ, ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ‚Ğ¸Ğ¿Ñ‹. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ LLM ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ñ‹ ÑĞ½Ğ¸Ğ¶Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ñ… Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğµ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾, Ğ½ĞµĞ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ B-score Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² LLM Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "De-biasing LLMs Through Multi-Turn Conversations",
                    "desc": "This paper explores how large language models (LLMs) can reduce their biases during multi-turn conversations by referencing their previous answers. The authors categorize questions into three types: Subjective, Random, and Objective, and find that LLMs can effectively 'de-bias' themselves when responding to Random questions. They introduce a new metric called B-score, which helps identify biases in LLM responses across various question types. The results show that using B-score enhances the accuracy of verifying LLM answers compared to traditional methods like confidence scores."
                },
                "zh": {
                    "title": "å¤šè½®å¯¹è¯ä¸­çš„å»åè§èƒ½åŠ›",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¸¸å¸¸è¡¨ç°å‡ºæ˜æ˜¾çš„åè§ï¼Œä¾‹å¦‚å¯¹å¥³æ€§çš„åè§æˆ–å¯¹æ•°å­—7çš„åå¥½ã€‚æˆ‘ä»¬ç ”ç©¶äº†åœ¨å¤šè½®å¯¹è¯ä¸­ï¼ŒLLMsæ˜¯å¦èƒ½å¤Ÿåœ¨è§‚å¯Ÿåˆ°è‡ªå·±ä¹‹å‰çš„å›ç­”åï¼Œè¾“å‡ºæ›´å°‘åè§çš„ç­”æ¡ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç»„æ¶µç›–9ä¸ªä¸»é¢˜çš„æµ‹è¯•é—®é¢˜ï¼Œåˆ†ä¸ºä¸»è§‚ã€éšæœºå’Œå®¢è§‚ä¸‰ç§ç±»å‹ï¼Œä»¥äº†è§£å“ªäº›é—®é¢˜æ›´å®¹æ˜“å¼•å‘åè§ã€‚ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨é¢å¯¹å¯»æ±‚éšæœºã€ä¸åè§ç­”æ¡ˆçš„é—®é¢˜æ—¶ï¼Œèƒ½å¤Ÿè‡ªæˆ‘â€œå»åè§â€ï¼Œå¹¶ä¸”æˆ‘ä»¬æå‡ºçš„B-scoreæŒ‡æ ‡åœ¨æ£€æµ‹åè§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æé«˜äº†LLMç­”æ¡ˆçš„éªŒè¯å‡†ç¡®æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20259",
            "title": "Lifelong Safety Alignment for Language Models",
            "url": "https://huggingface.co/papers/2505.20259",
            "abstract": "A lifecycle safety alignment framework employs a Meta-Attacker and Defender to adapt LLMs to novel jailbreaking strategies, improving robustness in deployment.  \t\t\t\t\tAI-generated summary \t\t\t\t LLMs have made impressive progress, but their growing capabilities also expose them to highly flexible jailbreaking attacks designed to bypass safety alignment. While many existing defenses focus on known types of attacks, it is more critical to prepare LLMs for unseen attacks that may arise during deployment. To address this, we propose a lifelong safety alignment framework that enables LLMs to continuously adapt to new and evolving jailbreaking strategies. Our framework introduces a competitive setup between two components: a Meta-Attacker, trained to actively discover novel jailbreaking strategies, and a Defender, trained to resist them. To effectively warm up the Meta-Attacker, we first leverage the GPT-4o API to extract key insights from a large collection of jailbreak-related research papers. Through iterative training, the first iteration Meta-Attacker achieves a 73% attack success rate (ASR) on RR and a 57% transfer ASR on LAT using only single-turn attacks. Meanwhile, the Defender progressively improves its robustness and ultimately reduces the Meta-Attacker's success rate to just 7%, enabling safer and more reliable deployment of LLMs in open-ended environments. The code is available at https://github.com/sail-sg/LifelongSafetyAlignment.",
            "score": 22,
            "issue_id": 3969,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "af43851ea2378c4b",
            "authors": [
                "Haoyu Wang",
                "Zeyu Qin",
                "Yifei Zhao",
                "Chao Du",
                "Min Lin",
                "Xueqian Wang",
                "Tianyu Pang"
            ],
            "affiliations": [
                "Sea AI Lab, Singapore",
                "The Hong Kong University of Science and Technology",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20259.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#alignment",
                    "#security"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "ĞĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾Ñ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ°Ñ‚Ğ°Ğº",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ°Ñ‚Ğ°Ğº Ğ½Ğ° Ğ¸Ñ… Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñƒ. Ğ’ Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ»ĞµĞ¶Ğ¸Ñ‚ ÑĞ¾Ñ€ĞµĞ²Ğ½Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ ĞœĞµÑ‚Ğ°-ĞÑ‚Ğ°ĞºÑƒÑÑ‰Ğ¸Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ° Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹, Ğ¸ Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ½Ğ¸ĞºĞ¾Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¾ÑÑ‚ÑŒ ÑÑ‚Ğ¸Ğ¼ Ğ°Ñ‚Ğ°ĞºĞ°Ğ¼. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ GPT-4 Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ±Ğ¾Ñ‚ Ğ¿Ğ¾ Ğ²Ğ·Ğ»Ğ¾Ğ¼Ñƒ LLM Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸ ĞœĞµÑ‚Ğ°-ĞÑ‚Ğ°ĞºÑƒÑÑ‰ĞµĞ³Ğ¾. Ğ’ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ½Ğ¸Ğº ÑĞ¼Ğ¾Ğ³ ÑĞ½Ğ¸Ğ·Ğ¸Ñ‚ÑŒ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ğ°Ñ‚Ğ°Ğº Ñ 73% Ğ´Ğ¾ 7%, Ñ‡Ñ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ LLM Ğ¿Ñ€Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Adapting LLMs for Unseen Threats: A Lifelong Safety Approach",
                    "desc": "This paper presents a lifecycle safety alignment framework designed to enhance the robustness of large language models (LLMs) against jailbreaking attacks. It introduces a competitive system involving a Meta-Attacker, which learns to identify new jailbreaking strategies, and a Defender, which evolves to counter these attacks. The framework emphasizes the importance of preparing LLMs for unforeseen threats rather than just known vulnerabilities. Through iterative training, the Defender significantly reduces the Meta-Attacker's success rate, ensuring safer deployment of LLMs in dynamic environments."
                },
                "zh": {
                    "title": "æå‡LLMså®‰å…¨æ€§çš„ç”Ÿå‘½å‘¨æœŸå¯¹é½æ¡†æ¶",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ç”Ÿå‘½å‘¨æœŸå®‰å…¨å¯¹é½æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å¯¹æ–°å‹è¶Šç‹±æ”»å‡»æ—¶çš„é²æ£’æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥ä¸€ä¸ªå…ƒæ”»å‡»è€…å’Œä¸€ä¸ªé˜²å¾¡è€…çš„ç«äº‰æœºåˆ¶ï¼Œä½¿LLMsèƒ½å¤ŸæŒç»­é€‚åº”ä¸æ–­æ¼”å˜çš„è¶Šç‹±ç­–ç•¥ã€‚å…ƒæ”»å‡»è€…è´Ÿè´£ä¸»åŠ¨å‘ç°æ–°çš„è¶Šç‹±ç­–ç•¥ï¼Œè€Œé˜²å¾¡è€…åˆ™è‡´åŠ›äºæŠµå¾¡è¿™äº›æ”»å‡»ã€‚é€šè¿‡è¿­ä»£è®­ç»ƒï¼Œé˜²å¾¡è€…æ˜¾è‘—æé«˜äº†å¯¹æŠ—èƒ½åŠ›ï¼Œå°†å…ƒæ”»å‡»è€…çš„æˆåŠŸç‡é™ä½åˆ°ä»…7%ï¼Œä»è€Œå®ç°äº†LLMsåœ¨å¼€æ”¾ç¯å¢ƒä¸­çš„æ›´å®‰å…¨å¯é éƒ¨ç½²ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19209",
            "title": "MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis\n  Discovery via Hierarchical Search",
            "url": "https://huggingface.co/papers/2505.19209",
            "abstract": "A method is proposed to generate detailed scientific hypotheses using LLMs by defining and optimizing a latent reward landscape, outperforming baselines in benchmark evaluations.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) have shown promise in automating scientific hypothesis generation, yet existing approaches primarily yield coarse-grained hypotheses lacking critical methodological and experimental details. We introduce and formally define the novel task of fine-grained scientific hypothesis discovery, which entails generating detailed, experimentally actionable hypotheses from coarse initial research directions. We frame this as a combinatorial optimization problem and investigate the upper limits of LLMs' capacity to solve it when maximally leveraged. Specifically, we explore four foundational questions: (1) how to best harness an LLM's internal heuristics to formulate the fine-grained hypothesis it itself would judge as the most promising among all the possible hypotheses it might generate, based on its own internal scoring-thus defining a latent reward landscape over the hypothesis space; (2) whether such LLM-judged better hypotheses exhibit stronger alignment with ground-truth hypotheses; (3) whether shaping the reward landscape using an ensemble of diverse LLMs of similar capacity yields better outcomes than defining it with repeated instances of the strongest LLM among them; and (4) whether an ensemble of identical LLMs provides a more reliable reward landscape than a single LLM. To address these questions, we propose a hierarchical search method that incrementally proposes and integrates details into the hypothesis, progressing from general concepts to specific experimental configurations. We show that this hierarchical process smooths the reward landscape and enables more effective optimization. Empirical evaluations on a new benchmark of expert-annotated fine-grained hypotheses from recent chemistry literature show that our method consistently outperforms strong baselines.",
            "score": 22,
            "issue_id": 3968,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "cb70528ba0407554",
            "authors": [
                "Zonglin Yang",
                "Wanhao Liu",
                "Ben Gao",
                "Yujie Liu",
                "Wei Li",
                "Tong Xie",
                "Lidong Bing",
                "Wanli Ouyang",
                "Erik Cambria",
                "Dongzhan Zhou"
            ],
            "affiliations": [
                "MiroMind",
                "Nanyang Technological University",
                "National University of Singapore",
                "Shanghai Artificial Intelligence Laboratory",
                "University of New South Wales",
                "University of Science and Technology of China",
                "Wuhan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19209.jpg",
            "data": {
                "categories": [
                    "#science",
                    "#rlhf",
                    "#benchmark",
                    "#multimodal",
                    "#optimization"
                ],
                "emoji": "ğŸ§ª",
                "ru": {
                    "title": "Ğ˜ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ¶Ğµ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°: Ğ¾Ñ‚ Ğ¸Ğ´ĞµĞ¸ Ğº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñƒ",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ· Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ğ°Ğ½Ğ´ÑˆĞ°Ñ„Ñ‚Ğ° Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞµ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ² Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñƒ, Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ³Ğ°ÑÑÑŒ Ğ¾Ñ‚ Ğ¾Ğ±Ñ‰Ğ¸Ñ… ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¹ Ğº ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ»Ğ°Ğ½Ğ´ÑˆĞ°Ñ„Ñ‚ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ½Ğ° Ğ½Ğ¾Ğ²Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğµ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ğ¾-Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ· Ğ¸Ğ· Ğ½ĞµĞ´Ğ°Ğ²Ğ½ĞµĞ¹ Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Unlocking Detailed Scientific Hypotheses with LLMs",
                    "desc": "This paper presents a new method for generating detailed scientific hypotheses using large language models (LLMs). It defines the task of fine-grained scientific hypothesis discovery, which focuses on creating actionable hypotheses from broader research ideas. The authors frame this task as a combinatorial optimization problem and explore how to optimize the hypothesis generation process by leveraging LLMs' internal scoring mechanisms. Their hierarchical search method improves the quality of generated hypotheses, as demonstrated by superior performance on benchmark evaluations compared to existing methods."
                },
                "zh": {
                    "title": "åˆ©ç”¨LLMsç”Ÿæˆç»†ç²’åº¦ç§‘å­¦å‡è®¾çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆè¯¦ç»†ç§‘å­¦å‡è®¾çš„æ–¹æ³•ï¼Œé€šè¿‡å®šä¹‰å’Œä¼˜åŒ–æ½œåœ¨å¥–åŠ±æ™¯è§‚ï¼Œè¶…è¶Šäº†åŸºå‡†è¯„ä¼°ä¸­çš„å…¶ä»–æ–¹æ³•ã€‚æˆ‘ä»¬é¦–æ¬¡æ­£å¼å®šä¹‰äº†ç»†ç²’åº¦ç§‘å­¦å‡è®¾å‘ç°çš„ä»»åŠ¡ï¼Œæ—¨åœ¨ä»ç²—ç•¥çš„ç ”ç©¶æ–¹å‘ç”Ÿæˆå¯å®éªŒæ“ä½œçš„è¯¦ç»†å‡è®¾ã€‚æˆ‘ä»¬å°†æ­¤ä»»åŠ¡è§†ä¸ºç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå¹¶æ¢è®¨LLMsåœ¨æœ€å¤§åŒ–åˆ©ç”¨æ—¶è§£å†³è¯¥é—®é¢˜çš„èƒ½åŠ›ä¸Šé™ã€‚é€šè¿‡åˆ†å±‚æœç´¢æ–¹æ³•ï¼Œæˆ‘ä»¬é€æ­¥æå‡ºå¹¶æ•´åˆå‡è®¾ç»†èŠ‚ï¼Œä»ä¸€èˆ¬æ¦‚å¿µåˆ°å…·ä½“å®éªŒé…ç½®ï¼Œå®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨æ–°åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18675",
            "title": "Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual\n  Reasoning from Transit Maps",
            "url": "https://huggingface.co/papers/2505.18675",
            "abstract": "Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic. However, their capacity for reasoning tasks involving fine-grained visual understanding remains insufficiently evaluated. To address this gap, we introduce ReasonMap, a benchmark designed to assess the fine-grained visual understanding and spatial reasoning abilities of MLLMs. ReasonMap encompasses high-resolution transit maps from 30 cities across 13 countries and includes 1,008 question-answer pairs spanning two question types and three templates. Furthermore, we design a two-level evaluation pipeline that properly assesses answer correctness and quality. Comprehensive evaluations of 15 popular MLLMs, including both base and reasoning variants, reveal a counterintuitive pattern: among open-source models, base models outperform reasoning ones, while the opposite trend is observed in closed-source models. Additionally, performance generally degrades when visual inputs are masked, indicating that while MLLMs can leverage prior knowledge to answer some questions, fine-grained visual reasoning tasks still require genuine visual perception for strong performance. Our benchmark study offers new insights into visual reasoning and contributes to investigating the gap between open-source and closed-source models.",
            "score": 22,
            "issue_id": 3967,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "61fe1af51f08d30f",
            "authors": [
                "Sicheng Feng",
                "Song Wang",
                "Shuyi Ouyang",
                "Lingdong Kong",
                "Zikai Song",
                "Jianke Zhu",
                "Huan Wang",
                "Xinchao Wang"
            ],
            "affiliations": [
                "Huazhong University of Science and Technology",
                "National University of Singapore",
                "Westlake University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18675.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#multimodal",
                    "#benchmark",
                    "#cv",
                    "#open_source"
                ],
                "emoji": "ğŸ—ºï¸",
                "ru": {
                    "title": "ReasonMap: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ReasonMap - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ ĞºĞ°Ñ€Ñ‚Ñ‹ Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ¸Ğ· 30 Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ² Ğ¸ 1008 Ğ¿Ğ°Ñ€ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ ÑÑ€ĞµĞ´Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸, Ğ° Ñƒ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµÑ‚ÑÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ Ñ‚ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ñ. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ½Ğ° Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ğ¿Ğ¾-Ğ¿Ñ€ĞµĞ¶Ğ½ĞµĞ¼Ñƒ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¿Ğ¾Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ğµ."
                },
                "en": {
                    "title": "Evaluating Visual Reasoning in Multimodal Models with ReasonMap",
                    "desc": "This paper introduces ReasonMap, a benchmark aimed at evaluating the fine-grained visual understanding and spatial reasoning capabilities of multimodal large language models (MLLMs). The benchmark includes high-resolution transit maps and a set of question-answer pairs to rigorously test the models' reasoning abilities. The study finds that base models often outperform reasoning variants in open-source settings, while closed-source models show the opposite trend. Additionally, the results indicate that masking visual inputs generally leads to decreased performance, highlighting the importance of genuine visual perception in complex reasoning tasks."
                },
                "zh": {
                    "title": "ç»†ç²’åº¦è§†è§‰æ¨ç†çš„æ–°åŸºå‡†",
                    "desc": "å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨ç»†ç²’åº¦è§†è§‰ç†è§£çš„æ¨ç†ä»»åŠ¡ä¸Šä»ç„¶ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ReasonMapï¼Œä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsçš„ç»†ç²’åº¦è§†è§‰ç†è§£å’Œç©ºé—´æ¨ç†èƒ½åŠ›ã€‚ReasonMapåŒ…å«æ¥è‡ª13ä¸ªå›½å®¶30ä¸ªåŸå¸‚çš„é«˜åˆ†è¾¨ç‡äº¤é€šåœ°å›¾ï¼Œå¹¶è®¾è®¡äº†ä¸¤çº§è¯„ä¼°æµç¨‹æ¥å‡†ç¡®è¯„ä¼°ç­”æ¡ˆçš„æ­£ç¡®æ€§å’Œè´¨é‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†ä¸€ä¸ªåç›´è§‰çš„æ¨¡å¼ï¼šåœ¨å¼€æºæ¨¡å‹ä¸­ï¼ŒåŸºç¡€æ¨¡å‹çš„è¡¨ç°ä¼˜äºæ¨ç†æ¨¡å‹ï¼Œè€Œåœ¨é—­æºæ¨¡å‹ä¸­åˆ™ç›¸åã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19439",
            "title": "Surrogate Signals from Format and Length: Reinforcement Learning for\n  Solving Mathematical Problems without Ground Truth Answers",
            "url": "https://huggingface.co/papers/2505.19439",
            "abstract": "Large Language Models have achieved remarkable success in natural language processing tasks, with Reinforcement Learning playing a key role in adapting them to specific applications. However, obtaining ground truth answers for training LLMs in mathematical problem-solving is often challenging, costly, and sometimes unfeasible. This research delves into the utilization of format and length as surrogate signals to train LLMs for mathematical problem-solving, bypassing the need for traditional ground truth answers.Our study shows that a reward function centered on format correctness alone can yield performance improvements comparable to the standard GRPO algorithm in early phases. Recognizing the limitations of format-only rewards in the later phases, we incorporate length-based rewards. The resulting GRPO approach, leveraging format-length surrogate signals, not only matches but surpasses the performance of the standard GRPO algorithm relying on ground truth answers in certain scenarios, achieving 40.0\\% accuracy on AIME2024 with a 7B base model. Through systematic exploration and experimentation, this research not only offers a practical solution for training LLMs to solve mathematical problems and reducing the dependence on extensive ground truth data collection, but also reveals the essence of why our label-free approach succeeds: base model is like an excellent student who has already mastered mathematical and logical reasoning skills, but performs poorly on the test paper, it simply needs to develop good answering habits to achieve outstanding results in exams , in other words, to unlock the capabilities it already possesses.",
            "score": 20,
            "issue_id": 3971,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "fc8a2a184c9655b1",
            "authors": [
                "Rihui Xin",
                "Han Liu",
                "Zecheng Wang",
                "Yupeng Zhang",
                "Dianbo Sui",
                "Xiaolin Hu",
                "Bingning Wang"
            ],
            "affiliations": [
                "Baichuan Inc.",
                "Harbin Institute of Technology",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19439.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#math",
                    "#rl",
                    "#optimization",
                    "#training"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ Ğ±ĞµĞ· Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ²ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ±ĞµĞ· Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ² Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°, Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ´Ğ°Ñ‚ÑŒ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ñ‹Ğµ ÑĞ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ¼ GRPO Ğ½Ğ° Ñ€Ğ°Ğ½Ğ½Ğ¸Ñ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ…. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ GRPO, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğ¹ ÑÑƒÑ€Ñ€Ğ¾Ğ³Ğ°Ñ‚Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ñ‹, Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚, Ğ½Ğ¾ Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° GRPO Ğ² Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ ÑÑƒÑ‚ÑŒ ÑƒÑĞ¿ĞµÑ…Ğ° Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ±ĞµĞ· Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğº: Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ° Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğ¼Ñƒ ÑƒÑ‡ĞµĞ½Ğ¸ĞºÑƒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚ÑŒ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞºĞ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ğ´Ğ°ÑÑ‰Ğ¸Ñ…ÑÑ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞºĞ·Ğ°Ğ¼ĞµĞ½Ğ°Ñ…."
                },
                "en": {
                    "title": "Unlocking LLMs: Training with Format and Length Signals",
                    "desc": "This paper explores how to train Large Language Models (LLMs) for solving mathematical problems without relying on traditional ground truth answers. It introduces the idea of using format and length as surrogate signals to guide the training process. The research demonstrates that a reward function focused on format correctness can improve performance significantly, especially in the early training phases. By incorporating length-based rewards later on, the proposed GRPO approach not only matches but exceeds the performance of standard methods that depend on ground truth data, achieving notable accuracy on mathematical problem sets."
                },
                "zh": {
                    "title": "åˆ©ç”¨æ ¼å¼ä¸é•¿åº¦æå‡æ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨æ ¼å¼å’Œé•¿åº¦ä½œä¸ºæ›¿ä»£ä¿¡å·ï¼Œè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§£å†³æ•°å­¦é—®é¢˜ï¼Œè€Œæ— éœ€ä¼ ç»Ÿçš„çœŸå®ç­”æ¡ˆã€‚æˆ‘ä»¬å‘ç°ï¼Œä»…ä¾é æ ¼å¼æ­£ç¡®æ€§çš„å¥–åŠ±å‡½æ•°ï¼Œåœ¨æ—©æœŸé˜¶æ®µå¯ä»¥è·å¾—ä¸æ ‡å‡†GRPOç®—æ³•ç›¸å½“çš„æ€§èƒ½æå‡ã€‚éšç€è®­ç»ƒçš„æ·±å…¥ï¼Œæ ¼å¼å¥–åŠ±çš„å±€é™æ€§æ˜¾ç°ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥äº†åŸºäºé•¿åº¦çš„å¥–åŠ±ã€‚æœ€ç»ˆçš„GRPOæ–¹æ³•åˆ©ç”¨æ ¼å¼-é•¿åº¦æ›¿ä»£ä¿¡å·ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ä¸ä»…åŒ¹é…äº†æ ‡å‡†GRPOç®—æ³•çš„è¡¨ç°ï¼Œè¿˜è¶…è¶Šäº†å…¶åœ¨AIME2024ä¸Šçš„è¡¨ç°ï¼Œè¾¾åˆ°äº†40.0%çš„å‡†ç¡®ç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18601",
            "title": "Flex-Judge: Think Once, Judge Anywhere",
            "url": "https://huggingface.co/papers/2505.18601",
            "abstract": "Flex-Judge uses minimal textual reasoning data to generalize across multiple modalities and evaluation formats, outperforming state-of-the-art models in multimodal evaluations.  \t\t\t\t\tAI-generated summary \t\t\t\t Human-generated reward signals are critical for aligning generative models with human preferences, guiding both training and inference-time evaluations. While large language models (LLMs) employed as proxy evaluators, i.e., LLM-as-a-Judge, significantly reduce the costs associated with manual annotations, they typically require extensive modality-specific training data and fail to generalize well across diverse multimodal tasks. In this paper, we propose Flex-Judge, a reasoning-guided multimodal judge model that leverages minimal textual reasoning data to robustly generalize across multiple modalities and evaluation formats. Our core intuition is that structured textual reasoning explanations inherently encode generalizable decision-making patterns, enabling an effective transfer to multimodal judgments, e.g., with images or videos. Empirical results demonstrate that Flex-Judge, despite being trained on significantly fewer text data, achieves competitive or superior performance compared to state-of-the-art commercial APIs and extensively trained multimodal evaluators. Notably, Flex-Judge presents broad impact in modalities like molecule, where comprehensive evaluation benchmarks are scarce, underscoring its practical value in resource-constrained domains. Our framework highlights reasoning-based text supervision as a powerful, cost-effective alternative to traditional annotation-intensive approaches, substantially advancing scalable multimodal model-as-a-judge.",
            "score": 19,
            "issue_id": 3968,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "a0fd5b19cac44ab0",
            "authors": [
                "Jongwoo Ko",
                "Sungnyun Kim",
                "Sungwoo Cho",
                "Se-Young Yun"
            ],
            "affiliations": [
                "KAIST AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18601.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#rlhf",
                    "#alignment",
                    "#benchmark",
                    "#multimodal",
                    "#transfer_learning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° - ĞºĞ»ÑÑ‡ Ğº ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ",
                    "desc": "Flex-Judge - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ğ±ÑŠĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾. Flex-Judge Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¸Ğµ API Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸ĞºĞ¸, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¾Ğ±ÑŠĞµĞ¼Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾ÑĞ¾Ğ±ÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ… Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸, Ñ‚Ğ°ĞºĞ¸Ñ… ĞºĞ°Ğº Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ»ÑÑ€Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ."
                },
                "en": {
                    "title": "Flex-Judge: Efficient Multimodal Evaluation with Minimal Data",
                    "desc": "Flex-Judge is a novel multimodal evaluation model that utilizes minimal textual reasoning data to effectively generalize across various modalities and evaluation formats. It addresses the limitations of existing models that require extensive, modality-specific training data and often struggle with diverse tasks. By leveraging structured textual reasoning, Flex-Judge captures generalizable decision-making patterns, allowing it to perform well even with limited training resources. Empirical results show that it outperforms state-of-the-art models, making it a valuable tool in scenarios with scarce evaluation benchmarks."
                },
                "zh": {
                    "title": "Flex-Judgeï¼šç”¨æœ€å°‘æ•°æ®å®ç°å¤šæ¨¡æ€è¯„ä¼°çš„çªç ´",
                    "desc": "Flex-Judgeæ˜¯ä¸€ç§å¤šæ¨¡æ€è¯„ä¼°æ¨¡å‹ï¼Œå®ƒåˆ©ç”¨æœ€å°‘çš„æ–‡æœ¬æ¨ç†æ•°æ®æ¥å®ç°è·¨å¤šç§æ¨¡æ€å’Œè¯„ä¼°æ ¼å¼çš„æ³›åŒ–ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“æ„åŒ–çš„æ–‡æœ¬æ¨ç†è§£é‡Šï¼Œæ•æ‰åˆ°å¯è½¬ç§»çš„å†³ç­–æ¨¡å¼ï¼Œä»è€Œåœ¨å›¾åƒæˆ–è§†é¢‘ç­‰å¤šæ¨¡æ€åˆ¤æ–­ä¸­è¡¨ç°å‡ºè‰²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡Flex-Judgeçš„è®­ç»ƒæ•°æ®è¿œå°‘äºå…¶ä»–æ¨¡å‹ï¼Œä½†å…¶æ€§èƒ½ä»ç„¶ä¸æœ€å…ˆè¿›çš„å•†ä¸šAPIç›¸å½“ï¼Œç”šè‡³æ›´ä¼˜ã€‚è¯¥æ¡†æ¶å±•ç¤ºäº†åŸºäºæ¨ç†çš„æ–‡æœ¬ç›‘ç£ä½œä¸ºä¸€ç§å¼ºå¤§ä¸”ç»æµçš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ¨åŠ¨äº†å¯æ‰©å±•çš„å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19590",
            "title": "Learning to Reason without External Rewards",
            "url": "https://huggingface.co/papers/2505.19590",
            "abstract": "Intuitor, a Reinforcement Learning from Internal Feedback method, uses self-certainty as a reward signal to enable unsupervised learning of large language models, achieving performance comparable to GRPO on benchmarks and superior generalization.  \t\t\t\t\tAI-generated summary \t\t\t\t Training large language models (LLMs) for complex reasoning via Reinforcement Learning with Verifiable Rewards (RLVR) is effective but limited by reliance on costly, domain-specific supervision. We explore Reinforcement Learning from Internal Feedback (RLIF), a framework that enables LLMs to learn from intrinsic signals without external rewards or labeled data. We propose Intuitor, an RLIF method that uses a model's own confidence, termed self-certainty, as its sole reward signal. Intuitor replaces external rewards in Group Relative Policy Optimization (GRPO) with self-certainty scores, enabling fully unsupervised learning. Experiments demonstrate that Intuitor matches GRPO's performance on mathematical benchmarks while achieving superior generalization to out-of-domain tasks like code generation, without requiring gold solutions or test cases. Our findings show that intrinsic model signals can drive effective learning across domains, offering a scalable alternative to RLVR for autonomous AI systems where verifiable rewards are unavailable. Code is available at https://github.com/sunblaze-ucb/Intuitor",
            "score": 18,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "d847f0743c20b2e9",
            "authors": [
                "Xuandong Zhao",
                "Zhewei Kang",
                "Aosong Feng",
                "Sergey Levine",
                "Dawn Song"
            ],
            "affiliations": [
                "UC Berkeley",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19590.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#rlhf",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ¡Ğ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜: Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ°Ğº Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞ¹ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Intuitor. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ°Ğ¼Ğ¾ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ° Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±ĞµĞ· Ğ²Ğ½ĞµÑˆĞ½ĞµĞ³Ğ¾ Ğ½Ğ°Ğ´Ğ·Ğ¾Ñ€Ğ°. Intuitor Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ğ¾Ğ¹ Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ¼ GRPO Ğ½Ğ° ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ¾Ğ¼ĞµĞ½Ğ°Ñ…, Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ÑƒÑ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Learning from Confidence: Intuitor's Unsupervised Approach to AI",
                    "desc": "The paper introduces Intuitor, a method for Reinforcement Learning from Internal Feedback (RLIF) that allows large language models (LLMs) to learn without external supervision. Instead of relying on costly labeled data, Intuitor uses self-certainty, which is the model's own confidence in its predictions, as a reward signal. This approach enables unsupervised learning and matches the performance of existing methods like Group Relative Policy Optimization (GRPO) on benchmarks. Additionally, Intuitor demonstrates better generalization to tasks outside its training domain, such as code generation, highlighting the potential of intrinsic signals for effective learning in AI systems."
                },
                "zh": {
                    "title": "è‡ªæˆ‘ç¡®å®šæ€§é©±åŠ¨çš„æ— ç›‘ç£å­¦ä¹ ",
                    "desc": "Intuitoræ˜¯ä¸€ç§åŸºäºå†…éƒ¨åé¦ˆçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨è‡ªæˆ‘ç¡®å®šæ€§ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œæ— ç›‘ç£å­¦ä¹ ã€‚è¯¥æ–¹æ³•åœ¨æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¸GRPOç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶åœ¨ä»£ç ç”Ÿæˆç­‰é¢†åŸŸä»»åŠ¡ä¸Šå±•ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡ä½¿ç”¨æ¨¡å‹è‡ªèº«çš„ä¿¡å¿ƒåˆ†æ•°ä½œä¸ºå”¯ä¸€çš„å¥–åŠ±ä¿¡å·ï¼ŒIntuitorå®ç°äº†å®Œå…¨æ— ç›‘ç£çš„å­¦ä¹ ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå†…éƒ¨æ¨¡å‹ä¿¡å·å¯ä»¥æœ‰æ•ˆæ¨åŠ¨è·¨é¢†åŸŸçš„å­¦ä¹ ï¼Œä¸ºç¼ºä¹å¯éªŒè¯å¥–åŠ±çš„è‡ªä¸»AIç³»ç»Ÿæä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18536",
            "title": "Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal\n  Large Language Models",
            "url": "https://huggingface.co/papers/2505.18536",
            "abstract": "Standing in 2025, at a critical juncture in the pursuit of Artificial General Intelligence (AGI), reinforcement fine-tuning (RFT) has demonstrated significant potential in enhancing the reasoning capability of large language models (LLMs) and has led to the development of cutting-edge AI models such as OpenAI-o1 and DeepSeek-R1. Moreover, the efficient application of RFT to enhance the reasoning capability of multimodal large language models (MLLMs) has attracted widespread attention from the community. In this position paper, we argue that reinforcement fine-tuning powers the reasoning capability of multimodal large language models. To begin with, we provide a detailed introduction to the fundamental background knowledge that researchers interested in this field should be familiar with. Furthermore, we meticulously summarize the improvements of RFT in powering reasoning capability of MLLMs into five key points: diverse modalities, diverse tasks and domains, better training algorithms, abundant benchmarks and thriving engineering frameworks. Finally, we propose five promising directions for future research that the community might consider. We hope that this position paper will provide valuable insights to the community at this pivotal stage in the advancement toward AGI. Summary of works done on RFT for MLLMs is available at https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.",
            "score": 18,
            "issue_id": 3967,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "03c065b99c9707fe",
            "authors": [
                "Haoyuan Sun",
                "Jiaqi Wu",
                "Bo Xia",
                "Yifu Luo",
                "Yifei Zhao",
                "Kai Qin",
                "Xufei Lv",
                "Tiantian Zhang",
                "Yongzhe Chang",
                "Xueqian Wang"
            ],
            "affiliations": [
                "Tsinghua Shenzhen International Graduate School, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18536.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#training",
                    "#reasoning",
                    "#benchmark",
                    "#rlhf",
                    "#agi",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "RFT: ĞºĞ»ÑÑ‡ Ğº ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ˜Ğ˜-Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ñ‚Ğ¾Ğ½ĞºĞ¾Ğ¹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RFT) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM) Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ RFT Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒÑĞ¸Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ MLLM Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. Ğ’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ Ğ¿ÑÑ‚ÑŒ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ¾Ğ² ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ MLLM Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ RFT, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡, ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ². Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ¿ÑÑ‚ÑŒ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑÑ‚Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Reinforcement Fine-Tuning: Powering Reasoning in Multimodal AI",
                    "desc": "This paper discusses the role of reinforcement fine-tuning (RFT) in improving the reasoning abilities of multimodal large language models (MLLMs). It highlights how RFT has contributed to the development of advanced AI models and emphasizes its importance in enhancing reasoning across various tasks and domains. The authors summarize five key improvements brought by RFT, including better training algorithms and diverse benchmarks. They also suggest future research directions to further explore the potential of RFT in the quest for Artificial General Intelligence (AGI)."
                },
                "zh": {
                    "title": "å¼ºåŒ–å¾®è°ƒï¼šæ¨åŠ¨å¤šæ¨¡æ€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„å…³é”®",
                    "desc": "åœ¨2025å¹´ï¼Œå¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ï¼Œå¹¶æ¨åŠ¨äº†å¦‚OpenAI-o1å’ŒDeepSeek-R1ç­‰å‰æ²¿AIæ¨¡å‹çš„å‘å±•ã€‚RFTåœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­çš„é«˜æ•ˆåº”ç”¨å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†ç ”ç©¶è€…åº”äº†è§£çš„åŸºç¡€çŸ¥è¯†ï¼Œå¹¶æ€»ç»“äº†RFTåœ¨æå‡MLLMæ¨ç†èƒ½åŠ›æ–¹é¢çš„äº”ä¸ªå…³é”®æ”¹è¿›ç‚¹ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†äº”ä¸ªæœªæ¥ç ”ç©¶çš„æœ‰å‰æ™¯æ–¹å‘ï¼Œä»¥æœŸä¸ºAGIçš„è¿›æ­¥æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19752",
            "title": "Discrete Markov Bridge",
            "url": "https://huggingface.co/papers/2505.19752",
            "abstract": "A novel framework, Discrete Markov Bridge, is introduced for discrete data modeling with Matrix Learning and Score Learning components, demonstrating superior performance compared to existing methods on Text8 and CIFAR-10 datasets.  \t\t\t\t\tAI-generated summary \t\t\t\t Discrete diffusion has recently emerged as a promising paradigm in discrete data modeling. However, existing methods typically rely on a fixed rate transition matrix during training, which not only limits the expressiveness of latent representations, a fundamental strength of variational methods, but also constrains the overall design space. To address these limitations, we propose Discrete Markov Bridge, a novel framework specifically designed for discrete representation learning. Our approach is built upon two key components: Matrix Learning and Score Learning. We conduct a rigorous theoretical analysis, establishing formal performance guarantees for Matrix Learning and proving the convergence of the overall framework. Furthermore, we analyze the space complexity of our method, addressing practical constraints identified in prior studies. Extensive empirical evaluations validate the effectiveness of the proposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO) of 1.38 on the Text8 dataset, outperforming established baselines. Moreover, the proposed model demonstrates competitive performance on the CIFAR-10 dataset, achieving results comparable to those obtained by image-specific generation approaches.",
            "score": 15,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "ffd4e97918d0f33f",
            "authors": [
                "Hengli Li",
                "Yuxuan Wang",
                "Song-Chun Zhu",
                "Ying Nian Wu",
                "Zilong Zheng"
            ],
            "affiliations": [
                "Department of Automation, Tsinghua University",
                "Institute of Artificial Intelligence, Peking University",
                "NLCo Lab, Beijing Institute for General Artificial Intelligence",
                "State Key Laboratory of General Artificial Intelligence",
                "University of California, Los Angeles"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19752.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#data",
                    "#benchmark",
                    "#diffusion",
                    "#dataset",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "ğŸŒ‰",
                "ru": {
                    "title": "Ğ”Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ€ĞºĞ¾Ğ²ÑĞºĞ¸Ğ¹ Ğ¼Ğ¾ÑÑ‚: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Discrete Markov Bridge Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Matrix Learning Ğ¸ Score Learning. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ñƒ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¾Ğ². ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·, ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Matrix Learning Ğ¸ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ²ÑĞµĞ³Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€ĞºĞ°. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ½Ğ° Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Text8 Ğ¸ CIFAR-10."
                },
                "en": {
                    "title": "Revolutionizing Discrete Data Modeling with Discrete Markov Bridge",
                    "desc": "The paper introduces a new framework called Discrete Markov Bridge for modeling discrete data, which includes two main components: Matrix Learning and Score Learning. This framework overcomes limitations of existing methods that use a fixed transition matrix, allowing for more expressive latent representations. The authors provide theoretical guarantees for the performance of Matrix Learning and demonstrate the convergence of the entire framework. Empirical results show that Discrete Markov Bridge outperforms previous methods on the Text8 dataset and achieves competitive results on CIFAR-10, indicating its effectiveness in discrete representation learning."
                },
                "zh": {
                    "title": "ç¦»æ•£é©¬å°”å¯å¤«æ¡¥ï¼šæå‡ç¦»æ•£æ•°æ®å»ºæ¨¡çš„æ–°æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç§°ä¸ºç¦»æ•£é©¬å°”å¯å¤«æ¡¥ï¼Œä¸“é—¨ç”¨äºç¦»æ•£æ•°æ®å»ºæ¨¡ã€‚è¯¥æ¡†æ¶ç»“åˆäº†çŸ©é˜µå­¦ä¹ å’Œè¯„åˆ†å­¦ä¹ ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨è®­ç»ƒä¸­ä¾èµ–å›ºå®šè½¬ç§»çŸ©é˜µçš„å±€é™æ€§ã€‚é€šè¿‡ä¸¥æ ¼çš„ç†è®ºåˆ†æï¼Œæœ¬æ–‡ä¸ºçŸ©é˜µå­¦ä¹ å»ºç«‹äº†æ­£å¼çš„æ€§èƒ½ä¿è¯ï¼Œå¹¶è¯æ˜äº†æ•´ä½“æ¡†æ¶çš„æ”¶æ•›æ€§ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œç¦»æ•£é©¬å°”å¯å¤«æ¡¥åœ¨Text8å’ŒCIFAR-10æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œè¶…è¶Šäº†ç°æœ‰åŸºå‡†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20139",
            "title": "StructEval: Benchmarking LLMs' Capabilities to Generate Structural\n  Outputs",
            "url": "https://huggingface.co/papers/2505.20139",
            "abstract": "StructEval benchmarks Large Language Models for generating and converting structured outputs, highlighting performance gaps and challenges in producing visual content.  \t\t\t\t\tAI-generated summary \t\t\t\t As Large Language Models (LLMs) become integral to software development workflows, their ability to generate structured outputs has become critically important. We introduce StructEval, a comprehensive benchmark for evaluating LLMs' capabilities in producing both non-renderable (JSON, YAML, CSV) and renderable (HTML, React, SVG) structured formats. Unlike prior benchmarks, StructEval systematically evaluates structural fidelity across diverse formats through two paradigms: 1) generation tasks, producing structured output from natural language prompts, and 2) conversion tasks, translating between structured formats. Our benchmark encompasses 18 formats and 44 types of task, with novel metrics for format adherence and structural correctness. Results reveal significant performance gaps, even state-of-the-art models like o1-mini achieve only 75.58 average score, with open-source alternatives lagging approximately 10 points behind. We find generation tasks more challenging than conversion tasks, and producing correct visual content more difficult than generating text-only structures.",
            "score": 14,
            "issue_id": 3974,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "58742ac851da48f3",
            "authors": [
                "Jialin Yang",
                "Dongfu Jiang",
                "Lipeng He",
                "Sherman Siu",
                "Yuxuan Zhang",
                "Disen Liao",
                "Zhuofeng Li",
                "Huaye Zeng",
                "Yiming Jia",
                "Haozhe Wang",
                "Benjamin Schneider",
                "Chi Ruan",
                "Wentao Ma",
                "Zhiheng Lyu",
                "Yifei Wang",
                "Yi Lu",
                "Quy Duc Do",
                "Ziyan Jiang",
                "Ping Nie",
                "Wenhu Chen"
            ],
            "affiliations": [
                "HKUST",
                "Independent Contributor",
                "Shanghai University",
                "University of Toronto",
                "University of Waterloo",
                "Vector Institute"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20139.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#multimodal",
                    "#open_source",
                    "#benchmark"
                ],
                "emoji": "ğŸ—ï¸",
                "ru": {
                    "title": "StructEval: Ğ˜Ğ·Ğ¼ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½ÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "StructEval - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ² 18 Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°Ñ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ JSON, HTML Ğ¸ SVG. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ² Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ñƒ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¾Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ¹ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "StructEval: Bridging the Gap in Structured Output Generation for LLMs",
                    "desc": "StructEval is a new benchmark designed to assess how well Large Language Models (LLMs) can create and convert structured outputs. It evaluates the models' performance in generating formats like JSON and HTML, as well as converting between different structured formats. The benchmark includes 18 formats and 44 task types, focusing on metrics for structural fidelity and correctness. Results show that even advanced models struggle with these tasks, particularly in generating visual content compared to text-only structures."
                },
                "zh": {
                    "title": "è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›",
                    "desc": "StructEvalæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆå’Œè½¬æ¢ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚å®ƒå…³æ³¨æ¨¡å‹åœ¨ç”Ÿæˆä¸å¯æ¸²æŸ“ï¼ˆå¦‚JSONã€YAMLã€CSVï¼‰å’Œå¯æ¸²æŸ“ï¼ˆå¦‚HTMLã€Reactã€SVGï¼‰æ ¼å¼æ—¶çš„è¡¨ç°å·®è·å’ŒæŒ‘æˆ˜ã€‚è¯¥åŸºå‡†æµ‹è¯•é€šè¿‡ç”Ÿæˆä»»åŠ¡å’Œè½¬æ¢ä»»åŠ¡ä¸¤ç§æ–¹å¼ï¼Œç³»ç»Ÿåœ°è¯„ä¼°ä¸åŒæ ¼å¼çš„ç»“æ„å®Œæ•´æ€§ã€‚ç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå…¶å¹³å‡å¾—åˆ†ä¹Ÿä»…ä¸º75.58ï¼Œä¸”ç”Ÿæˆä»»åŠ¡æ¯”è½¬æ¢ä»»åŠ¡æ›´å…·æŒ‘æˆ˜æ€§ï¼Œç”Ÿæˆæ­£ç¡®çš„è§†è§‰å†…å®¹æ¯”ç”Ÿæˆçº¯æ–‡æœ¬ç»“æ„æ›´å›°éš¾ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19949",
            "title": "Which Data Attributes Stimulate Math and Code Reasoning? An\n  Investigation via Influence Functions",
            "url": "https://huggingface.co/papers/2505.19949",
            "abstract": "Influence functions are used to attribute LLMs' reasoning in math and coding to individual training elements, revealing cross-domain effects and enabling a reweighting strategy that improves model accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) have demonstrated remarkable reasoning capabilities in math and coding, often bolstered by post-training on the chain-of-thoughts (CoTs) generated by stronger models. However, existing strategies for curating such training data predominantly rely on heuristics, limiting generalizability and failing to capture subtleties underlying in data. To address these limitations, we leverage influence functions to systematically attribute LLMs' reasoning ability on math and coding to individual training examples, sequences, and tokens, enabling deeper insights into effective data characteristics. Our Influence-based Reasoning Attribution (Infra) uncovers nontrivial cross-domain effects across math and coding tasks: high-difficulty math examples improve both math and code reasoning, while low-difficulty code tasks most effectively benefit code reasoning. Based on these findings, we introduce a simple yet effective dataset reweighting strategy by flipping task difficulty, which doubles AIME24 accuracy from 10\\% to 20\\% and boosts LiveCodeBench accuracy from 33.8\\% to 35.3\\% for Qwen2.5-7B-Instruct. Moreover, our fine-grained attribution reveals that the sequence-level exploratory behaviors enhance reasoning performance in both math and code, and the token-level influence patterns are distinct for math and code reasoning: the former prefers natural language logic connectors and the latter emphasizes structural syntax.",
            "score": 14,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "1cb8e6d994dcd7db",
            "authors": [
                "Siqi Kou",
                "Qingyuan Tian",
                "Hanwen Xu",
                "Zihao Zeng",
                "Zhijie Deng"
            ],
            "affiliations": [
                "Shanghai Jiao Tong University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19949.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#data",
                    "#dataset",
                    "#optimization",
                    "#interpretability"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ ÑĞµĞºÑ€ĞµÑ‚Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ²ĞºĞ»Ğ°Ğ´Ğ° Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ² ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ€ĞµÑˆĞ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. Ğ‘Ñ‹Ğ»Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾, Ñ‡Ñ‚Ğ¾ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‚ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ ĞºĞ°Ğº Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ, Ñ‚Ğ°Ğº Ğ¸ Ğ² Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸, Ğ² Ñ‚Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ ĞºĞ°Ğº Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¸Ñ… Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¾Ğ² Ğ±Ñ‹Ğ»Ğ° Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ·Ğ²ĞµÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ğ»Ğ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğ°Ñ… AIME24 Ğ¸ LiveCodeBench. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²Ñ‹ÑĞ²Ğ¸Ğ», Ñ‡Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±ĞµĞ¸Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ…."
                },
                "en": {
                    "title": "Unlocking LLM Reasoning: Influence Functions for Enhanced Accuracy",
                    "desc": "This paper explores how influence functions can help us understand the reasoning abilities of large language models (LLMs) in math and coding tasks. By attributing the model's performance to specific training examples, the authors reveal important cross-domain effects, such as how challenging math problems can enhance coding skills. They propose a new dataset reweighting strategy that improves model accuracy significantly by adjusting the difficulty of tasks. Additionally, the study highlights distinct patterns in how LLMs utilize language for reasoning in math versus coding, providing insights for better training data curation."
                },
                "zh": {
                    "title": "åˆ©ç”¨å½±å“å‡½æ•°æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†å½±å“å‡½æ•°åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨å°†æ¨¡å‹åœ¨æ•°å­¦å’Œç¼–ç¨‹æ¨ç†ä¸­çš„è¡¨ç°å½’å› äºå…·ä½“çš„è®­ç»ƒæ ·æœ¬ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œç ”ç©¶æ­ç¤ºäº†è·¨é¢†åŸŸçš„å½±å“ï¼Œè¡¨æ˜é«˜éš¾åº¦çš„æ•°å­¦ç¤ºä¾‹å¯ä»¥åŒæ—¶æå‡æ•°å­¦å’Œç¼–ç¨‹æ¨ç†èƒ½åŠ›ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ•°æ®é›†é‡åŠ æƒç­–ç•¥ï¼Œé€šè¿‡è°ƒæ•´ä»»åŠ¡éš¾åº¦æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚æœ€åï¼Œç»†è‡´çš„å½’å› åˆ†ææ˜¾ç¤ºï¼Œåºåˆ—çº§çš„æ¢ç´¢è¡Œä¸ºåœ¨æ•°å­¦å’Œç¼–ç¨‹æ¨ç†ä¸­å‡æœ‰åŠ©äºæå‡è¡¨ç°ï¼Œè€Œåœ¨ä¸åŒä»»åŠ¡ä¸­ï¼Œæ ‡è®°çº§çš„å½±å“æ¨¡å¼ä¹Ÿå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20256",
            "title": "Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System\n  Collaboration",
            "url": "https://huggingface.co/papers/2505.20256",
            "abstract": "An end-to-end reinforcement learning framework, Omni-R1, achieves superior performance in long-horizon video-audio reasoning and fine-grained pixel understanding tasks by combining global reasoning and detail understanding systems.  \t\t\t\t\tAI-generated summary \t\t\t\t Long-horizon video-audio reasoning and fine-grained pixel understanding impose conflicting requirements on omnimodal models: dense temporal coverage demands many low-resolution frames, whereas precise grounding calls for high-resolution inputs. We tackle this trade-off with a two-system architecture: a Global Reasoning System selects informative keyframes and rewrites the task at low spatial cost, while a Detail Understanding System performs pixel-level grounding on the selected high-resolution snippets. Because ``optimal'' keyframe selection and reformulation are ambiguous and hard to supervise, we formulate them as a reinforcement learning (RL) problem and present Omni-R1, an end-to-end RL framework built on Group Relative Policy Optimization. Omni-R1 trains the Global Reasoning System through hierarchical rewards obtained via online collaboration with the Detail Understanding System, requiring only one epoch of RL on small task splits.   Experiments on two challenging benchmarks, namely Referring Audio-Visual Segmentation (RefAVS) and Reasoning Video Object Segmentation (REVOS), show that Omni-R1 not only surpasses strong supervised baselines but also outperforms specialized state-of-the-art models, while substantially improving out-of-domain generalization and mitigating multimodal hallucination. Our results demonstrate the first successful application of RL to large-scale omnimodal reasoning and highlight a scalable path toward universally foundation models.",
            "score": 13,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "5a9a5050221ec342",
            "authors": [
                "Hao Zhong",
                "Muzhi Zhu",
                "Zongze Du",
                "Zheng Huang",
                "Canyu Zhao",
                "Mingyu Liu",
                "Wen Wang",
                "Hao Chen",
                "Chunhua Shen"
            ],
            "affiliations": [
                "Zhejiang University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20256.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#reasoning",
                    "#video",
                    "#hallucinations",
                    "#benchmark",
                    "#multimodal",
                    "#optimization"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€ÑƒĞ´Ğ°: Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
                    "desc": "Omni-R1 - ÑÑ‚Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹. ĞĞ½Ğ° ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… Ğ¿Ğ¾Ğ´ÑĞ¸ÑÑ‚ĞµĞ¼: Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ÑÑ‰ĞµĞ¹ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ĞºĞ°Ğ´Ñ€Ñ‹, Ğ¸ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ, Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‰ĞµĞ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ğ´Ğ²ÑƒÑ… Ğ¿Ğ¾Ğ´ÑĞ¸ÑÑ‚ĞµĞ¼. Omni-R1 Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ¾Ğ¼ĞµĞ½Ñ‹."
                },
                "en": {
                    "title": "Omni-R1: Bridging Global Reasoning and Detail Understanding in Reinforcement Learning",
                    "desc": "The paper presents Omni-R1, an end-to-end reinforcement learning framework designed for complex tasks involving both video and audio reasoning. It addresses the challenge of balancing the need for low-resolution frames for temporal coverage with the requirement for high-resolution inputs for detailed understanding. By employing a two-system architecture, it utilizes a Global Reasoning System to select keyframes and a Detail Understanding System for pixel-level analysis. The framework demonstrates superior performance on benchmarks, outperforming existing models and enhancing generalization across different tasks."
                },
                "zh": {
                    "title": "Omni-R1ï¼šå¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„å…¨æ¨¡æ€æ¨ç†æ–°çªç ´",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºOmni-R1çš„ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é•¿æ—¶é—´è§†é¢‘éŸ³é¢‘æ¨ç†å’Œç»†ç²’åº¦åƒç´ ç†è§£ä»»åŠ¡ä¸­çš„çŸ›ç›¾éœ€æ±‚ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å…¨å±€æ¨ç†ç³»ç»Ÿå’Œç»†èŠ‚ç†è§£ç³»ç»Ÿï¼Œé€šè¿‡é€‰æ‹©å…³é”®ä¿¡æ¯å¸§æ¥é™ä½ç©ºé—´æˆæœ¬ï¼ŒåŒæ—¶åœ¨é«˜åˆ†è¾¨ç‡ç‰‡æ®µä¸Šè¿›è¡Œåƒç´ çº§çš„åŸºç¡€å®šä½ã€‚æˆ‘ä»¬å°†å…³é”®ä¿¡æ¯å¸§çš„é€‰æ‹©å’Œé‡æ„è§†ä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œåˆ©ç”¨å±‚æ¬¡å¥–åŠ±æœºåˆ¶è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmni-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å¼ºå¤§çš„ç›‘ç£åŸºçº¿å’Œä¸“ä¸šçš„æœ€å…ˆè¿›æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13136",
            "title": "ModernGBERT: German-only 1B Encoder Model Trained from Scratch",
            "url": "https://huggingface.co/papers/2505.13136",
            "abstract": "ModernGBERT and LL\\\"aMmlein2Vec, new German encoder models, outperform existing models in terms of performance and parameter-efficiency across various NLP tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Despite the prominence of decoder-only language models, encoders remain crucial for resource-constrained applications. We introduce ModernGBERT (134M, 1B), a fully transparent family of German encoder models trained from scratch, incorporating architectural innovations from ModernBERT. To evaluate the practical trade-offs of training encoders from scratch, we also present LL\\\"aMmlein2Vec (120M, 1B, 7B), a family of encoders derived from German decoder-only models via LLM2Vec. We benchmark all models on natural language understanding, text embedding, and long-context reasoning tasks, enabling a controlled comparison between dedicated encoders and converted decoders. Our results show that ModernGBERT 1B outperforms prior state-of-the-art German encoders as well as encoders adapted via LLM2Vec, with regard to performance and parameter-efficiency. All models, training data, checkpoints and code are publicly available, advancing the German NLP ecosystem with transparent, high-performance encoder models.",
            "score": 13,
            "issue_id": 3976,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "01dde4c221d27e3d",
            "authors": [
                "Anton Ehrmanntraut",
                "Julia Wunderle",
                "Jan Pfister",
                "Fotis Jannidis",
                "Andreas Hotho"
            ],
            "affiliations": [
                "CAIDAS Center for Artificial Intelligence and Data Science",
                "Computer Philology and History of Contemporary German Literature",
                "Data Science",
                "JMU Julius-Maximilians-UniversitÃ¤t WÃ¼rzburg"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13136.jpg",
            "data": {
                "categories": [
                    "#multilingual",
                    "#benchmark",
                    "#open_source",
                    "#dataset",
                    "#training",
                    "#low_resource",
                    "#architecture"
                ],
                "emoji": "ğŸ‡©ğŸ‡ª",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ² Ğ½ĞµĞ¼ĞµÑ†ĞºĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…: ModernGBERT Ğ¸ LL\"aMmlein2Vec",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ½ĞµĞ¼ĞµÑ†ĞºĞ¸Ğµ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ModernGBERT Ğ¸ LL\"aMmlein2Vec, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°. ModernGBERT Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ñ Ğ½ÑƒĞ»Ñ Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ· ModernBERT, Ğ² Ñ‚Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ ĞºĞ°Ğº LL\"aMmlein2Vec Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ° Ğ¸Ğ· Ğ½ĞµĞ¼ĞµÑ†ĞºĞ¸Ñ… Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° LLM2Vec. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°, Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ° Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ModernGBERT 1B Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ½ĞµĞ¼ĞµÑ†ĞºĞ¸Ğµ ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‡ĞµÑ€ĞµĞ· LLM2Vec ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Revolutionizing German NLP with Efficient Encoders",
                    "desc": "The paper introduces two new German encoder models, ModernGBERT and LL\"aMmlein2Vec, which demonstrate superior performance and efficiency compared to existing models in various natural language processing (NLP) tasks. ModernGBERT is a family of models trained from scratch, utilizing architectural advancements from ModernBERT, while LL\"aMmlein2Vec derives encoders from existing decoder-only models. The authors benchmark these models on tasks such as natural language understanding and long-context reasoning, highlighting the advantages of dedicated encoders over converted decoders. The findings indicate that ModernGBERT 1B achieves the best results in terms of performance and parameter efficiency, contributing valuable resources to the German NLP community."
                },
                "zh": {
                    "title": "æ–°ä¸€ä»£å¾·è¯­ç¼–ç å™¨æ¨¡å‹ï¼Œæ€§èƒ½å“è¶Šï¼",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸¤ç§æ–°çš„å¾·è¯­ç¼–ç å™¨æ¨¡å‹ï¼šModernGBERTå’ŒLL\"aMmlein2Vecã€‚è¿™äº›æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶ä¸”åœ¨å‚æ•°æ•ˆç‡ä¸Šè¶…è¿‡äº†ç°æœ‰æ¨¡å‹ã€‚ModernGBERTæ˜¯ä¸€ä¸ªå…¨æ–°çš„å¾·è¯­ç¼–ç å™¨ç³»åˆ—ï¼Œé‡‡ç”¨äº†ModernBERTçš„æ¶æ„åˆ›æ–°ï¼Œè€ŒLL\"aMmlein2Vecåˆ™æ˜¯ä»å¾·è¯­è§£ç å™¨æ¨¡å‹è½¬æ¢è€Œæ¥çš„ç¼–ç å™¨ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒModernGBERT 1Båœ¨æ€§èƒ½å’Œå‚æ•°æ•ˆç‡æ–¹é¢ä¼˜äºä¹‹å‰çš„å¾·è¯­ç¼–ç å™¨ï¼Œæ¨åŠ¨äº†å¾·è¯­è‡ªç„¶è¯­è¨€å¤„ç†çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19788",
            "title": "Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured\n  Multi-Turn Decomposition",
            "url": "https://huggingface.co/papers/2505.19788",
            "abstract": "Multi-Turn Decomposition improves efficiency in large reasoning models by breaking down chain-of-thought into manageable turns, reducing token usage and latency while maintaining performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Reasoning Models (LRMs) are criticized for the excessively lengthy Chain-of-Thought (CoT) to derive the final answer, suffering from high first-token and overall latency. Typically, the CoT of LRMs mixes multiple thinking units; each unit attempts to produce a candidate answer to the original query. Hence, a natural idea to improve efficiency is to reduce the unit number. Yet, the fact that the thinking units in vanilla CoT cannot be explicitly managed renders doing so challenging. This paper introduces Multi-Turn Decomposition (MinD) to decode conventional CoT into a sequence of explicit, structured, and turn-wise interactions to bridge the gap. In MinD, the model provides a multi-turn response to the query, where each turn embraces a thinking unit and yields a corresponding answer. The subsequent turns can reflect, verify, revise, or explore alternative approaches to both the thinking and answer parts of earlier ones. This not only makes the answer delivered more swiftly, but also enables explicit controls over the iterative reasoning process (i.e., users may halt or continue at any turn). We follow a supervised fine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We first rephrase the outputs of an LRM into multi-turn formats by prompting another LLM, and then tune the LRM with such data. Observing that the tuned model tends to consume even more tokens than the original one (probably due to that the multi-turn formats introduce additional answer tokens), we advocate leveraging RL algorithms like GRPO to prioritize correct outputs with fewer turns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up to ~70% reduction in both output token usage and time to first token (TTFT), while maintaining competitive performance on reasoning benchmarks such as MATH-500, AIME24, AMC23, and GPQA-Diamond.",
            "score": 12,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "95cddffa071ceb3b",
            "authors": [
                "Zihao Zeng",
                "Xuyao Huang",
                "Boxiu Li",
                "Hao Zhang",
                "Zhijie Deng"
            ],
            "affiliations": [
                "RealAI",
                "Shanghai Jiao Tong University",
                "University of California, San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19788.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#benchmark",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑˆĞ°Ğ³Ğ°Ğ¼: MinD Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ LRM",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Multi-Turn Decomposition (MinD) Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (LRM). MinD Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºÑƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºÑƒ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ´Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Streamlining Reasoning with Multi-Turn Decomposition",
                    "desc": "This paper presents Multi-Turn Decomposition (MinD), a method that enhances the efficiency of Large Reasoning Models (LRMs) by breaking down complex reasoning tasks into smaller, manageable turns. Each turn focuses on a specific thinking unit, allowing the model to generate responses iteratively, which reduces the overall token usage and latency. By structuring the reasoning process, users can control the flow of interactions, enabling them to verify or revise answers at each step. The approach combines supervised fine-tuning and reinforcement learning to optimize the model's performance while significantly decreasing the time to first token and output tokens used."
                },
                "zh": {
                    "title": "å¤šè½®åˆ†è§£ï¼šæå‡æ¨ç†æ¨¡å‹æ•ˆç‡çš„å…³é”®",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºå¤šè½®åˆ†è§£ï¼ˆMinDï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜å¤§å‹æ¨ç†æ¨¡å‹çš„æ•ˆç‡ã€‚é€šè¿‡å°†æ€ç»´é“¾ï¼ˆCoTï¼‰åˆ†è§£ä¸ºå¯ç®¡ç†çš„å¤šä¸ªå›åˆï¼ŒMinDå‡å°‘äº†ä»¤ç‰Œçš„ä½¿ç”¨å’Œå»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„æ€§èƒ½ã€‚æ¯ä¸ªå›åˆéƒ½åŒ…å«ä¸€ä¸ªæ€ç»´å•å…ƒï¼Œèƒ½å¤Ÿåæ€ã€éªŒè¯æˆ–ä¿®æ­£ä¹‹å‰çš„æ€è€ƒå’Œç­”æ¡ˆï¼Œä»è€Œå®ç°æ›´å¿«é€Ÿçš„å“åº”ã€‚è¯¥æ–¹æ³•é€šè¿‡ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ çš„ç»“åˆï¼Œä¼˜åŒ–äº†æ¨ç†è¿‡ç¨‹ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨ä»»æ„å›åˆä¸­æ§åˆ¶æ¨ç†çš„ç»§ç»­æˆ–åœæ­¢ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18759",
            "title": "The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT\n  Distillation",
            "url": "https://huggingface.co/papers/2505.18759",
            "abstract": "Data-centric distillation, including data augmentation, selection, and mixing, offers a promising path to creating smaller, more efficient student Large Language Models (LLMs) that retain strong reasoning abilities. However, there still lacks a comprehensive benchmark to systematically assess the effect of each distillation approach. This paper introduces DC-CoT, the first data-centric benchmark that investigates data manipulation in chain-of-thought (CoT) distillation from method, model and data perspectives. Utilizing various teacher models (e.g., o4-mini, Gemini-Pro, Claude-3.5) and student architectures (e.g., 3B, 7B parameters), we rigorously evaluate the impact of these data manipulations on student model performance across multiple reasoning datasets, with a focus on in-distribution (IID) and out-of-distribution (OOD) generalization, and cross-domain transfer. Our findings aim to provide actionable insights and establish best practices for optimizing CoT distillation through data-centric techniques, ultimately facilitating the development of more accessible and capable reasoning models. The dataset can be found at https://huggingface.co/datasets/rana-shahroz/DC-COT, while our code is shared in https://anonymous.4open.science/r/DC-COT-FF4C/.",
            "score": 12,
            "issue_id": 3971,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "eae631a1cc27fbf9",
            "authors": [
                "Ruichen Zhang",
                "Rana Muhammad Shahroz Khan",
                "Zhen Tan",
                "Dawei Li",
                "Song Wang",
                "Tianlong Chen"
            ],
            "affiliations": [
                "Arizona State University",
                "University of North Carolina at Chapel Hill",
                "University of Virginia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18759.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#reasoning",
                    "#transfer_learning",
                    "#dataset",
                    "#optimization",
                    "#training"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ DC-CoT - Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°-Ñ†ĞµĞ½Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞµĞº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (Chain-of-Thought, CoT). Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸Ğ·ÑƒÑ‡Ğ°ÑÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¹ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹. ĞÑĞ¾Ğ±Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ÑƒĞ´ĞµĞ»ÑĞµÑ‚ÑÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸ Ğ²Ğ½ĞµÑ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑƒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ´Ğ¾Ğ¼ĞµĞ½Ğ°Ğ¼Ğ¸. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ½Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ CoT Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ĞµĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ Ğº Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Optimizing Reasoning in Smaller Models with Data-Centric Distillation",
                    "desc": "This paper presents DC-CoT, a new benchmark for evaluating data-centric distillation methods in training smaller student Large Language Models (LLMs) while maintaining their reasoning capabilities. It explores various data manipulation techniques, such as augmentation, selection, and mixing, to understand their effects on model performance. The study uses different teacher and student model architectures to assess how these techniques influence both in-distribution and out-of-distribution generalization. The results aim to guide best practices for optimizing chain-of-thought distillation, making advanced reasoning models more efficient and accessible."
                },
                "zh": {
                    "title": "æ•°æ®é©±åŠ¨çš„è’¸é¦ä¼˜åŒ–ä¹‹è·¯",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDC-CoTçš„æ•°æ®ä¸­å¿ƒåŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°æ•°æ®å¢å¼ºã€é€‰æ‹©å’Œæ··åˆå¯¹é“¾å¼æ¨ç†ï¼ˆCoTï¼‰è’¸é¦çš„å½±å“ã€‚é€šè¿‡ä½¿ç”¨å¤šç§æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¶æ„ï¼Œæˆ‘ä»¬å¯¹æ•°æ®æ“ä½œå¯¹å­¦ç”Ÿæ¨¡å‹æ€§èƒ½çš„å½±å“è¿›è¡Œäº†ä¸¥æ ¼è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨åœ¨åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœä¸ºä¼˜åŒ–CoTè’¸é¦æä¾›äº†å¯è¡Œçš„è§è§£å’Œæœ€ä½³å®è·µï¼Œä¿ƒè¿›äº†æ›´é«˜æ•ˆçš„æ¨ç†æ¨¡å‹çš„å¼€å‘ã€‚è¯¥æ•°æ®é›†å’Œä»£ç å¯åœ¨æŒ‡å®šé“¾æ¥ä¸­æ‰¾åˆ°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20152",
            "title": "Hard Negative Contrastive Learning for Fine-Grained Geometric\n  Understanding in Large Multimodal Models",
            "url": "https://huggingface.co/papers/2505.20152",
            "abstract": "A novel hard negative contrastive learning framework improves geometric reasoning in Large Multimodal Models, significantly enhancing their performance compared to existing models.  \t\t\t\t\tAI-generated summary \t\t\t\t Benefiting from contrastively trained visual encoders on large-scale natural scene images, Large Multimodal Models (LMMs) have achieved remarkable performance across various visual perception tasks. However, the inherent limitations of contrastive learning upon summarized descriptions fundamentally restrict the capabilities of models in meticulous reasoning, particularly in crucial scenarios of geometric problem-solving. To enhance geometric understanding, we propose a novel hard negative contrastive learning framework for the vision encoder, which combines image-based contrastive learning using generation-based hard negatives created by perturbing diagram generation code, and text-based contrastive learning using rule-based negatives derived from modified geometric descriptions and retrieval-based negatives selected based on caption similarity. We train CLIP using our strong negative learning method, namely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for geometric problem-solving. Experiments show that our trained model, MMGeoLM, significantly outperforms other open-source models on three geometric reasoning benchmarks. Even with a size of 7B, it can rival powerful closed-source models like GPT-4o. We further study the impact of different negative sample construction methods and the number of negative samples on the geometric reasoning performance of LMM, yielding fruitful conclusions. The code and dataset are available at https://github.com/THU-KEG/MMGeoLM.",
            "score": 11,
            "issue_id": 3969,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "ee370e43a48e58a9",
            "authors": [
                "Kai Sun",
                "Yushi Bai",
                "Zhen Yang",
                "Jiajie Zhang",
                "Ji Qi",
                "Lei Hou",
                "Juanzi Li"
            ],
            "affiliations": [
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20152.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#benchmark",
                    "#training",
                    "#reasoning",
                    "#dataset",
                    "#open_source"
                ],
                "emoji": "ğŸ“",
                "ru": {
                    "title": "ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğ¸ Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· ÑƒÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ MMGeoLM Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ñ‚Ñ€ĞµÑ… ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ğ¿Ğ¾ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "Enhancing Geometric Reasoning with Hard Negative Contrastive Learning",
                    "desc": "This paper introduces a new framework for hard negative contrastive learning that enhances geometric reasoning in Large Multimodal Models (LMMs). By utilizing contrastively trained visual encoders and generating hard negatives through perturbations and rule-based modifications, the framework improves the model's ability to solve geometric problems. The proposed model, MMGeoLM, demonstrates superior performance on geometric reasoning tasks compared to existing models, even rivaling larger closed-source models. The study also explores how different methods of constructing negative samples affect the model's reasoning capabilities, providing valuable insights for future research."
                },
                "zh": {
                    "title": "æå‡å‡ ä½•æ¨ç†çš„æ–°å¯¹æ¯”å­¦ä¹ æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›°éš¾è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œä»¥æé«˜å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨å‡ ä½•æ¨ç†æ–¹é¢çš„è¡¨ç°ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨åœ¨è‡ªç„¶åœºæ™¯å›¾åƒä¸Šå–å¾—äº†æ˜¾è‘—çš„æ•ˆæœï¼Œä½†åœ¨ç»†è‡´æ¨ç†æ–¹é¢å­˜åœ¨å±€é™ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†åŸºäºå›¾åƒçš„å¯¹æ¯”å­¦ä¹ å’ŒåŸºäºæ–‡æœ¬çš„å¯¹æ¯”å­¦ä¹ ï¼Œåˆ©ç”¨ç”Ÿæˆçš„å›°éš¾è´Ÿæ ·æœ¬å’Œä¿®æ”¹çš„å‡ ä½•æè¿°æ¥å¢å¼ºæ¨¡å‹çš„å‡ ä½•ç†è§£èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å‡ ä½•æ¨ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18822",
            "title": "AdaCtrl: Towards Adaptive and Controllable Reasoning via\n  Difficulty-Aware Budgeting",
            "url": "https://huggingface.co/papers/2505.18822",
            "abstract": "AdaCtrl, a novel framework, dynamically adjusts reasoning length based on problem difficulty and user control, improving performance and reducing response length across various datasets compared to standard training methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Modern large reasoning models demonstrate impressive problem-solving capabilities by employing sophisticated reasoning strategies. However, they often struggle to balance efficiency and effectiveness, frequently generating unnecessarily lengthy reasoning chains for simple problems. In this work, we propose AdaCtrl, a novel framework to support both difficulty-aware adaptive reasoning budget allocation and explicit user control over reasoning depth. AdaCtrl dynamically adjusts its reasoning length based on self-assessed problem difficulty, while also allowing users to manually control the budget to prioritize either efficiency or effectiveness. This is achieved through a two-stage training pipeline: an initial cold-start fine-tuning phase to instill the ability to self-aware difficulty and adjust reasoning budget, followed by a difficulty-aware reinforcement learning (RL) stage that refines the model's adaptive reasoning strategies and calibrates its difficulty assessments based on its evolving capabilities during online training. To enable intuitive user interaction, we design explicit length-triggered tags that function as a natural interface for budget control. Empirical results show that AdaCtrl adapts reasoning length based on estimated difficulty, compared to the standard training baseline that also incorporates fine-tuning and RL, it yields performance improvements and simultaneously reduces response length by 10.06% and 12.14% on the more challenging AIME2024 and AIME2025 datasets, which require elaborate reasoning, and by 62.05% and 91.04% on the MATH500 and GSM8K datasets, where more concise responses are sufficient. Furthermore, AdaCtrl enables precise user control over the reasoning budget, allowing for tailored responses to meet specific needs.",
            "score": 11,
            "issue_id": 3974,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "4ae93c717abf8bdf",
            "authors": [
                "Shijue Huang",
                "Hongru Wang",
                "Wanjun Zhong",
                "Zhaochen Su",
                "Jiazhan Feng",
                "Bowen Cao",
                "Yi R. Fung"
            ],
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "Peking University",
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18822.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#rl",
                    "#dataset"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ¾Ğ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "AdaCtrl - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ñ€ĞµĞ³ÑƒĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° fine-tuning Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹. AdaCtrl Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ½Ğ° 10-90% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ ÑĞ¾ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ…. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ´Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ²Ğ½Ğ¾ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñƒ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ‚ĞµĞ³Ğ¾Ğ²."
                },
                "en": {
                    "title": "Adaptive Reasoning for Efficient Problem Solving",
                    "desc": "AdaCtrl is a new framework that enhances reasoning in machine learning models by adjusting the length of reasoning based on the difficulty of the problem and user preferences. It addresses the common issue of models generating overly long reasoning chains for simple tasks by implementing a two-stage training process. The first stage fine-tunes the model to recognize problem difficulty, while the second stage uses reinforcement learning to improve its reasoning strategies. Empirical results show that AdaCtrl not only improves performance but also reduces response length significantly across various datasets, allowing users to control the depth of reasoning as needed."
                },
                "zh": {
                    "title": "æ™ºèƒ½æ¨ç†ï¼Œçµæ´»æ§åˆ¶ï¼",
                    "desc": "AdaCtrlæ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿæ ¹æ®é—®é¢˜çš„éš¾åº¦å’Œç”¨æˆ·çš„æ§åˆ¶åŠ¨æ€è°ƒæ•´æ¨ç†é•¿åº¦ï¼Œä»è€Œæé«˜æ€§èƒ½å¹¶å‡å°‘å“åº”é•¿åº¦ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªæˆ‘è¯„ä¼°é—®é¢˜éš¾åº¦æ¥è°ƒæ•´æ¨ç†é¢„ç®—ï¼ŒåŒæ—¶å…è®¸ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶é¢„ç®—ï¼Œä»¥ä¼˜å…ˆè€ƒè™‘æ•ˆç‡æˆ–æœ‰æ•ˆæ€§ã€‚AdaCtrlé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œé¦–å…ˆè¿›è¡Œå†·å¯åŠ¨å¾®è°ƒï¼Œç„¶åé€šè¿‡éš¾åº¦æ„ŸçŸ¥çš„å¼ºåŒ–å­¦ä¹ é˜¶æ®µæ¥ä¼˜åŒ–æ¨¡å‹çš„è‡ªé€‚åº”æ¨ç†ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼ŒAdaCtrlåœ¨å¤„ç†ä¸åŒæ•°æ®é›†æ—¶ï¼Œèƒ½å¤Ÿæ ¹æ®ä¼°è®¡çš„éš¾åº¦è°ƒæ•´æ¨ç†é•¿åº¦ï¼Œæ˜¾è‘—æé«˜äº†æ€§èƒ½å¹¶å‡å°‘äº†å“åº”é•¿åº¦ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20046",
            "title": "REARANK: Reasoning Re-ranking Agent via Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.20046",
            "abstract": "REARANK, a reinforcement learning-enhanced large language model for listwise reasoning,outperforms baseline models and even surpasses GPT-4 on reasoning-intensive benchmarks with minimal data.  \t\t\t\t\tAI-generated summary \t\t\t\t We present REARANK, a large language model (LLM)-based listwise reasoning reranking agent. REARANK explicitly reasons before reranking, significantly improving both performance and interpretability. Leveraging reinforcement learning and data augmentation, REARANK achieves substantial improvements over baseline models across popular information retrieval benchmarks, notably requiring only 179 annotated samples. Built on top of Qwen2.5-7B, our REARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and out-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT benchmarks. These results underscore the effectiveness of our approach and highlight how reinforcement learning can enhance LLM reasoning capabilities in reranking.",
            "score": 10,
            "issue_id": 3980,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "cf154abb2291ee80",
            "authors": [
                "Le Zhang",
                "Bo Wang",
                "Xipeng Qiu",
                "Siva Reddy",
                "Aishwarya Agrawal"
            ],
            "affiliations": [
                "Canada CIFAR AI Chair",
                "Fudan University",
                "McGill University",
                "Mila - Quebec AI Institute",
                "UniversitÃ© de MontrÃ©al"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20046.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#agents",
                    "#interpretability",
                    "#optimization",
                    "#reasoning",
                    "#rlhf",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "REARANK: Ğ£ÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "REARANK - ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM) Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. ĞĞ½Ğ° ÑĞ²Ğ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ. REARANK Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ½Ğ° Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ²ÑĞµĞ³Ğ¾ 179 Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ². ĞœĞ¾Ğ´ĞµĞ»ÑŒ REARANK-7B, Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Qwen2.5-7B, Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ, ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼ÑƒÑ Ñ GPT-4, Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ĞµĞ³Ğ¾ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ¸Ğ½Ñ‚ĞµĞ½ÑĞ¸Ğ²Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "REARANK: Elevating Reasoning with Reinforcement Learning",
                    "desc": "REARANK is a large language model designed to improve listwise reasoning by using reinforcement learning techniques. It enhances the process of reranking information by explicitly reasoning about the data, which leads to better performance and clearer results. The model shows significant improvements over traditional baseline models, even outperforming GPT-4 on challenging reasoning tasks with very few training samples. This research highlights the potential of combining reinforcement learning with large language models to boost their reasoning abilities in information retrieval tasks."
                },
                "zh": {
                    "title": "REARANKï¼šå¼ºåŒ–å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„åˆ›æ–°ä¹‹ä½œ",
                    "desc": "REARANKæ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åˆ—è¡¨æ¨ç†é‡æ’åºä»£ç†ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ•°æ®å¢å¼ºæŠ€æœ¯æ˜¾è‘—æå‡äº†æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚è¯¥æ¨¡å‹åœ¨æ¨ç†ä¹‹å‰è¿›è¡Œæ˜ç¡®çš„æ¨ç†ï¼Œä»è€Œæé«˜äº†é‡æ’åºçš„æ•ˆæœã€‚REARANKåœ¨æµè¡Œçš„ä¿¡æ¯æ£€ç´¢åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä»…éœ€179ä¸ªæ ‡æ³¨æ ·æœ¬å³å¯å®ç°æ˜¾è‘—æ”¹è¿›ã€‚ä¸GPT-4ç›¸æ¯”ï¼ŒREARANKåœ¨æ¨ç†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æ›´ä½³ï¼Œå±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ åœ¨å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19640",
            "title": "Interleaved Reasoning for Large Language Models via Reinforcement\n  Learning",
            "url": "https://huggingface.co/papers/2505.19640",
            "abstract": "A reinforcement learning-guided training paradigm enhances large language models' reasoning efficiency and performance for multi-hop questions by interleaving thinking and answering.  \t\t\t\t\tAI-generated summary \t\t\t\t Long chain-of-thought (CoT) significantly enhances large language models' (LLM) reasoning capabilities. However, the extensive reasoning traces lead to inefficiencies and an increased time-to-first-token (TTFT). We propose a novel training paradigm that uses reinforcement learning (RL) to guide reasoning LLMs to interleave thinking and answering for multi-hop questions. We observe that models inherently possess the ability to perform interleaved reasoning, which can be further enhanced through RL. We introduce a simple yet effective rule-based reward to incentivize correct intermediate steps, which guides the policy model toward correct reasoning paths by leveraging intermediate signals generated during interleaved reasoning. Extensive experiments conducted across five diverse datasets and three RL algorithms (PPO, GRPO, and REINFORCE++) demonstrate consistent improvements over traditional think-answer reasoning, without requiring external tools. Specifically, our approach reduces TTFT by over 80% on average and improves up to 19.3% in Pass@1 accuracy. Furthermore, our method, trained solely on question answering and logical reasoning datasets, exhibits strong generalization ability to complex reasoning datasets such as MATH, GPQA, and MMLU. Additionally, we conduct in-depth analysis to reveal several valuable insights into conditional reward modeling.",
            "score": 10,
            "issue_id": 3970,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "6fff32b94b547c0e",
            "authors": [
                "Roy Xie",
                "David Qiu",
                "Deepak Gopinath",
                "Dong Lin",
                "Yanchao Sun",
                "Chong Wang",
                "Saloni Potdar",
                "Bhuwan Dhingra"
            ],
            "affiliations": [
                "Apple",
                "Duke University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19640.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#math",
                    "#rlhf",
                    "#training",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜: Ğ¼Ñ‹ÑĞ»ÑŒ Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ (RL) Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ‡ĞµÑ€ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ° (TTFT) Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ñ‚ÑŒ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ². Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ğ¿ÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğº Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Reinforcement Learning Boosts Reasoning Efficiency in Language Models",
                    "desc": "This paper presents a new training method for large language models (LLMs) that improves their ability to answer multi-hop questions efficiently. By using reinforcement learning (RL), the model learns to alternate between thinking and answering, which enhances its reasoning capabilities. The authors introduce a reward system that encourages the model to take correct intermediate steps during reasoning, leading to better performance. Experiments show that this approach significantly reduces the time taken to generate answers and improves accuracy on various reasoning tasks without needing additional tools."
                },
                "zh": {
                    "title": "å¼ºåŒ–å­¦ä¹ æå‡è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒèŒƒå¼ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè·³é—®é¢˜ä¸Šçš„æ¨ç†æ•ˆç‡å’Œæ€§èƒ½ã€‚é€šè¿‡äº¤æ›¿æ€è€ƒå’Œå›ç­”ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡Œæ¨ç†ï¼Œå‡å°‘äº†é¦–æ¬¡ç”Ÿæˆä»¤ç‰Œçš„æ—¶é—´ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„åŸºäºè§„åˆ™çš„å¥–åŠ±æœºåˆ¶ï¼Œé¼“åŠ±æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­é‡‡å–æ­£ç¡®çš„ä¸­é—´æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ï¼Œä¸”æ— éœ€å¤–éƒ¨å·¥å…·ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19602",
            "title": "Memory-Efficient Visual Autoregressive Modeling with Scale-Aware KV\n  Cache Compression",
            "url": "https://huggingface.co/papers/2505.19602",
            "abstract": "ScaleKV compresses the KV cache in Visual Autoregressive models by differentiating drafters and refiners across transformer layers, reducing memory consumption while maintaining high fidelity.  \t\t\t\t\tAI-generated summary \t\t\t\t Visual Autoregressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction approach, which yields substantial improvements in efficiency, scalability, and zero-shot generalization. Nevertheless, the coarse-to-fine methodology inherent in VAR results in exponential growth of the KV cache during inference, causing considerable memory consumption and computational redundancy. To address these bottlenecks, we introduce ScaleKV, a novel KV cache compression framework tailored for VAR architectures. ScaleKV leverages two critical observations: varying cache demands across transformer layers and distinct attention patterns at different scales. Based on these insights, ScaleKV categorizes transformer layers into two functional groups: drafters and refiners. Drafters exhibit dispersed attention across multiple scales, thereby requiring greater cache capacity. Conversely, refiners focus attention on the current token map to process local details, consequently necessitating substantially reduced cache capacity. ScaleKV optimizes the multi-scale inference pipeline by identifying scale-specific drafters and refiners, facilitating differentiated cache management tailored to each scale. Evaluation on the state-of-the-art text-to-image VAR model family, Infinity, demonstrates that our approach effectively reduces the required KV cache memory to 10% while preserving pixel-level fidelity.",
            "score": 10,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "26a6b9a07958f010",
            "authors": [
                "Kunjun Li",
                "Zigeng Chen",
                "Cheng-Yen Yang",
                "Jenq-Neng Hwang"
            ],
            "affiliations": [
                "National University of Singapore",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19602.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "ğŸ—œï¸",
                "ru": {
                    "title": "ScaleKV: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑĞ¶Ğ°Ñ‚Ğ¸Ğµ ĞºÑÑˆĞ° Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ˜Ğ˜-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ScaleKV - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¶Ğ°Ñ‚Ğ¸Ñ KV-ĞºÑÑˆĞ° Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ ÑĞ»Ğ¾Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° Ğ½Ğ° Ğ´Ñ€Ğ°Ñ„Ñ‚ĞµÑ€Ñ‹ Ğ¸ Ñ€ĞµÑ„Ğ°Ğ¹Ğ½ĞµÑ€Ñ‹, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸. Ğ”Ñ€Ğ°Ñ„Ñ‚ĞµÑ€Ñ‹ Ğ¸Ğ¼ĞµÑÑ‚ Ñ€Ğ°ÑÑĞµÑĞ½Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ ĞºÑÑˆĞ°, Ğ° Ñ€ĞµÑ„Ğ°Ğ¹Ğ½ĞµÑ€Ñ‹ Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ½Ğ° Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ ĞºĞ°Ñ€Ñ‚Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ½ÑƒĞ¶Ğ´Ğ°ÑÑ‚ÑÑ Ğ² Ğ¼ĞµĞ½ÑŒÑˆĞµĞ¼ Ğ¾Ğ±ÑŠĞµĞ¼Ğµ. Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Infinity Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ KV-ĞºÑÑˆĞ° Ğ´Ğ¾ 10% Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Efficient Memory Management in Visual Autoregressive Models with ScaleKV",
                    "desc": "ScaleKV is a new framework designed to compress the key-value (KV) cache in Visual Autoregressive (VAR) models, which helps reduce memory usage during inference. It identifies two types of transformer layers: drafters, which need more cache due to their broad attention across multiple scales, and refiners, which focus on local details and require less cache. By optimizing cache management based on these layer types, ScaleKV significantly lowers memory consumption while maintaining high-quality outputs. Tests on the Infinity model show that ScaleKV can cut KV cache memory usage by 90% without sacrificing pixel-level fidelity."
                },
                "zh": {
                    "title": "ScaleKVï¼šé«˜æ•ˆå‹ç¼©è§†è§‰è‡ªå›å½’æ¨¡å‹çš„KVç¼“å­˜",
                    "desc": "ScaleKVæ˜¯ä¸€ç§æ–°é¢–çš„KVç¼“å­˜å‹ç¼©æ¡†æ¶ï¼Œä¸“ä¸ºè§†è§‰è‡ªå›å½’æ¨¡å‹è®¾è®¡ã€‚å®ƒé€šè¿‡åŒºåˆ†å˜å‹å™¨å±‚ä¸­çš„è‰å›¾ç”Ÿæˆå™¨å’Œç²¾ç»†åŒ–å¤„ç†å™¨ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒäº†é«˜ä¿çœŸåº¦ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äº†ä¸åŒå±‚å¯¹ç¼“å­˜çš„éœ€æ±‚å·®å¼‚å’Œä¸åŒå°ºåº¦ä¸‹çš„æ³¨æ„åŠ›æ¨¡å¼ï¼Œä»è€Œä¼˜åŒ–äº†å¤šå°ºåº¦æ¨ç†æµç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒScaleKVèƒ½å¤Ÿå°†æ‰€éœ€çš„KVç¼“å­˜å†…å­˜å‡å°‘åˆ°10%ï¼Œè€Œåƒç´ çº§çš„ä¿çœŸåº¦å¾—ä»¥ä¿æŒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.13426",
            "title": "G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language\n  Model via Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.13426",
            "abstract": "VLM-Gym addresses the \"knowing-doing\" gap in Vision-Language Models by training them in a diverse RL environment, leading to enhanced perception and reasoning abilities that surpass existing models in interactive games.  \t\t\t\t\tAI-generated summary \t\t\t\t Vision-Language Models (VLMs) excel in many direct multimodal tasks but struggle to translate this prowess into effective decision-making within interactive, visually rich environments like games. This ``knowing-doing'' gap significantly limits their potential as autonomous agents, as leading VLMs often performing badly in simple games. To address this, we introduce VLM-Gym, a curated reinforcement learning (RL) environment featuring diverse visual games with unified interfaces and adjustable, compositional difficulty, specifically designed for scalable multi-game parallel training. Leveraging VLM-Gym, we train G0 models using pure RL-driven self-evolution, which demonstrate emergent perception and reasoning patterns. To further mitigate challenges arising from game diversity, we develop G1 models. G1 incorporates a perception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models consistently surpass their teacher across all games and outperform leading proprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals an intriguing finding: perception and reasoning abilities mutually bootstrap each other throughout the RL training process. Source code including VLM-Gym and RL training are released at https://github.com/chenllliang/G1 to foster future research in advancing VLMs as capable interactive agents.",
            "score": 10,
            "issue_id": 3967,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "8cfc8c8f1a7e5589",
            "authors": [
                "Liang Chen",
                "Hongcheng Gao",
                "Tianyu Liu",
                "Zhiqi Huang",
                "Flood Sung",
                "Xinyu Zhou",
                "Yuxin Wu",
                "Baobao Chang"
            ],
            "affiliations": [
                "Moonshot AI",
                "Peking University",
                "UCAS"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.13426.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#training",
                    "#reasoning",
                    "#open_source",
                    "#agents",
                    "#games",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "ğŸ®",
                "ru": {
                    "title": "ĞŸÑ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ñ€Ñ‹Ğ²Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ĞµĞ¼ Ğ² Vision-Language Models Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ RL",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ VLM-Gym - ÑÑ€ĞµĞ´Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Vision-Language Models, Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½ÑƒÑ Ğ½Ğ° Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ñ€Ñ‹Ğ²Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ĞµĞ¼. VLM-Gym Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ³Ñ€Ñ‹ Ñ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°Ğ¼Ğ¸ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼Ğ¾Ğ¹ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑÑ‚Ñƒ ÑÑ€ĞµĞ´Ñƒ, Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ G0 Ğ¸ G1, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ñ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ G1 Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¿Ñ€Ğ¸ĞµÑ‚Ğ°Ñ€Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¸Ğ³Ñ€Ğ°Ñ…."
                },
                "en": {
                    "title": "Bridging the Knowing-Doing Gap in Vision-Language Models",
                    "desc": "VLM-Gym is a new training environment designed to improve Vision-Language Models (VLMs) by bridging the gap between their knowledge and practical application in interactive games. Traditional VLMs excel in tasks involving text and images but struggle with decision-making in dynamic environments. By using reinforcement learning (RL) in a diverse set of visual games, VLM-Gym enables models to develop better perception and reasoning skills. The G1 models trained in this environment outperform existing models, demonstrating that enhanced perception and reasoning can support each other during training."
                },
                "zh": {
                    "title": "VLM-Gymï¼šæå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„å†³ç­–èƒ½åŠ›",
                    "desc": "VLM-Gym æ˜¯ä¸€ä¸ªé’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œæ—¨åœ¨è§£å†³å®ƒä»¬åœ¨äº’åŠ¨æ¸¸æˆä¸­çš„å†³ç­–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚é€šè¿‡åœ¨å¤šæ ·åŒ–çš„æ¸¸æˆç¯å¢ƒä¸­è®­ç»ƒï¼ŒVLM-Gym æå‡äº†æ¨¡å‹çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶åœ¨ç®€å•æ¸¸æˆä¸­è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ã€‚æˆ‘ä»¬å¼€å‘äº† G0 å’Œ G1 æ¨¡å‹ï¼Œå…¶ä¸­ G1 æ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒä¹‹å‰è¿›è¡Œäº†æ„ŸçŸ¥å¢å¼ºï¼Œä»¥åº”å¯¹æ¸¸æˆå¤šæ ·æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æœ€ç»ˆï¼ŒG1 æ¨¡å‹åœ¨æ‰€æœ‰æ¸¸æˆä¸­å‡è¶…è¶Šäº†å…¶æ•™å¸ˆæ¨¡å‹ï¼Œå¹¶ä¸”åœ¨æ€§èƒ½ä¸Šè¶…è¿‡äº†é¢†å…ˆçš„ä¸“æœ‰æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19386",
            "title": "Force Prompting: Video Generation Models Can Learn and Generalize\n  Physics-based Control Signals",
            "url": "https://huggingface.co/papers/2505.19386",
            "abstract": "Force prompts enable video generation models to simulate realistic physical interactions using pretrained models and force conditioning from Blender-generated videos.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in video generation models have sparked interest in world models capable of simulating realistic environments. While navigation has been well-explored, physically meaningful interactions that mimic real-world forces remain largely understudied. In this work, we investigate using physical forces as a control signal for video generation and propose force prompts which enable users to interact with images through both localized point forces, such as poking a plant, and global wind force fields, such as wind blowing on fabric. We demonstrate that these force prompts can enable videos to respond realistically to physical control signals by leveraging the visual and motion prior in the original pretrained model, without using any 3D asset or physics simulator at inference. The primary challenge of force prompting is the difficulty in obtaining high quality paired force-video training data, both in the real world due to the difficulty of obtaining force signals, and in synthetic data due to limitations in the visual quality and domain diversity of physics simulators. Our key finding is that video generation models can generalize remarkably well when adapted to follow physical force conditioning from videos synthesized by Blender, even with limited demonstrations of few objects. Our method can generate videos which simulate forces across diverse geometries, settings, and materials. We also try to understand the source of this generalization and perform ablations that reveal two key elements: visual diversity and the use of specific text keywords during training. Our approach is trained on only around 15k training examples for a single day on four A100 GPUs, and outperforms existing methods on force adherence and physics realism, bringing world models closer to real-world physics interactions. We release all datasets, code, weights, and interactive video demos at our project page.",
            "score": 9,
            "issue_id": 3981,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "1f53616fb8118a51",
            "authors": [
                "Nate Gillman",
                "Charles Herrmann",
                "Michael Freeman",
                "Daksh Aggarwal",
                "Evan Luo",
                "Deqing Sun",
                "Chen Sun"
            ],
            "affiliations": [
                "Brown University",
                "Google DeepMind"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19386.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#video",
                    "#synthetic",
                    "#games",
                    "#data"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "Ğ¡Ğ¸Ğ»Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ¸ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ñ„Ğ¸Ğ·Ğ¸ĞºĞ¸ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ 'ÑĞ¸Ğ»Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·Ğ¾Ğº' Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ĞµĞ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Blender, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ĞµĞ¹ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ´Ğ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾Ğ¹ Ñ„Ğ¸Ğ·Ğ¸ĞºĞ¾Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ². ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼Ğ¸ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ ÑƒÑĞ¿ĞµÑ…Ğ° Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° ÑĞ²Ğ»ÑÑÑ‚ÑÑ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾ Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ„Ğ¸Ğ·Ğ¸ĞºĞ¸, Ğ¿Ñ€Ğ¸Ğ±Ğ»Ğ¸Ğ¶Ğ°Ñ Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğº Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑĞ¼."
                },
                "en": {
                    "title": "Force Prompts: Realistic Video Interactions through Physical Control",
                    "desc": "This paper introduces a novel approach called force prompts for enhancing video generation models, allowing them to simulate realistic physical interactions. By using pretrained models and force conditioning derived from Blender-generated videos, the authors enable users to apply localized and global forces to video content. The study highlights the challenge of obtaining high-quality training data for force-video pairs, yet demonstrates that the models can generalize well with limited examples. The findings suggest that incorporating visual diversity and specific text keywords during training significantly improves the model's ability to generate videos that adhere to physical forces and exhibit realism."
                },
                "zh": {
                    "title": "åŠ›æç¤ºï¼šè®©è§†é¢‘ç”Ÿæˆæ›´çœŸå®çš„ç‰©ç†äº¤äº’",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ç‰©ç†åŠ›ä½œä¸ºè§†é¢‘ç”Ÿæˆçš„æ§åˆ¶ä¿¡å·ï¼Œæå‡ºäº†åŠ›æç¤ºçš„æ¦‚å¿µï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡å±€éƒ¨ç‚¹åŠ›å’Œå…¨å±€é£åŠ›åœºä¸å›¾åƒè¿›è¡Œäº¤äº’ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¿™äº›åŠ›æç¤ºå¯ä»¥ä½¿è§†é¢‘åœ¨æ²¡æœ‰3Dèµ„äº§æˆ–ç‰©ç†æ¨¡æ‹Ÿå™¨çš„æƒ…å†µä¸‹ï¼ŒçœŸå®åœ°å“åº”ç‰©ç†æ§åˆ¶ä¿¡å·ã€‚ç ”ç©¶å‘ç°ï¼Œè§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨é€‚åº”Blenderåˆæˆè§†é¢‘çš„ç‰©ç†åŠ›æ¡ä»¶æ—¶ï¼Œèƒ½å¤Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå³ä½¿åœ¨æœ‰é™çš„ç‰©ä½“ç¤ºä¾‹ä¸‹ä¹Ÿèƒ½ç”Ÿæˆå¤šæ ·åŒ–çš„ç‰©ç†äº¤äº’è§†é¢‘ã€‚æˆ‘ä»¬çš„è®­ç»ƒæ–¹æ³•åœ¨ä»…ç”¨15kç¤ºä¾‹çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ¨åŠ¨äº†ä¸–ç•Œæ¨¡å‹å‘çœŸå®ç‰©ç†äº¤äº’çš„è¿›æ­¥ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16972",
            "title": "From Tens of Hours to Tens of Thousands: Scaling Back-Translation for\n  Speech Recognition",
            "url": "https://huggingface.co/papers/2505.16972",
            "abstract": "Recent advances in Automatic Speech Recognition (ASR) have been largely fueled by massive speech corpora. However, extending coverage to diverse languages with limited resources remains a formidable challenge. This paper introduces Speech Back-Translation, a scalable pipeline that improves multilingual ASR models by converting large-scale text corpora into synthetic speech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just tens of hours of real transcribed speech can effectively train TTS models to generate synthetic speech at hundreds of times the original volume while maintaining high quality. To evaluate synthetic speech quality, we develop an intelligibility-based assessment framework and establish clear thresholds for when synthetic data benefits ASR training. Using Speech Back-Translation, we generate more than 500,000 hours of synthetic speech in ten languages and continue pre-training Whisper-large-v3, achieving average transcription error reductions of over 30\\%. These results highlight the scalability and effectiveness of Speech Back-Translation for enhancing multilingual ASR systems.",
            "score": 9,
            "issue_id": 3967,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "784a648ae844599f",
            "authors": [
                "Tianduo Wang",
                "Lu Xu",
                "Wei Lu",
                "Shanbo Cheng"
            ],
            "affiliations": [
                "ByteDance Seed",
                "StatNLP Research Group, Singapore University of Technology and Design"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16972.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#multilingual",
                    "#low_resource",
                    "#dataset",
                    "#audio",
                    "#synthetic"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ€ĞµÑ‡ÑŒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğ³Ğ¾ ASR",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Speech Back-Translation Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑ‡Ğ¸ (ASR). ĞœĞµÑ‚Ğ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ ĞºĞ¾Ñ€Ğ¿ÑƒÑÑ‹ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ text-to-speech (TTS) Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ€ĞµÑ‡Ğ¸ Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ¾Ğ±ÑŠĞµĞ¼Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ´Ğ°Ğ¶Ğµ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€ĞµÑ‡Ğ¸ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ TTS Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Whisper-large-v3 Ğ½Ğ° 500 000 Ñ‡Ğ°ÑĞ°Ñ… ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ€ĞµÑ‡Ğ¸ Ğ½Ğ° 10 ÑĞ·Ñ‹ĞºĞ°Ñ… Ğ¿Ñ€Ğ¸Ğ²ĞµĞ»Ğ¾ Ğº ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ Ğ² ÑÑ€ĞµĞ´Ğ½ĞµĞ¼ Ğ½Ğ° 30%."
                },
                "en": {
                    "title": "Scaling ASR with Synthetic Speech: Speech Back-Translation",
                    "desc": "This paper presents a method called Speech Back-Translation to enhance Automatic Speech Recognition (ASR) systems for multiple languages, especially those with limited resources. By using text-to-speech (TTS) models, the authors convert large text corpora into synthetic speech, significantly increasing the amount of training data available. They show that even a small amount of real speech can train TTS models to produce high-quality synthetic speech at a much larger scale. The results indicate that this approach can improve ASR performance, achieving over 30% reduction in transcription errors across ten languages."
                },
                "zh": {
                    "title": "è¯­éŸ³åå‘ç¿»è¯‘ï¼šæå‡å¤šè¯­è¨€ASRçš„æœ‰æ•ˆåˆ©å™¨",
                    "desc": "è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºè¯­éŸ³åå‘ç¿»è¯‘ï¼ˆSpeech Back-Translationï¼‰çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨æ”¹å–„å¤šè¯­è¨€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å¤§è§„æ¨¡æ–‡æœ¬è¯­æ–™åº“è½¬æ¢ä¸ºåˆæˆè¯­éŸ³ï¼Œåˆ©ç”¨ç°æˆçš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œè§£å†³äº†èµ„æºæœ‰é™è¯­è¨€çš„è¦†ç›–é—®é¢˜ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä»…éœ€æ•°åå°æ—¶çš„çœŸå®è½¬å½•è¯­éŸ³ï¼Œå°±èƒ½æœ‰æ•ˆè®­ç»ƒTTSæ¨¡å‹ç”Ÿæˆæ•°ç™¾å€çš„åˆæˆè¯­éŸ³ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†è¶…è¿‡50ä¸‡å°æ—¶çš„åˆæˆè¯­éŸ³ï¼Œå¹¶åœ¨å¤šè¯­è¨€ASRç³»ç»Ÿä¸­å®ç°äº†è¶…è¿‡30%çš„è½¬å½•é”™è¯¯ç‡é™ä½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19955",
            "title": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research",
            "url": "https://huggingface.co/papers/2505.19955",
            "abstract": "MLR-Bench evaluates AI agents in scientific research through modular stages, revealing that while LLMs perform well in ideation and writing, coding agents often produce unreliable experimental results.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advancements in AI agents have demonstrated their growing potential to drive and support scientific discovery. In this work, we introduce MLR-Bench, a comprehensive benchmark for evaluating AI agents on open-ended machine learning research. MLR-Bench includes three key components: (1) 201 research tasks sourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2) MLR-Judge, an automated evaluation framework combining LLM-based reviewers with carefully designed review rubrics to assess research quality; and (3) MLR-Agent, a modular agent scaffold capable of completing research tasks through four stages: idea generation, proposal formulation, experimentation, and paper writing. Our framework supports both stepwise assessment across these distinct research stages, and end-to-end evaluation of the final research paper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced coding agent, finding that while LLMs are effective at generating coherent ideas and well-structured papers, current coding agents frequently (e.g., in 80% of the cases) produce fabricated or invalidated experimental results--posing a major barrier to scientific reliability. We validate MLR-Judge through human evaluation, showing high agreement with expert reviewers, supporting its potential as a scalable tool for research evaluation. We open-source MLR-Bench to help the community benchmark, diagnose, and improve AI research agents toward trustworthy and transparent scientific discovery.",
            "score": 8,
            "issue_id": 3974,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "8ac88b4e4afd844e",
            "authors": [
                "Hui Chen",
                "Miao Xiong",
                "Yujie Lu",
                "Wei Han",
                "Ailin Deng",
                "Yufei He",
                "Jiaying Wu",
                "Yibo Li",
                "Yue Liu",
                "Bryan Hooi"
            ],
            "affiliations": [
                "National University of Singapore",
                "Singapore University of Technology and Design",
                "University of California, Santa Barbara"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19955.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#science",
                    "#benchmark",
                    "#open_source"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "MLR-Bench: ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ˜Ğ˜ Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ…",
                    "desc": "MLR-Bench - ÑÑ‚Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ 201 Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ MLR-Judge Ğ¸ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° MLR-Agent. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ´ĞµĞ¹ Ğ¸ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¸ ÑÑ‚Ğ°Ñ‚ĞµĞ¹, Ğ½Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹. MLR-Judge Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ» Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğµ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¸Ğµ Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚ ĞµĞ³Ğ¾ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Evaluating AI Agents for Reliable Scientific Research",
                    "desc": "MLR-Bench is a new benchmark designed to evaluate AI agents in the context of scientific research, focusing on their performance across various stages of the research process. It includes 201 diverse research tasks and utilizes MLR-Judge, an automated evaluation system that combines LLM-based reviewers with specific rubrics to assess the quality of research outputs. The study reveals that while large language models (LLMs) excel in generating ideas and writing coherent papers, coding agents often struggle, producing unreliable experimental results in 80% of cases. By open-sourcing MLR-Bench, the authors aim to provide a tool for the community to enhance the reliability and transparency of AI-driven scientific discovery."
                },
                "zh": {
                    "title": "è¯„ä¼°AIä»£ç†ï¼Œæ¨åŠ¨ç§‘å­¦ç ”ç©¶çš„å¯é æ€§",
                    "desc": "MLR-Benchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIä»£ç†åœ¨ç§‘å­¦ç ”ç©¶ä¸­çš„è¡¨ç°çš„åŸºå‡†å·¥å…·ã€‚å®ƒåŒ…æ‹¬201ä¸ªæ¥è‡ªNeurIPSã€ICLRå’ŒICMLç ”è®¨ä¼šçš„ç ”ç©¶ä»»åŠ¡ï¼Œæ¶µç›–äº†å¤šç§æœºå™¨å­¦ä¹ ä¸»é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å››ä¸ªé˜¶æ®µï¼ˆåˆ›æ„ç”Ÿæˆã€ææ¡ˆåˆ¶å®šã€å®éªŒå’Œè®ºæ–‡å†™ä½œï¼‰æ¥è¯„ä¼°AIä»£ç†çš„ç ”ç©¶èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ›æ„å’Œå†™ä½œæ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†ç¼–ç ä»£ç†åœ¨å®éªŒç»“æœçš„å¯é æ€§ä¸Šå­˜åœ¨è¾ƒå¤§é—®é¢˜ï¼Œå½±å“äº†ç§‘å­¦ç ”ç©¶çš„å¯ä¿¡åº¦ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19443",
            "title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications\n  of Agentic AI",
            "url": "https://huggingface.co/papers/2505.19443",
            "abstract": "A review contrasts vibe coding and agentic coding paradigms, highlighting their differences in interaction, autonomy, and application areas in AI-assisted software development.  \t\t\t\t\tAI-generated summary \t\t\t\t This review presents a comprehensive analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. While both leverage large language models (LLMs), they differ fundamentally in autonomy, architectural design, and the role of the developer. Vibe coding emphasizes intuitive, human-in-the-loop interaction through prompt-based, conversational workflows that support ideation, experimentation, and creative exploration. In contrast, agentic coding enables autonomous software development through goal-driven agents capable of planning, executing, testing, and iterating tasks with minimal human intervention. We propose a detailed taxonomy spanning conceptual foundations, execution models, feedback loops, safety mechanisms, debugging strategies, and real-world tool ecosystems. Through comparative workflow analysis and 20 detailed use cases, we illustrate how vibe systems thrive in early-stage prototyping and education, while agentic systems excel in enterprise-grade automation, codebase refactoring, and CI/CD integration. We further examine emerging trends in hybrid architectures, where natural language interfaces are coupled with autonomous execution pipelines. Finally, we articulate a future roadmap for agentic AI, outlining the infrastructure needed for trustworthy, explainable, and collaborative systems. Our findings suggest that successful AI software engineering will rely not on choosing one paradigm, but on harmonizing their strengths within a unified, human-centered development lifecycle.",
            "score": 8,
            "issue_id": 3967,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "04b7019c8d659b76",
            "authors": [
                "Ranjan Sapkota",
                "Konstantinos I. Roumeliotis",
                "Manoj Karkee"
            ],
            "affiliations": [
                "Cornell University, Department of Biological and Environmental Engineering, USA",
                "University of the Peloponnese, Department of Informatics and Telecommunications, Tripoli, Greece"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19443.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#agents",
                    "#architecture",
                    "#interpretability"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ’Ğ°Ğ¹Ğ± vs ĞĞ³ĞµĞ½Ñ‚: ĞĞ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼ Ğ² Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜: Ğ²Ğ°Ğ¹Ğ±-ĞºĞ¾Ğ´Ğ¸Ğ½Ğ³Ğ° Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ¸Ğ½Ğ³Ğ°. Ğ’Ğ°Ğ¹Ğ±-ĞºĞ¾Ğ´Ğ¸Ğ½Ğ³ Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ½Ğ° Ğ¸Ğ½Ñ‚ÑƒĞ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ° Ñ Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑÑ‹, Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°Ñ Ñ‚Ğ²Ğ¾Ñ€Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ. ĞĞ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´Ğ¸Ğ½Ğ³, Ğ½Ğ°Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ², Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½ÑƒÑ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ²Ğ¼ĞµÑˆĞ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾Ğ¼ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ñ†ĞµĞ»ĞµĞ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ‚Ğ°ĞºÑĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰ÑƒÑ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ, Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸ Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµĞ¸Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼."
                },
                "en": {
                    "title": "Harmonizing Vibe and Agentic Coding for AI Development",
                    "desc": "This paper reviews two coding paradigms in AI-assisted software development: vibe coding and agentic coding. Vibe coding focuses on human interaction and creativity, using conversational prompts to aid in ideation and experimentation. In contrast, agentic coding allows for more autonomous development, where AI agents can plan and execute tasks with little human input. The authors propose a taxonomy to compare these paradigms and suggest that the future of AI software engineering will benefit from integrating both approaches for a more effective development process."
                },
                "zh": {
                    "title": "èåˆæƒ…æ„Ÿç¼–ç ä¸è‡ªä¸»ç¼–ç çš„æœªæ¥è½¯ä»¶å¼€å‘",
                    "desc": "æœ¬æ–‡å¯¹ä¸¤ç§æ–°å…´çš„äººå·¥æ™ºèƒ½è¾…åŠ©è½¯ä»¶å¼€å‘èŒƒå¼è¿›è¡Œäº†å…¨é¢åˆ†æï¼šæƒ…æ„Ÿç¼–ç å’Œè‡ªä¸»ç¼–ç ã€‚æƒ…æ„Ÿç¼–ç å¼ºè°ƒé€šè¿‡åŸºäºæç¤ºçš„å¯¹è¯å·¥ä½œæµç¨‹å®ç°ç›´è§‚çš„äººæœºäº¤äº’ï¼Œé€‚åˆäºåˆ›æ„æ¢ç´¢å’Œå®éªŒã€‚è€Œè‡ªä¸»ç¼–ç åˆ™é€šè¿‡ç›®æ ‡é©±åŠ¨çš„æ™ºèƒ½ä½“å®ç°è‡ªä¸»è½¯ä»¶å¼€å‘ï¼Œèƒ½å¤Ÿåœ¨æœ€å°äººç±»å¹²é¢„ä¸‹è¿›è¡Œè§„åˆ’ã€æ‰§è¡Œå’Œæµ‹è¯•ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒæˆåŠŸçš„äººå·¥æ™ºèƒ½è½¯ä»¶å·¥ç¨‹å°†ä¾èµ–äºå°†è¿™ä¸¤ç§èŒƒå¼çš„ä¼˜åŠ¿ç»“åˆåœ¨ä¸€ä¸ªä»¥äººä¸ºä¸­å¿ƒçš„å¼€å‘ç”Ÿå‘½å‘¨æœŸä¸­ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19427",
            "title": "WINA: Weight Informed Neuron Activation for Accelerating Large Language\n  Model Inference",
            "url": "https://huggingface.co/papers/2505.19427",
            "abstract": "WINA, a training-free sparse activation framework for large language models, improves inference accuracy by considering hidden state magnitudes and weight matrix norms, outperforming existing methods.  \t\t\t\t\tAI-generated summary \t\t\t\t The growing computational demands of large language models (LLMs) make efficient inference and activation strategies increasingly critical. While recent approaches, such as Mixture-of-Experts (MoE), leverage selective activation but require specialized training, training-free sparse activation methods offer broader applicability and superior resource efficiency through their plug-and-play design. However, many existing methods rely solely on hidden state magnitudes to determine activation, resulting in high approximation errors and suboptimal inference accuracy. To address these limitations, we propose WINA (Weight Informed Neuron Activation), a novel, simple, and training-free sparse activation framework that jointly considers hidden state magnitudes and the column-wise ell_2-norms of weight matrices. We show that this leads to a sparsification strategy that obtains optimal approximation error bounds with theoretical guarantees tighter than existing techniques. Empirically, WINA also outperforms state-of-the-art methods (e.g., TEAL) by up to 2.94% in average performance at the same sparsity levels, across a diverse set of LLM architectures and datasets. These results position WINA as a new performance frontier for training-free sparse activation in LLM inference, advancing training-free sparse activation methods and setting a robust baseline for efficient inference. The source code is available at https://github.com/microsoft/wina.",
            "score": 8,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "b49e78670cfbb696",
            "authors": [
                "Sihan Chen",
                "Dan Zhao",
                "Jongwoo Ko",
                "Colby Banbury",
                "Huiping Zhuang",
                "Luming Liang",
                "Tianyi Chen"
            ],
            "affiliations": [
                "Microsoft",
                "New York University",
                "Renmin University of China",
                "South China University of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19427.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#open_source",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "WINA: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "WINA - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğ¹ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ ĞºĞ°Ğº Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹, Ñ‚Ğ°Ğº Ğ¸ Ğ½Ğ¾Ñ€Ğ¼Ñ‹ Ğ²ĞµÑĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†. WINA Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ°Ğ¿Ğ¿Ñ€Ğ¾ĞºÑĞ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ñ Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸ÑĞ¼Ğ¸. Ğ­Ğ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸ WINA Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¾ 2.94% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ¿Ñ€Ğ¸ Ñ‚Ğ¾Ğ¼ Ğ¶Ğµ ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "WINA: Efficient Inference with Training-Free Sparse Activation",
                    "desc": "WINA is a new framework designed for sparse activation in large language models that does not require training. It improves inference accuracy by considering both the magnitudes of hidden states and the norms of weight matrices, which helps reduce errors in activation decisions. This approach allows for better resource efficiency and broader applicability compared to existing methods that rely only on hidden state magnitudes. Empirical results show that WINA outperforms current state-of-the-art techniques, making it a significant advancement in efficient inference for large language models."
                },
                "zh": {
                    "title": "WINAï¼šæ— è®­ç»ƒçš„ç¨€ç–æ¿€æ´»æ–°çªç ´",
                    "desc": "WINAæ˜¯ä¸€ç§æ— è®­ç»ƒçš„ç¨€ç–æ¿€æ´»æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†å‡†ç¡®æ€§ã€‚å®ƒé€šè¿‡åŒæ—¶è€ƒè™‘éšè—çŠ¶æ€çš„å¤§å°å’Œæƒé‡çŸ©é˜µçš„åˆ—å‘ell_2èŒƒæ•°ï¼Œä¼˜åŒ–äº†æ¿€æ´»ç­–ç•¥ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒWINAåœ¨ç›¸åŒç¨€ç–åº¦ä¸‹çš„å¹³å‡æ€§èƒ½æé«˜äº†æœ€å¤š2.94%ã€‚è¿™ä¸€åˆ›æ–°æ–¹æ³•ä¸ºæ— è®­ç»ƒçš„ç¨€ç–æ¿€æ´»æä¾›äº†æ–°çš„æ€§èƒ½åŸºå‡†ï¼Œæ¨åŠ¨äº†é«˜æ•ˆæ¨ç†çš„å‘å±•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19103",
            "title": "WHISTRESS: Enriching Transcriptions with Sentence Stress Detection",
            "url": "https://huggingface.co/papers/2505.19103",
            "abstract": "WHISTRESS is an alignment-free method for sentence stress detection trained on synthetic data, outperforming existing methods and generalizing well to diverse benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Spoken language conveys meaning not only through words but also through intonation, emotion, and emphasis. Sentence stress, the emphasis placed on specific words within a sentence, is crucial for conveying speaker intent and has been extensively studied in linguistics. In this work, we introduce WHISTRESS, an alignment-free approach for enhancing transcription systems with sentence stress detection. To support this task, we propose TINYSTRESS-15K, a scalable, synthetic training data for the task of sentence stress detection which resulted from a fully automated dataset creation process. We train WHISTRESS on TINYSTRESS-15K and evaluate it against several competitive baselines. Our results show that WHISTRESS outperforms existing methods while requiring no additional input priors during training or inference. Notably, despite being trained on synthetic data, WHISTRESS demonstrates strong zero-shot generalization across diverse benchmarks. Project page: https://pages.cs.huji.ac.il/adiyoss-lab/whistress.",
            "score": 8,
            "issue_id": 3981,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "8a3080cabca549f8",
            "authors": [
                "Iddo Yosha",
                "Dorin Shteyman",
                "Yossi Adi"
            ],
            "affiliations": [
                "The School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19103.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#synthetic",
                    "#audio",
                    "#data",
                    "#benchmark",
                    "#alignment"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "WHISTRESS: Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ… Ğ±ĞµĞ· Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ",
                    "desc": "WHISTRESS - ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ ÑƒĞ´Ğ°Ñ€ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ…, Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğ¹ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ½ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ‹. Ğ”Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ±Ñ‹Ğ»Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ±Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… TINYSTRESS-15K Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°. ĞĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, WHISTRESS Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¸Ğ»ÑŒĞ½ÑƒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ½ÑƒĞ»ĞµĞ²Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…."
                },
                "en": {
                    "title": "Revolutionizing Sentence Stress Detection with WHISTRESS",
                    "desc": "WHISTRESS is a novel method for detecting sentence stress without needing alignment with the spoken input. It is trained on a synthetic dataset called TINYSTRESS-15K, which was created automatically to provide a large amount of training data. The method shows superior performance compared to existing techniques and does not require extra information during training or inference. Remarkably, WHISTRESS also exhibits strong zero-shot generalization, meaning it can perform well on new, unseen data without additional training."
                },
                "zh": {
                    "title": "æ— å¯¹é½å¥å­é‡éŸ³æ£€æµ‹çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "WHISTRESSæ˜¯ä¸€ç§æ— å¯¹é½çš„æ–¹æ³•ï¼Œç”¨äºæ£€æµ‹å¥å­é‡éŸ³ï¼Œé‡‡ç”¨åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å¥å­é‡éŸ³æ˜¯æŒ‡åœ¨å¥å­ä¸­å¯¹ç‰¹å®šå•è¯çš„å¼ºè°ƒï¼Œå¯¹äºä¼ è¾¾è¯´è¯è€…çš„æ„å›¾è‡³å…³é‡è¦ã€‚æˆ‘ä»¬æå‡ºäº†TINYSTRESS-15Kï¼Œè¿™æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„åˆæˆè®­ç»ƒæ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºå¥å­é‡éŸ³æ£€æµ‹ã€‚WHISTRESSåœ¨TINYSTRESS-15Kä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªç«äº‰åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­æ— éœ€é¢å¤–è¾“å…¥å…ˆéªŒä¿¡æ¯ï¼Œä¾ç„¶è¡¨ç°å‡ºè‰²ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20278",
            "title": "The Coverage Principle: A Framework for Understanding Compositional\n  Generalization",
            "url": "https://huggingface.co/papers/2505.20278",
            "abstract": "Large language models excel at pattern matching, yet often fall short in systematic compositional generalization. We propose the coverage principle: a data-centric framework showing that models relying primarily on pattern matching for compositional tasks cannot reliably generalize beyond substituting fragments that yield identical results when used in the same contexts. We demonstrate that this framework has a strong predictive power for the generalization capabilities of Transformers. First, we derive and empirically confirm that the training data required for two-hop generalization grows at least quadratically with the token set size, and the training data efficiency does not improve with 20x parameter scaling. Second, for compositional tasks with path ambiguity where one variable affects the output through multiple computational paths, we show that Transformers learn context-dependent state representations that undermine both performance and interoperability. Third, Chain-of-Thought supervision improves training data efficiency for multi-hop tasks but still struggles with path ambiguity. Finally, we outline a mechanism-based taxonomy that distinguishes three ways neural networks can generalize: structure-based (bounded by coverage), property-based (leveraging algebraic invariances), and shared-operator (through function reuse). This conceptual lens contextualizes our results and highlights where new architectural ideas are needed to achieve systematic compositionally. Overall, the coverage principle provides a unified lens for understanding compositional reasoning, and underscores the need for fundamental architectural or training innovations to achieve truly systematic compositionality.",
            "score": 7,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "afca6c0a8de30a05",
            "authors": [
                "Hoyeon Chang",
                "Jinho Park",
                "Hanseul Cho",
                "Sohee Yang",
                "Miyoung Ko",
                "Hyeonbin Hwang",
                "Seungpil Won",
                "Dohaeng Lee",
                "Youbin Ahn",
                "Minjoon Seo"
            ],
            "affiliations": [
                "KAIST",
                "LG AI Research",
                "UCL"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20278.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#training",
                    "#reasoning",
                    "#data",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ·Ğ³Ğ»ÑĞ´ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ² Ğ˜Ğ˜",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ, Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ğ¾Ğ², Ğ½Ğµ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒ Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‹ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ² Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ´Ğ»Ñ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ€Ğ¾ÑÑ‚ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ° ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² 20 Ñ€Ğ°Ğ· Ğ½Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ‚Ğ°ĞºÑĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ¾Ğ² Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğµ, ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ."
                },
                "en": {
                    "title": "Unlocking Systematic Compositionality in Language Models",
                    "desc": "This paper introduces the coverage principle, which highlights the limitations of large language models in systematic compositional generalization. It shows that models relying on pattern matching struggle to generalize effectively when faced with tasks that require substituting different fragments. The authors demonstrate that the amount of training data needed for effective two-hop generalization increases significantly with the size of the token set, and that simply increasing model parameters does not enhance training efficiency. Additionally, they propose a taxonomy for understanding different types of generalization in neural networks, emphasizing the need for new architectural innovations to improve compositional reasoning."
                },
                "zh": {
                    "title": "è¦†ç›–åŸåˆ™ï¼šç†è§£ç»„åˆæ¨ç†çš„ç»Ÿä¸€è§†è§’",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡å¼åŒ¹é…æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç³»ç»Ÿæ€§ç»„åˆæ³›åŒ–æ–¹é¢å¸¸å¸¸ä¸è¶³ã€‚æˆ‘ä»¬æå‡ºäº†è¦†ç›–åŸåˆ™ï¼šè¿™æ˜¯ä¸€ä¸ªä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ¡†æ¶ï¼Œè¡¨æ˜ä¸»è¦ä¾èµ–æ¨¡å¼åŒ¹é…çš„æ¨¡å‹åœ¨ç»„åˆä»»åŠ¡ä¸­æ— æ³•å¯é åœ°æ³›åŒ–ã€‚æˆ‘ä»¬è¯æ˜äº†è¯¥æ¡†æ¶å¯¹å˜æ¢å™¨çš„æ³›åŒ–èƒ½åŠ›å…·æœ‰å¼ºå¤§çš„é¢„æµ‹èƒ½åŠ›ï¼Œå¹¶æŒ‡å‡ºè®­ç»ƒæ•°æ®çš„éœ€æ±‚éšç€æ ‡è®°é›†å¤§å°çš„å¢åŠ è€Œè‡³å°‘å‘ˆå¹³æ–¹å¢é•¿ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæœºåˆ¶çš„åˆ†ç±»æ³•ï¼ŒåŒºåˆ†äº†ç¥ç»ç½‘ç»œçš„ä¸‰ç§æ³›åŒ–æ–¹å¼ï¼Œå¼ºè°ƒäº†å®ç°çœŸæ­£ç³»ç»Ÿæ€§ç»„åˆæ‰€éœ€çš„æ–°æ¶æ„åˆ›æ–°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19223",
            "title": "LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language\n  Diffusion Models",
            "url": "https://huggingface.co/papers/2505.19223",
            "abstract": "VRPO is a variance-reduced preference optimization framework for Masked Diffusion Models that significantly enhances their alignment with human preferences and performance across various benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t While Masked Diffusion Models (MDMs), such as LLaDA, present a promising paradigm for language modeling, there has been relatively little effort in aligning these models with human preferences via reinforcement learning. The challenge primarily arises from the high variance in Evidence Lower Bound (ELBO)-based likelihood estimates required for preference optimization. To address this issue, we propose Variance-Reduced Preference Optimization (VRPO), a framework that formally analyzes the variance of ELBO estimators and derives bounds on both the bias and variance of preference optimization gradients. Building on this theoretical foundation, we introduce unbiased variance reduction strategies, including optimal Monte Carlo budget allocation and antithetic sampling, that significantly improve the performance of MDM alignment. We demonstrate the effectiveness of VRPO by applying it to LLaDA, and the resulting model, LLaDA 1.5, outperforms its SFT-only predecessor consistently and significantly across mathematical (GSM8K +4.7), code (HumanEval +3.0, MBPP +1.8), and alignment benchmarks (IFEval +4.0, Arena-Hard +4.3). Furthermore, LLaDA 1.5 demonstrates a highly competitive mathematical performance compared to strong language MDMs and ARMs. Project page: https://ml-gsai.github.io/LLaDA-1.5-Demo/.",
            "score": 7,
            "issue_id": 3974,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "9e984483e970bca5",
            "authors": [
                "Fengqi Zhu",
                "Rongzhen Wang",
                "Shen Nie",
                "Xiaolu Zhang",
                "Chunwei Wu",
                "Jun Hu",
                "Jun Zhou",
                "Jianfei Chen",
                "Yankai Lin",
                "Ji-Rong Wen",
                "Chongxuan Li"
            ],
            "affiliations": [
                "Ant Group",
                "Beijing Key Laboratory of Research on Large Models and Intelligent Governance",
                "Engineering Research Center of Next-Generation Intelligent Search and Recommendation, MOE",
                "Gaoling School of AI, Renmin University of China",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19223.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rl",
                    "#benchmark",
                    "#architecture",
                    "#optimization",
                    "#alignment",
                    "#rlhf"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "ĞŸĞ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹",
                    "desc": "VRPO - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ Ñ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸ĞµĞ¹ Ğ´Ğ»Ñ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MDM). ĞĞ½ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¸ Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞ°Ñ… Ğ¿Ñ€Ğ°Ğ²Ğ´Ğ¾Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ELBO, Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹. VRPO Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ±ÑĞ´Ğ¶ĞµÑ‚Ğ° ĞœĞ¾Ğ½Ñ‚Ğµ-ĞšĞ°Ñ€Ğ»Ğ¾ Ğ¸ Ğ°Ğ½Ñ‚Ğ¸Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ VRPO Ğº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ LLaDA Ğ¿Ñ€Ğ¸Ğ²ĞµĞ»Ğ¾ Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ LLaDA 1.5, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ²Ğ·Ğ¾ÑˆĞ»Ğ° ÑĞ²Ğ¾ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑˆĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¸ĞºĞ° Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ğ¼."
                },
                "en": {
                    "title": "Enhancing MDMs with Variance-Reduced Preference Optimization",
                    "desc": "This paper introduces Variance-Reduced Preference Optimization (VRPO), a new framework designed to improve the alignment of Masked Diffusion Models (MDMs) with human preferences. The authors address the challenge of high variance in Evidence Lower Bound (ELBO) estimates that complicates preference optimization. By analyzing the variance of ELBO estimators, they develop unbiased variance reduction techniques, such as optimal Monte Carlo budget allocation and antithetic sampling. The application of VRPO to the LLaDA model results in LLaDA 1.5, which shows significant performance improvements across various benchmarks, outperforming previous models in both alignment and task-specific evaluations."
                },
                "zh": {
                    "title": "æ–¹å·®å‡å°‘ï¼Œä¼˜åŒ–åå¥½å¯¹é½ï¼",
                    "desc": "VRPOæ˜¯ä¸€ç§æ–¹å·®å‡å°‘çš„åå¥½ä¼˜åŒ–æ¡†æ¶ï¼Œä¸“ä¸ºæ©è”½æ‰©æ•£æ¨¡å‹è®¾è®¡ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹ä¸äººç±»åå¥½çš„å¯¹é½ç¨‹åº¦åŠå…¶åœ¨å„ç±»åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ã€‚æ©è”½æ‰©æ•£æ¨¡å‹ï¼ˆMDMsï¼‰åœ¨è¯­è¨€å»ºæ¨¡ä¸­å±•ç°å‡ºè‰¯å¥½çš„å‰æ™¯ï¼Œä½†åœ¨é€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹é½äººç±»åå¥½æ–¹é¢çš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚VRPOé€šè¿‡åˆ†æELBOä¼°è®¡å™¨çš„æ–¹å·®ï¼Œæå‡ºäº†åå·®å’Œæ–¹å·®çš„ç•Œé™ï¼Œå¹¶å¼•å…¥äº†æ— åæ–¹å·®å‡å°‘ç­–ç•¥ï¼Œå¦‚æœ€ä¼˜çš„è’™ç‰¹å¡æ´›é¢„ç®—åˆ†é…å’Œå¯¹ç«‹é‡‡æ ·ã€‚é€šè¿‡å°†VRPOåº”ç”¨äºLLaDAï¼Œç”Ÿæˆçš„æ¨¡å‹LLaDA 1.5åœ¨æ•°å­¦ã€ä»£ç å’Œå¯¹é½åŸºå‡†æµ‹è¯•ä¸­å‡æ˜¾è‘—ä¼˜äºå…¶å‰èº«ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.10887",
            "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer\n  Interaction",
            "url": "https://huggingface.co/papers/2505.10887",
            "abstract": "InfantAgent-Next is a multimodal agent that integrates tool-based and vision models in a modular architecture to solve various benchmarks, including OSWorld, GAIA, and SWE-Bench.  \t\t\t\t\tAI-generated summary \t\t\t\t This paper introduces InfantAgent-Next, a generalist agent capable of interacting with computers in a multimodal manner, encompassing text, images, audio, and video. Unlike existing approaches that either build intricate workflows around a single large model or only provide workflow modularity, our agent integrates tool-based and pure vision agents within a highly modular architecture, enabling different models to collaboratively solve decoupled tasks in a step-by-step manner. Our generality is demonstrated by our ability to evaluate not only pure vision-based real-world benchmarks (i.e., OSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and SWE-Bench). Specifically, we achieve 7.27% accuracy on OSWorld, higher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced at https://github.com/bin123apple/InfantAgent.",
            "score": 7,
            "issue_id": 3968,
            "pub_date": "2025-05-16",
            "pub_date_card": {
                "ru": "16 Ğ¼Ğ°Ñ",
                "en": "May 16",
                "zh": "5æœˆ16æ—¥"
            },
            "hash": "ed2c69dbcbbae339",
            "authors": [
                "Bin Lei",
                "Weitai Kang",
                "Zijian Zhang",
                "Winson Chen",
                "Xi Xie",
                "Shan Zuo",
                "Mimi Xie",
                "Ali Payani",
                "Mingyi Hong",
                "Yan Yan",
                "Caiwen Ding"
            ],
            "affiliations": [
                "Cisco Research",
                "The University of Texas at San Antonio",
                "University of Connecticut",
                "University of Illinois Chicago",
                "University of Minnesota"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.10887.jpg",
            "data": {
                "categories": [
                    "#agi",
                    "#open_source",
                    "#benchmark",
                    "#agents",
                    "#multimodal",
                    "#architecture"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡",
                    "desc": "InfantAgent-Next - ÑÑ‚Ğ¾ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚, Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒĞ½ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ. ĞĞ½ ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ°Ğ¼Ğ¸, Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ Ñ‚ĞµĞºÑÑ‚, Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾. ĞĞ³ĞµĞ½Ñ‚ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ, Ñ€ĞµÑˆĞ°Ñ ĞºĞ°Ğº Ñ‡Ğ¸ÑÑ‚Ğ¾ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ (OSWorld), Ñ‚Ğ°Ğº Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ¸Ğ»Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾-Ğ¸Ğ½Ñ‚ĞµĞ½ÑĞ¸Ğ²Ğ½Ñ‹Ğµ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¸ (GAIA, SWE-Bench). ĞĞ° Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞµ OSWorld InfantAgent-Next Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ 7.27%, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Claude-Computer-Use."
                },
                "en": {
                    "title": "Empowering Multimodal Interaction with InfantAgent-Next",
                    "desc": "InfantAgent-Next is a versatile multimodal agent designed to handle various tasks by integrating both tool-based and vision models. It features a modular architecture that allows different models to work together efficiently, solving tasks step-by-step. This approach contrasts with traditional methods that rely on a single large model or rigid workflows. The agent's effectiveness is showcased through its performance on multiple benchmarks, achieving notable accuracy in real-world scenarios."
                },
                "zh": {
                    "title": "å¤šæ¨¡æ€æ™ºèƒ½ä½“çš„æœªæ¥ï¼šInfantAgent-Next",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†InfantAgent-Nextï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡æ€æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿé€šè¿‡æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ä¸è®¡ç®—æœºè¿›è¡Œäº¤äº’ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒInfantAgent-Nextåœ¨é«˜åº¦æ¨¡å—åŒ–çš„æ¶æ„ä¸­æ•´åˆäº†åŸºäºå·¥å…·å’Œçº¯è§†è§‰çš„æ™ºèƒ½ä½“ï¼Œä½¿ä¸åŒæ¨¡å‹èƒ½å¤Ÿä»¥é€æ­¥çš„æ–¹å¼åä½œè§£å†³è§£è€¦ä»»åŠ¡ã€‚æˆ‘ä»¬çš„æ™ºèƒ½ä½“åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬çº¯è§†è§‰çš„OSWorldå’Œæ›´å¤æ‚çš„GAIAä¸SWE-Benchï¼Œå±•ç¤ºäº†å…¶é€šç”¨æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åœ¨OSWorldä¸Šè¾¾åˆ°äº†7.27%çš„å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†Claude-Computer-Useã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19731",
            "title": "Accelerating Nash Learning from Human Feedback via Mirror Prox",
            "url": "https://huggingface.co/papers/2505.19731",
            "abstract": "Nash Mirror Prox is an online algorithm for Nash Learning from Human Feedback that achieves linear convergence to the Nash equilibrium and is applicable for fine-tuning language models.  \t\t\t\t\tAI-generated summary \t\t\t\t Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on reward models, frequently assuming preference structures like the Bradley-Terry model, which may not accurately capture the complexities of real human preferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF) offers a more direct alternative by framing the problem as finding a Nash equilibrium of a game defined by these preferences. In this work, we introduce Nash Mirror Prox (Nash-MP), an online NLHF algorithm that leverages the Mirror Prox optimization scheme to achieve fast and stable convergence to the Nash equilibrium. Our theoretical analysis establishes that Nash-MP exhibits last-iterate linear convergence towards the beta-regularized Nash equilibrium. Specifically, we prove that the KL-divergence to the optimal policy decreases at a rate of order (1+2beta)^{-N/2}, where N is a number of preference queries. We further demonstrate last-iterate linear convergence for the exploitability gap and uniformly for the span semi-norm of log-probabilities, with all these rates being independent of the size of the action space. Furthermore, we propose and analyze an approximate version of Nash-MP where proximal steps are estimated using stochastic policy gradients, making the algorithm closer to applications. Finally, we detail a practical implementation strategy for fine-tuning large language models and present experiments that demonstrate its competitive performance and compatibility with existing methods.",
            "score": 6,
            "issue_id": 3975,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "8c7cc8955de4314c",
            "authors": [
                "Daniil Tiapkin",
                "Daniele Calandriello",
                "Denis Belomestny",
                "Eric Moulines",
                "Alexey Naumov",
                "Kashif Rasul",
                "Michal Valko",
                "Pierre Menard"
            ],
            "affiliations": [
                "CMAP, CNRS, Ã‰cole Polytechnique",
                "Duisburg-Essen University",
                "ENS Lyon",
                "Google DeepMind",
                "HSE University",
                "Hugging Face",
                "LMO, UniversitÃ© Paris-Saclay",
                "Mohamed Bin Zayed University of AI",
                "Stealth Startup / Inria / ENS"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19731.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#rlhf",
                    "#training",
                    "#alignment",
                    "#optimization"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Nash Mirror Prox: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ˜Ğ˜ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Nash Mirror Prox - Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸ Ğ¾Ñ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°. ĞĞ½ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğº Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ²ĞµÑĞ¸Ñ ĞÑÑˆĞ° Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ¼ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑÑ…ĞµĞ¼Ñƒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Mirror Prox Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ¸ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸. Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Nash-MP Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½ÑƒÑ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğº Ğ±ĞµÑ‚Ğ°-Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ²ĞµÑĞ¸Ñ ĞÑÑˆĞ°."
                },
                "en": {
                    "title": "Achieving Fast Convergence to Nash Equilibrium in Language Models",
                    "desc": "Nash Mirror Prox (Nash-MP) is a novel online algorithm designed for Nash Learning from Human Feedback (NLHF), which aims to find a Nash equilibrium based on human preferences. Unlike traditional Reinforcement Learning from Human Feedback that relies on potentially inaccurate reward models, Nash-MP directly addresses the complexities of human preferences by framing them as a game. The algorithm achieves linear convergence to the Nash equilibrium, ensuring fast and stable performance, particularly in fine-tuning language models. Additionally, an approximate version of Nash-MP is proposed, utilizing stochastic policy gradients for practical applications, with experiments showing its effectiveness compared to existing methods."
                },
                "zh": {
                    "title": "å¿«é€Ÿæ”¶æ•›çš„çº³ä»€å­¦ä¹ ç®—æ³•",
                    "desc": "Nash Mirror Proxï¼ˆNash-MPï¼‰æ˜¯ä¸€ç§åœ¨çº¿ç®—æ³•ï¼Œç”¨äºä»äººç±»åé¦ˆä¸­è¿›è¡Œçº³ä»€å­¦ä¹ ï¼Œèƒ½å¤Ÿå¿«é€Ÿç¨³å®šåœ°æ”¶æ•›åˆ°çº³ä»€å‡è¡¡ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºå¥–åŠ±æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒNash-MPç›´æ¥å°†é—®é¢˜è§†ä¸ºå¯»æ‰¾åå¥½ç»“æ„ä¸‹çš„çº³ä»€å‡è¡¡ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼ŒNash-MPåœ¨æœ€åä¸€æ¬¡è¿­ä»£ä¸­ä»¥çº¿æ€§é€Ÿåº¦æ”¶æ•›åˆ°Î²æ­£åˆ™åŒ–çš„çº³ä»€å‡è¡¡ï¼Œå¹¶ä¸”KLæ•£åº¦ä»¥ç‰¹å®šé€Ÿç‡ä¸‹é™ã€‚è¯¥ç®—æ³•è¿˜æå‡ºäº†ä¸€ç§è¿‘ä¼¼ç‰ˆæœ¬ï¼Œåˆ©ç”¨éšæœºç­–ç•¥æ¢¯åº¦è¿›è¡Œä¼°è®¡ï¼Œä½¿å…¶æ›´é€‚åˆå®é™…åº”ç”¨ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18773",
            "title": "Strong Membership Inference Attacks on Massive Datasets and (Moderately)\n  Large Language Models",
            "url": "https://huggingface.co/papers/2505.18773",
            "abstract": "State-of-the-art membership inference attacks (MIAs) typically require training many reference models, making it difficult to scale these attacks to large pre-trained language models (LLMs). As a result, prior research has either relied on weaker attacks that avoid training reference models (e.g., fine-tuning attacks), or on stronger attacks applied to small-scale models and datasets. However, weaker attacks have been shown to be brittle - achieving close-to-arbitrary success - and insights from strong attacks in simplified settings do not translate to today's LLMs. These challenges have prompted an important question: are the limitations observed in prior work due to attack design choices, or are MIAs fundamentally ineffective on LLMs? We address this question by scaling LiRA - one of the strongest MIAs - to GPT-2 architectures ranging from 10M to 1B parameters, training reference models on over 20B tokens from the C4 dataset. Our results advance the understanding of MIAs on LLMs in three key ways: (1) strong MIAs can succeed on pre-trained LLMs; (2) their effectiveness, however, remains limited (e.g., AUC<0.7) in practical settings; and, (3) the relationship between MIA success and related privacy metrics is not as straightforward as prior work has suggested.",
            "score": 6,
            "issue_id": 3973,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "8f8b97df6594a242",
            "authors": [
                "Jamie Hayes",
                "Ilia Shumailov",
                "Christopher A. Choquette-Choo",
                "Matthew Jagielski",
                "George Kaissis",
                "Katherine Lee",
                "Milad Nasr",
                "Sahra Ghalebikesabi",
                "Niloofar Mireshghallah",
                "Meenatchi Sundaram Mutu Selva Annamalai",
                "Igor Shilov",
                "Matthieu Meeus",
                "Yves-Alexandre de Montjoye",
                "Franziska Boenisch",
                "Adam Dziedzic",
                "A. Feder Cooper"
            ],
            "affiliations": [
                "CISPA Helmholtz Center for Information Security",
                "Cornell University",
                "Google DeepMind",
                "Imperial College London",
                "University College London",
                "University of Washington"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18773.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#dataset",
                    "#benchmark",
                    "#security",
                    "#leakage"
                ],
                "emoji": "ğŸ•µï¸",
                "ru": {
                    "title": "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ‚Ğ°Ğº Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ñ‡Ğ»ĞµĞ½ÑÑ‚Ğ²Ğ° Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸ ÑĞ¸Ğ»ÑŒĞ½ÑƒÑ Ğ°Ñ‚Ğ°ĞºÑƒ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ñ‡Ğ»ĞµĞ½ÑÑ‚Ğ²Ğ° (MIA) Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ LiRA Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ GPT-2 Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ². ĞĞ½Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ğ»Ğ¸ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ 20 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ°Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸Ğ· Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° C4. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ MIA Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM), Ğ½Ğ¾ Ğ¸Ñ… ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾ÑÑ‚Ğ°ĞµÑ‚ÑÑ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ² Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ ÑĞ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑƒÑĞ¿ĞµÑ…Ğ¾Ğ¼ MIA Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğµ Ñ‚Ğ°Ğº Ğ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ğ°, ĞºĞ°Ğº Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°Ğ½ĞµĞµ."
                },
                "en": {
                    "title": "Scaling Membership Inference Attacks on Large Language Models",
                    "desc": "This paper investigates the effectiveness of membership inference attacks (MIAs) on large pre-trained language models (LLMs) like GPT-2. It highlights the challenges of scaling MIAs due to the need for training multiple reference models, which has limited previous research. The authors scale the LiRA attack to various GPT-2 architectures and find that while strong MIAs can be effective, their success rates are still relatively low in practical applications. Additionally, the study reveals that the relationship between MIA success and privacy metrics is more complex than previously thought."
                },
                "zh": {
                    "title": "æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„ä¼šå‘˜æ¨æ–­æ”»å‡»æŒ‘æˆ˜",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†ä¼šå‘˜æ¨æ–­æ”»å‡»ï¼ˆMIAï¼‰åœ¨å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸Šçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬æ‰©å±•äº†LiRAæ”»å‡»æ–¹æ³•ï¼Œåº”ç”¨äºä¸åŒè§„æ¨¡çš„GPT-2æ¨¡å‹ï¼Œå¹¶åœ¨è¶…è¿‡200äº¿ä¸ªC4æ•°æ®é›†çš„æ ‡è®°ä¸Šè®­ç»ƒå‚è€ƒæ¨¡å‹ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å¼ºå¤§çš„MIAå¯ä»¥åœ¨é¢„è®­ç»ƒçš„LLMä¸Šå–å¾—æˆåŠŸï¼Œä½†å…¶æœ‰æ•ˆæ€§åœ¨å®é™…åº”ç”¨ä¸­ä»ç„¶æœ‰é™ï¼ˆä¾‹å¦‚ï¼ŒAUC<0.7ï¼‰ã€‚æ­¤å¤–ï¼ŒMIAæˆåŠŸä¸éšç§æŒ‡æ ‡ä¹‹é—´çš„å…³ç³»æ¯”ä¹‹å‰çš„ç ”ç©¶æ‰€æš—ç¤ºçš„è¦å¤æ‚å¾—å¤šã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18384",
            "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
            "url": "https://huggingface.co/papers/2505.18384",
            "abstract": "Adversaries can significantly enhance foundation model capabilities in offensive cybersecurity with limited computational resources, underscoring the need for dynamic threat model assessments.  \t\t\t\t\tAI-generated summary \t\t\t\t Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.",
            "score": 5,
            "issue_id": 3971,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "ef99d86a3934644e",
            "authors": [
                "Boyi Wei",
                "Benedikt Stroebl",
                "Jiacen Xu",
                "Joie Zhang",
                "Zhou Li",
                "Peter Henderson"
            ],
            "affiliations": [
                "Princeton University",
                "University of California, Irvine"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18384.jpg",
            "data": {
                "categories": [
                    "#cybersecurity",
                    "#agents",
                    "#security"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ÑƒĞ³Ñ€Ğ¾Ğ· Ğ˜Ğ˜ Ğ² ĞºĞ¸Ğ±ĞµÑ€Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ·Ğ»Ğ¾ÑƒĞ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ğ¸ĞºĞ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ½Ğ°ÑÑ‚ÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ¸Ğ±ĞµÑ€Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµÑÑƒÑ€ÑÑ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑƒÑ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€Ğ¸ÑĞºĞ¾Ğ² Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑƒĞ³Ñ€Ğ¾Ğ· Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ ĞºĞ¸Ğ±ĞµÑ€Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ´Ğ°Ğ¶Ğµ Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ±ÑĞ´Ğ¶ĞµÑ‚Ğ¾Ğ¼ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ ĞºĞ¸Ğ±ĞµÑ€Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ñ‡ĞµĞ¼ Ğ½Ğ° 40% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼ ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¼. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ÑÑ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ€Ğ¸ÑĞºĞ¾Ğ² ĞºĞ¸Ğ±ĞµÑ€Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ°."
                },
                "en": {
                    "title": "Enhancing Cybersecurity: Adversaries Boost AI with Limited Resources",
                    "desc": "This paper discusses how adversaries can improve the capabilities of foundation models in offensive cybersecurity, even with limited computational resources. It highlights the importance of dynamic threat model assessments that consider the various options available to adversaries in real-world scenarios. The authors demonstrate that adversaries can enhance an agent's performance significantly, achieving over 40% improvement in cybersecurity tasks with minimal compute resources. This underscores the necessity for more comprehensive evaluations of cybersecurity risks associated with AI agents."
                },
                "zh": {
                    "title": "åŠ¨æ€è¯„ä¼°å¯¹æŠ—è€…åœ¨ç½‘ç»œå®‰å…¨ä¸­çš„å¨èƒ",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¯¹æŠ—è€…å¦‚ä½•åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹æ˜¾è‘—æå‡åŸºç¡€æ¨¡å‹åœ¨è¿›æ”»æ€§ç½‘ç»œå®‰å…¨ä¸­çš„èƒ½åŠ›ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒåŸºç¡€æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–ç¼–ç¨‹æ–¹é¢çš„è¿›æ­¥å¯èƒ½ä½¿å…¶èƒ½å¤Ÿè‡ªåŠ¨åŒ–å±é™©çš„ç½‘ç»œæ”»å‡»æ“ä½œã€‚å½“å‰çš„æ¨¡å‹å®¡è®¡å¾€å¾€æœªèƒ½è€ƒè™‘ç°å®ä¸–ç•Œä¸­å¯¹æŠ—è€…çš„è‡ªç”±åº¦ï¼Œå¯¼è‡´å¯¹ç½‘ç»œå®‰å…¨é£é™©çš„è¯„ä¼°ä¸è¶³ã€‚æˆ‘ä»¬å»ºè®®åœ¨ç½‘ç»œå®‰å…¨è¯„ä¼°ä¸­åº”è€ƒè™‘æ‰©å±•çš„å¨èƒæ¨¡å‹ï¼Œä»¥åŠ¨æ€æ–¹å¼è¯„ä¼°å¯¹æŠ—è€…åœ¨ä¸åŒç¯å¢ƒä¸‹çš„èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.17652",
            "title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM\n  Reasoning: A Competence-Difficulty Alignment Perspective",
            "url": "https://huggingface.co/papers/2505.17652",
            "abstract": "CDAS addresses low sample efficiency in reinforcement learning by aligning model competence with problem difficulty, improving both accuracy and efficiency in mathematical benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement learning exhibits potential in enhancing the reasoning abilities of large language models, yet it is hard to scale for the low sample efficiency during the rollout phase. Existing methods attempt to improve efficiency by scheduling problems based on problem difficulties. However, these approaches suffer from unstable and biased estimations of problem difficulty and fail to capture the alignment between model competence and problem difficulty in RL training, leading to suboptimal results. To tackle these limitations, this paper introduces Competence-Difficulty Alignment Sampling (CDAS), which enables accurate and stable estimation of problem difficulties by aggregating historical performance discrepancies of problems. Then the model competence is quantified to adaptively select problems whose difficulty is in alignment with the model's current competence using a fixed-point system. Experimental results across a range of challenging mathematical benchmarks show that CDAS achieves great improvements in both accuracy and efficiency. CDAS attains the highest average accuracy against baselines and exhibits significant speed advantages compared to Dynamic Sampling, a competitive strategy in DAPO, which is 2.33 times slower than CDAS.",
            "score": 5,
            "issue_id": 3968,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "84801a2fd0a3c281",
            "authors": [
                "Deyang Kong",
                "Qi Guo",
                "Xiangyu Xi",
                "Wei Wang",
                "Jingang Wang",
                "Xunliang Cai",
                "Shikun Zhang",
                "Wei Ye"
            ],
            "affiliations": [
                "Meituan Group, Beijing, China",
                "National Engineering Research Center for Software Engineering, Peking University, Beijing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.17652.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#training",
                    "#reasoning",
                    "#math",
                    "#optimization"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ: CDAS Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "CDAS (Competence-Difficulty Alignment Sampling) - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½ Ñ€ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ¿ÑƒÑ‚ĞµĞ¼ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿ĞµÑ‚ĞµĞ½Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¾ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. CDAS Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Aligning Model Skills with Task Challenges for Better Learning Efficiency",
                    "desc": "CDAS, or Competence-Difficulty Alignment Sampling, improves the efficiency of reinforcement learning by aligning the model's abilities with the difficulty of the tasks it faces. Traditional methods struggle with unstable estimates of problem difficulty, leading to poor training outcomes. CDAS addresses this by using historical performance data to accurately assess problem difficulties and adaptively select tasks that match the model's current competence level. Experimental results demonstrate that CDAS significantly enhances both accuracy and speed in solving complex mathematical problems compared to existing strategies."
                },
                "zh": {
                    "title": "èƒ½åŠ›ä¸éš¾åº¦çš„å®Œç¾å¯¹é½",
                    "desc": "CDASï¼ˆèƒ½åŠ›-éš¾åº¦å¯¹é½é‡‡æ ·ï¼‰æ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ ä¸­çš„ä½æ ·æœ¬æ•ˆç‡é—®é¢˜ã€‚å®ƒé€šè¿‡å¯¹é—®é¢˜éš¾åº¦çš„å†å²è¡¨ç°å·®å¼‚è¿›è¡Œèšåˆï¼Œæä¾›å‡†ç¡®ä¸”ç¨³å®šçš„éš¾åº¦ä¼°è®¡ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®æ¨¡å‹å½“å‰çš„èƒ½åŠ›ï¼Œè‡ªé€‚åº”é€‰æ‹©ä¸ä¹‹å¯¹é½çš„éš¾åº¦é—®é¢˜ï¼Œä»è€Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCDASåœ¨å¤šä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20254",
            "title": "Position: Mechanistic Interpretability Should Prioritize Feature\n  Consistency in SAEs",
            "url": "https://huggingface.co/papers/2505.20254",
            "abstract": "Prioritizing feature consistency in sparse autoencoders improves mechanistic interpretability of neural networks by ensuring reliable and interpretable features.  \t\t\t\t\tAI-generated summary \t\t\t\t Sparse Autoencoders (SAEs) are a prominent tool in mechanistic interpretability (MI) for decomposing neural network activations into interpretable features. However, the aspiration to identify a canonical set of features is challenged by the observed inconsistency of learned SAE features across different training runs, undermining the reliability and efficiency of MI research. This position paper argues that mechanistic interpretability should prioritize feature consistency in SAEs -- the reliable convergence to equivalent feature sets across independent runs. We propose using the Pairwise Dictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to operationalize consistency and demonstrate that high levels are achievable (0.80 for TopK SAEs on LLM activations) with appropriate architectural choices. Our contributions include detailing the benefits of prioritizing consistency; providing theoretical grounding and synthetic validation using a model organism, which verifies PW-MCC as a reliable proxy for ground-truth recovery; and extending these findings to real-world LLM data, where high feature consistency strongly correlates with the semantic similarity of learned feature explanations. We call for a community-wide shift towards systematically measuring feature consistency to foster robust cumulative progress in MI.",
            "score": 4,
            "issue_id": 3968,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "8f3f187fdcf8d056",
            "authors": [
                "Xiangchen Song",
                "Aashiq Muhamed",
                "Yujia Zheng",
                "Lingjing Kong",
                "Zeyu Tang",
                "Mona T. Diab",
                "Virginia Smith",
                "Kun Zhang"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "MBZUAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20254.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#training",
                    "#math",
                    "#architecture"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² - ĞºĞ»ÑÑ‡ Ğº Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ² Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ°Ñ… Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ PW-MCC Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¼Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶Ğ¸Ğ¼Ğ° Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ ÑĞ¸Ğ»ÑŒĞ½Ğ¾ ĞºĞ¾Ñ€Ñ€ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸Ğ·Ğ¼ĞµÑ€ÑÑ‚ÑŒ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ° Ğ² Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Enhancing Interpretability through Feature Consistency in Sparse Autoencoders",
                    "desc": "This paper discusses the importance of feature consistency in Sparse Autoencoders (SAEs) for improving mechanistic interpretability (MI) of neural networks. It highlights that inconsistent features across different training runs can hinder the reliability of MI research. The authors propose the Pairwise Dictionary Mean Correlation Coefficient (PW-MCC) as a metric to measure feature consistency, showing that high consistency levels can be achieved with the right architectural choices. They advocate for a shift in the research community to prioritize and measure feature consistency to enhance the interpretability of neural networks."
                },
                "zh": {
                    "title": "ä¼˜å…ˆè€ƒè™‘ç‰¹å¾ä¸€è‡´æ€§ï¼Œæå‡ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§",
                    "desc": "ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰åœ¨æœºåˆ¶å¯è§£é‡Šæ€§ï¼ˆMIï¼‰ä¸­æ˜¯ä¸€ä¸ªé‡è¦å·¥å…·ï¼Œå¯ä»¥å°†ç¥ç»ç½‘ç»œçš„æ¿€æ´»åˆ†è§£ä¸ºå¯è§£é‡Šçš„ç‰¹å¾ã€‚ç„¶è€Œï¼Œä¸åŒè®­ç»ƒè¿è¡Œä¸­å­¦ä¹ åˆ°çš„SAEç‰¹å¾ä¸ä¸€è‡´ï¼Œå½±å“äº†MIç ”ç©¶çš„å¯é æ€§å’Œæ•ˆç‡ã€‚æœ¬æ–‡ä¸»å¼ åœ¨SAEä¸­ä¼˜å…ˆè€ƒè™‘ç‰¹å¾ä¸€è‡´æ€§ï¼Œä»¥ç¡®ä¿åœ¨ç‹¬ç«‹è¿è¡Œä¸­æ”¶æ•›åˆ°ç­‰æ•ˆç‰¹å¾é›†ã€‚æˆ‘ä»¬æå‡ºä½¿ç”¨æˆå¯¹å­—å…¸å‡å€¼ç›¸å…³ç³»æ•°ï¼ˆPW-MCCï¼‰ä½œä¸ºè¡¡é‡ä¸€è‡´æ€§çš„å®ç”¨æŒ‡æ ‡ï¼Œå¹¶å±•ç¤ºåœ¨é€‚å½“çš„æ¶æ„é€‰æ‹©ä¸‹å¯ä»¥å®ç°é«˜æ°´å¹³çš„ä¸€è‡´æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15804",
            "title": "STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs",
            "url": "https://huggingface.co/papers/2505.15804",
            "abstract": "STAR-R1, a novel RL framework with a fine-grained reward mechanism, enhances spatial reasoning in multimodal large language models by addressing limitations in traditional SFT and sparse-reward RL.  \t\t\t\t\tAI-generated summary \t\t\t\t Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across diverse tasks, yet they lag significantly behind humans in spatial reasoning. We investigate this gap through Transformation-Driven Visual Reasoning (TVR), a challenging task requiring identification of object transformations across images under varying viewpoints. While traditional Supervised Fine-Tuning (SFT) fails to generate coherent reasoning paths in cross-view settings, sparse-reward Reinforcement Learning (RL) suffers from inefficient exploration and slow convergence. To address these limitations, we propose STAR-R1, a novel framework that integrates a single-stage RL paradigm with a fine-grained reward mechanism tailored for TVR. Specifically, STAR-R1 rewards partial correctness while penalizing excessive enumeration and passive inaction, enabling efficient exploration and precise reasoning. Comprehensive evaluations demonstrate that STAR-R1 achieves state-of-the-art performance across all 11 metrics, outperforming SFT by 23% in cross-view scenarios. Further analysis reveals STAR-R1's anthropomorphic behavior and highlights its unique ability to compare all objects for improving spatial reasoning. Our work provides critical insights in advancing the research of MLLMs and reasoning models. The codes, model weights, and data will be publicly available at https://github.com/zongzhao23/STAR-R1.",
            "score": 4,
            "issue_id": 3978,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 Ğ¼Ğ°Ñ",
                "en": "May 21",
                "zh": "5æœˆ21æ—¥"
            },
            "hash": "4bdc30d74409ba0b",
            "authors": [
                "Zongzhao Li",
                "Zongyang Ma",
                "Mingze Li",
                "Songyou Li",
                "Yu Rong",
                "Tingyang Xu",
                "Ziqi Zhang",
                "Deli Zhao",
                "Wenbing Huang"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group, Hangzhou, China",
                "Gaoling School of Artificial Intelligence, Renmin University of China",
                "Hupan Lab, Hangzhou, China",
                "MAIS, Institute of Automation, Chinese Academy of Sciences"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15804.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#multimodal",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞŸÑ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğ¸ Ğ˜Ğ˜ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "STAR-R1 - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ. STAR-R1 Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ½Ğ° 23% Ğ² ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ñ€Ğ°ĞºÑƒÑ€ÑĞ°Ğ¼Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ°Ğ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¾Ğ¼Ğ¾Ñ€Ñ„Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¸ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "STAR-R1: Enhancing Spatial Reasoning in MLLMs with Fine-Grained Rewards",
                    "desc": "The paper introduces STAR-R1, a new reinforcement learning (RL) framework designed to improve spatial reasoning in multimodal large language models (MLLMs). It addresses the shortcomings of traditional supervised fine-tuning (SFT) and sparse-reward RL by implementing a fine-grained reward mechanism that encourages efficient exploration and precise reasoning. STAR-R1 rewards partial correctness and discourages excessive enumeration, leading to better performance in tasks requiring visual reasoning across different viewpoints. The results show that STAR-R1 significantly outperforms SFT, achieving state-of-the-art results in various metrics and enhancing the understanding of spatial relationships in MLLMs."
                },
                "zh": {
                    "title": "STAR-R1ï¼šæå‡ç©ºé—´æ¨ç†çš„æ–°æ¡†æ¶",
                    "desc": "STAR-R1æ˜¯ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé‡‡ç”¨ç»†ç²’åº¦å¥–åŠ±æœºåˆ¶ï¼Œæ—¨åœ¨æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚ä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒ(SFT)å’Œç¨€ç–å¥–åŠ±å¼ºåŒ–å­¦ä¹ (RL)åœ¨å¤„ç†ç©ºé—´æ¨ç†æ—¶å­˜åœ¨å±€é™æ€§ï¼Œå¯¼è‡´æ¨ç†è·¯å¾„ä¸è¿è´¯å’Œæ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚STAR-R1é€šè¿‡å¥–åŠ±éƒ¨åˆ†æ­£ç¡®æ€§å¹¶æƒ©ç½šè¿‡åº¦æšä¸¾å’Œè¢«åŠ¨ä¸ä½œä¸ºï¼Œä¿ƒè¿›äº†é«˜æ•ˆæ¢ç´¢å’Œç²¾ç¡®æ¨ç†ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒSTAR-R1åœ¨11ä¸ªæŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨è·¨è§†è§’åœºæ™¯ä¸­æ¯”SFTæé«˜äº†23%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20294",
            "title": "GLEAM: Learning Generalizable Exploration Policy for Active Mapping in\n  Complex 3D Indoor Scenes",
            "url": "https://huggingface.co/papers/2505.20294",
            "abstract": "A new benchmark and policy, GLEAM-Bench and GLEAM, improve the scalability and reliability of active mapping in complex environments through semantic representations and efficient exploration strategies.  \t\t\t\t\tAI-generated summary \t\t\t\t Generalizable active mapping in complex unknown environments remains a critical challenge for mobile robots. Existing methods, constrained by insufficient training data and conservative exploration strategies, exhibit limited generalizability across scenes with diverse layouts and complex connectivity. To enable scalable training and reliable evaluation, we introduce GLEAM-Bench, the first large-scale benchmark designed for generalizable active mapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets. Building upon this foundation, we propose GLEAM, a unified generalizable exploration policy for active mapping. Its superior generalizability comes mainly from our semantic representations, long-term navigable goals, and randomized strategies. It significantly outperforms state-of-the-art methods, achieving 66.50% coverage (+9.49%) with efficient trajectories and improved mapping accuracy on 128 unseen complex scenes. Project page: https://xiao-chen.tech/gleam/.",
            "score": 3,
            "issue_id": 3974,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "94f683ed3b0961cc",
            "authors": [
                "Xiao Chen",
                "Tai Wang",
                "Quanyi Li",
                "Tao Huang",
                "Jiangmiao Pang",
                "Tianfan Xue"
            ],
            "affiliations": [
                "Shanghai AI Laboratory",
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20294.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#transfer_learning",
                    "#3d",
                    "#robotics",
                    "#synthetic"
                ],
                "emoji": "ğŸ—ºï¸",
                "ru": {
                    "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ ĞºĞ°Ñ€Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸: GLEAM Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ñ‹",
                    "desc": "GLEAM-Bench Ğ¸ GLEAM - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ°Ñ€Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ€ĞµĞ´Ğ°Ñ…. GLEAM-Bench Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ ĞºÑ€ÑƒĞ¿Ğ½Ğ¾Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ñ 1152 Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ 3D-ÑÑ†ĞµĞ½Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ°Ñ€Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. GLEAM - ÑÑ‚Ğ¾ ÑƒĞ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ñ†ĞµĞ»Ğ¸. Ğ­Ñ‚Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ 66.50% Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ (+9.49%) Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ñ€Ğ°ĞµĞºÑ‚Ğ¾Ñ€Ğ¸ÑĞ¼Ğ¸ Ğ½Ğ° 128 Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ…."
                },
                "en": {
                    "title": "Unlocking Generalizable Active Mapping with GLEAM",
                    "desc": "This paper presents GLEAM-Bench, a new benchmark for evaluating active mapping in complex environments, featuring 1,152 diverse 3D scenes. It addresses the limitations of existing methods that struggle with generalizability due to lack of training data and conservative exploration. The authors introduce GLEAM, a novel exploration policy that utilizes semantic representations and long-term goals to enhance mapping efficiency. GLEAM demonstrates significant improvements over current techniques, achieving higher coverage and mapping accuracy in previously unseen environments."
                },
                "zh": {
                    "title": "æå‡ç§»åŠ¨æœºå™¨äººä¸»åŠ¨æ˜ å°„çš„é€šç”¨æ€§ä¸å¯é æ€§",
                    "desc": "æœ¬è®ºæ–‡æå‡ºäº†GLEAM-Benchå’ŒGLEAMï¼Œæ—¨åœ¨æé«˜ç§»åŠ¨æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„ä¸»åŠ¨æ˜ å°„èƒ½åŠ›ã€‚GLEAM-Benchæ˜¯é¦–ä¸ªå¤§è§„æ¨¡åŸºå‡†ï¼ŒåŒ…å«1152ä¸ªå¤šæ ·åŒ–çš„3Dåœºæ™¯ï¼Œæ”¯æŒå¯æ‰©å±•çš„è®­ç»ƒå’Œå¯é çš„è¯„ä¼°ã€‚GLEAMåˆ™æ˜¯ä¸€ç§ç»Ÿä¸€çš„ä¸»åŠ¨æ˜ å°„æ¢ç´¢ç­–ç•¥ï¼Œåˆ©ç”¨è¯­ä¹‰è¡¨ç¤ºå’Œé•¿æœŸå¯å¯¼èˆªç›®æ ‡ï¼Œæ˜¾è‘—æå‡äº†æ–¹æ³•çš„é€šç”¨æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGLEAMåœ¨128ä¸ªæœªè§å¤æ‚åœºæ™¯ä¸­ï¼Œè¦†ç›–ç‡è¾¾åˆ°66.50%ï¼Œæ¯”ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº†9.49%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19630",
            "title": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning\n  System for Multi-Turn Clinical Dialogue",
            "url": "https://huggingface.co/papers/2505.19630",
            "abstract": "Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Existing systems rely on a one-way information transmission mode where patients must fully describe their symptoms in a single round, leading to nonspecific diagnostic recommendations when complaints are vague. Traditional multi-turn dialogue methods based on supervised learning are constrained by static data-driven paradigms, lacking generalizability and struggling to intelligently extract key clinical information. To address these limitations, we propose DoctorAgent-RL, a reinforcement learning (RL)-based multi-agent collaborative framework that models medical consultations as a dynamic decision-making process under uncertainty. The doctor agent continuously optimizes its questioning strategy within the RL framework through multi-turn interactions with the patient agent, dynamically adjusting its information-gathering path based on comprehensive rewards from the Consultation Evaluator. This RL fine-tuning mechanism enables LLMs to autonomously develop interaction strategies aligned with clinical reasoning logic, rather than superficially imitating patterns in existing dialogue data. Notably, we constructed MTMedDialog, the first English multi-turn medical consultation dataset capable of simulating patient interactions. Experiments demonstrate that DoctorAgent-RL outperforms existing models in both multi-turn reasoning capability and final diagnostic performance, demonstrating practical value in assisting clinical consultations. https://github.com/JarvisUSTC/DoctorAgent-RL",
            "score": 3,
            "issue_id": 3967,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "ab312c010a92062f",
            "authors": [
                "Yichun Feng",
                "Jiawei Wang",
                "Lu Zhou",
                "Yixue Li"
            ],
            "affiliations": [
                "Department of EEIS, University of Science and Technology of China",
                "Guangzhou National Laboratory",
                "School of Advanced Interdisciplinary Sciences, University of Chinese Academy of Sciences",
                "Shanghai Institute of Nutrition and Health, Chinese Academy of Sciences"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19630.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#reasoning",
                    "#science",
                    "#healthcare",
                    "#dataset",
                    "#games",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "ğŸ©º",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¾ĞºÑ‚Ğ¾Ñ€: Ğ˜Ğ˜ ÑƒÑ‡Ğ¸Ñ‚ÑÑ Ğ²ĞµÑÑ‚Ğ¸ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³ Ñ Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ DoctorAgent-RL - ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ğ¹. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´, Ğ³Ğ´Ğµ Ğ°Ğ³ĞµĞ½Ñ‚-Ğ²Ñ€Ğ°Ñ‡ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°ĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ², Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ±Ğ¾Ñ€ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ DoctorAgent-RL Ğ½Ğ°Ğ´ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ… Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸."
                },
                "en": {
                    "title": "Revolutionizing Clinical Consultations with Reinforcement Learning",
                    "desc": "This paper introduces DoctorAgent-RL, a novel framework that enhances biomedical question answering by using reinforcement learning (RL) to improve multi-turn medical consultations. Unlike traditional systems that rely on static data, DoctorAgent-RL allows a doctor agent to adaptively optimize its questioning strategy through dynamic interactions with a patient agent. The framework is designed to intelligently extract relevant clinical information, addressing the limitations of vague patient descriptions. Additionally, the authors present MTMedDialog, a new dataset for simulating patient interactions, which supports the framework's effectiveness in real-world clinical settings."
                },
                "zh": {
                    "title": "æ™ºèƒ½åŒ»ç–—å’¨è¯¢çš„æ–°çªç ´",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿç‰©åŒ»å­¦é—®ç­”é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å®é™…ä¸´åºŠå’¨è¯¢ä¸­çš„åº”ç”¨ä»é¢ä¸´æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç°æœ‰ç³»ç»Ÿä¾èµ–å•å‘ä¿¡æ¯ä¼ é€’æ¨¡å¼ï¼Œæ‚£è€…å¿…é¡»åœ¨ä¸€æ¬¡æ€§æè¿°ç—‡çŠ¶ï¼Œå¯¼è‡´æ¨¡ç³ŠæŠ•è¯‰æ—¶çš„è¯Šæ–­å»ºè®®ä¸å¤Ÿå…·ä½“ã€‚ä¼ ç»Ÿçš„åŸºäºç›‘ç£å­¦ä¹ çš„å¤šè½®å¯¹è¯æ–¹æ³•å—é™äºé™æ€æ•°æ®é©±åŠ¨çš„èŒƒå¼ï¼Œç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼Œéš¾ä»¥æ™ºèƒ½æå–å…³é”®ä¸´åºŠä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DoctorAgent-RLï¼Œä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼Œå°†åŒ»ç–—å’¨è¯¢å»ºæ¨¡ä¸ºä¸ç¡®å®šæ€§ä¸‹çš„åŠ¨æ€å†³ç­–è¿‡ç¨‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19084",
            "title": "Jodi: Unification of Visual Generation and Understanding via Joint\n  Modeling",
            "url": "https://huggingface.co/papers/2505.19084",
            "abstract": "Jodi, a diffusion framework using a linear diffusion transformer and role switch mechanism, unifies visual generation and understanding, performing joint, controllable, and perceptual tasks effectively across multiple visual domains.  \t\t\t\t\tAI-generated summary \t\t\t\t Visual generation and understanding are two deeply interconnected aspects of human intelligence, yet they have been traditionally treated as separate tasks in machine learning. In this paper, we propose Jodi, a diffusion framework that unifies visual generation and understanding by jointly modeling the image domain and multiple label domains. Specifically, Jodi is built upon a linear diffusion transformer along with a role switch mechanism, which enables it to perform three particular types of tasks: (1) joint generation, where the model simultaneously generates images and multiple labels; (2) controllable generation, where images are generated conditioned on any combination of labels; and (3) image perception, where multiple labels can be predicted at once from a given image. Furthermore, we present the Joint-1.6M dataset, which contains 200,000 high-quality images collected from public sources, automatic labels for 7 visual domains, and LLM-generated captions. Extensive experiments demonstrate that Jodi excels in both generation and understanding tasks and exhibits strong extensibility to a wider range of visual domains. Code is available at https://github.com/VIPL-GENUN/Jodi.",
            "score": 3,
            "issue_id": 3974,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "a90dad40e2c803ae",
            "authors": [
                "Yifeng Xu",
                "Zhenliang He",
                "Meina Kan",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "affiliations": [
                "State Key Lab of AI Safety, Institute of Computing Technology, CAS, China",
                "University of Chinese Academy of Sciences, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19084.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#diffusion",
                    "#cv",
                    "#multimodal",
                    "#open_source"
                ],
                "emoji": "ğŸ¨",
                "ru": {
                    "title": "Jodi: Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
                    "desc": "Jodi - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸, Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑÑÑ‰Ğ¸Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€ Ğ¸ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ñ€Ğ¾Ğ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ñ‹Ñ…, ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¸ Ğ¿ĞµÑ€Ñ†ĞµĞ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. Jodi ÑĞ¿Ğ¾ÑĞ¾Ğ±ĞµĞ½ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚ĞºĞ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ¼ĞµÑ‚ĞºĞ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Jodi Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ¾Ğ¼ĞµĞ½Ğ°Ñ…."
                },
                "en": {
                    "title": "Unifying Visual Generation and Understanding with Jodi",
                    "desc": "Jodi is a novel diffusion framework that integrates visual generation and understanding into a single model. It utilizes a linear diffusion transformer and a role switch mechanism to perform tasks such as joint generation of images and labels, controllable generation based on label conditions, and simultaneous image perception. The framework is trained on the Joint-1.6M dataset, which includes a diverse set of images and labels across multiple visual domains. Experimental results show that Jodi effectively handles both generation and understanding tasks, demonstrating its versatility in various visual applications."
                },
                "zh": {
                    "title": "Jodiï¼šç»Ÿä¸€è§†è§‰ç”Ÿæˆä¸ç†è§£çš„åˆ›æ–°æ¡†æ¶",
                    "desc": "Jodiæ˜¯ä¸€ä¸ªæ‰©æ•£æ¡†æ¶ï¼Œç»“åˆäº†çº¿æ€§æ‰©æ•£å˜æ¢å™¨å’Œè§’è‰²åˆ‡æ¢æœºåˆ¶ï¼Œæ—¨åœ¨ç»Ÿä¸€è§†è§‰ç”Ÿæˆå’Œç†è§£ã€‚å®ƒé€šè¿‡è”åˆå»ºæ¨¡å›¾åƒåŸŸå’Œå¤šä¸ªæ ‡ç­¾åŸŸï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æ‰§è¡Œç”Ÿæˆã€å¯æ§å’Œæ„ŸçŸ¥ç­‰ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼ŒJodiå¯ä»¥åŒæ—¶ç”Ÿæˆå›¾åƒå’Œå¤šä¸ªæ ‡ç­¾ï¼ŒåŸºäºæ ‡ç­¾ç»„åˆç”Ÿæˆå›¾åƒï¼Œä»¥åŠä»ç»™å®šå›¾åƒä¸­é¢„æµ‹å¤šä¸ªæ ‡ç­¾ã€‚æ­¤å¤–ï¼ŒJodiè¿˜å¼•å…¥äº†Joint-1.6Mæ•°æ®é›†ï¼ŒåŒ…å«20ä¸‡å¼ é«˜è´¨é‡å›¾åƒå’Œ7ä¸ªè§†è§‰åŸŸçš„è‡ªåŠ¨æ ‡ç­¾ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19056",
            "title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks",
            "url": "https://huggingface.co/papers/2505.19056",
            "abstract": "Modifying models to generate justified refusals through fine-tuning on an extended-refusal dataset mitigates ablation attacks while maintaining high refusal rates and general performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) are typically aligned to comply with safety guidelines by refusing harmful instructions. A recent attack, termed abliteration, isolates and suppresses the single latent direction most responsible for refusal behavior, enabling the model to generate unethical content. We propose a defense that modifies how models generate refusals. We construct an extended-refusal dataset that contains harmful prompts with a full response that justifies the reason for refusal. We then fine-tune Llama-2-7B-Chat and Qwen2.5-Instruct (1.5B and 3B parameters) on our extended-refusal dataset, and evaluate the resulting systems on a set of harmful prompts. In our experiments, extended-refusal models maintain high refusal rates, dropping at most by 10%, whereas baseline models' refusal rates drop by 70-80% after abliteration. A broad evaluation of safety and utility shows that extended-refusal fine-tuning neutralizes the abliteration attack while preserving general performance.",
            "score": 3,
            "issue_id": 3974,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "2728a5086c10e308",
            "authors": [
                "Harethah Abu Shairah",
                "Hasan Abed Al Kader Hammoud",
                "Bernard Ghanem",
                "George Turkiyyah"
            ],
            "affiliations": [
                "King Abdullah University of Science and Technology (KAUST)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19056.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#security",
                    "#dataset",
                    "#alignment",
                    "#ethics"
                ],
                "emoji": "ğŸ›¡ï¸",
                "ru": {
                    "title": "Ğ£ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ±Ğ°Ñ€ÑŒĞµÑ€Ğ¾Ğ² Ğ² Ğ˜Ğ˜ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚ĞºĞ°Ğ·Ñ‹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ»Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾Ñ‚ Ğ°Ñ‚Ğ°Ğº, Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ¾Ğ² Ğ¾Ñ‚ĞºĞ°Ğ·Ğ° Ğ¾Ñ‚ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹. ĞĞ½Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ»Ğ¸ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°Ğ¼Ğ¸ Ğ¸ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ğ½Ğ° Ğ½ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Llama-2 Ğ¸ Qwen2. ĞœĞ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ¾Ğ² Ğ´Ğ°Ğ¶Ğµ Ğ¿Ğ¾ÑĞ»Ğµ Ğ°Ñ‚Ğ°Ğº, Ğ² Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ²ĞµÑ€ÑĞ¸Ğ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ Ğ°Ñ‚Ğ°ĞºĞ¸ Ğ±ĞµĞ· ÑƒÑ‰ĞµÑ€Ğ±Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "Strengthening Refusal Mechanisms in LLMs Against Attacks",
                    "desc": "This paper addresses the vulnerability of large language models (LLMs) to a specific attack called abliteration, which reduces their ability to refuse harmful instructions. The authors propose a solution by creating an extended-refusal dataset that includes harmful prompts along with justifications for refusal. They fine-tune existing models, Llama-2-7B-Chat and Qwen2.5-Instruct, on this dataset to enhance their refusal capabilities. The results show that these modified models maintain high refusal rates even under attack, significantly outperforming baseline models that suffer drastic declines in refusal performance."
                },
                "zh": {
                    "title": "é€šè¿‡æ‰©å±•æ‹’ç»å¾®è°ƒæå‡æ¨¡å‹å®‰å…¨æ€§",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡åœ¨æ‰©å±•æ‹’ç»æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒæ¥ç”Ÿæˆåˆç†æ‹’ç»çš„æ¨¡å‹ä¿®æ”¹æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡è½»æ¶ˆèæ”»å‡»ï¼ŒåŒæ—¶ä¿æŒé«˜æ‹’ç»ç‡å’Œè‰¯å¥½çš„æ•´ä½“æ€§èƒ½ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ‰©å±•æ‹’ç»æ•°æ®é›†ï¼ŒåŒ…å«æœ‰å®³æç¤ºåŠå…¶æ‹’ç»ç†ç”±çš„å®Œæ•´å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡æ‰©å±•æ‹’ç»å¾®è°ƒçš„æ¨¡å‹åœ¨é¢å¯¹æœ‰å®³æç¤ºæ—¶ï¼Œæ‹’ç»ç‡ä»…ä¸‹é™æœ€å¤š10%ï¼Œè€ŒåŸºçº¿æ¨¡å‹çš„æ‹’ç»ç‡ä¸‹é™äº†70-80%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18926",
            "title": "Hybrid Neural-MPM for Interactive Fluid Simulations in Real-Time",
            "url": "https://huggingface.co/papers/2505.18926",
            "abstract": "A hybrid neural physics system with diffusion-based control achieves real-time, interactive fluid simulations with low latency and high fidelity.  \t\t\t\t\tAI-generated summary \t\t\t\t We propose a neural physics system for real-time, interactive fluid simulations. Traditional physics-based methods, while accurate, are computationally intensive and suffer from latency issues. Recent machine-learning methods reduce computational costs while preserving fidelity; yet most still fail to satisfy the latency constraints for real-time use and lack support for interactive applications. To bridge this gap, we introduce a novel hybrid method that integrates numerical simulation, neural physics, and generative control. Our neural physics jointly pursues low-latency simulation and high physical fidelity by employing a fallback safeguard to classical numerical solvers. Furthermore, we develop a diffusion-based controller that is trained using a reverse modeling strategy to generate external dynamic force fields for fluid manipulation. Our system demonstrates robust performance across diverse 2D/3D scenarios, material types, and obstacle interactions, achieving real-time simulations at high frame rates (11~29% latency) while enabling fluid control guided by user-friendly freehand sketches. We present a significant step towards practical, controllable, and physically plausible fluid simulations for real-time interactive applications. We promise to release both models and data upon acceptance.",
            "score": 3,
            "issue_id": 3983,
            "pub_date": "2025-05-25",
            "pub_date_card": {
                "ru": "25 Ğ¼Ğ°Ñ",
                "en": "May 25",
                "zh": "5æœˆ25æ—¥"
            },
            "hash": "cf71badcb13cd468",
            "authors": [
                "Jingxuan Xu",
                "Hong Huang",
                "Chuhang Zou",
                "Manolis Savva",
                "Yunchao Wei",
                "Wuyang Chen"
            ],
            "affiliations": [
                "Beijing Jiaotong University",
                "Meta Reality Labs",
                "Simon Fraser University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18926.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#3d",
                    "#agents",
                    "#diffusion",
                    "#open_source",
                    "#optimization"
                ],
                "emoji": "ğŸ’§",
                "ru": {
                    "title": "Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¶Ğ¸Ğ´ĞºĞ¾ÑÑ‚ĞµĞ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                    "desc": "ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½ÑƒÑ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¶Ğ¸Ğ´ĞºĞ¾ÑÑ‚ĞµĞ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ¾Ñ‡ĞµÑ‚Ğ°ĞµÑ‚ Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½ÑƒÑ Ñ„Ğ¸Ğ·Ğ¸ĞºÑƒ Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ. ĞšĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ¹ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒÑ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ»ĞµÑ€, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¸Ğ»Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… 2D/3D ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ… Ñ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ¹ Ñ„Ğ¸Ğ·Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ."
                },
                "en": {
                    "title": "Real-Time Fluid Simulations with Neural Physics and Diffusion Control",
                    "desc": "This paper presents a hybrid neural physics system designed for real-time fluid simulations that are both interactive and high-fidelity. Traditional methods are often slow and computationally heavy, while recent machine learning approaches can reduce costs but struggle with latency. The proposed system combines numerical simulations with neural physics and a diffusion-based control mechanism to achieve low-latency performance. It allows users to manipulate fluid dynamics through intuitive sketches, making it suitable for various applications in 2D and 3D environments."
                },
                "zh": {
                    "title": "å®æ—¶æµä½“æ¨¡æ‹Ÿçš„æ–°çªç ´",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆç¥ç»ç‰©ç†ç³»ç»Ÿï¼Œç”¨äºå®æ—¶äº¤äº’å¼æµä½“æ¨¡æ‹Ÿã€‚ä¼ ç»Ÿçš„ç‰©ç†æ–¹æ³•è™½ç„¶å‡†ç¡®ï¼Œä½†è®¡ç®—é‡å¤§ï¼Œå»¶è¿Ÿé«˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†æ•°å€¼æ¨¡æ‹Ÿã€ç¥ç»ç‰©ç†å’Œç”Ÿæˆæ§åˆ¶ï¼Œæ—¨åœ¨å®ç°ä½å»¶è¿Ÿå’Œé«˜ç‰©ç†çœŸå®æ„Ÿçš„æµä½“æ¨¡æ‹Ÿã€‚é€šè¿‡ä½¿ç”¨æ‰©æ•£æ§åˆ¶å™¨ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤šç§åœºæ™¯ä¸­å®ç°é«˜å¸§ç‡çš„æµä½“æ§åˆ¶ï¼Œæ»¡è¶³å®æ—¶äº¤äº’çš„éœ€æ±‚ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18323",
            "title": "Architectural Backdoors for Within-Batch Data Stealing and Model\n  Inference Manipulation",
            "url": "https://huggingface.co/papers/2505.18323",
            "abstract": "For nearly a decade the academic community has investigated backdoors in neural networks, primarily focusing on classification tasks where adversaries manipulate the model prediction. While demonstrably malicious, the immediate real-world impact of such prediction-altering attacks has remained unclear. In this paper we introduce a novel and significantly more potent class of backdoors that builds upon recent advancements in architectural backdoors. We demonstrate how these backdoors can be specifically engineered to exploit batched inference, a common technique for hardware utilization, enabling large-scale user data manipulation and theft. By targeting the batching process, these architectural backdoors facilitate information leakage between concurrent user requests and allow attackers to fully control model responses directed at other users within the same batch. In other words, an attacker who can change the model architecture can set and steal model inputs and outputs of other users within the same batch. We show that such attacks are not only feasible but also alarmingly effective, can be readily injected into prevalent model architectures, and represent a truly malicious threat to user privacy and system integrity. Critically, to counteract this new class of vulnerabilities, we propose a deterministic mitigation strategy that provides formal guarantees against this new attack vector, unlike prior work that relied on Large Language Models to find the backdoors. Our mitigation strategy employs a novel Information Flow Control mechanism that analyzes the model graph and proves non-interference between different user inputs within the same batch. Using our mitigation strategy we perform a large scale analysis of models hosted through Hugging Face and find over 200 models that introduce (unintended) information leakage between batch entries due to the use of dynamic quantization.",
            "score": 3,
            "issue_id": 3973,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "10dd310ff67b7a4d",
            "authors": [
                "Nicolas KÃ¼chler",
                "Ivan Petrov",
                "Conrad Grobler",
                "Ilia Shumailov"
            ],
            "affiliations": [
                "ETH Zurich",
                "Google DeepMind"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18323.jpg",
            "data": {
                "categories": [
                    "#leakage",
                    "#inference",
                    "#security",
                    "#architecture"
                ],
                "emoji": "ğŸ•µï¸",
                "ru": {
                    "title": "ĞĞ¾Ğ²Ñ‹Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ğ±ÑĞºĞ´Ğ¾Ñ€Ñ‹: ÑĞºÑ€Ñ‹Ñ‚Ğ°Ñ ÑƒĞ³Ñ€Ğ¾Ğ·Ğ° Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¼Ñƒ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñƒ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ±ÑĞºĞ´Ğ¾Ñ€Ğ¾Ğ² Ğ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ÑÑ…, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°. Ğ­Ñ‚Ğ¸ Ğ±ÑĞºĞ´Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‚ Ğ·Ğ»Ğ¾ÑƒĞ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ğ¸ĞºĞ°Ğ¼ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ¸ ĞºÑ€Ğ°ÑÑ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ°ĞºĞ¸Ñ… Ğ°Ñ‚Ğ°Ğº Ğ¸ Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğº Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ ÑÑ‚Ğ¸Ğ¼ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ÑĞ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ ÑĞ¼ÑĞ³Ñ‡ĞµĞ½Ğ¸Ñ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ³Ñ€Ğ°Ñ„Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğµ Ğ½ĞµĞ²Ğ¼ĞµÑˆĞ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ² Ğ¿Ğ°ĞºĞµÑ‚Ğµ."
                },
                "en": {
                    "title": "Exposing and Mitigating Architectural Backdoors in Neural Network Batching",
                    "desc": "This paper explores a new type of backdoor attack in neural networks that targets the batching process during inference, allowing attackers to manipulate and steal user data. Unlike traditional backdoor attacks that focus on altering model predictions, this method exploits architectural vulnerabilities to leak information between concurrent user requests. The authors demonstrate that these attacks can be easily integrated into existing model architectures, posing a significant threat to user privacy and system integrity. To combat this issue, they propose a deterministic mitigation strategy using Information Flow Control to ensure that user inputs remain isolated within the same batch, providing formal guarantees against such attacks."
                },
                "zh": {
                    "title": "æ­ç¤ºç¥ç»ç½‘ç»œä¸­çš„æ–°å‹åé—¨æ”»å‡»ä¸é˜²æŠ¤ç­–ç•¥",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†ä¸€ç§æ–°å‹çš„ç¥ç»ç½‘ç»œåé—¨æ”»å‡»ï¼Œç‰¹åˆ«é’ˆå¯¹æ‰¹é‡æ¨ç†æŠ€æœ¯ã€‚è¿™ç§æ”»å‡»å¯ä»¥åœ¨åŒä¸€æ‰¹æ¬¡ä¸­æ“æ§ç”¨æˆ·æ•°æ®ï¼Œå¯¼è‡´ä¿¡æ¯æ³„éœ²å’Œæ¨¡å‹å“åº”çš„æ§åˆ¶ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç¡®å®šæ€§çš„ç¼“è§£ç­–ç•¥ï¼Œé€šè¿‡ä¿¡æ¯æµæ§åˆ¶æœºåˆ¶ï¼Œç¡®ä¿ä¸åŒç”¨æˆ·è¾“å…¥ä¹‹é—´çš„éå¹²æ‰°æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ”»å‡»ä¸ä»…å¯è¡Œä¸”æœ‰æ•ˆï¼Œå¹¶ä¸”åœ¨ç°æœ‰æ¨¡å‹æ¶æ„ä¸­æ™®éå­˜åœ¨ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18116",
            "title": "Bridging Supervised Learning and Reinforcement Learning in Math\n  Reasoning",
            "url": "https://huggingface.co/papers/2505.18116",
            "abstract": "Negative-aware Fine-Tuning (NFT) enhances LLMs' math abilities using supervised learning with negative feedback, achieving performance comparable to RL methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement Learning (RL) has played a central role in the recent surge of LLMs' math abilities by enabling self-improvement through binary verifier signals. In contrast, Supervised Learning (SL) is rarely considered for such verification-driven training, largely due to its heavy reliance on reference answers and inability to reflect on mistakes. In this work, we challenge the prevailing notion that self-improvement is exclusive to RL and propose Negative-aware Fine-Tuning (NFT) -- a supervised approach that enables LLMs to reflect on their failures and improve autonomously with no external teachers. In online training, instead of throwing away self-generated negative answers, NFT constructs an implicit negative policy to model them. This implicit policy is parameterized with the same positive LLM we target to optimize on positive data, enabling direct policy optimization on all LLMs' generations. We conduct experiments on 7B and 32B models in math reasoning tasks. Results consistently show that through the additional leverage of negative feedback, NFT significantly improves over SL baselines like Rejection sampling Fine-Tuning, matching or even surpassing leading RL algorithms like GRPO and DAPO. Furthermore, we demonstrate that NFT and GRPO are actually equivalent in strict-on-policy training, even though they originate from entirely different theoretical foundations. Our experiments and theoretical findings bridge the gap between SL and RL methods in binary-feedback learning systems.",
            "score": 3,
            "issue_id": 3987,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "7810c6a91231902d",
            "authors": [
                "Huayu Chen",
                "Kaiwen Zheng",
                "Qinsheng Zhang",
                "Ganqu Cui",
                "Yin Cui",
                "Haotian Ye",
                "Tsung-Yi Lin",
                "Ming-Yu Liu",
                "Jun Zhu",
                "Haoxiang Wang"
            ],
            "affiliations": [
                "NVIDIA",
                "Stanford University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18116.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#training",
                    "#math",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ñ‡Ğ¸Ğ¼ÑÑ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ…: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ - Negative-aware Fine-Tuning (NFT). NFT Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° ÑĞ²Ğ¾Ğ¸Ñ… Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ… Ğ±ĞµĞ· Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ NFT Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¸ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼ Ğ¿Ğ¾ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ NFT Ğ¸ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ñ€Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ…."
                },
                "en": {
                    "title": "Unlocking LLMs' Math Skills with Negative Feedback",
                    "desc": "This paper introduces Negative-aware Fine-Tuning (NFT), a novel supervised learning method that enhances the mathematical abilities of large language models (LLMs) by incorporating negative feedback. Unlike traditional reinforcement learning (RL) approaches that rely on positive reinforcement, NFT allows LLMs to learn from their mistakes by modeling negative outputs as part of the training process. The authors demonstrate that NFT can achieve performance levels comparable to leading RL methods while using a supervised framework, thus challenging the belief that self-improvement is exclusive to RL. Through experiments on various model sizes, the results show that NFT not only improves upon existing supervised learning techniques but also aligns closely with RL methods in specific training scenarios."
                },
                "zh": {
                    "title": "è´Ÿåé¦ˆå¾®è°ƒï¼šæå‡LLMsæ•°å­¦èƒ½åŠ›çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œç§°ä¸ºè´Ÿåé¦ˆå¾®è°ƒï¼ˆNFTï¼‰ï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ•°å­¦èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•ä¸åŒï¼ŒNFTåˆ©ç”¨è‡ªæˆ‘ç”Ÿæˆçš„è´Ÿé¢ç­”æ¡ˆè¿›è¡Œè®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåæ€é”™è¯¯å¹¶è‡ªä¸»æ”¹è¿›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNFTåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ åŸºçº¿ï¼Œç”šè‡³ä¸é¢†å…ˆçš„RLç®—æ³•ç›¸åª²ç¾ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼ŒNFTå’ŒRLä¹‹é—´çš„å·®è·å¾—ä»¥ç¼©å°ï¼Œå±•ç¤ºäº†è´Ÿåé¦ˆåœ¨å­¦ä¹ ç³»ç»Ÿä¸­çš„é‡è¦æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16984",
            "title": "UFT: Unifying Supervised and Reinforcement Fine-Tuning",
            "url": "https://huggingface.co/papers/2505.16984",
            "abstract": "A new post-training method, Unified Fine-Tuning (UFT), improves upon supervised and reinforcement fine-tuning for large language models by combining their benefits, achieving better generalization and faster convergence.  \t\t\t\t\tAI-generated summary \t\t\t\t Post-training has demonstrated its importance in enhancing the reasoning capabilities of large language models (LLMs). The primary post-training methods can be categorized into supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). SFT is efficient and well-suited for small language models, but it may lead to overfitting and limit the reasoning abilities of larger models. In contrast, RFT generally yields better generalization but depends heavily on the strength of the base model. To address the limitations of SFT and RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm that unifies SFT and RFT into a single, integrated process. UFT enables the model to effectively explore solutions while incorporating informative supervision signals, bridging the gap between memorizing and thinking underlying existing methods. Notably, UFT outperforms both SFT and RFT in general, regardless of model sizes. Furthermore, we theoretically prove that UFT breaks RFT's inherent exponential sample complexity bottleneck, showing for the first time that unified training can exponentially accelerate convergence on long-horizon reasoning tasks.",
            "score": 3,
            "issue_id": 3980,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "c20894984fdad880",
            "authors": [
                "Mingyang Liu",
                "Gabriele Farina",
                "Asuman Ozdaglar"
            ],
            "affiliations": [
                "LIDS, EECS, Massachusetts Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16984.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "UFT: ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ¸Ğ· SFT Ğ¸ RFT Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾ÑÑ‚-Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ - Unified Fine-Tuning (UFT). ĞĞ½ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° supervised fine-tuning (SFT) Ğ¸ reinforcement fine-tuning (RFT), ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¾Ğ±Ğ¾Ğ±Ñ‰Ğ°ÑÑ‰ÑƒÑ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ÑƒÑĞºĞ¾Ñ€ÑÑ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ. UFT Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ, Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ñ‡Ñ‚Ğ¾ UFT Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ²Ğ°ĞµÑ‚ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ RFT Ğ¿Ğ¾ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸, ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ ÑƒÑĞºĞ¾Ñ€ÑÑ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ¾Ğ¼."
                },
                "en": {
                    "title": "Unified Fine-Tuning: Merging Supervised and Reinforcement Learning for Better AI",
                    "desc": "Unified Fine-Tuning (UFT) is a new method that enhances the performance of large language models by merging the strengths of supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). This approach allows models to generalize better and converge faster by effectively balancing the need for informative supervision with the exploration of solutions. UFT addresses the overfitting issues seen in SFT and the dependency on strong base models in RFT, making it suitable for various model sizes. The method also theoretically demonstrates a significant improvement in convergence speed for complex reasoning tasks, breaking previous limitations of RFT."
                },
                "zh": {
                    "title": "ç»Ÿä¸€å¾®è°ƒï¼šæå‡è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä¸æ•ˆç‡",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åè®­ç»ƒæ–¹æ³•ï¼Œç§°ä¸ºç»Ÿä¸€å¾®è°ƒï¼ˆUFTï¼‰ï¼Œæ—¨åœ¨ç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰çš„ä¼˜ç‚¹ï¼Œä»è€Œæé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ”¶æ•›é€Ÿåº¦ã€‚SFTé€‚åˆå°å‹è¯­è¨€æ¨¡å‹ï¼Œä½†å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œè€ŒRFTåˆ™åœ¨å¤§å‹æ¨¡å‹ä¸­è¡¨ç°æ›´å¥½ï¼Œä½†ä¾èµ–äºåŸºç¡€æ¨¡å‹çš„å¼ºåº¦ã€‚UFTé€šè¿‡å°†SFTå’ŒRFTæ•´åˆä¸ºä¸€ä¸ªè¿‡ç¨‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ¢ç´¢è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶å¼•å…¥æœ‰ç”¨çš„ç›‘ç£ä¿¡å·ï¼Œå¼¥è¡¥äº†ç°æœ‰æ–¹æ³•ä¸­è®°å¿†ä¸æ€è€ƒä¹‹é—´çš„å·®è·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUFTåœ¨å„ç§æ¨¡å‹è§„æ¨¡ä¸‹å‡ä¼˜äºSFTå’ŒRFTï¼Œå¹¶ä¸”ç†è®ºè¯æ˜UFTæ‰“ç ´äº†RFTå›ºæœ‰çš„æ ·æœ¬å¤æ‚åº¦ç“¶é¢ˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16886",
            "title": "Don't \"Overthink\" Passage Reranking: Is Reasoning Truly Necessary?",
            "url": "https://huggingface.co/papers/2505.16886",
            "abstract": "With the growing success of reasoning models across complex natural language tasks, researchers in the Information Retrieval (IR) community have begun exploring how similar reasoning capabilities can be integrated into passage rerankers built on Large Language Models (LLMs). These methods typically employ an LLM to produce an explicit, step-by-step reasoning process before arriving at a final relevance prediction. But, does reasoning actually improve reranking accuracy? In this paper, we dive deeper into this question, studying the impact of the reasoning process by comparing reasoning-based pointwise rerankers (ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under identical training conditions, and observe that StandardRR generally outperforms ReasonRR. Building on this observation, we then study the importance of reasoning to ReasonRR by disabling its reasoning process (ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more effective than ReasonRR. Examining the cause of this result, our findings reveal that reasoning-based rerankers are limited by the LLM's reasoning process, which pushes it toward polarized relevance scores and thus fails to consider the partial relevance of passages, a key factor for the accuracy of pointwise rerankers.",
            "score": 3,
            "issue_id": 3978,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "42bc690254efb192",
            "authors": [
                "Nour Jedidi",
                "Yung-Sung Chuang",
                "James Glass",
                "Jimmy Lin"
            ],
            "affiliations": [
                "MIT Lincoln Laboratory",
                "Massachusetts Institute of Technology",
                "University of Waterloo"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16886.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#multimodal",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "ğŸ¤”",
                "ru": {
                    "title": "Ğ Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸: Ğ½Ğµ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸Ğ·ÑƒÑ‡Ğ°ÑÑ‚ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°ÑÑĞ°Ğ¶ĞµĞ¹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ¾Ğ² Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸ (ReasonRR) Ğ¸ Ğ±ĞµĞ· Ğ½Ğ¸Ñ… (StandardRR) Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ StandardRR Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ReasonRR. Ğ”Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² ReasonRR (ReasonRR-NoReason) Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸. ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ LLM ÑĞºĞ»Ğ¾Ğ½ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğº Ğ¿Ğ¾Ğ»ÑÑ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¾Ñ†ĞµĞ½ĞºĞ°Ğ¼ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒÑ Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½ÑƒÑ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ°ÑÑĞ°Ğ¶ĞµĞ¹."
                },
                "en": {
                    "title": "Reasoning in Rerankers: Less is More!",
                    "desc": "This paper investigates the effectiveness of reasoning in passage rerankers that utilize Large Language Models (LLMs) for natural language tasks. The authors compare two types of rerankers: ReasonRR, which incorporates a reasoning process, and StandardRR, which does not. Surprisingly, the results show that StandardRR outperforms ReasonRR, and even a version of ReasonRR without reasoning (ReasonRR-NoReason) performs better than the full reasoning model. The study concludes that the reasoning process in LLMs can lead to overly polarized relevance scores, neglecting the nuanced relevance of passages, which is crucial for accurate reranking."
                },
                "zh": {
                    "title": "æ¨ç†æœªå¿…æå‡é‡æ’åºå‡†ç¡®æ€§",
                    "desc": "éšç€æ¨ç†æ¨¡å‹åœ¨å¤æ‚è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­çš„æˆåŠŸï¼Œä¿¡æ¯æ£€ç´¢é¢†åŸŸçš„ç ”ç©¶è€…å¼€å§‹æ¢ç´¢å¦‚ä½•å°†ç±»ä¼¼çš„æ¨ç†èƒ½åŠ›æ•´åˆåˆ°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ®µè½é‡æ’åºå™¨ä¸­ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ˜ç¡®çš„é€æ­¥æ¨ç†è¿‡ç¨‹ï¼Œç„¶åå¾—å‡ºæœ€ç»ˆçš„ç›¸å…³æ€§é¢„æµ‹ã€‚ç„¶è€Œï¼Œæ¨ç†çœŸçš„èƒ½æé«˜é‡æ’åºçš„å‡†ç¡®æ€§å—ï¼Ÿæˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œåœ¨ç›¸åŒçš„è®­ç»ƒæ¡ä»¶ä¸‹ï¼Œæ ‡å‡†çš„éæ¨ç†é‡æ’åºå™¨é€šå¸¸ä¼˜äºåŸºäºæ¨ç†çš„é‡æ’åºå™¨ï¼Œä¸”ç¦ç”¨æ¨ç†è¿‡ç¨‹çš„é‡æ’åºå™¨è¡¨ç°å‡ºä¹æ„æ–™åœ°æ›´æœ‰æ•ˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16312",
            "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via\n  Action Pruning",
            "url": "https://huggingface.co/papers/2505.16312",
            "abstract": "EquivPruner reduces token consumption and improves reasoning accuracy by pruning semantically equivalent actions in LLM searches, leveraging a new dataset for mathematical equivalence.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) excel at complex reasoning through search algorithms, yet current strategies often suffer from massive token consumption due to redundant exploration of semantically equivalent steps. Existing semantic similarity methods struggle to accurately identify such equivalence in domain-specific contexts like mathematical reasoning. To address this, we propose EquivPruner, a simple yet effective approach that identifies and prunes semantically equivalent actions during LLM reasoning search. We also introduce MathEquiv, the first dataset we created for mathematical statement equivalence, which enables the training of a lightweight equivalence detector. Extensive experiments across various models and tasks demonstrate that EquivPruner significantly reduces token consumption, improving searching efficiency and often bolstering reasoning accuracy. For instance, when applied to Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by 48.1\\% while also improving accuracy. Our code is available at https://github.com/Lolo1222/EquivPruner.",
            "score": 3,
            "issue_id": 3972,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "6ae91cff5462f129",
            "authors": [
                "Jiawei Liu",
                "Qisi Chen",
                "Jianshu Zhang",
                "Quan Liu",
                "Defu Lian"
            ],
            "affiliations": [
                "University of Science and Technology of China",
                "iFLYTEK Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16312.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#data",
                    "#dataset",
                    "#optimization",
                    "#training"
                ],
                "emoji": "âœ‚ï¸",
                "ru": {
                    "title": "EquivPruner: ÑƒĞ¼Ğ½Ğ¾Ğµ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… LLM",
                    "desc": "EquivPruner - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿Ñ€Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. ĞĞ½ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ¾Ñ‚ÑĞµĞºĞ°Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. Ğ”Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ»ĞµĞ³ĞºĞ¾Ğ²ĞµÑĞ½Ğ¾Ğ³Ğ¾ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ° ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ±Ñ‹Ğ» ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ MathEquiv, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ EquivPruner."
                },
                "en": {
                    "title": "Streamlining Reasoning with EquivPruner: Less Tokens, More Accuracy!",
                    "desc": "EquivPruner is a novel method designed to enhance the efficiency of Large Language Models (LLMs) by reducing unnecessary token usage during reasoning tasks. It achieves this by identifying and eliminating semantically equivalent actions in the search process, which helps streamline the reasoning flow. The paper introduces a new dataset called MathEquiv, specifically created to train a lightweight equivalence detector for mathematical statements. Experimental results show that EquivPruner can significantly lower token consumption while improving the accuracy of reasoning tasks, demonstrating its effectiveness in optimizing LLM performance."
                },
                "zh": {
                    "title": "ä¿®å‰ªç­‰ä»·åŠ¨ä½œï¼Œæå‡æ¨ç†æ•ˆç‡",
                    "desc": "EquivPruneræ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœç´¢ä¸­ä¿®å‰ªè¯­ä¹‰ç­‰ä»·çš„åŠ¨ä½œï¼Œå‡å°‘äº†ä»¤ç‰Œæ¶ˆè€—å¹¶æé«˜äº†æ¨ç†å‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äº†æˆ‘ä»¬åˆ›å»ºçš„MathEquivæ•°æ®é›†ï¼Œä¸“æ³¨äºæ•°å­¦ç­‰ä»·æ€§ï¼Œä»è€Œæœ‰æ•ˆè¯†åˆ«å’Œå»é™¤å†—ä½™çš„æœç´¢æ­¥éª¤ã€‚ç°æœ‰çš„è¯­ä¹‰ç›¸ä¼¼æ€§æ–¹æ³•åœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æ•°å­¦æ¨ç†ï¼‰ä¸­éš¾ä»¥å‡†ç¡®è¯†åˆ«ç­‰ä»·æ€§ï¼Œè€ŒEquivPruneråˆ™æä¾›äº†ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEquivPruneråœ¨å¤šä¸ªæ¨¡å‹å’Œä»»åŠ¡ä¸­æ˜¾è‘—é™ä½äº†ä»¤ç‰Œæ¶ˆè€—ï¼ŒåŒæ—¶æé«˜äº†æ¨ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19706",
            "title": "Error Typing for Smarter Rewards: Improving Process Reward Models with\n  Error-Aware Hierarchical Supervision",
            "url": "https://huggingface.co/papers/2505.19706",
            "abstract": "PathFinder-PRM, a hierarchical and error-aware Process Reward Model, improves mathematical problem-solving by fine-grained error classification and step correctness estimation, achieving state-of-the-art PRMScore with reduced data usage.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) are prone to hallucination, especially during multi-hop and reasoning-intensive tasks such as mathematical problem solving. While Outcome Reward Models verify only final answers, Process Reward Models (PRMs) score each intermediate step to steer generation toward coherent solutions. We introduce PathFinder-PRM, a novel hierarchical, error-aware discriminative PRM that first classifies math and consistency errors at each step, then combines these fine-grained signals to estimate step correctness. To train PathFinder-PRM, we construct a 400K-sample dataset by enriching the human-annotated PRM800K corpus and RLHFlow Mistral traces with three-dimensional step-level labels. On PRMBench, PathFinder-PRM achieves a new state-of-the-art PRMScore of 67.7, outperforming the prior best (65.5) while using 3 times less data. When applied to reward guided greedy search, our model yields prm@8 48.3, a +1.5 point gain over the strongest baseline. These results demonstrate that decoupled error detection and reward estimation not only boost fine-grained error detection but also substantially improve end-to-end, reward-guided mathematical reasoning with greater data efficiency.",
            "score": 2,
            "issue_id": 3967,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "e60e6086053e62d0",
            "authors": [
                "Tej Deep Pala",
                "Panshul Sharma",
                "Amir Zadeh",
                "Chuan Li",
                "Soujanya Poria"
            ],
            "affiliations": [
                "Lambda Labs",
                "Singapore University of Technology and Design"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19706.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#math",
                    "#hallucinations",
                    "#dataset",
                    "#optimization"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ… Ñ PathFinder-PRM",
                    "desc": "PathFinder-PRM - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸, Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞĞ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑˆĞ°Ğ³Ğ°. PathFinder-PRM Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ PRMScore, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ² 3 Ñ€Ğ°Ğ·Ğ° Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğº Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡."
                },
                "en": {
                    "title": "PathFinder-PRM: Enhancing Math Problem-Solving with Fine-Grained Error Detection",
                    "desc": "PathFinder-PRM is a new model designed to enhance mathematical problem-solving by focusing on detailed error classification and assessing the correctness of each step in the solution process. Unlike traditional Outcome Reward Models that only evaluate final answers, this model uses a hierarchical and error-aware approach to score intermediate steps, which helps guide the generation of coherent solutions. It was trained on a large dataset that includes fine-grained labels for errors, allowing it to achieve a state-of-the-art PRMScore while using significantly less data. The results show that this model not only improves error detection but also enhances overall performance in reward-guided reasoning tasks."
                },
                "zh": {
                    "title": "æå‡æ•°å­¦æ¨ç†çš„é”™è¯¯æ„ŸçŸ¥æ¨¡å‹",
                    "desc": "PathFinder-PRMæ˜¯ä¸€ç§å±‚æ¬¡åŒ–ä¸”å…·å¤‡é”™è¯¯æ„ŸçŸ¥çš„è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡ç»†è‡´çš„é”™è¯¯åˆ†ç±»å’Œæ­¥éª¤æ­£ç¡®æ€§ä¼°è®¡æ¥æå‡æ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›ã€‚è¯¥æ¨¡å‹é€šè¿‡å¯¹æ¯ä¸ªæ­¥éª¤çš„æ•°å­¦é”™è¯¯å’Œä¸€è‡´æ€§é”™è¯¯è¿›è¡Œåˆ†ç±»ï¼Œç»“åˆè¿™äº›ç»†è‡´çš„ä¿¡å·æ¥è¯„ä¼°æ­¥éª¤çš„æ­£ç¡®æ€§ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«40ä¸‡æ ·æœ¬çš„æ•°æ®é›†ï¼ŒPathFinder-PRMåœ¨PRMBenchä¸Šè¾¾åˆ°äº†67.7çš„æœ€æ–°çŠ¶æ€ï¼Œä½¿ç”¨çš„æ•°æ®é‡æ¯”ä¹‹å‰å‡å°‘äº†ä¸‰å€ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè§£è€¦çš„é”™è¯¯æ£€æµ‹å’Œå¥–åŠ±ä¼°è®¡ä¸ä»…æå‡äº†ç»†ç²’åº¦é”™è¯¯æ£€æµ‹çš„èƒ½åŠ›ï¼Œè¿˜æ˜¾è‘—æ”¹å–„äº†åŸºäºå¥–åŠ±çš„æ•°å­¦æ¨ç†æ•ˆç‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18283",
            "title": "TAGS: A Test-Time Generalist-Specialist Framework with\n  Retrieval-Augmented Reasoning and Verification",
            "url": "https://huggingface.co/papers/2505.18283",
            "abstract": "TAGS, a test-time framework combining generalist and specialist models with hierarchical retrieval and reliability scoring, enhances medical LLM reasoning without fine-tuning.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances such as Chain-of-Thought prompting have significantly improved large language models (LLMs) in zero-shot medical reasoning. However, prompting-based methods often remain shallow and unstable, while fine-tuned medical LLMs suffer from poor generalization under distribution shifts and limited adaptability to unseen clinical scenarios. To address these limitations, we present TAGS, a test-time framework that combines a broadly capable generalist with a domain-specific specialist to offer complementary perspectives without any model fine-tuning or parameter updates. To support this generalist-specialist reasoning process, we introduce two auxiliary modules: a hierarchical retrieval mechanism that provides multi-scale exemplars by selecting examples based on both semantic and rationale-level similarity, and a reliability scorer that evaluates reasoning consistency to guide final answer aggregation. TAGS achieves strong performance across nine MedQA benchmarks, boosting GPT-4o accuracy by 13.8%, DeepSeek-R1 by 16.8%, and improving a vanilla 7B model from 14.1% to 23.9%. These results surpass several fine-tuned medical LLMs, without any parameter updates. The code will be available at https://github.com/JianghaoWu/TAGS.",
            "score": 2,
            "issue_id": 3976,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "6cb15e47a7465ed3",
            "authors": [
                "Jianghao Wu",
                "Feilong Tang",
                "Yulong Li",
                "Ming Hu",
                "Haochen Xue",
                "Shoaib Jameel",
                "Yutong Xie",
                "Imran Razzak"
            ],
            "affiliations": [
                "Mohamed bin Zayed University of Artificial Intelligence",
                "Monash University",
                "University of Southampton",
                "Xian Jiaotong-Liverpool University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18283.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#healthcare",
                    "#optimization",
                    "#reasoning",
                    "#training"
                ],
                "emoji": "ğŸ©º",
                "ru": {
                    "title": "TAGS: Ğ¡Ğ¸Ğ½ĞµÑ€Ğ³Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ğ»Ğ¸ÑÑ‚Ğ¾Ğ² Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… LLM",
                    "desc": "TAGS - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-Ğ³ĞµĞ½ĞµÑ€Ğ°Ğ»Ğ¸ÑÑ‚ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹. TAGS Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ¸ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… LLM Ğ½Ğ° Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
                },
                "en": {
                    "title": "TAGS: Enhancing Medical LLMs with Generalist-Specialist Synergy",
                    "desc": "The paper introduces TAGS, a novel framework that enhances medical reasoning in large language models (LLMs) without the need for fine-tuning. It combines a generalist model with a specialist model to leverage their strengths, providing a more robust reasoning process. TAGS incorporates a hierarchical retrieval system to select relevant examples and a reliability scoring mechanism to assess the consistency of the reasoning. This approach significantly improves performance on medical question-answering benchmarks, demonstrating that effective model combination can outperform traditional fine-tuning methods."
                },
                "zh": {
                    "title": "TAGSï¼šæ— å¾®è°ƒçš„åŒ»ç–—æ¨ç†æ–°æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºTAGSçš„æµ‹è¯•æ—¶æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºåŒ»ç–—é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œæ— éœ€è¿›è¡Œæ¨¡å‹å¾®è°ƒã€‚TAGSç»“åˆäº†é€šç”¨æ¨¡å‹å’Œä¸“ä¸šæ¨¡å‹ï¼Œé€šè¿‡å±‚æ¬¡æ£€ç´¢å’Œå¯é æ€§è¯„åˆ†æ¥æä¾›äº’è¡¥çš„æ¨ç†è§†è§’ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤ä¸ªè¾…åŠ©æ¨¡å—ï¼šå±‚æ¬¡æ£€ç´¢æœºåˆ¶å’Œå¯é æ€§è¯„åˆ†å™¨ï¼Œä»¥æ”¯æŒæ›´æœ‰æ•ˆçš„æ¨ç†è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTAGSåœ¨ä¹ä¸ªMedQAåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œè¶…è¶Šäº†å¤šç§å¾®è°ƒçš„åŒ»ç–—LLMã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.15957",
            "title": "Towards Holistic Evaluation of Large Audio-Language Models: A\n  Comprehensive Survey",
            "url": "https://huggingface.co/papers/2505.15957",
            "abstract": "A survey proposes a systematic taxonomy for evaluating large audio-language models across dimensions including auditory awareness, knowledge reasoning, dialogue ability, and fairness, to address fragmented benchmarks in the field.  \t\t\t\t\tAI-generated summary \t\t\t\t With advancements in large audio-language models (LALMs), which enhance large language models (LLMs) with auditory capabilities, these models are expected to demonstrate universal proficiency across various auditory tasks. While numerous benchmarks have emerged to assess LALMs' performance, they remain fragmented and lack a structured taxonomy. To bridge this gap, we conduct a comprehensive survey and propose a systematic taxonomy for LALM evaluations, categorizing them into four dimensions based on their objectives: (1) General Auditory Awareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented Ability, and (4) Fairness, Safety, and Trustworthiness. We provide detailed overviews within each category and highlight challenges in this field, offering insights into promising future directions. To the best of our knowledge, this is the first survey specifically focused on the evaluations of LALMs, providing clear guidelines for the community. We will release the collection of the surveyed papers and actively maintain it to support ongoing advancements in the field.",
            "score": 2,
            "issue_id": 3968,
            "pub_date": "2025-05-21",
            "pub_date_card": {
                "ru": "21 Ğ¼Ğ°Ñ",
                "en": "May 21",
                "zh": "5æœˆ21æ—¥"
            },
            "hash": "ed5ebb17c81ad1e0",
            "authors": [
                "Chih-Kai Yang",
                "Neo S. Ho",
                "Hung-yi Lee"
            ],
            "affiliations": [
                "National Taiwan University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.15957.jpg",
            "data": {
                "categories": [
                    "#ethics",
                    "#reasoning",
                    "#audio",
                    "#benchmark",
                    "#multimodal",
                    "#survey"
                ],
                "emoji": "ğŸ§",
                "ru": {
                    "title": "Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ°ÑƒĞ´Ğ¸Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ˜Ğ˜-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ‚Ğ°ĞºÑĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ğ°ÑƒĞ´Ğ¸Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LALM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹Ğ´ĞµĞ»ÑÑÑ‚ Ñ‡ĞµÑ‚Ñ‹Ñ€Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ: Ğ¾Ğ±Ñ‰ĞµĞµ ÑĞ»ÑƒÑ…Ğ¾Ğ²Ğ¾Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸ÑÑ‚Ğ¸Ğµ, Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹, Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑĞ¿Ñ€Ğ°Ğ²ĞµĞ´Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ. Ğ­Ñ‚Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€, Ñ„Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ÑÑ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ğ½Ğ° Ğ¾Ñ†ĞµĞ½ĞºĞµ LALM, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‡ĞµÑ‚ĞºĞ¸Ğµ Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğ°. Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ½Ğ° Ğ¿Ñ€ĞµĞ¾Ğ´Ğ¾Ğ»ĞµĞ½Ğ¸Ğµ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ñ‚Ğ°ĞºĞ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."
                },
                "en": {
                    "title": "A Unified Framework for Evaluating Large Audio-Language Models",
                    "desc": "This paper presents a structured approach to evaluate large audio-language models (LALMs) by proposing a systematic taxonomy. It identifies four key dimensions for assessment: auditory awareness, knowledge reasoning, dialogue ability, and fairness. The authors highlight the current fragmentation in benchmarks and aim to provide clarity and direction for future evaluations. This survey is the first of its kind, offering comprehensive insights and guidelines for researchers in the field of LALMs."
                },
                "zh": {
                    "title": "ç³»ç»Ÿè¯„ä¼°å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„åˆ†ç±»æ³•",
                    "desc": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„åˆ†ç±»æ³•ï¼Œç”¨äºè¯„ä¼°å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMsï¼‰ã€‚è¯„ä¼°ç»´åº¦åŒ…æ‹¬å¬è§‰æ„è¯†ã€çŸ¥è¯†æ¨ç†ã€å¯¹è¯èƒ½åŠ›å’Œå…¬å¹³æ€§ï¼Œä»¥è§£å†³è¯¥é¢†åŸŸåŸºå‡†æµ‹è¯•çš„ç¢ç‰‡åŒ–é—®é¢˜ã€‚é€šè¿‡å¯¹ç°æœ‰æ–‡çŒ®çš„å…¨é¢è°ƒæŸ¥ï¼Œè®ºæ–‡ä¸ºLALMçš„è¯„ä¼°æä¾›äº†æ¸…æ™°çš„æŒ‡å¯¼ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚æ­¤ç ”ç©¶æ˜¯é¦–æ¬¡ä¸“æ³¨äºLALMè¯„ä¼°çš„è°ƒæŸ¥ï¼Œä¸ºç›¸å…³ç¤¾åŒºæä¾›äº†é‡è¦çš„å‚è€ƒã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20297",
            "title": "DiSA: Diffusion Step Annealing in Autoregressive Image Generation",
            "url": "https://huggingface.co/papers/2505.20297",
            "abstract": "Diffusion step annealing enhances inference efficiency in autoregressive models by reducing the number of diffusion steps as more tokens are generated, preserving quality.  \t\t\t\t\tAI-generated summary \t\t\t\t An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and Harmon adopt diffusion sampling to improve the quality of image generation. However, this strategy leads to low inference efficiency, because it usually takes 50 to 100 steps for diffusion to sample a token. This paper explores how to effectively address this issue. Our key motivation is that as more tokens are generated during the autoregressive process, subsequent tokens follow more constrained distributions and are easier to sample. To intuitively explain, if a model has generated part of a dog, the remaining tokens must complete the dog and thus are more constrained. Empirical evidence supports our motivation: at later generation stages, the next tokens can be well predicted by a multilayer perceptron, exhibit low variance, and follow closer-to-straight-line denoising paths from noise to tokens. Based on our finding, we introduce diffusion step annealing (DiSA), a training-free method which gradually uses fewer diffusion steps as more tokens are generated, e.g., using 50 steps at the beginning and gradually decreasing to 5 steps at later stages. Because DiSA is derived from our finding specific to diffusion in autoregressive models, it is complementary to existing acceleration methods designed for diffusion alone. DiSA can be implemented in only a few lines of code on existing models, and albeit simple, achieves 5-10times faster inference for MAR and Harmon and 1.4-2.5times for FlowAR and xAR, while maintaining the generation quality.",
            "score": 1,
            "issue_id": 3989,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "509479fbd2f0beb6",
            "authors": [
                "Qinyu Zhao",
                "Jaskirat Singh",
                "Ming Xu",
                "Akshay Asthana",
                "Stephen Gould",
                "Liang Zheng"
            ],
            "affiliations": [
                "Australian National University",
                "Seeing Machines Ltd"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20297.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#training",
                    "#diffusion",
                    "#optimization"
                ],
                "emoji": "ğŸš€",
                "ru": {
                    "title": "Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ±ĞµĞ· Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°: Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ¶Ğ¸Ğ³ ÑˆĞ°Ğ³Ğ¾Ğ² Ğ² Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ¶Ğ¸Ğ³Ğ° ÑˆĞ°Ğ³Ğ¾Ğ² (DiSA) Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ² Ğ°Ğ²Ñ‚Ğ¾Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼ ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼. DiSA Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑˆĞ°Ğ³Ğ¾Ğ² Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¼ĞµÑ€Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ², Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹Ğ²Ğ°ÑÑÑŒ Ğ½Ğ° Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ ÑĞ»ĞµĞ´ÑƒÑÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ÑĞ¼. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑƒÑĞºĞ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ² 5-10 Ñ€Ğ°Ğ· Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ MAR Ğ¸ Harmon Ğ¸ Ğ² 1.4-2.5 Ñ€Ğ°Ğ·Ğ° Ğ´Ğ»Ñ FlowAR Ğ¸ xAR, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸. DiSA Ğ»ĞµĞ³ĞºĞ¾ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ÑÑ Ğ¸ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Speed Up Inference with Diffusion Step Annealing!",
                    "desc": "This paper presents a method called diffusion step annealing (DiSA) to improve the efficiency of autoregressive models during inference. The key idea is that as more tokens are generated, the distribution of subsequent tokens becomes more constrained, allowing for fewer diffusion steps without sacrificing quality. Empirical results show that DiSA can significantly speed up the inference process, achieving up to 10 times faster performance in certain models. This method is easy to implement and complements existing techniques for accelerating diffusion processes in machine learning."
                },
                "zh": {
                    "title": "æ‰©æ•£æ­¥éª¤é€€ç«ï¼šæå‡è‡ªå›å½’æ¨¡å‹æ¨ç†æ•ˆç‡çš„åˆ›æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æ¢è®¨äº†ä¸€ç§åä¸ºæ‰©æ•£æ­¥éª¤é€€ç«ï¼ˆDiSAï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜è‡ªå›å½’æ¨¡å‹çš„æ¨ç†æ•ˆç‡ã€‚éšç€ç”Ÿæˆçš„æ ‡è®°æ•°é‡å¢åŠ ï¼Œåç»­æ ‡è®°çš„åˆ†å¸ƒå˜å¾—æ›´åŠ å—é™ï¼Œä»è€Œæ›´å®¹æ˜“è¿›è¡Œé‡‡æ ·ã€‚é€šè¿‡å®éªŒè¯æ˜ï¼Œåœ¨ç”Ÿæˆçš„åæœŸé˜¶æ®µï¼Œä¸‹ä¸€æ ‡è®°å¯ä»¥é€šè¿‡å¤šå±‚æ„ŸçŸ¥å™¨è¿›è¡Œè‰¯å¥½é¢„æµ‹ï¼Œä¸”å…·æœ‰ä½æ–¹å·®ã€‚DiSAæ–¹æ³•åœ¨ç”ŸæˆåˆæœŸä½¿ç”¨è¾ƒå¤šçš„æ‰©æ•£æ­¥éª¤ï¼Œéšç€ç”Ÿæˆçš„è¿›è¡Œé€æ¸å‡å°‘æ­¥éª¤æ•°é‡ï¼Œä»è€Œå®ç°äº†æ¨ç†é€Ÿåº¦çš„æ˜¾è‘—æå‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20290",
            "title": "EgoZero: Robot Learning from Smart Glasses",
            "url": "https://huggingface.co/papers/2505.20290",
            "abstract": "EgoZero learns robust manipulation policies for robots using in-the-wild human demonstrations and zero robot data, enabling zero-shot transfer across diverse tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Despite recent progress in general purpose robotics, robot policies still lag far behind basic human capabilities in the real world. Humans interact constantly with the physical world, yet this rich data resource remains largely untapped in robot learning. We propose EgoZero, a minimal system that learns robust manipulation policies from human demonstrations captured with Project Aria smart glasses, and zero robot data. EgoZero enables: (1) extraction of complete, robot-executable actions from in-the-wild, egocentric, human demonstrations, (2) compression of human visual observations into morphology-agnostic state representations, and (3) closed-loop policy learning that generalizes morphologically, spatially, and semantically. We deploy EgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot transfer with 70% success rate over 7 manipulation tasks and only 20 minutes of data collection per task. Our results suggest that in-the-wild human data can serve as a scalable foundation for real-world robot learning - paving the way toward a future of abundant, diverse, and naturalistic training data for robots. Code and videos are available at https://egozero-robot.github.io.",
            "score": 1,
            "issue_id": 3980,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "64efed1421a47a18",
            "authors": [
                "Vincent Liu",
                "Ademi Adeniji",
                "Haotian Zhan",
                "Raunaq Bhirangi",
                "Pieter Abbeel",
                "Lerrel Pinto"
            ],
            "affiliations": [
                "New York University",
                "UC Berkeley"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20290.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#optimization",
                    "#robotics",
                    "#transfer_learning"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸ÑĞ¼ Ğ±ĞµĞ· Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "EgoZero - ÑÑ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ², Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ»ÑĞ´ĞµĞ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ… Ğ¸ Ğ±ĞµĞ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ². Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğµ, Ğ¸ÑĞ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼Ñ‹Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ¼ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ¸Ğ· ÑĞ³Ğ¾Ñ†ĞµĞ½Ñ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°, ÑĞ¶Ğ¸Ğ¼Ğ°ĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ñ Ğ² Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğº Ğ¼Ğ¾Ñ€Ñ„Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹ Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºÑƒ Ñ Ğ·Ğ°Ğ¼ĞºĞ½ÑƒÑ‚Ñ‹Ğ¼ Ñ†Ğ¸ĞºĞ»Ğ¾Ğ¼. EgoZero Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ½Ğ¾Ñ Ñ Ğ½ÑƒĞ»ĞµĞ²Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ñ 70% ÑƒÑĞ¿ĞµÑ…Ğ¾Ğ¼ Ğ½Ğ° 7 Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ²ÑĞµĞ³Ğ¾ 20 Ğ¼Ğ¸Ğ½ÑƒÑ‚ ÑĞ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ."
                },
                "en": {
                    "title": "Learning Robot Skills from Human Actions, No Robot Data Needed!",
                    "desc": "EgoZero is a novel system that enables robots to learn manipulation skills by observing human actions without needing any robot-specific data. It utilizes human demonstrations captured through smart glasses to extract actionable insights and create adaptable representations that are not tied to any specific robot design. The system employs closed-loop policy learning, allowing it to generalize across different tasks and environments effectively. With a 70% success rate in zero-shot transfer across multiple manipulation tasks, EgoZero highlights the potential of using real-world human data to enhance robotic learning capabilities."
                },
                "zh": {
                    "title": "åˆ©ç”¨äººç±»ç¤ºèŒƒå®ç°æœºå™¨äººé›¶æ ·æœ¬å­¦ä¹ ",
                    "desc": "EgoZero æ˜¯ä¸€ä¸ªå­¦ä¹ æœºå™¨äººæ“ä½œç­–ç•¥çš„ç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨äººç±»åœ¨çœŸå®ç¯å¢ƒä¸­çš„ç¤ºèŒƒï¼Œè€Œä¸éœ€è¦ä»»ä½•æœºå™¨äººæ•°æ®ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿä»äººç±»çš„ç¬¬ä¸€äººç§°è§†è§’ç¤ºèŒƒä¸­æå–å¯æ‰§è¡Œçš„æ“ä½œï¼Œå¹¶å°†äººç±»çš„è§†è§‰è§‚å¯Ÿå‹ç¼©ä¸ºä¸å½¢æ€æ— å…³çš„çŠ¶æ€è¡¨ç¤ºã€‚EgoZero è¿˜å®ç°äº†é—­ç¯ç­–ç•¥å­¦ä¹ ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçš„å½¢æ€ã€ç©ºé—´å’Œè¯­ä¹‰ä¸Šè¿›è¡Œæ³›åŒ–ã€‚é€šè¿‡åœ¨ Franka Panda æœºå™¨äººä¸Šéƒ¨ç½² EgoZero ç­–ç•¥ï¼Œæˆ‘ä»¬åœ¨ä¸ƒä¸ªæ“ä½œä»»åŠ¡ä¸­å®ç°äº† 70% çš„é›¶æ ·æœ¬è½¬ç§»æˆåŠŸç‡ï¼Œè¡¨æ˜çœŸå®ä¸–ç•Œçš„äººç±»æ•°æ®å¯ä»¥ä¸ºæœºå™¨äººå­¦ä¹ æä¾›å¯æ‰©å±•çš„åŸºç¡€ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20236",
            "title": "Seeing is Believing, but How Much? A Comprehensive Analysis of\n  Verbalized Calibration in Vision-Language Models",
            "url": "https://huggingface.co/papers/2505.20236",
            "abstract": "Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems.",
            "score": 1,
            "issue_id": 3989,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "00b85a02408d1380",
            "authors": [
                "Weihao Xuan",
                "Qingcheng Zeng",
                "Heli Qi",
                "Junjue Wang",
                "Naoto Yokoya"
            ],
            "affiliations": [
                "Northwestern University",
                "RIKEN AIP",
                "The University of Tokyo",
                "Waseda University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20236.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#training",
                    "#interpretability",
                    "#reasoning"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…: Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²ĞµÑ€Ğ±Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ ÑĞ·Ñ‹ĞºĞ° (VLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´ÑÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½ÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ VLM Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¸ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ÑÑ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ VLM Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ·Ğ°Ğ¼ĞµÑ‚Ğ½ÑƒÑ Ğ¼Ğ¸ÑĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºÑƒ, Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ»ÑƒÑ‡ÑˆÑƒÑ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºÑƒ. Ğ”Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ´Ğ²ÑƒÑ…ÑÑ‚Ğ°Ğ¿Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¸Ğ½Ğ³Ğ° Visual Confidence-Aware Prompting."
                },
                "en": {
                    "title": "Enhancing Trust in Vision-Language Models through Confidence Calibration",
                    "desc": "This paper focuses on uncertainty quantification in vision-language models (VLMs), which is crucial for ensuring the reliability of AI systems. It evaluates how well these models express their confidence through verbalized uncertainty, a method that has been effective in large language models but not thoroughly explored in VLMs. The study finds that VLMs often miscalibrate their confidence levels across various tasks, although visual reasoning models perform better in this regard. To improve this calibration, the authors propose a new strategy called Visual Confidence-Aware Prompting, which enhances confidence alignment in multimodal contexts."
                },
                "zh": {
                    "title": "æå‡è§†è§‰-è¯­è¨€æ¨¡å‹çš„ä¿¡å¿ƒæ ¡å‡†",
                    "desc": "ä¸ç¡®å®šæ€§é‡åŒ–å¯¹äºè¯„ä¼°ç°ä»£äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§å’Œå¯ä¿¡åº¦è‡³å…³é‡è¦ã€‚æœ¬æ–‡ç ”ç©¶äº†åœ¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸­ï¼Œæ¨¡å‹é€šè¿‡è‡ªç„¶è¯­è¨€è¡¨è¾¾ä¿¡å¿ƒçš„æ–¹å¼ï¼Œå³å£å¤´ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œå½“å‰çš„VLMsåœ¨ä¸åŒä»»åŠ¡å’Œè®¾ç½®ä¸­å¸¸å¸¸å­˜åœ¨æ˜¾è‘—çš„æ ¡å‡†å¤±è°ƒï¼Œå°¤å…¶æ˜¯è§†è§‰æ¨ç†æ¨¡å‹è¡¨ç°å‡ºæ›´å¥½çš„æ ¡å‡†æ•ˆæœã€‚ä¸ºäº†è§£å†³æ ¡å‡†é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è§†è§‰ä¿¡å¿ƒæ„ŸçŸ¥æç¤ºçš„ä¸¤é˜¶æ®µç­–ç•¥ï¼Œä»¥æ”¹å–„å¤šæ¨¡æ€ç¯å¢ƒä¸­çš„ä¿¡å¿ƒå¯¹é½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19800",
            "title": "MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs",
            "url": "https://huggingface.co/papers/2505.19800",
            "abstract": "A framework leveraging Large Language Models (LLMs) is introduced for automatic metadata extraction from scientific papers, with a focus on datasets from languages other than Arabic.  \t\t\t\t\tAI-generated summary \t\t\t\t Metadata extraction is essential for cataloging and preserving datasets, enabling effective research discovery and reproducibility, especially given the current exponential growth in scientific research. While Masader (Alyafeai et al.,2021) laid the groundwork for extracting a wide range of metadata attributes from Arabic NLP datasets' scholarly articles, it relies heavily on manual annotation. In this paper, we present MOLE, a framework that leverages Large Language Models (LLMs) to automatically extract metadata attributes from scientific papers covering datasets of languages other than Arabic. Our schema-driven methodology processes entire documents across multiple input formats and incorporates robust validation mechanisms for consistent output. Additionally, we introduce a new benchmark to evaluate the research progress on this task. Through systematic analysis of context length, few-shot learning, and web browsing integration, we demonstrate that modern LLMs show promising results in automating this task, highlighting the need for further future work improvements to ensure consistent and reliable performance. We release the code: https://github.com/IVUL-KAUST/MOLE and dataset: https://huggingface.co/datasets/IVUL-KAUST/MOLE for the research community.",
            "score": 1,
            "issue_id": 3974,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "dba6eea5b69199a0",
            "authors": [
                "Zaid Alyafeai",
                "Maged S. Al-Shaibani",
                "Bernard Ghanem"
            ],
            "affiliations": [
                "KAUST",
                "SDAIA-KFUPM Joint Research Center for AI, KFUPM"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19800.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#benchmark",
                    "#data",
                    "#multilingual",
                    "#science",
                    "#open_source",
                    "#low_resource"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "MOLE: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° MOLE, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ°Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ°Ñ…. ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ†ĞµĞ»Ñ‹Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°Ñ… Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ñ‹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ². Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ° Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑÑ‚Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ» Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, Ğ½Ğ¾ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Automating Metadata Extraction with Large Language Models",
                    "desc": "This paper introduces MOLE, a framework that uses Large Language Models (LLMs) to automatically extract metadata from scientific papers, specifically focusing on datasets in languages other than Arabic. The framework aims to improve the efficiency of metadata extraction, which is crucial for research discovery and reproducibility in the rapidly growing field of scientific research. MOLE employs a schema-driven approach to process various document formats and includes validation mechanisms to ensure the accuracy of the extracted metadata. The authors also present a new benchmark for evaluating progress in this area and demonstrate that LLMs can effectively automate metadata extraction, while highlighting areas for future improvement."
                },
                "zh": {
                    "title": "åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨æå–ç§‘å­¦è®ºæ–‡å…ƒæ•°æ®",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨æå–ç§‘å­¦è®ºæ–‡å…ƒæ•°æ®çš„æ¡†æ¶ï¼Œç‰¹åˆ«å…³æ³¨éé˜¿æ‹‰ä¼¯è¯­çš„æ•°æ®é›†ã€‚å…ƒæ•°æ®æå–å¯¹äºç§‘å­¦ç ”ç©¶çš„å‘ç°å’Œå¯é‡å¤æ€§è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨ç§‘å­¦ç ”ç©¶å¿«é€Ÿå¢é•¿çš„èƒŒæ™¯ä¸‹ã€‚æˆ‘ä»¬æå‡ºçš„MOLEæ¡†æ¶èƒ½å¤Ÿå¤„ç†å¤šç§è¾“å…¥æ ¼å¼çš„å®Œæ•´æ–‡æ¡£ï¼Œå¹¶é‡‡ç”¨å¼ºå¤§çš„éªŒè¯æœºåˆ¶ä»¥ç¡®ä¿è¾“å‡ºçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æ¥è¯„ä¼°è¯¥ä»»åŠ¡çš„ç ”ç©¶è¿›å±•ï¼Œå±•ç¤ºäº†ç°ä»£LLMsåœ¨è‡ªåŠ¨åŒ–å…ƒæ•°æ®æå–æ–¹é¢çš„æ½œåŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19440",
            "title": "The Birth of Knowledge: Emergent Features across Time, Space, and Scale\n  in Large Language Models",
            "url": "https://huggingface.co/papers/2505.19440",
            "abstract": "This paper studies the emergence of interpretable categorical features within large language models (LLMs), analyzing their behavior across training checkpoints (time), transformer layers (space), and varying model sizes (scale). Using sparse autoencoders for mechanistic interpretability, we identify when and where specific semantic concepts emerge within neural activations. Results indicate clear temporal and scale-specific thresholds for feature emergence across multiple domains. Notably, spatial analysis reveals unexpected semantic reactivation, with early-layer features re-emerging at later layers, challenging standard assumptions about representational dynamics in transformer models.",
            "score": 1,
            "issue_id": 3979,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "49e0286d6a9b6731",
            "authors": [
                "Shashata Sawmya",
                "Micah Adler",
                "Nir Shavit"
            ],
            "affiliations": [
                "Massachusetts Institute of Technology",
                "Red Hat, Inc."
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19440.jpg",
            "data": {
                "categories": [
                    "#interpretability",
                    "#training",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°Ñ Ñ‚Ğ°Ğ¹Ğ½Ñ‹ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ¸ Ğ² Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ°Ñ… Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹",
                    "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¿Ğ¾ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑĞ»Ğ¾ÑÑ… Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ° Ğ¸ Ğ¿Ñ€Ğ¸ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ğ¸, Ğ¾Ğ½Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑÑÑ‚, ĞºĞ¾Ğ³Ğ´Ğ° Ğ¸ Ğ³Ğ´Ğµ Ğ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸ÑÑ… Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ°ÑÑ‚ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ‚Ñ‹. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ñ‡ĞµÑ‚ĞºĞ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ¾Ğ¼ĞµĞ½Ğ°Ñ…."
                },
                "en": {
                    "title": "Unveiling the Dynamics of Feature Emergence in Language Models",
                    "desc": "This paper investigates how interpretable categorical features develop in large language models (LLMs) over time, across different layers, and with varying model sizes. It employs sparse autoencoders to achieve mechanistic interpretability, pinpointing the emergence of specific semantic concepts in neural activations. The findings show distinct thresholds for feature emergence that depend on the training time and model scale, highlighting the complexity of feature development. Additionally, the study uncovers surprising patterns of semantic reactivation, where features from earlier layers reappear in later layers, questioning traditional views on how representations evolve in transformer architectures."
                },
                "zh": {
                    "title": "æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¯è§£é‡Šç‰¹å¾",
                    "desc": "æœ¬è®ºæ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å¯è§£é‡Šçš„åˆ†ç±»ç‰¹å¾çš„å‡ºç°ï¼Œåˆ†æäº†å®ƒä»¬åœ¨è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆæ—¶é—´ï¼‰ã€å˜æ¢å™¨å±‚ï¼ˆç©ºé—´ï¼‰å’Œä¸åŒæ¨¡å‹è§„æ¨¡ï¼ˆè§„æ¨¡ï¼‰ä¸Šçš„è¡Œä¸ºã€‚æˆ‘ä»¬ä½¿ç”¨ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œæœºåˆ¶å¯è§£é‡Šæ€§ï¼Œè¯†åˆ«å‡ºç‰¹å®šè¯­ä¹‰æ¦‚å¿µåœ¨ç¥ç»æ¿€æ´»ä¸­çš„å‡ºç°æ—¶æœºå’Œä½ç½®ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä¸ªé¢†åŸŸä¸­ï¼Œç‰¹å¾å‡ºç°å­˜åœ¨æ˜æ˜¾çš„æ—¶é—´å’Œè§„æ¨¡ç‰¹å®šé˜ˆå€¼ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç©ºé—´åˆ†ææ­ç¤ºäº†æ„æƒ³ä¸åˆ°çš„è¯­ä¹‰å†æ¿€æ´»ç°è±¡ï¼Œæ—©æœŸå±‚çš„ç‰¹å¾åœ¨åæœŸå±‚é‡æ–°å‡ºç°ï¼Œè¿™æŒ‘æˆ˜äº†å¯¹å˜æ¢å™¨æ¨¡å‹è¡¨ç¤ºåŠ¨æ€çš„æ ‡å‡†å‡è®¾ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.19415",
            "title": "MMIG-Bench: Towards Comprehensive and Explainable Evaluation of\n  Multi-Modal Image Generation Models",
            "url": "https://huggingface.co/papers/2505.19415",
            "abstract": "A comprehensive benchmark, MMIG-Bench, evaluates multi-modal image generators using text prompts and reference images, providing detailed insights through low-level, mid-level, and high-level metrics.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent multimodal image generators such as GPT-4o, Gemini 2.0 Flash, and Gemini 2.5 Pro excel at following complex instructions, editing images and maintaining concept consistency. However, they are still evaluated by disjoint toolkits: text-to-image (T2I) benchmarks that lacks multi-modal conditioning, and customized image generation benchmarks that overlook compositional semantics and common knowledge. We propose MMIG-Bench, a comprehensive Multi-Modal Image Generation Benchmark that unifies these tasks by pairing 4,850 richly annotated text prompts with 1,750 multi-view reference images across 380 subjects, spanning humans, animals, objects, and artistic styles. MMIG-Bench is equipped with a three-level evaluation framework: (1) low-level metrics for visual artifacts and identity preservation of objects; (2) novel Aspect Matching Score (AMS): a VQA-based mid-level metric that delivers fine-grained prompt-image alignment and shows strong correlation with human judgments; and (3) high-level metrics for aesthetics and human preference. Using MMIG-Bench, we benchmark 17 state-of-the-art models, including Gemini 2.5 Pro, FLUX, DreamBooth, and IP-Adapter, and validate our metrics with 32k human ratings, yielding in-depth insights into architecture and data design. We will release the dataset and evaluation code to foster rigorous, unified evaluation and accelerate future innovations in multi-modal image generation.",
            "score": 1,
            "issue_id": 3984,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "26d84e35c5cc1799",
            "authors": [
                "Hang Hua",
                "Ziyun Zeng",
                "Yizhi Song",
                "Yunlong Tang",
                "Liu He",
                "Daniel Aliaga",
                "Wei Xiong",
                "Jiebo Luo"
            ],
            "affiliations": [
                "NVIDIA",
                "Purdue University",
                "University of Rochester"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.19415.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#optimization",
                    "#dataset",
                    "#survey",
                    "#open_source",
                    "#benchmark"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "MMIG-Bench: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
                    "desc": "MMIG-Bench - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. ĞĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ² ÑĞµĞ±Ñ 4850 Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ 1750 ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ 380 Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµĞ¼. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‚Ñ€ĞµÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¾Ñ†ĞµĞ½ĞºĞ¸, Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‰ÑƒÑ Ğ½Ğ¸Ğ·ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ², ÑÑ€ĞµĞ´Ğ½ĞµÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ Aspect Matching Score (AMS) Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ ÑÑÑ‚ĞµÑ‚Ğ¸ĞºĞ¸. Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ MMIG-Bench Ğ±Ñ‹Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ 17 ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Gemini 2.5 Pro Ğ¸ FLUX."
                },
                "en": {
                    "title": "Unifying Evaluation for Multi-Modal Image Generators",
                    "desc": "The paper introduces MMIG-Bench, a new benchmark designed to evaluate multi-modal image generators that use both text prompts and reference images. It addresses the limitations of existing evaluation methods by providing a unified framework that includes low-level, mid-level, and high-level metrics. The benchmark features a large dataset with 4,850 annotated text prompts and 1,750 reference images, allowing for comprehensive assessments of model performance. By testing 17 advanced models, the authors validate their metrics against human ratings, aiming to enhance the evaluation process in multi-modal image generation."
                },
                "zh": {
                    "title": "ç»Ÿä¸€è¯„ä¼°å¤šæ¨¡æ€å›¾åƒç”Ÿæˆçš„åŸºå‡†",
                    "desc": "MMIG-Benchæ˜¯ä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€å›¾åƒç”ŸæˆåŸºå‡†ï¼Œæ—¨åœ¨é€šè¿‡æ–‡æœ¬æç¤ºå’Œå‚è€ƒå›¾åƒè¯„ä¼°å¤šæ¨¡æ€å›¾åƒç”Ÿæˆå™¨ã€‚è¯¥åŸºå‡†ç»“åˆäº†4,850ä¸ªä¸°å¯Œæ³¨é‡Šçš„æ–‡æœ¬æç¤ºå’Œ1,750ä¸ªå¤šè§†è§’å‚è€ƒå›¾åƒï¼Œæ¶µç›–äººç±»ã€åŠ¨ç‰©ã€ç‰©ä½“å’Œè‰ºæœ¯é£æ ¼ã€‚MMIG-Benché‡‡ç”¨ä¸‰å±‚è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬ä½çº§æŒ‡æ ‡ã€ä¸­çº§çš„Aspect Matching Scoreï¼ˆAMSï¼‰å’Œé«˜çº§ç¾å­¦æŒ‡æ ‡ï¼Œä»¥æä¾›è¯¦ç»†çš„è¯„ä¼°ç»“æœã€‚é€šè¿‡å¯¹17ä¸ªæœ€å…ˆè¿›æ¨¡å‹çš„åŸºå‡†æµ‹è¯•ï¼ŒMMIG-Benchä¸ºå¤šæ¨¡æ€å›¾åƒç”Ÿæˆçš„æ¶æ„å’Œæ•°æ®è®¾è®¡æä¾›äº†æ·±å…¥çš„è§è§£ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18497",
            "title": "The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic\n  Competence in Large Language Models",
            "url": "https://huggingface.co/papers/2505.18497",
            "abstract": "Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acquire this competence throughout the training process remains poorly understood. In this work, we introduce ALTPRAG, a dataset grounded in the pragmatic concept of alternatives, designed to evaluate whether LLMs at different training stages can accurately infer nuanced speaker intentions. Each instance pairs two contextually appropriate but pragmatically distinct continuations, enabling fine-grained assessment of both pragmatic interpretation and contrastive reasoning. We systematically evaluate 22 LLMs across key training stages: pre-training, supervised fine-tuning (SFT), and preference optimization, to examine the development of pragmatic competence. Our results show that even base models exhibit notable sensitivity to pragmatic cues, which improves consistently with increases in model and data scale. Additionally, SFT and RLHF contribute further gains, particularly in cognitive-pragmatic reasoning. These findings highlight pragmatic competence as an emergent and compositional property of LLM training and offer new insights for aligning models with human communicative norms.",
            "score": 1,
            "issue_id": 3989,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "5f6f1003fa242fdd",
            "authors": [
                "Kefan Yu",
                "Qingcheng Zeng",
                "Weihao Xuan",
                "Wanxin Li",
                "Jingyi Wu",
                "Rob Voigt"
            ],
            "affiliations": [
                "Northwestern University",
                "The University of Tokyo",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18497.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#training",
                    "#alignment",
                    "#reasoning",
                    "#dataset"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "Ğ Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ğ¿Ñ€Ğ°Ğ³Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ ALTPRAG - Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ñ€Ğ°Ğ³Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞĞ½Ğ°Ğ»Ğ¸Ğ· 22 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ», Ñ‡Ñ‚Ğ¾ Ğ´Ğ°Ğ¶Ğµ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğº Ğ¿Ñ€Ğ°Ğ³Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ°Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ÑÑ Ñ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ ÑƒÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ°ÑÑ‚ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ¸Ğ¹ Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ² ĞºĞ¾Ğ³Ğ½Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¾-Ğ¿Ñ€Ğ°Ğ³Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑÑ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ°Ğ³Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ĞºĞ¾Ğ¼Ğ¿ĞµÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ÑĞ¼ĞµÑ€Ğ´Ğ¶ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM."
                },
                "en": {
                    "title": "Unlocking Pragmatic Understanding in Language Models",
                    "desc": "This paper introduces ALTPRAG, a dataset designed to assess how large language models (LLMs) understand speaker intentions through pragmatic reasoning. It evaluates LLMs at various training stages, including pre-training, supervised fine-tuning, and preference optimization, to see how their ability to interpret nuanced meanings develops. The study finds that even basic models show some understanding of pragmatic cues, which improves as the models and training data grow. Additionally, supervised fine-tuning and reinforcement learning from human feedback enhance cognitive-pragmatic reasoning, suggesting that pragmatic competence emerges as LLMs are trained."
                },
                "zh": {
                    "title": "æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¯­ç”¨èƒ½åŠ›å‘å±•",
                    "desc": "å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¤¾ä¼šæ™ºèƒ½ä»»åŠ¡ä¸­å±•ç°å‡ºæ–°å…´èƒ½åŠ›ï¼ŒåŒ…æ‹¬éšå«æ„ä¹‰è§£æå’Œå¿ƒæ™ºç†è®ºæ¨ç†ï¼Œè¿™äº›éƒ½éœ€è¦æ·±åšçš„è¯­ç”¨ç†è§£ã€‚ç„¶è€Œï¼ŒLLMsåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•è·å¾—è¿™ç§èƒ½åŠ›ä»ç„¶ä¸å¤ªæ¸…æ¥šã€‚æˆ‘ä»¬å¼•å…¥äº†ALTPRAGæ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°ä¸åŒè®­ç»ƒé˜¶æ®µçš„LLMsæ˜¯å¦èƒ½å¤Ÿå‡†ç¡®æ¨æ–­ç»†å¾®çš„è¯´è¯è€…æ„å›¾ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯åŸºç¡€æ¨¡å‹å¯¹è¯­ç”¨çº¿ç´¢ä¹Ÿè¡¨ç°å‡ºæ˜¾è‘—çš„æ•æ„Ÿæ€§ï¼Œå¹¶ä¸”éšç€æ¨¡å‹å’Œæ•°æ®è§„æ¨¡çš„å¢åŠ ï¼Œè¿™ç§èƒ½åŠ›ä¸æ–­æé«˜ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18454",
            "title": "Hybrid Latent Reasoning via Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.18454",
            "abstract": "Hybrid reasoning policy optimization (HRPO) leverages reinforcement learning to integrate latent reasoning with large language models, enhancing performance in knowledge- and reasoning-intensive tasks while maintaining interpretability.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in large language models (LLMs) have introduced latent reasoning as a promising alternative to autoregressive reasoning. By performing internal computation with hidden states from previous steps, latent reasoning benefit from more informative features rather than sampling a discrete chain-of-thought (CoT) path. Yet latent reasoning approaches are often incompatible with LLMs, as their continuous paradigm conflicts with the discrete nature of autoregressive generation. Moreover, these methods rely on CoT traces for training and thus fail to exploit the inherent reasoning patterns of LLMs. In this work, we explore latent reasoning by leveraging the intrinsic capabilities of LLMs via reinforcement learning (RL). To this end, we introduce hybrid reasoning policy optimization (HRPO), an RL-based hybrid latent reasoning approach that (1) integrates prior hidden states into sampled tokens with a learnable gating mechanism, and (2) initializes training with predominantly token embeddings while progressively incorporating more hidden features. This design maintains LLMs' generative capabilities and incentivizes hybrid reasoning using both discrete and continuous representations. In addition, the hybrid HRPO introduces stochasticity into latent reasoning via token sampling, thereby enabling RL-based optimization without requiring CoT trajectories. Extensive evaluations across diverse benchmarks show that HRPO outperforms prior methods in both knowledge- and reasoning-intensive tasks. Furthermore, HRPO-trained LLMs remain interpretable and exhibit intriguing behaviors like cross-lingual patterns and shorter completion lengths, highlighting the potential of our RL-based approach and offer insights for future work in latent reasoning.",
            "score": 1,
            "issue_id": 3984,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 Ğ¼Ğ°Ñ",
                "en": "May 24",
                "zh": "5æœˆ24æ—¥"
            },
            "hash": "386942e77eeb844e",
            "authors": [
                "Zhenrui Yue",
                "Bowen Jin",
                "Huimin Zeng",
                "Honglei Zhuang",
                "Zhen Qin",
                "Jinsung Yoon",
                "Lanyu Shang",
                "Jiawei Han",
                "Dong Wang"
            ],
            "affiliations": [
                "Google",
                "LMU",
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18454.jpg",
            "data": {
                "categories": [
                    "#rlhf",
                    "#training",
                    "#optimization",
                    "#interpretability",
                    "#reasoning",
                    "#multilingual",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…: Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğµ Ğ¸ ÑĞ²Ğ½Ğ¾Ğµ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ³Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (HRPO), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼. HRPO Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹ Ğ² ÑÑĞ¼Ğ¿Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹, Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°Ñ Ğ´Ğ¾Ğ»Ñ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ². Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ HRPO Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ñ‹Ğµ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ°, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº ĞºÑ€Ğ¾ÑÑ-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹."
                },
                "en": {
                    "title": "Enhancing Reasoning in Language Models with Hybrid Optimization",
                    "desc": "Hybrid Reasoning Policy Optimization (HRPO) is a novel approach that combines reinforcement learning with large language models (LLMs) to enhance reasoning capabilities. It integrates latent reasoning by utilizing prior hidden states and a learnable gating mechanism, allowing for more informative feature extraction. Unlike traditional methods that rely on discrete chain-of-thought paths, HRPO maintains the generative nature of LLMs while introducing stochasticity through token sampling. This results in improved performance on knowledge- and reasoning-intensive tasks, while also preserving interpretability and revealing interesting behaviors in the models."
                },
                "zh": {
                    "title": "æ··åˆæ¨ç†ï¼Œä¼˜åŒ–æœªæ¥ï¼",
                    "desc": "æ··åˆæ¨ç†ç­–ç•¥ä¼˜åŒ–ï¼ˆHRPOï¼‰ç»“åˆäº†å¼ºåŒ–å­¦ä¹ ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæå‡äº†åœ¨çŸ¥è¯†å’Œæ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ŒåŒæ—¶ä¿æŒäº†è§£é‡Šæ€§ã€‚HRPOé€šè¿‡å¼•å…¥éšçŠ¶æ€å’Œå¯å­¦ä¹ çš„é—¨æ§æœºåˆ¶ï¼Œå°†å…ˆå‰çš„éšçŠ¶æ€ä¸é‡‡æ ·çš„æ ‡è®°ç»“åˆèµ·æ¥ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„æ¨ç†ã€‚è¯¥æ–¹æ³•åœ¨è®­ç»ƒåˆæœŸä¸»è¦ä½¿ç”¨æ ‡è®°åµŒå…¥ï¼Œé€æ­¥å¼•å…¥æ›´å¤šçš„éšç‰¹å¾ï¼Œä¿æŒäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥éšæœºæ€§ï¼ŒHRPOèƒ½å¤Ÿåœ¨ä¸ä¾èµ–é“¾å¼æ¨ç†è½¨è¿¹çš„æƒ…å†µä¸‹è¿›è¡Œä¼˜åŒ–ï¼Œå±•ç°å‡ºä¼˜äºä»¥å¾€æ–¹æ³•çš„æ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18291",
            "title": "InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning",
            "url": "https://huggingface.co/papers/2505.18291",
            "abstract": "A new benchmark, InstructPart, and a task-oriented part segmentation dataset are introduced to evaluate and improve the performance of Vision-Language Models in real-world contexts.  \t\t\t\t\tAI-generated summary \t\t\t\t Large multimodal foundation models, particularly in the domains of language and vision, have significantly advanced various tasks, including robotics, autonomous driving, information retrieval, and grounding. However, many of these models perceive objects as indivisible, overlooking the components that constitute them. Understanding these components and their associated affordances provides valuable insights into an object's functionality, which is fundamental for performing a wide range of tasks. In this work, we introduce a novel real-world benchmark, InstructPart, comprising hand-labeled part segmentation annotations and task-oriented instructions to evaluate the performance of current models in understanding and executing part-level tasks within everyday contexts. Through our experiments, we demonstrate that task-oriented part segmentation remains a challenging problem, even for state-of-the-art Vision-Language Models (VLMs). In addition to our benchmark, we introduce a simple baseline that achieves a twofold performance improvement through fine-tuning with our dataset. With our dataset and benchmark, we aim to facilitate research on task-oriented part segmentation and enhance the applicability of VLMs across various domains, including robotics, virtual reality, information retrieval, and other related fields. Project website: https://zifuwan.github.io/InstructPart/.",
            "score": 1,
            "issue_id": 3982,
            "pub_date": "2025-05-23",
            "pub_date_card": {
                "ru": "23 Ğ¼Ğ°Ñ",
                "en": "May 23",
                "zh": "5æœˆ23æ—¥"
            },
            "hash": "ea625ba03695e0d2",
            "authors": [
                "Zifu Wan",
                "Yaqi Xie",
                "Ce Zhang",
                "Zhiqiu Lin",
                "Zihan Wang",
                "Simon Stepputtis",
                "Deva Ramanan",
                "Katia Sycara"
            ],
            "affiliations": [
                "Robotics Institute, Carnegie Mellon University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18291.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#multimodal",
                    "#robotics",
                    "#benchmark",
                    "#survey"
                ],
                "emoji": "ğŸ§©",
                "ru": {
                    "title": "Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²: Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº InstructPart Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ², Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸. Ğ¦ĞµĞ»ÑŒ - Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ‡Ğ°ÑÑ‚ĞµĞ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¾ÑÑ‚Ğ°ĞµÑ‚ÑÑ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡ĞµĞ¹ Ğ´Ğ°Ğ¶Ğµ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Vision-Language Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ´Ğ²Ğ° Ñ€Ğ°Ğ·Ğ° Ğ¿Ñ€Ğ¸ Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Enhancing Vision-Language Models with InstructPart for Task-Oriented Segmentation",
                    "desc": "This paper presents a new benchmark called InstructPart, designed to assess and enhance the capabilities of Vision-Language Models (VLMs) in understanding and executing tasks related to object parts. The dataset includes detailed part segmentation annotations and task-oriented instructions, which help models learn to recognize and utilize the components of objects effectively. The authors highlight that even advanced VLMs struggle with task-oriented part segmentation, indicating the complexity of this problem. By providing this benchmark and a baseline model that improves performance through fine-tuning, the authors aim to advance research in this area and broaden the application of VLMs in practical scenarios."
                },
                "zh": {
                    "title": "æå‡è§†è§‰-è¯­è¨€æ¨¡å‹çš„éƒ¨ä»¶ç†è§£èƒ½åŠ›",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•InstructPartï¼Œä»¥åŠä¸€ä¸ªé¢å‘ä»»åŠ¡çš„éƒ¨ä»¶åˆ†å‰²æ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°å’Œæå‡è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„è¡¨ç°ã€‚è®¸å¤šç°æœ‰æ¨¡å‹å°†ç‰©ä½“è§†ä¸ºä¸å¯åˆ†å‰²çš„æ•´ä½“ï¼Œå¿½è§†äº†æ„æˆç‰©ä½“çš„å„ä¸ªéƒ¨åˆ†ã€‚ç†è§£è¿™äº›éƒ¨åˆ†åŠå…¶åŠŸèƒ½å¯¹äºæ‰§è¡Œå„ç§ä»»åŠ¡è‡³å…³é‡è¦ã€‚é€šè¿‡å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†å³ä½¿æ˜¯æœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ä»»åŠ¡å¯¼å‘çš„éƒ¨ä»¶åˆ†å‰²ä¸Šä»é¢ä¸´æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç®€å•çš„åŸºçº¿ï¼Œé€šè¿‡å¾®è°ƒæˆ‘ä»¬çš„æ•°æ®é›†å®ç°äº†ä¸¤å€çš„æ€§èƒ½æå‡ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.12737",
            "title": "Option-aware Temporally Abstracted Value for Offline Goal-Conditioned\n  Reinforcement Learning",
            "url": "https://huggingface.co/papers/2505.12737",
            "abstract": "Option-aware Temporally Abstracted (OTA) value learning improves offline goal-conditioned reinforcement learning performance by refining the high-level policy through better advantage estimates in long-horizon settings.  \t\t\t\t\tAI-generated summary \t\t\t\t Offline goal-conditioned reinforcement learning (GCRL) offers a practical learning paradigm where goal-reaching policies are trained from abundant unlabeled (reward-free) datasets without additional environment interaction. However, offline GCRL still struggles with long-horizon tasks, even with recent advances that employ hierarchical policy structures, such as HIQL. By identifying the root cause of this challenge, we observe the following insights: First, performance bottlenecks mainly stem from the high-level policy's inability to generate appropriate subgoals. Second, when learning the high-level policy in the long-horizon regime, the sign of the advantage signal frequently becomes incorrect. Thus, we argue that improving the value function to produce a clear advantage signal for learning the high-level policy is essential. In this paper, we propose a simple yet effective solution: Option-aware Temporally Abstracted value learning, dubbed OTA, which incorporates temporal abstraction into the temporal-difference learning process. By modifying the value update to be option-aware, the proposed learning scheme contracts the effective horizon length, enabling better advantage estimates even in long-horizon regimes. We experimentally show that the high-level policy extracted using the OTA value function achieves strong performance on complex tasks from OGBench, a recently proposed offline GCRL benchmark, including maze navigation and visual robotic manipulation environments.",
            "score": 1,
            "issue_id": 3977,
            "pub_date": "2025-05-19",
            "pub_date_card": {
                "ru": "19 Ğ¼Ğ°Ñ",
                "en": "May 19",
                "zh": "5æœˆ19æ—¥"
            },
            "hash": "d7ac138a20e7f945",
            "authors": [
                "Hongjoon Ahn",
                "Heewoong Choi",
                "Jisu Han",
                "Taesup Moon"
            ],
            "affiliations": [
                "Department of ECE / IPAI / ASRI / INMC, Seoul National University",
                "Department of Electrical and Computer Engineering (ECE), Seoul National University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.12737.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#rl",
                    "#rlhf",
                    "#optimization",
                    "#reasoning",
                    "#benchmark"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Option-aware Temporally Abstracted (OTA) Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ² Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½-Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ñ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ†ĞµĞ»ĞµĞ¹. OTA ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²ÑƒÑ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºÑƒ. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ¸ ÑƒÑ‡ĞµÑ‚Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ OTA Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Enhancing Long-Horizon Learning with OTA Value Learning",
                    "desc": "The paper introduces Option-aware Temporally Abstracted (OTA) value learning, which enhances offline goal-conditioned reinforcement learning (GCRL) by improving the high-level policy's performance in long-horizon tasks. It identifies that the main issues arise from the high-level policy's difficulty in generating suitable subgoals and the incorrect advantage signals during learning. By refining the value function to be option-aware, OTA allows for better advantage estimates, effectively shortening the learning horizon. Experimental results demonstrate that policies derived from OTA significantly outperform existing methods on complex tasks, showcasing its effectiveness in offline GCRL settings."
                },
                "zh": {
                    "title": "é€‰é¡¹æ„ŸçŸ¥æ—¶é—´æŠ½è±¡å€¼å­¦ä¹ æå‡å¼ºåŒ–å­¦ä¹ è¡¨ç°",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºé€‰é¡¹æ„ŸçŸ¥æ—¶é—´æŠ½è±¡å€¼å­¦ä¹ ï¼ˆOTAï¼‰çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨æ”¹å–„ç¦»çº¿ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ï¼ˆGCRLï¼‰åœ¨é•¿æ—¶é—´ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œé«˜å±‚ç­–ç•¥åœ¨ç”Ÿæˆé€‚å½“å­ç›®æ ‡æ–¹é¢å­˜åœ¨ç“¶é¢ˆï¼Œå¯¼è‡´ä¼˜åŠ¿ä¿¡å·ä¸å‡†ç¡®ã€‚OTAé€šè¿‡å°†æ—¶é—´æŠ½è±¡å¼•å…¥æ—¶é—´å·®åˆ†å­¦ä¹ è¿‡ç¨‹ï¼Œä¼˜åŒ–äº†ä»·å€¼å‡½æ•°ï¼Œä»è€Œæä¾›æ›´æ¸…æ™°çš„ä¼˜åŠ¿ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨OTAå€¼å‡½æ•°æå–çš„é«˜å±‚ç­–ç•¥åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.20225",
            "title": "FLAME-MoE: A Transparent End-to-End Research Platform for\n  Mixture-of-Experts Language Models",
            "url": "https://huggingface.co/papers/2505.20225",
            "abstract": "FLAME-MoE is an open-source research suite for MoE architectures in LLMs, providing tools to investigate scaling, routing, and expert behavior with reproducible experiments.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent large language models such as Gemini-1.5, DeepSeek-V3, and Llama-4 increasingly adopt Mixture-of-Experts (MoE) architectures, which offer strong efficiency-performance trade-offs by activating only a fraction of the model per token. Yet academic researchers still lack a fully open, end-to-end MoE platform for investigating scaling, routing, and expert behavior. We release FLAME-MoE, a completely open-source research suite composed of seven decoder-only models, ranging from 38M to 1.7B active parameters, whose architecture--64 experts with top-8 gating and 2 shared experts--closely reflects modern production LLMs. All training data pipelines, scripts, logs, and checkpoints are publicly available to enable reproducible experimentation. Across six evaluation tasks, FLAME-MoE improves average accuracy by up to 3.4 points over dense baselines trained with identical FLOPs. Leveraging full training trace transparency, we present initial analyses showing that (i) experts increasingly specialize on distinct token subsets, (ii) co-activation matrices remain sparse, reflecting diverse expert usage, and (iii) routing behavior stabilizes early in training. All code, training logs, and model checkpoints are available at https://github.com/cmu-flame/FLAME-MoE.",
            "score": 0,
            "issue_id": 3981,
            "pub_date": "2025-05-26",
            "pub_date_card": {
                "ru": "26 Ğ¼Ğ°Ñ",
                "en": "May 26",
                "zh": "5æœˆ26æ—¥"
            },
            "hash": "92965f65b95b3e0e",
            "authors": [
                "Hao Kang",
                "Zichun Yu",
                "Chenyan Xiong"
            ],
            "affiliations": [
                "Foundation and Language Model Center Carnegie Mellon University",
                "Language Technologies Institute",
                "School of Computer Science"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.20225.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#open_source",
                    "#training",
                    "#architecture",
                    "#optimization"
                ],
                "emoji": "ğŸ”¥",
                "ru": {
                    "title": "FLAME-MoE: ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ»Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Mixture-of-Experts Ğ² LLM",
                    "desc": "FLAME-MoE - ÑÑ‚Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€ Mixture-of-Experts (MoE) Ğ² Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…. ĞĞ½ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸. ĞĞ°Ğ±Ğ¾Ñ€ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ ÑĞµĞ¼ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´ĞµĞºĞ¾Ğ´ĞµÑ€Ğ° Ñ 64 ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°Ğ¼Ğ¸, Ğ²ĞµÑ€Ñ…Ğ½Ğ¸Ğ¼Ğ¸ 8 Ğ³ĞµĞ¹Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ 2 Ğ¾Ğ±Ñ‰Ğ¸Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°Ğ¼Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¾Ñ‚Ñ€Ğ°Ğ¶Ğ°ĞµÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ½Ñ‹Ğµ LLM. FLAME-MoE Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¾ 3.4 Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğµ FLOP."
                },
                "en": {
                    "title": "Unlocking Efficiency in Language Models with FLAME-MoE",
                    "desc": "FLAME-MoE is an open-source research suite designed for exploring Mixture-of-Experts (MoE) architectures in large language models (LLMs). It provides a comprehensive platform for researchers to study scaling, routing, and expert behavior through reproducible experiments. The suite includes seven decoder-only models with varying active parameters, closely mimicking modern LLMs, and offers full transparency of training data and processes. Initial analyses indicate that experts specialize in distinct token subsets, maintain sparse co-activation matrices, and exhibit stable routing behavior early in training, leading to improved accuracy over dense baselines."
                },
                "zh": {
                    "title": "FLAME-MoEï¼šæ¢ç´¢æ··åˆä¸“å®¶æ¶æ„çš„å¼€æºå¹³å°",
                    "desc": "FLAME-MoEæ˜¯ä¸€ä¸ªå¼€æºçš„ç ”ç©¶å¥—ä»¶ï¼Œä¸“æ³¨äºæ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¶æ„åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„åº”ç”¨ã€‚è¯¥å¹³å°æä¾›äº†å·¥å…·æ¥ç ”ç©¶æ¨¡å‹çš„æ‰©å±•æ€§ã€è·¯ç”±å’Œä¸“å®¶è¡Œä¸ºï¼Œå¹¶æ”¯æŒå¯é‡å¤çš„å®éªŒã€‚FLAME-MoEåŒ…å«ä¸ƒä¸ªä»…è§£ç å™¨æ¨¡å‹ï¼Œå‚æ•°èŒƒå›´ä»3800ä¸‡åˆ°17äº¿ï¼Œæ¶æ„è®¾è®¡ä¸ç°ä»£ç”Ÿäº§LLMsç›¸ä¼¼ã€‚é€šè¿‡å…­ä¸ªè¯„ä¼°ä»»åŠ¡ï¼ŒFLAME-MoEåœ¨ä¸ç›¸åŒFLOPsçš„å¯†é›†åŸºçº¿ç›¸æ¯”ï¼Œå¹³å‡å‡†ç¡®ç‡æé«˜äº†æœ€å¤š3.4ä¸ªç™¾åˆ†ç‚¹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.16968",
            "title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark",
            "url": "https://huggingface.co/papers/2505.16968",
            "abstract": "We introduce CASS, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA leftrightarrow HIP) and assembly-level (Nvidia SASS leftrightarrow AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the CASS family of domain-specific language models, achieving 95% source translation accuracy and 37.5% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce CASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation. Dataset and benchmark are on https://huggingface.co/datasets/MBZUAI/cass{blue{HuggingFace}}, with code at https://github.com/GustavoStahl/CASS{blue{GitHub}}.",
            "score": 0,
            "issue_id": 3989,
            "pub_date": "2025-05-22",
            "pub_date_card": {
                "ru": "22 Ğ¼Ğ°Ñ",
                "en": "May 22",
                "zh": "5æœˆ22æ—¥"
            },
            "hash": "a069288c85761286",
            "authors": [
                "Ahmed Heakl",
                "Sarim Hashmi",
                "Gustavo Bertolo Stahl",
                "Seung Hun Eddie Han",
                "Salman Khan",
                "Abdulrahman Mahmoud"
            ],
            "affiliations": [
                "Australian National University",
                "MBZUAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.16968.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#low_resource",
                    "#benchmark",
                    "#open_source"
                ],
                "emoji": "ğŸ”„",
                "ru": {
                    "title": "CASS: Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² ĞºÑ€Ğ¾ÑÑ-Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¸Ğ»ÑÑ†Ğ¸Ğ¸ GPU-ĞºĞ¾Ğ´Ğ°",
                    "desc": "CASS - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ²Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ ĞºÑ€Ğ¾ÑÑ-Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ¹ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¸Ğ»ÑÑ†Ğ¸Ğ¸ GPU-ĞºĞ¾Ğ´Ğ°, Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹ ĞºĞ°Ğº ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ° (CUDA â†” HIP), Ñ‚Ğ°Ğº Ğ¸ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ°ÑÑĞµĞ¼Ğ±Ğ»ĞµÑ€Ğ° (Nvidia SASS â†” AMD RDNA3). ĞĞ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ 70 Ñ‚Ñ‹ÑÑÑ‡ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€ ĞºĞ¾Ğ´Ğ° Ğ´Ğ»Ñ Ñ…Ğ¾ÑÑ‚Ğ° Ğ¸ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ°, Ñ‡Ñ‚Ğ¾ Ñ€ĞµÑˆĞ°ĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ¾Ğ³Ğ¾ GPU-ĞºĞ¾Ğ´Ğ°. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ CASS, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ° ÑÑ‚Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ 95% Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞ»ÑÑ†Ğ¸Ğ¸ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ° Ğ¸ 37.5% Ğ´Ğ»Ñ Ğ°ÑÑĞµĞ¼Ğ±Ğ»ĞµÑ€Ğ°, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ğ»Ğ¸ CASS-Bench - ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ² 16 GPU-Ğ´Ğ¾Ğ¼ĞµĞ½Ğ°Ñ…."
                },
                "en": {
                    "title": "CASS: Bridging GPU Code Across Architectures",
                    "desc": "CASS is a groundbreaking dataset and model suite designed for translating GPU code between different architectures, specifically CUDA and HIP at the source level, and Nvidia SASS and AMD RDNA3 at the assembly level. It includes 70,000 verified code pairs, which helps improve the portability of low-level GPU code. The CASS models achieve impressive translation accuracies of 95% for source code and 37.5% for assembly code, outperforming existing commercial solutions. Additionally, the generated code maintains native performance in over 85% of cases, and the CASS-Bench provides a comprehensive evaluation framework for testing across various GPU domains."
                },
                "zh": {
                    "title": "CASSï¼šè·¨æ¶æ„GPUä»£ç è½¬è¯‘çš„çªç ´æ€§è¿›å±•",
                    "desc": "æˆ‘ä»¬ä»‹ç»äº†CASSï¼Œè¿™æ˜¯é¦–ä¸ªå¤§è§„æ¨¡çš„æ•°æ®é›†å’Œæ¨¡å‹å¥—ä»¶ï¼Œä¸“æ³¨äºè·¨æ¶æ„GPUä»£ç è½¬è¯‘ï¼Œæ¶µç›–æºä»£ç çº§ï¼ˆCUDAä¸HIPä¹‹é—´ï¼‰å’Œæ±‡ç¼–çº§ï¼ˆNvidia SASSä¸AMD RDNA3ä¹‹é—´ï¼‰çš„è½¬æ¢ã€‚è¯¥æ•°æ®é›†åŒ…å«70,000å¯¹ç»è¿‡éªŒè¯çš„ä»£ç å¯¹ï¼Œè§£å†³äº†ä½çº§GPUä»£ç å¯ç§»æ¤æ€§çš„é‡è¦é—®é¢˜ã€‚åˆ©ç”¨è¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬è®­ç»ƒäº†CASSç³»åˆ—ç‰¹å®šé¢†åŸŸè¯­è¨€æ¨¡å‹ï¼Œå®ç°äº†95%çš„æºä»£ç ç¿»è¯‘å‡†ç¡®ç‡å’Œ37.5%çš„æ±‡ç¼–ç¿»è¯‘å‡†ç¡®ç‡ï¼Œæ˜¾è‘—è¶…è¶Šäº†å•†ä¸šåŸºå‡†å¦‚GPT-4oã€Claudeå’ŒHipifyã€‚æˆ‘ä»¬çš„ç”Ÿæˆä»£ç åœ¨è¶…è¿‡85%çš„æµ‹è¯•æ¡ˆä¾‹ä¸­ä¸åŸç”Ÿæ€§èƒ½ç›¸åŒ¹é…ï¼Œä¿æŒäº†è¿è¡Œæ—¶å’Œå†…å­˜è¡Œä¸ºçš„ä¸€è‡´æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14071",
            "title": "Textual Steering Vectors Can Improve Visual Understanding in Multimodal\n  Large Language Models",
            "url": "https://huggingface.co/papers/2505.14071",
            "abstract": "Steering methods have emerged as effective and targeted tools for guiding large language models' (LLMs) behavior without modifying their parameters. Multimodal large language models (MLLMs), however, do not currently enjoy the same suite of techniques, due in part to their recency and architectural diversity. Inspired by this gap, we investigate whether MLLMs can be steered using vectors derived from their text-only LLM backbone, via sparse autoencoders (SAEs), mean shift, and linear probing. We find that text-derived steering consistently enhances multimodal accuracy across diverse MLLM architectures and visual tasks. In particular, mean shift boosts spatial relationship accuracy on CV-Bench by up to +7.3% and counting accuracy by up to +3.3%, outperforming prompting and exhibiting strong generalization to out-of-distribution datasets. These results highlight textual steering vectors as a powerful, efficient mechanism for enhancing grounding in MLLMs with minimal additional data collection and computational overhead.",
            "score": 0,
            "issue_id": 3987,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 Ğ¼Ğ°Ñ",
                "en": "May 20",
                "zh": "5æœˆ20æ—¥"
            },
            "hash": "5cc7321d9950a5db",
            "authors": [
                "Woody Haosheng Gan",
                "Deqing Fu",
                "Julian Asilis",
                "Ollie Liu",
                "Dani Yogatama",
                "Vatsal Sharan",
                "Robin Jia",
                "Willie Neiswanger"
            ],
            "affiliations": [
                "University of Southern California"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14071.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#training",
                    "#cv",
                    "#optimization",
                    "#multimodal"
                ],
                "emoji": "ğŸ§­",
                "ru": {
                    "title": "Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ ĞºĞ°Ğº ĞºĞ¾Ğ¼Ğ¿Ğ°Ñ Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ (steering) Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM) Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ², Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¸Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ°Ğ²Ñ‚Ğ¾ÑĞ½ĞºĞ¾Ğ´ĞµÑ€Ñ‹, ÑĞ´Ğ²Ğ¸Ğ³ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¸ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğµ Ğ·Ğ¾Ğ½Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ MLLM Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‡ĞµÑ‚Ğ° Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ­Ñ‚Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ±ĞµĞ· Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."
                },
                "en": {
                    "title": "Enhancing MLLM Performance with Text-Derived Steering Vectors",
                    "desc": "This paper explores how to steer multimodal large language models (MLLMs) using techniques derived from text-only language models. The authors utilize sparse autoencoders, mean shift, and linear probing to create steering vectors that improve the performance of MLLMs on various visual tasks. Their findings show that these text-derived steering methods significantly enhance accuracy, particularly in spatial relationships and counting tasks, compared to traditional prompting methods. Overall, the study demonstrates that textual steering vectors can effectively improve MLLM performance with minimal extra data and computational costs."
                },
                "zh": {
                    "title": "æ–‡æœ¬å¯¼å‘ï¼šæå‡å¤šæ¨¡æ€æ¨¡å‹çš„å¼ºå¤§å·¥å…·",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¦‚ä½•é€šè¿‡æ–‡æœ¬å¯¼å‘å‘é‡æ¥å¼•å¯¼å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¡Œä¸ºï¼Œè€Œæ— éœ€ä¿®æ”¹å…¶å‚æ•°ã€‚æˆ‘ä»¬ä½¿ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰ã€å‡å€¼æ¼‚ç§»å’Œçº¿æ€§æ¢æµ‹ç­‰æŠ€æœ¯ï¼Œå‘ç°æ–‡æœ¬å¯¼å‘çš„å¼•å¯¼æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜å¤šæ¨¡æ€æ¨¡å‹åœ¨ä¸åŒè§†è§‰ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ã€‚ç‰¹åˆ«æ˜¯ï¼Œå‡å€¼æ¼‚ç§»åœ¨CV-Benchä¸Šæå‡äº†ç©ºé—´å…³ç³»å‡†ç¡®æ€§é«˜è¾¾7.3%ï¼Œå¹¶ä¸”åœ¨è®¡æ•°å‡†ç¡®æ€§ä¸Šæå‡äº†3.3%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ–‡æœ¬å¯¼å‘å‘é‡æ˜¯ä¸€ç§å¼ºå¤§ä¸”é«˜æ•ˆçš„æœºåˆ¶ï¼Œå¯ä»¥åœ¨æœ€å°çš„æ•°æ®æ”¶é›†å’Œè®¡ç®—å¼€é”€ä¸‹å¢å¼ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºç¡€èƒ½åŠ›ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-27.html",
    "link_next": "2025-05-29.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "27.05",
        "en": "05/27",
        "zh": "5æœˆ27æ—¥"
    },
    "short_date_next": {
        "ru": "29.05",
        "en": "05/29",
        "zh": "5æœˆ29æ—¥"
    },
    "categories": {
        "#dataset": 27,
        "#data": 12,
        "#benchmark": 29,
        "#agents": 9,
        "#cv": 4,
        "#rl": 17,
        "#rlhf": 12,
        "#rag": 0,
        "#plp": 0,
        "#inference": 7,
        "#3d": 2,
        "#audio": 3,
        "#video": 2,
        "#multimodal": 19,
        "#math": 10,
        "#multilingual": 5,
        "#architecture": 12,
        "#healthcare": 2,
        "#training": 41,
        "#robotics": 3,
        "#agi": 3,
        "#games": 4,
        "#interpretability": 9,
        "#reasoning": 35,
        "#transfer_learning": 4,
        "#graphs": 0,
        "#ethics": 3,
        "#security": 5,
        "#optimization": 37,
        "#survey": 5,
        "#diffusion": 4,
        "#alignment": 8,
        "#story_generation": 0,
        "#hallucinations": 3,
        "#long_context": 1,
        "#synthetic": 5,
        "#machine_translation": 1,
        "#leakage": 2,
        "#open_source": 17,
        "#small_models": 1,
        "#science": 5,
        "#low_resource": 4,
        "#cybersecurity": 1
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ã€‚ä»¥å‰ä¸»è¦é€šè¿‡å¢åŠ å‚æ•°æ•°é‡æ¥æé«˜æ€§èƒ½ï¼Œä½†ç°åœ¨ç¡¬ä»¶é™åˆ¶ä½¿å¾—è‡ªæ³¨æ„åŠ›æˆæœ¬æˆä¸ºä¸»è¦ç“¶é¢ˆã€‚æ–‡ç« æå‡ºç ”ç©¶é‡ç‚¹åº”ä»æ¨¡å‹å‹ç¼©è½¬å‘æ•°æ®å‹ç¼©ï¼Œç‰¹åˆ«æ˜¯ä»¤ç‰Œå‹ç¼©ã€‚ä»¤ç‰Œå‹ç¼©å¯ä»¥å‡å°‘è®­ç»ƒæˆ–æ¨ç†è¿‡ç¨‹ä¸­çš„ä»¤ç‰Œæ•°é‡ï¼Œä»è€Œæé«˜AIæ•ˆç‡ã€‚ä½œè€…åˆ†æäº†é•¿ä¸Šä¸‹æ–‡AIçš„å‘å±•ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ•°å­¦æ¡†æ¶ï¼Œå¹¶æ¢è®¨äº†ä»¤ç‰Œå‹ç¼©çš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚",
        "title": "Shifting AI Efficiency From Model-Centric to Data-Centric Compression",
        "pinyin": "è¿™ç¯‡æ–‡ç« è®¨è®ºäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ã€‚ä»¥å‰ä¸»è¦é€šè¿‡å¢åŠ å‚æ•°æ•°é‡æ¥æé«˜æ€§èƒ½ï¼Œä½†ç°åœ¨ç¡¬ä»¶é™åˆ¶ä½¿å¾—è‡ªæ³¨æ„åŠ›æˆæœ¬æˆä¸ºä¸»è¦ç“¶é¢ˆã€‚æ–‡ç« æå‡ºç ”ç©¶é‡ç‚¹åº”ä»æ¨¡å‹å‹ç¼©è½¬å‘æ•°æ®å‹ç¼©ï¼Œç‰¹åˆ«æ˜¯ä»¤ç‰Œå‹ç¼©ã€‚ä»¤ç‰Œå‹ç¼©å¯ä»¥å‡å°‘è®­ç»ƒæˆ–æ¨ç†è¿‡ç¨‹ä¸­çš„ä»¤ç‰Œæ•°é‡ï¼Œä»è€Œæé«˜AIæ•ˆç‡ã€‚ä½œè€…åˆ†æäº†é•¿ä¸Šä¸‹æ–‡AIçš„å‘å±•ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ•°å­¦æ¡†æ¶ï¼Œå¹¶æ¢è®¨äº†ä»¤ç‰Œå‹ç¼©çš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\n\nZhÃ¨ piÄn wÃ©nzhÄng tÇolÃ¹n le dÃ xÃ­ng yÇ”yÃ¡n mÃ³xÃ­ng hÃ© duÅ mÃ³shÃ¬ yÇ”yÃ¡n mÃ³xÃ­ng de kuÃ isÃ¹ fÄzhÇn. YÇqiÃ¡n zhÇ”yÃ o tÅngguÃ² zÄ“ngjiÄ cÄnshÃ¹ shÃ¹liÃ ng lÃ¡i tÃ­gÄo xÃ¬ngnÃ©ng, dÃ n xiÃ nzÃ i yÃ¬ngjiÃ n xiÃ nzhÃ¬ shÇdÃ© zÃ¬ zhÃ¹yÃ¬lÃ¬ chÃ©ngbÄ›n chÃ©ngwÃ©i zhÇ”yÃ o pÃ­ngtÇng. WÃ©nzhÄng tÃ­chÅ« yÃ¡njiÅ« zhÃ²ngdiÇn yÄ«ng cÃ³ng mÃ³xÃ­ng yÄsuÅ zhuÇnxiÃ ng shÃ¹jÃ¹ yÄsuÅ, tÃ¨biÃ© shÃ¬ lÃ¬ngpÃ¡i yÄsuÅ. LÃ¬ngpÃ¡i yÄsuÅ kÄ›yÇ jiÇnshÇo xÃ¹nliÃ n huÃ² tuÄ«lÇ guÃ²chÃ©ng zhÅng de lÃ¬ngpÃ¡i shÃ¹liÃ ng, cÃ³ng'Ã©r tÃ­gÄo AI xiÃ onÃ©ng. ZuÃ²zhÄ› fÄ“nxi le chÃ¡ng shÃ ngxÃ¬awÃ©nfÇ AI de fÄzhÇn, tÃ­chÅ« le yÄ«gÃ¨ tÇ’ngyÄ« de shÃ¹xuÃ© kuÃ ngjiÃ , bÃ¬ng tÃ ntÇo le lÃ¬ngpÃ¡i yÄsuÅ de yÅushÃ¬ hÃ© tiÇozhÃ n.",
        "vocab": "[\n    {\"word\": \"è®¨è®º\", \"pinyin\": \"tÇo lÃ¹n\", \"trans\": \"discuss\"},\n    {\"word\": \"å¤§å‹\", \"pinyin\": \"dÃ  xÃ­ng\", \"trans\": \"large-scale\"},\n    {\"word\": \"è¯­è¨€æ¨¡å‹\", \"pinyin\": \"yÇ” yÃ¡n mÃ³ xÃ­ng\", \"trans\": \"language model\"},\n    {\"word\": \"å¤šæ¨¡æ€\", \"pinyin\": \"duÅ mÃ³ tÃ i\", \"trans\": \"multimodal\"},\n    {\"word\": \"å¿«é€Ÿ\", \"pinyin\": \"kuÃ i sÃ¹\", \"trans\": \"rapid\"},\n    {\"word\": \"å‘å±•\", \"pinyin\": \"fÄ zhÇn\", \"trans\": \"development\"},\n    {\"word\": \"ä¸»è¦\", \"pinyin\": \"zhÇ” yÃ o\", \"trans\": \"main\"},\n    {\"word\": \"é€šè¿‡\", \"pinyin\": \"tÅng guÃ²\", \"trans\": \"through\"},\n    {\"word\": \"å¢åŠ \", \"pinyin\": \"zÄ“ng jiÄ\", \"trans\": \"increase\"},\n    {\"word\": \"å‚æ•°\", \"pinyin\": \"cÄn shÇ”\", \"trans\": \"parameter\"},\n    {\"word\": \"æ•°é‡\", \"pinyin\": \"shÃ¹ liÃ ng\", \"trans\": \"quantity\"},\n    {\"word\": \"æé«˜\", \"pinyin\": \"tÃ­ gÄo\", \"trans\": \"improve\"},\n    {\"word\": \"æ€§èƒ½\", \"pinyin\": \"xÃ¬ng nÃ©ng\", \"trans\": \"performance\"},\n    {\"word\": \"ç¡¬ä»¶\", \"pinyin\": \"yÃ¬ng jiÃ n\", \"trans\": \"hardware\"},\n    {\"word\": \"é™åˆ¶\", \"pinyin\": \"xiÃ n zhÃ¬\", \"trans\": \"limit\"},\n    {\"word\": \"è‡ªæ³¨æ„åŠ›\", \"pinyin\": \"zÃ¬ zhÃ¹ yÃ¬ lÃ¬\", \"trans\": \"self-attention\"},\n    {\"word\": \"æˆæœ¬\", \"pinyin\": \"chÃ©ng bÄ›n\", \"trans\": \"cost\"},\n    {\"word\": \"ç“¶é¢ˆ\", \"pinyin\": \"pÃ­ng lÃ³ng\", \"trans\": \"bottleneck\"},\n    {\"word\": \"ç ”ç©¶\", \"pinyin\": \"yÃ¡n jiÅ«\", \"trans\": \"research\"},\n    {\"word\": \"é‡ç‚¹\", \"pinyin\": \"zhÃ²ng diÇn\", \"trans\": \"focus\"},\n    {\"word\": \"æ¨¡å‹å‹ç¼©\", \"pinyin\": \"mÃ³ xÃ­ng yÄ suÅ\", \"trans\": \"model compression\"},\n    {\"word\": \"è½¬å‘\", \"pinyin\": \"zhuÇn xiÃ ng\", \"trans\": \"turn to\"},\n    {\"word\": \"æ•°æ®å‹ç¼©\", \"pinyin\": \"shÃ¹ jÃ¹ yÄ suÅ\", \"trans\": \"data compression\"},\n    {\"word\": \"ä»¤ç‰Œ\", \"pinyin\": \"lÃ¬ng pÃ¡i\", \"trans\": \"token\"},\n    {\"word\": \"å‹ç¼©\", \"pinyin\": \"yÄ suÅ\", \"trans\": \"compression\"},\n    {\"word\": \"å‡å°‘\", \"pinyin\": \"jiÇn shÇo\", \"trans\": \"reduce\"},\n    {\"word\": \"è®­ç»ƒ\", \"pinyin\": \"xÃ¹n liÃ n\", \"trans\": \"training\"},\n    {\"word\": \"æ¨ç†\", \"pinyin\": \"tuÄ« lÇ\", \"trans\": \"inference\"},\n    {\"word\": \"è¿‡ç¨‹\", \"pinyin\": \"guÃ² chÃ©ng\", \"trans\": \"process\"},\n    {\"word\": \"æ•ˆç‡\", \"pinyin\": \"xiÃ o lÇœ\", \"trans\": \"efficiency\"},\n    {\"word\": \"ä½œè€…\", \"pinyin\": \"zuÃ² zhÄ›\", \"trans\": \"author\"},\n    {\"word\": \"åˆ†æ\", \"pinyin\": \"fÄ“n xÄ«\", \"trans\": \"analyze\"},\n    {\"word\": \"é•¿ä¸Šä¸‹æ–‡\", \"pinyin\": \"chÃ¡ng shÃ ng xiÃ  wÃ©n\", \"trans\": \"long context\"},\n    {\"word\": \"æ•°å­¦æ¡†æ¶\", \"pinyin\": \"shÃ¹ xuÃ© kuÃ ng jiÃ \", \"trans\": \"mathematical framework\"},\n    {\"word\": \"æ¢è®¨\", \"pinyin\": \"tÃ n tÇo\", \"trans\": \"explore\"},\n    {\"word\": \"ä¼˜åŠ¿\", \"pinyin\": \"yÅu shÃ¬\", \"trans\": \"advantage\"},\n    {\"word\": \"æŒ‘æˆ˜\", \"pinyin\": \"tiÇo zhÃ n\", \"trans\": \"challenge\"}\n]",
        "trans": "This article discusses the rapid development of large language models and multimodal language models. Previously, performance was mainly improved by increasing the number of parameters, but now hardware limitations make the cost of self-attention a major bottleneck. The article proposes that the focus of research should shift from model compression to data compression, particularly token compression. Token compression can reduce the number of tokens during training or inference, thereby improving AI efficiency. The author analyzes the development of long-context AI, proposes a unified mathematical framework, and explores the advantages and challenges of token compression.",
        "update_ts": "2025-05-27 09:12"
    }
}