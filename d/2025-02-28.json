{
    "date": {
        "ru": "28 февраля",
        "en": "February 28",
        "zh": "2月28日"
    },
    "time_utc": "2025-02-28 06:14",
    "weekday": 4,
    "issue_id": 2458,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.19613",
            "title": "Self-rewarding correction for mathematical reasoning",
            "url": "https://huggingface.co/papers/2502.19613",
            "abstract": "We study self-rewarding reasoning large language models (LLMs), which can simultaneously generate step-by-step reasoning and evaluate the correctness of their outputs during the inference time-without external feedback. This integrated approach allows a single model to independently guide its reasoning process, offering computational advantages for model deployment. We particularly focus on the representative task of self-correction, where models autonomously detect errors in their responses, revise outputs, and decide when to terminate iterative refinement loops. To enable this, we propose a two-staged algorithmic framework for constructing self-rewarding reasoning models using only self-generated data. In the first stage, we employ sequential rejection sampling to synthesize long chain-of-thought trajectories that incorporate both self-rewarding and self-correction mechanisms. Fine-tuning models on these curated data allows them to learn the patterns of self-rewarding and self-correction. In the second stage, we further enhance the models' ability to assess response accuracy and refine outputs through reinforcement learning with rule-based signals. Experiments with Llama-3 and Qwen-2.5 demonstrate that our approach surpasses intrinsic self-correction capabilities and achieves performance comparable to systems that rely on external reward models.",
            "score": 38,
            "issue_id": 2455,
            "pub_date": "2025-02-26",
            "pub_date_card": {
                "ru": "26 февраля",
                "en": "February 26",
                "zh": "2月26日"
            },
            "hash": "e2535efc8aadcc9d",
            "authors": [
                "Wei Xiong",
                "Hanning Zhang",
                "Chenlu Ye",
                "Lichang Chen",
                "Nan Jiang",
                "Tong Zhang"
            ],
            "affiliations": [
                "University of Illinois Urbana-Champaign",
                "University of Maryland, College Park"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.19613.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#inference",
                    "#optimization",
                    "#rl"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Самокорректирующиеся языковые модели: новый шаг к автономному ИИ",
                    "desc": "Исследователи изучают языковые модели с самовознаграждением, способные генерировать пошаговые рассуждения и оценивать их корректность без внешней обратной связи. Предложен двухэтапный алгоритмический подход для создания таких моделей, использующий только самогенерируемые данные. На первом этапе применяется последовательная выборка с отклонением для синтеза длинных цепочек рассуждений, включающих механизмы самовознаграждения и самокоррекции. Второй этап усиливает способность моделей оценивать точность ответов и улучшать выходные данные с помощью обучения с подкреплением."
                },
                "en": {
                    "title": "Empowering LLMs with Self-Rewarding Reasoning and Self-Correction",
                    "desc": "This paper explores self-rewarding reasoning in large language models (LLMs), enabling them to generate and evaluate their own reasoning without needing outside feedback. The focus is on self-correction, where models can identify and fix their mistakes independently. The authors introduce a two-stage framework that first uses sequential rejection sampling to create data for training the models on self-rewarding and self-correction. The second stage enhances the models' accuracy assessment and output refinement through reinforcement learning, showing that their method outperforms traditional self-correction techniques."
                },
                "zh": {
                    "title": "自我奖励推理：模型的独立思考与修正",
                    "desc": "我们研究了自我奖励推理的大型语言模型（LLMs），这些模型能够在推理过程中同时生成逐步推理并评估输出的正确性，而无需外部反馈。这种集成方法使得单一模型能够独立引导其推理过程，为模型部署提供了计算优势。我们特别关注自我修正的任务，模型能够自主检测响应中的错误，修正输出，并决定何时终止迭代优化循环。为此，我们提出了一种两阶段的算法框架，利用自生成的数据构建自我奖励推理模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20082",
            "title": "LongRoPE2: Near-Lossless LLM Context Window Scaling",
            "url": "https://huggingface.co/papers/2502.20082",
            "abstract": "LongRoPE2 is a novel approach that extends the effective context window of pre-trained large language models (LLMs) to the target length, while preserving the performance on the original shorter context window. This is achieved by three contributions: (1) a hypothesis that insufficient training in higher RoPE dimensions contributes to the persistent out-of-distribution (OOD) issues observed in existing methods; (2) an effective RoPE rescaling algorithm that adopts evolutionary search guided by \"needle-driven\" perplexity to address the insufficient training problem; (3) a mixed context window training approach that fine-tunes model weights to adopt rescaled RoPE for long-context sequences while preserving the short-context performance with the original RoPE. Extensive experiments on LLaMA3-8B and Phi3-mini-3.8B across various benchmarks validate the hypothesis and demonstrate the effectiveness of LongRoPE2. Remarkably, LongRoPE2 extends LLaMA3-8B to achieve a 128K effective context length while retaining over 98.5% of short-context performance, using only 10B tokens -- 80x fewer than Meta's approach, which fails to reach the target effective context length. Code will be available at https://github.com/microsoft/LongRoPE.",
            "score": 14,
            "issue_id": 2456,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "ee15387b2b27d4c6",
            "authors": [
                "Ning Shang",
                "Li Lyna Zhang",
                "Siyuan Wang",
                "Gaokai Zhang",
                "Gilsinia Lopez",
                "Fan Yang",
                "Weizhu Chen",
                "Mao Yang"
            ],
            "affiliations": [
                "Microsoft",
                "Shanghai Jiao Tong University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20082.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#benchmark",
                    "#long_context"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "Расширение контекста языковых моделей без потери качества",
                    "desc": "LongRoPE2 - это новый подход к расширению эффективного контекстного окна предобученных больших языковых моделей (LLM) до целевой длины. Метод основан на гипотезе о недостаточном обучении в высших измерениях RoPE и использует эволюционный поиск для эффективного масштабирования RoPE. LongRoPE2 применяет смешанное обучение на контекстах разной длины для адаптации весов модели. Эксперименты показали, что LongRoPE2 может расширить контекст LLaMA3-8B до 128 тысяч токенов, сохраняя производительность на коротких контекстах."
                },
                "en": {
                    "title": "Extending Context Length Without Compromise",
                    "desc": "LongRoPE2 is a new method that enhances the context length of large language models (LLMs) while maintaining their performance on shorter contexts. It introduces a hypothesis that inadequate training in higher dimensions of RoPE leads to out-of-distribution issues in existing models. The method employs a RoPE rescaling algorithm that uses evolutionary search to improve training effectiveness. Additionally, it utilizes a mixed context window training strategy to fine-tune model weights, allowing for long-context sequences without sacrificing short-context performance."
                },
                "zh": {
                    "title": "扩展上下文窗口，保持性能的创新方法",
                    "desc": "LongRoPE2是一种新方法，旨在扩展预训练大型语言模型（LLMs）的有效上下文窗口，同时保持在原始较短上下文窗口上的性能。该方法通过三个贡献实现：首先，提出了一个假设，认为在更高RoPE维度上的训练不足导致了现有方法中持续存在的分布外（OOD）问题；其次，提出了一种有效的RoPE重缩放算法，通过“针驱动”的困惑度指导的进化搜索来解决训练不足的问题；最后，采用混合上下文窗口训练方法，微调模型权重以适应长上下文序列的重缩放RoPE，同时保持短上下文的原始RoPE性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.16645",
            "title": "CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale",
            "url": "https://huggingface.co/papers/2502.16645",
            "abstract": "Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: https://github.com/Lucky-voyage/Code-Sync.",
            "score": 8,
            "issue_id": 2456,
            "pub_date": "2025-02-23",
            "pub_date_card": {
                "ru": "23 февраля",
                "en": "February 23",
                "zh": "2月23日"
            },
            "hash": "616cf3f6f2ab1d17",
            "authors": [
                "Chenlong Wang",
                "Zhaoyang Chu",
                "Zhengxiang Cheng",
                "Xuyi Yang",
                "Kaiyue Qiu",
                "Yao Wan",
                "Zhou Zhao",
                "Xuanhua Shi",
                "Dongping Chen"
            ],
            "affiliations": [
                "Huazhong University of Science and Technology",
                "Wuhuan University",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.16645.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#open_source",
                    "#data",
                    "#optimization",
                    "#benchmark"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Синхронизация языковых моделей с эволюцией кода",
                    "desc": "Статья представляет CODESYNC - инструмент для выявления устаревших паттернов кода и сбора обновлений знаний о коде из сторонних библиотек Python в реальном времени. На основе CODESYNC разработан CODESYNCBENCH - комплексный бенчмарк для оценки способности моделей большого языка (LLM) синхронизироваться с эволюцией кода, охватывающий реальные обновления для 220 API из шести библиотек Python. Эксперименты на 14 современных LLM показали, что они испытывают трудности с динамической эволюцией кода даже при поддержке продвинутых методов обновления знаний. Авторы полагают, что их бенчмарк может стать основой для разработки более эффективных методов обновления знаний о коде в реальном времени."
                },
                "en": {
                    "title": "CODESYNC: Keeping Code Knowledge Fresh for LLMs",
                    "desc": "This paper addresses the limitations of Large Language Models (LLMs) in adapting to changes in third-party library APIs, which can lead to outdated or inefficient code. It introduces CODESYNC, a data engine designed to identify outdated code patterns and gather real-time updates from Python libraries. Additionally, the authors present CODESYNCBENCH, a benchmark for evaluating LLMs' performance in keeping up with code evolution, featuring 3,300 test cases across various tasks. The findings indicate that even advanced LLMs struggle with dynamic code changes, highlighting the need for improved methods for real-time code knowledge updating."
                },
                "zh": {
                    "title": "实时代码知识更新的基准测试",
                    "desc": "大型语言模型（LLMs）在软件工程中表现出色，但在适应不断变化的代码知识方面面临挑战，尤其是第三方库API的频繁更新。由于静态的预训练数据集，这种限制常常导致生成的代码无法执行或实现的安全性和效率不佳。为了解决这个问题，本文提出了CODESYNC，一个用于识别过时代码模式并收集来自Python第三方库的实时代码知识更新的数据引擎。基于CODESYNC，我们开发了CODESYNCBENCH，一个全面的基准测试，用于评估LLMs在代码演变中的同步能力，涵盖了来自六个Python库的220个API的真实更新。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20395",
            "title": "R2-T2: Re-Routing in Test-Time for Multimodal Mixture-of-Experts",
            "url": "https://huggingface.co/papers/2502.20395",
            "abstract": "In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks. The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input. However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample. To bridge the gap, we propose a novel and efficient method \"Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample. We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces. R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters.",
            "score": 8,
            "issue_id": 2456,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "e8862deee761c4d0",
            "authors": [
                "Zhongyang Li",
                "Ziyue Li",
                "Tianyi Zhou"
            ],
            "affiliations": [
                "Johns Hopkins University",
                "University of Maryland, College Park"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20395.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#training",
                    "#architecture",
                    "#optimization",
                    "#benchmark"
                ],
                "emoji": "🔀",
                "ru": {
                    "title": "Оптимизация маршрутизации на лету для повышения эффективности мультимодальных моделей",
                    "desc": "В статье представлен метод Re-Routing in Test-Time (R2-T2) для улучшения работы мультимодальных моделей на основе смеси экспертов (MoE). Авторы обнаружили, что маршрутизатор, обученный по принципу end-to-end, не всегда оптимально распределяет веса между экспертами для тестовых образцов. R2-T2 оптимизирует вектор весов маршрутизации во время тестирования, приближая его к векторам правильно предсказанных соседних образцов. Предложены три стратегии R2-T2 с различными целями оптимизации и пространствами поиска соседей."
                },
                "en": {
                    "title": "Optimizing Multimodal Performance with Test-Time Re-Routing",
                    "desc": "This paper addresses the performance gap in large multimodal models (LMMs) when processing non-language data compared to large language models (LLMs). The authors introduce a mixture-of-experts (MoE) approach to enhance the vision encoder, allowing for richer and more diverse representations. They identify that the router, which determines how to mix these expert representations, often fails to optimize routing weights effectively during testing. To solve this, they propose a method called Re-Routing in Test-Time (R2-T2), which fine-tunes routing weights based on nearby correctly predicted samples, significantly boosting the performance of LMMs on various challenging tasks without retraining the base model."
                },
                "zh": {
                    "title": "提升多模态模型性能的新方法",
                    "desc": "在大型多模态模型（LMMs）中，视觉表示的感知能力通常不如大型语言模型（LLMs）的推理能力，这影响了LMMs在复杂任务上的表现。最近，通过用专家混合（MoE）替换视觉编码器，缓解了这一弱点，提供了丰富且多样的表示。我们发现，端到端训练的路由器并不总能为每个测试样本生成最佳的路由权重。为了解决这个问题，我们提出了一种新颖且高效的方法“测试时重新路由（R2-T2）”，通过在测试时优化路由权重向量，显著提升了LMMs在多样化任务基准上的表现。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20127",
            "title": "SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning",
            "url": "https://huggingface.co/papers/2502.20127",
            "abstract": "Mainstream issue-resolving frameworks predominantly rely on commercial models, leading to high costs and privacy concerns. Existing training approaches for issue resolving struggle with poor generalization and fail to fully leverage open-source development resources. We propose Subtask-oriented Reinforced Fine-Tuning (SoRFT), a novel training approach to enhance the issue resolving capability of LLMs. We decomposes issue resolving into structured subtasks: file localization, function localization, line localization, and code edit generation. SoRFT consists of two training stages: (1) rejection-sampled supervised fine-tuning, Chain of Thought (CoT) data is filtered using ground-truth before fine-tuning the LLM, and (2) rule-based reinforcement learning, which leverages PPO with ground-truth based rewards. We evaluate the SoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving state-of-the-art (SOTA) performance among open-source models (e.g., resolve 21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental results demonstrate that SoRFT significantly enhances issue-resolving performance, improves model generalization, and provides a cost-efficient alternative to commercial models.",
            "score": 3,
            "issue_id": 2456,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "ad848cf98c7468a7",
            "authors": [
                "Zexiong Ma",
                "Chao Peng",
                "Pengfei Gao",
                "Xiangxin Meng",
                "Yanzhen Zou",
                "Bing Xie"
            ],
            "affiliations": [
                "ByteDance",
                "School of Computer Science, Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20127.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#training",
                    "#rlhf",
                    "#rl",
                    "#optimization"
                ],
                "emoji": "🔧",
                "ru": {
                    "title": "SoRFT: Эффективное обучение ЯМ для автоматического исправления кода",
                    "desc": "Авторы предлагают новый подход к обучению языковых моделей для решения проблем в программном коде - Subtask-oriented Reinforced Fine-Tuning (SoRFT). Метод разбивает задачу на подзадачи: локализацию файла, функции и строки кода, а также генерацию исправлений. SoRFT включает два этапа обучения: тонкую настройку с отбором данных и обучение с подкреплением на основе правил. Эксперименты показывают, что SoRFT значительно улучшает способность моделей решать проблемы в коде и обеспечивает экономичную альтернативу коммерческим моделям."
                },
                "en": {
                    "title": "Enhancing Issue Resolution with SoRFT: A Cost-Effective Approach",
                    "desc": "This paper introduces Subtask-oriented Reinforced Fine-Tuning (SoRFT), a new method designed to improve the issue-resolving capabilities of large language models (LLMs). It breaks down the issue resolution process into specific subtasks, such as file and function localization, and code editing. The training process involves two stages: first, a supervised fine-tuning phase that uses filtered data, and second, a reinforcement learning phase that applies Proximal Policy Optimization (PPO) with rewards based on ground-truth data. The results show that models trained with SoRFT outperform existing open-source models, achieving state-of-the-art results while being more cost-effective and maintaining better privacy."
                },
                "zh": {
                    "title": "提升问题解决能力的新方法",
                    "desc": "本论文提出了一种新的训练方法，称为子任务导向强化微调（SoRFT），旨在提高大型语言模型（LLMs）在问题解决方面的能力。我们将问题解决分解为结构化的子任务，包括文件定位、功能定位、行定位和代码编辑生成。SoRFT包含两个训练阶段：首先是基于拒绝采样的监督微调，其次是基于规则的强化学习，利用基于真实数据的奖励进行训练。实验结果表明，SoRFT显著提升了问题解决性能，改善了模型的泛化能力，并为商业模型提供了一种成本效益高的替代方案。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20321",
            "title": "UniTok: A Unified Tokenizer for Visual Generation and Understanding",
            "url": "https://huggingface.co/papers/2502.20321",
            "abstract": "The representation disparity between visual generation and understanding imposes a critical gap in integrating these capabilities into a single framework. To bridge this gap, we introduce UniTok, a discrete visual tokenizer that encodes fine-grained details for generation while also capturing high-level semantics for understanding. Despite recent studies have shown that these objectives could induce loss conflicts in training, we reveal that the underlying bottleneck stems from limited representational capacity of discrete tokens. We address this by introducing multi-codebook quantization, which divides vector quantization with several independent sub-codebooks to expand the latent feature space, while avoiding training instability caused by overlarge codebooks. Our method significantly raises the upper limit of unified discrete tokenizers to match or even surpass domain-specific continuous tokenizers. For instance, UniTok achieves a remarkable rFID of 0.38 (versus 0.87 for SD-VAE) and a zero-shot accuracy of 78.6% (versus 76.2% for CLIP) on ImageNet. Our code is available at https://github.com/FoundationVision/UniTok.",
            "score": 2,
            "issue_id": 2457,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "1e65564c1594ef39",
            "authors": [
                "Chuofan Ma",
                "Yi Jiang",
                "Junfeng Wu",
                "Jihan Yang",
                "Xin Yu",
                "Zehuan Yuan",
                "Bingyue Peng",
                "Xiaojuan Qi"
            ],
            "affiliations": [
                "ByteDance Inc.",
                "Huazhong University of Science and Technology",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20321.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#architecture",
                    "#multimodal",
                    "#cv",
                    "#optimization"
                ],
                "emoji": "🖼️",
                "ru": {
                    "title": "UniTok: Единый токенизатор для генерации и понимания изображений",
                    "desc": "UniTok - это дискретный визуальный токенизатор, который объединяет возможности генерации и понимания изображений. Он использует мультикодовую квантизацию для расширения пространства латентных признаков, избегая при этом нестабильности обучения. UniTok превосходит специализированные непрерывные токенизаторы, достигая rFID 0.38 и точности zero-shot классификации 78.6% на ImageNet. Это решение преодолевает разрыв между визуальной генерацией и пониманием в единой модели."
                },
                "en": {
                    "title": "Bridging Visual Generation and Understanding with UniTok",
                    "desc": "This paper presents UniTok, a novel discrete visual tokenizer designed to improve the integration of visual generation and understanding. It addresses the challenges of representation disparity by using multi-codebook quantization, which enhances the capacity of discrete tokens without causing training instability. The method allows for better encoding of both fine-grained details and high-level semantics, leading to improved performance metrics. UniTok outperforms existing models, achieving higher accuracy and fidelity on tasks like image classification compared to traditional continuous tokenizers."
                },
                "zh": {
                    "title": "UniTok：统一视觉生成与理解的突破",
                    "desc": "本文提出了一种名为UniTok的离散视觉标记器，旨在解决视觉生成与理解之间的表示差异。UniTok能够编码细粒度的细节以进行生成，同时捕捉高层次的语义以便于理解。我们通过引入多代码本量化来扩展潜在特征空间，从而克服离散标记的表示能力限制。实验结果表明，UniTok在ImageNet上取得了显著的性能提升，超越了领域特定的连续标记器。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20126",
            "title": "FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute",
            "url": "https://huggingface.co/papers/2502.20126",
            "abstract": "Despite their remarkable performance, modern Diffusion Transformers are hindered by substantial resource requirements during inference, stemming from the fixed and large amount of compute needed for each denoising step. In this work, we revisit the conventional static paradigm that allocates a fixed compute budget per denoising iteration and propose a dynamic strategy instead. Our simple and sample-efficient framework enables pre-trained DiT models to be converted into flexible ones -- dubbed FlexiDiT -- allowing them to process inputs at varying compute budgets. We demonstrate how a single flexible model can generate images without any drop in quality, while reducing the required FLOPs by more than 40\\% compared to their static counterparts, for both class-conditioned and text-conditioned image generation. Our method is general and agnostic to input and conditioning modalities. We show how our approach can be readily extended for video generation, where FlexiDiT models generate samples with up to 75\\% less compute without compromising performance.",
            "score": 1,
            "issue_id": 2457,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "405098fcd7a76209",
            "authors": [
                "Sotiris Anagnostidis",
                "Gregor Bachmann",
                "Yeongmin Kim",
                "Jonas Kohler",
                "Markos Georgopoulos",
                "Artsiom Sanakoyeu",
                "Yuming Du",
                "Albert Pumarola",
                "Ali Thabet",
                "Edgar Schönfeld"
            ],
            "affiliations": [
                "ETH Zurich",
                "KAIST",
                "Meta GenAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20126.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#cv",
                    "#inference",
                    "#video",
                    "#optimization"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "FlexiDiT: Эффективная генерация без компромиссов",
                    "desc": "Статья представляет новый подход к оптимизации работы моделей диффузионных трансформеров (DiT). Авторы предлагают динамическую стратегию распределения вычислительных ресурсов вместо статической, что позволяет значительно снизить требования к вычислительной мощности без потери качества генерации. Разработанный метод, названный FlexiDiT, применим к предобученным моделям DiT и позволяет сократить количество операций с плавающей запятой (FLOP) более чем на 40% при генерации изображений. Гибкость подхода демонстрируется его успешным применением к задачам генерации видео, где экономия вычислений достигает 75%."
                },
                "en": {
                    "title": "Flexibility in Diffusion: Reducing Compute with FlexiDiT",
                    "desc": "This paper addresses the high resource demands of Diffusion Transformers during image generation. The authors introduce a dynamic strategy that allows for flexible compute allocation during the denoising process, leading to the development of FlexiDiT models. These models can adapt to varying compute budgets while maintaining image quality, achieving over 40% reduction in FLOPs compared to traditional static models. Additionally, the approach is versatile and can be applied to video generation, achieving up to 75% less compute usage without sacrificing performance."
                },
                "zh": {
                    "title": "灵活计算，提升生成效率",
                    "desc": "现代扩散变换器在推理时需要大量资源，主要是因为每个去噪步骤都需要固定且大量的计算。本文提出了一种动态策略，取代传统的静态计算预算分配方法，使得预训练的扩散变换器模型（DiT）能够灵活处理不同的计算预算。我们的方法称为FlexiDiT，能够在不降低生成图像质量的情况下，减少超过40%的计算量。该方法通用且不依赖于输入和条件模式，甚至可以扩展到视频生成，显著降低计算需求。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20238",
            "title": "FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving",
            "url": "https://huggingface.co/papers/2502.20238",
            "abstract": "Many challenging reasoning tasks require not just rapid, intuitive responses, but a more deliberate, multi-step approach. Recent progress in large language models (LLMs) highlights an important shift from the \"System 1\" way of quick reactions to the \"System 2\" style of reflection-and-correction problem solving. However, current benchmarks heavily rely on the final-answer accuracy, leaving much of a model's intermediate reasoning steps unexamined. This fails to assess the model's ability to reflect and rectify mistakes within the reasoning process. To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark for fine-grained evaluation of LLMs' reasoning capabilities. Each puzzle can be decomposed into atomic steps, making it ideal for rigorous validation of intermediate correctness. Building on this, we introduce two tasks: state checking, and state transition, for a comprehensive evaluation of how models assess the current situation and plan the next move. To support broader research, we also provide a puzzle training set aimed at enhancing performance on general mathematical tasks. We show that models trained on our state checking and transition data demonstrate gains in math reasoning by up to 5.1% on GSM8K.",
            "score": 0,
            "issue_id": 2458,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "e121721fdef71315",
            "authors": [
                "Guizhen Chen",
                "Weiwen Xu",
                "Hao Zhang",
                "Hou Pong Chan",
                "Chaoqun Liu",
                "Lidong Bing",
                "Deli Zhao",
                "Anh Tuan Luu",
                "Yu Rong"
            ],
            "affiliations": [
                "DAMO Academy, Alibaba Group, Singapore",
                "Nanyang Technological University, Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20238.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#reasoning",
                    "#dataset",
                    "#math"
                ],
                "emoji": "🧩",
                "ru": {
                    "title": "FINEREASON: Новый подход к оценке рассуждений искусственного интеллекта",
                    "desc": "Статья представляет новый бенчмарк FINEREASON для оценки способностей больших языковых моделей (LLM) к многоступенчатому рассуждению. В отличие от существующих бенчмарков, FINEREASON позволяет оценивать промежуточные шаги рассуждений, а не только конечный результат. Бенчмарк включает задачи проверки состояния и перехода между состояниями для комплексной оценки. Авторы также предоставляют набор данных для обучения, который улучшает результаты в задачах математического рассуждения."
                },
                "en": {
                    "title": "Enhancing Reasoning in Language Models with FINEREASON",
                    "desc": "This paper introduces FINEREASON, a new benchmark designed to evaluate the reasoning capabilities of large language models (LLMs) through logic puzzles. Unlike traditional benchmarks that focus solely on final-answer accuracy, FINEREASON emphasizes the importance of intermediate reasoning steps, allowing for a more detailed assessment of a model's reflective and corrective abilities. The benchmark includes two specific tasks: state checking and state transition, which help evaluate how models understand their current context and plan their next actions. The authors demonstrate that training on this benchmark can improve LLM performance in mathematical reasoning tasks by up to 5.1%."
                },
                "zh": {
                    "title": "提升推理能力的细致评估",
                    "desc": "许多复杂的推理任务需要不仅快速的直觉反应，还需要更深思熟虑的多步骤方法。最近大型语言模型（LLMs）的进展显示，从快速反应的“系统1”转向反思和纠正问题解决的“系统2”风格是一个重要的变化。当前的基准测试主要依赖最终答案的准确性，忽视了模型在推理过程中的中间步骤，这无法评估模型反思和纠正错误的能力。为了解决这个问题，我们提出了FINEREASON，这是一个逻辑难题基准，用于细致评估LLMs的推理能力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.20307",
            "title": "Mobius: Text to Seamless Looping Video Generation via Latent Shift",
            "url": "https://huggingface.co/papers/2502.20307",
            "abstract": "We present Mobius, a novel method to generate seamlessly looping videos from text descriptions directly without any user annotations, thereby creating new visual materials for the multi-media presentation. Our method repurposes the pre-trained video latent diffusion model for generating looping videos from text prompts without any training. During inference, we first construct a latent cycle by connecting the starting and ending noise of the videos. Given that the temporal consistency can be maintained by the context of the video diffusion model, we perform multi-frame latent denoising by gradually shifting the first-frame latent to the end in each step. As a result, the denoising context varies in each step while maintaining consistency throughout the inference process. Moreover, the latent cycle in our method can be of any length. This extends our latent-shifting approach to generate seamless looping videos beyond the scope of the video diffusion model's context. Unlike previous cinemagraphs, the proposed method does not require an image as appearance, which will restrict the motions of the generated results. Instead, our method can produce more dynamic motion and better visual quality. We conduct multiple experiments and comparisons to verify the effectiveness of the proposed method, demonstrating its efficacy in different scenarios. All the code will be made available.",
            "score": 0,
            "issue_id": 2458,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "4763c15bca31d3b1",
            "authors": [
                "Xiuli Bi",
                "Jianfei Yuan",
                "Bo Liu",
                "Yong Zhang",
                "Xiaodong Cun",
                "Chi-Man Pun",
                "Bin Xiao"
            ],
            "affiliations": [
                "Chongqing University of Post and Telecommunications, China",
                "GVC Lab, Great Bay University, China",
                "Meituan, China",
                "University of Macau, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.20307.jpg",
            "data": {
                "categories": [
                    "#diffusion",
                    "#multimodal",
                    "#video",
                    "#open_source"
                ],
                "emoji": "🔄",
                "ru": {
                    "title": "Бесшовная генерация зацикленных видео из текста с помощью латентной диффузии",
                    "desc": "Метод Mobius предлагает новый подход к генерации зацикленных видео на основе текстовых описаний без дополнительной разметки. Он использует предобученную модель латентной видео-диффузии, создавая латентный цикл путем соединения начального и конечного шума. Процесс многокадрового латентного шумоподавления поддерживает временную согласованность, постепенно смещая латентное представление первого кадра к концу на каждом шаге. Метод позволяет создавать более динамичные и качественные зацикленные видео по сравнению с традиционными синемаграфами, не требуя исходного изображения."
                },
                "en": {
                    "title": "Seamless Video Creation from Text: Introducing Mobius!",
                    "desc": "Mobius is a new technique that creates seamless looping videos directly from text descriptions without needing user input. It utilizes a pre-trained video latent diffusion model to generate these videos, ensuring that the start and end of the video connect smoothly. The method involves a latent cycle that allows for flexible video lengths while maintaining temporal consistency through multi-frame latent denoising. This approach enables the generation of dynamic and high-quality visuals, surpassing previous methods that relied on static images."
                },
                "zh": {
                    "title": "Mobius：从文本生成无缝循环视频的新方法",
                    "desc": "本文介绍了一种名为Mobius的新方法，可以直接从文本描述生成无缝循环视频，而无需用户注释。这种方法利用预训练的视频潜在扩散模型，通过连接视频的起始和结束噪声构建潜在循环，从而生成循环视频。在推理过程中，我们通过逐步将第一帧的潜在表示转移到最后一帧，进行多帧潜在去噪，确保时间一致性。与以往的动态图片不同，该方法不需要图像作为外观，因此能够生成更动态的运动和更好的视觉质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.19735",
            "title": "R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning Learning",
            "url": "https://huggingface.co/papers/2502.19735",
            "abstract": "Despite recent breakthroughs in reasoning-enhanced large language models (LLMs) like DeepSeek-R1, incorporating inference-time reasoning into machine translation (MT), where human translators naturally employ structured, multi-layered reasoning chain-of-thoughts (CoTs), is yet underexplored. Existing methods either design a fixed CoT tailored for a specific MT sub-task (e.g., literature translation), or rely on synthesizing CoTs unaligned with humans and supervised fine-tuning (SFT) prone to catastrophic forgetting, limiting their adaptability to diverse translation scenarios. This paper introduces R1-Translator (R1-T1), a novel framework to achieve inference-time reasoning for general MT via reinforcement learning (RL) with human-aligned CoTs comprising six common patterns. Our approach pioneers three innovations: (1) extending reasoning-based translation beyond MT sub-tasks to six languages and diverse tasks (e.g., legal/medical domain adaptation, idiom resolution); (2) formalizing six expert-curated CoT templates that mirror hybrid human strategies like context-aware paraphrasing and back translation; and (3) enabling self-evolving CoT discovery and anti-forgetting adaptation through RL with KL-constrained rewards. Experimental results indicate a steady translation performance improvement in 21 languages and 80 translation directions on Flores-101 test set, especially on the 15 languages unseen from training, with its general multilingual abilities preserved compared with plain SFT.",
            "score": 0,
            "issue_id": 2457,
            "pub_date": "2025-02-27",
            "pub_date_card": {
                "ru": "27 февраля",
                "en": "February 27",
                "zh": "2月27日"
            },
            "hash": "45b53278bddf4ab9",
            "authors": [
                "Minggui He",
                "Yilun Liu",
                "Shimin Tao",
                "Yuanchang Luo",
                "Hongyong Zeng",
                "Chang Su",
                "Li Zhang",
                "Hongxia Ma",
                "Daimeng Wei",
                "Weibin Meng",
                "Hao Yang",
                "Boxing Chen",
                "Osamu Yoshie"
            ],
            "affiliations": [
                "Huawei Canada, Canada",
                "Huawei, China",
                "Waseda University, Japan"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.19735.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#training",
                    "#machine_translation",
                    "#rl",
                    "#multilingual"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Разумный перевод: как научить ИИ думать как переводчик",
                    "desc": "Эта статья представляет R1-Translator (R1-T1) - новый фреймворк для машинного перевода с использованием рассуждений во время вывода. Авторы предлагают шесть шаблонов цепочек рассуждений, основанных на стратегиях профессиональных переводчиков. Метод использует обучение с подкреплением для адаптации и улучшения перевода без катастрофического забывания. Эксперименты показывают улучшение качества перевода на 21 языке, особенно на 15 языках, не встречавшихся при обучении."
                },
                "en": {
                    "title": "Revolutionizing Machine Translation with Reasoning-Enhanced Frameworks",
                    "desc": "This paper presents R1-Translator (R1-T1), a new framework that enhances machine translation (MT) by incorporating reasoning during translation, similar to how human translators think. It addresses limitations of existing methods that either use fixed reasoning patterns or rely on supervised fine-tuning, which can lead to forgetting important information. The framework utilizes reinforcement learning (RL) to align translation with human reasoning through six expert-curated chain-of-thought (CoT) templates. Experimental results show that R1-T1 improves translation quality across multiple languages and tasks, particularly for languages not seen during training, while maintaining strong multilingual capabilities."
                },
                "zh": {
                    "title": "推理驱动的通用机器翻译新框架",
                    "desc": "本文探讨了在机器翻译中引入推理增强的大型语言模型（LLMs），尤其是如何在推理时进行有效的翻译。我们提出了一种新的框架R1-Translator（R1-T1），通过强化学习（RL）结合人类对推理链的理解，来实现通用的机器翻译。该方法创新性地扩展了推理翻译的应用范围，并制定了六种专家策划的推理模板，以适应不同的翻译任务。实验结果表明，该方法在21种语言和80个翻译方向上均表现出稳定的翻译性能提升，尤其是在训练中未见过的15种语言上。"
                }
            }
        }
    ],
    "link_prev": "2025-02-27.html",
    "link_next": "2025-03-03.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "27.02",
        "en": "02/27",
        "zh": "2月27日"
    },
    "short_date_next": {
        "ru": "03.03",
        "en": "03/03",
        "zh": "3月3日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 4,
        "#agents": 0,
        "#cv": 2,
        "#rl": 3,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 2,
        "#3d": 0,
        "#audio": 0,
        "#video": 2,
        "#multimodal": 3,
        "#math": 1,
        "#multilingual": 1,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 6,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 3,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 1,
        "#leakage": 0,
        "#open_source": 3,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "我们介绍了Kanana，一系列在韩语和英语中表现出色的双语模型。Kanana的计算成本显著低于类似规模的顶级模型。报告详细介绍了预训练中使用的技术，包括高质量数据过滤、分阶段预训练、深度扩展、剪枝和蒸馏。此外，报告还概述了Kanana模型在训练后使用的方法，包括监督微调和偏好优化，以提高其与用户互动的能力。最后，报告还讨论了语言模型适应特定场景的可能方法，如嵌入、检索增强生成和函数调用。Kanana模型系列从2.1B到32.5B参数不等，2.1B模型（基础、指令、嵌入）已公开发布，以促进韩语模型研究。",
        "title": "Kanana: Compute-efficient Bilingual Language Models",
        "pinyin": "Wǒmen jièshào le Kanana, yī xìliè zài hányǔ hé yīngyǔ zhōng biǎoxiàn chūsè de shuāngyǔ móxíng. Kanana de jìsuàn chéngběn xiǎnzhù dīyú lèisì guīmó de dǐngjí móxíng. Bàogào xiángxì jièshào le yùxùnliàn zhōng shǐyòng de jìshù, bāokuò gāo zhìliàng shùjù guòlǜ, fēn jiēduàn yùxùnliàn, shēndù kuòzhǎn, jiǎnzhī hé zhēngliú. Cǐwài, bàogào hái gàikuàng le Kanana móxíng zài xùnliàn hòu shǐyòng de fāngfǎ, bāokuò jiàndū wēitiáo hé piānhǎo yōuhuà, yǐ tígāo qí yǔ yònghù hùdòng de nénglì. Zùihòu, bàogào hái tǎolùn le yǔyán móxíng shìyìng tèdìng chǎngjīng de kěnéng fāngfǎ, rú qiànrù, jiǎnsuǒ zēngqiáng shēngchéng hé hánshù diàoyòng. Kanana móxíng xìliè cóng 2.1B dào 32.5B cānshù bùděng, 2.1B móxíng (jīchǔ, zhǐlìng, qiànrù) yǐ gōngkāi fābù, yǐ cùjìn hányǔ móxíng yánjiū.",
        "vocab": "[{'word': '介绍', 'pinyin': 'jièshào', 'trans': 'introduce'},\n{'word': '双语', 'pinyin': 'shuāngyǔ', 'trans': 'bilingual'},\n{'word': '计算成本', 'pinyin': 'jìsuàn chéngběn', 'trans': 'computational cost'},\n{'word': '显著', 'pinyin': 'xiǎnzhù', 'trans': 'significant'},\n{'word': '预训练', 'pinyin': 'yù xùnliàn', 'trans': 'pre-training'},\n{'word': '高质量', 'pinyin': 'gāo zhìliàng', 'trans': 'high-quality'},\n{'word': '过滤', 'pinyin': 'guòlǜ', 'trans': 'filter'},\n{'word': '分阶段', 'pinyin': 'fēn jiēduàn', 'trans': 'phased'},\n{'word': '深度扩展', 'pinyin': 'shēndù kuòzhǎn', 'trans': 'deep expansion'},\n{'word': '剪枝', 'pinyin': 'jiǎnzhī', 'trans': 'pruning'},\n{'word': '蒸馏', 'pinyin': 'zhēngliú', 'trans': 'distillation'},\n{'word': '监督微调', 'pinyin': 'jiàndū wēitiáo', 'trans': 'supervised fine-tuning'},\n{'word': '偏好优化', 'pinyin': 'piānhào yōuhuà', 'trans': 'preference optimization'},\n{'word': '互动', 'pinyin': 'hùdòng', 'trans': 'interaction'},\n{'word': '嵌入', 'pinyin': 'qiànrù', 'trans': 'embedding'},\n{'word': '检索增强生成', 'pinyin': 'jiǎnsuǒ zēngqiáng shēngchéng', 'trans': 'retrieval-augmented generation'},\n{'word': '函数调用', 'pinyin': 'hánshù diàoyòng', 'trans': 'function call'},\n{'word': '参数', 'pinyin': 'cānshù', 'trans': 'parameters'},\n{'word': '公开发布', 'pinyin': 'gōngkāi fābù', 'trans': 'publicly released'},\n{'word': '促进', 'pinyin': 'cùjìn', 'trans': 'promote'}]",
        "trans": "We introduced Kanana, a series of bilingual models that perform excellently in Korean and English. Kanana's computational cost is significantly lower than that of top models of similar scale. The report details the techniques used during pre-training, including high-quality data filtering, staged pre-training, deep scaling, pruning, and distillation. Additionally, the report outlines the methods used with the Kanana models post-training, such as supervised fine-tuning and preference optimization, to enhance their ability to interact with users. Finally, the report discusses potential methods for adapting language models to specific scenarios, such as embedding, retrieval-augmented generation, and function calling. The Kanana model series ranges from 2.1B to 32.5B parameters, with the 2.1B model (base, instruction, embedding) already publicly released to promote research on Korean language models.",
        "update_ts": "2025-02-27 09:11"
    }
}