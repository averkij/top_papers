{
    "date": {
        "ru": "7 февраля",
        "en": "February 7",
        "zh": "2月7日"
    },
    "time_utc": "2025-02-07 04:12",
    "weekday": 4,
    "issue_id": 2087,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.04306",
            "title": "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization",
            "url": "https://huggingface.co/papers/2502.04306",
            "abstract": "Recent research has leveraged large language model multi-agent systems for complex problem-solving while trying to reduce the manual effort required to build them, driving the development of automated agent workflow optimization methods. However, existing methods remain inflexible due to representational limitations, a lack of adaptability, and poor scalability when relying on discrete optimization techniques. We address these challenges with ScoreFlow, a simple yet high-performance framework that leverages efficient gradient-based optimization in a continuous space. ScoreFlow incorporates Score-DPO, a novel variant of the direct preference optimization method that accounts for quantitative feedback. Across six benchmarks spanning question answering, coding, and mathematical reasoning, ScoreFlow achieves an 8.2% improvement over existing baselines. Moreover, it empowers smaller models to outperform larger ones with lower inference costs. Project: https://github.com/Gen-Verse/ScoreFlow",
            "score": 4,
            "issue_id": 2087,
            "pub_date": "2025-02-06",
            "pub_date_card": {
                "ru": "6 февраля",
                "en": "February 6",
                "zh": "2月6日"
            },
            "hash": "51ace85d35c202d5",
            "authors": [
                "Yinjie Wang",
                "Ling Yang",
                "Guohao Li",
                "Mengdi Wang",
                "Bryon Aragam"
            ],
            "affiliations": [
                "Princeton University",
                "University of Chicago",
                "University of Oxford"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.04306.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#inference",
                    "#optimization",
                    "#agents",
                    "#rlhf",
                    "#small_models"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "ScoreFlow: эффективная оптимизация мультиагентных систем на основе ИИ",
                    "desc": "В статье представлен новый фреймворк ScoreFlow для оптимизации рабочих процессов мультиагентных систем на основе больших языковых моделей. ScoreFlow использует градиентную оптимизацию в непрерывном пространстве, что позволяет преодолеть ограничения существующих методов. Ключевым компонентом является Score-DPO - новый вариант метода прямой оптимизации предпочтений, учитывающий количественную обратную связь. На шести тестовых задачах ScoreFlow показал улучшение результатов на 8.2% по сравнению с базовыми методами."
                },
                "en": {
                    "title": "ScoreFlow: Optimizing Multi-Agent Systems with Continuous Gradient Techniques",
                    "desc": "This paper introduces ScoreFlow, a new framework designed to enhance the performance of multi-agent systems in solving complex problems. It addresses the limitations of existing optimization methods by utilizing gradient-based optimization in a continuous space, which allows for greater flexibility and scalability. ScoreFlow features Score-DPO, a novel approach that incorporates quantitative feedback into the optimization process. The results show that ScoreFlow not only improves performance by 8.2% over previous methods but also enables smaller models to achieve better results than larger models at a lower cost."
                },
                "zh": {
                    "title": "ScoreFlow：高效的多智能体优化框架",
                    "desc": "最近的研究利用大型语言模型的多智能体系统来解决复杂问题，同时努力减少构建这些系统所需的手动工作。现有方法由于表示限制、缺乏适应性和依赖离散优化技术而导致灵活性不足。我们提出了ScoreFlow，这是一个简单但高性能的框架，利用基于梯度的优化在连续空间中进行优化。ScoreFlow在六个基准测试中表现出色，超越了现有基线，并使较小的模型以更低的推理成本超越较大的模型。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.04153",
            "title": "UltraIF: Advancing Instruction Following from the Wild",
            "url": "https://huggingface.co/papers/2502.04153",
            "abstract": "Instruction-following made modern large language models (LLMs) helpful assistants. However, the key to taming LLMs on complex instructions remains mysterious, for that there are huge gaps between models trained by open-source community and those trained by leading companies. To bridge the gap, we propose a simple and scalable approach UltraIF for building LLMs that can follow complex instructions with open-source data. UltraIF first decomposes real-world user prompts into simpler queries, constraints, and corresponding evaluation questions for the constraints. Then, we train an UltraComposer to compose constraint-associated prompts with evaluation questions. This prompt composer allows us to synthesize complicated instructions as well as filter responses with evaluation questions. In our experiment, for the first time, we successfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5 instruction-following benchmarks without any benchmark information, using only 8B model as response generator and evaluator. The aligned model also achieved competitive scores on other benchmarks. Moreover, we also show that UltraIF could further improve LLaMA-3.1-8B-Instruct through self-alignment, motivating broader use cases for the method. Our code will be available at https://github.com/kkk-an/UltraIF.",
            "score": 4,
            "issue_id": 2087,
            "pub_date": "2025-02-06",
            "pub_date_card": {
                "ru": "6 февраля",
                "en": "February 6",
                "zh": "2月6日"
            },
            "hash": "5c7c902f1effa8a3",
            "authors": [
                "Kaikai An",
                "Li Sheng",
                "Ganqu Cui",
                "Shuzheng Si",
                "Ning Ding",
                "Yu Cheng",
                "Baobao Chang"
            ],
            "affiliations": [
                "Peking University",
                "Shanghai AI Lab",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.04153.jpg",
            "data": {
                "categories": [
                    "#open_source",
                    "#training",
                    "#benchmark",
                    "#alignment",
                    "#rlhf"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "UltraIF: простой метод для обучения LLM следовать сложным инструкциям",
                    "desc": "Исследователи представили подход UltraIF для улучшения способности больших языковых моделей (LLM) следовать сложным инструкциям. Метод разбивает пользовательские запросы на более простые компоненты и использует специальную модель UltraComposer для составления сложных инструкций с вопросами для оценки. Эксперименты показали, что UltraIF позволяет значительно улучшить следование инструкциям у базовой модели LLaMA-3.1-8B без использования специальных данных. Подход также продемонстрировал возможность дальнейшего улучшения версии модели, уже обученной следовать инструкциям."
                },
                "en": {
                    "title": "UltraIF: Simplifying Complex Instructions for LLMs",
                    "desc": "This paper introduces UltraIF, a method designed to enhance large language models (LLMs) in following complex instructions using open-source data. The approach involves breaking down user prompts into simpler components, such as queries and constraints, and then training a model called UltraComposer to generate these structured prompts. By synthesizing complicated instructions and evaluating responses, UltraIF successfully aligns the LLaMA-3.1-8B-Base model with its instruct version on multiple benchmarks without prior benchmark data. Additionally, the method shows potential for improving existing instruct models through self-alignment, expanding its applicability in various scenarios."
                },
                "zh": {
                    "title": "UltraIF：让大型语言模型更聪明的秘密武器",
                    "desc": "本文提出了一种名为UltraIF的方法，用于提高大型语言模型（LLMs）对复杂指令的理解能力。该方法通过将用户的真实请求分解为更简单的查询、约束和相应的评估问题来实现。接着，训练一个名为UltraComposer的模型，能够生成与约束相关的提示，并结合评估问题来过滤响应。实验表明，UltraIF成功地使LLaMA-3.1-8B-Base在多个指令跟随基准上与其指令版本对齐，展示了该方法的有效性和广泛应用潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.03860",
            "title": "BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation",
            "url": "https://huggingface.co/papers/2502.03860",
            "abstract": "Large language models (LLMs), such as o1 from OpenAI, have demonstrated remarkable reasoning capabilities. o1 generates a long chain-of-thought (LongCoT) before answering a question. LongCoT allows LLMs to analyze problems, devise plans, reflect, and backtrack effectively. These actions empower LLM to solve complex problems. After the release of o1, many teams have attempted to replicate its LongCoT and reasoning capabilities. In terms of methods, they primarily rely on knowledge distillation with data from existing models with LongCoT capacities (e.g., OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), leaving significant uncertainties on systematically developing such reasoning abilities. In terms of data domains, these works focus narrowly on math while a few others include coding, limiting their generalizability. This paper introduces a novel approach to enable LLM's LongCoT capacity without distillation from o1-like models or expensive human annotations, where we bootstrap LongCoT (BOLT) from a standard instruct model. BOLT involves three stages: 1) LongCoT data bootstrapping with in-context learning on a standard instruct model; 2) LongCoT supervised finetuning; 3) online training to further refine LongCoT capacities. In BOLT, only a few in-context examples need to be constructed during the bootstrapping stage; in our experiments, we created 10 examples, demonstrating the feasibility of this approach. We use Llama-3.1-70B-Instruct to bootstrap LongCoT and apply our method to various model scales (7B, 8B, 70B). We achieve impressive performance on a variety of benchmarks, Arena-Hard, MT-Bench, WildBench, ZebraLogic, MATH500, which evaluate diverse task-solving and reasoning capabilities.",
            "score": 0,
            "issue_id": 2087,
            "pub_date": "2025-02-06",
            "pub_date_card": {
                "ru": "6 февраля",
                "en": "February 6",
                "zh": "2月6日"
            },
            "hash": "b861ba86ae27e974",
            "authors": [
                "Bo Pang",
                "Hanze Dong",
                "Jiacheng Xu",
                "Silvio Savarese",
                "Yingbo Zhou",
                "Caiming Xiong"
            ],
            "affiliations": [
                "Salesforce AI Research"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.03860.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#benchmark",
                    "#math",
                    "#long_context",
                    "#dataset",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Самообучение ИИ сложным рассуждениям без подсказок",
                    "desc": "Эта статья представляет новый подход к обучению больших языковых моделей (LLM) способности генерировать длинные цепочки рассуждений (LongCoT) без использования дистилляции знаний от существующих моделей. Метод BOLT включает три этапа: начальную генерацию данных LongCoT с помощью обучения в контексте, супервизорную донастройку и онлайн-обучение для дальнейшего улучшения способностей. Авторы применили свой метод к моделям различных масштабов и достигли впечатляющих результатов на ряде бенчмарков, оценивающих разнообразные способности решения задач и рассуждений. Этот подход позволяет развивать способности LLM к сложным рассуждениям без необходимости в дорогостоящих аннотациях или данных от существующих продвинутых моделей."
                },
                "en": {
                    "title": "Empowering LLMs with Efficient Long Chain-of-Thought Bootstrapping",
                    "desc": "This paper presents a new method called Bootstrapping Long Chain-of-Thought (BOLT) to enhance the reasoning abilities of large language models (LLMs) without relying on knowledge distillation from existing models. BOLT consists of three stages: bootstrapping LongCoT data using in-context learning, supervised fine-tuning for LongCoT, and online training for further refinement. The approach requires only a few examples to start the bootstrapping process, making it efficient and scalable across different model sizes. Experimental results show that BOLT significantly improves performance on various reasoning and problem-solving benchmarks, demonstrating its effectiveness in developing LLMs' LongCoT capabilities."
                },
                "zh": {
                    "title": "引导长链思维，提升推理能力！",
                    "desc": "本文介绍了一种新方法，旨在使大型语言模型（LLM）具备长链思维（LongCoT）能力，而无需依赖于类似o1模型的知识蒸馏或昂贵的人类标注。该方法称为BOLT，分为三个阶段：首先通过上下文学习从标准指令模型引导LongCoT数据，其次进行LongCoT的监督微调，最后进行在线训练以进一步提升LongCoT能力。实验中，我们仅构建了10个示例，证明了该方法的可行性。我们在多个基准测试上取得了显著的性能，展示了该方法在解决复杂问题和推理能力方面的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.04295",
            "title": "Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization",
            "url": "https://huggingface.co/papers/2502.04295",
            "abstract": "Large Language Models (LLMs) have shown significant capability across various tasks, with their real-world effectiveness often driven by prompt design. While recent research has focused on optimizing prompt content, the role of prompt formatting, a critical but often overlooked dimension, has received limited systematic investigation. In this paper, we introduce Content-Format Integrated Prompt Optimization (CFPO), an innovative methodology that jointly optimizes both prompt content and formatting through an iterative refinement process. CFPO leverages natural language mutations to explore content variations and employs a dynamic format exploration strategy that systematically evaluates diverse format options. Our extensive evaluations across multiple tasks and open-source LLMs demonstrate that CFPO demonstrates measurable performance improvements compared to content-only optimization methods. This highlights the importance of integrated content-format optimization and offers a practical, model-agnostic approach to enhancing LLM performance. Code will be available at https://github.com/HenryLau7/CFPO.",
            "score": 0,
            "issue_id": 2087,
            "pub_date": "2025-02-06",
            "pub_date_card": {
                "ru": "6 февраля",
                "en": "February 6",
                "zh": "2月6日"
            },
            "hash": "f72f46ad2c1b9853",
            "authors": [
                "Yuanye Liu",
                "Jiahang Xu",
                "Li Lyna Zhang",
                "Qi Chen",
                "Xuan Feng",
                "Yang Chen",
                "Zhongxin Guo",
                "Yuqing Yang",
                "Cheng Peng"
            ],
            "affiliations": [
                "Fudan University",
                "Microsoft Research Asia"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.04295.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#open_source",
                    "#training"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "Интегрированная оптимизация формы и содержания промптов повышает эффективность LLM",
                    "desc": "Статья представляет новую методологию оптимизации промптов для больших языковых моделей (LLM), называемую CFPO. Этот подход оптимизирует как содержание, так и форматирование промптов через итеративный процесс уточнения. CFPO использует мутации естественного языка для исследования вариаций содержания и применяет динамическую стратегию исследования форматов. Результаты показывают значительное улучшение производительности по сравнению с методами оптимизации, ориентированными только на содержание."
                },
                "en": {
                    "title": "Enhancing LLMs with Integrated Content and Format Optimization",
                    "desc": "This paper presents a new method called Content-Format Integrated Prompt Optimization (CFPO) that improves the performance of Large Language Models (LLMs) by optimizing both the content and formatting of prompts. The authors argue that while prompt content has been the focus of recent research, the formatting aspect is equally important and has not been thoroughly explored. CFPO uses natural language mutations to create variations in content and a dynamic strategy to test different formatting options. The results show that this integrated approach leads to better performance in various tasks compared to methods that only optimize content."
                },
                "zh": {
                    "title": "内容与格式的完美结合，提升LLM性能！",
                    "desc": "大型语言模型（LLMs）在各种任务中表现出色，其实际效果往往依赖于提示设计。尽管最近的研究主要集中在优化提示内容上，但提示格式的作用却被忽视，缺乏系统性的研究。本文提出了一种新的方法——内容格式集成提示优化（CFPO），通过迭代优化过程同时优化提示内容和格式。我们的评估表明，CFPO在多个任务和开源LLMs上相较于仅优化内容的方法，显示出显著的性能提升，强调了内容与格式集成优化的重要性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.04296",
            "title": "Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression",
            "url": "https://huggingface.co/papers/2502.04296",
            "abstract": "We propose Heterogeneous Masked Autoregression (HMA) for modeling action-video dynamics to generate high-quality data and evaluation in scaling robot learning. Building interactive video world models and policies for robotics is difficult due to the challenge of handling diverse settings while maintaining computational efficiency to run in real time. HMA uses heterogeneous pre-training from observations and action sequences across different robotic embodiments, domains, and tasks. HMA uses masked autoregression to generate quantized or soft tokens for video predictions. \\ourshort achieves better visual fidelity and controllability than the previous robotic video generation models with 15 times faster speed in the real world. After post-training, this model can be used as a video simulator from low-level action inputs for evaluating policies and generating synthetic data. See this link https://liruiw.github.io/hma for more information.",
            "score": 0,
            "issue_id": 2087,
            "pub_date": "2025-02-06",
            "pub_date_card": {
                "ru": "6 февраля",
                "en": "February 6",
                "zh": "2月6日"
            },
            "hash": "da9d11d5ea5d9d9e",
            "authors": [
                "Lirui Wang",
                "Kevin Zhao",
                "Chaoqi Liu",
                "Xinlei Chen"
            ],
            "affiliations": [
                "MIT",
                "Meta, FAIR",
                "UIUC"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.04296.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#robotics",
                    "#dataset",
                    "#video",
                    "#synthetic"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "HMA: Быстрое и качественное моделирование видео для обучения роботов",
                    "desc": "Статья представляет новый метод Heterogeneous Masked Autoregression (HMA) для моделирования динамики видео действий в робототехнике. HMA использует гетерогенное предобучение на наблюдениях и последовательностях действий из различных роботизированных воплощений, доменов и задач. Метод применяет маскированную авторегрессию для генерации квантованных или мягких токенов для предсказания видео. HMA достигает лучшего визуального качества и управляемости по сравнению с предыдущими моделями генерации видео для роботов, работая в 15 раз быстрее в реальном мире."
                },
                "en": {
                    "title": "Revolutionizing Robot Learning with Heterogeneous Video Modeling",
                    "desc": "The paper introduces Heterogeneous Masked Autoregression (HMA), a novel approach for modeling the dynamics of action videos to enhance robot learning. HMA addresses the challenges of diverse environments and the need for real-time computational efficiency by leveraging heterogeneous pre-training from various robotic tasks and domains. By employing masked autoregression, HMA generates high-quality video predictions using quantized or soft tokens. The results show that HMA significantly improves visual fidelity and controllability while operating 15 times faster than previous models, making it a valuable tool for simulating video from low-level actions and evaluating robotic policies."
                },
                "zh": {
                    "title": "异构掩蔽自回归：提升机器人学习的视频生成",
                    "desc": "我们提出了异构掩蔽自回归（HMA）模型，用于建模动作视频的动态，以生成高质量的数据并评估机器人学习的扩展性。构建交互式视频世界模型和机器人策略面临挑战，因为需要处理多样化的环境，同时保持实时运行的计算效率。HMA通过对不同机器人形态、领域和任务的观察和动作序列进行异构预训练，来提高模型的性能。经过后期训练，该模型可以作为视频模拟器，从低级动作输入中评估策略并生成合成数据。"
                }
            }
        }
    ],
    "link_prev": "2025-02-06.html",
    "link_next": "2025-02-10.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "06.02",
        "en": "02/06",
        "zh": "2月6日"
    },
    "short_date_next": {
        "ru": "10.02",
        "en": "02/10",
        "zh": "2月10日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 0,
        "#benchmark": 3,
        "#agents": 1,
        "#cv": 0,
        "#rl": 0,
        "#rlhf": 2,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 0,
        "#math": 1,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 1,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 1,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 2,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 1,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 1,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章研究社会行为的产生。传统模型难以捕捉人类行为的复杂性。大型语言模型（LLM）代理可模拟非理性因素。我们介绍了TwinMarket，使用LLM模拟社会经济系统。实验展示了个体行为如何引发群体行为和突现现象。",
        "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
        "pinyin": "这篇文章研究社会行为的产生。\nZhè piān wénzhāng yánjiū shèhuì xíngwéi de chǎnshēng.\n\n传统模型难以捕捉人类行为的复杂性。\nChuántǒng móxíng nányǐ bǔzhuō rénlèi xíngwéi de fùzáxìng.\n\n大型语言模型（LLM）代理可模拟非理性因素。\nDàxíng yǔyán móxíng (LLM) dàilǐ kě mónǐ fēi lǐxìng yīnsù.\n\n我们介绍了TwinMarket，使用LLM模拟社会经济系统。\nWǒmen jièshào le TwinMarket, shǐyòng LLM mónǐ shèhuì jīngjì xìtǒng.\n\n实验展示了个体行为如何引发群体行为和突现现象。\nShíyàn zhǎnshì le gètǐ xíngwéi rúhé yǐnfā qúntǐ xíngwéi hé tūxiàn xiànxiàng.",
        "vocab": "[\n    {\"word\": \"研究\", \"pinyin\": \"yán jiū\", \"trans\": \"research\"},\n    {\"word\": \"社会行为\", \"pinyin\": \"shè huì xíng wéi\", \"trans\": \"social behavior\"},\n    {\"word\": \"产生\", \"pinyin\": \"chǎn shēng\", \"trans\": \"generate\"},\n    {\"word\": \"传统\", \"pinyin\": \"chuán tǒng\", \"trans\": \"traditional\"},\n    {\"word\": \"模型\", \"pinyin\": \"mó xíng\", \"trans\": \"model\"},\n    {\"word\": \"难以\", \"pinyin\": \"nán yǐ\", \"trans\": \"difficult to\"},\n    {\"word\": \"捕捉\", \"pinyin\": \"bǔ zhuō\", \"trans\": \"capture\"},\n    {\"word\": \"复杂性\", \"pinyin\": \"fù zá xìng\", \"trans\": \"complexity\"},\n    {\"word\": \"大型\", \"pinyin\": \"dà xíng\", \"trans\": \"large-scale\"},\n    {\"word\": \"语言模型\", \"pinyin\": \"yǔ yán mó xíng\", \"trans\": \"language model\"},\n    {\"word\": \"代理\", \"pinyin\": \"dài lǐ\", \"trans\": \"agent\"},\n    {\"word\": \"模拟\", \"pinyin\": \"mó nǐ\", \"trans\": \"simulate\"},\n    {\"word\": \"非理性\", \"pinyin\": \"fēi lǐ xìng\", \"trans\": \"irrational\"},\n    {\"word\": \"因素\", \"pinyin\": \"yīn sù\", \"trans\": \"factor\"},\n    {\"word\": \"介绍\", \"pinyin\": \"jiè shào\", \"trans\": \"introduce\"},\n    {\"word\": \"TwinMarket\", \"pinyin\": \"TwinMarket\", \"trans\": \"TwinMarket\"},\n    {\"word\": \"使用\", \"pinyin\": \"shǐ yòng\", \"trans\": \"use\"},\n    {\"word\": \"社会经济系统\", \"pinyin\": \"shè huì jīng jì xì tǒng\", \"trans\": \"socio-economic system\"},\n    {\"word\": \"实验\", \"pinyin\": \"shí yàn\", \"trans\": \"experiment\"},\n    {\"word\": \"展示\", \"pinyin\": \"zhǎn shì\", \"trans\": \"demonstrate\"},\n    {\"word\": \"个体行为\", \"pinyin\": \"gè tǐ xíng wéi\", \"trans\": \"individual behavior\"},\n    {\"word\": \"引发\", \"pinyin\": \"yǐn fā\", \"trans\": \"trigger\"},\n    {\"word\": \"群体行为\", \"pinyin\": \"qún tǐ xíng wéi\", \"trans\": \"group behavior\"},\n    {\"word\": \"突现现象\", \"pinyin\": \"tū xiàn xiàn xiàng\", \"trans\": \"emergent phenomenon\"}\n]",
        "trans": "This article investigates the generation of social behaviors. Traditional models struggle to capture the complexity of human behavior. Large Language Model (LLM) agents can simulate non-rational factors. We introduce TwinMarket, which uses LLM to simulate socio-economic systems. Experiments demonstrate how individual behaviors trigger group behaviors and emergent phenomena.",
        "update_ts": "2025-02-06 09:11"
    }
}