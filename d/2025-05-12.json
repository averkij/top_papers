{
    "date": {
        "ru": "12 Ğ¼Ğ°Ñ",
        "en": "May 12",
        "zh": "5æœˆ12æ—¥"
    },
    "time_utc": "2025-05-12 12:21",
    "weekday": 0,
    "issue_id": 3709,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.02550",
            "title": "Bielik v3 Small: Technical Report",
            "url": "https://huggingface.co/papers/2505.02550",
            "abstract": "We introduce Bielik v3, a series of parameter-efficient generative text models (1.5B and 4.5B) optimized for Polish language processing. These models demonstrate that smaller, well-optimized architectures can achieve performance comparable to much larger counterparts while requiring substantially fewer computational resources. Our approach incorporates several key innovations: a custom Polish tokenizer (APT4) that significantly improves token efficiency, Weighted Instruction Cross-Entropy Loss to balance learning across instruction types, and Adaptive Learning Rate that dynamically adjusts based on training progress. Trained on a meticulously curated corpus of 292 billion tokens spanning 303 million documents, these models excel across multiple benchmarks, including the Open PL LLM Leaderboard, Complex Polish Text Understanding Benchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter model achieves results competitive with models 2-3 times its size, while the 1.5B model delivers strong performance despite its extremely compact profile. These advances establish new benchmarks for parameter-efficient language modeling in less-represented languages, making high-quality Polish language AI more accessible for resource-constrained applications.",
            "score": 28,
            "issue_id": 3707,
            "pub_date": "2025-05-05",
            "pub_date_card": {
                "ru": "5 Ğ¼Ğ°Ñ",
                "en": "May 5",
                "zh": "5æœˆ5æ—¥"
            },
            "hash": "a7c9d183be6447dd",
            "authors": [
                "Krzysztof Ociepa",
                "Åukasz Flis",
                "Remigiusz Kinas",
                "Krzysztof WrÃ³bel",
                "Adrian GwoÅºdziej"
            ],
            "affiliations": [
                "ACK Cyfronet AGH",
                "Azurro",
                "Enelpol",
                "Jagiellonian University",
                "SpeakLeash"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.02550.jpg",
            "data": {
                "categories": [
                    "#small_models",
                    "#plp",
                    "#multilingual",
                    "#low_resource",
                    "#dataset",
                    "#benchmark"
                ],
                "emoji": "ğŸ‡µğŸ‡±",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´ĞµĞ»Ğ°ÑÑ‚ Ğ˜Ğ˜ Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½ĞµĞµ",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° ÑĞµÑ€Ğ¸Ñ Bielik v3 - ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ¼Ğ¾Ğ¹ Ñ Ğ³Ğ¾Ñ€Ğ°Ğ·Ğ´Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ°Ğ¼Ğ¸. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‚ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ»ÑŒÑĞºĞ¸Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€, Ğ²Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½ÑƒÑ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ°Ñ…, ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ñ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ° Ğ´Ğ»Ñ Ğ¼ĞµĞ½ĞµĞµ Ñ€Ğ°ÑĞ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²."
                },
                "en": {
                    "title": "Efficient Polish Language Models: Big Performance from Small Sizes",
                    "desc": "Bielik v3 introduces efficient generative text models specifically designed for the Polish language, with sizes of 1.5B and 4.5B parameters. These models show that smaller architectures can perform as well as larger ones while using less computational power. Key innovations include a custom tokenizer for better token efficiency, a specialized loss function to balance learning, and an adaptive learning rate that adjusts during training. With training on a vast dataset, these models set new standards for language processing in Polish, making advanced AI more accessible for various applications."
                },
                "zh": {
                    "title": "é«˜æ•ˆæ³¢å…°è¯­ç”Ÿæˆæ¨¡å‹çš„åˆ›æ–°ä¹‹è·¯",
                    "desc": "æˆ‘ä»¬ä»‹ç»äº†Bielik v3ï¼Œè¿™æ˜¯ä¸€ç³»åˆ—é’ˆå¯¹æ³¢å…°è¯­å¤„ç†çš„é«˜æ•ˆç”Ÿæˆæ–‡æœ¬æ¨¡å‹ï¼ˆ1.5Bå’Œ4.5Bå‚æ•°ï¼‰ã€‚è¿™äº›æ¨¡å‹è¡¨æ˜ï¼Œè¾ƒå°ä¸”ç»è¿‡ä¼˜åŒ–çš„æ¶æ„å¯ä»¥åœ¨è®¡ç®—èµ„æºå¤§å¹…å‡å°‘çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°ä¸æ›´å¤§æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„åˆ›æ–°åŒ…æ‹¬å®šåˆ¶çš„æ³¢å…°è¯­åˆ†è¯å™¨ï¼ˆAPT4ï¼‰ï¼Œæ˜¾è‘—æé«˜äº†æ ‡è®°æ•ˆç‡ï¼Œä»¥åŠåŠ æƒæŒ‡ä»¤äº¤å‰ç†µæŸå¤±ï¼Œå¹³è¡¡ä¸åŒæŒ‡ä»¤ç±»å‹çš„å­¦ä¹ ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€è°ƒæ•´çš„å­¦ä¹ ç‡æ ¹æ®è®­ç»ƒè¿›åº¦è¿›è¡Œè°ƒæ•´ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.02410",
            "title": "Bielik 11B v2 Technical Report",
            "url": "https://huggingface.co/papers/2505.02410",
            "abstract": "We present Bielik 11B v2, a state-of-the-art language model optimized for Polish text processing. Built on the Mistral 7B v0.2 architecture and scaled to 11B parameters using depth up-scaling, this model demonstrates exceptional performance across Polish language benchmarks while maintaining strong cross-lingual capabilities. We introduce two key technical innovations: Weighted Instruction Cross-Entropy Loss, which optimizes learning across diverse instruction types by assigning quality-based weights to training examples, and Adaptive Learning Rate, which dynamically adjusts based on context length. Comprehensive evaluation across multiple benchmarks demonstrates that Bielik 11B v2 outperforms many larger models, including those with 2-6 times more parameters, and significantly surpasses other specialized Polish language models on tasks ranging from linguistic understanding to complex reasoning. The model's parameter efficiency and extensive quantization options enable deployment across various hardware configurations, advancing Polish language AI capabilities and establishing new benchmarks for resource-efficient language modeling in less-represented languages.",
            "score": 25,
            "issue_id": 3707,
            "pub_date": "2025-05-05",
            "pub_date_card": {
                "ru": "5 Ğ¼Ğ°Ñ",
                "en": "May 5",
                "zh": "5æœˆ5æ—¥"
            },
            "hash": "e9cb82cbeaac24ed",
            "authors": [
                "Krzysztof Ociepa",
                "Åukasz Flis",
                "Krzysztof WrÃ³bel",
                "Adrian GwoÅºdziej",
                "Remigiusz Kinas"
            ],
            "affiliations": [
                "ACK Cyfronet AGH",
                "Azurro",
                "Enelpol",
                "Jagiellonian University",
                "SpeakLeash"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.02410.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#multilingual",
                    "#low_resource",
                    "#training",
                    "#benchmark",
                    "#architecture",
                    "#optimization",
                    "#reasoning"
                ],
                "emoji": "ğŸ‡µğŸ‡±",
                "ru": {
                    "title": "Ğ ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¿Ğ¾Ğ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°: Bielik 11B v2 ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñ‹ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸",
                    "desc": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Bielik 11B v2 - ÑƒÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¿Ğ¾Ğ»ÑŒÑĞºĞ¸Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ². ĞÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ° Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ Mistral 7B v0.2 Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ´Ğ¾ 11 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ°Ñ€Ğ´Ğ¾Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¾Ğ½Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒÑĞºĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ…. Ğ’ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ñ‹ Ğ´Ğ²Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¸: Ğ²Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ´Ğ»Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹ Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Bielik 11B v2 Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ° Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Revolutionizing Polish Language Processing with Bielik 11B v2",
                    "desc": "Bielik 11B v2 is a cutting-edge language model specifically designed for processing Polish text. It utilizes the Mistral 7B v0.2 architecture and has been enhanced to 11 billion parameters, achieving remarkable results on Polish language tasks while also performing well in cross-lingual scenarios. The model introduces innovative techniques like Weighted Instruction Cross-Entropy Loss for better learning from diverse instructions and an Adaptive Learning Rate that adjusts based on the context length. Its efficiency and quantization options allow it to run on various hardware, making it a significant advancement in AI for Polish language applications."
                },
                "zh": {
                    "title": "æ³¢å…°è¯­å¤„ç†çš„æ–°æ ‡æ†ï¼šBielik 11B v2",
                    "desc": "Bielik 11B v2 æ˜¯ä¸€ä¸ªé’ˆå¯¹æ³¢å…°è¯­æ–‡æœ¬å¤„ç†çš„å…ˆè¿›è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Mistral 7B v0.2 æ¶æ„ï¼Œå‚æ•°è§„æ¨¡è¾¾åˆ° 11Bã€‚è¯¥æ¨¡å‹åœ¨æ³¢å…°è¯­åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶å…·å¤‡å¼ºå¤§çš„è·¨è¯­è¨€èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸¤é¡¹å…³é”®æŠ€æœ¯åˆ›æ–°ï¼šåŠ æƒæŒ‡ä»¤äº¤å‰ç†µæŸå¤±ï¼Œé€šè¿‡ä¸ºè®­ç»ƒæ ·æœ¬åˆ†é…åŸºäºè´¨é‡çš„æƒé‡æ¥ä¼˜åŒ–ä¸åŒæŒ‡ä»¤ç±»å‹çš„å­¦ä¹ ï¼Œä»¥åŠè‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡é•¿åº¦åŠ¨æ€è°ƒæ•´ã€‚ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒBielik 11B v2 è¶…è¶Šäº†è®¸å¤šæ›´å¤§æ¨¡å‹çš„è¡¨ç°ï¼Œå°¤å…¶åœ¨è¯­è¨€ç†è§£å’Œå¤æ‚æ¨ç†ç­‰ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–ä¸“é—¨çš„æ³¢å…°è¯­è¨€æ¨¡å‹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.06046",
            "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health\n  Information",
            "url": "https://huggingface.co/papers/2505.06046",
            "abstract": "As Large Language Models (LLMs) become widely accessible, a detailed understanding of their knowledge within specific domains becomes necessary for successful real world use. This is particularly critical in public health, where failure to retrieve relevant, accurate, and current information could significantly impact UK residents. However, currently little is known about LLM knowledge of UK Government public health information. To address this issue, this paper introduces a new benchmark, PubHealthBench, with over 8000 questions for evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form responses to public health queries, created via an automated pipeline. We also release a new dataset of the extracted UK Government public health guidance documents used as source text for PubHealthBench. Assessing 24 LLMs on PubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a high degree of knowledge, achieving >90% in the MCQA setup, and outperform humans with cursory search engine use. However, in the free form setup we see lower performance with no model scoring >75%. Therefore, whilst there are promising signs that state of the art (SOTA) LLMs are an increasingly accurate source of public health information, additional safeguards or tools may still be needed when providing free form responses on public health topics.",
            "score": 8,
            "issue_id": 3707,
            "pub_date": "2025-05-09",
            "pub_date_card": {
                "ru": "9 Ğ¼Ğ°Ñ",
                "en": "May 9",
                "zh": "5æœˆ9æ—¥"
            },
            "hash": "c671de3a9e8ff4de",
            "authors": [
                "Joshua Harris",
                "Fan Grayson",
                "Felix Feldman",
                "Timothy Laurence",
                "Toby Nonnenmacher",
                "Oliver Higgins",
                "Leo Loman",
                "Selina Patel",
                "Thomas Finnie",
                "Samuel Collins",
                "Michael Borowitz"
            ],
            "affiliations": [
                "UK Health Security Agency (UKHSA)"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.06046.jpg",
            "data": {
                "categories": [
                    "#alignment",
                    "#science",
                    "#dataset",
                    "#healthcare",
                    "#benchmark"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ LLM Ğ² ÑÑ„ĞµÑ€Ğµ Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ´Ñ€Ğ°Ğ²Ğ¾Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº PubHealthBench Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ´Ñ€Ğ°Ğ²Ğ¾Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ’ĞµĞ»Ğ¸ĞºĞ¾Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ğ¸. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ĞµĞµ 8000 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğ¼ Ğ¸ ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ¾Ğ¹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ½Ğ¾Ğ²ĞµĞ¹ÑˆĞ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ½Ñ‹Ğµ LLM Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ 90% Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğ¼, Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ñ Ğ»ÑĞ´ĞµĞ¹ Ñ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼. ĞĞ´Ğ½Ğ°ĞºĞ¾ Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… ÑĞ¾ ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ¸Ğ¶Ğµ, Ñ‡Ñ‚Ğ¾ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ° Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¼ĞµÑ€ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ LLM Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ Ğ·Ğ´Ñ€Ğ°Ğ²Ğ¾Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Evaluating LLMs for Public Health: Promising Yet Cautious",
                    "desc": "This paper investigates the knowledge of Large Language Models (LLMs) in the domain of UK public health information. It introduces a benchmark called PubHealthBench, which consists of over 8000 questions designed to evaluate LLMs' performance in Multiple Choice Question Answering (MCQA) and free form responses. The study assesses 24 different LLMs, revealing that the latest models perform well in MCQA tasks, achieving over 90% accuracy, but struggle with free form responses, none scoring above 75%. The findings suggest that while LLMs show promise as reliable sources of public health information, caution is needed when interpreting their free form outputs."
                },
                "zh": {
                    "title": "æå‡å…¬å…±å«ç”Ÿä¿¡æ¯çš„å‡†ç¡®æ€§",
                    "desc": "éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œäº†è§£å®ƒä»¬åœ¨ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†å˜å¾—è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å…¬å…±å«ç”Ÿé¢†åŸŸã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•PubHealthBenchï¼ŒåŒ…å«è¶…è¿‡8000ä¸ªé—®é¢˜ï¼Œç”¨äºè¯„ä¼°LLMsåœ¨å…¬å…±å«ç”ŸæŸ¥è¯¢ä¸­çš„å¤šé¡¹é€‰æ‹©é—®ç­”ï¼ˆMCQAï¼‰å’Œè‡ªç”±å½¢å¼å›ç­”çš„èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œæœ€æ–°çš„ç§æœ‰LLMsï¼ˆå¦‚GPT-4.5å’ŒGPT-4.1ï¼‰åœ¨MCQAæµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡è¶…è¿‡90%ï¼Œç”šè‡³è¶…è¶Šäº†äººç±»çš„æœç´¢å¼•æ“ä½¿ç”¨ã€‚ç„¶è€Œï¼Œåœ¨è‡ªç”±å½¢å¼å›ç­”ä¸­ï¼Œæ¨¡å‹çš„è¡¨ç°è¾ƒä½ï¼Œæ²¡æœ‰ä¸€ä¸ªæ¨¡å‹å¾—åˆ†è¶…è¿‡75%ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.06111",
            "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
            "url": "https://huggingface.co/papers/2505.06111",
            "abstract": "A generalist robot should perform effectively across various environments. However, most existing approaches heavily rely on scaling action-annotated data to enhance their capabilities. Consequently, they are often limited to single physical specification and struggle to learn transferable knowledge across different embodiments and environments. To confront these limitations, we propose UniVLA, a new framework for learning cross-embodiment vision-language-action (VLA) policies. Our key innovation is to derive task-centric action representations from videos with a latent action model. This enables us to exploit extensive data across a wide spectrum of embodiments and perspectives. To mitigate the effect of task-irrelevant dynamics, we incorporate language instructions and establish a latent action model within the DINO feature space. Learned from internet-scale videos, the generalist policy can be deployed to various robots through efficient latent action decoding. We obtain state-of-the-art results across multiple manipulation and navigation benchmarks, as well as real-robot deployments. UniVLA achieves superior performance over OpenVLA with less than 1/20 of pretraining compute and 1/10 of downstream data. Continuous performance improvements are observed as heterogeneous data, even including human videos, are incorporated into the training pipeline. The results underscore UniVLA's potential to facilitate scalable and efficient robot policy learning.",
            "score": 6,
            "issue_id": 3704,
            "pub_date": "2025-05-09",
            "pub_date_card": {
                "ru": "9 Ğ¼Ğ°Ñ",
                "en": "May 9",
                "zh": "5æœˆ9æ—¥"
            },
            "hash": "bf19981dd100b8fb",
            "authors": [
                "Qingwen Bu",
                "Yanting Yang",
                "Jisong Cai",
                "Shenyuan Gao",
                "Guanghui Ren",
                "Maoqing Yao",
                "Ping Luo",
                "Hongyang Li"
            ],
            "affiliations": [
                "AgiBot",
                "OpenDriveLab",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.06111.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#robotics",
                    "#training",
                    "#benchmark",
                    "#agents",
                    "#transfer_learning"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ ÑĞ·Ñ‹Ğº",
                    "desc": "UniVLA - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰ĞµĞ¹ ÑÑ€ĞµĞ´Ğ¾Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ñ€ĞµĞ½Ğ¸Ñ, ÑĞ·Ñ‹ĞºĞ° Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹. ĞšĞ»ÑÑ‡ĞµĞ²Ğ°Ñ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ²Ğ¸Ğ´ĞµĞ¾, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ğ¾Ñ€Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ğ»Ğ¾Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ². Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¿Ğ¾ Ğ¼Ğ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¸ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ…. UniVLA Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ OpenVLA, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
                },
                "en": {
                    "title": "UniVLA: Empowering Robots with Cross-Embodiment Learning",
                    "desc": "The paper introduces UniVLA, a framework designed to enhance the capabilities of generalist robots by learning cross-embodiment vision-language-action (VLA) policies. It addresses the limitations of existing methods that depend on large amounts of action-annotated data and are restricted to specific physical forms. By utilizing a latent action model derived from videos, UniVLA can leverage diverse data sources and improve knowledge transfer across different robot embodiments and environments. The framework demonstrates state-of-the-art performance in various tasks while requiring significantly less computational resources and data compared to previous approaches."
                },
                "zh": {
                    "title": "UniVLAï¼šæå‡é€šç”¨æœºå™¨äººå­¦ä¹ æ•ˆç‡çš„æ–°æ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶UniVLAï¼Œç”¨äºå­¦ä¹ è·¨ä½“ç°çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰ç­–ç•¥ï¼Œä»¥æé«˜é€šç”¨æœºå™¨äººåœ¨ä¸åŒç¯å¢ƒä¸­çš„è¡¨ç°ã€‚æˆ‘ä»¬é€šè¿‡è§†é¢‘ä¸­çš„æ½œåœ¨åŠ¨ä½œæ¨¡å‹æå–ä»¥ä»»åŠ¡ä¸ºä¸­å¿ƒçš„åŠ¨ä½œè¡¨ç¤ºï¼Œä»è€Œåˆ©ç”¨å¹¿æ³›çš„å¤šæ ·åŒ–æ•°æ®ã€‚ä¸ºäº†å‡å°‘ä¸ä»»åŠ¡æ— å…³çš„åŠ¨æ€å½±å“ï¼Œæˆ‘ä»¬ç»“åˆäº†è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶åœ¨DINOç‰¹å¾ç©ºé—´ä¸­å»ºç«‹äº†æ½œåœ¨åŠ¨ä½œæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUniVLAåœ¨å¤šä¸ªæ“ä½œå’Œå¯¼èˆªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨é¢„è®­ç»ƒè®¡ç®—å’Œä¸‹æ¸¸æ•°æ®æ–¹é¢çš„éœ€æ±‚æ˜¾è‘—ä½äºç°æœ‰æ–¹æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.05026",
            "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness",
            "url": "https://huggingface.co/papers/2505.05026",
            "abstract": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While recent Vision-Language Models (VLMs) can process automated UI analysis, current approaches focus on isolated design attributes rather than comparative persuasiveness-the key factor in optimizing user interactions. To address this, we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales. Additionally, we propose G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy. Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation. Through promoting VLM-driven evaluation of UI persuasiveness, our work offers an approach to complement A/B testing, propelling progress in scalable UI preference modeling and design optimization. Code and data will be released publicly.",
            "score": 5,
            "issue_id": 3705,
            "pub_date": "2025-05-08",
            "pub_date_card": {
                "ru": "8 Ğ¼Ğ°Ñ",
                "en": "May 8",
                "zh": "5æœˆ8æ—¥"
            },
            "hash": "41e61eccd430ea55",
            "authors": [
                "Jaehyun Jeon",
                "Jang Han Yoon",
                "Min Soo Kim",
                "Sumin Shim",
                "Yejin Choi",
                "Hanbin Kim",
                "Youngjae Yu"
            ],
            "affiliations": [
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.05026.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#cv",
                    "#benchmark",
                    "#optimization",
                    "#inference"
                ],
                "emoji": "ğŸ–¥ï¸",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ UI Ğ±ĞµĞ· A/B-Ñ‚ĞµÑÑ‚Ğ¾Ğ²",
                    "desc": "ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ² Ñ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸Ñ… ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞĞ½Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº WiserUI-Bench Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ², ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‰Ğ¸Ğ¹ 300 Ğ¿Ğ°Ñ€ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… UI-Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ A/B-Ñ‚ĞµÑÑ‚Ğ¾Ğ². Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ G-FOCUS Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ² Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ G-FOCUS Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¿Ğ¾ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ²."
                },
                "en": {
                    "title": "Revolutionizing UI Evaluation with G-FOCUS and WiserUI-Bench",
                    "desc": "This paper discusses the importance of evaluating user interface (UI) design not just for its visual appeal but for its ability to influence user behavior, a concept known as Design Persuasiveness. The authors highlight the limitations of traditional A/B testing, which is often expensive and slow, and propose a new benchmark called WiserUI-Bench for assessing UI design effectiveness through pairwise comparisons. They introduce G-FOCUS, an innovative reasoning strategy that improves the accuracy of Vision-Language Models (VLMs) in evaluating UI persuasiveness by minimizing biases. The results demonstrate that G-FOCUS outperforms existing methods, paving the way for more efficient and scalable UI design optimization."
                },
                "zh": {
                    "title": "æå‡ç”¨æˆ·ç•Œé¢è®¾è®¡çš„è¯´æœåŠ›è¯„ä¼°",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰è®¾è®¡çš„æœ‰æ•ˆæ€§è¯„ä¼°ï¼Œå¼ºè°ƒè®¾è®¡çš„è¯´æœåŠ›å¯¹ç”¨æˆ·è¡Œä¸ºçš„å½±å“ã€‚ä¼ ç»Ÿçš„A/Bæµ‹è¯•æ–¹æ³•è™½ç„¶å¸¸ç”¨ï¼Œä½†æˆæœ¬é«˜ä¸”è€—æ—¶ã€‚æˆ‘ä»¬æå‡ºäº†WiserUI-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæˆå¯¹UIè®¾è®¡è¯´æœåŠ›è¯„ä¼°çš„åŸºå‡†ï¼ŒåŒ…å«300å¯¹çœŸå®çš„UIå›¾åƒåŠå…¶A/Bæµ‹è¯•ç»“æœå’Œä¸“å®¶ç†ç”±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†G-FOCUSï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¨ç†ç­–ç•¥ï¼Œèƒ½å¤Ÿæé«˜åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„è¯´æœåŠ›è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.02686",
            "title": "Sailing AI by the Stars: A Survey of Learning from Rewards in\n  Post-Training and Test-Time Scaling of Large Language Models",
            "url": "https://huggingface.co/papers/2505.02686",
            "abstract": "Recent developments in Large Language Models (LLMs) have shifted from pre-training scaling to post-training and test-time scaling. Across these developments, a key unified paradigm has arisen: Learning from Rewards, where reward signals act as the guiding stars to steer LLM behavior. It has underpinned a wide range of prevalent techniques, such as reinforcement learning (in RLHF, DPO, and GRPO), reward-guided decoding, and post-hoc correction. Crucially, this paradigm enables the transition from passive learning from static data to active learning from dynamic feedback. This endows LLMs with aligned preferences and deep reasoning capabilities. In this survey, we present a comprehensive overview of the paradigm of learning from rewards. We categorize and analyze the strategies under this paradigm across training, inference, and post-inference stages. We further discuss the benchmarks for reward models and the primary applications. Finally we highlight the challenges and future directions. We maintain a paper collection at https://github.com/bobxwu/learning-from-rewards-llm-papers.",
            "score": 4,
            "issue_id": 3706,
            "pub_date": "2025-05-05",
            "pub_date_card": {
                "ru": "5 Ğ¼Ğ°Ñ",
                "en": "May 5",
                "zh": "5æœˆ5æ—¥"
            },
            "hash": "22b290e68229e62f",
            "authors": [
                "Xiaobao Wu"
            ],
            "affiliations": [
                "Nanyang Technological University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.02686.jpg",
            "data": {
                "categories": [
                    "#survey",
                    "#training",
                    "#rlhf",
                    "#alignment",
                    "#benchmark",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼: ĞºĞ»ÑÑ‡ Ğº ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ”Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¾Ğ±Ğ·Ğ¾Ñ€ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸ĞµĞ¼ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM). ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¸Ğ³Ğ¼Ñ‹ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğ°Ñ… Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ¸ Ğ¿Ğ¾ÑÑ‚-Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸. ĞĞ±ÑÑƒĞ¶Ğ´Ğ°ÑÑ‚ÑÑ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‚ LLM Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚ Ğ¿Ğ°ÑÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğº Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·ÑŒÑ. Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ñ‚Ğ°ĞºĞ¶Ğµ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ğµ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² ÑÑ‚Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Harnessing Rewards: The Future of Learning in LLMs",
                    "desc": "This paper discusses the evolution of Large Language Models (LLMs) focusing on the shift from pre-training to learning from rewards. It highlights how reward signals guide LLM behavior through techniques like reinforcement learning, reward-guided decoding, and post-hoc correction. The authors categorize various strategies used in training, inference, and post-inference stages, emphasizing the importance of dynamic feedback for improving model alignment and reasoning. Additionally, the paper addresses benchmarks for reward models and outlines future challenges and directions in this area."
                },
                "zh": {
                    "title": "ä»å¥–åŠ±ä¸­å­¦ä¹ ï¼Œèµ‹èƒ½å¤§å‹è¯­è¨€æ¨¡å‹",
                    "desc": "æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‘å±•ä»é¢„è®­ç»ƒæ‰©å±•åˆ°åè®­ç»ƒå’Œæµ‹è¯•æ—¶æ‰©å±•ã€‚ä¸€ä¸ªå…³é”®çš„ç»Ÿä¸€èŒƒå¼å‡ºç°äº†ï¼šä»å¥–åŠ±ä¸­å­¦ä¹ ï¼Œå…¶ä¸­å¥–åŠ±ä¿¡å·ä½œä¸ºæŒ‡å¯¼æ˜Ÿï¼Œå¼•å¯¼LLMçš„è¡Œä¸ºã€‚è¿™ä¸ªèŒƒå¼æ”¯æŒäº†è®¸å¤šæµè¡Œçš„æŠ€æœ¯ï¼Œå¦‚å¼ºåŒ–å­¦ä¹ ï¼ˆåœ¨RLHFã€DPOå’ŒGRPOä¸­ï¼‰ã€å¥–åŠ±å¼•å¯¼è§£ç å’Œäº‹åä¿®æ­£ã€‚é€šè¿‡è¿™ä¸ªèŒƒå¼ï¼ŒLLMsèƒ½å¤Ÿä»é™æ€æ•°æ®çš„è¢«åŠ¨å­¦ä¹ è½¬å‘ä»åŠ¨æ€åé¦ˆçš„ä¸»åŠ¨å­¦ä¹ ï¼Œèµ‹äºˆå®ƒä»¬å¯¹é½çš„åå¥½å’Œæ·±åº¦æ¨ç†èƒ½åŠ›ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.05621",
            "title": "A Preliminary Study for GPT-4o on Image Restoration",
            "url": "https://huggingface.co/papers/2505.05621",
            "abstract": "OpenAI's GPT-4o model, integrating multi-modal inputs and outputs within an autoregressive architecture, has demonstrated unprecedented performance in image generation. In this work, we investigate its potential impact on the image restoration community. We present the first systematic evaluation of GPT-4o across diverse restoration tasks. Our experiments reveal that, although restoration outputs from GPT-4o are visually appealing, they often suffer from pixel-level structural fidelity when compared to ground-truth images. Common issues are variations in image proportions, shifts in object positions and quantities, and changes in viewpoint.To address it, taking image dehazing, derainning, and low-light enhancement as representative case studies, we show that GPT-4o's outputs can serve as powerful visual priors, substantially enhancing the performance of existing dehazing networks. It offers practical guidelines and a baseline framework to facilitate the integration of GPT-4o into future image restoration pipelines. We hope the study on GPT-4o image restoration will accelerate innovation in the broader field of image generation areas. To support further research, we will release GPT-4o-restored images from over 10 widely used image restoration datasets.",
            "score": 0,
            "issue_id": 3709,
            "pub_date": "2025-05-08",
            "pub_date_card": {
                "ru": "8 Ğ¼Ğ°Ñ",
                "en": "May 8",
                "zh": "5æœˆ8æ—¥"
            },
            "hash": "4fd37a23cd5db52f",
            "authors": [
                "Hao Yang",
                "Yan Yang",
                "Ruikun Zhang",
                "Liyuan Pan"
            ],
            "affiliations": [
                "Australian National University",
                "Beijing Institute of Technology"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.05621.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#dataset",
                    "#cv",
                    "#multimodal",
                    "#open_source",
                    "#games"
                ],
                "emoji": "ğŸ–¼ï¸",
                "ru": {
                    "title": "GPT-4o: ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ€ÑƒĞ±ĞµĞ¶ Ğ² Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
                    "desc": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ GPT-4o Ğ¾Ñ‚ OpenAI Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° Ğ±ĞµÑĞ¿Ñ€ĞµÑ†ĞµĞ´ĞµĞ½Ñ‚Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ»Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ GPT-4o Ğ² Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹. Ğ¥Ğ¾Ñ‚Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹, Ğ¾Ğ½Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾ ÑÑ‚Ñ€Ğ°Ğ´Ğ°ÑÑ‚ Ğ¾Ñ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸. Ğ¢ĞµĞ¼ Ğ½Ğµ Ğ¼ĞµĞ½ĞµĞµ, Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ GPT-4o Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑĞ»ÑƒĞ¶Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ°Ğ¼Ğ¸, Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ÑĞµÑ‚ĞµĞ¹ Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ñ‹Ğ¼ĞºĞ¸, Ğ´Ğ¾Ğ¶Ğ´Ñ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸."
                },
                "en": {
                    "title": "Harnessing GPT-4o for Enhanced Image Restoration",
                    "desc": "The paper explores the capabilities of OpenAI's GPT-4o model in the field of image restoration, highlighting its ability to generate visually appealing images. Despite its impressive outputs, the model struggles with maintaining pixel-level accuracy, leading to issues like incorrect object positioning and altered image proportions. The authors demonstrate that GPT-4o can enhance existing image restoration techniques, particularly in tasks like dehazing and deraining, by providing valuable visual priors. This work aims to establish a foundation for integrating GPT-4o into future restoration workflows and encourages further research in image generation."
                },
                "zh": {
                    "title": "GPT-4oï¼šå›¾åƒä¿®å¤çš„æ–°åŠ¨åŠ›",
                    "desc": "OpenAIçš„GPT-4oæ¨¡å‹ç»“åˆäº†å¤šæ¨¡æ€è¾“å…¥å’Œè¾“å‡ºï¼Œå±•ç°äº†åœ¨å›¾åƒç”Ÿæˆæ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚æœ¬æ–‡ç³»ç»Ÿè¯„ä¼°äº†GPT-4oåœ¨å›¾åƒä¿®å¤ä»»åŠ¡ä¸­çš„æ½œåœ¨å½±å“ï¼Œå°½ç®¡å…¶ç”Ÿæˆçš„ä¿®å¤å›¾åƒåœ¨è§†è§‰ä¸Šå¸å¼•äººï¼Œä½†åœ¨åƒç´ çº§ç»“æ„ä¿çœŸåº¦ä¸Šä¸çœŸå®å›¾åƒç›¸æ¯”å­˜åœ¨é—®é¢˜ã€‚æˆ‘ä»¬é€šè¿‡å›¾åƒå»é›¾ã€å»é›¨å’Œä½å…‰å¢å¼ºç­‰æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†GPT-4oçš„è¾“å‡ºå¯ä»¥ä½œä¸ºå¼ºå¤§çš„è§†è§‰å…ˆéªŒï¼Œæ˜¾è‘—æå‡ç°æœ‰å»é›¾ç½‘ç»œçš„æ€§èƒ½ã€‚å¸Œæœ›æœ¬ç ”ç©¶èƒ½åŠ é€Ÿå›¾åƒç”Ÿæˆé¢†åŸŸçš„åˆ›æ–°ï¼Œå¹¶å°†å‘å¸ƒæ¥è‡ª10ä¸ªå¹¿æ³›ä½¿ç”¨çš„å›¾åƒä¿®å¤æ•°æ®é›†çš„GPT-4oä¿®å¤å›¾åƒä»¥æ”¯æŒè¿›ä¸€æ­¥ç ”ç©¶ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-09.html",
    "link_next": "2025-05-13.html",
    "link_month": "2025-05.html",
    "short_date_prev": {
        "ru": "09.05",
        "en": "05/09",
        "zh": "5æœˆ9æ—¥"
    },
    "short_date_next": {
        "ru": "13.05",
        "en": "05/13",
        "zh": "5æœˆ13æ—¥"
    },
    "categories": {
        "#dataset": 3,
        "#data": 0,
        "#benchmark": 6,
        "#agents": 1,
        "#cv": 2,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 1,
        "#inference": 2,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 2,
        "#architecture": 1,
        "#healthcare": 1,
        "#training": 3,
        "#robotics": 1,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 0,
        "#reasoning": 3,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 4,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 1,
        "#science": 1,
        "#low_resource": 2
    },
    "zh": {
        "text": "æˆ‘ä»¬ä»‹ç»äº† Bielik v3ï¼Œè¿™æ˜¯ä¸€ç³»åˆ—ä¸“ä¸ºæ³¢å…°è¯­å¤„ç†ä¼˜åŒ–çš„å‚æ•°é«˜æ•ˆç”Ÿæˆæ–‡æœ¬æ¨¡å‹ï¼ˆ1.5B å’Œ 4.5Bï¼‰ã€‚è¿™äº›æ¨¡å‹å±•ç¤ºäº†è¾ƒå°ä½†ä¼˜åŒ–è‰¯å¥½çš„æ¶æ„å¯ä»¥å®ç°ä¸å¤§å¾—å¤šæ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶éœ€è¦æ›´å°‘çš„è®¡ç®—èµ„æºã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬è‡ªå®šä¹‰æ³¢å…°è¯­åˆ†è¯å™¨ï¼ˆAPT4ï¼‰ã€å¹³è¡¡ä¸åŒæŒ‡ä»¤ç±»å‹å­¦ä¹ çš„åŠ æƒæŒ‡ä»¤äº¤å‰ç†µæŸå¤±å’Œæ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´çš„è‡ªé€‚åº”å­¦ä¹ ç‡ã€‚ç»è¿‡ç²¾å¿ƒç­–åˆ’çš„ 292 äº¿ä¸ªæ ‡è®°å’Œ 303 ç™¾ä¸‡æ–‡æ¡£çš„è®­ç»ƒï¼Œè¿™äº›æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚4.5B å‚æ•°æ¨¡å‹çš„ç»“æœä¸å…¶ 2-3 å€å¤§å°çš„æ¨¡å‹ç«äº‰åŠ›ç›¸å½“ï¼Œè€Œ 1.5B æ¨¡å‹åˆ™åœ¨å…¶æå…¶ç´§å‡‘çš„é…ç½®ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚",
        "title": "Bielik v3 Small: Technical Report",
        "pinyin": "WÇ’men jiÃ¨shÃ o le Bielik v3, zhÃ¨ shÃ¬ yÄ« xÃ¬liÃ¨ zhuÄn wÃ¨i BÅlÃ¡n yÇ” chÇ”lÇ yÅuhuÃ  de cÄnshÃ¹ gÄoxiÃ o shÄ“ngchÃ©ng wÃ©nbÄ›n mÃ³xÃ­ng (1.5B hÃ© 4.5B). ZhÃ¨xiÄ“ mÃ³xÃ­ng zhÇnshÃ¬ le jiÃ o xiÇo dÃ n yÅuhuÃ  liÃ¡ng hÇo de jiÃ gÃ²u kÄ›yÇ shÃ­xiÃ n yÇ” dÃ  dÃ© duÅ mÃ³xÃ­ng xiÃ ngdÄng de xÃ­ngnÃ©ng, tÃ³ngshÃ­ xÅ«yÃ o gÃ¨ng shÇo de jÃ¬suÃ n zÄ«yuÃ¡n. WÇ’men de fÄngfÇ bÄokuÃ² zÃ¬dÃ¬ngyÃ¬ BÅlÃ¡n yÇ” fÄ“ncÃ­qÃ¬ (APT4), pÃ­ng hÃ©ng bÃ¹tÃ³ng zhÇlÃ¬ng lÃ¨ixÃ­ng xuÃ©xÃ­ de jiÄquÃ¡n zhÇlÃ¬ng jiÄochÄ shÄngsÇ”n yÇ” gÄ“njÃ¹ xÃ¹nliÃ n jÃ¬ndÃ¹ dÃ²ngtÃ i tiÃ¡ojiÃ© de zÃ¬shÃ¬yÃ¬ng xuÃ©xÃ­ lÇœ. JÄ«ngxÄ«n cÃ¨huÃ  de 292 yÃ¬ gÃ¨ biÄojÃ¬ hÃ© 303 bÇi wÃ n wÃ©njiÃ n de xÃ¹nliÃ n, zhÃ¨xiÄ“ mÃ³xÃ­ng zÃ i duÅgÃ¨ jÄ«zhÇ”n cÃ¨shÃ¬ zhÅng biÇoxiÃ n chÅ«sÃ¨. 4.5B cÄnshÃ¹ mÃ³xÃ­ng de jiÃ©guÇ’ yÇ” qÃ­ 2-3 bÃ¨i dÃ xÃ¬ao de mÃ³xÃ­ng jÃ¬ngzhÄ“nglÃ¬ xiÃ ngdÄng, Ã©r 1.5B mÃ³xÃ­ng zÃ© zÃ i qÃ­ qÃ­ tÃ¨ jÇnkÇ’u de pÃ¨izhÃ¬ xiÃ  biÇoxiÃ n chÅ« qiÃ¡ngdÃ  de xÃ­ngnÃ©ng.",
        "vocab": "[\n    {\"word\": \"ä»‹ç»\", \"pinyin\": \"jiÃ¨ shÃ o\", \"trans\": \"introduce\"},\n    {\"word\": \"ç³»åˆ—\", \"pinyin\": \"xÃ¬ liÃ¨\", \"trans\": \"series\"},\n    {\"word\": \"ä¸“ä¸º\", \"pinyin\": \"zhuÄn wÃ¨i\", \"trans\": \"specially for\"},\n    {\"word\": \"ä¼˜åŒ–\", \"pinyin\": \"yÅu huÃ \", \"trans\": \"optimize\"},\n    {\"word\": \"å‚æ•°\", \"pinyin\": \"cÄn shÃ¹\", \"trans\": \"parameters\"},\n    {\"word\": \"é«˜æ•ˆ\", \"pinyin\": \"gÄo xiÃ o\", \"trans\": \"efficient\"},\n    {\"word\": \"ç”Ÿæˆ\", \"pinyin\": \"shÄ“ng chÃ©ng\", \"trans\": \"generate\"},\n    {\"word\": \"æ¨¡å‹\", \"pinyin\": \"mÃ³ xÃ­ng\", \"trans\": \"model\"},\n    {\"word\": \"å±•ç¤º\", \"pinyin\": \"zhÇn shÃ¬\", \"trans\": \"demonstrate\"},\n    {\"word\": \"æ¶æ„\", \"pinyin\": \"jiÃ  gÃ²u\", \"trans\": \"architecture\"},\n    {\"word\": \"ç›¸å½“\", \"pinyin\": \"xiÄng dÄng\", \"trans\": \"equivalent\"},\n    {\"word\": \"æ€§èƒ½\", \"pinyin\": \"xÃ¬ng nÃ©ng\", \"trans\": \"performance\"},\n    {\"word\": \"è®¡ç®—\", \"pinyin\": \"jÃ¬ suÃ n\", \"trans\": \"compute\"},\n    {\"word\": \"èµ„æº\", \"pinyin\": \"zÄ« yuÃ¡n\", \"trans\": \"resources\"},\n    {\"word\": \"æ–¹æ³•\", \"pinyin\": \"fÄng fÇ\", \"trans\": \"method\"},\n    {\"word\": \"è‡ªå®šä¹‰\", \"pinyin\": \"zÃ¬ dÃ¬ng yÃ¬\", \"trans\": \"customize\"},\n    {\"word\": \"åˆ†è¯å™¨\", \"pinyin\": \"fÄ“n cÃ­ qÃ¬\", \"trans\": \"tokenizer\"},\n    {\"word\": \"å¹³è¡¡\", \"pinyin\": \"pÃ­ng hÃ©ng\", \"trans\": \"balance\"},\n    {\"word\": \"æŒ‡ä»¤\", \"pinyin\": \"zhÇ lÃ¬ng\", \"trans\": \"instruction\"},\n    {\"word\": \"ç±»å‹\", \"pinyin\": \"lÃ¨i xÃ­ng\", \"trans\": \"type\"},\n    {\"word\": \"å­¦ä¹ \", \"pinyin\": \"xuÃ© xÃ­\", \"trans\": \"learn\"},\n    {\"word\": \"åŠ æƒ\", \"pinyin\": \"jiÄ quÃ¡n\", \"trans\": \"weighted\"},\n    {\"word\": \"äº¤å‰ç†µ\", \"pinyin\": \"jiÄo chÄ shÄng\", \"trans\": \"cross-entropy\"},\n    {\"word\": \"æŸå¤±\", \"pinyin\": \"sÇ”n shÄ«\", \"trans\": \"loss\"},\n    {\"word\": \"è‡ªé€‚åº”\", \"pinyin\": \"zÃ¬ shÃ¬ yÃ¬ng\", \"trans\": \"adaptive\"},\n    {\"word\": \"å­¦ä¹ ç‡\", \"pinyin\": \"xuÃ© xÃ­ lÇœ\", \"trans\": \"learning rate\"},\n    {\"word\": \"ç­–åˆ’\", \"pinyin\": \"cÃ¨ huÃ \", \"trans\": \"plan\"},\n    {\"word\": \"æ ‡è®°\", \"pinyin\": \"biÄo jÃ¬\", \"trans\": \"token\"},\n    {\"word\": \"æ–‡æ¡£\", \"pinyin\": \"wÃ©n dÃ ng\", \"trans\": \"document\"},\n    {\"word\": \"è®­ç»ƒ\", \"pinyin\": \"xÃ¹n liÃ n\", \"trans\": \"train\"},\n    {\"word\": \"åŸºå‡†\", \"pinyin\": \"jÄ« zhÇ”n\", \"trans\": \"benchmark\"},\n    {\"word\": \"æµ‹è¯•\", \"pinyin\": \"cÃ¨ shÃ¬\", \"trans\": \"test\"},\n    {\"word\": \"è¡¨ç°\", \"pinyin\": \"biÇo xiÃ n\", \"trans\": \"perform\"},\n    {\"word\": \"å‡ºè‰²\", \"pinyin\": \"chÅ« sÃ¨\", \"trans\": \"outstanding\"},\n    {\"word\": \"ç»“æœ\", \"pinyin\": \"jiÃ© guÇ’\", \"trans\": \"result\"},\n    {\"word\": \"ç«äº‰åŠ›\", \"pinyin\": \"jÃ¬ng zhÄ“ng lÃ¬\", \"trans\": \"competitiveness\"},\n    {\"word\": \"é…ç½®\", \"pinyin\": \"pÃ¨i zhÃ¬\", \"trans\": \"configuration\"},\n    {\"word\": \"ç´§å‡‘\", \"pinyin\": \"jÇn cÃ²u\", \"trans\": \"compact\"},\n    {\"word\": \"å¼ºå¤§\", \"pinyin\": \"qiÃ¡ng dÃ \", \"trans\": \"powerful\"}\n]",
        "trans": "We introduced Bielik v3, a series of parameter-efficient text generation models optimized specifically for Polish language processing (1.5B and 4.5B). These models demonstrate that smaller but well-optimized architectures can achieve performance comparable to much larger models while requiring fewer computational resources. Our approach includes a custom Polish tokenizer (APT4), weighted instruction cross-entropy loss to balance learning across different instruction types, and adaptive learning rates dynamically adjusted according to training progress. With meticulously planned training on 292 billion tokens and 303 million documents, these models perform excellently on multiple benchmarks. The 4.5B parameter model's results are competitive with models 2-3 times its size, while the 1.5B model shows strong performance in its extremely compact configuration.",
        "update_ts": "2025-05-12 10:13"
    }
}