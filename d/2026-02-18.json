{
    "date": {
        "ru": "18 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
        "en": "February 18",
        "zh": "2æœˆ18æ—¥"
    },
    "time_utc": "2026-02-18 04:14",
    "weekday": 2,
    "issue_id": 1104,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2602.14299",
            "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
            "url": "https://huggingface.co/papers/2602.14299",
            "abstract": "Large language model agents in networked environments exhibit dynamic stability without true social convergence, maintaining individual diversity while lacking collective influence structures.  \t\t\t\t\tAI-generated summary \t\t\t\t As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitative diagnostic framework for dynamic evolution in AI agent societies, measuring semantic stabilization, lexical turnover, individual inertia, influence persistence, and collective consensus. Our analysis reveals a system in dynamic balance in Moltbook: while global semantic averages stabilize rapidly, individual agents retain high diversity and persistent lexical turnover, defying homogenization. However, agents exhibit strong individual inertia and minimal adaptive response to interaction partners, preventing mutual influence and consensus. Consequently, influence remains transient with no persistent supernodes, and the society fails to develop stable collective influence anchors due to the absence of shared social memory. These findings demonstrate that scale and interaction density alone are insufficient to induce socialization, providing actionable design and analysis principles for upcoming next-generation AI agent societies.",
            "score": 9,
            "issue_id": 1104,
            "pub_date": "2026-02-15",
            "pub_date_card": {
                "ru": "15 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 15",
                "zh": "2æœˆ15æ—¥"
            },
            "hash": "8484c159d88b35e7",
            "authors": [
                "Ming Li",
                "Xirui Li",
                "Tianyi Zhou"
            ],
            "affiliations": [
                "Mohamed bin Zayed University of Artificial Intelligence",
                "University of Maryland"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.14299.jpg",
            "data": {
                "categories": [],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "ĞĞ³ĞµĞ½Ñ‚Ñ‹ Ğ±ĞµĞ· ÑĞ¾Ñ†Ğ¸ÑƒĞ¼Ğ°: Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ˜Ğ˜-Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğ° Ğ½Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚ÑÑ Ğº ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑÑƒ",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ·ÑƒÑ‡Ğ°ĞµÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºÑƒ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² ÑĞµÑ‚ĞµĞ²Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸ÑÑ…, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ, Ğ¿Ğ¾Ğ´Ğ²ĞµÑ€Ğ³Ğ°ÑÑ‚ÑÑ Ğ»Ğ¸ Ğ¾Ğ½Ğ¸ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ğ³ĞµĞ½Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ´Ğ¾Ğ±Ğ½Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¸Ğ¼ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½ÑƒÑ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ»ĞµĞºÑĞ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹, Ğ¸Ğ½ĞµÑ€Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ Ğ² Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğµ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ½ĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ñ, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ¾Ğ±Ğ»Ğ°Ğ´Ğ°ÑÑ‚ ÑĞ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½ĞµÑ€Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ. Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ± Ğ¸ Ğ¿Ğ»Ğ¾Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ½Ğ¾Ğ²ĞµĞ½Ğ¸Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ±ĞµĞ· Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ¸ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼Ğ¾Ğ²."
                },
                "en": {
                    "title": "Dynamic Diversity in AI Agent Societies",
                    "desc": "This paper explores how large language model agents behave in networked environments, focusing on their ability to maintain individual diversity without forming a collective influence. The authors introduce a framework to quantitatively analyze the dynamics of these AI agent societies, measuring factors like semantic stabilization and lexical turnover. Their findings indicate that while the overall language used by agents stabilizes, individual agents continue to evolve independently, showing little adaptation to each other. This lack of mutual influence prevents the formation of stable social structures, suggesting that simply increasing the number of agents does not lead to effective socialization."
                },
                "zh": {
                    "title": "åŠ¨æ€ç¨³å®šæ€§ä¸ä¸ªä½“å¤šæ ·æ€§çš„å¹³è¡¡",
                    "desc": "åœ¨ç½‘ç»œç¯å¢ƒä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†è¡¨ç°å‡ºåŠ¨æ€ç¨³å®šæ€§ï¼Œä½†å¹¶æœªå®ç°çœŸæ­£çš„ç¤¾ä¼šè¶‹åŒã€‚è¿™äº›ä»£ç†ä¿æŒä¸ªä½“å¤šæ ·æ€§ï¼Œç¼ºä¹é›†ä½“å½±å“ç»“æ„ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡å…¨çƒè¯­ä¹‰å¹³å‡å€¼è¿…é€Ÿç¨³å®šï¼Œä¸ªä½“ä»£ç†å´ä¿æŒé«˜åº¦å¤šæ ·æ€§å’ŒæŒç»­çš„è¯æ±‡å˜åŠ¨ã€‚ç»“æœæ˜¾ç¤ºï¼Œä»£ç†ä¹‹é—´çš„ç›¸äº’å½±å“å¾®å¼±ï¼Œæ— æ³•å½¢æˆç¨³å®šçš„é›†ä½“å½±å“é”šç‚¹ï¼Œæç¤ºæˆ‘ä»¬åœ¨è®¾è®¡ä¸‹ä¸€ä»£AIä»£ç†ç¤¾ä¼šæ—¶éœ€è€ƒè™‘è¿™äº›å› ç´ ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.15763",
            "title": "GLM-5: from Vibe Coding to Agentic Engineering",
            "url": "https://huggingface.co/papers/2602.15763",
            "abstract": "GLM-5 advances foundation models with DSA for cost reduction, asynchronous reinforcement learning for improved alignment, and enhanced coding capabilities for real-world software engineering.  \t\t\t\t\tAI-generated summary \t\t\t\t We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.",
            "score": 5,
            "issue_id": 1104,
            "pub_date": "2026-02-17",
            "pub_date_card": {
                "ru": "17 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 17",
                "zh": "2æœˆ17æ—¥"
            },
            "hash": "fda04435921a43b6",
            "authors": [
                "GLM-5 Team",
                ":",
                "Aohan Zeng",
                "Xin Lv",
                "Zhenyu Hou",
                "Zhengxiao Du",
                "Qinkai Zheng",
                "Bin Chen",
                "Da Yin",
                "Chendi Ge",
                "Chengxing Xie",
                "Cunxiang Wang",
                "Gengzheng Pan",
                "Hao Zeng",
                "Haoke Zhang",
                "Haoran Wang",
                "Huilong Chen",
                "Jiajie Zhang",
                "Jian Jiao",
                "Jiaqi Guo",
                "Jingsen Wang",
                "Jingzhao Du",
                "Jinzhu Wu",
                "Kedong Wang",
                "Lei Li",
                "Lin Fan",
                "Lucen Zhong",
                "Mingdao Liu",
                "Mingming Zhao",
                "Pengfan Du",
                "Qian Dong",
                "Rui Lu",
                "Shuang-Li",
                "Shulin Cao",
                "Song Liu",
                "Ting Jiang",
                "Xiaodong Chen",
                "Xiaohan Zhang",
                "Xuancheng Huang",
                "Xuezhen Dong",
                "Yabo Xu",
                "Yao Wei",
                "Yifan An",
                "Yilin Niu",
                "Yitong Zhu",
                "Yuanhao Wen",
                "Yukuo Cen",
                "Yushi Bai",
                "Zhongpei Qiao",
                "Zihan Wang",
                "Zikang Wang",
                "Zilin Zhu",
                "Ziqiang Liu",
                "Zixuan Li",
                "Bojie Wang",
                "Bosi Wen",
                "Can Huang",
                "Changpeng Cai",
                "Chao Yu",
                "Chen Li",
                "Chen Li",
                "Chenghua Huang",
                "Chengwei Hu",
                "Chenhui Zhang",
                "Chenzheng Zhu",
                "Congfeng Yin",
                "Daoyan Lin",
                "Dayong Yang",
                "Di Wang",
                "Ding Ai",
                "Erle Zhu",
                "Fangzhou Yi",
                "Feiyu Chen",
                "Guohong Wen",
                "Hailong Sun",
                "Haisha Zhao",
                "Haiyi Hu",
                "Hanchen Zhang",
                "Hanrui Liu",
                "Hanyu Zhang",
                "Hao Peng",
                "Hao Tai",
                "Haobo Zhang",
                "He Liu",
                "Hongwei Wang",
                "Hongxi Yan",
                "Hongyu Ge",
                "Huan Liu",
                "Huan Liu",
                "Huanpeng Chu",
                "Jia'ni Zhao",
                "Jiachen Wang",
                "Jiajing Zhao",
                "Jiamin Ren",
                "Jiapeng Wang",
                "Jiaxin Zhang",
                "Jiayi Gui",
                "Jiayue Zhao",
                "Jijie Li",
                "Jing An",
                "Jing Li",
                "Jingwei Yuan",
                "Jinhua Du",
                "Jinxin Liu",
                "Junkai Zhi",
                "Junwen Duan",
                "Kaiyue Zhou",
                "Kangjian Wei",
                "Ke Wang",
                "Keyun Luo",
                "Laiqiang Zhang",
                "Leigang Sha",
                "Liang Xu",
                "Lindong Wu",
                "Lintao Ding",
                "Lu Chen",
                "Minghao Li",
                "Nianyi Lin",
                "Pan Ta",
                "Qiang Zou",
                "Rongjun Song",
                "Ruiqi Yang",
                "Shangqing Tu",
                "Shangtong Yang",
                "Shaoxiang Wu",
                "Shengyan Zhang",
                "Shijie Li",
                "Shuang Li",
                "Shuyi Fan",
                "Wei Qin",
                "Wei Tian",
                "Weining Zhang",
                "Wenbo Yu",
                "Wenjie Liang",
                "Xiang Kuang",
                "Xiangmeng Cheng",
                "Xiangyang Li",
                "Xiaoquan Yan",
                "Xiaowei Hu",
                "Xiaoying Ling",
                "Xing Fan",
                "Xingye Xia",
                "Xinyuan Zhang",
                "Xinze Zhang",
                "Xirui Pan",
                "Xunkai Zhang",
                "Yandong Wu",
                "Yanfu Li",
                "Yidong Wang",
                "Yifan Zhu",
                "Yijun Tan",
                "Yilin Zhou",
                "Yiming Pan",
                "Ying Zhang",
                "Yinpei Su",
                "Yipeng Geng",
                "Yipeng Geng",
                "Yong Yan",
                "Yonglin Tan",
                "Yuean Bi",
                "Yuhan Shen",
                "Yuhao Yang",
                "Yujiang Li",
                "Yunan Liu",
                "Yunqing Wang",
                "Yuntao Li",
                "Yurong Wu",
                "Yutao Zhang",
                "Yuxi Duan",
                "Yuxuan Zhang",
                "Zezhen Liu",
                "Zhengtao Jiang",
                "Zhenhe Yan",
                "Zheyu Zhang",
                "Zhixiang Wei",
                "Zhuo Chen",
                "Zhuoer Feng",
                "Zijun Yao",
                "Ziwei Chai",
                "Ziyuan Wang",
                "Zuzhou Zhang",
                "Bin Xu",
                "Minlie Huang",
                "Hongning Wang",
                "Juanzi Li",
                "Yuxiao Dong",
                "Jie Tang"
            ],
            "affiliations": [
                "Tsinghua University",
                "Zhipu AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.15763.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#agents",
                    "#training",
                    "#alignment",
                    "#optimization",
                    "#architecture",
                    "#plp",
                    "#open_source",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ",
                    "desc": "GLM-5 Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ DSA Ğ´Ğ»Ñ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚ Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ². Ğ”Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ ĞµÑ‘ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñ‹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°ĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ² Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´ĞºÑ€ĞµĞ¿Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‰Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ĞµĞµ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒÑÑ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ÑÑ… Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ¾Ğ¼. GLM-5 Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ñ‹Ğ´Ğ°ÑÑ‰Ğ¸ĞµÑÑ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹ Ğ² end-to-end Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼."
                },
                "en": {
                    "title": "GLM-5: Revolutionizing Software Engineering with Advanced AI",
                    "desc": "GLM-5 is a cutting-edge foundation model that enhances the capabilities of machine learning in software engineering. It utilizes Dynamic Sparse Attention (DSA) to lower the costs associated with training and inference while preserving the ability to handle long contexts. The model also incorporates asynchronous reinforcement learning to improve alignment and efficiency, allowing it to learn better from complex interactions. As a result, GLM-5 sets new benchmarks in real-world coding tasks, outperforming previous models in software engineering applications."
                },
                "zh": {
                    "title": "GLM-5ï¼šæå‡ç¼–ç èƒ½åŠ›ä¸æˆæœ¬æ•ˆç›Šçš„åŸºç¡€æ¨¡å‹",
                    "desc": "GLM-5æ˜¯ä¸€ç§æ–°ä¸€ä»£åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥åŠ¨æ€ç»“æ„è°ƒæ•´ï¼ˆDSAï¼‰æ¥é™ä½è®­ç»ƒå’Œæ¨ç†æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒé•¿ä¸Šä¸‹æ–‡çš„å‡†ç¡®æ€§ã€‚è¯¥æ¨¡å‹é‡‡ç”¨å¼‚æ­¥å¼ºåŒ–å­¦ä¹ åŸºç¡€è®¾æ–½ï¼Œæ˜¾è‘—æé«˜äº†åæœŸè®­ç»ƒçš„æ•ˆç‡ï¼Œä½¿ç”Ÿæˆä¸è®­ç»ƒè§£è€¦ã€‚GLM-5è¿˜æå‡ºäº†æ–°å‹çš„å¼‚æ­¥ä»£ç†å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä»å¤æ‚çš„é•¿æ—¶é—´äº¤äº’ä¸­å­¦ä¹ ã€‚é€šè¿‡è¿™äº›åˆ›æ–°ï¼ŒGLM-5åœ¨ä¸»è¦å¼€æ”¾åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨å®é™…ç¼–ç ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„åŸºå‡†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.15278",
            "title": "Visual Persuasion: What Influences Decisions of Vision-Language Models?",
            "url": "https://huggingface.co/papers/2602.15278",
            "abstract": "Visual-language models' decision-making preferences are studied through controlled image choice tasks with systematic input perturbations, revealing visual vulnerabilities and safety concerns.  \t\t\t\t\tAI-generated summary \t\t\t\t The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference: choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization, adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities, safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.",
            "score": 2,
            "issue_id": 1104,
            "pub_date": "2026-02-17",
            "pub_date_card": {
                "ru": "17 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 17",
                "zh": "2æœˆ17æ—¥"
            },
            "hash": "3406ed25de76ed9b",
            "authors": [
                "Manuel Cherep",
                "Pranav M R",
                "Pattie Maes",
                "Nikhil Singh"
            ],
            "affiliations": [
                "BITS Pilani, Goa, India",
                "Department of Computer Science, Dartmouth College, Hanover, USA",
                "Media Lab, Massachusetts Institute of Technology, Cambridge, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.15278.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#agents",
                    "#multimodal",
                    "#cv"
                ],
                "emoji": "ğŸ”",
                "ru": {
                    "title": "Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ·ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼ÑƒÑ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ñ‚Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸. Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·Ğ¾Ğº Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒÑÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ÑÑ‚, ĞºĞ°Ğº ÑÑ‚Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ²Ğ»Ğ¸ÑÑÑ‚ Ğ½Ğ° Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµĞ¹ĞµÑ€ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹ÑĞ²Ğ»ÑĞµÑ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² VLM, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°ÑƒĞ´Ğ¸Ñ‚ Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²."
                },
                "en": {
                    "title": "Unveiling Visual Preferences in AI Decision-Making",
                    "desc": "This paper investigates how visual-language models (VLMs) make decisions based on images by using controlled tasks that alter the input images. The authors propose a framework that treats the decision-making process of VLMs as a latent visual utility, which can be inferred from the choices made between modified images. They introduce methods for optimizing visual prompts, applying systematic edits to images to see how these changes affect the model's selection probabilities. The findings reveal significant shifts in decision-making based on these edits, highlighting potential vulnerabilities and safety issues in AI systems that rely on visual inputs."
                },
                "zh": {
                    "title": "æ­ç¤ºè§†è§‰è¯­è¨€æ¨¡å‹çš„å†³ç­–åå¥½ä¸å®‰å…¨éšæ‚£",
                    "desc": "æœ¬ç ”ç©¶æ¢è®¨äº†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å›¾åƒé€‰æ‹©ä»»åŠ¡ä¸­çš„å†³ç­–åå¥½ã€‚é€šè¿‡ç³»ç»Ÿæ€§åœ°æ‰°åŠ¨è¾“å…¥å›¾åƒï¼Œæˆ‘ä»¬æ­ç¤ºäº†è¿™äº›æ¨¡å‹çš„è§†è§‰è„†å¼±æ€§å’Œå®‰å…¨éšæ‚£ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œé€šè¿‡æ§åˆ¶å›¾åƒé€‰æ‹©ä»»åŠ¡æ¥åˆ†æVLMçš„å†³ç­–å‡½æ•°ï¼Œå¹¶ä¼˜åŒ–è§†è§‰æç¤ºä»¥æé«˜é€‰æ‹©æ¦‚ç‡ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œç»è¿‡ä¼˜åŒ–çš„å›¾åƒç¼–è¾‘æ˜¾è‘—æ”¹å˜äº†æ¨¡å‹çš„é€‰æ‹©æ¦‚ç‡ï¼Œä»è€Œä¸ºå›¾åƒåŸºç¡€çš„AIä»£ç†æä¾›äº†æ›´æœ‰æ•ˆçš„å®¡è®¡å’Œæ²»ç†æ–¹æ³•ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.15112",
            "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
            "url": "https://huggingface.co/papers/2602.15112",
            "abstract": "ResearchGym presents a benchmark environment for evaluating AI agents on end-to-end research tasks, revealing significant capability-reliability gaps in current autonomous agents despite occasional state-of-the-art performance.  \t\t\t\t\tAI-generated summary \t\t\t\t We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.",
            "score": 2,
            "issue_id": 1104,
            "pub_date": "2026-02-16",
            "pub_date_card": {
                "ru": "16 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 16",
                "zh": "2æœˆ16æ—¥"
            },
            "hash": "9e29c2baa76e59ee",
            "authors": [
                "Aniketh Garikaparthi",
                "Manasi Patwardhan",
                "Arman Cohan"
            ],
            "affiliations": [
                "TCS Research",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.15112.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#science",
                    "#agents",
                    "#long_context",
                    "#dataset"
                ],
                "emoji": "ğŸ§ª",
                "ru": {
                    "title": "ĞÑ†ĞµĞ½ĞºĞ° Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ñ‹Ñ… AI Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑÑ…",
                    "desc": "ResearchGym Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ AI Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞºĞ²Ğ¾Ğ·Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¿ÑÑ‚ÑŒ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ñ ĞºĞ¾Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ğ¹ ICML, ICLR Ğ¸ ACL, ÑĞ¾Ğ·Ğ´Ğ°Ğ² 39 Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ³Ğ´Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ñ‚ÑŒ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñ‹, Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ. ĞÑ†ĞµĞ½ĞºĞ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ GPT-5 Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ñ€Ñ‹Ğ² Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ Ğ¸ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ: Ğ°Ğ³ĞµĞ½Ñ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ»Ğ¸Ğ½Ğ¸Ğ¹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ¸Ğ· Ğ¿ÑÑ‚Ğ½Ğ°Ğ´Ñ†Ğ°Ñ‚Ğ¸ ÑĞ»ÑƒÑ‡Ğ°ĞµĞ² Ğ¸ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ğ» Ğ² ÑÑ€ĞµĞ´Ğ½ĞµĞ¼ Ğ»Ğ¸ÑˆÑŒ 26.5% Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ´Ğ°Ñ‡. ĞĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° ÑÑ‚Ğ¾, Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ… frontier Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ state-of-the-art Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, Ğ½Ğ¾ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡."
                },
                "en": {
                    "title": "Bridging the Capability-Reliability Gap in AI Research",
                    "desc": "ResearchGym is a new benchmark environment designed to assess AI agents on complex research tasks. It uses real datasets and evaluation methods from notable machine learning conferences but omits the original methods proposed in the papers. The study reveals that even advanced agents like GPT-5 show a significant gap between their capabilities and reliability, succeeding in only a small fraction of tasks. This highlights persistent challenges in AI, such as managing resources and coordinating experiments, despite occasional high performance."
                },
                "zh": {
                    "title": "è¯„ä¼°AIä»£ç†çš„èƒ½åŠ›ä¸å¯é æ€§å·®è·",
                    "desc": "ResearchGymæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°äººå·¥æ™ºèƒ½ä»£ç†åœ¨ç«¯åˆ°ç«¯ç ”ç©¶ä»»åŠ¡ä¸­çš„åŸºå‡†ç¯å¢ƒã€‚å°½ç®¡æŸäº›ä»£ç†å¶å°”èƒ½è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä½†æˆ‘ä»¬å‘ç°å®ƒä»¬åœ¨èƒ½åŠ›å’Œå¯é æ€§ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚é€šè¿‡å¯¹äº”ç¯‡ä¼šè®®è®ºæ–‡çš„ä»»åŠ¡è¿›è¡Œå®¹å™¨åŒ–å¤„ç†ï¼Œä»£ç†éœ€è¦æå‡ºæ–°å‡è®¾å¹¶è¿›è¡Œå®éªŒï¼Œä»¥è¶…è¶Šäººç±»åŸºçº¿ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œä»£ç†åœ¨15æ¬¡è¯„ä¼°ä¸­ä»…åœ¨1æ¬¡ä¸­è¡¨ç°ä¼˜äºåŸºçº¿ï¼Œä¸”å¹³å‡ä»…å®Œæˆ26.5%çš„å­ä»»åŠ¡ï¼Œæ­ç¤ºäº†é•¿æœŸå¤±è´¥æ¨¡å¼çš„æ™®éæ€§ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.15322",
            "title": "On Surprising Effectiveness of Masking Updates in Adaptive Optimizers",
            "url": "https://huggingface.co/papers/2602.15322",
            "abstract": "Random parameter update masking achieves superior optimization for large language models by inducing curvature-dependent regularization, with a momentum-aligned variant delivering significant performance improvements over state-of-the-art adaptive optimizers.  \t\t\t\t\tAI-generated summary \t\t\t\t Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\\% and 9\\% compared to Adam and Muon, respectively.",
            "score": 1,
            "issue_id": 1104,
            "pub_date": "2026-02-17",
            "pub_date_card": {
                "ru": "17 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 17",
                "zh": "2æœˆ17æ—¥"
            },
            "hash": "de1c836aa6754a7d",
            "authors": [
                "Taejong Joo",
                "Wenhan Xia",
                "Cheolmin Kim",
                "Ming Zhang",
                "Eugene Ie"
            ],
            "affiliations": [
                "Google",
                "Northwestern University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.15322.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#architecture"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğµ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ â€” Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ LLM",
                    "desc": "Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğµ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ². ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ RMSProp Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ Ğ¸Ğ½Ğ´ÑƒÑ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ·Ğ°Ğ²Ğ¸ÑÑÑ‰ĞµĞ¹ Ğ¾Ñ‚ ĞºÑ€Ğ¸Ğ²Ğ¸Ğ·Ğ½Ñ‹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ğ½Ğ¸ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Magma, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ¼Ğ¿ÑƒĞ»ÑŒÑĞ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ LLM Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒÑÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€Ğ¿Ğ»ĞµĞºÑĞ¸Ğ¸ Ğ¸ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° ĞºĞ°Ğº Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²."
                },
                "en": {
                    "title": "Random Masking Revolutionizes LLM Optimization",
                    "desc": "This paper presents a novel approach to optimizing large language models (LLMs) by using random parameter update masking. The authors demonstrate that this method, particularly a masked variant of the RMSProp optimizer, can outperform traditional adaptive optimizers. They introduce a new technique called Momentum-aligned gradient masking (Magma), which enhances the effectiveness of the random masking by aligning it with momentum gradients. The results show significant improvements in model performance, with Magma achieving lower perplexity compared to state-of-the-art optimizers while maintaining low computational costs."
                },
                "zh": {
                    "title": "éšæœºæ©è”½ï¼Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬æ–‡æå‡ºäº†ä¸€ç§éšæœºå‚æ•°æ›´æ–°æ©è”½çš„æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒã€‚é€šè¿‡éšæœºæ©è”½å‚æ•°æ›´æ–°ï¼Œç ”ç©¶è¡¨æ˜è¿™ç§æ–¹æ³•åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­èƒ½å¤Ÿå¼•å…¥ä¸æ›²ç‡ç›¸å…³çš„å‡ ä½•æ­£åˆ™åŒ–ï¼Œä»è€Œå¹³æ»‘ä¼˜åŒ–è½¨è¿¹ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§åä¸ºMagmaçš„åŠ¨é‡å¯¹é½æ¢¯åº¦æ©è”½æ–¹æ³•ï¼Œå®ƒé€šè¿‡åŠ¨é‡ä¸æ¢¯åº¦çš„å¯¹é½æ¥è°ƒèŠ‚æ©è”½æ›´æ–°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMagmaåœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—é™ä½äº†å›°æƒ‘åº¦ï¼Œä¸”è®¡ç®—å¼€é”€æå°ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.07854",
            "title": "Geometry-Aware Rotary Position Embedding for Consistent Video World Model",
            "url": "https://huggingface.co/papers/2602.07854",
            "abstract": "ViewRope, a geometry-aware encoding method, enhances long-term consistency in predictive world models by injecting camera-ray directions into video transformer attention layers, addressing spatial persistence issues through relative ray geometry parameterization.  \t\t\t\t\tAI-generated summary \t\t\t\t Predictive world models that simulate future observations under explicit camera control are fundamental to interactive AI. Despite rapid advances, current systems lack spatial persistence: they fail to maintain stable scene structures over long trajectories, frequently hallucinating details when cameras revisit previously observed locations. We identify that this geometric drift stems from reliance on screen-space positional embeddings, which conflict with the projective geometry required for 3D consistency. We introduce ViewRope, a geometry-aware encoding that injects camera-ray directions directly into video transformer self-attention layers. By parameterizing attention with relative ray geometry rather than pixel locality, ViewRope provides a model-native inductive bias for retrieving 3D-consistent content across temporal gaps. We further propose Geometry-Aware Frame-Sparse Attention, which exploits these geometric cues to selectively attend to relevant historical frames, improving efficiency without sacrificing memory consistency. We also present ViewBench, a diagnostic suite measuring loop-closure fidelity and geometric drift. Our results demonstrate that ViewRope substantially improves long-term consistency while reducing computational costs.",
            "score": 1,
            "issue_id": 1104,
            "pub_date": "2026-02-08",
            "pub_date_card": {
                "ru": "8 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 8",
                "zh": "2æœˆ8æ—¥"
            },
            "hash": "9e1ba6fe1b318876",
            "authors": [
                "Chendong Xiang",
                "Jiajun Liu",
                "Jintao Zhang",
                "Xiao Yang",
                "Zhengwei Fang",
                "Shizun Wang",
                "Zijun Wang",
                "Yingtian Zou",
                "Hang Su",
                "Jun Zhu"
            ],
            "affiliations": [
                "ByteDance",
                "Peking University",
                "Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.07854.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#benchmark",
                    "#architecture",
                    "#3d"
                ],
                "emoji": "ğŸ¬",
                "ru": {
                    "title": "Ğ“ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸",
                    "desc": "ViewRope â€” ÑÑ‚Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾ÑĞ²ĞµĞ´Ğ¾Ğ¼Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½ÑƒÑ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¿Ñ€ĞµĞ´Ğ¸ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ğ¼Ğ¸Ñ€Ğ° Ğ·Ğ° ÑÑ‡Ñ‘Ñ‚ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ»ÑƒÑ‡ĞµĞ¹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ² ÑĞ»Ğ¾Ğ¸ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾-Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ°. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ‚Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ ÑĞºÑ€Ğ°Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´ÑÑ‚ Ğº Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ğ´Ñ€ĞµĞ¹Ñ„Ñƒ Ğ¸ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸ÑĞ¼ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾ÑĞµÑ‰ĞµĞ½Ğ¸Ğ¸ Ñ€Ğ°Ğ½ĞµĞµ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ñ‹Ñ… Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ğ¹. ViewRope Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ·ÑƒĞµÑ‚ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸ĞµĞ¹ Ğ»ÑƒÑ‡ĞµĞ¹ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¿Ğ¸ĞºÑĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ğ¾Ğµ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ 3D-ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğ³Ğ¾. Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾ÑĞ²ĞµĞ´Ğ¾Ğ¼Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ñ€ĞµĞ¶ĞµĞ½Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ ĞºĞ°Ğ´Ñ€Ğ°Ğ¼ Ğ¸ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ ViewBench Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ¼Ñ‹ĞºĞ°Ğ½Ğ¸Ñ Ñ†Ğ¸ĞºĞ»Ğ° Ğ¸ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ´Ñ€ĞµĞ¹Ñ„Ğ°."
                },
                "en": {
                    "title": "Enhancing Consistency in Predictive Models with Geometry-Aware Encoding",
                    "desc": "ViewRope is a new method that improves how predictive world models maintain consistency over time by using camera-ray directions in video transformer attention layers. This approach addresses the problem of spatial persistence, where models often lose track of stable scene structures when revisiting locations. By focusing on relative ray geometry instead of just pixel positions, ViewRope helps the model better understand 3D content across different time frames. Additionally, it introduces a technique called Geometry-Aware Frame-Sparse Attention to enhance efficiency while keeping memory consistent."
                },
                "zh": {
                    "title": "ViewRopeï¼šæå‡é¢„æµ‹æ¨¡å‹çš„é•¿æœŸä¸€è‡´æ€§",
                    "desc": "ViewRopeæ˜¯ä¸€ç§å‡ ä½•æ„ŸçŸ¥ç¼–ç æ–¹æ³•ï¼Œé€šè¿‡å°†ç›¸æœºå…‰çº¿æ–¹å‘æ³¨å…¥è§†é¢‘å˜æ¢å™¨çš„è‡ªæ³¨æ„åŠ›å±‚ï¼Œå¢å¼ºäº†é¢„æµ‹ä¸–ç•Œæ¨¡å‹çš„é•¿æœŸä¸€è‡´æ€§ã€‚å½“å‰çš„ç³»ç»Ÿåœ¨ç©ºé—´æŒä¹…æ€§æ–¹é¢å­˜åœ¨é—®é¢˜ï¼Œæ— æ³•åœ¨é•¿æ—¶é—´è½¨è¿¹ä¸­ä¿æŒç¨³å®šçš„åœºæ™¯ç»“æ„ã€‚æˆ‘ä»¬å‘ç°è¿™ç§å‡ ä½•æ¼‚ç§»æºäºå¯¹å±å¹•ç©ºé—´ä½ç½®åµŒå…¥çš„ä¾èµ–ï¼Œè¿™ä¸3Dä¸€è‡´æ€§æ‰€éœ€çš„æŠ•å½±å‡ ä½•ç›¸å†²çªã€‚ViewRopeé€šè¿‡ç›¸å¯¹å…‰çº¿å‡ ä½•å‚æ•°åŒ–æ³¨æ„åŠ›ï¼Œæä¾›äº†ä¸€ä¸ªæ¨¡å‹æœ¬åœ°çš„å½’çº³åç½®ï¼Œä»è€Œåœ¨æ—¶é—´é—´éš”ä¸­æ£€ç´¢3Dä¸€è‡´çš„å†…å®¹ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2602.15620",
            "title": "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens",
            "url": "https://huggingface.co/papers/2602.15620",
            "abstract": "Research identifies spurious tokens as the cause of training instability in reinforcement learning fine-tuning of large language models and proposes a solution that selectively masks problematic gradient updates to improve reasoning performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\\%, which we term spurious tokens. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\\% over GRPO, 20-Entropy and JustRL.",
            "score": 0,
            "issue_id": 1104,
            "pub_date": "2026-02-17",
            "pub_date_card": {
                "ru": "17 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ",
                "en": "February 17",
                "zh": "2æœˆ17æ—¥"
            },
            "hash": "9ce7a6bfe1a7f741",
            "authors": [
                "Shiqi Liu",
                "Zeyu He",
                "Guojian Zhan",
                "Letian Tao",
                "Zhilong Zheng",
                "Jiang Wu",
                "Yinuo Wang",
                "Yang Guan",
                "Kehua Sheng",
                "Bo Zhang",
                "Keqiang Li",
                "Jingliang Duan",
                "Shengbo Eben Li"
            ],
            "affiliations": [
                "DiDi Voyager Labs, DiDi Autonomous Driving",
                "School of Vehicle and Mobility & College of AI, Tsinghua University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2602.15620.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#rl"
                ],
                "emoji": "ğŸ¯",
                "ru": {
                    "title": "ĞĞ°Ñ…Ğ¾Ğ´Ğ¸ Ğ¸ Ğ¸ÑĞºĞ»ÑÑ‡Ğ°Ğ¹: ĞºĞ°Ğº Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ´ĞºĞ¸Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ‹ÑĞ²Ğ¸Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ fine-tuning Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ reinforcement learning Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ñ€ĞµĞ´ĞºĞ¸Ğ¼Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸ (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ 0,01%), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ÑÑ‚ Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ·-Ğ·Ğ° Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ½Ğ°Ğ³Ñ€Ğ°Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ĞºĞ¾Ñ€Ñ€ĞµĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸ĞµĞ¹ Ğ¿Ğ¾Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ¼ĞµÑ‚Ğ¾Ğ´ STAPO (Spurious-Token-Aware Policy Optimization), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞµĞ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¼Ğ°ÑĞºĞ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ° ÑˆĞµÑÑ‚Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ STAPO Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ğ¸ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° 7,13% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
                },
                "en": {
                    "title": "Masking Spurious Tokens for Stable RL Fine-Tuning",
                    "desc": "This paper addresses the issue of training instability in reinforcement learning (RL) fine-tuning of large language models caused by spurious tokens. Spurious tokens are a small fraction of tokens that, when present in correct responses, lead to disproportionately large gradient updates without contributing to reasoning quality. The authors introduce a new method called Spurious-Token-Aware Policy Optimization (STAPO), which selectively masks these problematic updates and adjusts the loss calculation to focus on valid tokens. The results show that STAPO improves reasoning performance and stability across multiple benchmarks compared to existing methods."
                },
                "zh": {
                    "title": "è™šå‡æ ‡è®°ï¼šå¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„éšæ‚£ä¸è§£å†³æ–¹æ¡ˆ",
                    "desc": "æœ¬ç ”ç©¶å‘ç°ï¼Œè™šå‡æ ‡è®°æ˜¯å¯¼è‡´å¼ºåŒ–å­¦ä¹ å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒä¸ç¨³å®šçš„åŸå› ï¼Œå¹¶æå‡ºäº†ä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡é€‰æ‹©æ€§åœ°å±è”½æœ‰é—®é¢˜çš„æ¢¯åº¦æ›´æ–°æ¥æé«˜æ¨ç†æ€§èƒ½ã€‚å¼ºåŒ–å­¦ä¹ åœ¨å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰çš„å¾®è°ƒæ–¹æ³•ä¾èµ–äºå¯å‘å¼æŠ€æœ¯ï¼Œå¯¼è‡´è®­ç»ƒåæœŸæ€§èƒ½å´©æºƒã€‚æˆ‘ä»¬è¯æ˜äº†åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæ ‡è®°çº§ç­–ç•¥æ¢¯åº¦çš„å¤§å°ä¸æ ‡è®°æ¦‚ç‡å’Œå±€éƒ¨ç­–ç•¥ç†µå‘ˆè´Ÿç›¸å…³ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†è™šå‡æ ‡è®°æ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–ï¼ˆSTAPOï¼‰ï¼Œé€šè¿‡å±è”½ä¸è‰¯æ›´æ–°å¹¶å¯¹æœ‰æ•ˆæ ‡è®°é‡æ–°å½’ä¸€åŒ–æŸå¤±ï¼Œä»è€Œæé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ¨ç†èƒ½åŠ›ã€‚"
                }
            }
        }
    ],
    "link_prev": "2026-02-17.html",
    "link_next": "2026-02-19.html",
    "link_month": "2026-02.html",
    "short_date_prev": {
        "ru": "17.02",
        "en": "02/17",
        "zh": "2æœˆ17æ—¥"
    },
    "short_date_next": {
        "ru": "19.02",
        "en": "02/19",
        "zh": "2æœˆ19æ—¥"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 3,
        "#agents": 3,
        "#cv": 1,
        "#rl": 2,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 1,
        "#inference": 1,
        "#3d": 1,
        "#audio": 0,
        "#video": 1,
        "#multimodal": 1,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 3,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 0,
        "#reasoning": 2,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 3,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0
    }
}