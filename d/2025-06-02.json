{
    "date": {
        "ru": "2 Ğ¸ÑĞ½Ñ",
        "en": "June 2",
        "zh": "6æœˆ2æ—¥"
    },
    "time_utc": "2025-06-02 04:23",
    "weekday": 0,
    "issue_id": 4068,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.24863",
            "title": "AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time",
            "url": "https://huggingface.co/papers/2505.24863",
            "abstract": "This paper presents AlphaOne (alpha1), a universal framework for modulating reasoning progress in large reasoning models (LRMs) at test time. alpha1 first introduces alpha moment, which represents the scaled thinking phase with a universal parameter alpha. Within this scaled pre-alpha moment phase, it dynamically schedules slow thinking transitions by modeling the insertion of reasoning transition tokens as a Bernoulli stochastic process. After the alpha moment, alpha1 deterministically terminates slow thinking with the end-of-thinking token, thereby fostering fast reasoning and efficient answer generation. This approach unifies and generalizes existing monotonic scaling methods by enabling flexible and dense slow-to-fast reasoning modulation. Extensive empirical studies on various challenging benchmarks across mathematical, coding, and scientific domains demonstrate alpha1's superior reasoning capability and efficiency. Project page: https://alphaone-project.github.io/",
            "score": 17,
            "issue_id": 4066,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "a30c2004fdd2d154",
            "authors": [
                "Junyu Zhang",
                "Runpei Dong",
                "Han Wang",
                "Xuying Ning",
                "Haoran Geng",
                "Peihao Li",
                "Xialin He",
                "Yutong Bai",
                "Jitendra Malik",
                "Saurabh Gupta",
                "Huan Zhang"
            ],
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24863.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#training",
                    "#benchmark",
                    "#architecture"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "AlphaOne: Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ˜Ğ˜",
                    "desc": "AlphaOne (alpha1) - ÑÑ‚Ğ¾ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ² ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ (LRM) Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. ĞĞ½Ğ° Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ğµ Ğ°Ğ»ÑŒÑ„Ğ°-Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ°, Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‰ĞµĞ³Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ Ñ„Ğ°Ğ·Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ¼ Ğ°Ğ»ÑŒÑ„Ğ°. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ¸ Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸ĞµĞ¼, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€ÑƒÑ Ğ²ÑÑ‚Ğ°Ğ²ĞºÑƒ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ° Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ ĞºĞ°Ğº ÑÑ‚Ğ¾Ñ…Ğ°ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ‘ĞµÑ€Ğ½ÑƒĞ»Ğ»Ğ¸. AlphaOne Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¼Ğ¾Ğ½Ğ¾Ñ‚Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°Ñ Ğ³Ğ¸Ğ±ĞºÑƒÑ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "AlphaOne: Revolutionizing Reasoning in Large Models",
                    "desc": "This paper introduces AlphaOne, a framework designed to enhance the reasoning capabilities of large reasoning models (LRMs) during testing. It introduces the concept of the alpha moment, which allows for a controlled thinking phase using a universal parameter. By employing a Bernoulli stochastic process, AlphaOne dynamically manages the transition from slow to fast reasoning, optimizing the model's performance. Empirical results show that AlphaOne outperforms existing methods in various complex tasks, demonstrating its effectiveness in improving reasoning efficiency."
                },
                "zh": {
                    "title": "çµæ´»è°ƒèŠ‚æ¨ç†è¿›ç¨‹çš„AlphaOneæ¡†æ¶",
                    "desc": "æœ¬æ–‡æå‡ºäº†AlphaOneï¼ˆalpha1ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨æµ‹è¯•æ—¶è°ƒèŠ‚å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰æ¨ç†è¿›ç¨‹çš„é€šç”¨æ¡†æ¶ã€‚alpha1é¦–å…ˆå¼•å…¥äº†alphaæ—¶åˆ»ï¼Œè¡¨ç¤ºå¸¦æœ‰é€šç”¨å‚æ•°alphaçš„ç¼©æ”¾æ€ç»´é˜¶æ®µã€‚åœ¨è¿™ä¸ªç¼©æ”¾çš„å‰alphaæ—¶åˆ»é˜¶æ®µä¸­ï¼Œå®ƒé€šè¿‡å°†æ¨ç†è¿‡æ¸¡æ ‡è®°çš„æ’å…¥å»ºæ¨¡ä¸ºä¼¯åŠªåˆ©éšæœºè¿‡ç¨‹ï¼ŒåŠ¨æ€è°ƒåº¦ç¼“æ…¢æ€ç»´çš„è¿‡æ¸¡ã€‚åœ¨alphaæ—¶åˆ»ä¹‹åï¼Œalpha1é€šè¿‡æ€ç»´ç»“æŸæ ‡è®°ç¡®å®šæ€§åœ°ç»ˆæ­¢ç¼“æ…¢æ€ç»´ï¼Œä»è€Œä¿ƒè¿›å¿«é€Ÿæ¨ç†å’Œé«˜æ•ˆç­”æ¡ˆç”Ÿæˆã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14752",
            "title": "Large Language Models for Data Synthesis",
            "url": "https://huggingface.co/papers/2505.14752",
            "abstract": "LLMSynthor enhances LLMs for efficient and statistically accurate data synthesis through distributional feedback and proposal sampling.  \t\t\t\t\tAI-generated summary \t\t\t\t Generating synthetic data that faithfully captures the statistical structure of real-world distributions is a fundamental challenge in data modeling. Classical approaches often depend on strong parametric assumptions or manual structural design and struggle in high-dimensional or heterogeneous domains. Recent progress in Large Language Models (LLMs) reveals their potential as flexible, high-dimensional priors over real-world distributions. However, when applied to data synthesis, standard LLM-based sampling is inefficient, constrained by fixed context limits, and fails to ensure statistical alignment. Given this, we introduce LLMSynthor, a general framework for data synthesis that transforms LLMs into structure-aware simulators guided by distributional feedback. LLMSynthor treats the LLM as a nonparametric copula simulator for modeling high-order dependencies and introduces LLM Proposal Sampling to generate grounded proposal distributions that improve sampling efficiency without requiring rejection. By minimizing discrepancies in the summary statistics space, the iterative synthesis loop aligns real and synthetic data while gradually uncovering and refining the latent generative structure. We evaluate LLMSynthor in both controlled and real-world settings using heterogeneous datasets in privacy-sensitive domains (e.g., e-commerce, population, and mobility) that encompass both structured and unstructured formats. The synthetic data produced by LLMSynthor shows high statistical fidelity, practical utility, and cross-data adaptability, positioning it as a valuable tool across economics, social science, urban studies, and beyond.",
            "score": 7,
            "issue_id": 4067,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 Ğ¼Ğ°Ñ",
                "en": "May 20",
                "zh": "5æœˆ20æ—¥"
            },
            "hash": "202c77d3d43de6f6",
            "authors": [
                "Yihong Tang",
                "Menglin Kong",
                "Lijun Sun"
            ],
            "affiliations": [
                "McGill University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14752.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#synthetic",
                    "#data"
                ],
                "emoji": "ğŸ§¬",
                "ru": {
                    "title": "LLMSynthor: ĞŸÑ€ĞµĞ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
                    "desc": "LLMSynthor - ÑÑ‚Ğ¾ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ğ² ÑĞ¸Ğ¼ÑƒĞ»ÑÑ‚Ğ¾Ñ€Ñ‹, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‰Ğ¸Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ. ĞĞ½ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ LLM ĞºĞ°Ğº Ğ½ĞµĞ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ¿ÑƒĞ»Ğ°-ÑĞ¸Ğ¼ÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞ° Ğ¸ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ LLM Proposal Sampling Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ñ‹Ñ… Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğ¹. LLMSynthor Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº, Ğ²Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. Ğ¤Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ³ĞµÑ‚ĞµÑ€Ğ¾Ğ³ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑÑ…."
                },
                "en": {
                    "title": "Transforming LLMs into Efficient Data Synthesizers",
                    "desc": "LLMSynthor is a framework that enhances Large Language Models (LLMs) for creating synthetic data that accurately reflects real-world statistical distributions. It addresses the limitations of traditional data synthesis methods, which often rely on rigid assumptions and struggle with complex data types. By using distributional feedback and a novel LLM Proposal Sampling technique, LLMSynthor improves the efficiency and accuracy of data generation without the need for rejection sampling. The framework has been tested in various real-world scenarios, demonstrating its ability to produce high-quality synthetic data suitable for diverse applications."
                },
                "zh": {
                    "title": "LLMSynthorï¼šé«˜æ•ˆçš„ç»Ÿè®¡æ•°æ®åˆæˆæ–°å·¥å…·",
                    "desc": "LLMSynthor æ˜¯ä¸€ç§å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»¥å®ç°é«˜æ•ˆå’Œç»Ÿè®¡å‡†ç¡®çš„æ•°æ®åˆæˆçš„æ–¹æ³•ã€‚å®ƒé€šè¿‡åˆ†å¸ƒåé¦ˆå’Œæè®®é‡‡æ ·ï¼Œå°† LLM è½¬å˜ä¸ºç»“æ„æ„ŸçŸ¥çš„æ¨¡æ‹Ÿå™¨ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰çœŸå®ä¸–ç•Œåˆ†å¸ƒçš„ç»Ÿè®¡ç‰¹å¾ã€‚è¯¥æ¡†æ¶é€šè¿‡æœ€å°åŒ–æ‘˜è¦ç»Ÿè®¡ç©ºé—´ä¸­çš„å·®å¼‚ï¼Œé€æ­¥å¯¹é½çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ï¼ŒåŒæ—¶æ­ç¤ºå’Œä¼˜åŒ–æ½œåœ¨çš„ç”Ÿæˆç»“æ„ã€‚LLMSynthor åœ¨éšç§æ•æ„Ÿé¢†åŸŸçš„å¼‚æ„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ˜¾ç¤ºå‡ºé«˜ç»Ÿè®¡ä¿çœŸåº¦å’Œå®ç”¨æ€§ï¼Œé€‚ç”¨äºç»æµå­¦ã€ç¤¾ä¼šç§‘å­¦å’ŒåŸå¸‚ç ”ç©¶ç­‰å¤šä¸ªé¢†åŸŸã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24878",
            "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and\n  Benchmarking Multimodal LLM Agents",
            "url": "https://huggingface.co/papers/2505.24878",
            "abstract": "CAPTCHAs have been a critical bottleneck for deploying web agents in real-world applications, often blocking them from completing end-to-end automation tasks. While modern multimodal LLM agents have demonstrated impressive performance in static perception tasks, their ability to handle interactive, multi-step reasoning challenges like CAPTCHAs is largely untested. To address this gap, we introduce Open CaptchaWorld, the first web-based benchmark and platform specifically designed to evaluate the visual reasoning and interaction capabilities of MLLM-powered agents through diverse and dynamic CAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225 CAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth, which quantifies the number of cognitive and motor steps required to solve each puzzle. Experimental results show that humans consistently achieve near-perfect scores, state-of-the-art MLLM agents struggle significantly, with success rates at most 40.0% by Browser-Use Openai-o3, far below human-level performance, 93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing the limits of current multimodal agents and guiding the development of more robust multimodal reasoning systems. Code and Data are available at this https URL.",
            "score": 4,
            "issue_id": 4067,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "9cceceaf09c77468",
            "authors": [
                "Yaxin Luo",
                "Zhaoyi Li",
                "Jiacheng Liu",
                "Jiacheng Cui",
                "Xiaohan Zhao",
                "Zhiqiang Shen"
            ],
            "affiliations": [
                "MetaAgentX",
                "VILA Lab, MBZUAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24878.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "ğŸ¤–",
                "ru": {
                    "title": "Open CaptchaWorld: Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Open CaptchaWorld - Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ²ĞµĞ±-Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (MLLM) Ğ² Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¸ CAPTCHA. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ 20 Ñ‚Ğ¸Ğ¿Ğ¾Ğ² ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… CAPTCHA, Ğ²ÑĞµĞ³Ğ¾ 225 Ğ·Ğ°Ğ´Ğ°Ñ‡, Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¾Ğ¹ - Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ¾Ğ¹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ CAPTCHA. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ»ÑĞ´Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ÑÑ‚ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¸ Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ², Ğ² Ñ‚Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ ĞºĞ°Ğº Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ MLLM-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ Ñ 40% Ğ·Ğ°Ğ´Ğ°Ñ‡. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´Ñ‡ĞµÑ€ĞºĞ¸Ğ²Ğ°ĞµÑ‚ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Open CaptchaWorld Ğ´Ğ»Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ±Ğ¾Ğ»ĞµĞµ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Unlocking the Future: Evaluating MLLM Agents with Open CaptchaWorld",
                    "desc": "This paper introduces Open CaptchaWorld, a new benchmark designed to test the capabilities of multimodal large language model (MLLM) agents in solving CAPTCHA puzzles. It evaluates the visual reasoning and interaction skills of these agents through a variety of 225 CAPTCHA types, measuring their performance with a novel metric called CAPTCHA Reasoning Depth. Experimental results reveal that while humans achieve high success rates, MLLM agents struggle significantly, with a maximum success rate of only 40%. This underscores the need for improved multimodal reasoning systems and positions Open CaptchaWorld as a crucial tool for assessing and enhancing agent performance in complex tasks."
                },
                "zh": {
                    "title": "çªç ´CAPTCHAç“¶é¢ˆï¼Œæå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼",
                    "desc": "CAPTCHAåœ¨å®é™…åº”ç”¨ä¸­æ˜¯éƒ¨ç½²ç½‘ç»œä»£ç†çš„ä¸€ä¸ªé‡è¦ç“¶é¢ˆï¼Œå¸¸å¸¸é˜»ç¢å®ƒä»¬å®Œæˆç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚è™½ç„¶ç°ä»£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨é™æ€æ„ŸçŸ¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†äº¤äº’å¼ã€å¤šæ­¥éª¤æ¨ç†æŒ‘æˆ˜ï¼ˆå¦‚CAPTCHAï¼‰æ–¹é¢çš„èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†æµ‹è¯•ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Open CaptchaWorldï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°MLLMä»£ç†çš„è§†è§‰æ¨ç†å’Œäº¤äº’èƒ½åŠ›çš„ç½‘ç»œåŸºå‡†å¹³å°ï¼Œæ¶µç›–20ç§ç°ä»£CAPTCHAç±»å‹ï¼Œå…±225ä¸ªCAPTCHAï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„åº¦é‡æ ‡å‡†ï¼šCAPTCHAæ¨ç†æ·±åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œäººç±»çš„æˆåŠŸç‡æ¥è¿‘å®Œç¾ï¼Œè€Œæœ€å…ˆè¿›çš„MLLMä»£ç†çš„æˆåŠŸç‡æœ€é«˜ä»…ä¸º40.0%ï¼Œè¿œä½äºäººç±»çš„93.3%ï¼Œè¿™çªæ˜¾äº†Open CaptchaWorldä½œä¸ºè¯Šæ–­å½“å‰å¤šæ¨¡æ€ä»£ç†å±€é™æ€§çš„é‡è¦åŸºå‡†ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24521",
            "title": "UniGeo: Taming Video Diffusion for Unified Consistent Geometry\n  Estimation",
            "url": "https://huggingface.co/papers/2505.24521",
            "abstract": "Recently, methods leveraging diffusion model priors to assist monocular geometric estimation (e.g., depth and normal) have gained significant attention due to their strong generalization ability. However, most existing works focus on estimating geometric properties within the camera coordinate system of individual video frames, neglecting the inherent ability of diffusion models to determine inter-frame correspondence. In this work, we demonstrate that, through appropriate design and fine-tuning, the intrinsic consistency of video generation models can be effectively harnessed for consistent geometric estimation. Specifically, we 1) select geometric attributes in the global coordinate system that share the same correspondence with video frames as the prediction targets, 2) introduce a novel and efficient conditioning method by reusing positional encodings, and 3) enhance performance through joint training on multiple geometric attributes that share the same correspondence. Our results achieve superior performance in predicting global geometric attributes in videos and can be directly applied to reconstruction tasks. Even when trained solely on static video data, our approach exhibits the potential to generalize to dynamic video scenes.",
            "score": 4,
            "issue_id": 4067,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "4ae43b7cdb482867",
            "authors": [
                "Yang-Tian Sun",
                "Xin Yu",
                "Zehuan Huang",
                "Yi-Hua Huang",
                "Yuan-Chen Guo",
                "Ziyi Yang",
                "Yan-Pei Cao",
                "Xiaojuan Qi"
            ],
            "affiliations": [
                "Beihang University",
                "The University of Hong Kong",
                "VAST"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24521.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#diffusion",
                    "#optimization",
                    "#cv"
                ],
                "emoji": "ğŸ¥",
                "ru": {
                    "title": "Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ² Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ ÑĞ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸. ĞĞ½Ğ¸ Ğ²Ğ²Ğ¾Ğ´ÑÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¿ĞµÑ€ĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸, Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ÑÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿ÑƒÑ‚ĞµĞ¼ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ°Ñ…. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¸ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ² Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ñ‹ Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸."
                },
                "en": {
                    "title": "Harnessing Diffusion Models for Consistent Geometric Estimation in Videos",
                    "desc": "This paper explores the use of diffusion models to improve the estimation of geometric properties like depth and normals in videos. Unlike previous methods that focus on individual frames, this approach leverages the relationships between frames to enhance consistency in geometric estimation. The authors propose a novel conditioning method that reuses positional encodings and advocate for joint training on multiple geometric attributes. Their results show improved performance in predicting global geometric attributes, demonstrating the model's ability to generalize even from static video data to dynamic scenes."
                },
                "zh": {
                    "title": "åˆ©ç”¨æ‰©æ•£æ¨¡å‹æå‡è§†é¢‘å‡ ä½•ä¼°è®¡çš„ä¸€è‡´æ€§",
                    "desc": "æœ€è¿‘ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹å…ˆéªŒæ¥è¾…åŠ©å•ç›®å‡ ä½•ä¼°è®¡ï¼ˆå¦‚æ·±åº¦å’Œæ³•çº¿ï¼‰çš„æ–¹æ³•å—åˆ°äº†å¹¿æ³›å…³æ³¨ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰å·¥ä½œé›†ä¸­åœ¨å•ä¸ªè§†é¢‘å¸§çš„ç›¸æœºåæ ‡ç³»å†…ä¼°è®¡å‡ ä½•å±æ€§ï¼Œå¿½è§†äº†æ‰©æ•£æ¨¡å‹åœ¨ç¡®å®šå¸§é—´å¯¹åº”å…³ç³»æ–¹é¢çš„å›ºæœ‰èƒ½åŠ›ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡é€‚å½“çš„è®¾è®¡å’Œå¾®è°ƒï¼Œå¯ä»¥æœ‰æ•ˆåˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„å†…åœ¨ä¸€è‡´æ€§æ¥è¿›è¡Œä¸€è‡´çš„å‡ ä½•ä¼°è®¡ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é€‰æ‹©åœ¨å…¨å±€åæ ‡ç³»ä¸­ä¸è§†é¢‘å¸§å…±äº«ç›¸åŒå¯¹åº”å…³ç³»çš„å‡ ä½•å±æ€§ä½œä¸ºé¢„æµ‹ç›®æ ‡ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°é¢–é«˜æ•ˆçš„æ¡ä»¶æ–¹æ³•ï¼Œé€šè¿‡é‡ç”¨ä½ç½®ç¼–ç æ¥å¢å¼ºæ€§èƒ½ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24850",
            "title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher\n  Data for LLM Reasoning",
            "url": "https://huggingface.co/papers/2505.24850",
            "abstract": "Recent advances in model distillation demonstrate that data from advanced reasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer complex reasoning abilities to smaller, efficient student models. However, standard practices employ rejection sampling, discarding incorrect reasoning examples -- valuable, yet often underutilized data. This paper addresses the critical question: How can both positive and negative distilled reasoning traces be effectively leveraged to maximize LLM reasoning performance in an offline setting? To this end, We propose Reinforcement Distillation (REDI), a two-stage framework. Stage 1 learns from positive traces via Supervised Fine-Tuning (SFT). Stage 2 further refines the model using both positive and negative traces through our proposed REDI objective. This novel objective is a simple, reference-free loss function that outperforms established methods like DPO and SimPO in this distillation context. Our empirical evaluations demonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT combined with DPO/SimPO on mathematical reasoning tasks. Notably, the Qwen-REDI-1.5B model, post-trained on just 131k positive and negative examples from the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1). Its performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a model post-trained on 800k proprietary data) across various mathematical reasoning benchmarks, establishing a new state-of-the-art for 1.5B models post-trained offline with openly available data.",
            "score": 3,
            "issue_id": 4067,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "e946031c286b5bf4",
            "authors": [
                "Shuyao Xu",
                "Cheng Peng",
                "Jiangxuan Long",
                "Weidi Xu",
                "Wei Chu",
                "Yuan Qi"
            ],
            "affiliations": [
                "AI3 Institute of Fudan University",
                "INFLY TECH (Shanghai) Co., Ltd.",
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24850.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#dataset",
                    "#math"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "REDI: Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼ Ğ½Ğ° Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¸ Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ…",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ¸ÑÑ‚Ğ¸Ğ»Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Reinforcement Distillation (REDI). REDI Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ĞºĞ°Ğº Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ, Ñ‚Ğ°Ğº Ğ¸ Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğº Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ. ĞœĞµÑ‚Ğ¾Ğ´ ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· Ğ´Ğ²ÑƒÑ… ÑÑ‚Ğ°Ğ¿Ğ¾Ğ²: Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ… Ğ¸ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ REDI. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€ĞµĞ²Ğ¾ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ REDI Ğ½Ğ°Ğ´ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ°Ğ¼Ğ¸ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹, Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°."
                },
                "en": {
                    "title": "Maximizing Reasoning Performance with Reinforcement Distillation",
                    "desc": "This paper introduces Reinforcement Distillation (REDI), a two-stage framework designed to enhance the reasoning capabilities of smaller models by utilizing both positive and negative reasoning examples. In the first stage, the model is fine-tuned using positive reasoning traces through Supervised Fine-Tuning (SFT). The second stage refines the model further by incorporating both types of traces with a novel, reference-free loss function that improves performance over traditional methods like DPO and SimPO. Empirical results show that the Qwen-REDI-1.5B model achieves impressive scores on mathematical reasoning tasks, outperforming larger models trained on more extensive proprietary datasets."
                },
                "zh": {
                    "title": "å¼ºåŒ–è’¸é¦ï¼šæå‡æ¨ç†æ€§èƒ½çš„æ–°æ–¹æ³•",
                    "desc": "æœ¬è®ºæ–‡æ¢è®¨äº†å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æ­£è´Ÿæ¨ç†è½¨è¿¹æ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºå¼ºåŒ–è’¸é¦ï¼ˆREDIï¼‰çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç¬¬ä¸€é˜¶æ®µé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å­¦ä¹ æ­£æ¨ç†è½¨è¿¹ï¼Œç¬¬äºŒé˜¶æ®µåˆ™ç»“åˆæ­£è´Ÿæ¨ç†è½¨è¿¹è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ã€‚æˆ‘ä»¬çš„REDIç›®æ ‡æ˜¯ä¸€ä¸ªç®€å•çš„æ— å‚è€ƒæŸå¤±å‡½æ•°ï¼Œåœ¨è’¸é¦ä»»åŠ¡ä¸­ä¼˜äºä¼ ç»Ÿæ–¹æ³•å¦‚DPOå’ŒSimPOã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡131kæ­£è´Ÿæ ·æœ¬è®­ç»ƒçš„Qwen-REDI-1.5Bæ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†83.1%çš„å¾—åˆ†ï¼Œåˆ›é€ äº†1.5Bæ¨¡å‹çš„æ–°çŠ¶æ€ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24417",
            "title": "EasyText: Controllable Diffusion Transformer for Multilingual Text\n  Rendering",
            "url": "https://huggingface.co/papers/2505.24417",
            "abstract": "Generating accurate multilingual text with diffusion models has long been desired but remains challenging. Recent methods have made progress in rendering text in a single language, but rendering arbitrary languages is still an unexplored area. This paper introduces EasyText, a text rendering framework based on DiT (Diffusion Transformer), which connects denoising latents with multilingual character tokens encoded as character tokens. We propose character positioning encoding and position encoding interpolation techniques to achieve controllable and precise text rendering. Additionally, we construct a large-scale synthetic text image dataset with 1 million multilingual image-text annotations as well as a high-quality dataset of 20K annotated images, which are used for pretraining and fine-tuning respectively. Extensive experiments and evaluations demonstrate the effectiveness and advancement of our approach in multilingual text rendering, visual quality, and layout-aware text integration.",
            "score": 2,
            "issue_id": 4066,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "f28c426fafe8156a",
            "authors": [
                "Runnan Lu",
                "Yuxuan Zhang",
                "Jailing Liu",
                "Haifa Wang",
                "Yiren Song"
            ],
            "affiliations": [
                "Liblib AI",
                "National University of Singapore",
                "The Chinese University of Hong Kong",
                "Tiamat AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24417.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#dataset",
                    "#multilingual",
                    "#cv",
                    "#diffusion"
                ],
                "emoji": "ğŸŒ",
                "ru": {
                    "title": "EasyText: Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ² Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğ¼ Ñ€ĞµĞ½Ğ´ĞµÑ€Ğ¸Ğ½Ğ³Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ EasyText - Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº Ğ´Ğ»Ñ Ñ€ĞµĞ½Ğ´ĞµÑ€Ğ¸Ğ½Ğ³Ğ° Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ DiT. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ½Ğ´ĞµÑ€Ğ¸Ğ½Ğ³Ğ° Ñ‚ĞµĞºÑÑ‚Ğ°. Ğ”Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ±Ñ‹Ğ» ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ñ 1 Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ¼ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ñ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ°Ñ…. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ² Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾Ğ¼ Ñ€ĞµĞ½Ğ´ĞµÑ€Ğ¸Ğ½Ğ³Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ¼Ğ°ĞºĞµÑ‚Ğ°."
                },
                "en": {
                    "title": "EasyText: Multilingual Text Rendering Made Simple",
                    "desc": "This paper presents EasyText, a novel framework for generating multilingual text using diffusion models. It leverages a Diffusion Transformer (DiT) to connect denoising latents with multilingual character tokens, addressing the challenge of rendering text in various languages. The authors introduce innovative techniques such as character positioning encoding and position encoding interpolation to enhance the control and precision of text rendering. They also create a large-scale dataset with 1 million multilingual image-text pairs, which significantly improves the model's performance in multilingual text rendering and visual quality."
                },
                "zh": {
                    "title": "å¤šè¯­è¨€æ–‡æœ¬æ¸²æŸ“çš„æ–°çªç ´",
                    "desc": "æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºEasyTextçš„æ–‡æœ¬æ¸²æŸ“æ¡†æ¶ï¼ŒåŸºäºæ‰©æ•£å˜æ¢å™¨ï¼ˆDiTï¼‰æŠ€æœ¯ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†å»å™ªæ½œå˜é‡ä¸å¤šè¯­è¨€å­—ç¬¦ä»¤ç‰Œè¿æ¥ï¼Œå®ç°äº†å¯¹å¤šè¯­è¨€æ–‡æœ¬çš„ç²¾ç¡®æ¸²æŸ“ã€‚æˆ‘ä»¬æå‡ºäº†å­—ç¬¦ä½ç½®ç¼–ç å’Œä½ç½®ç¼–ç æ’å€¼æŠ€æœ¯ï¼Œä»¥å®ç°å¯æ§å’Œç²¾ç¡®çš„æ–‡æœ¬æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«100ä¸‡æ¡å¤šè¯­è¨€å›¾åƒ-æ–‡æœ¬æ³¨é‡Šçš„å¤§è§„æ¨¡åˆæˆæ–‡æœ¬å›¾åƒæ•°æ®é›†ï¼Œç”¨äºé¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œå®éªŒç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šè¯­è¨€æ–‡æœ¬æ¸²æŸ“å’Œè§†è§‰è´¨é‡æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24293",
            "title": "Large Language Models are Locally Linear Mappings",
            "url": "https://huggingface.co/papers/2505.24293",
            "abstract": "We demonstrate that the inference operations of several open-weight large language models (LLMs) can be mapped to an exactly equivalent linear system for an input sequence without modifying the model weights or altering output predictions. Extending techniques from image diffusion models that exhibit local or piecewise linearity, we strategically alter the gradient computation with respect to a given input sequence for a next-token prediction such that the Jacobian of the model nearly exactly reproduces the forward prediction with a linear system. We demonstrate this approach across models (Llama 3, Gemma 3, Qwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show through the singular value decomposition of the detached Jacobian that these LLMs operate in extremely low-dimensional subspaces where many of the largest singular vectors decode to concepts related to the most-likely output token. This approach also allows us to examine the operation of each successive layer (and its attention and MLP components) as nearly-exact linear systems and observe the emergence of semantic concepts. Despite their expressive power and global nonlinearity, modern LLMs can be interpreted through nearly-exact locally linear decompositions that provide insights into their internal representations and reveal interpretable semantic structures in the next-token prediction process.",
            "score": 1,
            "issue_id": 4066,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 Ğ¼Ğ°Ñ",
                "en": "May 30",
                "zh": "5æœˆ30æ—¥"
            },
            "hash": "42a9e20ff9742560",
            "authors": [
                "James R. Golden"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2505.24293.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#interpretability",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "ğŸ§®",
                "ru": {
                    "title": "Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹",
                    "desc": "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ‚ÑŒ Ğ² ÑĞºĞ²Ğ¸Ğ²Ğ°Ğ»ĞµĞ½Ñ‚Ğ½ÑƒÑ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹. ĞĞ½Ğ¸ Ñ€Ğ°ÑÑˆĞ¸Ñ€Ğ¸Ğ»Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸Ğ· Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ¸Ñ„Ñ„ÑƒĞ·Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ¿Ñ€Ğ¾ÑĞ²Ğ»ÑÑÑ‰Ğ¸Ñ… Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ğ¸Ğ»Ğ¸ ĞºÑƒÑĞ¾Ñ‡Ğ½ÑƒÑ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾ÑÑ‚ÑŒ, ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ² Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ°. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ±Ñ‹Ğ» Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Llama 3, Gemma 3 Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ. ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¸Ğ½Ğ³ÑƒĞ»ÑÑ€Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞºĞ¾Ğ±Ğ¸Ğ°Ğ½Ğ° Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ», Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¸ LLM Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ² ÑĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ½Ğ¸Ğ·ĞºĞ¾Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°Ñ…, Ğ³Ğ´Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¸Ğµ Ğ¸Ğ· ĞºÑ€ÑƒĞ¿Ğ½ĞµĞ¹ÑˆĞ¸Ñ… ÑĞ¸Ğ½Ğ³ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ² ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ¼."
                },
                "en": {
                    "title": "Unlocking LLMs: Linear Insights into Complex Predictions",
                    "desc": "This paper shows that the inference processes of large language models (LLMs) can be represented as linear systems without changing the model's weights or outputs. By modifying the gradient calculations for next-token predictions, the authors create a Jacobian that closely mirrors the model's predictions using linear methods. They analyze various LLMs and find that these models operate in low-dimensional spaces, where significant singular vectors correspond to key concepts for predicting the next token. This method allows for a deeper understanding of how each layer functions and reveals interpretable semantic structures in the predictions of LLMs."
                },
                "zh": {
                    "title": "æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹çš„çº¿æ€§æœ¬è´¨",
                    "desc": "æœ¬æ–‡å±•ç¤ºäº†å¤šä¸ªå¼€æ”¾æƒé‡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†æ“ä½œå¯ä»¥æ˜ å°„åˆ°ä¸€ä¸ªå®Œå…¨ç­‰ä»·çš„çº¿æ€§ç³»ç»Ÿï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡å‹æƒé‡æˆ–æ”¹å˜è¾“å‡ºé¢„æµ‹ã€‚æˆ‘ä»¬å€Ÿé‰´äº†å›¾åƒæ‰©æ•£æ¨¡å‹çš„æŠ€æœ¯ï¼Œé€šè¿‡æˆ˜ç•¥æ€§åœ°æ”¹å˜ç›¸å¯¹äºç»™å®šè¾“å…¥åºåˆ—çš„æ¢¯åº¦è®¡ç®—ï¼Œä½¿å¾—æ¨¡å‹çš„é›…å¯æ¯”çŸ©é˜µå‡ ä¹å®Œå…¨é‡ç°äº†çº¿æ€§ç³»ç»Ÿçš„å‰å‘é¢„æµ‹ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ¨¡å‹ä¸ŠéªŒè¯äº†è¿™ç§æ–¹æ³•ï¼Œå¹¶é€šè¿‡å¯¹åˆ†ç¦»é›…å¯æ¯”çŸ©é˜µçš„å¥‡å¼‚å€¼åˆ†è§£ï¼Œå‘ç°è¿™äº›LLMsåœ¨æä½ç»´çš„å­ç©ºé—´ä¸­æ“ä½œï¼Œè®¸å¤šæœ€å¤§çš„å¥‡å¼‚å‘é‡è§£ç å‡ºä¸æœ€å¯èƒ½è¾“å‡ºæ ‡è®°ç›¸å…³çš„æ¦‚å¿µã€‚å°½ç®¡ç°ä»£LLMså…·æœ‰å¼ºå¤§çš„è¡¨è¾¾èƒ½åŠ›å’Œå…¨å±€éçº¿æ€§ï¼Œä½†å¯ä»¥é€šè¿‡å‡ ä¹ç²¾ç¡®çš„å±€éƒ¨çº¿æ€§åˆ†è§£è¿›è¡Œè§£é‡Šï¼Œä»è€Œæä¾›å¯¹å…¶å†…éƒ¨è¡¨ç¤ºçš„æ´å¯Ÿï¼Œå¹¶æ­ç¤ºä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹è¿‡ç¨‹ä¸­çš„å¯è§£é‡Šè¯­ä¹‰ç»“æ„ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23009",
            "title": "EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic,\n  Expressiveness, and Linguistic Challenges Using Model-as-a-Judge",
            "url": "https://huggingface.co/papers/2505.23009",
            "abstract": "A comprehensive TTS benchmark, EmergentTTS-Eval, automates test-case generation and evaluation using LLMs and LALM to assess nuanced and semantically complex text in speech outputs.  \t\t\t\t\tAI-generated summary \t\t\t\t Text-to-Speech (TTS) benchmarks often fail to capture how well models handle nuanced and semantically complex text. Building on EmergentTTS, we introduce EmergentTTS-Eval, a comprehensive benchmark covering six challenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic complexity, complex pronunciation (e.g. URLs, formulas), and questions. Crucially, our framework automates both test-case generation and evaluation, making the benchmark easily extensible. Starting from a small set of human-written seed prompts, we iteratively extend them using LLMs to target specific structural, phonetic and prosodic challenges, resulting in 1,645 diverse test cases. Moreover, we employ a model-as-a-judge approach, using a Large Audio Language Model (LALM) to assess the speech across multiple dimensions such as expressed emotion, prosodic, intonational, and pronunciation accuracy. We evaluate state-of-the-art open-source and proprietary TTS systems, such as 11Labs, Deepgram, and OpenAI's 4o-mini-TTS, on EmergentTTS-Eval, demonstrating its ability to reveal fine-grained performance differences. Results show that the model-as-a-judge approach offers robust TTS assessment and a high correlation with human preferences. We open source the evaluation https://github.com/boson-ai/EmergentTTS-Eval-public{code} and the https://huggingface.co/datasets/bosonai/EmergentTTS-Eval{dataset}.",
            "score": 1,
            "issue_id": 4067,
            "pub_date": "2025-05-29",
            "pub_date_card": {
                "ru": "29 Ğ¼Ğ°Ñ",
                "en": "May 29",
                "zh": "5æœˆ29æ—¥"
            },
            "hash": "8ed75b2649e36558",
            "authors": [
                "Ruskin Raj Manku",
                "Yuzhi Tang",
                "Xingjian Shi",
                "Mu Li",
                "Alex Smola"
            ],
            "affiliations": [
                "Boson AI, Santa Clara, CA 95054"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23009.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#benchmark",
                    "#open_source",
                    "#audio"
                ],
                "emoji": "ğŸ—£ï¸",
                "ru": {
                    "title": "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ¾Ğ² ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ° Ñ€ĞµÑ‡Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ˜Ğ˜",
                    "desc": "EmergentTTS-Eval - ÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ¸ÑÑ‚ĞµĞ¼ Text-to-Speech (TTS). ĞĞ½ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LLM) Ğ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾-ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (LALM) Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ»ÑƒÑ‡Ğ°ĞµĞ² Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€ĞµÑ‡Ğ¸. Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¾Ñ…Ğ²Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ÑˆĞµÑÑ‚ÑŒ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ĞµĞ², Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸, Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ¸Ğ½Ğ³Ğ²Ğ¸ÑÑ‚Ğ¸ĞºÑƒ, Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ. Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ 'Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-ĞºĞ°Ğº-ÑÑƒĞ´ÑŒÑ' Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½ÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ TTS ÑĞ¸ÑÑ‚ĞµĞ¼ Ğ¸ Ğ²Ñ‹ÑĞ¾ĞºÑƒÑ ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ Ñ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ»ÑĞ´ĞµĞ¹."
                },
                "en": {
                    "title": "Automating TTS Evaluation for Nuanced Speech Outputs",
                    "desc": "The paper presents EmergentTTS-Eval, a new benchmark for evaluating Text-to-Speech (TTS) systems that focuses on complex and nuanced text. It automates the generation of test cases using Large Language Models (LLMs) and evaluates the outputs with a Large Audio Language Model (LALM). The benchmark includes six challenging scenarios, such as emotional expression and complex pronunciation, and generates 1,645 diverse test cases from a small set of human-written prompts. The results show that this automated approach provides a reliable assessment of TTS systems, correlating well with human evaluations."
                },
                "zh": {
                    "title": "å…¨é¢è¯„ä¼°æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿçš„EmergentTTS-Eval",
                    "desc": "æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªå…¨é¢çš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰åŸºå‡†æµ‹è¯•å·¥å…·EmergentTTS-Evalï¼Œæ—¨åœ¨è‡ªåŠ¨ç”Ÿæˆå’Œè¯„ä¼°æµ‹è¯•æ¡ˆä¾‹ï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨å¤„ç†å¤æ‚è¯­ä¹‰æ–‡æœ¬æ—¶çš„è¡¨ç°ã€‚è¯¥åŸºå‡†æ¶µç›–å…­ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„TTSåœºæ™¯ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿã€æ—è¯­è¨€ã€å¤–è¯­ã€å¥æ³•å¤æ‚æ€§ã€å¤æ‚å‘éŸ³ï¼ˆå¦‚ç½‘å€ã€å…¬å¼ï¼‰å’Œé—®é¢˜ã€‚é€šè¿‡ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿­ä»£æ‰©å±•äººç±»ç¼–å†™çš„ç§å­æç¤ºï¼Œç”Ÿæˆäº†1645ä¸ªå¤šæ ·åŒ–çš„æµ‹è¯•æ¡ˆä¾‹ã€‚æˆ‘ä»¬è¿˜é‡‡ç”¨äº†æ¨¡å‹ä½œä¸ºè¯„åˆ¤è€…çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰ä»å¤šä¸ªç»´åº¦è¯„ä¼°è¯­éŸ³è¾“å‡ºï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ­ç¤ºä¸åŒTTSç³»ç»Ÿä¹‹é—´çš„ç»†å¾®æ€§èƒ½å·®å¼‚ã€‚"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23844",
            "title": "Enabling Flexible Multi-LLM Integration for Scalable Knowledge\n  Aggregation",
            "url": "https://huggingface.co/papers/2505.23844",
            "abstract": "Large language models (LLMs) have shown remarkable promise but remain challenging to continually improve through traditional finetuning, particularly when integrating capabilities from other specialized LLMs. Popular methods like ensemble and weight merging require substantial memory and struggle to adapt to changing data environments. Recent efforts have transferred knowledge from multiple LLMs into a single target model; however, they suffer from interference and degraded performance among tasks, largely due to limited flexibility in candidate selection and training pipelines. To address these issues, we propose a framework that adaptively selects and aggregates knowledge from diverse LLMs to build a single, stronger model, avoiding the high memory overhead of ensemble and inflexible weight merging. Specifically, we design an adaptive selection network that identifies the most relevant source LLMs based on their scores, thereby reducing knowledge interference. We further propose a dynamic weighted fusion strategy that accounts for the inherent strengths of candidate LLMs, along with a feedback-driven loss function that prevents the selector from converging on a single subset of sources. Experimental results demonstrate that our method can enable a more stable and scalable knowledge aggregation process while reducing knowledge interference by up to 50% compared to existing approaches. Code is avaliable at https://github.com/ZLKong/LLM_Integration",
            "score": 1,
            "issue_id": 4066,
            "pub_date": "2025-05-28",
            "pub_date_card": {
                "ru": "28 Ğ¼Ğ°Ñ",
                "en": "May 28",
                "zh": "5æœˆ28æ—¥"
            },
            "hash": "252af3d7c602c2c3",
            "authors": [
                "Zhenglun Kong",
                "Zheng Zhan",
                "Shiyue Hou",
                "Yifan Gong",
                "Xin Meng",
                "Pengwei Sui",
                "Peiyan Dong",
                "Xuan Shen",
                "Zifeng Wang",
                "Pu Zhao",
                "Hao Tang",
                "Stratis Ioannidis",
                "Yanzhi Wang"
            ],
            "affiliations": [
                "Google",
                "Harvard University",
                "Northeastern University",
                "Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23844.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#multimodal",
                    "#training",
                    "#optimization"
                ],
                "emoji": "ğŸ§ ",
                "ru": {
                    "title": "Ğ£Ğ¼Ğ½Ğ¾Ğµ ÑĞ»Ğ¸ÑĞ½Ğ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹",
                    "desc": "Ğ­Ñ‚Ğ° ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (LLM) Ğ¿ÑƒÑ‚ĞµĞ¼ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ±Ğ¾Ñ€Ğ° Ğ¸ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… LLM. ĞĞ²Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ÑÑ‚ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞµÑ‚ÑŒ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºÑƒÑ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ²Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¸ÑĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑƒÑ‡ĞµÑ‚Ğ° ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ñ… ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. ĞœĞµÑ‚Ğ¾Ğ´ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ½Ğ¸Ğ·Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµÑ€ĞµĞ½Ñ†Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ½Ğ° 50% Ğ¿Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°Ğ¼Ğ¸. Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹."
                },
                "en": {
                    "title": "Adaptive Knowledge Aggregation for Enhanced LLM Performance",
                    "desc": "This paper presents a new framework for improving large language models (LLMs) by adaptively selecting and aggregating knowledge from multiple specialized LLMs. Traditional methods like ensemble and weight merging are limited by high memory usage and performance degradation due to knowledge interference. The proposed approach includes an adaptive selection network that identifies the most relevant LLMs and a dynamic weighted fusion strategy that leverages the strengths of these models. Experimental results show that this method significantly reduces knowledge interference and enhances the stability and scalability of knowledge aggregation."
                },
                "zh": {
                    "title": "è‡ªé€‚åº”çŸ¥è¯†èšåˆï¼Œæ„å»ºæ›´å¼ºå¤§çš„è¯­è¨€æ¨¡å‹",
                    "desc": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†é€šè¿‡ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•æŒç»­æ”¹è¿›ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ•´åˆå…¶ä»–ä¸“ä¸šLLMsçš„èƒ½åŠ›æ—¶ã€‚ç°æœ‰çš„æ–¹æ³•å¦‚é›†æˆå’Œæƒé‡åˆå¹¶éœ€è¦å¤§é‡å†…å­˜ï¼Œå¹¶ä¸”éš¾ä»¥é€‚åº”å˜åŒ–çš„æ•°æ®ç¯å¢ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°é€‰æ‹©å’Œèšåˆæ¥è‡ªä¸åŒLLMsçš„çŸ¥è¯†ï¼Œä»¥æ„å»ºä¸€ä¸ªæ›´å¼ºå¤§çš„å•ä¸€æ¨¡å‹ï¼Œé¿å…äº†é›†æˆæ–¹æ³•çš„é«˜å†…å­˜å¼€é”€å’Œæƒé‡åˆå¹¶çš„çµæ´»æ€§ä¸è¶³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°æ›´ç¨³å®šå’Œå¯æ‰©å±•çš„çŸ¥è¯†èšåˆè¿‡ç¨‹ï¼ŒåŒæ—¶å°†çŸ¥è¯†å¹²æ‰°å‡å°‘äº†50%ã€‚"
                }
            }
        }
    ],
    "link_prev": "2025-05-30.html",
    "link_next": "2025-06-03.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "30.05",
        "en": "05/30",
        "zh": "5æœˆ30æ—¥"
    },
    "short_date_next": {
        "ru": "03.06",
        "en": "06/03",
        "zh": "6æœˆ3æ—¥"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 3,
        "#agents": 0,
        "#cv": 2,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 0,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 2,
        "#math": 2,
        "#multilingual": 1,
        "#architecture": 2,
        "#healthcare": 0,
        "#training": 3,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 1,
        "#reasoning": 3,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 4,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 0,
        "#long_context": 0,
        "#synthetic": 2,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ä¸¤ç§åè®­ç»ƒç­–ç•¥ï¼Œè’¸é¦å’Œå¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰ï¼Œç”¨äºè¡¨æ ¼æ¨ç†ä»»åŠ¡çš„æ¨ç†æ—¶ç¼©æ”¾ã€‚è¿™äº›ç­–ç•¥åˆ›å»ºäº†ä¸€ä¸ªåä¸ºTable-R1-Zeroçš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨è¾ƒå°‘çš„å‚æ•°åŒ¹é…GPT-4.1çš„æ€§èƒ½ï¼Œå¹¶å±•ç¤ºå‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿè¯„ä¼°äº†è¿™äº›æ¨¡å‹åœ¨å¤šç§è¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ŒåŒ…æ‹¬çŸ­ç­”é—®ç­”ã€äº‹å®éªŒè¯å’Œè‡ªç”±å½¢å¼é—®ç­”ã€‚ç»“æœæ˜¾ç¤ºï¼ŒTable-R1-Zeroæ¨¡å‹åœ¨ä½¿ç”¨è¾ƒå°‘å‚æ•°çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½åŒ¹é…æˆ–è¶…è¶Šäº†GPT-4.1å’ŒDeepSeek-R1ã€‚",
        "title": "Table-R1: Inference-Time Scaling for Table Reasoning",
        "pinyin": "ZhÃ¨ piÄn wÃ©nzhÄng jiÃ¨shÃ o le liÇng zhÇ’ng hÃ²u xÃ¹nliÃ n cÃ¨lÃ¼Ã¨, zhÄ“ngliÃº hÃ© qiÃ¡ngzhÃ¬ xuÃ©xÃ­ yÇ” kÄ› yÃ nzhÃ¨ng jiÇnglÃ¬ (RLVR), yÃ²ngyÃº biÇogÃ© tuÄ«lÇ rÃ¨nwÃ¹ de tuÄ«lÇ shÃ­ suÅfÃ ng. ZhÃ¨xiÄ“ cÃ¨lÃ¼Ã¨ chuÃ ngjiÃ n le yÄ«gÃ¨ mÃ­ngyÇ Table-R1-Zero de mÃ³xÃ­ng, gÄi mÃ³xÃ­ng shÇyÃ²ng jiÃ o shÇo de cÄnshÃ¹ pÇpÃ¨i GPT-4.1 de xÃ­ngnÃ©ng, bÃ¬ng zhÃ nshÃ¬ chÅ« qiÃ¡ngdÃ  de fÃ nhuÃ  nÃ©nglÃ¬. YÃ¡njiÅ« tuÃ¡nduÃ¬ pÃ­nggÅ« le zhÃ¨xiÄ“ mÃ³xÃ­ng zÃ i duÅ zhÇ’ng biÇogÃ© tuÄ«lÇ rÃ¨nwÃ¹ zhÅng de biÇoxiÃ n, bÄokuÃ² duÇn dÃ¡ wÃ¨ndÃ¡, shÃ¬shÃ­ yÃ nzhÃ¨ng hÃ© zÃ¬yÃ³u xÃ­ngshÃ¬ wÃ¨ndÃ¡. JiÃ©guÇ’ xiÇnshÃ¬, Table-R1-Zero mÃ³xÃ­ng zÃ i shÇyÃ²ng jiÃ o shÇo cÄnshÃ¹ de qÃ­ngkuÃ ng xiÃ , xÃ­ngnÃ©ng pÇpÃ¨i huÃ² chÄoyuÃ¨ le GPT-4.1 hÃ© DeepSeek-R1.",
        "vocab": "[\n    {\"word\": \"è’¸é¦\", \"pinyin\": \"zhÄ“ngliÃº\", \"trans\": \"distillation\"},\n    {\"word\": \"å¼ºåŒ–å­¦ä¹ \", \"pinyin\": \"qiÃ¡ng huÃ  xuÃ© xÃ­\", \"trans\": \"reinforcement learning\"},\n    {\"word\": \"å¯éªŒè¯å¥–åŠ±\", \"pinyin\": \"kÄ› yÃ n zhÃ¨ng jiÇng lÃ¬\", \"trans\": \"verifiable reward\"},\n    {\"word\": \"è¡¨æ ¼æ¨ç†\", \"pinyin\": \"biÇo gÃ© tuÄ« lÇ\", \"trans\": \"table reasoning\"},\n    {\"word\": \"æ¨ç†æ—¶ç¼©æ”¾\", \"pinyin\": \"tuÄ« lÇ shÃ­ suÅ fÃ ng\", \"trans\": \"inference-time scaling\"},\n    {\"word\": \"æ³›åŒ–èƒ½åŠ›\", \"pinyin\": \"fÃ n huÃ  nÃ©ng lÃ¬\", \"trans\": \"generalization capability\"},\n    {\"word\": \"çŸ­ç­”é—®ç­”\", \"pinyin\": \"duÇn dÃ¡ wÃ¨n dÃ¡\", \"trans\": \"short answer Q&A\"},\n    {\"word\": \"äº‹å®éªŒè¯\", \"pinyin\": \"shÃ¬ shÃ­ yÃ n zhÃ¨ng\", \"trans\": \"fact verification\"},\n    {\"word\": \"è‡ªç”±å½¢å¼é—®ç­”\", \"pinyin\": \"zÃ¬ yÃ³u xÃ­ng shÃ¬ wÃ¨n dÃ¡\", \"trans\": \"free-form Q&A\"}\n]",
        "trans": "This article introduces two post-training strategies, distillation and reinforcement learning with verifiable rewards (RLVR), for scaling inference-time reasoning in table reasoning tasks. These strategies create a model called Table-R1-Zero, which matches the performance of GPT-4.1 with fewer parameters and demonstrates strong generalization capabilities. The research team evaluated the performance of these models on various table reasoning tasks, including short answer question-answering, fact verification, and free-form question-answering. The results show that the Table-R1-Zero model matches or outperforms GPT-4.1 and DeepSeek-R1 with fewer parameters.",
        "update_ts": "2025-06-01 12:47"
    }
}