{
    "date": {
        "ru": "2 июня",
        "en": "June 2",
        "zh": "6月2日"
    },
    "time_utc": "2025-06-02 05:13",
    "weekday": 0,
    "issue_id": 4069,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2505.24863",
            "title": "AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time",
            "url": "https://huggingface.co/papers/2505.24863",
            "abstract": "This paper presents AlphaOne (alpha1), a universal framework for modulating reasoning progress in large reasoning models (LRMs) at test time. alpha1 first introduces alpha moment, which represents the scaled thinking phase with a universal parameter alpha. Within this scaled pre-alpha moment phase, it dynamically schedules slow thinking transitions by modeling the insertion of reasoning transition tokens as a Bernoulli stochastic process. After the alpha moment, alpha1 deterministically terminates slow thinking with the end-of-thinking token, thereby fostering fast reasoning and efficient answer generation. This approach unifies and generalizes existing monotonic scaling methods by enabling flexible and dense slow-to-fast reasoning modulation. Extensive empirical studies on various challenging benchmarks across mathematical, coding, and scientific domains demonstrate alpha1's superior reasoning capability and efficiency. Project page: https://alphaone-project.github.io/",
            "score": 20,
            "issue_id": 4066,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "a30c2004fdd2d154",
            "authors": [
                "Junyu Zhang",
                "Runpei Dong",
                "Han Wang",
                "Xuying Ning",
                "Haoran Geng",
                "Peihao Li",
                "Xialin He",
                "Yutong Bai",
                "Jitendra Malik",
                "Saurabh Gupta",
                "Huan Zhang"
            ],
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24863.jpg",
            "data": {
                "categories": [
                    "#math",
                    "#reasoning",
                    "#training",
                    "#benchmark",
                    "#architecture"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "AlphaOne: Универсальная модуляция рассуждений в ИИ",
                    "desc": "AlphaOne (alpha1) - это универсальная система для модуляции процесса рассуждений в крупных моделях рассуждений (LRM) во время тестирования. Она вводит понятие альфа-момента, представляющего масштабированную фазу мышления с универсальным параметром альфа. Система динамически планирует переходы между медленным и быстрым мышлением, моделируя вставку токенов перехода рассуждений как стохастический процесс Бернулли. AlphaOne превосходит существующие методы монотонного масштабирования, обеспечивая гибкую модуляцию рассуждений."
                },
                "en": {
                    "title": "AlphaOne: Revolutionizing Reasoning in Large Models",
                    "desc": "This paper introduces AlphaOne, a framework designed to enhance the reasoning capabilities of large reasoning models (LRMs) during testing. It introduces the concept of the alpha moment, which allows for a controlled thinking phase using a universal parameter. By employing a Bernoulli stochastic process, AlphaOne dynamically manages the transition from slow to fast reasoning, optimizing the model's performance. Empirical results show that AlphaOne outperforms existing methods in various complex tasks, demonstrating its effectiveness in improving reasoning efficiency."
                },
                "zh": {
                    "title": "灵活调节推理进程的AlphaOne框架",
                    "desc": "本文提出了AlphaOne（alpha1），这是一个在测试时调节大型推理模型（LRMs）推理进程的通用框架。alpha1首先引入了alpha时刻，表示带有通用参数alpha的缩放思维阶段。在这个缩放的前alpha时刻阶段中，它通过将推理过渡标记的插入建模为伯努利随机过程，动态调度缓慢思维的过渡。在alpha时刻之后，alpha1通过思维结束标记确定性地终止缓慢思维，从而促进快速推理和高效答案生成。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24864",
            "title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in\n  Large Language Models",
            "url": "https://huggingface.co/papers/2505.24864",
            "abstract": "Recent advances in reasoning-centric language models have highlighted reinforcement learning (RL) as a promising method for aligning models with verifiable rewards. However, it remains contentious whether RL truly expands a model's reasoning capabilities or merely amplifies high-reward outputs already latent in the base model's distribution, and whether continually scaling up RL compute reliably leads to improved reasoning performance. In this work, we challenge prevailing assumptions by demonstrating that prolonged RL (ProRL) training can uncover novel reasoning strategies that are inaccessible to base models, even under extensive sampling. We introduce ProRL, a novel training methodology that incorporates KL divergence control, reference policy resetting, and a diverse suite of tasks. Our empirical analysis reveals that RL-trained models consistently outperform base models across a wide range of pass@k evaluations, including scenarios where base models fail entirely regardless of the number of attempts. We further show that reasoning boundary improvements correlates strongly with task competence of base model and training duration, suggesting that RL can explore and populate new regions of solution space over time. These findings offer new insights into the conditions under which RL meaningfully expands reasoning boundaries in language models and establish a foundation for future work on long-horizon RL for reasoning. We release model weights to support further research: https://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B",
            "score": 12,
            "issue_id": 4069,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "390a294f460cedfc",
            "authors": [
                "Mingjie Liu",
                "Shizhe Diao",
                "Ximing Lu",
                "Jian Hu",
                "Xin Dong",
                "Yejin Choi",
                "Jan Kautz",
                "Yi Dong"
            ],
            "affiliations": [
                "NVIDIA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24864.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#optimization",
                    "#training",
                    "#rl",
                    "#alignment",
                    "#open_source"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Расширение границ рассуждений языковых моделей с помощью длительного обучения с подкреплением",
                    "desc": "Статья описывает новый метод обучения языковых моделей с подкреплением (RL) под названием ProRL. Авторы показывают, что длительное RL-обучение может раскрыть новые стратегии рассуждений, недоступные базовым моделям. ProRL включает контроль расхождения KL, сброс эталонной политики и набор разнообразных задач. Эмпирический анализ демонстрирует, что модели, обученные с помощью RL, превосходят базовые модели в различных оценках pass@k."
                },
                "en": {
                    "title": "Unlocking New Reasoning Strategies with ProRL",
                    "desc": "This paper explores the effectiveness of reinforcement learning (RL) in enhancing the reasoning capabilities of language models. The authors introduce a new training method called ProRL, which employs techniques like KL divergence control and reference policy resetting to improve model performance. Their experiments show that models trained with ProRL outperform base models in various reasoning tasks, even in cases where base models struggle. The study suggests that prolonged RL training can help discover new reasoning strategies, indicating that RL can significantly expand the reasoning abilities of language models over time."
                },
                "zh": {
                    "title": "强化学习扩展推理能力的新方法",
                    "desc": "最近的研究表明，基于推理的语言模型在强化学习（RL）方面取得了进展，这被认为是一种有效的方法来使模型与可验证的奖励对齐。然而，关于RL是否真正增强了模型的推理能力，还是仅仅放大了基础模型分布中已经存在的高奖励输出，仍然存在争议。本文提出了一种新的训练方法ProRL，证明了经过长时间的RL训练可以发现基础模型无法访问的新推理策略。我们的实证分析显示，经过RL训练的模型在多种评估任务中表现优于基础模型，尤其是在基础模型完全失败的情况下。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24098",
            "title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding",
            "url": "https://huggingface.co/papers/2505.24098",
            "abstract": "Verifiers play a crucial role in large language model (LLM) reasoning, needed by post-training techniques such as reinforcement learning. However, reliable verifiers are hard to get for difficult coding problems, because a well-disguised wrong solution may only be detected by carefully human-written edge cases that are difficult to synthesize. To address this issue, we propose HARDTESTGEN, a pipeline for high-quality test synthesis using LLMs. With this pipeline, we curate a comprehensive competitive programming dataset HARDTESTS with 47k problems and synthetic high-quality tests. Compared with existing tests, HARDTESTGEN tests demonstrate precision that is 11.3 percentage points higher and recall that is 17.5 percentage points higher when evaluating LLM-generated code. For harder problems, the improvement in precision can be as large as 40 points. HARDTESTS also proves to be more effective for model training, measured by downstream code generation performance. We will open-source our dataset and synthesis pipeline at https://leililab.github.io/HardTests/.",
            "score": 12,
            "issue_id": 4069,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "1a86a8aadff22dbb",
            "authors": [
                "Zhongmou He",
                "Yee Man Choi",
                "Kexun Zhang",
                "Jiabao Ji",
                "Junting Zhou",
                "Dejia Xu",
                "Ivan Bercovich",
                "Aidan Zhang",
                "Lei Li"
            ],
            "affiliations": [
                "Carnegie Mellon University",
                "UC Santa Barbara",
                "UT Austin"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24098.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#reasoning",
                    "#training",
                    "#data",
                    "#open_source",
                    "#dataset"
                ],
                "emoji": "🧪",
                "ru": {
                    "title": "Улучшение верификации кода с помощью синтетических тестов",
                    "desc": "Статья представляет HARDTESTGEN - пайплайн для синтеза высококачественных тестов с использованием больших языковых моделей (LLM). На его основе создан набор данных HARDTESTS, содержащий 47 тысяч задач по соревновательному программированию с синтетическими тестами высокого качества. Тесты HARDTESTGEN показывают значительно более высокую точность и полноту при оценке кода, сгенерированного LLM, по сравнению с существующими тестами. HARDTESTS также оказывается более эффективным для обучения моделей, что измеряется производительностью генерации кода."
                },
                "en": {
                    "title": "Enhancing LLM Evaluation with Synthetic Test Cases",
                    "desc": "This paper introduces HARDTESTGEN, a new method for generating high-quality test cases for evaluating large language models (LLMs) in coding tasks. The challenge with existing verifiers is that they often fail to catch subtle errors in code, which can only be identified through complex human-written edge cases. HARDTESTGEN addresses this by synthesizing a dataset called HARDTESTS, which includes 47,000 programming problems along with high-quality tests generated by LLMs. The results show that tests from HARDTESTGEN significantly improve the precision and recall of evaluating LLM-generated code, making it a valuable tool for enhancing model training and performance."
                },
                "zh": {
                    "title": "高质量测试合成，提升LLM推理能力",
                    "desc": "本文提出了一种名为HARDTESTGEN的高质量测试合成管道，旨在解决大型语言模型（LLM）推理中的验证器问题。由于难以为复杂编码问题获取可靠的验证器，HARDTESTGEN能够生成高质量的测试用例，帮助评估LLM生成的代码。我们创建了一个包含47,000个问题的竞争编程数据集HARDTESTS，并且与现有测试相比，HARDTESTGEN的测试在精确度和召回率上都有显著提升。该数据集和合成管道将开源，供研究人员使用。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.14752",
            "title": "Large Language Models for Data Synthesis",
            "url": "https://huggingface.co/papers/2505.14752",
            "abstract": "LLMSynthor enhances LLMs for efficient and statistically accurate data synthesis through distributional feedback and proposal sampling.  \t\t\t\t\tAI-generated summary \t\t\t\t Generating synthetic data that faithfully captures the statistical structure of real-world distributions is a fundamental challenge in data modeling. Classical approaches often depend on strong parametric assumptions or manual structural design and struggle in high-dimensional or heterogeneous domains. Recent progress in Large Language Models (LLMs) reveals their potential as flexible, high-dimensional priors over real-world distributions. However, when applied to data synthesis, standard LLM-based sampling is inefficient, constrained by fixed context limits, and fails to ensure statistical alignment. Given this, we introduce LLMSynthor, a general framework for data synthesis that transforms LLMs into structure-aware simulators guided by distributional feedback. LLMSynthor treats the LLM as a nonparametric copula simulator for modeling high-order dependencies and introduces LLM Proposal Sampling to generate grounded proposal distributions that improve sampling efficiency without requiring rejection. By minimizing discrepancies in the summary statistics space, the iterative synthesis loop aligns real and synthetic data while gradually uncovering and refining the latent generative structure. We evaluate LLMSynthor in both controlled and real-world settings using heterogeneous datasets in privacy-sensitive domains (e.g., e-commerce, population, and mobility) that encompass both structured and unstructured formats. The synthetic data produced by LLMSynthor shows high statistical fidelity, practical utility, and cross-data adaptability, positioning it as a valuable tool across economics, social science, urban studies, and beyond.",
            "score": 11,
            "issue_id": 4067,
            "pub_date": "2025-05-20",
            "pub_date_card": {
                "ru": "20 мая",
                "en": "May 20",
                "zh": "5月20日"
            },
            "hash": "202c77d3d43de6f6",
            "authors": [
                "Yihong Tang",
                "Menglin Kong",
                "Lijun Sun"
            ],
            "affiliations": [
                "McGill University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.14752.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#synthetic",
                    "#data"
                ],
                "emoji": "🧬",
                "ru": {
                    "title": "LLMSynthor: Превращение языковых моделей в точные генераторы синтетических данных",
                    "desc": "LLMSynthor - это фреймворк для синтеза данных, который превращает большие языковые модели (LLM) в симуляторы, учитывающие структуру данных и использующие распределительную обратную связь. Он применяет LLM как непараметрический копула-симулятор для моделирования зависимостей высокого порядка и вводит LLM Proposal Sampling для создания обоснованных предлагаемых распределений. LLMSynthor итеративно минимизирует расхождения в пространстве сводных статистик, выравнивая реальные и синтетические данные. Фреймворк показывает высокую статистическую точность и практическую полезность на гетерогенных наборах данных в конфиденциальных областях."
                },
                "en": {
                    "title": "Transforming LLMs into Efficient Data Synthesizers",
                    "desc": "LLMSynthor is a framework that enhances Large Language Models (LLMs) for creating synthetic data that accurately reflects real-world statistical distributions. It addresses the limitations of traditional data synthesis methods, which often rely on rigid assumptions and struggle with complex data types. By using distributional feedback and a novel LLM Proposal Sampling technique, LLMSynthor improves the efficiency and accuracy of data generation without the need for rejection sampling. The framework has been tested in various real-world scenarios, demonstrating its ability to produce high-quality synthetic data suitable for diverse applications."
                },
                "zh": {
                    "title": "LLMSynthor：高效的统计数据合成新工具",
                    "desc": "LLMSynthor 是一种增强大型语言模型（LLM）以实现高效和统计准确的数据合成的方法。它通过分布反馈和提议采样，将 LLM 转变为结构感知的模拟器，能够更好地捕捉真实世界分布的统计特征。该框架通过最小化摘要统计空间中的差异，逐步对齐真实数据和合成数据，同时揭示和优化潜在的生成结构。LLMSynthor 在隐私敏感领域的异构数据集上进行了评估，显示出高统计保真度和实用性，适用于经济学、社会科学和城市研究等多个领域。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24878",
            "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and\n  Benchmarking Multimodal LLM Agents",
            "url": "https://huggingface.co/papers/2505.24878",
            "abstract": "CAPTCHAs have been a critical bottleneck for deploying web agents in real-world applications, often blocking them from completing end-to-end automation tasks. While modern multimodal LLM agents have demonstrated impressive performance in static perception tasks, their ability to handle interactive, multi-step reasoning challenges like CAPTCHAs is largely untested. To address this gap, we introduce Open CaptchaWorld, the first web-based benchmark and platform specifically designed to evaluate the visual reasoning and interaction capabilities of MLLM-powered agents through diverse and dynamic CAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225 CAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth, which quantifies the number of cognitive and motor steps required to solve each puzzle. Experimental results show that humans consistently achieve near-perfect scores, state-of-the-art MLLM agents struggle significantly, with success rates at most 40.0% by Browser-Use Openai-o3, far below human-level performance, 93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing the limits of current multimodal agents and guiding the development of more robust multimodal reasoning systems. Code and Data are available at this https URL.",
            "score": 7,
            "issue_id": 4067,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "9cceceaf09c77468",
            "authors": [
                "Yaxin Luo",
                "Zhaoyi Li",
                "Jiacheng Liu",
                "Jiacheng Cui",
                "Xiaohan Zhao",
                "Zhiqiang Shen"
            ],
            "affiliations": [
                "MetaAgentX",
                "VILA Lab, MBZUAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24878.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#benchmark",
                    "#reasoning"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Open CaptchaWorld: вызов для мультимодальных ИИ-агентов",
                    "desc": "Статья представляет Open CaptchaWorld - первый веб-бенчмарк для оценки возможностей мультимодальных языковых моделей (MLLM) в решении CAPTCHA. Бенчмарк включает 20 типов современных CAPTCHA, всего 225 задач, с новой метрикой - глубиной рассуждения CAPTCHA. Эксперименты показали, что люди достигают почти идеальных результатов, в то время как лучшие MLLM-агенты справляются максимум с 40% задач. Это подчеркивает важность Open CaptchaWorld для диагностики ограничений современных мультимодальных агентов и разработки более надежных систем рассуждений."
                },
                "en": {
                    "title": "Unlocking the Future: Evaluating MLLM Agents with Open CaptchaWorld",
                    "desc": "This paper introduces Open CaptchaWorld, a new benchmark designed to test the capabilities of multimodal large language model (MLLM) agents in solving CAPTCHA puzzles. It evaluates the visual reasoning and interaction skills of these agents through a variety of 225 CAPTCHA types, measuring their performance with a novel metric called CAPTCHA Reasoning Depth. Experimental results reveal that while humans achieve high success rates, MLLM agents struggle significantly, with a maximum success rate of only 40%. This underscores the need for improved multimodal reasoning systems and positions Open CaptchaWorld as a crucial tool for assessing and enhancing agent performance in complex tasks."
                },
                "zh": {
                    "title": "突破CAPTCHA瓶颈，提升多模态推理能力！",
                    "desc": "CAPTCHA在实际应用中是部署网络代理的一个重要瓶颈，常常阻碍它们完成端到端的自动化任务。虽然现代多模态大语言模型（MLLM）在静态感知任务中表现出色，但它们在处理交互式、多步骤推理挑战（如CAPTCHA）方面的能力尚未得到充分测试。为了解决这个问题，我们推出了Open CaptchaWorld，这是第一个专门设计用于评估MLLM代理的视觉推理和交互能力的网络基准平台，涵盖20种现代CAPTCHA类型，共225个CAPTCHA，并引入了一种新的度量标准：CAPTCHA推理深度。实验结果表明，人类的成功率接近完美，而最先进的MLLM代理的成功率最高仅为40.0%，远低于人类的93.3%，这突显了Open CaptchaWorld作为诊断当前多模态代理局限性的重要基准。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24850",
            "title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher\n  Data for LLM Reasoning",
            "url": "https://huggingface.co/papers/2505.24850",
            "abstract": "Recent advances in model distillation demonstrate that data from advanced reasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer complex reasoning abilities to smaller, efficient student models. However, standard practices employ rejection sampling, discarding incorrect reasoning examples -- valuable, yet often underutilized data. This paper addresses the critical question: How can both positive and negative distilled reasoning traces be effectively leveraged to maximize LLM reasoning performance in an offline setting? To this end, We propose Reinforcement Distillation (REDI), a two-stage framework. Stage 1 learns from positive traces via Supervised Fine-Tuning (SFT). Stage 2 further refines the model using both positive and negative traces through our proposed REDI objective. This novel objective is a simple, reference-free loss function that outperforms established methods like DPO and SimPO in this distillation context. Our empirical evaluations demonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT combined with DPO/SimPO on mathematical reasoning tasks. Notably, the Qwen-REDI-1.5B model, post-trained on just 131k positive and negative examples from the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1). Its performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a model post-trained on 800k proprietary data) across various mathematical reasoning benchmarks, establishing a new state-of-the-art for 1.5B models post-trained offline with openly available data.",
            "score": 4,
            "issue_id": 4067,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "e946031c286b5bf4",
            "authors": [
                "Shuyao Xu",
                "Cheng Peng",
                "Jiangxuan Long",
                "Weidi Xu",
                "Wei Chu",
                "Yuan Qi"
            ],
            "affiliations": [
                "AI3 Institute of Fudan University",
                "INFLY TECH (Shanghai) Co., Ltd.",
                "National University of Singapore"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24850.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#reasoning",
                    "#dataset",
                    "#math"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "REDI: Эффективное обучение рассуждениям на положительных и отрицательных примерах",
                    "desc": "Статья представляет новый метод дистилляции моделей машинного обучения под названием Reinforcement Distillation (REDI). REDI использует как положительные, так и отрицательные примеры рассуждений для улучшения способностей языковых моделей к логическому мышлению. Метод состоит из двух этапов: обучение на положительных примерах и дальнейшая оптимизация с использованием специальной целевой функции REDI. Эксперименты показывают превосходство REDI над базовыми методами на задачах математических рассуждений, особенно для моделей среднего размера."
                },
                "en": {
                    "title": "Maximizing Reasoning Performance with Reinforcement Distillation",
                    "desc": "This paper introduces Reinforcement Distillation (REDI), a two-stage framework designed to enhance the reasoning capabilities of smaller models by utilizing both positive and negative reasoning examples. In the first stage, the model is fine-tuned using positive reasoning traces through Supervised Fine-Tuning (SFT). The second stage refines the model further by incorporating both types of traces with a novel, reference-free loss function that improves performance over traditional methods like DPO and SimPO. Empirical results show that the Qwen-REDI-1.5B model achieves impressive scores on mathematical reasoning tasks, outperforming larger models trained on more extensive proprietary datasets."
                },
                "zh": {
                    "title": "强化蒸馏：提升推理性能的新方法",
                    "desc": "本论文探讨了如何有效利用正负推理轨迹来提升大型语言模型（LLM）的推理性能。我们提出了一种名为强化蒸馏（REDI）的两阶段框架，第一阶段通过监督微调（SFT）学习正推理轨迹，第二阶段则结合正负推理轨迹进一步优化模型。我们的REDI目标是一个简单的无参考损失函数，在蒸馏任务中优于传统方法如DPO和SimPO。实验结果表明，经过131k正负样本训练的Qwen-REDI-1.5B模型在数学推理任务上达到了83.1%的得分，创造了1.5B模型的新状态。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24521",
            "title": "UniGeo: Taming Video Diffusion for Unified Consistent Geometry\n  Estimation",
            "url": "https://huggingface.co/papers/2505.24521",
            "abstract": "Recently, methods leveraging diffusion model priors to assist monocular geometric estimation (e.g., depth and normal) have gained significant attention due to their strong generalization ability. However, most existing works focus on estimating geometric properties within the camera coordinate system of individual video frames, neglecting the inherent ability of diffusion models to determine inter-frame correspondence. In this work, we demonstrate that, through appropriate design and fine-tuning, the intrinsic consistency of video generation models can be effectively harnessed for consistent geometric estimation. Specifically, we 1) select geometric attributes in the global coordinate system that share the same correspondence with video frames as the prediction targets, 2) introduce a novel and efficient conditioning method by reusing positional encodings, and 3) enhance performance through joint training on multiple geometric attributes that share the same correspondence. Our results achieve superior performance in predicting global geometric attributes in videos and can be directly applied to reconstruction tasks. Even when trained solely on static video data, our approach exhibits the potential to generalize to dynamic video scenes.",
            "score": 4,
            "issue_id": 4067,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "4ae43b7cdb482867",
            "authors": [
                "Yang-Tian Sun",
                "Xin Yu",
                "Zehuan Huang",
                "Yi-Hua Huang",
                "Yuan-Chen Guo",
                "Ziyi Yang",
                "Yan-Pei Cao",
                "Xiaojuan Qi"
            ],
            "affiliations": [
                "Beihang University",
                "The University of Hong Kong",
                "VAST"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24521.jpg",
            "data": {
                "categories": [
                    "#video",
                    "#diffusion",
                    "#optimization",
                    "#cv"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "Согласованная геометрическая оценка видео с помощью диффузионных моделей",
                    "desc": "Статья представляет новый подход к оценке геометрических свойств в видео с использованием диффузионных моделей. Авторы предлагают метод, который позволяет использовать внутреннюю согласованность моделей генерации видео для последовательной геометрической оценки. Они вводят новый метод кондиционирования, переиспользуя позиционные кодировки, и улучшают производительность путем совместного обучения на нескольких геометрических атрибутах. Результаты показывают превосходную производительность в предсказании глобальных геометрических атрибутов в видео и могут быть применены к задачам реконструкции."
                },
                "en": {
                    "title": "Harnessing Diffusion Models for Consistent Geometric Estimation in Videos",
                    "desc": "This paper explores the use of diffusion models to improve the estimation of geometric properties like depth and normals in videos. Unlike previous methods that focus on individual frames, this approach leverages the relationships between frames to enhance consistency in geometric estimation. The authors propose a novel conditioning method that reuses positional encodings and advocate for joint training on multiple geometric attributes. Their results show improved performance in predicting global geometric attributes, demonstrating the model's ability to generalize even from static video data to dynamic scenes."
                },
                "zh": {
                    "title": "利用扩散模型提升视频几何估计的一致性",
                    "desc": "最近，利用扩散模型先验来辅助单目几何估计（如深度和法线）的方法受到了广泛关注，因为它们具有很强的泛化能力。然而，大多数现有工作集中在单个视频帧的相机坐标系内估计几何属性，忽视了扩散模型在确定帧间对应关系方面的固有能力。在本研究中，我们展示了通过适当的设计和微调，可以有效利用视频生成模型的内在一致性来进行一致的几何估计。具体而言，我们选择在全局坐标系中与视频帧共享相同对应关系的几何属性作为预测目标，并引入了一种新颖高效的条件方法，通过重用位置编码来增强性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24196",
            "title": "CLaSp: In-Context Layer Skip for Self-Speculative Decoding",
            "url": "https://huggingface.co/papers/2505.24196",
            "abstract": "Speculative decoding (SD) is a promising method for accelerating the decoding process of Large Language Models (LLMs). The efficiency of SD primarily hinges on the consistency between the draft model and the verify model. However, existing drafting approaches typically require additional modules to be trained, which can be challenging to implement and ensure compatibility across various LLMs. In this paper, we propose CLaSp, an in-context layer-skipping strategy for self-speculative decoding. Unlike prior methods, CLaSp does not require additional drafting modules or extra training. Instead, it employs a plug-and-play mechanism by skipping intermediate layers of the verify model to construct a compressed draft model. Specifically, we develop a dynamic programming algorithm that optimizes the layer-skipping process by leveraging the complete hidden states from the last verification stage as an objective. This enables CLaSp to dynamically adjust its layer-skipping strategy after each verification stage, without relying on pre-optimized sets of skipped layers. Experimental results across diverse downstream tasks demonstrate that CLaSp achieves a speedup of 1.3x ~ 1.7x on LLaMA3 series models without altering the original distribution of the generated text.",
            "score": 4,
            "issue_id": 4069,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "004f8eaa8c2fe087",
            "authors": [
                "Longze Chen",
                "Renke Shan",
                "Huiming Wang",
                "Lu Wang",
                "Ziqiang Liu",
                "Run Luo",
                "Jiawei Wang",
                "Hamid Alinejad-Rokny",
                "Min Yang"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2505.24196.jpg",
            "data": {
                "categories": [
                    "#inference",
                    "#architecture",
                    "#optimization",
                    "#training"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "Ускорение LLM без компромиссов: CLaSp - новый метод спекулятивного декодирования",
                    "desc": "В статье представлен метод CLaSp для ускорения декодирования больших языковых моделей (LLM) с помощью спекулятивного декодирования. CLaSp использует стратегию пропуска слоев в контексте для самоспекулятивного декодирования, не требуя дополнительных модулей или обучения. Метод применяет алгоритм динамического программирования для оптимизации процесса пропуска слоев, используя скрытые состояния последней стадии верификации. Эксперименты показывают, что CLaSp достигает ускорения в 1.3-1.7 раза на моделях серии LLaMA3 без изменения исходного распределения генерируемого текста."
                },
                "en": {
                    "title": "Accelerating LLM Decoding with Layer-Skipping Efficiency",
                    "desc": "This paper introduces CLaSp, a novel approach to speculative decoding that enhances the efficiency of Large Language Models (LLMs) without the need for additional training modules. CLaSp utilizes an in-context layer-skipping strategy, allowing it to create a compressed draft model by skipping certain layers in the verify model. The method employs a dynamic programming algorithm to optimize the layer-skipping process, adapting after each verification stage based on the hidden states. Experimental results show that CLaSp can speed up the decoding process by 1.3x to 1.7x on LLaMA3 models while maintaining the quality of the generated text."
                },
                "zh": {
                    "title": "CLaSp：加速解码的新策略",
                    "desc": "本文提出了一种名为CLaSp的自我推测解码策略，旨在加速大型语言模型的解码过程。CLaSp通过跳过验证模型的中间层，构建一个压缩的草稿模型，从而避免了额外模块的训练需求。该方法利用动态规划算法优化层跳过过程，使其能够在每个验证阶段后动态调整策略。实验结果表明，CLaSp在LLaMA3系列模型上实现了1.3倍到1.7倍的加速，同时保持生成文本的原始分布不变。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24858",
            "title": "MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs",
            "url": "https://huggingface.co/papers/2505.24858",
            "abstract": "A critical component in the trustworthiness of LLMs is reliable uncertainty communication, yet LLMs often use assertive language when conveying false claims, leading to over-reliance and eroded trust. We present the first systematic study of faithful confidence calibration of LLMs, benchmarking models' ability to use linguistic expressions of uncertainty that faithfully reflect their intrinsic uncertainty, across a comprehensive array of models, datasets, and prompting strategies. Our results demonstrate that LLMs largely fail at this task, and that existing interventions are insufficient: standard prompt approaches provide only marginal gains, and existing, factuality-based calibration techniques can even harm faithful calibration. To address this critical gap, we introduce MetaFaith, a novel prompt-based calibration approach inspired by human metacognition. We show that MetaFaith robustly improves faithful calibration across diverse models and task domains, enabling up to 61% improvement in faithfulness and achieving an 83% win rate over original generations as judged by humans.",
            "score": 3,
            "issue_id": 4069,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "5cc52e721279a4e1",
            "authors": [
                "Gabrielle Kaili-May Liu",
                "Gal Yona",
                "Avi Caciularu",
                "Idan Szpektor",
                "Tim G. J. Rudner",
                "Arman Cohan"
            ],
            "affiliations": [
                "Google Research",
                "New York University",
                "Yale University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24858.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#benchmark",
                    "#alignment",
                    "#interpretability",
                    "#hallucinations",
                    "#dataset"
                ],
                "emoji": "🎯",
                "ru": {
                    "title": "Научить ИИ честно выражать неуверенность",
                    "desc": "Исследование посвящено проблеме надежной коммуникации неопределенности в больших языковых моделях (LLM). Авторы провели систематический анализ способности моделей выражать неуверенность, соответствующую их внутренней неопределенности. Результаты показали, что существующие LLM и методы в основном не справляются с этой задачей. Предложен новый метод калибровки MetaFaith, вдохновленный человеческой метакогнитивностью, который значительно улучшает верную калибровку моделей."
                },
                "en": {
                    "title": "Enhancing Trust in LLMs through Better Uncertainty Communication",
                    "desc": "This paper addresses the issue of how large language models (LLMs) communicate uncertainty, which is crucial for building trust in their outputs. The authors conduct a systematic study to evaluate how well LLMs express their confidence levels in a way that matches their actual uncertainty. They find that current methods for improving this communication are largely ineffective, and some can even worsen the situation. To solve this problem, they propose a new method called MetaFaith, which significantly enhances the ability of LLMs to convey uncertainty accurately, leading to better trustworthiness in their responses."
                },
                "zh": {
                    "title": "提升大型语言模型的不确定性表达信任度",
                    "desc": "本研究探讨了大型语言模型（LLMs）在不确定性传达方面的可靠性，指出它们在表达错误信息时常使用过于自信的语言，从而导致用户过度依赖并削弱信任。我们系统地评估了LLMs在使用不确定性语言表达其内在不确定性方面的能力，结果显示大多数模型在这方面表现不佳。现有的干预措施效果有限，标准提示方法仅带来微小改进，而基于事实的校准技术甚至可能对忠实校准产生负面影响。为了解决这一问题，我们提出了MetaFaith，这是一种基于提示的新型校准方法，能够显著提高不同模型和任务领域的忠实校准效果。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23941",
            "title": "Vision Language Models are Biased",
            "url": "https://huggingface.co/papers/2505.23941",
            "abstract": "Large language models (LLMs) memorize a vast amount of prior knowledge from the Internet that help them on downstream tasks but also may notoriously sway their outputs towards wrong or biased answers. In this work, we test how the knowledge about popular subjects hurt the accuracy of vision language models (VLMs) on standard, objective visual tasks of counting and identification. We find that state-of-the-art VLMs are strongly biased (e.g, unable to recognize a fourth stripe has been added to a 3-stripe Adidas logo) scoring an average of 17.05% accuracy in counting (e.g., counting stripes in an Adidas-like logo) across 7 diverse domains from animals, logos, chess, board games, optical illusions, to patterned grids. Insert text (e.g., \"Adidas\") describing the subject name into the counterfactual image further decreases VLM accuracy. The biases in VLMs are so strong that instructing them to double-check their results or rely exclusively on image details to answer improves counting accuracy by only +2 points, on average. Our work presents an interesting failure mode in VLMs and an automated framework for testing VLM biases. Code and data are available at: vlmsarebiased.github.io.",
            "score": 3,
            "issue_id": 4069,
            "pub_date": "2025-05-29",
            "pub_date_card": {
                "ru": "29 мая",
                "en": "May 29",
                "zh": "5月29日"
            },
            "hash": "1c96442d8acb3ec5",
            "authors": [
                "An Vo",
                "Khai-Nguyen Nguyen",
                "Mohammad Reza Taesiri",
                "Vy Tuong Dang",
                "Anh Totti Nguyen",
                "Daeyoung Kim"
            ],
            "affiliations": [
                "Auburn University",
                "College of William and Mary",
                "KAIST",
                "University of Alberta"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23941.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#cv",
                    "#hallucinations",
                    "#ethics",
                    "#dataset"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Предвзятость визуально-языковых моделей: когда знания мешают точности",
                    "desc": "Это исследование показывает, что крупные языковые модели (LLM) и визуально-языковые модели (VLM) могут быть сильно предвзяты из-за предварительных знаний, полученных из интернета. Авторы тестируют VLM на задачах подсчета и идентификации объектов, обнаруживая низкую точность (в среднем 17,05%) в различных доменах. Интересно, что добавление текстовой информации о предмете еще больше снижает точность моделей. Инструктирование моделей перепроверять свои результаты или полагаться только на детали изображения лишь незначительно улучшает точность подсчета."
                },
                "en": {
                    "title": "Unveiling Biases in Vision Language Models",
                    "desc": "This paper investigates how large language models (LLMs) influence the performance of vision language models (VLMs) on visual tasks like counting and identification. The authors find that VLMs exhibit significant biases, leading to poor accuracy when recognizing visual elements, such as miscounting stripes on logos. Even when provided with counterfactual information, such as the name of the subject, the accuracy of VLMs decreases further. The study highlights a critical failure mode in VLMs and introduces a framework for assessing these biases systematically."
                },
                "zh": {
                    "title": "视觉语言模型的偏见问题",
                    "desc": "大型语言模型（LLMs）从互联网中记忆了大量知识，这对下游任务有帮助，但也可能导致输出偏向错误或有偏见的答案。我们研究了流行主题的知识如何影响视觉语言模型（VLMs）在标准视觉任务（如计数和识别）上的准确性。结果显示，最先进的VLMs在计数任务中的平均准确率仅为17.05%，并且在识别图案时存在明显的偏见。我们的研究揭示了VLMs中的一种有趣的失败模式，并提供了一个自动化框架来测试VLM的偏见。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24417",
            "title": "EasyText: Controllable Diffusion Transformer for Multilingual Text\n  Rendering",
            "url": "https://huggingface.co/papers/2505.24417",
            "abstract": "Generating accurate multilingual text with diffusion models has long been desired but remains challenging. Recent methods have made progress in rendering text in a single language, but rendering arbitrary languages is still an unexplored area. This paper introduces EasyText, a text rendering framework based on DiT (Diffusion Transformer), which connects denoising latents with multilingual character tokens encoded as character tokens. We propose character positioning encoding and position encoding interpolation techniques to achieve controllable and precise text rendering. Additionally, we construct a large-scale synthetic text image dataset with 1 million multilingual image-text annotations as well as a high-quality dataset of 20K annotated images, which are used for pretraining and fine-tuning respectively. Extensive experiments and evaluations demonstrate the effectiveness and advancement of our approach in multilingual text rendering, visual quality, and layout-aware text integration.",
            "score": 2,
            "issue_id": 4066,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "f28c426fafe8156a",
            "authors": [
                "Runnan Lu",
                "Yuxuan Zhang",
                "Jailing Liu",
                "Haifa Wang",
                "Yiren Song"
            ],
            "affiliations": [
                "Liblib AI",
                "National University of Singapore",
                "The Chinese University of Hong Kong",
                "Tiamat AI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.24417.jpg",
            "data": {
                "categories": [
                    "#synthetic",
                    "#dataset",
                    "#multilingual",
                    "#cv",
                    "#diffusion"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "EasyText: прорыв в многоязычном рендеринге текста с помощью диффузионных моделей",
                    "desc": "Статья представляет EasyText - фреймворк для рендеринга многоязычного текста, основанный на модели диффузии DiT. Авторы предлагают методы кодирования позиций символов и интерполяции позиционного кодирования для точного рендеринга текста. Для обучения модели был создан большой синтетический датасет с 1 миллионом аннотаций изображений с текстом на разных языках. Эксперименты показывают эффективность подхода в многоязычном рендеринге текста, визуальном качестве и интеграции текста с учетом макета."
                },
                "en": {
                    "title": "EasyText: Multilingual Text Rendering Made Simple",
                    "desc": "This paper presents EasyText, a novel framework for generating multilingual text using diffusion models. It leverages a Diffusion Transformer (DiT) to connect denoising latents with multilingual character tokens, addressing the challenge of rendering text in various languages. The authors introduce innovative techniques such as character positioning encoding and position encoding interpolation to enhance the control and precision of text rendering. They also create a large-scale dataset with 1 million multilingual image-text pairs, which significantly improves the model's performance in multilingual text rendering and visual quality."
                },
                "zh": {
                    "title": "多语言文本渲染的新突破",
                    "desc": "本论文介绍了一种名为EasyText的文本渲染框架，基于扩散变换器（DiT）技术。该框架通过将去噪潜变量与多语言字符令牌连接，实现了对多语言文本的精确渲染。我们提出了字符位置编码和位置编码插值技术，以实现可控和精确的文本渲染。此外，我们构建了一个包含100万条多语言图像-文本注释的大规模合成文本图像数据集，用于预训练和微调，实验结果表明我们的方法在多语言文本渲染和视觉质量方面具有显著优势。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23009",
            "title": "EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic,\n  Expressiveness, and Linguistic Challenges Using Model-as-a-Judge",
            "url": "https://huggingface.co/papers/2505.23009",
            "abstract": "A comprehensive TTS benchmark, EmergentTTS-Eval, automates test-case generation and evaluation using LLMs and LALM to assess nuanced and semantically complex text in speech outputs.  \t\t\t\t\tAI-generated summary \t\t\t\t Text-to-Speech (TTS) benchmarks often fail to capture how well models handle nuanced and semantically complex text. Building on EmergentTTS, we introduce EmergentTTS-Eval, a comprehensive benchmark covering six challenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic complexity, complex pronunciation (e.g. URLs, formulas), and questions. Crucially, our framework automates both test-case generation and evaluation, making the benchmark easily extensible. Starting from a small set of human-written seed prompts, we iteratively extend them using LLMs to target specific structural, phonetic and prosodic challenges, resulting in 1,645 diverse test cases. Moreover, we employ a model-as-a-judge approach, using a Large Audio Language Model (LALM) to assess the speech across multiple dimensions such as expressed emotion, prosodic, intonational, and pronunciation accuracy. We evaluate state-of-the-art open-source and proprietary TTS systems, such as 11Labs, Deepgram, and OpenAI's 4o-mini-TTS, on EmergentTTS-Eval, demonstrating its ability to reveal fine-grained performance differences. Results show that the model-as-a-judge approach offers robust TTS assessment and a high correlation with human preferences. We open source the evaluation https://github.com/boson-ai/EmergentTTS-Eval-public{code} and the https://huggingface.co/datasets/bosonai/EmergentTTS-Eval{dataset}.",
            "score": 2,
            "issue_id": 4067,
            "pub_date": "2025-05-29",
            "pub_date_card": {
                "ru": "29 мая",
                "en": "May 29",
                "zh": "5月29日"
            },
            "hash": "8ed75b2649e36558",
            "authors": [
                "Ruskin Raj Manku",
                "Yuzhi Tang",
                "Xingjian Shi",
                "Mu Li",
                "Alex Smola"
            ],
            "affiliations": [
                "Boson AI, Santa Clara, CA 95054"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23009.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#benchmark",
                    "#open_source",
                    "#audio"
                ],
                "emoji": "🗣️",
                "ru": {
                    "title": "Автоматизированная оценка сложных аспектов синтеза речи с помощью ИИ",
                    "desc": "EmergentTTS-Eval - это новый комплексный бенчмарк для оценки систем Text-to-Speech (TTS). Он использует языковые модели (LLM) и аудио-языковые модели (LALM) для автоматической генерации тестовых случаев и оценки качества синтезированной речи. Бенчмарк охватывает шесть сложных сценариев, включая эмоции, паралингвистику, иностранные слова и сложное произношение. Результаты показывают, что подход 'модель-как-судья' обеспечивает надежную оценку TTS систем и высокую корреляцию с предпочтениями людей."
                },
                "en": {
                    "title": "Automating TTS Evaluation for Nuanced Speech Outputs",
                    "desc": "The paper presents EmergentTTS-Eval, a new benchmark for evaluating Text-to-Speech (TTS) systems that focuses on complex and nuanced text. It automates the generation of test cases using Large Language Models (LLMs) and evaluates the outputs with a Large Audio Language Model (LALM). The benchmark includes six challenging scenarios, such as emotional expression and complex pronunciation, and generates 1,645 diverse test cases from a small set of human-written prompts. The results show that this automated approach provides a reliable assessment of TTS systems, correlating well with human evaluations."
                },
                "zh": {
                    "title": "全面评估文本到语音系统的EmergentTTS-Eval",
                    "desc": "本文介绍了一个全面的文本到语音（TTS）基准测试工具EmergentTTS-Eval，旨在自动生成和评估测试案例，以评估模型在处理复杂语义文本时的表现。该基准涵盖六种具有挑战性的TTS场景，包括情感、旁语言、外语、句法复杂性、复杂发音（如网址、公式）和问题。通过使用大型语言模型（LLM）迭代扩展人类编写的种子提示，生成了1645个多样化的测试案例。我们还采用了模型作为评判者的方法，利用大型音频语言模型（LALM）从多个维度评估语音输出，结果显示该方法能够有效揭示不同TTS系统之间的细微性能差异。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.24293",
            "title": "Large Language Models are Locally Linear Mappings",
            "url": "https://huggingface.co/papers/2505.24293",
            "abstract": "We demonstrate that the inference operations of several open-weight large language models (LLMs) can be mapped to an exactly equivalent linear system for an input sequence without modifying the model weights or altering output predictions. Extending techniques from image diffusion models that exhibit local or piecewise linearity, we strategically alter the gradient computation with respect to a given input sequence for a next-token prediction such that the Jacobian of the model nearly exactly reproduces the forward prediction with a linear system. We demonstrate this approach across models (Llama 3, Gemma 3, Qwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show through the singular value decomposition of the detached Jacobian that these LLMs operate in extremely low-dimensional subspaces where many of the largest singular vectors decode to concepts related to the most-likely output token. This approach also allows us to examine the operation of each successive layer (and its attention and MLP components) as nearly-exact linear systems and observe the emergence of semantic concepts. Despite their expressive power and global nonlinearity, modern LLMs can be interpreted through nearly-exact locally linear decompositions that provide insights into their internal representations and reveal interpretable semantic structures in the next-token prediction process.",
            "score": 1,
            "issue_id": 4066,
            "pub_date": "2025-05-30",
            "pub_date_card": {
                "ru": "30 мая",
                "en": "May 30",
                "zh": "5月30日"
            },
            "hash": "42a9e20ff9742560",
            "authors": [
                "James R. Golden"
            ],
            "affiliations": [],
            "pdf_title_img": "assets/pdf/title_img/2505.24293.jpg",
            "data": {
                "categories": [
                    "#architecture",
                    "#interpretability",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "🧮",
                "ru": {
                    "title": "Линейное представление нелинейных языковых моделей",
                    "desc": "Исследователи показали, что операции вывода нескольких открытых большим языковых моделей (LLM) можно отобразить в эквивалентную линейную систему для входной последовательности без изменения весов модели или предсказаний. Они расширили методы из моделей диффузии изображений, проявляющих локальную или кусочную линейность, стратегически изменив вычисление градиента для предсказания следующего токена. Этот подход был продемонстрирован на различных моделях, включая Llama 3, Gemma 3 и другие. Анализ сингулярного разложения отсоединенного якобиана показал, что эти LLM работают в экстремально низкоразмерных подпространствах, где многие из крупнейших сингулярных векторов декодируются в концепции, связанные с наиболее вероятным выходным токеном."
                },
                "en": {
                    "title": "Unlocking LLMs: Linear Insights into Complex Predictions",
                    "desc": "This paper shows that the inference processes of large language models (LLMs) can be represented as linear systems without changing the model's weights or outputs. By modifying the gradient calculations for next-token predictions, the authors create a Jacobian that closely mirrors the model's predictions using linear methods. They analyze various LLMs and find that these models operate in low-dimensional spaces, where significant singular vectors correspond to key concepts for predicting the next token. This method allows for a deeper understanding of how each layer functions and reveals interpretable semantic structures in the predictions of LLMs."
                },
                "zh": {
                    "title": "揭示大型语言模型的线性本质",
                    "desc": "本文展示了多个开放权重的大型语言模型（LLMs）的推理操作可以映射到一个完全等价的线性系统，而无需修改模型权重或改变输出预测。我们借鉴了图像扩散模型的技术，通过战略性地改变相对于给定输入序列的梯度计算，使得模型的雅可比矩阵几乎完全重现了线性系统的前向预测。我们在多个模型上验证了这种方法，并通过对分离雅可比矩阵的奇异值分解，发现这些LLMs在极低维的子空间中操作，许多最大的奇异向量解码出与最可能输出标记相关的概念。尽管现代LLMs具有强大的表达能力和全局非线性，但可以通过几乎精确的局部线性分解进行解释，从而提供对其内部表示的洞察，并揭示下一个标记预测过程中的可解释语义结构。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.23844",
            "title": "Enabling Flexible Multi-LLM Integration for Scalable Knowledge\n  Aggregation",
            "url": "https://huggingface.co/papers/2505.23844",
            "abstract": "Large language models (LLMs) have shown remarkable promise but remain challenging to continually improve through traditional finetuning, particularly when integrating capabilities from other specialized LLMs. Popular methods like ensemble and weight merging require substantial memory and struggle to adapt to changing data environments. Recent efforts have transferred knowledge from multiple LLMs into a single target model; however, they suffer from interference and degraded performance among tasks, largely due to limited flexibility in candidate selection and training pipelines. To address these issues, we propose a framework that adaptively selects and aggregates knowledge from diverse LLMs to build a single, stronger model, avoiding the high memory overhead of ensemble and inflexible weight merging. Specifically, we design an adaptive selection network that identifies the most relevant source LLMs based on their scores, thereby reducing knowledge interference. We further propose a dynamic weighted fusion strategy that accounts for the inherent strengths of candidate LLMs, along with a feedback-driven loss function that prevents the selector from converging on a single subset of sources. Experimental results demonstrate that our method can enable a more stable and scalable knowledge aggregation process while reducing knowledge interference by up to 50% compared to existing approaches. Code is avaliable at https://github.com/ZLKong/LLM_Integration",
            "score": 1,
            "issue_id": 4066,
            "pub_date": "2025-05-28",
            "pub_date_card": {
                "ru": "28 мая",
                "en": "May 28",
                "zh": "5月28日"
            },
            "hash": "252af3d7c602c2c3",
            "authors": [
                "Zhenglun Kong",
                "Zheng Zhan",
                "Shiyue Hou",
                "Yifan Gong",
                "Xin Meng",
                "Pengwei Sui",
                "Peiyan Dong",
                "Xuan Shen",
                "Zifeng Wang",
                "Pu Zhao",
                "Hao Tang",
                "Stratis Ioannidis",
                "Yanzhi Wang"
            ],
            "affiliations": [
                "Google",
                "Harvard University",
                "Northeastern University",
                "Peking University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.23844.jpg",
            "data": {
                "categories": [
                    "#transfer_learning",
                    "#multimodal",
                    "#training",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Умное слияние языковых моделей: адаптивный подход к интеграции знаний",
                    "desc": "Эта статья представляет новый подход к улучшению больших языковых моделей (LLM) путем адаптивного отбора и объединения знаний из различных LLM. Авторы предлагают фреймворк, который использует сеть адаптивного выбора для определения наиболее релевантных исходных моделей и динамическую стратегию взвешенного слияния для учета сильных сторон каждой модели. Метод позволяет снизить интерференцию знаний на 50% по сравнению с существующими подходами. Экспериментальные результаты показывают, что предложенный метод обеспечивает более стабильный и масштабируемый процесс агрегации знаний."
                },
                "en": {
                    "title": "Adaptive Knowledge Aggregation for Enhanced LLM Performance",
                    "desc": "This paper presents a new framework for improving large language models (LLMs) by adaptively selecting and aggregating knowledge from multiple specialized LLMs. Traditional methods like ensemble and weight merging are limited by high memory usage and performance degradation due to knowledge interference. The proposed approach includes an adaptive selection network that identifies the most relevant LLMs and a dynamic weighted fusion strategy that leverages the strengths of these models. Experimental results show that this method significantly reduces knowledge interference and enhances the stability and scalability of knowledge aggregation."
                },
                "zh": {
                    "title": "自适应知识聚合，构建更强大的语言模型",
                    "desc": "大型语言模型（LLMs）在性能上表现出色，但通过传统的微调方法持续改进仍然具有挑战性，尤其是在整合其他专业LLMs的能力时。现有的方法如集成和权重合并需要大量内存，并且难以适应变化的数据环境。我们提出了一种框架，能够自适应地选择和聚合来自不同LLMs的知识，以构建一个更强大的单一模型，避免了集成方法的高内存开销和权重合并的灵活性不足。实验结果表明，我们的方法能够实现更稳定和可扩展的知识聚合过程，同时将知识干扰减少了50%。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2505.18842",
            "title": "Don't Look Only Once: Towards Multimodal Interactive Reasoning with\n  Selective Visual Revisitation",
            "url": "https://huggingface.co/papers/2505.18842",
            "abstract": "v1 enhances Multimodal Large Language Models by enabling selective and dynamic visual region retrieval during inference, improving performance on multimodal reasoning tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t We present v1, a lightweight extension to Multimodal Large Language Models (MLLMs) that enables selective visual revisitation during inference. While current MLLMs typically consume visual input only once and reason purely over internal memory, v1 introduces a simple point-and-copy mechanism that allows the model to dynamically retrieve relevant image regions throughout the reasoning process. This mechanism augments existing architectures with minimal modifications, enabling contextual access to visual tokens based on the model's evolving hypotheses. To train this capability, we construct v1g, a dataset of 300K multimodal reasoning traces with interleaved visual grounding annotations. Experiments on three multimodal mathematical reasoning benchmarks -- MathVista, MathVision, and MathVerse -- demonstrate that v1 consistently improves performance over comparable baselines, particularly on tasks requiring fine-grained visual reference and multi-step reasoning. Our results suggest that dynamic visual access is a promising direction for enhancing grounded multimodal reasoning. Code, models, and data will be released to support future research.",
            "score": 1,
            "issue_id": 4069,
            "pub_date": "2025-05-24",
            "pub_date_card": {
                "ru": "24 мая",
                "en": "May 24",
                "zh": "5月24日"
            },
            "hash": "a97f1e174b838d2d",
            "authors": [
                "Jiwan Chung",
                "Junhyeok Kim",
                "Siyeol Kim",
                "Jaeyoung Lee",
                "Min Soo Kim",
                "Youngjae Yu"
            ],
            "affiliations": [
                "Seoul National University",
                "Yonsei University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2505.18842.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#reasoning",
                    "#benchmark",
                    "#games",
                    "#architecture",
                    "#dataset"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Динамический визуальный доступ для улучшения мультимодальных рассуждений",
                    "desc": "v1 - это расширение для мультимодальных больших языковых моделей (MLLM), которое позволяет избирательно обращаться к визуальным данным во время вывода. Оно вводит механизм указания и копирования, позволяющий модели динамически извлекать релевантные области изображения в процессе рассуждения. Для обучения этой возможности был создан набор данных v1g из 300 тысяч трасс мультимодальных рассуждений с аннотациями визуальной привязки. Эксперименты на трех эталонных тестах по мультимодальным математическим рассуждениям показали, что v1 стабильно улучшает производительность по сравнению с базовыми моделями."
                },
                "en": {
                    "title": "Dynamic Visual Retrieval for Enhanced Multimodal Reasoning",
                    "desc": "The paper introduces v1, an enhancement to Multimodal Large Language Models (MLLMs) that allows for selective and dynamic retrieval of visual information during inference. Unlike traditional MLLMs that process visual inputs only once, v1 employs a point-and-copy mechanism to revisit relevant image regions as the model generates responses. This approach improves the model's ability to perform multimodal reasoning tasks by providing contextual access to visual data based on its ongoing hypotheses. The authors validate v1's effectiveness through experiments on multiple benchmarks, showing significant performance gains in tasks that require detailed visual references and complex reasoning steps."
                },
                "zh": {
                    "title": "动态视觉访问提升多模态推理能力",
                    "desc": "v1是对多模态大型语言模型（MLLMs）的轻量级扩展，能够在推理过程中实现选择性视觉区域的动态检索。与传统的MLLMs仅在内部记忆中进行推理不同，v1引入了一种简单的点对点复制机制，使模型能够在推理过程中动态获取相关的图像区域。通过构建包含30万条多模态推理轨迹的数据集v1g，模型得以训练这种能力。实验结果表明，v1在多个多模态数学推理基准上表现优异，尤其是在需要细致视觉参考和多步骤推理的任务中。"
                }
            }
        }
    ],
    "link_prev": "2025-05-30.html",
    "link_next": "2025-06-03.html",
    "link_month": "2025-06.html",
    "short_date_prev": {
        "ru": "30.05",
        "en": "05/30",
        "zh": "5月30日"
    },
    "short_date_next": {
        "ru": "03.06",
        "en": "06/03",
        "zh": "6月3日"
    },
    "categories": {
        "#dataset": 7,
        "#data": 2,
        "#benchmark": 5,
        "#agents": 0,
        "#cv": 3,
        "#rl": 1,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 2,
        "#3d": 0,
        "#audio": 1,
        "#video": 1,
        "#multimodal": 4,
        "#math": 2,
        "#multilingual": 1,
        "#architecture": 4,
        "#healthcare": 0,
        "#training": 7,
        "#robotics": 0,
        "#agi": 0,
        "#games": 2,
        "#interpretability": 2,
        "#reasoning": 6,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 6,
        "#survey": 0,
        "#diffusion": 2,
        "#alignment": 2,
        "#story_generation": 0,
        "#hallucinations": 2,
        "#long_context": 0,
        "#synthetic": 3,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 3,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 0
    },
    "zh": {
        "text": "这篇文章介绍了两种后训练策略，蒸馏和强化学习与可验证奖励（RLVR），用于表格推理任务的推理时缩放。这些策略创建了一个名为Table-R1-Zero的模型，该模型使用较少的参数匹配GPT-4.1的性能，并展示出强大的泛化能力。研究团队评估了这些模型在多种表格推理任务中的表现，包括短答问答、事实验证和自由形式问答。结果显示，Table-R1-Zero模型在使用较少参数的情况下，性能匹配或超越了GPT-4.1和DeepSeek-R1。",
        "title": "Table-R1: Inference-Time Scaling for Table Reasoning",
        "pinyin": "Zhè piān wénzhāng jièshào le liǎng zhǒng hòu xùnliàn cèlüè, zhēngliú hé qiángzhì xuéxí yǔ kě yànzhèng jiǎnglì (RLVR), yòngyú biǎogé tuīlǐ rènwù de tuīlǐ shí suōfàng. Zhèxiē cèlüè chuàngjiàn le yīgè míngyǐ Table-R1-Zero de móxíng, gāi móxíng shǐyòng jiào shǎo de cānshù pǐpèi GPT-4.1 de xíngnéng, bìng zhànshì chū qiángdà de fànhuà nénglì. Yánjiū tuánduì pínggū le zhèxiē móxíng zài duō zhǒng biǎogé tuīlǐ rènwù zhōng de biǎoxiàn, bāokuò duǎn dá wèndá, shìshí yànzhèng hé zìyóu xíngshì wèndá. Jiéguǒ xiǎnshì, Table-R1-Zero móxíng zài shǐyòng jiào shǎo cānshù de qíngkuàng xià, xíngnéng pǐpèi huò chāoyuè le GPT-4.1 hé DeepSeek-R1.",
        "vocab": "[\n    {\"word\": \"蒸馏\", \"pinyin\": \"zhēngliú\", \"trans\": \"distillation\"},\n    {\"word\": \"强化学习\", \"pinyin\": \"qiáng huà xué xí\", \"trans\": \"reinforcement learning\"},\n    {\"word\": \"可验证奖励\", \"pinyin\": \"kě yàn zhèng jiǎng lì\", \"trans\": \"verifiable reward\"},\n    {\"word\": \"表格推理\", \"pinyin\": \"biǎo gé tuī lǐ\", \"trans\": \"table reasoning\"},\n    {\"word\": \"推理时缩放\", \"pinyin\": \"tuī lǐ shí suō fàng\", \"trans\": \"inference-time scaling\"},\n    {\"word\": \"泛化能力\", \"pinyin\": \"fàn huà néng lì\", \"trans\": \"generalization capability\"},\n    {\"word\": \"短答问答\", \"pinyin\": \"duǎn dá wèn dá\", \"trans\": \"short answer Q&A\"},\n    {\"word\": \"事实验证\", \"pinyin\": \"shì shí yàn zhèng\", \"trans\": \"fact verification\"},\n    {\"word\": \"自由形式问答\", \"pinyin\": \"zì yóu xíng shì wèn dá\", \"trans\": \"free-form Q&A\"}\n]",
        "trans": "This article introduces two post-training strategies, distillation and reinforcement learning with verifiable rewards (RLVR), for scaling inference-time reasoning in table reasoning tasks. These strategies create a model called Table-R1-Zero, which matches the performance of GPT-4.1 with fewer parameters and demonstrates strong generalization capabilities. The research team evaluated the performance of these models on various table reasoning tasks, including short answer question-answering, fact verification, and free-form question-answering. The results show that the Table-R1-Zero model matches or outperforms GPT-4.1 and DeepSeek-R1 with fewer parameters.",
        "update_ts": "2025-06-01 12:47"
    }
}