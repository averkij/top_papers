{
    "date": {
        "ru": "14 февраля",
        "en": "February 14",
        "zh": "2月14日"
    },
    "time_utc": "2025-02-14 03:14",
    "weekday": 4,
    "issue_id": 2209,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2502.09604",
            "title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models",
            "url": "https://huggingface.co/papers/2502.09604",
            "abstract": "We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks.",
            "score": 5,
            "issue_id": 2209,
            "pub_date": "2025-02-13",
            "pub_date_card": {
                "ru": "13 февраля",
                "en": "February 13",
                "zh": "2月13日"
            },
            "hash": "7aa5ce3731848736",
            "authors": [
                "Yung-Sung Chuang",
                "Benjamin Cohen-Wang",
                "Shannon Zejiang Shen",
                "Zhaofeng Wu",
                "Hu Xu",
                "Xi Victoria Lin",
                "James Glass",
                "Shang-Wen Li",
                "Wen-tau Yih"
            ],
            "affiliations": [
                "Massachusetts Institute of Technology",
                "Meta FAIR"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.09604.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#long_context",
                    "#training",
                    "#alignment",
                    "#rlhf",
                    "#benchmark"
                ],
                "emoji": "📚",
                "ru": {
                    "title": "SelfCite: Самообучение ИИ искусству цитирования",
                    "desc": "SelfCite - это новый подход к самообучению больших языковых моделей (LLM) для генерации качественных цитат на уровне предложений. Метод использует сигнал награды, предоставляемый самой моделью через абляцию контекста, что позволяет избежать дорогостоящей ручной разметки. SelfCite применяет стратегию выборки best-of-N во время вывода и оптимизацию предпочтений для точной настройки моделей. Эффективность подхода подтверждается увеличением F1-меры цитирования до 5.3 пунктов на бенчмарке LongBench-Cite."
                },
                "en": {
                    "title": "Enhancing Citation Quality with SelfCite",
                    "desc": "SelfCite is a self-supervised method designed to enhance the citation quality in responses generated by large language models (LLMs). It uses a unique reward signal derived from the LLM itself, which assesses the necessity of citations by analyzing the impact of removing or retaining cited text. This approach not only improves the citation generation process during inference but also allows for fine-tuning the models to produce better citations through preference optimization. The results show a significant increase in citation accuracy, as evidenced by a 5.3 point improvement in citation F1 scores on the LongBench-Cite benchmark."
                },
                "zh": {
                    "title": "自监督引用生成的创新方法",
                    "desc": "SelfCite是一种新颖的自监督方法，旨在使大型语言模型（LLM）生成高质量、细粒度的句子级引用。该方法通过上下文消融提供的奖励信号，减少对昂贵和劳动密集型注释的依赖。具体来说，如果引用是必要的，移除被引用文本应防止相同的响应；如果足够，保留被引用文本应保持相同的响应。SelfCite在LongBench-Cite基准测试中显示出有效性，使引用的F1分数提高了5.3个百分点。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.08946",
            "title": "The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding",
            "url": "https://huggingface.co/papers/2502.08946",
            "abstract": "In a systematic way, we investigate a widely asked question: Do LLMs really understand what they say?, which relates to the more familiar term Stochastic Parrot. To this end, we propose a summative assessment over a carefully designed physical concept understanding task, PhysiCo. Our task alleviates the memorization issue via the usage of grid-format inputs that abstractly describe physical phenomena. The grids represents varying levels of understanding, from the core phenomenon, application examples to analogies to other abstract patterns in the grid world. A comprehensive study on our task demonstrates: (1) state-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag behind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs, as they fail on our grid task but can describe and recognize the same concepts well in natural language; (3) our task challenges the LLMs due to intrinsic difficulties rather than the unfamiliar grid format, as in-context learning and fine-tuning on same formatted data added little to their performance.",
            "score": 1,
            "issue_id": 2209,
            "pub_date": "2025-02-13",
            "pub_date_card": {
                "ru": "13 февраля",
                "en": "February 13",
                "zh": "2月13日"
            },
            "hash": "daecc7f38306f7b8",
            "authors": [
                "Mo Yu",
                "Lemao Liu",
                "Junjie Wu",
                "Tsz Ting Chung",
                "Shunchi Zhang",
                "Jiangnan Li",
                "Dit-Yan Yeung",
                "Jie Zhou"
            ],
            "affiliations": [
                "HKUST",
                "JHU",
                "WeChat AI, Tencent"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.08946.jpg",
            "data": {
                "categories": [
                    "#hallucinations",
                    "#dataset",
                    "#training",
                    "#reasoning",
                    "#interpretability"
                ],
                "emoji": "🦜",
                "ru": {
                    "title": "Языковые модели: понимание или имитация?",
                    "desc": "Исследователи изучают вопрос о действительном понимании языковыми моделями (LLM) того, что они говорят. Они разработали задачу PhysiCo для оценки понимания физических концепций, используя абстрактные сетки вместо естественного языка. Результаты показывают, что современные LLM, включая GPT-4 и Gemini 2.0, отстают от людей примерно на 40% в этой задаче. Исследование подтверждает феномен 'стохастического попугая', так как модели не справляются с сеточной задачей, но хорошо описывают те же концепции на естественном языке."
                },
                "en": {
                    "title": "Unveiling the Limits of LLM Understanding",
                    "desc": "This paper investigates whether large language models (LLMs) truly understand the content they generate, addressing the concept of the 'Stochastic Parrot'. The authors introduce a new assessment task called PhysiCo, which uses grid-format inputs to evaluate understanding of physical concepts. Their findings reveal that top-performing LLMs, like GPT-4o and Gemini 2.0, significantly underperform compared to humans, indicating a gap in comprehension. Additionally, the study shows that LLMs struggle with the task due to inherent challenges in understanding rather than just the format of the input data."
                },
                "zh": {
                    "title": "探究大型语言模型的理解能力",
                    "desc": "本研究系统性地探讨了一个常见问题：大型语言模型（LLMs）是否真正理解它们所说的内容。我们提出了一种名为PhysiCo的评估任务，旨在通过网格格式的输入来减轻记忆问题，这些输入抽象地描述了物理现象。研究表明，当前最先进的LLMs在理解能力上落后于人类约40%，并且在网格任务中表现不佳，显示出随机鹦鹉现象的存在。我们的任务挑战了LLMs，主要是由于内在的困难，而非网格格式的不熟悉。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.09100",
            "title": "Logical Reasoning in Large Language Models: A Survey",
            "url": "https://huggingface.co/papers/2502.09100",
            "abstract": "With the emergence of advanced reasoning models like OpenAI o3 and DeepSeek-R1, large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, their ability to perform rigorous logical reasoning remains an open question. This survey synthesizes recent advancements in logical reasoning within LLMs, a critical area of AI research. It outlines the scope of logical reasoning in LLMs, its theoretical foundations, and the benchmarks used to evaluate reasoning proficiency. We analyze existing capabilities across different reasoning paradigms - deductive, inductive, abductive, and analogical - and assess strategies to enhance reasoning performance, including data-centric tuning, reinforcement learning, decoding strategies, and neuro-symbolic approaches. The review concludes with future directions, emphasizing the need for further exploration to strengthen logical reasoning in AI systems.",
            "score": 1,
            "issue_id": 2209,
            "pub_date": "2025-02-13",
            "pub_date_card": {
                "ru": "13 февраля",
                "en": "February 13",
                "zh": "2月13日"
            },
            "hash": "72b32d40c559c7e4",
            "authors": [
                "Hanmeng Liu",
                "Zhizhang Fu",
                "Mengru Ding",
                "Ruoxi Ning",
                "Chaoli Zhang",
                "Xiaozhang Liu",
                "Yue Zhang"
            ],
            "affiliations": [
                "Hainan University",
                "Westlake University",
                "Zhejiang Normal University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.09100.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#survey",
                    "#reasoning",
                    "#rl",
                    "#benchmark"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Логическое мышление в больших языковых моделях: прогресс и перспективы",
                    "desc": "Этот обзор посвящен последним достижениям в области логического рассуждения в больших языковых моделях (LLM). В нем рассматриваются теоретические основы и методы оценки способностей LLM к логическому мышлению. Авторы анализируют существующие возможности в различных парадигмах рассуждений, включая дедуктивное, индуктивное, абдуктивное и аналогическое. Также обсуждаются стратегии улучшения производительности рассуждений, такие как настройка данных, обучение с подкреплением и нейросимволические подходы."
                },
                "en": {
                    "title": "Enhancing Logical Reasoning in Large Language Models",
                    "desc": "This paper reviews the progress made in enhancing logical reasoning capabilities of large language models (LLMs) like OpenAI o3 and DeepSeek-R1. It discusses various reasoning paradigms such as deductive, inductive, abductive, and analogical reasoning, highlighting their theoretical foundations and evaluation benchmarks. The authors analyze strategies to improve reasoning performance, including data-centric tuning and neuro-symbolic approaches. The paper concludes by suggesting future research directions to further develop logical reasoning in AI systems."
                },
                "zh": {
                    "title": "提升AI系统逻辑推理能力的探索",
                    "desc": "随着OpenAI o3和DeepSeek-R1等先进推理模型的出现，大型语言模型（LLMs）展现了出色的推理能力。然而，它们在进行严格逻辑推理方面的能力仍然是一个未解之谜。本文综述了LLMs中逻辑推理的最新进展，探讨了逻辑推理的范围、理论基础以及评估推理能力的基准。我们分析了不同推理范式（如演绎、归纳、溯因和类比）的现有能力，并评估了增强推理性能的策略，包括数据中心调优、强化学习、解码策略和神经符号方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2502.09056",
            "title": "An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging",
            "url": "https://huggingface.co/papers/2502.09056",
            "abstract": "This paper investigates data selection and model merging methodologies aimed at incorporating advanced reasoning capabilities such as those of DeepSeek R1 into language-specific large language models (LLMs), with a particular focus on the Thai LLM. Our goal is to enhance the reasoning capabilities of language-specific LLMs while maintaining their target language abilities. DeepSeek R1 excels in reasoning but primarily benefits high-resource languages such as English and Chinese. However, low-resource languages remain underserved due to the dominance of English-centric training data and model optimizations, which limit performance in these languages. This limitation results in unreliable code-switching and diminished effectiveness on tasks in low-resource languages. Meanwhile, local and regional LLM initiatives have attempted to bridge this gap by developing language-specific LLMs that focus on improving local linguistic fidelity. We demonstrate that, with only publicly available datasets and a computational budget of $120, it is possible to enhance the reasoning capabilities of language-specific LLMs to match the level of DeepSeek R1, without compromising their performance on target language tasks.",
            "score": 0,
            "issue_id": 2209,
            "pub_date": "2025-02-13",
            "pub_date_card": {
                "ru": "13 февраля",
                "en": "February 13",
                "zh": "2月13日"
            },
            "hash": "36c3c29072ae279d",
            "authors": [
                "Kunat Pipatanakul",
                "Pittawat Taveekitworachai",
                "Potsawee Manakul",
                "Kasima Tharnpipitchai"
            ],
            "affiliations": [
                "SCB 10X R&D SCBX Group Bangkok, Thailand"
            ],
            "pdf_title_img": "assets/pdf/title_img/2502.09056.jpg",
            "data": {
                "categories": [
                    "#data",
                    "#dataset",
                    "#low_resource",
                    "#multilingual",
                    "#training",
                    "#reasoning"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Усиление логики локальных языковых моделей",
                    "desc": "Данное исследование посвящено методам улучшения способностей к рассуждению у языково-специфичных больших языковых моделей (LLM), в частности для тайского языка. Авторы предлагают подходы к отбору данных и слиянию моделей, чтобы перенести продвинутые навыки рассуждения из модели DeepSeek R1 в локальные LLM. Цель состоит в том, чтобы усилить логические возможности языково-специфичных моделей, сохраняя при этом их способности в целевом языке. Исследователи показывают, что даже с ограниченным бюджетом и общедоступными данными можно значительно улучшить рассуждения локальных LLM до уровня DeepSeek R1."
                },
                "en": {
                    "title": "Empowering Thai LLMs with Enhanced Reasoning Capabilities",
                    "desc": "This paper explores methods for selecting data and merging models to improve reasoning abilities in language-specific large language models (LLMs), particularly for the Thai language. The authors aim to enhance these models' reasoning skills while ensuring they remain effective in their target languages. They highlight the challenges faced by low-resource languages, which often lack the extensive training data available for high-resource languages like English. The study demonstrates that it is feasible to boost the reasoning capabilities of these LLMs using only publicly available datasets and a modest budget, achieving results comparable to advanced models like DeepSeek R1."
                },
                "zh": {
                    "title": "提升低资源语言LLM的推理能力",
                    "desc": "本文研究了数据选择和模型合并的方法，旨在将先进的推理能力（如DeepSeek R1）融入特定语言的大型语言模型（LLMs），特别关注泰语LLM。我们的目标是增强特定语言LLMs的推理能力，同时保持其目标语言的能力。DeepSeek R1在推理方面表现出色，但主要受益于高资源语言，如英语和中文，而低资源语言则受到忽视。我们展示了仅使用公开数据集和120美元的计算预算，就可以提升特定语言LLMs的推理能力，使其达到DeepSeek R1的水平，而不影响其在目标语言任务上的表现。"
                }
            }
        }
    ],
    "link_prev": "2025-02-13.html",
    "link_next": "2025-02-17.html",
    "link_month": "2025-02.html",
    "short_date_prev": {
        "ru": "13.02",
        "en": "02/13",
        "zh": "2月13日"
    },
    "short_date_next": {
        "ru": "17.02",
        "en": "02/17",
        "zh": "2月17日"
    },
    "categories": {
        "#dataset": 2,
        "#data": 1,
        "#benchmark": 2,
        "#agents": 0,
        "#cv": 0,
        "#rl": 1,
        "#rlhf": 1,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 0,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 0,
        "#math": 0,
        "#multilingual": 1,
        "#architecture": 0,
        "#healthcare": 0,
        "#training": 4,
        "#robotics": 0,
        "#agi": 0,
        "#games": 0,
        "#interpretability": 1,
        "#reasoning": 3,
        "#transfer_learning": 0,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 1,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 0,
        "#low_resource": 1
    },
    "zh": {
        "text": "最近的图像重光模型进展使得一致的光照效果成为可能。然而，视频重光仍然滞后，主要由于训练成本高昂和缺乏多样化、高质量的视频重光数据集。逐帧应用图像重光模型会导致光源和外观不一致，生成的视频会出现闪烁。我们提出了Light-A-Video，一种无需训练的视频重光方法。它通过一致光照注意力模块和渐进光融合策略来增强光照一致性，确保视频的时间连贯性。",
        "title": "Light-A-Video: Training-free Video Relighting via Progressive Light Fusion",
        "pinyin": "最近的图像重光模型进展使得一致的光照效果成为可能。然而，视频重光仍然滞后，主要由于训练成本高昂和缺乏多样化、高质量的视频重光数据集。逐帧应用图像重光模型会导致光源和外观不一致，生成的视频会出现闪烁。我们提出了Light-A-Video，一种无需训练的视频重光方法。它通过一致光照注意力模块和渐进光融合策略来增强光照一致性，确保视频的时间连贯性。\n\nZuìjìn de túxiàng zhòngguāng móxíng jìnzhǎn shǐdé yīzhì de guāngzhào xiàoguǒ chéngwéi kěnéng. Rán'ér, shìpín zhòngguāng réngrán zhìhòu, zhǔyào yóuyú xùnliàn chéngběn gāotáng hé quēfá duōyànghuà, gāo zhìliàng de shìpín zhòngguāng shùjùjí. Zhúzhèn yìngyòng túxiàng zhòngguāng móxíng huì dǎozhì guāngyuán hé wàixiàn bù yīzhì, shēngchéng de shìpín huì chūxiàn shǎnshuò. Wǒmen tíchūle Light-A-Video, yīzhǒng wúxū xùnliàn de shìpín zhòngguāng fāngfǎ. Tā tōngguò yīzhì guāngzhào zhùyìlì mókuài hé jiànjìn guāng rónghé cèlüè lái zēngqiáng guāngzhào yīzhìxìng, quèbǎo shìpín de shíjiān liánhéxìng.",
        "vocab": "[{'word': '重光', 'pinyin': 'chóng guāng', 'trans': 'relighting'},\n{'word': '进展', 'pinyin': 'jìn zhǎn', 'trans': 'progress'},\n{'word': '一致', 'pinyin': 'yī zhì', 'trans': 'consistent'},\n{'word': '光照', 'pinyin': 'guāng zhào', 'trans': 'illumination'},\n{'word': '滞后', 'pinyin': 'zhì hòu', 'trans': 'lag behind'},\n{'word': '主要', 'pinyin': 'zhǔ yào', 'trans': 'mainly'},\n{'word': '由于', 'pinyin': 'yóu yú', 'trans': 'due to'},\n{'word': '高昂', 'pinyin': 'gāo áng', 'trans': 'high'},\n{'word': '缺乏', 'pinyin': 'quē fá', 'trans': 'lack'},\n{'word': '多样化', 'pinyin': 'duō yàng huà', 'trans': 'diversified'},\n{'word': '高质量', 'pinyin': 'gāo zhì liàng', 'trans': 'high quality'},\n{'word': '数据集', 'pinyin': 'shù jù jí', 'trans': 'dataset'},\n{'word': '逐帧', 'pinyin': 'zhú zhēn', 'trans': 'frame-by-frame'},\n{'word': '导致', 'pinyin': 'dǎo zhì', 'trans': 'lead to'},\n{'word': '外观', 'pinyin': 'wài guǎn', 'trans': 'appearance'},\n{'word': '闪烁', 'pinyin': 'shǎn shuò', 'trans': 'flicker'},\n{'word': '提出', 'pinyin': 'tí chū', 'trans': 'propose'},\n{'word': '无需', 'pinyin': 'wú xū', 'trans': 'without needing'},\n{'word': '方法', 'pinyin': 'fāng fǎ', 'trans': 'method'},\n{'word': '模块', 'pinyin': 'mó kuài', 'trans': 'module'},\n{'word': '策略', 'pinyin': 'cè lüè', 'trans': 'strategy'},\n{'word': '增强', 'pinyin': 'zēng qiáng', 'trans': 'enhance'},\n{'word': '确保', 'pinyin': 'què bǎo', 'trans': 'ensure'},\n{'word': '连贯性', 'pinyin': 'lián guàn xìng', 'trans': 'coherence'}]",
        "trans": "Recent advancements in image relighting models have made consistent lighting effects possible. However, video relighting still lags behind, primarily due to the high training costs and the lack of diverse, high-quality video relighting datasets. Applying image relighting models frame-by-frame can result in inconsistent light sources and appearances, causing flickering in the generated videos. We propose Light-A-Video, a training-free video relighting method. It enhances lighting consistency through a consistent lighting attention module and a progressive light blending strategy, ensuring temporal coherence in the video.",
        "update_ts": "2025-02-13 09:11"
    }
}