{
    "date": {
        "ru": "17 —Å–µ–Ω—Ç—è–±—Ä—è",
        "en": "September 17",
        "zh": "9Êúà17Êó•"
    },
    "time_utc": "2025-09-17 08:15",
    "weekday": 2,
    "issue_id": 5935,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.13312",
            "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research",
            "url": "https://huggingface.co/papers/2509.13312",
            "abstract": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.  \t\t\t\t\tAI-generated summary \t\t\t\t This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents must synthesize vast web-scale information into insightful reports. Current approaches are plagued by dual-fold limitations: static research pipelines that decouple planning from evidence acquisition and one-shot generation paradigms that easily suffer from long-context failure issues like \"loss in the middle\" and hallucinations. To address these challenges, we introduce WebWeaver, a novel dual-agent framework that emulates the human research process. The planner operates in a dynamic cycle, iteratively interleaving evidence acquisition with outline optimization to produce a comprehensive, source-grounded outline linking to a memory bank of evidence. The writer then executes a hierarchical retrieval and writing process, composing the report section by section. By performing targeted retrieval of only the necessary evidence from the memory bank for each part, it effectively mitigates long-context issues. Our framework establishes a new state-of-the-art across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym. These results validate our human-centric, iterative methodology, demonstrating that adaptive planning and focused synthesis are crucial for producing high-quality, reliable, and well-structured reports.",
            "score": 41,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "7c9823f6fb958040",
            "authors": [
                "Zijian Li",
                "Xin Guan",
                "Bo Zhang",
                "Shen Huang",
                "Houquan Zhou",
                "Shaopeng Lai",
                "Ming Yan",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jun Zhang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13312.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#hallucinations",
                    "#long_context",
                    "#multimodal",
                    "#agents"
                ],
                "emoji": "üï∏Ô∏è",
                "ru": {
                    "title": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç WebWeaver - –¥–≤—É—Ö–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –≥–ª—É–±–æ–∫–æ–≥–æ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –ü–µ—Ä–≤—ã–π –∞–≥–µ–Ω—Ç (–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫) –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —Å–æ–±–∏—Ä–∞–µ—Ç –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–ª–∞–Ω, —Å–æ–∑–¥–∞–≤–∞—è –ø–æ–¥—Ä–æ–±–Ω—ã–π –ø–ª–∞–Ω —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –±–∞–Ω–∫ –¥–∞–Ω–Ω—ã—Ö. –í—Ç–æ—Ä–æ–π –∞–≥–µ–Ω—Ç (–ø–∏—Å–∞—Ç–µ–ª—å) –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –Ω–∞–ø–∏—Å–∞–Ω–∏—è, —Å–æ—Å—Ç–∞–≤–ª—è—è –æ—Ç—á–µ—Ç –ø–æ —á–∞—Å—Ç—è–º. –¢–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º–∏. WebWeaver –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –Ω–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –≥–ª—É–±–æ–∫–æ–≥–æ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."
                },
                "en": {
                    "title": "WebWeaver: Revolutionizing AI Research with Adaptive Planning and Focused Synthesis",
                    "desc": "This paper presents WebWeaver, a dual-agent framework designed to tackle open-ended deep research (OEDR) challenges in AI. It combines adaptive planning with focused synthesis to create high-quality reports by mimicking the human research process. The framework features a planner that dynamically interleaves evidence gathering with outline optimization, ensuring a comprehensive and reliable report structure. By using targeted retrieval from a memory bank, WebWeaver effectively addresses common issues like long-context failures and hallucinations, setting a new standard in OEDR performance."
                },
                "zh": {
                    "title": "WebWeaverÔºö‰∫∫Êú¨Á†îÁ©∂ÁöÑÊñ∞ÊñπÊ≥ï",
                    "desc": "WebWeaverÊòØ‰∏Ä‰∏™Âèå‰ª£ÁêÜÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥ÂºÄÊîæÂºèÊ∑±Â∫¶Á†îÁ©∂ÁöÑÊåëÊàò„ÄÇÂÆÉÈÄöËøáÂä®ÊÄÅËßÑÂàíÂíåËÅöÁÑ¶ÂêàÊàêÔºåÁîüÊàêÈ´òË¥®Èáè„ÄÅÂèØÈù†ÁöÑÁ†îÁ©∂Êä•Âëä„ÄÇËØ•Ê°ÜÊû∂Ê®°Êãü‰∫∫Á±ªÁ†îÁ©∂ËøáÁ®ãÔºåËßÑÂàíËÄÖÂú®Âä®ÊÄÅÂæ™ÁéØ‰∏≠‰ºòÂåñÂ§ßÁ∫≤Âπ∂Ëé∑ÂèñËØÅÊçÆÔºå‰ΩúÂÆ∂ÂàôÈÄêÊ≠•Êí∞ÂÜôÊä•Âëä„ÄÇWebWeaverÂú®Â§ö‰∏™ÂºÄÊîæÂºèÊ∑±Â∫¶Á†îÁ©∂Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÈ™åËØÅ‰∫ÜÂÖ∂‰∫∫Êú¨„ÄÅËø≠‰ª£ÁöÑÊñπÊ≥ïËÆ∫„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13310",
            "title": "Scaling Agents via Continual Pre-training",
            "url": "https://huggingface.co/papers/2509.13310",
            "abstract": "AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.  \t\t\t\t\tAI-generated summary \t\t\t\t Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.",
            "score": 38,
            "issue_id": 5932,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "b5b1de97f689d595",
            "authors": [
                "Liangcai Su",
                "Zhen Zhang",
                "Guangyu Li",
                "Zhuo Chen",
                "Chenxi Wang",
                "Maojia Song",
                "Xinyu Wang",
                "Kuan Li",
                "Jialong Wu",
                "Xuanzhong Chen",
                "Zile Qiao",
                "Zhongwang Zhang",
                "Huifeng Yin",
                "Shihao Cai",
                "Runnan Fang",
                "Zhengwei Tao",
                "Wenbiao Yin",
                "Chenxiong Qian",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13310.jpg",
            "data": {
                "categories": [
                    "#agents",
                    "#optimization",
                    "#training",
                    "#agi"
                ],
                "emoji": "ü§ñ",
                "ru": {
                    "title": "AgentFounder: –Ω–æ–≤—ã–π —à–∞–≥ –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
                    "desc": "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ AgentFounder - –º–æ–¥–µ–ª—å –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—é—â—É—é –ê–≥–µ–Ω—Ç–Ω–æ–µ –ö–æ–Ω—Ç–∏–Ω—É–∞–ª—å–Ω–æ–µ –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ (Agentic CPT). –≠—Ç–∞ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã. AgentFounder —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö. –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑–∞–ª–∞ –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ 10 –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö, –≤–∫–ª—é—á–∞—è BrowseComp –∏ HLE."
                },
                "en": {
                    "title": "Empowering Agents with Continual Learning for Superior Performance",
                    "desc": "The paper introduces AgentFounder, a deep research agent model that utilizes Agentic Continual Pre-training (Agentic CPT) to enhance performance in agentic tasks. Traditional post-training methods struggle with agentic tasks due to the lack of specialized foundational models, leading to optimization challenges. By implementing Agentic CPT, AgentFounder effectively learns diverse agentic behaviors while aligning with expert demonstrations. The model demonstrates superior performance on multiple benchmarks, showcasing its advanced tool-use capabilities and problem-solving skills."
                },
                "zh": {
                    "title": "AgentFounderÔºö‰ª£ÁêÜ‰ªªÂä°ÁöÑÊúÄ‰ºòËß£",
                    "desc": "Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÂêç‰∏∫AgentFounderÁöÑÊ∑±Â∫¶Á†îÁ©∂‰ª£ÁêÜÊ®°ÂûãÔºåËØ•Ê®°ÂûãÁªìÂêà‰∫Ü‰ª£ÁêÜÊåÅÁª≠È¢ÑËÆ≠ÁªÉÔºàAgentic Continual Pre-trainingÔºâÔºåÂú®‰ª£ÁêÜ‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂº∫Â§ßÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ËÉΩÂäõ„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ∑≤ÁªèÂèëÂ±ïÊàê‰∏∫ËÉΩÂ§üËá™‰∏ª‰ΩøÁî®Â∑•ÂÖ∑ÂíåËøõË°åÂ§öÊ≠•È™§Êé®ÁêÜÁöÑ‰ª£ÁêÜÁ≥ªÁªüÔºå‰ΩÜÂú®‰ª£ÁêÜ‰ªªÂä°‰∏≠ÔºåÂü∫‰∫éÈÄöÁî®Âü∫Á°ÄÊ®°ÂûãÁöÑÂêéËÆ≠ÁªÉÊñπÊ≥ïË°®Áé∞‰∏ç‰Ω≥„ÄÇÊàë‰ª¨ÂèëÁé∞ÈóÆÈ¢òÁöÑÊ†πÊ∫êÂú®‰∫éÁº∫‰πèÂº∫Â§ßÁöÑ‰ª£ÁêÜÂü∫Á°ÄÊ®°ÂûãÔºåÂØºËá¥Ê®°ÂûãÂú®ÂêéËÆ≠ÁªÉËøáÁ®ã‰∏≠ÈúÄË¶ÅÂêåÊó∂Â≠¶‰π†Â§öÊ†∑ÁöÑ‰ª£ÁêÜË°å‰∏∫Âπ∂‰∏é‰∏ìÂÆ∂Á§∫ËåÉÂØπÈΩêÔºå‰ªéËÄå‰∫ßÁîüÂü∫Êú¨ÁöÑ‰ºòÂåñÁüõÁõæ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨È¶ñÊ¨°ÊèêÂá∫Â∞Ü‰ª£ÁêÜÊåÅÁª≠È¢ÑËÆ≠ÁªÉÁ∫≥ÂÖ•Ê∑±Â∫¶Á†îÁ©∂‰ª£ÁêÜÁöÑËÆ≠ÁªÉÊµÅÁ®ãÔºå‰ª•ÊûÑÂª∫Âº∫Â§ßÁöÑ‰ª£ÁêÜÂü∫Á°ÄÊ®°Âûã„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13305",
            "title": "WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic\n  Data and Scalable Reinforcement Learning",
            "url": "https://huggingface.co/papers/2509.13305",
            "abstract": "WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.  \t\t\t\t\tAI-generated summary \t\t\t\t Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.",
            "score": 33,
            "issue_id": 5932,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "e7b960c7dacc4ae5",
            "authors": [
                "Kuan Li",
                "Zhongwang Zhang",
                "Huifeng Yin",
                "Rui Ye",
                "Yida Zhao",
                "Liwen Zhang",
                "Litu Ou",
                "Dingchu Zhang",
                "Xixi Wu",
                "Jialong Wu",
                "Xinyu Wang",
                "Zile Qiao",
                "Zhen Zhang",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13305.jpg",
            "data": {
                "categories": [
                    "#rl",
                    "#reasoning",
                    "#training",
                    "#optimization",
                    "#open_source",
                    "#agents",
                    "#agi"
                ],
                "emoji": "üß≠",
                "ru": {
                    "title": "WebSailor: –æ—Ç–∫—Ä—ã—Ç—ã–π –ø—É—Ç—å –∫ —Å–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–º—É –ø–æ–∏—Å–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                    "desc": "WebSailor - —ç—Ç–æ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º –≤ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –û–Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Å–Ω–∏–∂–µ–Ω–∏–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏, —á—Ç–æ —Ä–∞–Ω–µ–µ –±—ã–ª–æ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–ø—Ä–∏–µ—Ç–∞—Ä–Ω—ã–º –∞–≥–µ–Ω—Ç–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –≤–∫–ª—é—á–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á —Å –≤—ã—Å–æ–∫–æ–π –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å—é –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º DUPO. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ WebSailor –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –≤—Å–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ –∞–≥–µ–Ω—Ç—ã –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –ø—Ä–æ–ø—Ä–∏–µ—Ç–∞—Ä–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏."
                },
                "en": {
                    "title": "Closing the Gap: Empowering Open-Source Models with WebSailor",
                    "desc": "WebSailor is a new method that improves open-source machine learning models by reducing uncertainty in their decision-making processes. This technique allows these models to perform as well as proprietary systems in challenging tasks that require searching for information. The methodology includes creating difficult tasks that test the models' abilities and using a special training algorithm called Duplicating Sampling Policy Optimization (DUPO). By implementing these strategies, WebSailor helps open-source models achieve better performance in complex scenarios, bridging the gap with advanced proprietary agents."
                },
                "zh": {
                    "title": "WebSailorÔºöÁº©Â∞èÂºÄÊ∫ê‰∏é‰∏ìÊúâÊ®°ÂûãÁöÑËÉΩÂäõÂ∑ÆË∑ù",
                    "desc": "WebSailorÊòØ‰∏ÄÁßçÂêéËÆ≠ÁªÉÊñπÊ≥ïÔºåÊó®Âú®ÈÄöËøáÁ≥ªÁªüÊÄßÂáèÂ∞ë‰∏çÁ°ÆÂÆöÊÄßÊù•Â¢ûÂº∫ÂºÄÊ∫êÊ®°ÂûãÁöÑÊÄßËÉΩÔºå‰ΩøÂÖ∂Âú®Â§çÊùÇÁöÑ‰ø°ÊÅØÊ£ÄÁ¥¢‰ªªÂä°‰∏≠‰∏é‰∏ìÊúâ‰ª£ÁêÜÁöÑË°®Áé∞Áõ∏ÂåπÈÖç„ÄÇËØ•ÊñπÊ≥ïÁöÑÊàêÂäü‰æùËµñ‰∫é‰∏ÄÁßçÂ§çÊùÇÁöÑÊé®ÁêÜÊ®°ÂºèÔºåËøôÁßçÊ®°ÂºèÂú®ÂºÄÊ∫êÊ®°Âûã‰∏≠Áº∫Â§±ÔºåÂç≥Âú®ÂπøÈòîÁöÑ‰ø°ÊÅØÁéØÂ¢É‰∏≠Á≥ªÁªüÊÄßÂú∞ÂáèÂ∞ëÊûÅÁ´Ø‰∏çÁ°ÆÂÆöÊÄßÁöÑËÉΩÂäõ„ÄÇWebSailorÈÄöËøáÁªìÊûÑÂåñÈááÊ†∑Âíå‰ø°ÊÅØÊ®°Á≥äÂåñÁîüÊàêÊñ∞È¢ñÁöÑÈ´ò‰∏çÁ°ÆÂÆöÊÄß‰ªªÂä°ÔºåÂπ∂ÁªìÂêàÈ´òÊïàÁöÑ‰ª£ÁêÜÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÁÆóÊ≥ïÔºåÊòæËëóÊèêÂçá‰∫ÜÂºÄÊ∫ê‰ª£ÁêÜÂú®Â§çÊùÇ‰ø°ÊÅØÊ£ÄÁ¥¢‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇÊúÄÁªàÔºåWebSailorÊàêÂäüÁº©Â∞è‰∫ÜÂºÄÊ∫êÊ®°Âûã‰∏é‰∏ìÊúâÁ≥ªÁªü‰πãÈó¥ÁöÑËÉΩÂäõÂ∑ÆË∑ù„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13311",
            "title": "Towards General Agentic Intelligence via Environment Scaling",
            "url": "https://huggingface.co/papers/2509.13311",
            "abstract": "A scalable framework and two-phase fine-tuning strategy enhance function-calling capabilities of agents in diverse environments, improving performance on agentic benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practical, real-world applications. Diverse real-world APIs demand precise, robust function-calling intelligence, which needs agents to develop these capabilities through interaction in varied environments. The breadth of function-calling competence is closely tied to the diversity of environments in which agents are trained. In this work, we scale up environments as a step towards advancing general agentic intelligence. This gives rise to two central challenges: (i) how to scale environments in a principled manner, and (ii) how to effectively train agentic capabilities from experiences derived through interactions with these environments. To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated, systematically broadening the space of function-calling scenarios. We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts. Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models.",
            "score": 32,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "c97e7569e926b9a7",
            "authors": [
                "Runnan Fang",
                "Shihao Cai",
                "Baixuan Li",
                "Jialong Wu",
                "Guangyu Li",
                "Wenbiao Yin",
                "Xinyu Wang",
                "Xiaobin Wang",
                "Liangcai Su",
                "Zhen Zhang",
                "Shibin Wu",
                "Zhengwei Tao",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13311.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#agi",
                    "#training",
                    "#agents"
                ],
                "emoji": "ü§ñ",
                "ru": {
                    "title": "–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–π –≤ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—É—é —Å–∏—Å—Ç–µ–º—É –∏ –¥–≤—É—Ö—Ñ–∞–∑–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–æ–æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –∞–≥–µ–Ω—Ç–æ–≤ –∫ –≤—ã–∑–æ–≤—É —Ñ—É–Ω–∫—Ü–∏–π –≤ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –ê–≤—Ç–æ—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—é—â–∏–π –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ã–µ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã, —Ä–∞—Å—à–∏—Ä—è—è —Å–ø–µ–∫—Ç—Ä —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–π. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–±—É—á–µ–Ω–∏—è —Å–Ω–∞—á–∞–ª–∞ –Ω–∞–¥–µ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–æ–≤ –±–∞–∑–æ–≤—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏, –∞ –∑–∞—Ç–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Ö –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –ø–æ–∫–∞–∑–∞–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–µ–π –∫ –≤—ã–∑–æ–≤—É —Ñ—É–Ω–∫—Ü–∏–π."
                },
                "en": {
                    "title": "Scaling Agentic Intelligence for Enhanced Function-Calling",
                    "desc": "This paper presents a scalable framework and a two-phase fine-tuning strategy to improve the function-calling abilities of agents in various environments. The authors emphasize that training agents in diverse settings is crucial for developing robust function-calling intelligence, which is essential for real-world applications of Large Language Models. They propose a method to systematically create varied simulated environments and a training approach that first builds basic agentic skills before refining them for specific tasks. Experimental results show that their model, AgentScaler, outperforms existing benchmarks in function-calling tasks, indicating significant advancements in agentic intelligence."
                },
                "zh": {
                    "title": "ÊèêÂçáÊô∫ËÉΩ‰ΩìÂáΩÊï∞Ë∞ÉÁî®ËÉΩÂäõÁöÑÂèØÊâ©Â±ïÊ°ÜÊû∂",
                    "desc": "Êú¨ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂèØÊâ©Â±ïÁöÑÊ°ÜÊû∂Âíå‰∏§Èò∂ÊÆµÂæÆË∞ÉÁ≠ñÁï•Ôºå‰ª•Â¢ûÂº∫Êô∫ËÉΩ‰ΩìÂú®Â§öÊ†∑ÂåñÁéØÂ¢É‰∏≠ÁöÑÂáΩÊï∞Ë∞ÉÁî®ËÉΩÂäõ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÊô∫ËÉΩ‰ΩìÁöÑÂáΩÊï∞Ë∞ÉÁî®ËÉΩÂäõ‰∏éÂÖ∂ËÆ≠ÁªÉÁéØÂ¢ÉÁöÑÂ§öÊ†∑ÊÄßÂØÜÂàáÁõ∏ÂÖ≥„ÄÇÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Ëá™Âä®ÊûÑÂª∫ÂºÇÊûÑÁéØÂ¢ÉÁöÑÊ°ÜÊû∂ÔºåÁ≥ªÁªüÊÄßÂú∞Êâ©Â±ï‰∫ÜÂáΩÊï∞Ë∞ÉÁî®Âú∫ÊôØÁöÑÁ©∫Èó¥„ÄÇÊ≠§Â§ñÔºåÈÄöËøá‰∏§Èò∂ÊÆµÁöÑÂæÆË∞ÉÁ≠ñÁï•ÔºåÊàë‰ª¨È¶ñÂÖàËµã‰∫àÊô∫ËÉΩ‰ΩìÂü∫Êú¨ËÉΩÂäõÔºåÁÑ∂ÂêéÈíàÂØπÁâπÂÆöÈ¢ÜÂüüËøõË°å‰∏ì‰∏öÂåñËÆ≠ÁªÉÔºåÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13309",
            "title": "WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon\n  Agents",
            "url": "https://huggingface.co/papers/2509.13309",
            "abstract": "WebResearcher, a deep-research framework, enhances AI agents' knowledge synthesis by reformulating research as a Markov Decision Process and using a scalable data synthesis engine, achieving superior performance across benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in deep-research systems have demonstrated the potential for AI agents to autonomously discover and synthesize knowledge from external sources. In this paper, we introduce WebResearcher, a novel framework for building such agents through two key components: (1) WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, where agents periodically consolidate findings into evolving reports while maintaining focused workspaces, overcoming the context suffocation and noise contamination that plague existing mono-contextual approaches; and (2) WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation, enabling systematic creation of research tasks that bridge the gap between passive knowledge recall and active knowledge construction. Notably, we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods. Furthermore, our paradigm naturally scales through parallel thinking, enabling concurrent multi-agent exploration for more comprehensive conclusions. Extensive experiments across 6 challenging benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, even surpassing frontier proprietary systems.",
            "score": 31,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "f064e62f63131809",
            "authors": [
                "Zile Qiao",
                "Guoxin Chen",
                "Xuanzhong Chen",
                "Donglei Yu",
                "Wenbiao Yin",
                "Xinyu Wang",
                "Zhen Zhang",
                "Baixuan Li",
                "Huifeng Yin",
                "Kuan Li",
                "Rui Min",
                "Minpeng Liao",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13309.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#science",
                    "#dataset",
                    "#training",
                    "#agents",
                    "#transfer_learning"
                ],
                "emoji": "üï∏Ô∏è",
                "ru": {
                    "title": "WebResearcher: –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –ò–ò",
                    "desc": "WebResearcher - —ç—Ç–æ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è. –û–Ω–∞ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∫–∞–∫ –º–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã–π –º–µ—Ö–∞–Ω–∏–∑–º —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã—Ö. WebResearcher –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ —Å–∏—Å—Ç–µ–º—É WebFrontier –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ WebResearcher –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø–æ —Ä—è–¥—É —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤."
                },
                "en": {
                    "title": "Revolutionizing AI Knowledge Synthesis with WebResearcher",
                    "desc": "WebResearcher is a deep-research framework that improves how AI agents gather and synthesize knowledge by treating research as a Markov Decision Process. It features an iterative approach where agents create evolving reports while managing focused workspaces, which helps avoid distractions from irrelevant information. Additionally, the framework includes WebFrontier, a data synthesis engine that produces high-quality training data, enhancing the agents' ability to construct knowledge actively. Experiments show that WebResearcher outperforms existing systems across multiple benchmarks, demonstrating its effectiveness in autonomous knowledge discovery."
                },
                "zh": {
                    "title": "WebResearcherÔºöÊèêÂçáAIÁü•ËØÜÁªºÂêàÁöÑÊñ∞Ê°ÜÊû∂",
                    "desc": "WebResearcherÊòØ‰∏Ä‰∏™Ê∑±Â∫¶Á†îÁ©∂Ê°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜÁ†îÁ©∂ÈáçÊñ∞Ë°®Ëø∞‰∏∫È©¨Â∞îÂèØÂ§´ÂÜ≥Á≠ñËøáÁ®ãÔºåÂ¢ûÂº∫‰∫Ü‰∫∫Â∑•Êô∫ËÉΩ‰ª£ÁêÜÁöÑÁü•ËØÜÁªºÂêàËÉΩÂäõ„ÄÇËØ•Ê°ÜÊû∂ÂåÖÂê´‰∏§‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂Ôºö‰∏Ä‰∏™ÊòØËø≠‰ª£Ê∑±Â∫¶Á†îÁ©∂ËåÉÂºèÔºåËÉΩÂ§üÂÆöÊúüÊï¥ÂêàÂèëÁé∞Âπ∂ÁîüÊàê‰∏çÊñ≠ÊºîÂèòÁöÑÊä•ÂëäÔºåÂÖãÊúç‰∫ÜÁé∞ÊúâÂçï‰∏Ä‰∏ä‰∏ãÊñáÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÔºõÂè¶‰∏Ä‰∏™ÊòØÂèØÊâ©Â±ïÁöÑÊï∞ÊçÆÂêàÊàêÂºïÊìéÔºåËÉΩÂ§üÁîüÊàêÈ´òË¥®ÈáèÁöÑËÆ≠ÁªÉÊï∞ÊçÆÔºå‰øÉËøõ‰∏ªÂä®Áü•ËØÜÊûÑÂª∫„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåWebResearcherÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜËÆ∏Â§öÂâçÊ≤øÁöÑ‰∏ìÊúâÁ≥ªÁªü„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13313",
            "title": "ReSum: Unlocking Long-Horizon Search Intelligence via Context\n  Summarization",
            "url": "https://huggingface.co/papers/2509.13313",
            "abstract": "ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\\% over ReAct, with further gains of up to 8.2\\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\\% Pass@1 on BrowseComp-zh and 18.3\\% on BrowseComp-en, surpassing existing open-source web agents.",
            "score": 27,
            "issue_id": 5932,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "3850ff93d847cdb9",
            "authors": [
                "Xixi Wu",
                "Kuan Li",
                "Yida Zhao",
                "Liwen Zhang",
                "Litu Ou",
                "Huifeng Yin",
                "Zhongwang Zhang",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Minhao Cheng",
                "Shuai Wang",
                "Hong Cheng",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13313.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#training",
                    "#optimization",
                    "#long_context",
                    "#agents"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "ReSum: —Ä–∞–∑–¥–≤–∏–≥–∞—è –≥—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM",
                    "desc": "–í —Å—Ç–∞—Ç—å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ ReSum, –∫–æ—Ç–æ—Ä–∞—è —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ–±-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –∑–∞–¥–∞—á–∞—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –æ–±—à–∏—Ä–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π. ReSum –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ –ø—É—Ç–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º –ø—Ä–æ–≤–æ–¥–∏—Ç—å –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ. –ê–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç ReSum-GRPO - –º–µ—Ç–æ–¥ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–∞—Ä–∞–¥–∏–≥–º—ã, –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—â–∏–π GRPO —Å —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ ReSum –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É ReAct –Ω–∞ 4.5% –≤ —Å—Ä–µ–¥–Ω–µ–º, –∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è —Å ReSum-GRPO —É–ª—É—á—à–µ–Ω–∏–µ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç 8.2%."
                },
                "en": {
                    "title": "ReSum: Breaking Context Barriers for Smarter Web Agents",
                    "desc": "ReSum is a new approach that improves the performance of web agents on complex knowledge tasks by addressing the limitations of context windows found in previous methods like ReAct. It allows agents to summarize their interactions periodically, which helps them keep track of important information without being constrained by limited context. This method enables agents to explore more effectively, even when dealing with complicated queries that involve many entities and relationships. The results show that ReSum significantly enhances performance, achieving better accuracy with fewer training samples compared to existing models."
                },
                "zh": {
                    "title": "ReSumÔºöÁ™ÅÁ†¥‰∏ä‰∏ãÊñáÈôêÂà∂ÁöÑÊô∫ËÉΩ‰ΩìÊñ∞ÊñπÊ≥ï",
                    "desc": "ReSumÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÂë®ÊúüÊÄß‰∏ä‰∏ãÊñáÊëòË¶ÅÊñπÊ≥ïÔºåÊó®Âú®ÊèêÂçáÁΩëÁªúÊô∫ËÉΩ‰ΩìÂú®Áü•ËØÜÂØÜÈõÜÂûã‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇ‰º†ÁªüÁöÑReActÊñπÊ≥ïÂèóÂà∞‰∏ä‰∏ãÊñáÁ™óÂè£ÈôêÂà∂ÁöÑÂΩ±ÂìçÔºåÈöæ‰ª•Â§ÑÁêÜÂ§çÊùÇÊü•ËØ¢„ÄÇReSumÈÄöËøáÂ∞Ü‰∏çÊñ≠Â¢ûÈïøÁöÑ‰∫§‰∫íÂéÜÂè≤ËΩ¨Êç¢‰∏∫Á¥ßÂáëÁöÑÊé®ÁêÜÁä∂ÊÄÅÔºåÂÖãÊúç‰∫ÜËøô‰∫õÈôêÂà∂Ôºå‰ΩøÊô∫ËÉΩ‰ΩìËÉΩÂ§üÂú®‰∏çÂèó‰∏ä‰∏ãÊñáÁ∫¶ÊùüÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÊó†ÈôêÊé¢Á¥¢„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåReSumÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Áõ∏ËæÉ‰∫éReActÂπ≥ÂùáÊèêÈ´ò‰∫Ü4.5%ÁöÑÊÄßËÉΩÔºåÁªèËøáReSum-GRPOËÆ≠ÁªÉÂêéÔºåÊÄßËÉΩÊèêÂçáÂèØËææ8.2%„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13232",
            "title": "Single-stream Policy Optimization",
            "url": "https://huggingface.co/papers/2509.13232",
            "abstract": "Single-stream Policy Optimization (SPO) improves policy-gradient training for Large Language Models by eliminating group-based issues and providing a stable, low-variance learning signal, leading to better performance and efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t We revisit policy-gradient optimization for Large Language Models (LLMs) from a single-stream perspective. Prevailing group-based methods like GRPO reduce variance with on-the-fly baselines but suffer from critical flaws: frequent degenerate groups erase learning signals, and synchronization barriers hinder scalability. We introduce Single-stream Policy Optimization (SPO), which eliminates these issues by design. SPO replaces per-group baselines with a persistent, KL-adaptive value tracker and normalizes advantages globally across the batch, providing a stable, low-variance learning signal for every sample. Being group-free, SPO enables higher throughput and scales effectively in long-horizon or tool-integrated settings where generation times vary. Furthermore, the persistent value tracker naturally enables an adaptive curriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO converges more smoothly and attains higher accuracy than GRPO, while eliminating computation wasted on degenerate groups. Ablation studies confirm that SPO's gains stem from its principled approach to baseline estimation and advantage normalization, offering a more robust and efficient path for LLM reasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the average maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial absolute point gains on challenging datasets, including +7.3 pp on BRUMO 25, +4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain in pass@k across the evaluated k values. SPO's success challenges the prevailing trend of adding incidental complexity to RL algorithms, highlighting a path where fundamental principles, not architectural workarounds, drive the next wave of progress in LLM reasoning.",
            "score": 18,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "ecea2ef463a2c2ff",
            "authors": [
                "Zhongwen Xu",
                "Zihan Ding"
            ],
            "affiliations": [
                "Tencent"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13232.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "üöÄ",
                "ru": {
                    "title": "SPO: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º Single-stream Policy Optimization (SPO). SPO —É—Å—Ç—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≥—Ä—É–ø–ø–æ–≤—ã—Ö –º–µ—Ç–æ–¥–æ–≤, —Ç–∞–∫–∏–µ –∫–∞–∫ GRPO, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –æ–±—É—á–µ–Ω–∏—è —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π. –ú–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π KL-–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –∑–Ω–∞—á–µ–Ω–∏–π –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ –ø–æ –≤—Å–µ–º—É –±–∞—Ç—á—É. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å Qwen3-8B –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ SPO –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—É—é —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –∏ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å GRPO."
                },
                "en": {
                    "title": "Streamlining Learning for Better Language Model Performance",
                    "desc": "Single-stream Policy Optimization (SPO) enhances the training of Large Language Models (LLMs) by addressing the limitations of group-based policy-gradient methods. It eliminates issues like degenerate groups that disrupt learning signals and synchronization barriers that limit scalability. By using a persistent, KL-adaptive value tracker and normalizing advantages globally, SPO provides a stable and low-variance learning signal for each sample. This approach not only improves performance and efficiency but also supports adaptive curriculum learning through prioritized sampling, leading to significant gains in accuracy on challenging benchmarks."
                },
                "zh": {
                    "title": "ÂçïÊµÅÁ≠ñÁï•‰ºòÂåñÔºöÊèêÂçáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ≠ÁªÉÊïàÁéá",
                    "desc": "ÂçïÊµÅÁ≠ñÁï•‰ºòÂåñÔºàSPOÔºâÈÄöËøáÊ∂àÈô§Âü∫‰∫éÁªÑÁöÑÊñπÊ≥ïÈóÆÈ¢òÔºåÊîπËøõ‰∫ÜÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁ≠ñÁï•Ê¢ØÂ∫¶ËÆ≠ÁªÉ„ÄÇ‰º†ÁªüÁöÑÂü∫‰∫éÁªÑÁöÑÊñπÊ≥ïËôΩÁÑ∂ÂèØ‰ª•Èôç‰ΩéÊñπÂ∑ÆÔºå‰ΩÜÂ≠òÂú®Â≠¶‰π†‰ø°Âè∑‰∏¢Â§±ÂíåÂêåÊ≠•ÈöúÁ¢çÁ≠âÂÖ≥ÈîÆÁº∫Èô∑„ÄÇSPOÈÄöËøáÂºïÂÖ•ÊåÅ‰πÖÁöÑKLËá™ÈÄÇÂ∫î‰ª∑ÂÄºËøΩË∏™Âô®ÔºåÊèê‰æõ‰∫ÜÁ®≥ÂÆö„ÄÅ‰ΩéÊñπÂ∑ÆÁöÑÂ≠¶‰π†‰ø°Âè∑Ôºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊÄßËÉΩÂíåÊïàÁéá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSPOÂú®Â§ö‰∏™Êï∞Â≠¶Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºò‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÈïøÊó∂Èó¥Ë∑®Â∫¶ÊàñÂ∑•ÂÖ∑ÈõÜÊàêÁéØÂ¢É‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.12815",
            "title": "Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset\n  Generation",
            "url": "https://huggingface.co/papers/2509.12815",
            "abstract": "Hunyuan3D Studio automates 3D asset creation using AI, integrating neural modules to transform concept images or text into high-quality, game-ready 3D models with optimized geometry and PBR textures.  \t\t\t\t\tAI-generated summary \t\t\t\t The creation of high-quality 3D assets, a cornerstone of modern game development, has long been characterized by labor-intensive and specialized workflows. This paper presents Hunyuan3D Studio, an end-to-end AI-powered content creation platform designed to revolutionize the game production pipeline by automating and streamlining the generation of game-ready 3D assets. At its core, Hunyuan3D Studio integrates a suite of advanced neural modules (such as Part-level 3D Generation, Polygon Generation, Semantic UV, etc.) into a cohesive and user-friendly system. This unified framework allows for the rapid transformation of a single concept image or textual description into a fully-realized, production-quality 3D model complete with optimized geometry and high-fidelity PBR textures. We demonstrate that assets generated by Hunyuan3D Studio are not only visually compelling but also adhere to the stringent technical requirements of contemporary game engines, significantly reducing iteration time and lowering the barrier to entry for 3D content creation. By providing a seamless bridge from creative intent to technical asset, Hunyuan3D Studio represents a significant leap forward for AI-assisted workflows in game development and interactive media.",
            "score": 11,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "3561c2f1ae6a316c",
            "authors": [
                "Biwen Lei",
                "Yang Li",
                "Xinhai Liu",
                "Shuhui Yang",
                "Lixin Xu",
                "Jingwei Huang",
                "Ruining Tang",
                "Haohan Weng",
                "Jian Liu",
                "Jing Xu",
                "Zhen Zhou",
                "Yiling Zhu",
                "Jiankai Xing",
                "Jiachen Xu",
                "Changfeng Ma",
                "Xinhao Yan",
                "Yunhan Yang",
                "Chunshi Wang",
                "Duoteng Xu",
                "Xueqi Ma",
                "Yuguang Chen",
                "Jing Li",
                "Mingxin Yang",
                "Sheng Zhang",
                "Yifei Feng",
                "Xin Huang",
                "Di Luo",
                "Zebin He",
                "Puhua Jiang",
                "Changrong Hu",
                "Zihan Qin",
                "Shiwei Miao",
                "Haolin Liu",
                "Yunfei Zhao",
                "Zeqiang Lai",
                "Qingxiang Lin",
                "Zibo Zhao",
                "Kunhong Li",
                "Xianghui Yang",
                "Huiwen Shi",
                "Xin Yang",
                "Yuxuan Wang",
                "Zebin Yao",
                "Yihang Lian",
                "Sicong Liu",
                "Xintong Han",
                "Wangchen Qin",
                "Caisheng Ouyang",
                "Jianyin Liu",
                "Tianwen Yuan",
                "Shuai Jiang",
                "Hong Duan",
                "Yanqi Niu",
                "Wencong Lin",
                "Yifu Sun",
                "Shirui Huang",
                "Lin Niu",
                "Gu Gong",
                "Guojian Xiao",
                "Bojian Zheng",
                "Xiang Yuan",
                "Qi Chen",
                "Jie Xiao",
                "Dongyang Zheng",
                "Xiaofeng Yang",
                "Kai Liu",
                "Jianchen Zhu",
                "Lifu Wang",
                "Qinglin Lu",
                "Jie Liu",
                "Liang Dong",
                "Fan Jiang",
                "Ruibin Chen",
                "Lei Wang",
                "Chao Zhang",
                "Jiaxin Lin",
                "Hao Zhang",
                "Zheng Ye",
                "Peng He",
                "Runzhou Wu",
                "Yinhe Wu",
                "Jiayao Du",
                "Jupeng Chen",
                "Xinyue Mao",
                "Dongyuan Guo",
                "Yixuan Tang",
                "Yulin Tsai",
                "Yonghao Tan",
                "Jiaao Yu",
                "Junlin Yu",
                "Keren Zhang",
                "Yifan Li",
                "Peng Chen",
                "Tian Liu",
                "Di Wang",
                "Yuhong Liu",
                "Linus",
                "Jie Jiang",
                "Zhuo Chen",
                "Chunchao Guo"
            ],
            "affiliations": [
                "Tencent Hunyuan Hunyuan3D Studio"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.12815.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#optimization",
                    "#3d"
                ],
                "emoji": "üéÆ",
                "ru": {
                    "title": "–ò–ò —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ 3D-–∞—Å—Å–µ—Ç–æ–≤ –¥–ª—è –∏–≥—Ä",
                    "desc": "Hunyuan3D Studio - —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è 3D-–∞—Å—Å–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. –°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ 3D-–º–æ–¥–µ–ª–∏, –≥–æ—Ç–æ–≤—ã–µ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ –∏–≥—Ä–∞—Ö. Hunyuan3D Studio –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—é –∏ —Å–æ–∑–¥–∞–µ—Ç PBR-—Ç–µ–∫—Å—Ç—É—Ä—ã, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å–∫–æ—Ä—è—è —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏–≥—Ä. –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ò–ò-–∞—Å—Å–∏—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."
                },
                "en": {
                    "title": "Revolutionizing 3D Asset Creation with AI",
                    "desc": "Hunyuan3D Studio is an innovative AI-powered platform that automates the creation of high-quality 3D assets for game development. It utilizes advanced neural modules to convert concept images or text into fully-realized 3D models, complete with optimized geometry and PBR textures. This system streamlines the traditionally labor-intensive process, allowing for faster production and easier access to 3D content creation. By meeting the technical standards of modern game engines, Hunyuan3D Studio enhances the efficiency of game production workflows."
                },
                "zh": {
                    "title": "Hunyuan3D StudioÔºöÊ∏∏ÊàèËµÑ‰∫ßÂàõ‰ΩúÁöÑAIÈù©ÂëΩ",
                    "desc": "Hunyuan3D Studio ÊòØ‰∏Ä‰∏™Âü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÂÜÖÂÆπÂàõ‰ΩúÂπ≥Âè∞ÔºåÊó®Âú®Ëá™Âä®ÂåñÂíåÁÆÄÂåñÊ∏∏ÊàèÂà∂‰ΩúÊµÅÁ®ã„ÄÇÂÆÉÈÄöËøáÈõÜÊàêÂÖàËøõÁöÑÁ•ûÁªèÊ®°ÂùóÔºåÂ∞ÜÊ¶ÇÂøµÂõæÂÉèÊàñÊñáÊú¨Âø´ÈÄüËΩ¨Âåñ‰∏∫È´òË¥®ÈáèÁöÑ3DÊ®°ÂûãÔºåÊ®°ÂûãÂÖ∑Â§á‰ºòÂåñÁöÑÂá†‰ΩïÂΩ¢Áä∂ÂíåÈ´ò‰øùÁúüPBRÁ∫πÁêÜ„ÄÇËØ•Âπ≥Âè∞‰∏ç‰ªÖÊèêÈ´ò‰∫Ü3DËµÑ‰∫ßÁöÑÁîüÊàêÊïàÁéáÔºåËøòÁ°Æ‰øùÁîüÊàêÁöÑËµÑ‰∫ßÁ¨¶ÂêàÁé∞‰ª£Ê∏∏ÊàèÂºïÊìéÁöÑÊäÄÊúØË¶ÅÊ±Ç„ÄÇHunyuan3D Studio ‰ª£Ë°®‰∫ÜÊ∏∏ÊàèÂºÄÂèëÂíå‰∫íÂä®Â™í‰ΩìÈ¢ÜÂüü‰∏≠AIËæÖÂä©Â∑•‰ΩúÊµÅÁ®ãÁöÑÈáçÂ§ßËøõÊ≠•„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13317",
            "title": "3D Aware Region Prompted Vision Language Model",
            "url": "https://huggingface.co/papers/2509.13317",
            "abstract": "A Spatial Region 3D (SR-3D) vision-language model unifies 2D and 3D representations by enriching 2D features with 3D positional embeddings, enabling flexible region prompting and accurate spatial reasoning across frames.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Spatial Region 3D (SR-3D) aware vision-language model that connects single-view 2D images and multi-view 3D data through a shared visual token space. SR-3D supports flexible region prompting, allowing users to annotate regions with bounding boxes, segmentation masks on any frame, or directly in 3D, without the need for exhaustive multi-frame labeling. We achieve this by enriching 2D visual features with 3D positional embeddings, which allows the 3D model to draw upon strong 2D priors for more accurate spatial reasoning across frames, even when objects of interest do not co-occur within the same view. Extensive experiments on both general 2D vision language and specialized 3D spatial benchmarks demonstrate that SR-3D achieves state-of-the-art performance, underscoring its effectiveness for unifying 2D and 3D representation space on scene understanding. Moreover, we observe applicability to in-the-wild videos without sensory 3D inputs or ground-truth 3D annotations, where SR-3D accurately infers spatial relationships and metric measurements.",
            "score": 6,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "b8172aa326bbec5e",
            "authors": [
                "An-Chieh Cheng",
                "Yang Fu",
                "Yukang Chen",
                "Zhijian Liu",
                "Xiaolong Li",
                "Subhashree Radhakrishnan",
                "Song Han",
                "Yao Lu",
                "Jan Kautz",
                "Pavlo Molchanov",
                "Hongxu Yin",
                "Xiaolong Wang",
                "Sifei Liu"
            ],
            "affiliations": [
                "MIT",
                "NVIDIA",
                "UC San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13317.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#games",
                    "#3d",
                    "#cv",
                    "#multimodal",
                    "#reasoning"
                ],
                "emoji": "üîç",
                "ru": {
                    "title": "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ 2D –∏ 3D –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞",
                    "desc": "SR-3D - —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è 2D –∏ 3D –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∞ –æ–±–æ–≥–∞—â–∞–µ—Ç 2D –ø—Ä–∏–∑–Ω–∞–∫–∏ 3D –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥–∏–±–∫–æ –∑–∞–¥–∞–≤–∞—Ç—å —Ä–µ–≥–∏–æ–Ω—ã –∏–Ω—Ç–µ—Ä–µ—Å–∞ –∏ —Ç–æ—á–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏. –ú–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ç–∫—É —Ä–µ–≥–∏–æ–Ω–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–º–∏ —Ä–∞–º–∫–∞–º–∏, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–∞—Å–∫–∞–º–∏ –∏–ª–∏ –Ω–∞–ø—Ä—è–º—É—é –≤ 3D, –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–ª–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤. SR-3D –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–∞–∫ –Ω–∞ –æ–±—â–∏—Ö –∑–∞–¥–∞—á–∞—Ö –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è, —Ç–∞–∫ –∏ –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö 3D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö."
                },
                "en": {
                    "title": "Unifying 2D and 3D for Enhanced Scene Understanding",
                    "desc": "The Spatial Region 3D (SR-3D) model integrates 2D and 3D visual data by enhancing 2D features with 3D positional information. This allows for flexible region prompting, enabling users to annotate images and 3D spaces without extensive labeling across multiple frames. By leveraging 3D embeddings, the model improves spatial reasoning, even when objects are not visible together in the same view. Experiments show that SR-3D outperforms existing methods in both 2D and 3D tasks, demonstrating its capability to understand scenes effectively, even in videos lacking 3D data."
                },
                "zh": {
                    "title": "Áªü‰∏Ä2D‰∏é3DË°®Á§∫ÁöÑÁ©∫Èó¥Âå∫Âüü3DÊ®°Âûã",
                    "desc": "Êú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÁ©∫Èó¥Âå∫Âüü3DÔºàSR-3DÔºâËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºåÂÆÉÈÄöËøáÂ∞Ü2DÁâπÂæÅ‰∏é3D‰ΩçÁΩÆÂµåÂÖ•Áõ∏ÁªìÂêàÔºåÂÆûÁé∞‰∫Ü2DÂíå3DË°®Á§∫ÁöÑÁªü‰∏Ä„ÄÇSR-3DÊîØÊåÅÁÅµÊ¥ªÁöÑÂå∫ÂüüÊèêÁ§∫ÔºåÁî®Êà∑ÂèØ‰ª•Âú®‰ªªÊÑèÂ∏ß‰∏ä‰ΩøÁî®ËæπÁïåÊ°ÜÊàñÂàÜÂâ≤Êé©Á†ÅËøõË°åÊ†áÊ≥®ÔºåËÄåÊó†ÈúÄËøõË°åÁπÅÁêêÁöÑÂ§öÂ∏ßÊ†áÊ≥®„ÄÇÈÄöËøáÂ¢ûÂº∫2DËßÜËßâÁâπÂæÅÔºåSR-3DËÉΩÂ§üÂú®‰∏çÂêåÂ∏ß‰πãÈó¥ËøõË°åÊõ¥ÂáÜÁ°ÆÁöÑÁ©∫Èó¥Êé®ÁêÜÔºåÂç≥‰ΩøÊÑüÂÖ¥Ë∂£ÁöÑÁâ©‰Ωì‰∏çÂú®Âêå‰∏ÄËßÜÂõæ‰∏≠Âá∫Áé∞„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSR-3DÂú®2DËßÜËßâËØ≠Ë®ÄÂíå3DÁ©∫Èó¥Âü∫ÂáÜÊµãËØï‰∏≠ÂùáË°®Áé∞Âá∫Ëâ≤ÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®Âú∫ÊôØÁêÜËß£‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.12603",
            "title": "EconProver: Towards More Economical Test-Time Scaling for Automated\n  Theorem Proving",
            "url": "https://huggingface.co/papers/2509.12603",
            "abstract": "Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance.",
            "score": 6,
            "issue_id": 5931,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 16",
                "zh": "9Êúà16Êó•"
            },
            "hash": "8ca0696473050199",
            "authors": [
                "Mukai Li",
                "Linfeng Song",
                "Zhenwen Liang",
                "Jiahao Xu",
                "Shansan Gong",
                "Qi Liu",
                "Haitao Mi",
                "Dong Yu"
            ],
            "affiliations": [
                "Tencent",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.12603.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#rl",
                    "#training",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ —Ç–µ–æ—Ä–µ–º: –º–µ–Ω—å—à–µ –∑–∞—Ç—Ä–∞—Ç, —Ç–∞ –∂–µ –º–æ—â–Ω–æ—Å—Ç—å",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–∞ –º–µ—Ç–æ–¥–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç –≤ –º–æ–¥–µ–ª—è—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Ç–µ–æ—Ä–µ–º (ATP) –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ü–µ—Ä–≤—ã–π –º–µ—Ç–æ–¥ - –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (CoT), —Å–Ω–∏–∂–∞—é—â–µ–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤. –í—Ç–æ—Ä–æ–π –º–µ—Ç–æ–¥ - —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ-–º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL) —Å –æ–±—É—á–∞–µ–º—ã–º–∏ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º —á–∏—Å–ª–µ –ø—Ä–æ—Ö–æ–¥–æ–≤. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ EconProver –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Å—Ä–∞–≤–Ω–∏–º–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ª–∏—à—å 12% –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤."
                },
                "en": {
                    "title": "Efficient ATP: Cutting Costs Without Cutting Performance",
                    "desc": "This paper presents two innovative methods aimed at reducing the computational costs associated with Automated Theorem Proving (ATP) models while preserving their performance. The first method, dynamic Chain-of-Thought (CoT) switching, optimizes token usage by selectively activating CoT reasoning only when necessary. The second method, Diverse parallel-scaled reinforcement learning (RL), employs trainable prefixes to improve sampling efficiency under limited passes. Through experiments, the proposed EconProver demonstrates that it can achieve similar performance to existing models while using only 12% of the computational resources, offering a more efficient approach to ATP."
                },
                "zh": {
                    "title": "Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÔºåÊèêÂçáËá™Âä®ÂÆöÁêÜËØÅÊòéÊïàÁéá",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏§ÁßçÊñπÊ≥ïÔºåÂä®ÊÄÅÈìæÂºèÊÄùÁª¥ÂàáÊç¢ÂíåÂ§öÊ†∑ÂåñÂπ∂Ë°åÁº©ÊîæÂº∫ÂåñÂ≠¶‰π†Ôºå‰ª•Èôç‰ΩéËá™Âä®ÂÆöÁêÜËØÅÊòéÔºàATPÔºâÊ®°ÂûãÁöÑËÆ°ÁÆóÊàêÊú¨ÔºåÂêåÊó∂‰øùÊåÅÊÄßËÉΩ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÁé∞ÊúâÁöÑÊµãËØïÊó∂Èó¥Áº©ÊîæÁ≠ñÁï•Âú®Êé®ÁêÜÊó∂ÂºïÂÖ•‰∫ÜÊòæËëóÁöÑËÆ°ÁÆóÂºÄÈîÄÔºåËÄå‰º†ÁªüÁöÑÊàêÊú¨ÂàÜÊûêÂæÄÂæÄÂè™ÂÖ≥Ê≥®ÈááÊ†∑Ê¨°Êï∞„ÄÇÈÄöËøáÁ≥ªÁªüÊØîËæÉ‰∏çÂêåÁöÑÁº©ÊîæÁ≠ñÁï•ÔºåÊú¨ÊñáÂ±ïÁ§∫‰∫ÜÂΩìÂâçÂºÄÊ∫êÊñπÊ≥ïÁöÑ‰ΩéÊïàÊÄßÔºåÂπ∂ÊèêÂá∫‰∫ÜÂáèÂ∞ë‰ª§Áâå‰ΩøÁî®ÂíåÈááÊ†∑Ê¨°Êï∞ÁöÑÊúâÊïàÊñπÊ°à„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑEconProverÂú®‰ªÖ‰ΩøÁî®12%ËÆ°ÁÆóÊàêÊú¨ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊÄßËÉΩ‰∏éÂü∫Á∫øÊñπÊ≥ïÁõ∏ÂΩì„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.12341",
            "title": "Exact Coset Sampling for Quantum Lattice Algorithms",
            "url": "https://huggingface.co/papers/2509.12341",
            "abstract": "A replacement for the domain-extension step in a quantum lattice algorithm uses a pair-shift difference construction to correct periodicity issues and enforce modular linear relations efficiently.  \t\t\t\t\tAI-generated summary \t\t\t\t We give a simple, fully correct, and assumption-light replacement for the contested \"domain-extension\" in Step 9 of a recent windowed-QFT lattice algorithm with complex-Gaussian windows~chen2024quantum. The published Step~9 suffers from a periodicity/support mismatch. We present a pair-shift difference construction that coherently cancels all unknown offsets, produces an exact uniform CRT-coset state over Z_{P}, and then uses the QFT to enforce the intended modular linear relation. The unitary is reversible, uses poly(log M_2) gates, and preserves the algorithm's asymptotics. Project Page: https://github.com/yifanzhang-pro/quantum-lattice.",
            "score": 3,
            "issue_id": 5930,
            "pub_date": "2025-09-15",
            "pub_date_card": {
                "ru": "15 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 15",
                "zh": "9Êúà15Êó•"
            },
            "hash": "30a8fdee577071f4",
            "authors": [
                "Yifan Zhang"
            ],
            "affiliations": [
                "Princeton University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.12341.jpg",
            "data": {
                "categories": [],
                "emoji": "üî¨",
                "ru": {
                    "title": "–£—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–≤–∞–Ω—Ç–æ–≤–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–µ—à–µ—Ç–∫–∏: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ä–µ—à–µ—Ç–∫–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∑–∞–º–µ–Ω—É –¥–ª—è —à–∞–≥–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–æ–º–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é —Ä–∞–∑–Ω–æ—Å—Ç–∏ –ø–∞—Ä–Ω—ã—Ö —Å–¥–≤–∏–≥–æ–≤. –≠—Ç–æ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å—é –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –º–æ–¥—É–ª—å–Ω—ã–µ –ª–∏–Ω–µ–π–Ω—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è. –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—Å–∏–º–ø—Ç–æ—Ç–∏–∫—É –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞."
                },
                "en": {
                    "title": "Efficiently Correcting Periodicity in Quantum Lattice Algorithms",
                    "desc": "This paper introduces a new method to replace the problematic 'domain-extension' step in a quantum lattice algorithm. The proposed solution uses a pair-shift difference construction to address issues related to periodicity and support mismatches. By coherently canceling unknown offsets, it creates a uniform CRT-coset state and applies the Quantum Fourier Transform (QFT) to maintain the desired modular linear relations. This approach is efficient, reversible, and maintains the algorithm's performance characteristics."
                },
                "zh": {
                    "title": "È´òÊïàËß£ÂÜ≥ÈáèÂ≠êÁÆóÊ≥ï‰∏≠ÁöÑÂë®ÊúüÊÄßÈóÆÈ¢ò",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊõø‰ª£ÈáèÂ≠êÊ†ºÁÆóÊ≥ï‰∏≠ÂüüÊâ©Â±ïÊ≠•È™§ÁöÑÁÆÄÂçïÊñπÊ≥ïÔºåÊó®Âú®Ëß£ÂÜ≥Âë®ÊúüÊÄßÈóÆÈ¢ò„ÄÇÊàë‰ª¨‰ΩøÁî®‰∫Ü‰∏ÄÁßçÊàêÂØπÁßª‰ΩçÂ∑ÆÊûÑÈÄ†ÔºåËÉΩÂ§üÊúâÊïàÂú∞Ê∂àÈô§Êú™Áü•ÂÅèÁßªÈáèÔºåÂπ∂ÁîüÊàê‰∏Ä‰∏™Á≤æÁ°ÆÁöÑÂùáÂåÄ‰ΩôÊï∞Á±ªÁä∂ÊÄÅ„ÄÇËØ•ÊñπÊ≥ïÈÄöËøáÈáèÂ≠êÂÇÖÈáåÂè∂ÂèòÊç¢ÔºàQFTÔºâÊù•Âº∫Âà∂ÊâßË°åÈ¢ÑÊúüÁöÑÊ®°Á∫øÊÄßÂÖ≥Á≥ªÔºåÂêåÊó∂‰øùÊåÅÁÆóÊ≥ïÁöÑÊ∏êËøëÊÄßË¥®„ÄÇÊàë‰ª¨ÁöÑÊûÑÈÄ†ÊòØÂèØÈÄÜÁöÑÔºåÂπ∂‰∏î‰ΩøÁî®‰∫ÜÂ§öÈ°πÂºèÂØπÊï∞Á∫ßÂà´ÁöÑÈó®„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.06079",
            "title": "Multimodal Reasoning for Science: Technical Report and 1st Place\n  Solution to the ICML 2025 SeePhys Challenge",
            "url": "https://huggingface.co/papers/2509.06079",
            "abstract": "A caption-assisted reasoning framework bridges visual and textual modalities, achieving top performance in multimodal reasoning tasks like SeePhys and MathVerse.  \t\t\t\t\tAI-generated summary \t\t\t\t Multimodal reasoning remains a fundamental challenge in artificial intelligence. Despite substantial advances in text-based reasoning, even state-of-the-art models such as GPT-o3 struggle to maintain strong performance in multimodal scenarios. To address this gap, we introduce a caption-assisted reasoning framework that effectively bridges visual and textual modalities. Our approach achieved 1st place in the ICML 2025 AI for Math Workshop \\& Challenge 2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we validate its generalization on the MathVerse benchmark for geometric reasoning, demonstrating the versatility of our method. Our code is publicly available at https://github.com/OpenDCAI/SciReasoner.",
            "score": 3,
            "issue_id": 5930,
            "pub_date": "2025-09-07",
            "pub_date_card": {
                "ru": "7 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 7",
                "zh": "9Êúà7Êó•"
            },
            "hash": "58d2381d40c28302",
            "authors": [
                "Hao Liang",
                "Ruitao Wu",
                "Bohan Zeng",
                "Junbo Niu",
                "Wentao Zhang",
                "Bin Dong"
            ],
            "affiliations": [
                "Beihang University",
                "Peking University",
                "Zhongguancun Academy"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.06079.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#open_source",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–ú–æ—Å—Ç –º–µ–∂–¥—É –∑—Ä–µ–Ω–∏–µ–º –∏ —è–∑—ã–∫–æ–º: –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º—É –ò–ò",
                    "desc": "–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Ç–µ–∫—Å—Ç–∞. –§—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏ SeePhys –∏ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ MathVerse –¥–ª—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –¥–∞–∂–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤—Ä–æ–¥–µ GPT-3 –≤ –∑–∞–¥–∞—á–∞—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è."
                },
                "en": {
                    "title": "Bridging Visual and Textual Modalities for Superior Multimodal Reasoning",
                    "desc": "This paper presents a caption-assisted reasoning framework that enhances the integration of visual and textual information for multimodal reasoning tasks. The framework addresses the limitations of existing models, such as GPT-3, which struggle with multimodal scenarios despite their success in text-based reasoning. By achieving top performance in challenges like SeePhys and demonstrating strong generalization on the MathVerse benchmark, the proposed method showcases its effectiveness in geometric reasoning. The authors provide their code publicly, promoting further research and application in this area."
                },
                "zh": {
                    "title": "Ê†áÈ¢òËæÖÂä©Êé®ÁêÜÔºöËøûÊé•ËßÜËßâ‰∏éÊñáÊú¨ÁöÑÊ°•Ê¢Å",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊ†áÈ¢òËæÖÂä©Êé®ÁêÜÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÊúâÊïàËøûÊé•ËßÜËßâÂíåÊñáÊú¨Ê®°ÊÄÅÔºå‰ªéËÄåËß£ÂÜ≥Â§öÊ®°ÊÄÅÊé®ÁêÜ‰∏≠ÁöÑÊåëÊàò„ÄÇÂ∞ΩÁÆ°ÊñáÊú¨Êé®ÁêÜÂ∑≤ÊúâÊòæËëóËøõÂ±ïÔºå‰ΩÜÁé∞ÊúâÊ®°ÂûãÂú®Â§öÊ®°ÊÄÅÂú∫ÊôØ‰∏≠Ë°®Áé∞‰ªç‰∏çÁêÜÊÉ≥„ÄÇÊàë‰ª¨ÁöÑÊ°ÜÊû∂Âú®ICML 2025 AI for Math Workshop‰∏≠Ëé∑Âæó‰∫ÜÁ¨¨‰∏ÄÂêçÔºåËØÅÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÂú®MathVerseÂü∫ÂáÜ‰∏äÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®Âá†‰ΩïÊé®ÁêÜÊñπÈù¢ÁöÑÂπøÊ≥õÈÄÇÁî®ÊÄß„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.11526",
            "title": "Multiple Instance Learning Framework with Masked Hard Instance Mining\n  for Gigapixel Histopathology Image Analysis",
            "url": "https://huggingface.co/papers/2509.11526",
            "abstract": "A novel MIL framework, MHIM-MIL, uses masked hard instance mining with a Siamese structure and momentum teacher to improve cancer diagnosis and subtyping accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has opened new avenues for Computational Pathology (CPath). As positive tissue comprises only a small fraction of gigapixel WSIs, existing Multiple Instance Learning (MIL) methods typically focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting challenging ones. Recent studies have shown that hard examples are crucial for accurately modeling discriminative boundaries. Applying such an idea at the instance level, we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which utilizes a Siamese structure with a consistency constraint to explore the hard instances. Using a class-aware instance probability, MHIM-MIL employs a momentum teacher to mask salient instances and implicitly mine hard instances for training the student model. To obtain diverse, non-redundant hard instances, we adopt large-scale random masking while utilizing a global recycle network to mitigate the risk of losing key features. Furthermore, the student updates the teacher using an exponential moving average, which identifies new hard instances for subsequent training iterations and stabilizes optimization. Experimental results on cancer diagnosis, subtyping, survival analysis tasks, and 12 benchmarks demonstrate that MHIM-MIL outperforms the latest methods in both performance and efficiency. The code is available at: https://github.com/DearCaat/MHIM-MIL.",
            "score": 1,
            "issue_id": 5929,
            "pub_date": "2025-09-15",
            "pub_date_card": {
                "ru": "15 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 15",
                "zh": "9Êúà15Êó•"
            },
            "hash": "50c5e6e28356cfc4",
            "authors": [
                "Wenhao Tang",
                "Sheng Huang",
                "Heng Fang",
                "Fengtao Zhou",
                "Bo Liu",
                "Qingshan Liu"
            ],
            "affiliations": [
                "CS, Hefei University of Technology, Hefei, China",
                "CS, Hong Kong University of Science and Technology, Hong Kong, China",
                "CS, Nanjing University of Posts and Telecommunications, Nanjing, China",
                "School of Big Data & Software Engineering, Chongqing University, Chongqing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.11526.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#science",
                    "#optimization",
                    "#training",
                    "#healthcare"
                ],
                "emoji": "üî¨",
                "ru": {
                    "title": "–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–∞–∫–∞",
                    "desc": "–°—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é —Å —ç–∫–∑–µ–º–ø–ª—è—Ä–∞–º–∏ (MIL) –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –ø–æ–¥—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–∫–∞. –ú–µ—Ç–æ–¥ MHIM-MIL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å–ª–æ–∂–Ω—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ —Å —Å–∏–∞–º—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏ —É—á–∏—Ç–µ–ª–µ–º —Å –∏–º–ø—É–ª—å—Å–æ–º. –û–Ω —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏–º–µ—Ä–∞—Ö, –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ MIL. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ MHIM-MIL –Ω–∞–¥ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏."
                },
                "en": {
                    "title": "Unlocking Cancer Insights with Hard Instance Mining",
                    "desc": "The paper introduces a new Multiple Instance Learning (MIL) framework called MHIM-MIL, which focuses on improving cancer diagnosis and subtyping accuracy. It employs masked hard instance mining using a Siamese network structure and a momentum teacher to effectively identify and utilize challenging instances in gigapixel Whole Slide Images (WSIs). By masking easier instances, the framework encourages the model to learn from harder examples, which are essential for better discriminative boundary modeling. Experimental results show that MHIM-MIL significantly outperforms existing methods in various cancer-related tasks, demonstrating its effectiveness and efficiency in computational pathology."
                },
                "zh": {
                    "title": "Êé©ËîΩÂõ∞ÈöæÂÆû‰æãÊåñÊéòÔºåÊèêÂçáÁôåÁóáËØäÊñ≠ÂáÜÁ°ÆÊÄß",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂ§öÂÆû‰æãÂ≠¶‰π†Ê°ÜÊû∂MHIM-MILÔºåÊó®Âú®ÊèêÈ´òÁôåÁóáËØäÊñ≠Âíå‰∫öÂûãÂàÜÁ±ªÁöÑÂáÜÁ°ÆÊÄß„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®‰∫ÜÊé©ËîΩÂõ∞ÈöæÂÆû‰æãÊåñÊéòÊäÄÊúØÔºåÁªìÂêà‰∫ÜSiameseÁªìÊûÑÂíåÂä®ÈáèÊïôÂ∏àÔºå‰ª•Êõ¥Â•ΩÂú∞ËØÜÂà´Èöæ‰ª•ÂàÜÁ±ªÁöÑÂÆû‰æã„ÄÇÈÄöËøá‰ΩøÁî®Á±ªÊÑüÁü•ÂÆû‰æãÊ¶ÇÁéáÔºåMHIM-MILËÉΩÂ§üÊé©ËîΩÊòæËëóÂÆû‰æãÂπ∂ÈöêÂºèÊåñÊéòÂõ∞ÈöæÂÆû‰æãÔºå‰ªéËÄå‰ºòÂåñÂ≠¶ÁîüÊ®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMHIM-MILÂú®ÁôåÁóáËØäÊñ≠„ÄÅ‰∫öÂûãÂàÜÁ±ªÂíåÁîüÂ≠òÂàÜÊûêÁ≠â‰ªªÂä°‰∏äË°®Áé∞‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.11177",
            "title": "Optimal Brain Restoration for Joint Quantization and Sparsification of\n  LLMs",
            "url": "https://huggingface.co/papers/2509.11177",
            "abstract": "A framework combining quantization and pruning in LLMs through error compensation achieves significant speedup and memory reduction.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Large Language Model (LLM) compression, such as quantization and pruning, have achieved notable success. However, as these techniques gradually approach their respective limits, relying on a single method for further compression has become increasingly challenging. In this work, we explore an alternative solution by combining quantization and sparsity. This joint approach, though promising, introduces new difficulties due to the inherently conflicting requirements on weight distributions: quantization favors compact ranges, while pruning benefits from high variance. To attack this problem, we propose Optimal Brain Restoration (OBR), a general and training-free framework that aligns pruning and quantization by error compensation between both. OBR minimizes performance degradation on downstream tasks by building on a second-order Hessian objective, which is then reformulated into a tractable problem through surrogate approximation and ultimately reaches a closed-form solution via group error compensation. Experiments show that OBR enables aggressive W4A4KV4 quantization with 50% sparsity on existing LLMs, and delivers up to 4.72x speedup and 6.4x memory reduction compared to the FP16-dense baseline.",
            "score": 1,
            "issue_id": 5934,
            "pub_date": "2025-09-14",
            "pub_date_card": {
                "ru": "14 —Å–µ–Ω—Ç—è–±—Ä—è",
                "en": "September 14",
                "zh": "9Êúà14Êó•"
            },
            "hash": "69dce8903a88c970",
            "authors": [
                "Hang Guo",
                "Yawei Li",
                "Luca Benini"
            ],
            "affiliations": [
                "ETH Zurich"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.11177.jpg",
            "data": {
                "categories": [
                    "#optimization",
                    "#training",
                    "#inference"
                ],
                "emoji": "üß†",
                "ru": {
                    "title": "–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–∑–≥–∞: —Å–∂–∞—Ç–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞",
                    "desc": "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), —Å–æ—á–µ—Ç–∞—é—â–∏–π –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä—É–Ω–∏–Ω–≥. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ Optimal Brain Restoration (OBR), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å —ç—Ç–∏ –¥–≤–∞ –º–µ—Ç–æ–¥–∞ —á–µ—Ä–µ–∑ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—é –æ—à–∏–±–æ–∫. OBR –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç —É—Ö—É–¥—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ü–µ–ª–µ–≤—ã—Ö –∑–∞–¥–∞—á–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É—è —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–µ—Å—Å–∏–∞–Ω–∞. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ OBR –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ W4A4KV4 —Å 50% —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å—é –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º LLM, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ 4.72x –∏ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤ 6.4 —Ä–∞–∑–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é FP16."
                },
                "en": {
                    "title": "Combining Quantization and Pruning for Efficient LLMs",
                    "desc": "This paper presents a new framework called Optimal Brain Restoration (OBR) that combines quantization and pruning techniques to enhance the efficiency of Large Language Models (LLMs). By addressing the conflicting needs of quantization, which prefers compact weight ranges, and pruning, which benefits from high variance, OBR uses error compensation to align these methods effectively. The framework operates without requiring additional training, leveraging a second-order Hessian objective to minimize performance loss on downstream tasks. Experimental results demonstrate that OBR allows for significant compression, achieving up to 4.72 times speedup and 6.4 times memory reduction compared to traditional dense models."
                },
                "zh": {
                    "title": "ÈáèÂåñ‰∏éÂâ™ÊûùÁöÑÂÆåÁæéÁªìÂêàÔºåÊèêÂçáLLMÊÄßËÉΩÔºÅ",
                    "desc": "Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁªìÂêàÈáèÂåñÂíåÂâ™ÊûùÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÈÄüÂ∫¶ÂíåÂáèÂ∞ëÂÜÖÂ≠ò‰ΩøÁî®„ÄÇÈÄöËøáÂºïÂÖ•ÈîôËØØË°•ÂÅøÊú∫Âà∂Ôºå‰ºòÂåñ‰∫ÜÈáèÂåñÂíåÁ®ÄÁñèÊÄß‰πãÈó¥ÁöÑÁüõÁõæÔºåÂÖãÊúç‰∫ÜÂçï‰∏ÄÊñπÊ≥ïÂú®ÂéãÁº©ÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊúÄ‰ºòÂ§ßËÑëÊÅ¢Â§çÔºàOBRÔºâÊñπÊ≥ïÔºåËÉΩÂ§üÂú®‰∏çÂΩ±Âìç‰∏ãÊ∏∏‰ªªÂä°ÊÄßËÉΩÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆûÁé∞Êõ¥È´òÊïàÁöÑÊ®°ÂûãÂéãÁº©„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåOBRÊñπÊ≥ïÂú®Áé∞ÊúâLLM‰∏äÂÆûÁé∞‰∫ÜÈ´òËææ4.72ÂÄçÁöÑÂä†ÈÄüÂíå6.4ÂÄçÁöÑÂÜÖÂ≠òÂáèÂ∞ë„ÄÇ"
                }
            }
        }
    ],
    "link_prev": "2025-09-16.html",
    "link_next": "2025-09-18.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "16.09",
        "en": "09/16",
        "zh": "9Êúà16Êó•"
    },
    "short_date_next": {
        "ru": "18.09",
        "en": "09/18",
        "zh": "9Êúà18Êó•"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 7,
        "#agents": 6,
        "#cv": 1,
        "#rl": 3,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 2,
        "#3d": 2,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 9,
        "#robotics": 0,
        "#agi": 3,
        "#games": 2,
        "#interpretability": 0,
        "#reasoning": 5,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 11,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 2,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 2,
        "#small_models": 0,
        "#science": 2,
        "#low_resource": 0
    }
}