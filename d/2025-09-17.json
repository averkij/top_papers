{
    "date": {
        "ru": "17 сентября",
        "en": "September 17",
        "zh": "9月17日"
    },
    "time_utc": "2025-09-17 04:13",
    "weekday": 2,
    "issue_id": 5931,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.13232",
            "title": "Single-stream Policy Optimization",
            "url": "https://huggingface.co/papers/2509.13232",
            "abstract": "Single-stream Policy Optimization (SPO) improves policy-gradient training for Large Language Models by eliminating group-based issues and providing a stable, low-variance learning signal, leading to better performance and efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t We revisit policy-gradient optimization for Large Language Models (LLMs) from a single-stream perspective. Prevailing group-based methods like GRPO reduce variance with on-the-fly baselines but suffer from critical flaws: frequent degenerate groups erase learning signals, and synchronization barriers hinder scalability. We introduce Single-stream Policy Optimization (SPO), which eliminates these issues by design. SPO replaces per-group baselines with a persistent, KL-adaptive value tracker and normalizes advantages globally across the batch, providing a stable, low-variance learning signal for every sample. Being group-free, SPO enables higher throughput and scales effectively in long-horizon or tool-integrated settings where generation times vary. Furthermore, the persistent value tracker naturally enables an adaptive curriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO converges more smoothly and attains higher accuracy than GRPO, while eliminating computation wasted on degenerate groups. Ablation studies confirm that SPO's gains stem from its principled approach to baseline estimation and advantage normalization, offering a more robust and efficient path for LLM reasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the average maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial absolute point gains on challenging datasets, including +7.3 pp on BRUMO 25, +4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain in pass@k across the evaluated k values. SPO's success challenges the prevailing trend of adding incidental complexity to RL algorithms, highlighting a path where fundamental principles, not architectural workarounds, drive the next wave of progress in LLM reasoning.",
            "score": 14,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "ecea2ef463a2c2ff",
            "authors": [
                "Zhongwen Xu",
                "Zihan Ding"
            ],
            "affiliations": [
                "Tencent"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13232.jpg",
            "data": {
                "categories": [
                    "#training",
                    "#optimization",
                    "#rl",
                    "#reasoning"
                ],
                "emoji": "🚀",
                "ru": {
                    "title": "SPO: Революция в обучении языковых моделей",
                    "desc": "Статья представляет новый метод оптимизации политики для больших языковых моделей (LLM) под названием Single-stream Policy Optimization (SPO). SPO устраняет проблемы групповых методов, такие как GRPO, предоставляя стабильный сигнал обучения с низкой дисперсией. Метод использует персистентный KL-адаптивный трекер значений и нормализует преимущества глобально по всему батчу. Эксперименты с Qwen3-8B показывают, что SPO обеспечивает более плавную сходимость и более высокую точность по сравнению с GRPO."
                },
                "en": {
                    "title": "Streamlining Learning for Better Language Model Performance",
                    "desc": "Single-stream Policy Optimization (SPO) enhances the training of Large Language Models (LLMs) by addressing the limitations of group-based policy-gradient methods. It eliminates issues like degenerate groups that disrupt learning signals and synchronization barriers that limit scalability. By using a persistent, KL-adaptive value tracker and normalizing advantages globally, SPO provides a stable and low-variance learning signal for each sample. This approach not only improves performance and efficiency but also supports adaptive curriculum learning through prioritized sampling, leading to significant gains in accuracy on challenging benchmarks."
                },
                "zh": {
                    "title": "单流策略优化：提升大语言模型的训练效率",
                    "desc": "单流策略优化（SPO）通过消除基于组的方法问题，改进了大语言模型的策略梯度训练。传统的基于组的方法虽然可以降低方差，但存在学习信号丢失和同步障碍等关键缺陷。SPO通过引入持久的KL自适应价值追踪器，提供了稳定、低方差的学习信号，从而提高了性能和效率。实验结果表明，SPO在多个数学基准测试中表现优于传统方法，展示了其在长时间跨度或工具集成环境中的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.12815",
            "title": "Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset\n  Generation",
            "url": "https://huggingface.co/papers/2509.12815",
            "abstract": "Hunyuan3D Studio automates 3D asset creation using AI, integrating neural modules to transform concept images or text into high-quality, game-ready 3D models with optimized geometry and PBR textures.  \t\t\t\t\tAI-generated summary \t\t\t\t The creation of high-quality 3D assets, a cornerstone of modern game development, has long been characterized by labor-intensive and specialized workflows. This paper presents Hunyuan3D Studio, an end-to-end AI-powered content creation platform designed to revolutionize the game production pipeline by automating and streamlining the generation of game-ready 3D assets. At its core, Hunyuan3D Studio integrates a suite of advanced neural modules (such as Part-level 3D Generation, Polygon Generation, Semantic UV, etc.) into a cohesive and user-friendly system. This unified framework allows for the rapid transformation of a single concept image or textual description into a fully-realized, production-quality 3D model complete with optimized geometry and high-fidelity PBR textures. We demonstrate that assets generated by Hunyuan3D Studio are not only visually compelling but also adhere to the stringent technical requirements of contemporary game engines, significantly reducing iteration time and lowering the barrier to entry for 3D content creation. By providing a seamless bridge from creative intent to technical asset, Hunyuan3D Studio represents a significant leap forward for AI-assisted workflows in game development and interactive media.",
            "score": 7,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "3561c2f1ae6a316c",
            "authors": [
                "Biwen Lei",
                "Yang Li",
                "Xinhai Liu",
                "Shuhui Yang",
                "Lixin Xu",
                "Jingwei Huang",
                "Ruining Tang",
                "Haohan Weng",
                "Jian Liu",
                "Jing Xu",
                "Zhen Zhou",
                "Yiling Zhu",
                "Jiankai Xing",
                "Jiachen Xu",
                "Changfeng Ma",
                "Xinhao Yan",
                "Yunhan Yang",
                "Chunshi Wang",
                "Duoteng Xu",
                "Xueqi Ma",
                "Yuguang Chen",
                "Jing Li",
                "Mingxin Yang",
                "Sheng Zhang",
                "Yifei Feng",
                "Xin Huang",
                "Di Luo",
                "Zebin He",
                "Puhua Jiang",
                "Changrong Hu",
                "Zihan Qin",
                "Shiwei Miao",
                "Haolin Liu",
                "Yunfei Zhao",
                "Zeqiang Lai",
                "Qingxiang Lin",
                "Zibo Zhao",
                "Kunhong Li",
                "Xianghui Yang",
                "Huiwen Shi",
                "Xin Yang",
                "Yuxuan Wang",
                "Zebin Yao",
                "Yihang Lian",
                "Sicong Liu",
                "Xintong Han",
                "Wangchen Qin",
                "Caisheng Ouyang",
                "Jianyin Liu",
                "Tianwen Yuan",
                "Shuai Jiang",
                "Hong Duan",
                "Yanqi Niu",
                "Wencong Lin",
                "Yifu Sun",
                "Shirui Huang",
                "Lin Niu",
                "Gu Gong",
                "Guojian Xiao",
                "Bojian Zheng",
                "Xiang Yuan",
                "Qi Chen",
                "Jie Xiao",
                "Dongyang Zheng",
                "Xiaofeng Yang",
                "Kai Liu",
                "Jianchen Zhu",
                "Lifu Wang",
                "Qinglin Lu",
                "Jie Liu",
                "Liang Dong",
                "Fan Jiang",
                "Ruibin Chen",
                "Lei Wang",
                "Chao Zhang",
                "Jiaxin Lin",
                "Hao Zhang",
                "Zheng Ye",
                "Peng He",
                "Runzhou Wu",
                "Yinhe Wu",
                "Jiayao Du",
                "Jupeng Chen",
                "Xinyue Mao",
                "Dongyuan Guo",
                "Yixuan Tang",
                "Yulin Tsai",
                "Yonghao Tan",
                "Jiaao Yu",
                "Junlin Yu",
                "Keren Zhang",
                "Yifan Li",
                "Peng Chen",
                "Tian Liu",
                "Di Wang",
                "Yuhong Liu",
                "Linus",
                "Jie Jiang",
                "Zhuo Chen",
                "Chunchao Guo"
            ],
            "affiliations": [
                "Tencent Hunyuan Hunyuan3D Studio"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.12815.jpg",
            "data": {
                "categories": [
                    "#games",
                    "#optimization",
                    "#3d"
                ],
                "emoji": "🎮",
                "ru": {
                    "title": "ИИ революционизирует создание 3D-ассетов для игр",
                    "desc": "Hunyuan3D Studio - это платформа для автоматизированного создания 3D-ассетов с использованием искусственного интеллекта. Система интегрирует нейронные модули для преобразования концепт-изображений или текста в высококачественные 3D-модели, готовые к использованию в играх. Hunyuan3D Studio оптимизирует геометрию и создает PBR-текстуры, значительно ускоряя рабочий процесс разработки игр. Платформа демонстрирует потенциал ИИ-ассистированных технологий в создании интерактивного контента."
                },
                "en": {
                    "title": "Revolutionizing 3D Asset Creation with AI",
                    "desc": "Hunyuan3D Studio is an innovative AI-powered platform that automates the creation of high-quality 3D assets for game development. It utilizes advanced neural modules to convert concept images or text into fully-realized 3D models, complete with optimized geometry and PBR textures. This system streamlines the traditionally labor-intensive process, allowing for faster production and easier access to 3D content creation. By meeting the technical standards of modern game engines, Hunyuan3D Studio enhances the efficiency of game production workflows."
                },
                "zh": {
                    "title": "Hunyuan3D Studio：游戏资产创作的AI革命",
                    "desc": "Hunyuan3D Studio 是一个基于人工智能的内容创作平台，旨在自动化和简化游戏制作流程。它通过集成先进的神经模块，将概念图像或文本快速转化为高质量的3D模型，模型具备优化的几何形状和高保真PBR纹理。该平台不仅提高了3D资产的生成效率，还确保生成的资产符合现代游戏引擎的技术要求。Hunyuan3D Studio 代表了游戏开发和互动媒体领域中AI辅助工作流程的重大进步。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.12603",
            "title": "EconProver: Towards More Economical Test-Time Scaling for Automated\n  Theorem Proving",
            "url": "https://huggingface.co/papers/2509.12603",
            "abstract": "Two methods, dynamic CoT switching and Diverse parallel-scaled RL, reduce computational cost in ATP models while maintaining performance.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance.",
            "score": 4,
            "issue_id": 5931,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "8ca0696473050199",
            "authors": [
                "Mukai Li",
                "Linfeng Song",
                "Zhenwen Liang",
                "Jiahao Xu",
                "Shansan Gong",
                "Qi Liu",
                "Haitao Mi",
                "Dong Yu"
            ],
            "affiliations": [
                "Tencent",
                "The University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.12603.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#rl",
                    "#training",
                    "#inference",
                    "#optimization"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Эффективное автоматическое доказательство теорем: меньше затрат, та же мощность",
                    "desc": "Статья представляет два метода для снижения вычислительных затрат в моделях автоматического доказательства теорем (ATP) при сохранении производительности. Первый метод - динамическое переключение цепочки рассуждений (CoT), снижающее избыточное потребление токенов. Второй метод - разнообразное параллельно-масштабируемое обучение с подкреплением (RL) с обучаемыми префиксами для повышения эффективности при ограниченном числе проходов. Эксперименты показывают, что предложенный подход EconProver достигает сравнимой производительности с базовыми методами при использовании лишь 12% вычислительных ресурсов."
                },
                "en": {
                    "title": "Efficient ATP: Cutting Costs Without Cutting Performance",
                    "desc": "This paper presents two innovative methods aimed at reducing the computational costs associated with Automated Theorem Proving (ATP) models while preserving their performance. The first method, dynamic Chain-of-Thought (CoT) switching, optimizes token usage by selectively activating CoT reasoning only when necessary. The second method, Diverse parallel-scaled reinforcement learning (RL), employs trainable prefixes to improve sampling efficiency under limited passes. Through experiments, the proposed EconProver demonstrates that it can achieve similar performance to existing models while using only 12% of the computational resources, offering a more efficient approach to ATP."
                },
                "zh": {
                    "title": "降低计算成本，提升自动定理证明效率",
                    "desc": "本文提出了两种方法，动态链式思维切换和多样化并行缩放强化学习，以降低自动定理证明（ATP）模型的计算成本，同时保持性能。研究表明，现有的测试时间缩放策略在推理时引入了显著的计算开销，而传统的成本分析往往只关注采样次数。通过系统比较不同的缩放策略，本文展示了当前开源方法的低效性，并提出了减少令牌使用和采样次数的有效方案。实验结果表明，所提出的EconProver在仅使用12%计算成本的情况下，性能与基线方法相当。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.06079",
            "title": "Multimodal Reasoning for Science: Technical Report and 1st Place\n  Solution to the ICML 2025 SeePhys Challenge",
            "url": "https://huggingface.co/papers/2509.06079",
            "abstract": "A caption-assisted reasoning framework bridges visual and textual modalities, achieving top performance in multimodal reasoning tasks like SeePhys and MathVerse.  \t\t\t\t\tAI-generated summary \t\t\t\t Multimodal reasoning remains a fundamental challenge in artificial intelligence. Despite substantial advances in text-based reasoning, even state-of-the-art models such as GPT-o3 struggle to maintain strong performance in multimodal scenarios. To address this gap, we introduce a caption-assisted reasoning framework that effectively bridges visual and textual modalities. Our approach achieved 1st place in the ICML 2025 AI for Math Workshop \\& Challenge 2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we validate its generalization on the MathVerse benchmark for geometric reasoning, demonstrating the versatility of our method. Our code is publicly available at https://github.com/OpenDCAI/SciReasoner.",
            "score": 3,
            "issue_id": 5930,
            "pub_date": "2025-09-07",
            "pub_date_card": {
                "ru": "7 сентября",
                "en": "September 7",
                "zh": "9月7日"
            },
            "hash": "58d2381d40c28302",
            "authors": [
                "Hao Liang",
                "Ruitao Wu",
                "Bohan Zeng",
                "Junbo Niu",
                "Wentao Zhang",
                "Bin Dong"
            ],
            "affiliations": [
                "Beihang University",
                "Peking University",
                "Zhongguancun Academy"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.06079.jpg",
            "data": {
                "categories": [
                    "#reasoning",
                    "#open_source",
                    "#benchmark",
                    "#multimodal"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Мост между зрением и языком: новый подход к мультимодальному ИИ",
                    "desc": "Авторы представляют фреймворк для мультимодального рассуждения, который объединяет визуальные и текстовые модальности. Этот подход использует вспомогательные подписи для улучшения понимания изображений и текста. Фреймворк показал лучшие результаты на соревновании SeePhys и продемонстрировал эффективность на бенчмарке MathVerse для геометрических рассуждений. Предложенный метод превосходит даже современные языковые модели вроде GPT-3 в задачах мультимодального рассуждения."
                },
                "en": {
                    "title": "Bridging Visual and Textual Modalities for Superior Multimodal Reasoning",
                    "desc": "This paper presents a caption-assisted reasoning framework that enhances the integration of visual and textual information for multimodal reasoning tasks. The framework addresses the limitations of existing models, such as GPT-3, which struggle with multimodal scenarios despite their success in text-based reasoning. By achieving top performance in challenges like SeePhys and demonstrating strong generalization on the MathVerse benchmark, the proposed method showcases its effectiveness in geometric reasoning. The authors provide their code publicly, promoting further research and application in this area."
                },
                "zh": {
                    "title": "标题辅助推理：连接视觉与文本的桥梁",
                    "desc": "本文提出了一种基于标题辅助推理的框架，旨在有效连接视觉和文本模态，从而解决多模态推理中的挑战。尽管文本推理已有显著进展，但现有模型在多模态场景中表现仍不理想。我们的框架在ICML 2025 AI for Math Workshop中获得了第一名，证明了其有效性和鲁棒性。此外，我们还在MathVerse基准上验证了该方法在几何推理方面的广泛适用性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13317",
            "title": "3D Aware Region Prompted Vision Language Model",
            "url": "https://huggingface.co/papers/2509.13317",
            "abstract": "A Spatial Region 3D (SR-3D) vision-language model unifies 2D and 3D representations by enriching 2D features with 3D positional embeddings, enabling flexible region prompting and accurate spatial reasoning across frames.  \t\t\t\t\tAI-generated summary \t\t\t\t We present Spatial Region 3D (SR-3D) aware vision-language model that connects single-view 2D images and multi-view 3D data through a shared visual token space. SR-3D supports flexible region prompting, allowing users to annotate regions with bounding boxes, segmentation masks on any frame, or directly in 3D, without the need for exhaustive multi-frame labeling. We achieve this by enriching 2D visual features with 3D positional embeddings, which allows the 3D model to draw upon strong 2D priors for more accurate spatial reasoning across frames, even when objects of interest do not co-occur within the same view. Extensive experiments on both general 2D vision language and specialized 3D spatial benchmarks demonstrate that SR-3D achieves state-of-the-art performance, underscoring its effectiveness for unifying 2D and 3D representation space on scene understanding. Moreover, we observe applicability to in-the-wild videos without sensory 3D inputs or ground-truth 3D annotations, where SR-3D accurately infers spatial relationships and metric measurements.",
            "score": 2,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "b8172aa326bbec5e",
            "authors": [
                "An-Chieh Cheng",
                "Yang Fu",
                "Yukang Chen",
                "Zhijian Liu",
                "Xiaolong Li",
                "Subhashree Radhakrishnan",
                "Song Han",
                "Yao Lu",
                "Jan Kautz",
                "Pavlo Molchanov",
                "Hongxu Yin",
                "Xiaolong Wang",
                "Sifei Liu"
            ],
            "affiliations": [
                "MIT",
                "NVIDIA",
                "UC San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13317.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#games",
                    "#3d",
                    "#cv",
                    "#multimodal",
                    "#reasoning"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Объединение 2D и 3D для лучшего понимания пространства",
                    "desc": "SR-3D - это модель машинного обучения, объединяющая 2D и 3D представления визуальных данных. Она обогащает 2D признаки 3D позиционными эмбеддингами, что позволяет гибко задавать регионы интереса и точно анализировать пространственные отношения между кадрами. Модель поддерживает разметку регионов ограничивающими рамками, сегментационными масками или напрямую в 3D, без необходимости полной разметки всех кадров. SR-3D достигает наилучших результатов как на общих задачах компьютерного зрения, так и на специализированных 3D пространственных бенчмарках."
                },
                "en": {
                    "title": "Unifying 2D and 3D for Enhanced Scene Understanding",
                    "desc": "The Spatial Region 3D (SR-3D) model integrates 2D and 3D visual data by enhancing 2D features with 3D positional information. This allows for flexible region prompting, enabling users to annotate images and 3D spaces without extensive labeling across multiple frames. By leveraging 3D embeddings, the model improves spatial reasoning, even when objects are not visible together in the same view. Experiments show that SR-3D outperforms existing methods in both 2D and 3D tasks, demonstrating its capability to understand scenes effectively, even in videos lacking 3D data."
                },
                "zh": {
                    "title": "统一2D与3D表示的空间区域3D模型",
                    "desc": "本文介绍了一种空间区域3D（SR-3D）视觉语言模型，它通过将2D特征与3D位置嵌入相结合，实现了2D和3D表示的统一。SR-3D支持灵活的区域提示，用户可以在任意帧上使用边界框或分割掩码进行标注，而无需进行繁琐的多帧标注。通过增强2D视觉特征，SR-3D能够在不同帧之间进行更准确的空间推理，即使感兴趣的物体不在同一视图中出现。实验结果表明，SR-3D在2D视觉语言和3D空间基准测试中均表现出色，证明了其在场景理解中的有效性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.12341",
            "title": "Exact Coset Sampling for Quantum Lattice Algorithms",
            "url": "https://huggingface.co/papers/2509.12341",
            "abstract": "A replacement for the domain-extension step in a quantum lattice algorithm uses a pair-shift difference construction to correct periodicity issues and enforce modular linear relations efficiently.  \t\t\t\t\tAI-generated summary \t\t\t\t We give a simple, fully correct, and assumption-light replacement for the contested \"domain-extension\" in Step 9 of a recent windowed-QFT lattice algorithm with complex-Gaussian windows~chen2024quantum. The published Step~9 suffers from a periodicity/support mismatch. We present a pair-shift difference construction that coherently cancels all unknown offsets, produces an exact uniform CRT-coset state over Z_{P}, and then uses the QFT to enforce the intended modular linear relation. The unitary is reversible, uses poly(log M_2) gates, and preserves the algorithm's asymptotics. Project Page: https://github.com/yifanzhang-pro/quantum-lattice.",
            "score": 2,
            "issue_id": 5930,
            "pub_date": "2025-09-15",
            "pub_date_card": {
                "ru": "15 сентября",
                "en": "September 15",
                "zh": "9月15日"
            },
            "hash": "30a8fdee577071f4",
            "authors": [
                "Yifan Zhang"
            ],
            "affiliations": [
                "Princeton University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.12341.jpg",
            "data": {
                "categories": [],
                "emoji": "🔬",
                "ru": {
                    "title": "Усовершенствование квантового алгоритма решетки: эффективное расширение домена",
                    "desc": "Статья представляет улучшение для алгоритма квантовой решетки. Авторы предлагают замену для шага расширения домена, используя конструкцию разности парных сдвигов. Это исправляет проблемы с периодичностью и эффективно обеспечивает модульные линейные соотношения. Новый метод является полностью корректным, не требует дополнительных предположений и сохраняет асимптотику исходного алгоритма."
                },
                "en": {
                    "title": "Efficiently Correcting Periodicity in Quantum Lattice Algorithms",
                    "desc": "This paper introduces a new method to replace the problematic 'domain-extension' step in a quantum lattice algorithm. The proposed solution uses a pair-shift difference construction to address issues related to periodicity and support mismatches. By coherently canceling unknown offsets, it creates a uniform CRT-coset state and applies the Quantum Fourier Transform (QFT) to maintain the desired modular linear relations. This approach is efficient, reversible, and maintains the algorithm's performance characteristics."
                },
                "zh": {
                    "title": "高效解决量子算法中的周期性问题",
                    "desc": "本文提出了一种替代量子格算法中域扩展步骤的简单方法，旨在解决周期性问题。我们使用了一种成对移位差构造，能够有效地消除未知偏移量，并生成一个精确的均匀余数类状态。该方法通过量子傅里叶变换（QFT）来强制执行预期的模线性关系，同时保持算法的渐近性质。我们的构造是可逆的，并且使用了多项式对数级别的门。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13312",
            "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research",
            "url": "https://huggingface.co/papers/2509.13312",
            "abstract": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.  \t\t\t\t\tAI-generated summary \t\t\t\t This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents must synthesize vast web-scale information into insightful reports. Current approaches are plagued by dual-fold limitations: static research pipelines that decouple planning from evidence acquisition and one-shot generation paradigms that easily suffer from long-context failure issues like \"loss in the middle\" and hallucinations. To address these challenges, we introduce WebWeaver, a novel dual-agent framework that emulates the human research process. The planner operates in a dynamic cycle, iteratively interleaving evidence acquisition with outline optimization to produce a comprehensive, source-grounded outline linking to a memory bank of evidence. The writer then executes a hierarchical retrieval and writing process, composing the report section by section. By performing targeted retrieval of only the necessary evidence from the memory bank for each part, it effectively mitigates long-context issues. Our framework establishes a new state-of-the-art across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym. These results validate our human-centric, iterative methodology, demonstrating that adaptive planning and focused synthesis are crucial for producing high-quality, reliable, and well-structured reports.",
            "score": 1,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "7c9823f6fb958040",
            "authors": [
                "Zijian Li",
                "Xin Guan",
                "Bo Zhang",
                "Shen Huang",
                "Houquan Zhou",
                "Shaopeng Lai",
                "Ming Yan",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jun Zhang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13312.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#hallucinations",
                    "#long_context",
                    "#multimodal",
                    "#agents"
                ],
                "emoji": "🕸️",
                "ru": {
                    "title": "Адаптивное планирование и целенаправленный синтез для качественных исследовательских отчетов",
                    "desc": "Статья представляет WebWeaver - двухагентную систему для решения задач глубокого открытого исследования. Первый агент (планировщик) итеративно собирает доказательства и оптимизирует план, создавая подробный план с ссылками на банк данных. Второй агент (писатель) выполняет иерархический процесс извлечения информации и написания, составляя отчет по частям. Такой подход позволяет избежать проблем с длинным контекстом и галлюцинациями. WebWeaver достигает нового уровня качества на основных бенчмарках глубокого открытого исследования."
                },
                "en": {
                    "title": "WebWeaver: Revolutionizing AI Research with Adaptive Planning and Focused Synthesis",
                    "desc": "This paper presents WebWeaver, a dual-agent framework designed to tackle open-ended deep research (OEDR) challenges in AI. It combines adaptive planning with focused synthesis to create high-quality reports by mimicking the human research process. The framework features a planner that dynamically interleaves evidence gathering with outline optimization, ensuring a comprehensive and reliable report structure. By using targeted retrieval from a memory bank, WebWeaver effectively addresses common issues like long-context failures and hallucinations, setting a new standard in OEDR performance."
                },
                "zh": {
                    "title": "WebWeaver：人本研究的新方法",
                    "desc": "WebWeaver是一个双代理框架，旨在解决开放式深度研究的挑战。它通过动态规划和聚焦合成，生成高质量、可靠的研究报告。该框架模拟人类研究过程，规划者在动态循环中优化大纲并获取证据，作家则逐步撰写报告。WebWeaver在多个开放式深度研究基准测试中表现出色，验证了其人本、迭代的方法论。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13311",
            "title": "Towards General Agentic Intelligence via Environment Scaling",
            "url": "https://huggingface.co/papers/2509.13311",
            "abstract": "A scalable framework and two-phase fine-tuning strategy enhance function-calling capabilities of agents in diverse environments, improving performance on agentic benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practical, real-world applications. Diverse real-world APIs demand precise, robust function-calling intelligence, which needs agents to develop these capabilities through interaction in varied environments. The breadth of function-calling competence is closely tied to the diversity of environments in which agents are trained. In this work, we scale up environments as a step towards advancing general agentic intelligence. This gives rise to two central challenges: (i) how to scale environments in a principled manner, and (ii) how to effectively train agentic capabilities from experiences derived through interactions with these environments. To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated, systematically broadening the space of function-calling scenarios. We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts. Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models.",
            "score": 1,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "c97e7569e926b9a7",
            "authors": [
                "Runnan Fang",
                "Shihao Cai",
                "Baixuan Li",
                "Jialong Wu",
                "Guangyu Li",
                "Wenbiao Yin",
                "Xinyu Wang",
                "Xiaobin Wang",
                "Liangcai Su",
                "Zhen Zhang",
                "Shibin Wu",
                "Zhengwei Tao",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13311.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#agi",
                    "#training",
                    "#agents"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Масштабируемое обучение агентов для улучшения вызова функций в разнообразных средах",
                    "desc": "Статья представляет масштабируемую систему и двухфазную стратегию дообучения для улучшения способностей агентов к вызову функций в разнообразных средах. Авторы разработали фреймворк, автоматически создающий гетерогенные симулированные среды, расширяя спектр сценариев вызова функций. Предложенная стратегия обучения сначала наделяет агентов базовыми возможностями, а затем специализирует их для конкретных доменов. Эксперименты на различных бенчмарках показали значительное улучшение способностей моделей к вызову функций."
                },
                "en": {
                    "title": "Scaling Agentic Intelligence for Enhanced Function-Calling",
                    "desc": "This paper presents a scalable framework and a two-phase fine-tuning strategy to improve the function-calling abilities of agents in various environments. The authors emphasize that training agents in diverse settings is crucial for developing robust function-calling intelligence, which is essential for real-world applications of Large Language Models. They propose a method to systematically create varied simulated environments and a training approach that first builds basic agentic skills before refining them for specific tasks. Experimental results show that their model, AgentScaler, outperforms existing benchmarks in function-calling tasks, indicating significant advancements in agentic intelligence."
                },
                "zh": {
                    "title": "提升智能体函数调用能力的可扩展框架",
                    "desc": "本论文提出了一种可扩展的框架和两阶段微调策略，以增强智能体在多样化环境中的函数调用能力。研究表明，智能体的函数调用能力与其训练环境的多样性密切相关。我们设计了一个自动构建异构环境的框架，系统性地扩展了函数调用场景的空间。此外，通过两阶段的微调策略，我们首先赋予智能体基本能力，然后针对特定领域进行专业化训练，显著提升了模型的性能。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.13309",
            "title": "WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon\n  Agents",
            "url": "https://huggingface.co/papers/2509.13309",
            "abstract": "WebResearcher, a deep-research framework, enhances AI agents' knowledge synthesis by reformulating research as a Markov Decision Process and using a scalable data synthesis engine, achieving superior performance across benchmarks.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in deep-research systems have demonstrated the potential for AI agents to autonomously discover and synthesize knowledge from external sources. In this paper, we introduce WebResearcher, a novel framework for building such agents through two key components: (1) WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, where agents periodically consolidate findings into evolving reports while maintaining focused workspaces, overcoming the context suffocation and noise contamination that plague existing mono-contextual approaches; and (2) WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation, enabling systematic creation of research tasks that bridge the gap between passive knowledge recall and active knowledge construction. Notably, we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods. Furthermore, our paradigm naturally scales through parallel thinking, enabling concurrent multi-agent exploration for more comprehensive conclusions. Extensive experiments across 6 challenging benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, even surpassing frontier proprietary systems.",
            "score": 1,
            "issue_id": 5929,
            "pub_date": "2025-09-16",
            "pub_date_card": {
                "ru": "16 сентября",
                "en": "September 16",
                "zh": "9月16日"
            },
            "hash": "f064e62f63131809",
            "authors": [
                "Zile Qiao",
                "Guoxin Chen",
                "Xuanzhong Chen",
                "Donglei Yu",
                "Wenbiao Yin",
                "Xinyu Wang",
                "Zhen Zhang",
                "Baixuan Li",
                "Huifeng Yin",
                "Kuan Li",
                "Rui Min",
                "Minpeng Liao",
                "Yong Jiang",
                "Pengjun Xie",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "affiliations": [
                "Tongyi Lab, Alibaba Group"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.13309.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#optimization",
                    "#science",
                    "#dataset",
                    "#training",
                    "#agents",
                    "#transfer_learning"
                ],
                "emoji": "🕸️",
                "ru": {
                    "title": "WebResearcher: новый уровень глубокого исследования для ИИ",
                    "desc": "WebResearcher - это новая система глубокого исследования, которая улучшает способность ИИ-агентов синтезировать знания. Она переформулирует процесс исследования как марковский процесс принятия решений и использует масштабируемый механизм синтеза данных. WebResearcher включает в себя итеративную парадигму глубокого исследования и систему WebFrontier для генерации качественных обучающих данных. Эксперименты показывают, что WebResearcher превосходит существующие системы по ряду сложных тестов."
                },
                "en": {
                    "title": "Revolutionizing AI Knowledge Synthesis with WebResearcher",
                    "desc": "WebResearcher is a deep-research framework that improves how AI agents gather and synthesize knowledge by treating research as a Markov Decision Process. It features an iterative approach where agents create evolving reports while managing focused workspaces, which helps avoid distractions from irrelevant information. Additionally, the framework includes WebFrontier, a data synthesis engine that produces high-quality training data, enhancing the agents' ability to construct knowledge actively. Experiments show that WebResearcher outperforms existing systems across multiple benchmarks, demonstrating its effectiveness in autonomous knowledge discovery."
                },
                "zh": {
                    "title": "WebResearcher：提升AI知识综合的新框架",
                    "desc": "WebResearcher是一个深度研究框架，通过将研究重新表述为马尔可夫决策过程，增强了人工智能代理的知识综合能力。该框架包含两个关键组件：一个是迭代深度研究范式，能够定期整合发现并生成不断演变的报告，克服了现有单一上下文方法的局限性；另一个是可扩展的数据合成引擎，能够生成高质量的训练数据，促进主动知识构建。实验结果表明，WebResearcher在多个基准测试中表现优异，甚至超越了许多前沿的专有系统。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.11526",
            "title": "Multiple Instance Learning Framework with Masked Hard Instance Mining\n  for Gigapixel Histopathology Image Analysis",
            "url": "https://huggingface.co/papers/2509.11526",
            "abstract": "A novel MIL framework, MHIM-MIL, uses masked hard instance mining with a Siamese structure and momentum teacher to improve cancer diagnosis and subtyping accuracy.  \t\t\t\t\tAI-generated summary \t\t\t\t Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has opened new avenues for Computational Pathology (CPath). As positive tissue comprises only a small fraction of gigapixel WSIs, existing Multiple Instance Learning (MIL) methods typically focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting challenging ones. Recent studies have shown that hard examples are crucial for accurately modeling discriminative boundaries. Applying such an idea at the instance level, we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which utilizes a Siamese structure with a consistency constraint to explore the hard instances. Using a class-aware instance probability, MHIM-MIL employs a momentum teacher to mask salient instances and implicitly mine hard instances for training the student model. To obtain diverse, non-redundant hard instances, we adopt large-scale random masking while utilizing a global recycle network to mitigate the risk of losing key features. Furthermore, the student updates the teacher using an exponential moving average, which identifies new hard instances for subsequent training iterations and stabilizes optimization. Experimental results on cancer diagnosis, subtyping, survival analysis tasks, and 12 benchmarks demonstrate that MHIM-MIL outperforms the latest methods in both performance and efficiency. The code is available at: https://github.com/DearCaat/MHIM-MIL.",
            "score": 1,
            "issue_id": 5929,
            "pub_date": "2025-09-15",
            "pub_date_card": {
                "ru": "15 сентября",
                "en": "September 15",
                "zh": "9月15日"
            },
            "hash": "50c5e6e28356cfc4",
            "authors": [
                "Wenhao Tang",
                "Sheng Huang",
                "Heng Fang",
                "Fengtao Zhou",
                "Bo Liu",
                "Qingshan Liu"
            ],
            "affiliations": [
                "CS, Hefei University of Technology, Hefei, China",
                "CS, Hong Kong University of Science and Technology, Hong Kong, China",
                "CS, Nanjing University of Posts and Telecommunications, Nanjing, China",
                "School of Big Data & Software Engineering, Chongqing University, Chongqing, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.11526.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#science",
                    "#optimization",
                    "#training",
                    "#healthcare"
                ],
                "emoji": "🔬",
                "ru": {
                    "title": "Новый метод машинного обучения повышает точность диагностики рака",
                    "desc": "Статья представляет новый подход к множественному обучению с экземплярами (MIL) для улучшения диагностики и подтипирования рака. Метод MHIM-MIL использует маскированный поиск сложных экземпляров с сиамской структурой и учителем с импульсом. Он фокусируется на сложных для классификации примерах, в отличие от традиционных методов MIL. Экспериментальные результаты показывают превосходство MHIM-MIL над современными методами по производительности и эффективности."
                },
                "en": {
                    "title": "Unlocking Cancer Insights with Hard Instance Mining",
                    "desc": "The paper introduces a new Multiple Instance Learning (MIL) framework called MHIM-MIL, which focuses on improving cancer diagnosis and subtyping accuracy. It employs masked hard instance mining using a Siamese network structure and a momentum teacher to effectively identify and utilize challenging instances in gigapixel Whole Slide Images (WSIs). By masking easier instances, the framework encourages the model to learn from harder examples, which are essential for better discriminative boundary modeling. Experimental results show that MHIM-MIL significantly outperforms existing methods in various cancer-related tasks, demonstrating its effectiveness and efficiency in computational pathology."
                },
                "zh": {
                    "title": "掩蔽困难实例挖掘，提升癌症诊断准确性",
                    "desc": "本文提出了一种新的多实例学习框架MHIM-MIL，旨在提高癌症诊断和亚型分类的准确性。该框架采用了掩蔽困难实例挖掘技术，结合了Siamese结构和动量教师，以更好地识别难以分类的实例。通过使用类感知实例概率，MHIM-MIL能够掩蔽显著实例并隐式挖掘困难实例，从而优化学生模型的训练。实验结果表明，MHIM-MIL在癌症诊断、亚型分类和生存分析等任务上表现优于现有方法。"
                }
            }
        }
    ],
    "link_prev": "2025-09-16.html",
    "link_next": "2025-09-18.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "16.09",
        "en": "09/16",
        "zh": "9月16日"
    },
    "short_date_next": {
        "ru": "18.09",
        "en": "09/18",
        "zh": "9月18日"
    },
    "categories": {
        "#dataset": 1,
        "#data": 0,
        "#benchmark": 6,
        "#agents": 3,
        "#cv": 1,
        "#rl": 2,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 1,
        "#3d": 2,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 5,
        "#robotics": 0,
        "#agi": 1,
        "#games": 2,
        "#interpretability": 0,
        "#reasoning": 4,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 0,
        "#security": 0,
        "#optimization": 7,
        "#survey": 0,
        "#diffusion": 0,
        "#alignment": 0,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 1,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 1,
        "#small_models": 0,
        "#science": 2,
        "#low_resource": 0
    }
}