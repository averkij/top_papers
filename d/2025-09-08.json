{
    "date": {
        "ru": "8 сентября",
        "en": "September 8",
        "zh": "9月8日"
    },
    "time_utc": "2025-09-08 07:12",
    "weekday": 0,
    "issue_id": 5765,
    "home_page_url": "https://huggingface.co/papers",
    "papers": [
        {
            "id": "https://huggingface.co/papers/2509.04664",
            "title": "Why Language Models Hallucinate",
            "url": "https://huggingface.co/papers/2509.04664",
            "abstract": "Language models produce incorrect statements due to training and evaluation procedures that reward guessing over acknowledging uncertainty, leading to a need for socio-technical changes in benchmark scoring.  \t\t\t\t\tAI-generated summary \t\t\t\t Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such \"hallucinations\" persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious -- they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded -- language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This \"epidemic\" of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems.",
            "score": 26,
            "issue_id": 5763,
            "pub_date": "2025-09-04",
            "pub_date_card": {
                "ru": "4 сентября",
                "en": "September 4",
                "zh": "9月4日"
            },
            "hash": "a9af1f035c82b958",
            "authors": [
                "Adam Tauman Kalai",
                "Ofir Nachum",
                "Santosh S. Vempala",
                "Edwin Zhang"
            ],
            "affiliations": [
                "Georgia Tech",
                "OpenAI"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04664.jpg",
            "data": {
                "categories": [
                    "#hallucinations",
                    "#training",
                    "#ethics",
                    "#benchmark"
                ],
                "emoji": "🤖",
                "ru": {
                    "title": "Переосмысление оценки языковых моделей для борьбы с галлюцинациями",
                    "desc": "Статья рассматривает проблему галлюцинаций в языковых моделях, когда они генерируют правдоподобные, но неверные утверждения вместо признания неопределенности. Авторы утверждают, что это происходит из-за процедур обучения и оценки, которые поощряют угадывание. Они анализируют статистические причины галлюцинаций в современном процессе обучения моделей. Предлагается изменить систему оценки существующих бенчмарков, чтобы стимулировать разработку более надежных систем ИИ."
                },
                "en": {
                    "title": "Transforming AI Trustworthiness by Addressing Hallucinations",
                    "desc": "This paper discusses how large language models often produce incorrect statements, known as 'hallucinations', due to their training and evaluation methods. These models are rewarded for guessing answers even when they are uncertain, which leads to plausible but false outputs. The authors analyze how these hallucinations stem from errors in binary classification and the statistical pressures in the training process. They propose that to reduce these hallucinations, the scoring systems of benchmarks should be modified to discourage guessing and promote acknowledgment of uncertainty, ultimately fostering more reliable AI systems."
                },
                "zh": {
                    "title": "改进评分机制，提升语言模型可信度",
                    "desc": "这篇论文讨论了语言模型在训练和评估过程中产生错误陈述的原因。由于现有的评分机制奖励猜测而非承认不确定性，导致模型在面对不确定时倾向于猜测，从而产生虚假信息。作者分析了现代训练流程中导致这些“幻觉”的统计原因，并指出这些错误源于二元分类中的错误。为了提高语言模型的可信度，论文建议对现有基准的评分方式进行社会技术上的调整，而不是增加新的评估方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.04744",
            "title": "WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning",
            "url": "https://huggingface.co/papers/2509.04744",
            "abstract": "WildScore evaluates MLLMs' symbolic music reasoning through a benchmark of real-world music scores and user-generated queries, revealing both strengths and challenges.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various vision-language tasks. However, their reasoning abilities in the multimodal symbolic music domain remain largely unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to interpret real-world music scores and answer complex musicological queries. Each instance in WildScore is sourced from genuine musical compositions and accompanied by authentic user-generated questions and discussions, capturing the intricacies of practical music analysis. To facilitate systematic evaluation, we propose a systematic taxonomy, comprising both high-level and fine-grained musicological ontologies. Furthermore, we frame complex music reasoning as multiple-choice question answering, enabling controlled and scalable assessment of MLLMs' symbolic music understanding. Empirical benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns in their visual-symbolic reasoning, uncovering both promising directions and persistent challenges for MLLMs in symbolic music reasoning and analysis. We release the dataset and code.",
            "score": 6,
            "issue_id": 5761,
            "pub_date": "2025-09-05",
            "pub_date_card": {
                "ru": "5 сентября",
                "en": "September 5",
                "zh": "9月5日"
            },
            "hash": "44d75a7c2c61a026",
            "authors": [
                "Gagan Mundada",
                "Yash Vishe",
                "Amit Namburi",
                "Xin Xu",
                "Zachary Novack",
                "Julian McAuley",
                "Junda Wu"
            ],
            "affiliations": [
                "University of California, San Diego"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04744.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#dataset",
                    "#benchmark",
                    "#reasoning",
                    "#survey"
                ],
                "emoji": "🎼",
                "ru": {
                    "title": "WildScore: новый рубеж в понимании музыки искусственным интеллектом",
                    "desc": "Статья представляет WildScore - первый бенчмарк для оценки способностей мультимодальных языковых моделей (MLLM) в области анализа и рассуждений о символической музыке. Бенчмарк состоит из реальных музыкальных партитур и вопросов пользователей, охватывая сложности практического музыкального анализа. Авторы предлагают систематическую таксономию и формулируют задачу как ответы на вопросы с множественным выбором. Эмпирическое тестирование современных MLLM на WildScore выявляет как перспективные направления, так и сохраняющиеся проблемы в области рассуждений о символической музыке."
                },
                "en": {
                    "title": "WildScore: Unlocking MLLMs' Music Reasoning Potential",
                    "desc": "WildScore is a benchmark designed to assess the reasoning abilities of Multimodal Large Language Models (MLLMs) in the context of symbolic music. It evaluates how well these models can interpret real-world music scores and respond to complex questions about music. The benchmark includes genuine musical compositions and user-generated queries, providing a realistic setting for analysis. By framing music reasoning as multiple-choice questions, WildScore allows for systematic evaluation of MLLMs' understanding of music, revealing both their strengths and areas needing improvement."
                },
                "zh": {
                    "title": "WildScore：音乐推理的新基准",
                    "desc": "WildScore是一个评估多模态大型语言模型（MLLMs）在符号音乐推理能力的基准测试。它通过真实的音乐乐谱和用户生成的查询，揭示了这些模型在音乐分析中的优势和挑战。该基准测试采用了系统的分类法，涵盖了高层次和细粒度的音乐学本体。通过将复杂的音乐推理框架化为多项选择题回答，WildScore为MLLMs的符号音乐理解提供了可控和可扩展的评估方式。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.05263",
            "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for\n  Interactive Complex World Generation",
            "url": "https://huggingface.co/papers/2509.05263",
            "abstract": "LatticeWorld, a 3D world generation framework using lightweight LLMs and Unreal Engine 5, creates dynamic, interactive environments from textual and visual inputs, achieving high accuracy and efficiency.  \t\t\t\t\tAI-generated summary \t\t\t\t Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real world conveniently. While traditional manual modeling has enabled the creation of virtual 3D scenes, modern approaches have leveraged advanced machine learning algorithms for 3D world generation, with most recent advances focusing on generative methods that can create virtual worlds based on user instructions. This work explores such a research direction by proposing LatticeWorld, a simple yet effective 3D world generation framework that streamlines the industrial production pipeline of 3D environments. LatticeWorld leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed framework accepts textual descriptions and visual instructions as multimodal inputs and creates large-scale 3D interactive worlds with dynamic agents, featuring competitive multi-agent interaction, high-fidelity physics simulation, and real-time rendering. We conduct comprehensive experiments to evaluate LatticeWorld, showing that it achieves superior accuracy in scene layout generation and visual fidelity. Moreover, LatticeWorld achieves over a 90times increase in industrial production efficiency while maintaining high creative quality compared with traditional manual production methods. Our demo video is available at https://youtu.be/8VWZXpERR18",
            "score": 2,
            "issue_id": 5761,
            "pub_date": "2025-09-05",
            "pub_date_card": {
                "ru": "5 сентября",
                "en": "September 5",
                "zh": "9月5日"
            },
            "hash": "027e61af3a0f5c1a",
            "authors": [
                "Yinglin Duan",
                "Zhengxia Zou",
                "Tongwei Gu",
                "Wei Jia",
                "Zhan Zhao",
                "Luyi Xu",
                "Xinzhu Liu",
                "Hao Jiang",
                "Kang Chen",
                "Shuang Qiu"
            ],
            "affiliations": [
                "Beihang University, China",
                "City University of Hong Kong, China",
                "NetEase, Inc., China",
                "Tsinghua University, China"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.05263.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#games",
                    "#optimization",
                    "#agents",
                    "#3d"
                ],
                "emoji": "🌐",
                "ru": {
                    "title": "Генерация 3D-миров на основе ИИ: быстро, точно, реалистично",
                    "desc": "LatticeWorld - это фреймворк для создания трёхмерных миров, использующий облегчённые языковые модели и Unreal Engine 5. Система принимает текстовые и визуальные инструкции для генерации динамических интерактивных сред. LatticeWorld достигает высокой точности в создании планировки сцен и визуальной достоверности. Фреймворк значительно повышает эффективность промышленного производства по сравнению с традиционными ручными методами."
                },
                "en": {
                    "title": "Revolutionizing 3D World Generation with LatticeWorld",
                    "desc": "LatticeWorld is a 3D world generation framework that utilizes lightweight large language models (LLMs) and Unreal Engine 5 to create interactive environments from both textual and visual inputs. This framework aims to enhance the realism of simulations, bridging the gap between simulated and real-world scenarios, which is crucial for applications like autonomous driving and embodied AI. By employing generative methods, LatticeWorld can produce large-scale 3D worlds with dynamic agents, showcasing high-fidelity physics and real-time rendering capabilities. The results demonstrate a significant increase in production efficiency, achieving over 90 times faster output compared to traditional modeling techniques while maintaining high visual quality."
                },
                "zh": {
                    "title": "LatticeWorld：高效生成动态3D世界的创新框架",
                    "desc": "LatticeWorld是一个使用轻量级大语言模型和虚幻引擎5的3D世界生成框架。它能够根据文本和视觉输入创建动态、互动的环境，具有高准确性和效率。该框架通过多模态输入生成大规模的3D互动世界，支持动态代理和高保真物理模拟。与传统手动建模方法相比，LatticeWorld在工业生产效率上提高了90倍，同时保持了高创意质量。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.04013",
            "title": "On Robustness and Reliability of Benchmark-Based Evaluation of LLMs",
            "url": "https://huggingface.co/papers/2509.04013",
            "abstract": "LLMs show reduced effectiveness on paraphrased benchmark questions, indicating limitations in handling linguistic variability and suggesting the need for more robust evaluation methods.  \t\t\t\t\tAI-generated summary \t\t\t\t Large Language Models (LLMs) effectiveness is usually evaluated by means of benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in their original wording, thus in a fixed, standardized format. However, real-world applications involve linguistic variability, requiring models to maintain their effectiveness across diverse rewordings of the same question or query. In this study, we systematically assess the robustness of LLMs to paraphrased benchmark questions and investigate whether benchmark-based evaluations provide a reliable measure of model capabilities. We systematically generate various paraphrases of all the questions across six different common benchmarks, and measure the resulting variations in effectiveness of 34 state-of-the-art LLMs, of different size and effectiveness. Our findings reveal that while LLM rankings remain relatively stable across paraphrased inputs, absolute effectiveness scores change, and decline significantly. This suggests that LLMs struggle with linguistic variability, raising concerns about their generalization abilities and evaluation methodologies. Furthermore, the observed performance drop challenges the reliability of benchmark-based evaluations, indicating that high benchmark scores may not fully capture a model's robustness to real-world input variations. We discuss the implications of these findings for LLM evaluation methodologies, emphasizing the need for robustness-aware benchmarks that better reflect practical deployment scenarios.",
            "score": 2,
            "issue_id": 5764,
            "pub_date": "2025-09-04",
            "pub_date_card": {
                "ru": "4 сентября",
                "en": "September 4",
                "zh": "9月4日"
            },
            "hash": "32f0ad5327f657e2",
            "authors": [
                "Riccardo Lunardi",
                "Vincenzo Della Mea",
                "Stefano Mizzaro",
                "Kevin Roitero"
            ],
            "affiliations": [
                "University of Udine, Italy"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04013.jpg",
            "data": {
                "categories": [
                    "#evaluation",
                    "#interpretability",
                    "#benchmark",
                    "#reasoning",
                    "#data"
                ],
                "emoji": "🔍",
                "ru": {
                    "title": "Языковые модели спотыкаются о перефразированные вопросы",
                    "desc": "Исследование показало, что большие языковые модели (LLM) менее эффективны при работе с перефразированными вопросами из стандартных тестов. Это указывает на ограничения LLM в обработке лингвистических вариаций. Результаты ставят под сомнение надежность оценки моделей на основе существующих бенчмарков. Исследователи подчеркивают необходимость разработки более устойчивых методов оценки, которые лучше отражают реальные сценарии использования LLM."
                },
                "en": {
                    "title": "Evaluating LLMs: Beyond Fixed Benchmarks to Real-World Language Variability",
                    "desc": "This paper investigates how well Large Language Models (LLMs) perform when faced with paraphrased questions, highlighting their limitations in dealing with linguistic variability. The authors found that while the rankings of LLMs remained stable, their effectiveness scores dropped significantly when questions were reworded. This indicates that current benchmark evaluations may not accurately reflect a model's ability to generalize to real-world language use. The study calls for the development of more robust evaluation methods that account for diverse question phrasing to better assess LLM capabilities."
                },
                "zh": {
                    "title": "提升LLMs鲁棒性，重塑评估标准",
                    "desc": "大型语言模型（LLMs）在处理同一问题的不同表述时效果较差，显示出其在语言变异性方面的局限性。这项研究系统地评估了LLMs对改写基准问题的鲁棒性，并探讨了基于基准的评估是否可靠。研究发现，尽管LLMs在不同表述下的排名相对稳定，但其绝对有效性得分显著下降。这表明LLMs在应对真实世界的语言变异时存在困难，呼吁开发更能反映实际应用场景的评估方法。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.05296",
            "title": "WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool",
            "url": "https://huggingface.co/papers/2509.05296",
            "abstract": "WinT3R, a feed-forward reconstruction model, achieves high-quality camera pose estimation and real-time performance using a sliding window mechanism and a global camera token pool.  \t\t\t\t\tAI-generated summary \t\t\t\t We present WinT3R, a feed-forward reconstruction model capable of online prediction of precise camera poses and high-quality point maps. Previous methods suffer from a trade-off between reconstruction quality and real-time performance. To address this, we first introduce a sliding window mechanism that ensures sufficient information exchange among frames within the window, thereby improving the quality of geometric predictions without large computation. In addition, we leverage a compact representation of cameras and maintain a global camera token pool, which enhances the reliability of camera pose estimation without sacrificing efficiency. These designs enable WinT3R to achieve state-of-the-art performance in terms of online reconstruction quality, camera pose estimation, and reconstruction speed, as validated by extensive experiments on diverse datasets. Code and model are publicly available at https://github.com/LiZizun/WinT3R.",
            "score": 1,
            "issue_id": 5764,
            "pub_date": "2025-09-05",
            "pub_date_card": {
                "ru": "5 сентября",
                "en": "September 5",
                "zh": "9月5日"
            },
            "hash": "b6ac447839602a03",
            "authors": [
                "Zizun Li",
                "Jianjun Zhou",
                "Yifan Wang",
                "Haoyu Guo",
                "Wenzheng Chang",
                "Yang Zhou",
                "Haoyi Zhu",
                "Junyi Chen",
                "Chunhua Shen",
                "Tong He"
            ],
            "affiliations": [
                "SII",
                "Shanghai AI Lab",
                "University of Science and Technology of China",
                "Zhejiang University"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.05296.jpg",
            "data": {
                "categories": [
                    "#benchmark",
                    "#dataset",
                    "#cv"
                ],
                "emoji": "🎥",
                "ru": {
                    "title": "WinT3R: Революция в реконструкции камер в реальном времени",
                    "desc": "WinT3R - это модель прямого распространения для реконструкции, которая обеспечивает высококачественную оценку положения камеры и работу в режиме реального времени. Модель использует механизм скользящего окна для обмена информацией между кадрами, что улучшает качество геометрических предсказаний. WinT3R также применяет компактное представление камер и глобальный пул токенов камеры для повышения надежности оценки положения. Эти инновации позволяют модели достичь передовых результатов в онлайн-реконструкции, оценке положения камеры и скорости реконструкции."
                },
                "en": {
                    "title": "WinT3R: Real-Time Camera Pose Estimation with High Precision",
                    "desc": "WinT3R is a feed-forward reconstruction model designed for accurate camera pose estimation and efficient real-time performance. It utilizes a sliding window mechanism to facilitate effective information sharing among frames, enhancing the quality of geometric predictions while minimizing computational load. Additionally, the model incorporates a global camera token pool, which improves the reliability of pose estimation without compromising speed. As a result, WinT3R achieves state-of-the-art performance in online reconstruction tasks, as demonstrated through extensive testing on various datasets."
                },
                "zh": {
                    "title": "WinT3R：高效精准的相机姿态估计",
                    "desc": "WinT3R是一种前馈重建模型，能够实时预测精确的相机姿态和高质量的点云地图。以往的方法在重建质量和实时性能之间存在权衡。为了解决这个问题，我们引入了滑动窗口机制，确保窗口内帧之间的信息充分交流，从而提高几何预测的质量。通过维护一个全局相机令牌池，WinT3R在不牺牲效率的情况下增强了相机姿态估计的可靠性。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.03800",
            "title": "MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in\n  3D CT Disease Detection, Understanding and Reporting",
            "url": "https://huggingface.co/papers/2509.03800",
            "abstract": "MedVista3D is a multi-scale semantic-enriched vision-language pretraining framework for 3D CT analysis that addresses local-global understanding, report variability, and achieves state-of-the-art performance in disease classification, report retrieval, and medical visual question answering.  \t\t\t\t\tAI-generated summary \t\t\t\t Radiologic diagnostic errors-under-reading errors, inattentional blindness, and communication failures-remain prevalent in clinical practice. These issues often stem from missed localized abnormalities, limited global context, and variability in report language. These challenges are amplified in 3D imaging, where clinicians must examine hundreds of slices per scan. Addressing them requires systems with precise localized detection, global volume-level reasoning, and semantically consistent natural language reporting. However, existing 3D vision-language models are unable to meet all three needs jointly, lacking local-global understanding for spatial reasoning and struggling with the variability and noise of uncurated radiology reports. We present MedVista3D, a multi-scale semantic-enriched vision-language pretraining framework for 3D CT analysis. To enable joint disease detection and holistic interpretation, MedVista3D performs local and global image-text alignment for fine-grained representation learning within full-volume context. To address report variability, we apply language model rewrites and introduce a Radiology Semantic Matching Bank for semantics-aware alignment. MedVista3D achieves state-of-the-art performance on zero-shot disease classification, report retrieval, and medical visual question answering, while transferring well to organ segmentation and prognosis prediction. Code and datasets will be released.",
            "score": 1,
            "issue_id": 5762,
            "pub_date": "2025-09-04",
            "pub_date_card": {
                "ru": "4 сентября",
                "en": "September 4",
                "zh": "9月4日"
            },
            "hash": "ad0922456cbd778e",
            "authors": [
                "Yuheng Li",
                "Yenho Chen",
                "Yuxiang Lai",
                "Jike Zhong",
                "Vanessa Wildman",
                "Xiaofeng Yang"
            ],
            "affiliations": [
                "Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA",
                "Department of Computer Science, University of Southern California, Los Angeles, CA",
                "Department of Machine Learning, Georgia Institute of Technology, Atlanta, GA",
                "Department of Radiation Oncology, Emory University School of Medicine, Atlanta, USA"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.03800.jpg",
            "data": {
                "categories": [
                    "#multimodal",
                    "#science",
                    "#healthcare",
                    "#transfer_learning",
                    "#3d"
                ],
                "emoji": "🏥",
                "ru": {
                    "title": "Улучшение анализа КТ с помощью многомасштабного обучения компьютерного зрения и обработки естественного языка",
                    "desc": "MedVista3D - это фреймворк для предварительного обучения многомасштабных семантически обогащенных моделей компьютерного зрения и обработки естественного языка для анализа 3D КТ-изображений. Он решает проблемы локально-глобального понимания и вариативности медицинских отчетов. MedVista3D использует выравнивание изображения и текста на локальном и глобальном уровнях для детального представления в контексте полного объема. Фреймворк достигает передовых результатов в классификации заболеваний, поиске отчетов и медицинских вопросно-ответных системах."
                },
                "en": {
                    "title": "Revolutionizing 3D CT Analysis with MedVista3D",
                    "desc": "MedVista3D is a new framework designed to improve the analysis of 3D CT scans by combining vision and language understanding. It tackles common problems in radiology, such as missing details and inconsistent report language, by enhancing local and global context in image analysis. The framework uses advanced techniques for aligning images with text, allowing for better disease detection and interpretation of medical reports. MedVista3D has shown to outperform existing models in tasks like disease classification and report retrieval, making it a significant advancement in medical imaging technology."
                },
                "zh": {
                    "title": "MedVista3D：提升3D CT分析的智能框架",
                    "desc": "MedVista3D是一个多尺度语义增强的视觉-语言预训练框架，专门用于3D CT分析。它解决了局部与全局理解、报告变异性等问题，并在疾病分类、报告检索和医学视觉问答中达到了最先进的性能。该框架通过局部和全局图像-文本对齐，实现了细粒度的表示学习，并引入了语义匹配库来处理报告的变异性。MedVista3D在零样本疾病分类和器官分割等任务中表现优异，展示了其在医学影像分析中的潜力。"
                }
            }
        },
        {
            "id": "https://huggingface.co/papers/2509.04504",
            "title": "Behavioral Fingerprinting of Large Language Models",
            "url": "https://huggingface.co/papers/2509.04504",
            "abstract": "A Behavioral Fingerprinting framework evaluates Large Language Models using a Diagnostic Prompt Suite and automated pipeline, revealing divergent alignment behaviors and clustering patterns.  \t\t\t\t\tAI-generated summary \t\t\t\t Current benchmarks for Large Language Models (LLMs) primarily focus on performance metrics, often failing to capture the nuanced behavioral characteristics that differentiate them. This paper introduces a novel ``Behavioral Fingerprinting'' framework designed to move beyond traditional evaluation by creating a multi-faceted profile of a model's intrinsic cognitive and interactive styles. Using a curated Diagnostic Prompt Suite and an innovative, automated evaluation pipeline where a powerful LLM acts as an impartial judge, we analyze eighteen models across capability tiers. Our results reveal a critical divergence in the LLM landscape: while core capabilities like abstract and causal reasoning are converging among top models, alignment-related behaviors such as sycophancy and semantic robustness vary dramatically. We further document a cross-model default persona clustering (ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together, this suggests that a model's interactive nature is not an emergent property of its scale or reasoning power, but a direct consequence of specific, and highly variable, developer alignment strategies. Our framework provides a reproducible and scalable methodology for uncovering these deep behavioral differences. Project: https://github.com/JarvisPei/Behavioral-Fingerprinting",
            "score": 1,
            "issue_id": 5763,
            "pub_date": "2025-09-02",
            "pub_date_card": {
                "ru": "2 сентября",
                "en": "September 2",
                "zh": "9月2日"
            },
            "hash": "c8bc7caa6cf21161",
            "authors": [
                "Zehua Pei",
                "Hui-Ling Zhen",
                "Ying Zhang",
                "Zhiyuan Yang",
                "Xing Li",
                "Xianzhi Yu",
                "Mingxuan Yuan",
                "Bei Yu"
            ],
            "affiliations": [
                "Noahs Ark Lab, Huawei",
                "The Chinese University of Hong Kong"
            ],
            "pdf_title_img": "assets/pdf/title_img/2509.04504.jpg",
            "data": {
                "categories": [
                    "#dataset",
                    "#alignment",
                    "#benchmark",
                    "#interpretability"
                ],
                "emoji": "🧠",
                "ru": {
                    "title": "Поведенческий отпечаток: новый взгляд на оценку языковых моделей",
                    "desc": "Статья представляет новую методологию оценки больших языковых моделей (LLM), названную 'Поведенческим отпечатком'. Этот подход использует набор диагностических промптов и автоматизированный конвейер оценки, где мощная LLM выступает в роли беспристрастного судьи. Исследование выявило значительные различия в поведении моделей, связанном с выравниванием (alignment), несмотря на сходство в базовых когнитивных способностях. Результаты показывают, что интерактивная природа модели является прямым следствием конкретных стратегий выравнивания, а не просто побочным эффектом масштаба или мощности рассуждений."
                },
                "en": {
                    "title": "Unveiling the Hidden Behaviors of Language Models",
                    "desc": "This paper presents a new framework called 'Behavioral Fingerprinting' to evaluate Large Language Models (LLMs) beyond just their performance metrics. It uses a Diagnostic Prompt Suite and an automated evaluation pipeline to analyze the cognitive and interactive styles of various models. The study finds that while core reasoning abilities are becoming similar among top models, their alignment behaviors, such as sycophancy and semantic robustness, show significant differences. This indicates that a model's behavior is influenced more by the developers' alignment strategies than by its size or reasoning capabilities."
                },
                "zh": {
                    "title": "揭示大型语言模型的行为特征",
                    "desc": "本文提出了一种新的“行为指纹”框架，用于评估大型语言模型（LLMs），超越传统的性能指标，关注模型的行为特征。通过使用精心设计的诊断提示套件和自动化评估流程，分析了十八种不同能力层次的模型。研究发现，尽管顶级模型在抽象和因果推理等核心能力上趋于一致，但在对齐相关的行为（如谄媚和语义稳健性）上却存在显著差异。该框架为揭示模型之间深层次的行为差异提供了一种可重复和可扩展的方法。"
                }
            }
        }
    ],
    "link_prev": "2025-09-05.html",
    "link_next": "2025-09-09.html",
    "link_month": "2025-09.html",
    "short_date_prev": {
        "ru": "05.09",
        "en": "09/05",
        "zh": "9月5日"
    },
    "short_date_next": {
        "ru": "09.09",
        "en": "09/09",
        "zh": "9月9日"
    },
    "categories": {
        "#dataset": 3,
        "#data": 1,
        "#benchmark": 5,
        "#agents": 1,
        "#cv": 1,
        "#rl": 0,
        "#rlhf": 0,
        "#rag": 0,
        "#plp": 0,
        "#inference": 0,
        "#3d": 2,
        "#audio": 0,
        "#video": 0,
        "#multimodal": 3,
        "#math": 0,
        "#multilingual": 0,
        "#architecture": 0,
        "#healthcare": 1,
        "#training": 1,
        "#robotics": 0,
        "#agi": 0,
        "#games": 1,
        "#interpretability": 2,
        "#reasoning": 2,
        "#transfer_learning": 1,
        "#graphs": 0,
        "#ethics": 1,
        "#security": 0,
        "#optimization": 1,
        "#survey": 1,
        "#diffusion": 0,
        "#alignment": 1,
        "#story_generation": 0,
        "#hallucinations": 1,
        "#long_context": 0,
        "#synthetic": 0,
        "#machine_translation": 0,
        "#leakage": 0,
        "#open_source": 0,
        "#small_models": 0,
        "#science": 1,
        "#low_resource": 0,
        "#evaluation": 1
    }
}